,@Id,@ParentId,@ContentLicense,@CreationDate,@Body,@OwnerUserId,@LastActivityDate,@Code
0,20,19,CC BY-SA 4.0,2017-02-28T17:08:12.693,"<p>There's a couple of way to achieve the result:</p>

<ol>
<li><p>Chef has a <code>trusted_dir</code> to allow adding certificate to the trusted list. the <a href=""https://docs.chef.io/chef_client_security.html#ssl-certificates"" rel=""nofollow noreferrer"">documentation</a> has a lot of details about it. Adding your CA certificate to this directory would solve the problem. <code>knife</code> has it also in a slightly different path as per it's own <a href=""https://docs.chef.io/knife_ssl_fetch.html"" rel=""nofollow noreferrer"">documentation</a></p></li>
<li><p>Chef use its own CA certiticate list in <code>/opt/chef/embedded/ssl/certs/cacert.pem</code>. 
You can add your CA certificate at end of this list to trust it. </p></li>
</ol>

<p>The second option has an advantage of allowing you to export the environment variable <code>SSL_CERT_FILE</code> pointing to chef <code>cacert.pem</code> to allow most of the tools using <code>openssl</code> library to know your CA certificate.</p>

<p>For the case of a self signed certificate on the chef server (or another server used as target in a recipe), <code>knife ssl_fetch</code> would allow all knife commands to work.</p>

<p>To add the server certificate to the cacert.pem for the case 2. above, you can use the following command:</p>

<pre><code># For a self signed CA certiticate
openssl s_client -showcerts -connect &lt;YOUR_CHEF_SERVER&gt;:443 &lt;/dev/null 2&gt;/dev/null|openssl x509 -outform PEM &gt;&gt; /opt/chefdk/embedded/ssl/certs/cacert.pem

# For an internal CA signed certificate:
openssl s_client -showcerts -verify 5 -connect &lt;YOUR_CHEF_SERVER&gt;:443 &lt;/dev/null 2&gt;/dev/null | awk '/BEGIN/,/END/{if(/BEGIN/){a++}; certs[a]=(certs[a] ""\n"" $0)}; END {print certs[a]}' &gt;&gt; /opt/chefdk/embedded/ssl/certs/cacert.pem

export SSL_CERT_FILE=/opt/chefdk/embedded/ssl/certs/cacert.pem
</code></pre>

<p>The openssl command is included in chef-dk, so this can be done under windows also.  Change the path to <code>c:\opscode\</code> instead of <code>/opt/</code>. To export the environment variable use <code>set SSL_CERT_FILE=...</code> (with <code>/P</code> to add it permanently to your environment) in your command.</p>
",13,2020-01-29T09:44:30.313,"['# For a self signed CA certiticate\nopenssl s_client -showcerts -connect <YOUR_CHEF_SERVER>:443 </dev/null 2>/dev/null|openssl x509 -outform PEM >> /opt/chefdk/embedded/ssl/certs/cacert.pem\n\n# For an internal CA signed certificate:\nopenssl s_client -showcerts -verify 5 -connect <YOUR_CHEF_SERVER>:443 </dev/null 2>/dev/null | awk \'/BEGIN/,/END/{if(/BEGIN/){a++}; certs[a]=(certs[a] ""\\n"" $0)}; END {print certs[a]}\' >> /opt/chefdk/embedded/ssl/certs/cacert.pem\n\nexport SSL_CERT_FILE=/opt/chefdk/embedded/ssl/certs/cacert.pem\n']"
1,27,21,CC BY-SA 3.0,2017-02-28T17:15:06.537,"<p>There are many ways to do this but the easiest way I can think is doing a backup of the Jenkins Home folder.</p>

<p>You can see where is your Jenkins home with:</p>

<pre><code>echo $JENKINS_HOME
</code></pre>

<p>And for example, if you only want to backup the jobs you can go to:</p>

<pre><code>cd $JENKINS_HOME/jobs
</code></pre>

<p>And make a backup for that folder.</p>

<p>All that configuration will be a bunch of <strong>XML</strong> files.</p>

<p>If you are using the <a href=""https://hub.docker.com/_/jenkins/"" rel=""noreferrer"">official Jenkins docker image</a>, the home will be on:</p>

<pre><code>/var/jenkins_home
</code></pre>
",15,2017-02-28T17:15:06.537,"['echo $JENKINS_HOME\n', 'cd $JENKINS_HOME/jobs\n', '/var/jenkins_home\n']"
2,38,37,CC BY-SA 3.0,2017-02-28T17:21:13.990,"<p>Yes. AWS CodeDeploy bundletype is specified separately from the revision location, so you could upload a .nupkg to Amazon S3, set the bundle type to 'zip', and since a nupkg is simply an archive CodeDeploy will treat it as such and upload it to your EC2 instance.</p>

<p>In your nuspec, make sure your appspec.yml gets placed in the root of your .nupkg. My project contains the appspec.yml and powershell scripts to manage windows services in a directory structure like this:</p>

<pre><code>deploy/appspec.yml
deploy/lib/get.ps1
deploy/lib/start.ps1
deploy/lib/stop.ps1
...
</code></pre>

<p>You can include this structure at the root by simply recursively retrieving this directory structure (via double wildcards <code>**</code>) in the nuspec files element:</p>

<pre><code>&lt;files&gt;
  &lt;file src=""deploy\**"" target="""" /&gt;
&lt;/files&gt;  
</code></pre>

<p>And then after packing and outputting the nupkg, you can create the application revision as below:</p>

<p><a href=""https://i.stack.imgur.com/ZjJoI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZjJoI.png"" alt=""enter image description here""></a></p>
",36,2017-02-28T17:34:37.370,"['deploy/appspec.yml\ndeploy/lib/get.ps1\ndeploy/lib/start.ps1\ndeploy/lib/stop.ps1\n...\n', '<files>\n  <file src=""deploy\\**"" target="""" />\n</files>  \n']"
3,39,10,CC BY-SA 3.0,2017-02-28T17:21:28.930,"<p>Cloud-init files are essentially bootstrap codes, that run before each startup, and can - among others - modify files, set up services, create users, etc.</p>

<p>Not all types of droplets support all functionalities of cloud-init, for example CoreOS uses it's own implementation, with a very limited subset of valid values.</p>

<p>To use this in terraform, simply provide the cloud-init file during droplet creation:</p>

<p><code>main.tf</code>:</p>

<pre><code>resource ""digitalocean_droplet"" ""web"" {
  image              = ""coreos-stable""
  name               = ""web""
  region             = ""lon1""
  size               = ""2gb""
  private_networking = true
  ssh_keys           = [""${digitalocean_ssh_key.dodemo.id}""]
  user_data          = ""${file(""web.conf"")}""
}
</code></pre>

<p><code>web.conf</code>:</p>

<pre><code>#cloud-config
coreos:
  units:
    - name: ""etcd2.service""
      command: ""start""
    - name: ""fleet.service""
      command: ""start""
</code></pre>

<p>This will for example create a droplet, where CoreOS will run etcd2 and fleet during startup</p>

<p>You can find some more examples <a href=""https://github.com/sztupy/doclusterdemo/tree/master/terraform"" rel=""noreferrer"">in this repository</a>, where I show how one can use these configuration options to set up some simple docker based services on CoreOS</p>
",27,2017-02-28T17:21:28.930,"['resource ""digitalocean_droplet"" ""web"" {\n  image              = ""coreos-stable""\n  name               = ""web""\n  region             = ""lon1""\n  size               = ""2gb""\n  private_networking = true\n  ssh_keys           = [""${digitalocean_ssh_key.dodemo.id}""]\n  user_data          = ""${file(""web.conf"")}""\n}\n', '#cloud-config\ncoreos:\n  units:\n    - name: ""etcd2.service""\n      command: ""start""\n    - name: ""fleet.service""\n      command: ""start""\n']"
4,88,87,CC BY-SA 3.0,2017-02-28T18:37:25.087,"<p>This can be achieved by using <a href=""https://wiki.jenkins-ci.org/display/JENKINS/Post+build+task"" rel=""nofollow noreferrer"">Post build task</a> plugin and by adding the following <em>Script</em> command in <em>Post-build Action</em>, <em>Post build task</em> solved the problem:</p>

<pre><code>vagrant destroy -f
</code></pre>

<p>Plus adding rule with <em>Log text</em> as ""Build was aborted"" make sure that above command is only invoked on aborted builds.</p>

<p>For example:</p>

<p><a href=""https://i.stack.imgur.com/40brUl.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/40brUl.png"" alt=""Jenkins, screenshot Script, Post-build Action, Log text, Build was aborted""></a></p>
",3,2017-03-01T12:09:16.020,['vagrant destroy -f\n']
5,148,47,CC BY-SA 3.0,2017-03-01T08:49:15.780,"<p>Connecting a node to Jenkins through a terminal only is a two step process.</p>

<p>First, you should ssh into into your node machines and set them up with the following steps:</p>

<ol>
<li><p>Make a jenkins user shell:  <code>sudo adduser jenkins --shell /bin/bash</code></p></li>
<li><p>Create the directory after switching to the jenkins user:  <code>mkdir /home/jenkins/jenkins_slave</code></p></li>
<li><p>Create your SSH credentials to be used in the following bash script.</p></li>
</ol>

<p>Then, once your nodes are set up, you will need to connect to your jenkins machine and run bash script such as this <a href=""https://gist.github.com/sergeyhush/4e892837cf5c31c3d242"" rel=""nofollow noreferrer"">one</a> to connect your nodes to your master:</p>

  

<pre><code>#!/bin/bash

JENKINS_URL=$1
NODE_NAME=$2
NODE_SLAVE_HOME='/home/build/slave'
EXECUTORS=1
SSH_PORT=22
CRED_ID=$3
LABELS=build
USERID=${USER}

cat &lt;&lt;EOF | java -jar ~/bin/jenkins-cli.jar -s $1 create-node $2
&lt;slave&gt;
  &lt;name&gt;${NODE_NAME}&lt;/name&gt;
  &lt;description&gt;&lt;/description&gt;
  &lt;remoteFS&gt;${NODE_SLAVE_HOME}&lt;/remoteFS&gt;
  &lt;numExecutors&gt;${EXECUTORS}&lt;/numExecutors&gt;
  &lt;mode&gt;NORMAL&lt;/mode&gt;
  &lt;retentionStrategy class=""hudson.slaves.RetentionStrategy$Always""/&gt;
  &lt;launcher class=""hudson.plugins.sshslaves.SSHLauncher"" plugin=""ssh-slaves@1.5""&gt;
    &lt;host&gt;${NODE_NAME}&lt;/host&gt;
    &lt;port&gt;${SSH_PORT}&lt;/port&gt;
    &lt;credentialsId&gt;${CRED_ID}&lt;/credentialsId&gt;
  &lt;/launcher&gt;
  &lt;label&gt;${LABELS}&lt;/label&gt;
  &lt;nodeProperties/&gt;
  &lt;userId&gt;${USERID}&lt;/userId&gt;
&lt;/slave&gt;
EOF
</code></pre>
",10,2017-03-01T08:49:15.780,"['#!/bin/bash\n\nJENKINS_URL=$1\nNODE_NAME=$2\nNODE_SLAVE_HOME=\'/home/build/slave\'\nEXECUTORS=1\nSSH_PORT=22\nCRED_ID=$3\nLABELS=build\nUSERID=${USER}\n\ncat <<EOF | java -jar ~/bin/jenkins-cli.jar -s $1 create-node $2\n<slave>\n  <name>${NODE_NAME}</name>\n  <description></description>\n  <remoteFS>${NODE_SLAVE_HOME}</remoteFS>\n  <numExecutors>${EXECUTORS}</numExecutors>\n  <mode>NORMAL</mode>\n  <retentionStrategy class=""hudson.slaves.RetentionStrategy$Always""/>\n  <launcher class=""hudson.plugins.sshslaves.SSHLauncher"" plugin=""ssh-slaves@1.5"">\n    <host>${NODE_NAME}</host>\n    <port>${SSH_PORT}</port>\n    <credentialsId>${CRED_ID}</credentialsId>\n  </launcher>\n  <label>${LABELS}</label>\n  <nodeProperties/>\n  <userId>${USERID}</userId>\n</slave>\nEOF\n']"
6,167,149,CC BY-SA 3.0,2017-03-01T13:04:33.890,"<p>I think your can do some kind of alerting on a metric <code>rate</code> with something like this:</p>

<pre><code>ALERT DropInMetricsFromExporter
  IF rate(&lt;metric_name&gt;[1m]) == 0
  FOR 3m
  ANNOTATIONS {
    summary = ""Rate of metrics is 0 {{ $labels.&lt;your_label&gt; }}"",
    description = ""Rate of metric dropped, actually: {{ $value }}%"",
}
</code></pre>

<p>The main idea is to alert whenever the metric rate is at 0 for 3 minutes, with the proper metric name and a label somewhere telling from which exporter it comes it should give you the correct information.  </p>

<p>Choosing the right metric to monitor by exporter could be complex, without more insight is hard to give a better advice out of vacuum.<br>
This <a href=""https://prometheus.io/blog/2015/06/18/practical-anomaly-detection/"" rel=""noreferrer"">blog post</a> could be an inspiration also for a more generic detection.</p>
",13,2017-03-01T13:04:33.890,"['ALERT DropInMetricsFromExporter\n  IF rate(<metric_name>[1m]) == 0\n  FOR 3m\n  ANNOTATIONS {\n    summary = ""Rate of metrics is 0 {{ $labels.<your_label> }}"",\n    description = ""Rate of metric dropped, actually: {{ $value }}%"",\n}\n']"
7,172,58,CC BY-SA 3.0,2017-03-01T13:56:49.463,"<p>The installation of Windows application can be automated using <a href=""https://autohotkey.com/"" rel=""nofollow noreferrer"">AutoHotkey</a> (AHK), similar as <a href=""https://github.com/Winetricks/winetricks/blob/master/src/winetricks"" rel=""nofollow noreferrer"">Winetricks</a> does this for all common apps which support.</p>

<p>Here is example of AHK script which aims to install mentioned application:</p>

<pre><code>Run, mt5setup.exe
WinWait, MetaTrader 5 Setup
ControlClick, Button1
Sleep 100
ControlClick, Button3
WinWait, MetaTrader 5 Setup, Installation successfully completed
ControlClick, Button4
Process, Wait, terminal.exe
Process, Close, terminal.exe
</code></pre>

<p>To integrate it with CI, AHK needs to be installed by downloading ZIP file, uncompressing it and passing the above AHK script. Suggested <code>appveyor.yml</code> file:</p>

<pre><code>install:
- curl -sLo https://www.metatrader5.com/en/download
- curl -sLo http://www.autohotkey.com/download/AutoHotkey104805.zip
- unzip *.zip
before_test:
- dir
test_script:
- AutoHotkey.exe install.ahk
build: off
platform: x86
</code></pre>

<p>where <code>install.ahk</code> is the file to contain above AHK script which can be dynamically generated or downloaded from some repository.</p>
",3,2017-10-22T13:51:49.877,"['Run, mt5setup.exe\nWinWait, MetaTrader 5 Setup\nControlClick, Button1\nSleep 100\nControlClick, Button3\nWinWait, MetaTrader 5 Setup, Installation successfully completed\nControlClick, Button4\nProcess, Wait, terminal.exe\nProcess, Close, terminal.exe\n', 'install:\n- curl -sLo https://www.metatrader5.com/en/download\n- curl -sLo http://www.autohotkey.com/download/AutoHotkey104805.zip\n- unzip *.zip\nbefore_test:\n- dir\ntest_script:\n- AutoHotkey.exe install.ahk\nbuild: off\nplatform: x86\n']"
8,174,173,CC BY-SA 3.0,2017-03-01T14:08:25.377,"<p>As for workaround, the actual memory can be checked by invoking Groovy commands directly in <em>Script Console</em> (at <code>/computer/(master)/script</code>). Example command:</p>

<pre><code>println ""free -m"".execute().text
</code></pre>
",3,2017-03-01T14:08:25.377,"['println ""free -m"".execute().text\n']"
9,179,175,CC BY-SA 3.0,2017-03-01T15:08:19.913,"<p>You can use a <a href=""https://jenkins.io/doc/book/pipeline/"" rel=""noreferrer"">pipeline</a> to tie the jobs together, executing them either in parallel or sequentially through steps.<br>
You can pass the relevant parameters to each job as you call it from the pipeline script.<br>
Then you just need to rebuild a single pipeline job. You can tie the jobs together with a common build name through a variable as well.</p>

<pre><code>build job: 'buildjob1', parameters: [
  [$class: 'StringParameterValue', name: 'BUILD_NAME', value: ${env.JOB_BASE_NAME}-${env.BUILD_NUMBER}""], 
  [$class: 'StringParameterValue', name: 'FIXEDPARAM', value: 'some-string'],
  [$class: 'StringParameterValue', name: 'PARAM1', value: ""${PARAM1}""]
]
</code></pre>
",228,2017-03-01T15:12:42.387,"['build job: \'buildjob1\', parameters: [\n  [$class: \'StringParameterValue\', name: \'BUILD_NAME\', value: ${env.JOB_BASE_NAME}-${env.BUILD_NUMBER}""], \n  [$class: \'StringParameterValue\', name: \'FIXEDPARAM\', value: \'some-string\'],\n  [$class: \'StringParameterValue\', name: \'PARAM1\', value: ""${PARAM1}""]\n]\n']"
10,198,195,CC BY-SA 3.0,2017-03-02T01:50:59.160,"<p>There are a lot of specifics but the overall pattern we use is ""wrap and extend"". The general idea is to make a cookbook that depends on the community cookbook, usually named <code>mycompany_originalthing</code>, and then make recipes in that which call <code>include_recipe 'originalthing::whatever'</code> but with either more stuff added before/after or with calls to things like <code>edit_resource</code> to change resources. Avoid <code>edit_resource</code> when possible since it leads to brittle code, but it is there if you need it. You can also use wrapper cookbooks to set attributes, subclass or wrap custom resources, and so on.</p>

<p>For the specific case of ""I need to tweak a template in a community recipe"" it would look like this:</p>

<pre><code>include_recipe 'original::whatever'

edit_resource!(:template, '/path/to/something') do
  source 'mytemplate.erb'
  cookbook 'mycompany_original'
end
</code></pre>

<p>You can find more details about <code>edit_resource</code> and friends at <a href=""https://coderanger.net/rewind/"" rel=""noreferrer"">https://coderanger.net/rewind/</a></p>

<p>With cookbooks based around custom resources instead of recipes, things can get more complex but the specifics depend a lot on the how exactly the cookbook you are extending is written.</p>
",154,2017-03-02T01:50:59.160,"[""include_recipe 'original::whatever'\n\nedit_resource!(:template, '/path/to/something') do\n  source 'mytemplate.erb'\n  cookbook 'mycompany_original'\nend\n""]"
11,211,208,CC BY-SA 3.0,2017-03-02T10:48:01.473,"<p>Disclaimer: I'm not using Ansible.</p>

<p>What I would do is use a random ""predictable"" number.
According to Ansible doc you can seed the random number generator:</p>

<blockquote>
  <p>As of Ansible version 2.3, it’s also possible to initialize the random
  number generator from a seed. This way, you can create
  random-but-idempotent numbers:</p>
  
  <p>""{{ 59 |random(seed=inventory_hostname) }} * * * * root
  /script/from/cron""</p>
</blockquote>

<p>So in your case for a port number (I assume unpriviledged) I would go for a variable with something like:</p>

<pre><code>port=""{{ 32767 |random(start=1024,seed=service_name) }}""
</code></pre>

<p>Max at 32767 to avoid clashing with any client initiated port (See <a href=""https://en.wikipedia.org/wiki/Ephemeral_port"" rel=""noreferrer"">Ephemeral port</a> for the reason).</p>
",13,2017-03-02T10:48:01.473,"['port=""{{ 32767 |random(start=1024,seed=service_name) }}""\n']"
12,223,202,CC BY-SA 3.0,2017-03-02T13:22:54.443,"<p>There are two parts of this Vagrantfile, one does the mounting for Windows hosts (the first half), the other one for UNIX hosts (the second half), but essentially the do the same - just with different plugins.</p>

<p>You can see from the <code>config.vm.synced_folder</code> and <code>config.bindfs.bind_folder</code> commands where they set up the appropriate directories with the proper permissions.</p>

<p>To add a new directory with different permissions simply add them to the list. Note that <code>File.join('a','b')</code> simply converts the path to <code>a/b</code>, but it's a nicer way to do it, as it's platform independent (on Windows it can also handle <code>\</code> style paths).</p>

<p>So for example if you want to give the <code>/tmp/needswrite</code> folder more permission you can simply add the following two lines to their appropriate places:</p>

<p>Windows config:</p>

<pre><code>config.vm.synced_folder File.join(ANSIBLE_PATH, 'tmp', 'needswrite'), File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), mount_options: ['dmode=777', 'fmode=777']
</code></pre>

<p>Unix config:</p>

<pre><code>config.bindfs.bind_folder File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), perms: '0777'
</code></pre>

<p>This will for example set their permission to <code>777</code> instead of the default <code>755</code></p>

<p>Note that in the Windows config you have to map from <code>ANSIBLE_PATH</code> to <code>ANSIBLE_PATH_ON_VM</code>, while on the Unix config bindfs will do a remount, so you need to match them with the same directory name.</p>

<p>You can also play with users and groups:</p>

<p>Windows config:</p>

<pre><code>config.vm.synced_folder File.join(ANSIBLE_PATH, 'tmp', 'needswrite'), File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), owner: 'new-owner', group: 'new-group', mount_options: ['dmode=755', 'fmode=755']
</code></pre>

<p>Unix config:</p>

<pre><code>config.bindfs.bind_folder File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), u: 'new-owner', g: 'new-group', perms: '0777'
</code></pre>

<p>Here we set them to use user <code>new-owner</code> and group <code>new-group</code></p>
",27,2017-03-02T13:22:54.443,"[""config.vm.synced_folder File.join(ANSIBLE_PATH, 'tmp', 'needswrite'), File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), mount_options: ['dmode=777', 'fmode=777']\n"", ""config.bindfs.bind_folder File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), perms: '0777'\n"", ""config.vm.synced_folder File.join(ANSIBLE_PATH, 'tmp', 'needswrite'), File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), owner: 'new-owner', group: 'new-group', mount_options: ['dmode=755', 'fmode=755']\n"", ""config.bindfs.bind_folder File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), File.join(ANSIBLE_PATH_ON_VM, 'tmp', 'needswrite'), u: 'new-owner', g: 'new-group', perms: '0777'\n""]"
13,252,251,CC BY-SA 3.0,2017-03-02T23:29:44.160,"<p>A few things need to happen for this to work properly. First, add a <code>deployment</code> section to circle.yml:</p>

<pre><code>deployment:
  main: # or whatever your deployment is called
    branch: master # or whatever branch you want to deploy
    commands:
      - docker login -e (your email here) -u (your username here) -p (your password here)
      - docker push pgeiss/appname
      - ./start.sh
</code></pre>

<p><em>Thanks to <a href=""http://www.mikeheijmans.com/docker/2015/09/07/automated-docker-deployment-with-circle/"" rel=""noreferrer"">this blog post</a> for the following script.</em> Then, make a file called start.sh in the top level of your repository (if you use a different name, change the circle.yml's last line) that contains the following:</p>

<pre><code>#!/usr/bin/env bash

echo ""stopping running application""
ssh $DEPLOY_USER@$DEPLOY_HOST 'docker stop dodsv'
ssh $DEPLOY_USER@$DEPLOY_HOST 'docker rm dodsv'

echo ""pulling latest version of the code""
ssh $DEPLOY_USER@$DEPLOY_HOST 'docker pull pgeiss/appname-webapp:latest'

echo ""starting the new version""
ssh $DEPLOY_USER@$DEPLOY_HOST 'docker run -d --restart=always --name dodsv -p 80:5432 pgeiss/appname:latest'

echo ""success!""

exit 0
</code></pre>

<p>Finally, to allow the script to work you'll need to set the script to be executable with <code>chmod</code> and add the environment variables and your <code>DEPLOY_USER</code>'s ssh key (preferably) or credentials (if no ssh key) to CircleCI. After doing that CircleCI should deploy your app after a successful build.</p>
",201,2017-03-02T23:29:44.160,"['deployment:\n  main: # or whatever your deployment is called\n    branch: master # or whatever branch you want to deploy\n    commands:\n      - docker login -e (your email here) -u (your username here) -p (your password here)\n      - docker push pgeiss/appname\n      - ./start.sh\n', '#!/usr/bin/env bash\n\necho ""stopping running application""\nssh $DEPLOY_USER@$DEPLOY_HOST \'docker stop dodsv\'\nssh $DEPLOY_USER@$DEPLOY_HOST \'docker rm dodsv\'\n\necho ""pulling latest version of the code""\nssh $DEPLOY_USER@$DEPLOY_HOST \'docker pull pgeiss/appname-webapp:latest\'\n\necho ""starting the new version""\nssh $DEPLOY_USER@$DEPLOY_HOST \'docker run -d --restart=always --name dodsv -p 80:5432 pgeiss/appname:latest\'\n\necho ""success!""\n\nexit 0\n']"
14,274,54,CC BY-SA 3.0,2017-03-03T10:40:08.113,"<p>First, while <strong>Docker</strong> is sometimes seen and used as a <em>ad hoc</em> packaging system, it actually solves a totally different problem: <strong>Docker</strong> is about <em>running</em> programs. The <strong>Docker</strong> system allows to describe <em>services,</em> that can be <em>scaled</em> at will and to control <em>swarms</em> of containers. <strong>Debian packages</strong> are for installing programs and they are able to handle <em>dependencies</em> between software versions.  <strong>Docker</strong> certainly don't qualify as a descent packaging system: each “package” can only have one dependency, the system has no “recursive build” option and does not support complex version constraints!</p>

<p>A possible answer would be that, if you are willing to write a <strong>Debian package</strong> for your application, you can also use <strong>Docker</strong> to deploy your application.  This can be achieved with a configuration script <code>apt_setup.sh</code> which would look like</p>

<pre><code>apt-key add - &lt;&lt;EOF
-----BEGIN PGP PUBLIC KEY BLOCK-----
&lt;YOUR RELEASE OFFICER PGP KEY GOES HERE&gt;
EOF

cat &gt;&gt; /etc/apt/sources.list &lt;&lt;EOF
deb https://my.organisation.org/repo debian-jessie main
apt-get update -y
apt-get upgrade -y
EOF
</code></pre>

<p>and a <code>Dockerfile</code> along the lines of</p>

<pre><code>ADD apt_setup.sh /root
RUN sh -ex /root/apt_setup.sh &amp;&amp; rm /root/apt_setup.sh
RUN apt-get install -y my-node-js-package
</code></pre>

<p>(In your specific situation, the <code>apt_setup.sh</code> would be more complicated, adding the <em>nodesource</em> repositories and some helper packages such as <em>apt-transport-https</em>.)</p>

<p>It is therefore really possible to use <strong>Debian packages</strong> and <strong>Docker</strong> simultaneously, however …</p>

<blockquote>
  <p>My gut […] is telling me that if deb packages were a good fit, it would be more common</p>
</blockquote>

<p>This is a correct hitch which leads us to ask ourselves why <strong>Docker</strong> proves to be popular as a <em>ad hoc</em> packaging system, while it is not intended to be one. (See above.)</p>

<p>The “official” packaging system from a given distribution is just a possibility among many others to install software in some computing environment. There are many other sources available, like community-specific package managers such as <strong>npm</strong> or <strong>opam,</strong> port trees like <strong>pkgsrc</strong> and plain source code distribution.  From this perspective, it is easy to understand the success of <strong>Docker</strong> as an <em>ad hoc</em> packaging system:</p>

<ul>
<li><p><strong>Docker</strong> specifications are very close from a shell script and whatever source it comes from, we install software using the shell.</p></li>
<li><p><strong>Docker</strong> has a “built-in” (paying) service for hosting artefacts it produces, the <strong>Docker Hub</strong>.</p></li>
</ul>

<p>Now what are the strength of <strong>Debian packages</strong> over <strong>Docker images</strong> as a package system? The tight control over dependencies at installation. (The possibility to upgrade and downgrade also exists but has no practical importance if we are implementing the <a href=""/questions/tagged/immutable-server"" class=""post-tag"" title=""show questions tagged &#39;immutable-server&#39;"" rel=""tag"">immutable-server</a> pattern.) This leads to the</p>

<h3>Conclusion</h3>

<p>If you only have a single product deployed in a single version (which is typical for SaaS), your version management needs are very simple and using <strong>Docker</strong> as a <em>ad hoc</em> package manager should not have any hard drawbacks.  As soon as you work with several versions of a single product or several products, the complexity of the version constraints problem you need to solve increases and you need an appropriate tool for this, which might be <strong>Debian packages</strong> or some configuration management system if you are mixing software from different origins.</p>
",271,2017-03-03T10:40:08.113,"['apt-key add - <<EOF\n-----BEGIN PGP PUBLIC KEY BLOCK-----\n<YOUR RELEASE OFFICER PGP KEY GOES HERE>\nEOF\n\ncat >> /etc/apt/sources.list <<EOF\ndeb https://my.organisation.org/repo debian-jessie main\napt-get update -y\napt-get upgrade -y\nEOF\n', 'ADD apt_setup.sh /root\nRUN sh -ex /root/apt_setup.sh && rm /root/apt_setup.sh\nRUN apt-get install -y my-node-js-package\n']"
15,278,277,CC BY-SA 3.0,2017-03-03T11:20:59.370,"<p>You need to write some unit tests and set the <code>script</code> variable in your <code>.travis.yml</code> to actually run a file.</p>

<p>By default, Travis CI runs the command <code>phpunit</code> without any arguments. When this happens, <code>phpunit</code> doesn't know what you're asking it to do, and shows a help message, then exits with error code 2 (i.e. <strong>non-zero</strong>, which indicates an error occurred).</p>

<p>The <a href=""https://docs.travis-ci.com/user/for-beginners"" rel=""noreferrer"">Beginner's Guide</a> shows you a possible solution of setting the <code>script</code> variable to run a <code>Test.php</code> file with your tests in (insert this into your <code>.travis.yml</code>):</p>

<pre><code>script: phpunit Test.php
</code></pre>

<p>There is an example of a valid <code>Test.php</code> in the <a href=""https://github.com/plaindocs/travis-broken-example/blob/master/Test.php"" rel=""noreferrer"">example repo</a> that Travis provides:</p>

<pre><code>&lt;?php
    class Test extends PHPUnit_Framework_TestCase
    {
        public function testOnePlusOne() {
            $this-&gt;assertEquals(1+1,1);
        }
    }
?&gt;
</code></pre>
",14,2017-03-03T11:20:59.370,"['script: phpunit Test.php\n', '<?php\n    class Test extends PHPUnit_Framework_TestCase\n    {\n        public function testOnePlusOne() {\n            $this->assertEquals(1+1,1);\n        }\n    }\n?>\n']"
16,298,296,CC BY-SA 3.0,2017-03-03T17:52:35.087,"<p>The best solution we found so far, is using the <a href=""https://github.com/gocd/gocd/blob/master/config/config-server/src/com/thoughtworks/go/config/MagicalGoConfigXmlLoader.java"" rel=""nofollow noreferrer""><code>MagicalGoConfigXmlLoader</code></a>  interface from the go source code, as it calls an internal <code>validateCruiseConfig</code> command, that does all validations, or die if the file is invalid:</p>

<pre><code>MagicalGoConfigXmlLoader loader = new MagicalGoConfigXmlLoader(new ConfigCache());
loader.loadConfigHolder(configAsString);
</code></pre>

<p>The main problem with this solution that it essentially requires the whole GoCD server source code checked out, in a working state to work properly. Also as it's an internal API it is subject to changes between GoCD versions, making GoCD upgrades harder.</p>
",27,2017-03-03T17:52:35.087,['MagicalGoConfigXmlLoader loader = new MagicalGoConfigXmlLoader(new ConfigCache());\nloader.loadConfigHolder(configAsString);\n']
17,315,314,CC BY-SA 3.0,2017-03-04T12:51:06.503,"<p>Not sure if there aren't any others, but these are the criteria I use:</p>

<pre><code>+-------------------+-----------+-----------+
! Criteria          ! Agile     ! Waterfall !
+-------------------+-----------+-----------+
! Release Events    ! Frequent  ! Rare      !
! Risk              ! Less      ! High      !
! Required Effort   ! Smoother  ! Peaks     !
! Volume of changes ! Small     ! Huge      !
+-------------------+-----------+-----------+
</code></pre>

<p>And if you really want to experience the difference yourself as a user of some software, then think of using some software (like a Linux distribution), where you have a choice between using either of those releases:</p>

<ul>
<li><p>a ""<strong><code>Rolling</code></strong>"" release (==> Agile).</p></li>
<li><p>a ""<strong><code>Long Term Support</code></strong>"" release (==> Waterfall).</p></li>
</ul>
",40,2017-03-04T12:51:06.503,['+-------------------+-----------+-----------+\n! Criteria          ! Agile     ! Waterfall !\n+-------------------+-----------+-----------+\n! Release Events    ! Frequent  ! Rare      !\n! Risk              ! Less      ! High      !\n! Required Effort   ! Smoother  ! Peaks     !\n! Volume of changes ! Small     ! Huge      !\n+-------------------+-----------+-----------+\n']
18,316,313,CC BY-SA 3.0,2017-03-04T15:24:04.863,"<p>It works if I comment out the hostname_variable, because it allow to override the inventory_name with an ec2 variable, instead of using the destination_variable</p>

<pre><code>#hostname_variable = private_ip_address
#hostname_variable = ip_address
destination_variable = public_dns_name
vpc_destination_variable = private_ip_address
</code></pre>

<p>For Private IPs:</p>

<pre><code>destination_variable = private_ip_address
</code></pre>
",342,2017-03-04T15:24:04.863,"['#hostname_variable = private_ip_address\n#hostname_variable = ip_address\ndestination_variable = public_dns_name\nvpc_destination_variable = private_ip_address\n', 'destination_variable = private_ip_address\n']"
19,385,226,CC BY-SA 3.0,2017-03-06T11:23:46.303,"<p>Let's assume you have the following scenario: You have many customers, but most use the exact same app, except for some configuration changes. You would like each of your customer to get the latest of the app ASAP.</p>

<p>If this is your scenario then try make everything that needs to be differentiated between the apps a configuration change. You build one (or one set of) docker containers that can handle any of your customer based on the configuration it was given. Then on deployment time you simply supply the proper configurations for this container for each of your customer.</p>

<p>The benefit of this approach is that you don't really incur massive overheads when a new customer comes. You generate their configuration, create the new servers, add some entries into an inventory file, and the next time you deploy, it gets there as well. The more well your CD pipeline is set up the more you can automate any of this process.</p>

<p>So how would the flow generally look like:</p>

<ol>
<li>You have your application codebase, that can cater for <strong>all</strong> of your customers</li>
<li>You build the docker container for your application (one for the frontend, one for the backend, possibly a few more supporting ones)</li>
<li>You have a deployment script that uses a configuration file to determine where to deploy and what.</li>
<li>You run this deployment script. It will go over all of your customers, and simply deploy the latest version of your app with the appropriate config.</li>
</ol>

<p>If you have a new customer, the only place you have to change is the deployment configuration file. If you are using ansible most likely you have to change your inventory and your vars file. Let's say you have get a new customer, who would like the app to run under Spanish locale, and has access to the beta features. This customer's configuration would maybe look like this:</p>

<pre><code>config.js:

SETTINGS = { locale: 'es', beta: true };

config.php:

define('CUSTOMER_LOCALE','es');
define('CUSTOMER_BETA','true');
</code></pre>

<p>You then make sure that during deployment your container gets these files mounted on startup.</p>
",27,2017-03-06T11:23:46.303,"[""config.js:\n\nSETTINGS = { locale: 'es', beta: true };\n\nconfig.php:\n\ndefine('CUSTOMER_LOCALE','es');\ndefine('CUSTOMER_BETA','true');\n""]"
20,397,342,CC BY-SA 4.0,2017-03-07T00:29:40.637,"<p>I never used Ansible but since a few weeks, I try to figure out what good Ansible could be in comparison with shell scrips–Which proves, at least in my case, that the haunting ad-campaigns they run are effective! After many unsuccessful attempts–which proves how their documentation fail at answering one of the most obvious question–I think I finally got it.</p>

<p>My conclusion is that over shell scripting, Ansible essentially offers 1. The possibility of checking that a system agrees with a desired state, 2. the ability to integrate with Ansible Tower, which is a paying system that seems to include monitoring abilities. In some important cases, like when implementing the immutable server pattern, the point 1 is probably not very useful, so the list of advantages is rather thin.</p>

<p>It seems to me that the benefits offered by Ansible over shell-scripting, as the documentation present them, could be sensible in a few handful of optimistic cases well covered by available modules but are small or even hypothetical in the general case. For a skilled shell-programmer, these benefits are most likely counter-balanced by other aspects of the trade-off.</p>

<p>But my conclusion maybe only proves how bad the introduction material is at displaying the actual advantages of this software!</p>

<p>Now, I propose to watch the introduction video and go randomly as a potential new user through the introduction material to Ansible an let's compare it to what a skilled shell programmer can produce in a reasonable time.</p>

<h1>The quick start video:</h1>

<p>There is a <a href=""http://docs.ansible.com/ansible/quickstart.html"" rel=""nofollow noreferrer"">quick start video</a>. It starts with a page claiming that… well these are not really claims, these are bullet lists, an artefact <a href=""http://cristal.inria.fr/~weis/info/haladjian.pdf"" rel=""nofollow noreferrer"">commonly used to suspend critical judgement</a> in presentations (since the logic is not shown, it cannot be criticised!)</p>

<h3>1. Ansible is simple:</h3>

<p>1.1 Human readable automation – Specifications are technical documents, how could</p>

<pre><code>  name: upgrade all packages
  yum:
    name: '*'
    state: latest
</code></pre>

<p>be easier to read than the corresponding <em>yum</em> invocation found in a shell-script? Furthermore, anybody who had contact to AppleScript dies laughing when they read “human readable automation.”</p>

<p>1.2 No special coding skills required – What is coding if not writing formal specifications? Ansible has conditionals, variables, so, how is it not coding? And why would I need something I cannot program, that would henceforth be inflexible? The statement is happily inaccurate!</p>

<p>1.3 Tasks executed in order – Well, maybe some <a href=""http://codegolf.stackexchange.com"">codegolf aficionados</a> are aware of languages that execute tasks in disorder, but executing tasks in order hardly looks exceptional.</p>

<p>1.4 Get productive quickly – Skilled shell programmers are productive now. This counter-argument is just as serious as the initial argument.</p>

<h3>2. Ansible is powerful</h3>

<p>A popular salesman trick to sell artefacts is to fool people into believing they will acquire the “power” of these artefacts. The history of advertisement for cars or isotonic drinks should supply a convincing list of examples.</p>

<p>Here Ansible can do “app deployment” – but shell script surely do, “configuration management” but this is a mere statement of the purpose of the tool, not a feature, and “workflow orchestration” which looks a bit pretentious but no example in this document goes beyond what <a href=""https://www.gnu.org/software/parallel/man.html"" rel=""nofollow noreferrer"">GNU Parallel</a> can do.</p>

<h3>3. Ansible is agentless</h3>

<p>To populate the column, they wrote in three different manners that this only needs <em>ssh,</em> which, as everybody knows is a <em>daemon</em> and has nothing to do with these <em>agents</em> pervading the world of configuration management!</p>

<h3>The rest of the video</h3>

<p>The rest of the video introduces inventories, which are static lists of resources (like servers) and demonstrates how to deploy Apache on three servers simultaneously.  This really does not match the way I work, where resources are highly dynamic and can be enumerated by command-line tooling provided by my cloud provider, and consumed by my shell functions using the pipe <code>|</code> operator.  Also, I do not deploy Apache on three servers simultaneously, rather, I build a master instance image that I then use to start 3 instances which are exact replicas one of the other. So the “orchestrating” part of the argumentation does not look very pertinent.</p>

<h1>Random documentation step 1: Integration with EC2</h1>

<p>EC2 is the computing service from Amazon, interacting with it is supported by some <a href=""http://docs.ansible.com/ansible/guide_aws.html"" rel=""nofollow noreferrer"">Ansible module</a>. (Other popular cloud computing providers are also provided.):</p>

<pre><code># demo_setup.yml

- hosts: localhost
  connection: local
  gather_facts: False

  tasks:

    - name: Provision a set of instances
      ec2:
         key_name: my_key
         group: test
         instance_type: t2.micro
         image: ""{{ ami_id }}""
         wait: true
         exact_count: 5
         count_tag:
            Name: Demo
         instance_tags:
            Name: Demo
      register: ec2
</code></pre>

<p>The corresponding shell-script would be essentially identical with YAML replaced by JSON:</p>

<pre><code>provision_a_set_of_instances()
{
  aws --output=text ec2 run-instances --image-id …   
}
</code></pre>

<p>or the JSON version</p>

<pre><code>provision_a_set_of_instances()
{
  aws --output=text ec2 run-instances --cli-input-json ""$(provision_a_set_of_instances__json)""  
}

provision_a_set_of_instances__json()
{
  cat &lt;&lt;EOF
{
    ""ImageId"": … 
}
EOF
}
</code></pre>

<p>Both version are essentially identical, the bulk of the payload is the enumeration of the initialisation values in a YAML or JSON structures.</p>

<h1>Random documentation step 2: Continuous Delivery and Rolling Upgrades</h1>

<p>The largest part of <a href=""http://docs.ansible.com/ansible/guide_rolling_upgrade.html"" rel=""nofollow noreferrer"">this guide</a> does not display any really interesting feature: it introduces variables (IIRC, shell scripts also have variables)!, and an Ansible module that handles mysql, so that if instead of searching after “how do I create a mysql user with privileges on X Y” and end with something like</p>

<pre><code>create_application_db_user()
{
  mysql --host ""${mysql_host}"" --user ""${mysql_user}"" --password ""${mysql_password}"" ""${mysql_table}"" &lt;&lt;EOF
GRANT ALL PRIVILEGES ON *.* TO 'root'@'%';
EOF
}
</code></pre>

<p>you search after “how do I create a mysql user with privileges on X Y in <em>ansible</em>”  and end up with </p>

<pre><code>- name: Create Application DB User
  mysql_user: name={{ dbuser }} password={{ upassword }}
              priv=*.*:ALL host='%' state=present
</code></pre>

<p>The difference is still probably not very meaningful. On that page we also discover that Ansible has a template meta-Programming language</p>

<pre><code>{% for host in groups['monitoring'] %}
-A INPUT -p tcp -s {{ hostvars[host].ansible_default_ipv4.address }} --dport 5666 -j ACCEPT
{% endfor %}
</code></pre>

<p>When I see this, I happen to really be in my comfort zone. This kind of simple meta-programming for declarative languages is exactly the same theoretical paradigm as BSD Makefiles! Which I <a href=""https://github.com/michipili/bsdowl"" rel=""nofollow noreferrer"">happen to have programmed extensively</a> This excerpt shows us that the promise of working with YAML file is broken (so I cannot run my playbooks through a YAML parser, <em>e.g.</em>). It also shows us that Ansible must discuss the subtle art of evaluation order: we have to decide if variables are expanded at the “declarative part” of the language or at the “imperative” meta-part of the language. Here shell programming is simpler, there is no meta-programming, aside from <em>explicit</em> <code>eval</code> or external-script sourcing.  The hypothetical equivalent shell excerpt would be</p>

<pre><code>enumerate_group 'monitoring' | {
  while read host; do
    …
  done
}
</code></pre>

<p>whose complexity in comparison to the Ansible variant is probably tolerable: it just uses the plain, regular, boring constructs from the language.</p>

<h1>Random documentation step 3: Testing strategies</h1>

<p>Last, <a href=""http://docs.ansible.com/ansible/test_strategies.html"" rel=""nofollow noreferrer"">we meet what turns out to be the first actually interesting feature</a> of Ansible: “Ansible resources are models of desired-state. As such, it should not be necessary to test that services are started, packages are installed, or other such things. Ansible is the system that will ensure these things are declaratively true. Instead, assert these things in your playbooks.” Now it starts to be a bit interesting, but:</p>

<ol>
<li><p>Aside from a handful of standard situations readily implemented by available modules, I will have to feed the bits implementing the test myself, which will quite probably involve some shell commands.</p></li>
<li><p>Checking for the conformity of installations might not be very relevant in the context where the immutable server pattern is implemented: where all systems running are typically spawned from a master image (instance image or docker image for instance) and never updated – they are replaced by new instead.</p></li>
</ol>

<h1>Unaddressed concern: the maintainability</h1>

<p>The introductory material <a href=""http://docs.ansible.com/ansible/"" rel=""nofollow noreferrer"">from Ansible</a> ignores the question of the maintainability.  With essentially no type system, shell-scripting has the maintainability ease of JavaScript, Lisp or Python: extensive refactorings can only be achieved successfully with the help of an extensive automated testsuite – or at least designs that allows easy interactive testing. That said, while shell scripting is the <a href=""https://en.wikipedia.org/wiki/Mediterranean_Lingua_Franca"" rel=""nofollow noreferrer"">lingua franca</a> from system configuration and maintenance, nearly each programming language has an interface to the shell. It is therefore totally feasible to leverage the maintainability advantage of advanced languages, by using them to glue together the various the bits of shell-configuration bits. For OCaml, I wrote <a href=""https://github.com/michipili/rashell"" rel=""nofollow noreferrer"">Rashell</a> that essentially provides a hand of common interaction patterns for subprocesses, which makes the translation of configuration scripts to OCaml essentially trivial.</p>

<p>On the side from Ansible, the very weak structure of playbooks and the presence of a meta-programming feature make the situation essentially as bad as it is for shell scripting, with the minus points that it is not obvious how to write unit tests for Ansible, and the argument of introducing ad-hoc a higher-level language cannot be mimiced.</p>

<h1>Idempotency of configuration steps</h1>

<p>The documentation of Ansible draws the attention on the necessity of writing idempotent configuration steps. More precisely, configuration steps should be written so that the step sequence <em>a b a</em> can be simplified to <em>a b</em>, i.e. we do not need to repeat configuration step. This is a stronger condition than idempotency. Since Ansible allows playbooks to use arbitrary shell commands, Ansible itself is unable to guarantee that this stronger condition is respected. This only relies on the programmer's discipline and the importance of this variation of idempotency when writing configuration scripts is certainly not a novelty.</p>

<hr>

<p>Post-Scriptum. Since this answer seems to enjoy a relative popularity, I fixed a few embarrassing syntax errors and typos. By a twist of life I also had to use Ansible two years in my work. Overall my experience confirms what I foreseen here and I hardly can think about a situation where shell scripts would have been really outperformed by Ansible. On some aspects, Ansible is just worse than shell scripting. At least the shell has functions, these functions can be mocked, it is possible to test part of all of them, so overall the shell has much better software engineering features than Ansible has. In a shell script it is also possible to process data and <strong>awk</strong> can express all what SQL can, which is very important when programming configuration – the information we are working with here is not intrinsically hierarchical, so there is a need for extracting an rewriting. Ansible is so bad at extracting and rewriting data! Treatments must be expressed with a mixture of YAMl-templating at the playbook step level and a dialect of Jinja at the dictionary member level… this is cumbersome, ugly, hard to write, hard to test and poorly documented (I regularly looked up the Jinja filter implementations!).</p>
",271,2020-04-25T15:29:05.177,"[""  name: upgrade all packages\n  yum:\n    name: '*'\n    state: latest\n"", '# demo_setup.yml\n\n- hosts: localhost\n  connection: local\n  gather_facts: False\n\n  tasks:\n\n    - name: Provision a set of instances\n      ec2:\n         key_name: my_key\n         group: test\n         instance_type: t2.micro\n         image: ""{{ ami_id }}""\n         wait: true\n         exact_count: 5\n         count_tag:\n            Name: Demo\n         instance_tags:\n            Name: Demo\n      register: ec2\n', 'provision_a_set_of_instances()\n{\n  aws --output=text ec2 run-instances --image-id …   \n}\n', 'provision_a_set_of_instances()\n{\n  aws --output=text ec2 run-instances --cli-input-json ""$(provision_a_set_of_instances__json)""  \n}\n\nprovision_a_set_of_instances__json()\n{\n  cat <<EOF\n{\n    ""ImageId"": … \n}\nEOF\n}\n', 'create_application_db_user()\n{\n  mysql --host ""${mysql_host}"" --user ""${mysql_user}"" --password ""${mysql_password}"" ""${mysql_table}"" <<EOF\nGRANT ALL PRIVILEGES ON *.* TO \'root\'@\'%\';\nEOF\n}\n', ""- name: Create Application DB User\n  mysql_user: name={{ dbuser }} password={{ upassword }}\n              priv=*.*:ALL host='%' state=present\n"", ""{% for host in groups['monitoring'] %}\n-A INPUT -p tcp -s {{ hostvars[host].ansible_default_ipv4.address }} --dport 5666 -j ACCEPT\n{% endfor %}\n"", ""enumerate_group 'monitoring' | {\n  while read host; do\n    …\n  done\n}\n""]"
21,407,406,CC BY-SA 3.0,2017-03-07T08:35:32.477,"<h3>Shallow clone</h3>

<p>You can indeed get a shallow clone out of Git using:</p>

<pre><code>git clone --depth=1 &lt;url&gt;
</code></pre>

<p>This will still clone the repo and create a <code>.git</code> folder with the objects, only smaller in size (difference depending on your total file size vs. history size).</p>

<h3>Git archive</h3>

<p>You can also use <a href=""https://git-scm.com/docs/git-archive"" rel=""noreferrer"">git-archive</a> to extract an archive of the repo:</p>

<blockquote>
  <p>Creates an archive of the specified format containing the tree structure for the named tree, and writes it out to the standard output. If  is specified it is prepended to the filenames in the archive.</p>
</blockquote>

<p>In the <a href=""https://git-scm.com/docs/git-archive#_examples"" rel=""noreferrer"">examples</a> it shows for instance:</p>

<blockquote>
  <p><code>git archive --format=tar --prefix=git-1.4.0/ v1.4.0 | gzip &gt;git-1.4.0.tar.gz</code>  </p>
  
  <blockquote>
    <p>Create a compressed tarball for <a href=""/questions/tagged/v1.4.0"" class=""post-tag"" title=""show questions tagged &#39;v1.4.0&#39;"" rel=""tag"">v1.4.0</a> release.</p>
  </blockquote>
</blockquote>

<h3>Hosted Git, archive API</h3>

<p>If you are hosting your repo on GitHub, then you can use their <a href=""https://developer.github.com/v3/repos/contents/#get-archive-link"" rel=""noreferrer"">archive API</a>:</p>

<p><code>https://api.github.com/repos/&lt;username&gt;/&lt;repository&gt;/zipball/&lt;commit_hash&gt;</code></p>

<p>Bitbucket.org has a same functionality for this:</p>

<p><code>https://bitbucket.org/&lt;username&gt;/&lt;repository&gt;/get/&lt;branch_name|commit_hash|tag&gt;.zip</code></p>
",184,2017-03-10T09:50:08.590,['git clone --depth=1 <url>\n']
22,416,413,CC BY-SA 3.0,2017-03-07T12:55:25.557,"<p>Probably not exactly an answer, but worth giving the alternatives.</p>

<p>Chef's <a href=""https://www.habitat.sh"" rel=""nofollow noreferrer""><strong>habitat</strong></a> has been created with this in mind, creating a package with all needed dependencies without the extraneous distro/base image load you don't wish.</p>

<p>Extracts on what matters here, the container size from <a href=""https://blog.chef.io/2016/11/28/why-habitat-plans-and-packages-part-2/"" rel=""nofollow noreferrer""><strong>this blog post</strong></a> with a simple nodejs app:</p>

<blockquote>
<pre><code>michael@ricardo-2:plans_pkg_part_2$ docker images
REPOSITORY           TAG                 IMAGE ID            CREATED             SIZE
mfdii/node-example   latest              36c6568c606b        40 minutes ago      655.9 MB
node                 latest              04c0ca2a8dad        16 hours ago        654.6 MB
mfdii/mytutorialapp  latest              534afd80d74d        2 minutes ago       182.1 MB
</code></pre>
</blockquote>

<p><code>mdfii/node-example</code> is a docker image from a classic dockerfile while <code>mfdii/mytutorialapp</code> is the docker image produced with habitat.</p>

<p>If size is your main concern and you're up to take the learning curve of Habitat plans, this could be a solution for you.</p>
",13,2017-04-05T10:01:18.203,['michael@ricardo-2:plans_pkg_part_2$ docker images\nREPOSITORY           TAG                 IMAGE ID            CREATED             SIZE\nmfdii/node-example   latest              36c6568c606b        40 minutes ago      655.9 MB\nnode                 latest              04c0ca2a8dad        16 hours ago        654.6 MB\nmfdii/mytutorialapp  latest              534afd80d74d        2 minutes ago       182.1 MB\n']
23,417,413,CC BY-SA 3.0,2017-03-07T13:02:28.923,"<p>A <code>Dockerfile</code> creates a new layer for each of the commands in the file. Since layers are well, <em>layered</em> on top of each other - you cannot remove files that a previous layer added. This is why when you install packages, or download files, or create builds each in a separate command - these are still there in the image, even if in a future layer you removed them.</p>

<p>So if you just change this:</p>

<pre><code>RUN apt-get update -y
RUN apt-get install -y wget a-package
# ...
RUN apt-get purge -y wget
RUN rm -r a-build-dir
RUN apt-get purge -y a-package
</code></pre>

<p>To this:</p>

<pre><code>RUN apt-get update -y \
    &amp;&amp; apt-get install -y wget a-package \
    &amp;&amp; mkdir a-build-dir \
    &amp;&amp; wget http://some-site/very-big-source-code.tar.gz \
    &amp;&amp; tar xzvf very-big-source-code.tar.gz \
    &amp;&amp; do-some-compilation \
    &amp;&amp; apt-get purge -y wget \
    &amp;&amp; cd .. \
    &amp;&amp; rm -rf a-build-dir \
    &amp;&amp; apt-get purge -y a-package
</code></pre>

<p>You will get a much smaller image.</p>

<hr>

<p>Another option, is to <strong>squash</strong> the image after you built it.
<a href=""https://stackoverflow.com/questions/41764336/how-does-the-new-docker-squash-work"">Q: How does the new <code>docker --squash</code> work?</a></p>

<hr>

<p>Yet another option, is to choose a slim base image. For example, images that use <a href=""https://alpinelinux.org/"" rel=""noreferrer"">Alpine Linux</a> as their base instead of Debian, take just 10-15mb instead of 180-250mb. And this is before adding your own application and data. Many <em>official</em> base images on <a href=""https://hub.docker.com/"" rel=""noreferrer"">Docker Hub</a> have an alpine version.</p>
",6,2017-03-07T13:26:41.493,"['RUN apt-get update -y\nRUN apt-get install -y wget a-package\n# ...\nRUN apt-get purge -y wget\nRUN rm -r a-build-dir\nRUN apt-get purge -y a-package\n', 'RUN apt-get update -y \\\n    && apt-get install -y wget a-package \\\n    && mkdir a-build-dir \\\n    && wget http://some-site/very-big-source-code.tar.gz \\\n    && tar xzvf very-big-source-code.tar.gz \\\n    && do-some-compilation \\\n    && apt-get purge -y wget \\\n    && cd .. \\\n    && rm -rf a-build-dir \\\n    && apt-get purge -y a-package\n']"
24,421,419,CC BY-SA 3.0,2017-03-07T15:05:58.583,"<p>General ways to track why a process in Linux failed are good. One such way is to run a process using <a href=""http://man7.org/linux/man-pages/man1/strace.1.html"" rel=""nofollow noreferrer""><code>strace</code></a> which will tell you the system calls process did and usually point to the reason for a failure.</p>

<p>You can create a <code>Dockerfile</code> that looks something like this:</p>

<pre><code>FROM original_image

RUN apt-get -y update &amp;&amp; apt-get install -y strace

# build with `docker build -t debug_version`
</code></pre>

<p>Then run your new image using <code>docker run debug_version strace original_cmd</code>.</p>

<p>For processes that fork children (and then die) you want to run <code>strace</code> with the <code>-ff</code> option. You can also map some file using <a href=""https://docs.docker.com/engine/tutorials/dockervolumes/"" rel=""nofollow noreferrer"">Docker data volumes</a> and use the <code>-o</code> option from <code>strace</code> to write to it. But in general <code>strace</code> will leave output on stdout, which is readable using <code>docker log</code>.</p>

<p>Related <a href=""https://serverfault.com/questions/656760/linux-process-terminates-mysteriously"">Q: Linux process terminates mysteriously</a></p>
",6,2017-03-07T15:12:14.087,['FROM original_image\n\nRUN apt-get -y update && apt-get install -y strace\n\n# build with `docker build -t debug_version`\n']
25,423,404,CC BY-SA 3.0,2017-03-07T16:27:33.763,"<p>This answer is more about scalability considerations - if the number of workers can be high and/or multiple of them can produce logs at high rate at the same time.</p>

<p>Yes, using multiple logfiles simultaneously is a good practice.</p>

<p>Attempting to combine into a single logfile logs from multiple workers <strong>in real time</strong> will raise problems:</p>

<ul>
<li>using blocking mechanims to prevent message loss will slow down the workers</li>
<li>log messages can appear out-of-order in the combined logfile</li>
<li>a centralized logging facility which combines the logs can be overloaded due to limited write speed, messages would be lost </li>
</ul>

<p>Sharding logfiles (using multiple logfiles active in the same time) is itself a technique used by some hosting providers offering high performance, scalable centralized logging services. For example, when exporting logs to files Google's <a href=""https://cloud.google.com/logging/"" rel=""noreferrer"">StackDriver Logging</a> produces multiple sharded logfiles. From <a href=""https://cloud.google.com/logging/docs/export/using_exported_logs#log_entries_in_google_cloud_storage"" rel=""noreferrer"">Log entries in Google Cloud Storage</a>:</p>

<blockquote>
  <p>When you <a href=""https://cloud.google.com/logging/docs/export/configure_export"" rel=""noreferrer"">export logs</a> to a Cloud Storage bucket, Stackdriver
  Logging writes a set of files to the bucket. The files are organized
  in directory hierarchies by log type and date. The log type can be a
  simple name like <code>syslog</code> or a compound name like
  <code>appengine.googleapis.com/request_log</code>. If these logs were stored in a
  bucket named <code>my-gcs-bucket</code>, then the directories would be named as
  in the following example:</p>

<pre><code>my-gcs-bucket/syslog/YYYY/MM/DD/
my-gcs-bucket/appengine.googleapis.com/request_log/YYYY/MM/DD/
</code></pre>
  
  <p>A single bucket can contain logs from multiple log types.</p>
  
  <p>The leaf directories (<code>DD/</code>) contain multiple files, each of which
  holds the exported log entries for a time period specified in the file
  name. The files are sharded and their names end in a shard number,
  <code>Sn</code> or <code>An</code> (n=0, 1, 2, ...). For example, here are two files that
  might be stored within the <code>directory
  my-gcs-bucket/syslog/2015/01/13/</code>:</p>

<pre><code>08:00:00_08:59:59_S0.json
08:00:00_08:59:59_S1.json
</code></pre>
  
  <p>These two files together contain the <code>syslog</code> log entries for all
  instances during the hour beginning 0800 UTC. To get all the log
  entries, you must read all the shards for each time period—in this
  case, file shards 0 and 1. The number of file shards written can
  change for every time period depending on the volume of log entries.</p>
</blockquote>

<p>Such high-performance logging services can also offer alternatives to logging to files, management of logfiles can thus be avoided altogether if that is of interest:</p>

<ul>
<li>inserting logs directly into a database. For example Stackdriver Logging can <a href=""https://cloud.google.com/logging/docs/export/using_exported_logs#log_entries_in_google_bigquery"" rel=""noreferrer"">push logs directly into Google BigQuery</a></li>
<li>pushing logs directly into a processing engine. For example Stackdriver Logging can <a href=""https://cloud.google.com/logging/docs/export/using_exported_logs#log_entries_in_google_pubsub_topics"" rel=""noreferrer"">push logs into Google Pub/Sub topics</a></li>
</ul>

<p>Finally - if real-time logfile merging is not a requirement having multiple logfiles can help with offline log management:</p>

<ul>
<li>easy to devise progressive log backup, compression, archiving and eventual disposal schemes</li>
<li>parallel processing of multiple sets of logs (logfiles) is possible, reducing/avoiding bottleneck effects</li>
<li>no file splitting and re-writing necessary</li>
</ul>
",47,2017-03-07T16:27:33.763,"['my-gcs-bucket/syslog/YYYY/MM/DD/\nmy-gcs-bucket/appengine.googleapis.com/request_log/YYYY/MM/DD/\n', '08:00:00_08:59:59_S0.json\n08:00:00_08:59:59_S1.json\n']"
26,435,433,CC BY-SA 3.0,2017-03-08T10:55:33.710,"<p>There is no official Oracle JDK implementation provided by Docker. Docker used to support their own <a href=""https://hub.docker.com/_/java/"" rel=""nofollow noreferrer"">Java library</a> on hub.docker.com, but they deprecated it in favor of the actual OpenJDK implementation since it was ""OpenJDK-specific since it was first introduced"". Their reasoning:</p>

<blockquote>
  <p>As all of the major upstream Linux distributions are unwilling to redistribute Oracle Java in their own distribution channels, we have chosen to follow them. See references below on how each distribution does not distribute Oracle Java.</p>
</blockquote>

<p>So if you want to keep your Docker image as small as possible, consider using OpenJDK instead. There's an official <a href=""https://hub.docker.com/_/openjdk/"" rel=""nofollow noreferrer"">OpenJDK Dockerfile repository</a> or you can just use <code>docker pull openjdk</code>. The basic ""easy to run"" Dockerfile for OpenJDK 7 is as follows (taken from the website listed in the previous sentence):</p>

<pre><code>FROM openjdk:7
COPY . /usr/src/myapp
WORKDIR /usr/src/myapp
RUN javac Main.java
CMD [""java"", ""Main""]
</code></pre>
",201,2017-03-08T19:14:15.703,"['FROM openjdk:7\nCOPY . /usr/src/myapp\nWORKDIR /usr/src/myapp\nRUN javac Main.java\nCMD [""java"", ""Main""]\n']"
27,436,433,CC BY-SA 3.0,2017-03-08T10:58:47.563,"<p>As docker is not an operating system, no there's no JDK for docker.</p>

<p>As I understand your question, it's that a full JDK is too large for your wishes, in this case you may try switching to just the JRE and include only necessary libraries.</p>

<p>JDK is the acronym of Java Development Kit, JRE is the one for Java Runtime Engine. By ""lazyness"" due to the complexity to list every needed dependency no one strip down to the necessary libraries only, but that is the way to go if you wish to reduce the installed size to strict minimum.</p>

<p>A more usable way could be strip off some of the installed things which are taking a lot of space:</p>

<pre><code>/usr/lib/jvm/jdk1.8.0_101$ du -hs *
776K    bin
4.0K    COPYRIGHT
5.7M    db
208K    include
4.9M    javafx-src.zip
187M    jre
133M    lib
4.0K    LICENSE
2.0M    man
4.0K    README.html
4.0K    release
21M     src.zip
108K    THIRDPARTYLICENSEREADME-JAVAFX.txt
176K    THIRDPARTYLICENSEREADME.txt
</code></pre>

<p>There's two *src.zip which can be removed, they won't be of use, and as you can see the lib directory is half the size and within it you have a bunch of things you don't really need:</p>

<pre><code>/usr/lib/jvm/jdk1.8.0_101$ du -hs lib/*
120K    lib/amd64
1.2M    lib/ant-javafx.jar
18M     lib/ct.sym
160K    lib/dt.jar
20K     lib/ir.idl
36K     lib/javafx-mx.jar
400K    lib/jconsole.jar
12K     lib/jexec
60M     lib/missioncontrol
4.0K    lib/orb.idl
8.0K    lib/packager.jar
2.4M    lib/sa-jdi.jar
18M     lib/tools.jar
34M     lib/visualvm
</code></pre>

<p>You can without problem remove missoncontrol on a server, I assume you can get rid of visualvm also, you'll have to check if you need something in this lib directory, but I can't tell without knowing your app..</p>

<p>One thing you should do in your dockerfile while installing oracle jdk is to remove the downloaded <code>.tar.gz</code> file which is roughly the same size as the resulting directory as <code>.jar</code> files are already compressed, the tar.gz is just there to ""package"" them.</p>

<p>You have to do all this in the same <code>RUN</code> command, chaining with <code>&amp;&amp;</code> to avoid adding layers where you won't remove size by removing files from previous layer.</p>
",13,2017-03-08T11:12:43.530,"['/usr/lib/jvm/jdk1.8.0_101$ du -hs *\n776K    bin\n4.0K    COPYRIGHT\n5.7M    db\n208K    include\n4.9M    javafx-src.zip\n187M    jre\n133M    lib\n4.0K    LICENSE\n2.0M    man\n4.0K    README.html\n4.0K    release\n21M     src.zip\n108K    THIRDPARTYLICENSEREADME-JAVAFX.txt\n176K    THIRDPARTYLICENSEREADME.txt\n', '/usr/lib/jvm/jdk1.8.0_101$ du -hs lib/*\n120K    lib/amd64\n1.2M    lib/ant-javafx.jar\n18M     lib/ct.sym\n160K    lib/dt.jar\n20K     lib/ir.idl\n36K     lib/javafx-mx.jar\n400K    lib/jconsole.jar\n12K     lib/jexec\n60M     lib/missioncontrol\n4.0K    lib/orb.idl\n8.0K    lib/packager.jar\n2.4M    lib/sa-jdi.jar\n18M     lib/tools.jar\n34M     lib/visualvm\n']"
28,535,457,CC BY-SA 3.0,2017-03-16T09:03:48.417,"<p>I've created the <a href=""https://github.com/owenmorgan/jenkins-remote-builder"" rel=""noreferrer"">jenkins-remote-builder</a> script which will follow your remote build to completion.</p>
<p>Some more details about it (from its <a href=""https://github.com/owenmorgan/jenkins-remote-builder/blob/master/README.md"" rel=""noreferrer"">README.md</a>):</p>
<blockquote>
<h2>Example</h2>
<pre><code>jenkins=https://user:pass@jenkins.mydomain.com:8080
jenkins_job=MyApp-Deploy

environment=dev
application=myapp
revision=9fd71f63b351b8208264daf86d292ced580a2f60

./jenkins_remote_trigger.sh \
            -h ${jenkins} \
            -j ${jenkins_job} \
            -p &quot;ENVIRONMENT=${environment}&amp;APPLICATION=${application}&amp;REVISION=${revision}&quot;
</code></pre>
<h2>Usage:</h2>
<pre><code>-h HOST     | --host=HOST                       Jenkins host
-j JOBNAME  | --jobname=test-build-job          The name of the jenkins job to trigger
-p JOBPARAM | --jobparam=environment=uat&amp;test=1 Jenkins job paramiters
-q          | --quiet                           Don't output any status messages
</code></pre>
</blockquote>
",53,2017-03-20T09:02:20.457,"['jenkins=https://user:pass@jenkins.mydomain.com:8080\njenkins_job=MyApp-Deploy\n\nenvironment=dev\napplication=myapp\nrevision=9fd71f63b351b8208264daf86d292ced580a2f60\n\n./jenkins_remote_trigger.sh \\\n            -h ${jenkins} \\\n            -j ${jenkins_job} \\\n            -p ""ENVIRONMENT=${environment}&APPLICATION=${application}&REVISION=${revision}""\n', ""-h HOST     | --host=HOST                       Jenkins host\n-j JOBNAME  | --jobname=test-build-job          The name of the jenkins job to trigger\n-p JOBPARAM | --jobparam=environment=uat&test=1 Jenkins job paramiters\n-q          | --quiet                           Don't output any status messages\n""]"
29,542,537,CC BY-SA 3.0,2017-03-17T08:54:40.677,"<p>This come from a design choice of YAML language about <a href=""http://yaml.org/type/bool.html"" rel=""noreferrer"">booleans</a></p>

<p>Every unquoted value matching this ""regex"":</p>

<pre><code> y|Y|yes|Yes|YES|n|N|no|No|NO
|true|True|TRUE|false|False|FALSE
|on|On|ON|off|Off|OFF
</code></pre>

<p>Will be converted to <code>True</code>  or <code>False</code>.</p>

<p>This start causing a problem when your code will test an environment value to be yes or no for example taking this script (other examples <a href=""https://github.com/docker/compose/pull/2000#issuecomment-138676720"" rel=""noreferrer"">in the PR discution</a>):</p>

<pre><code>if [ ""$SOME_VAR"" == ""yes"" ];
then
  echo ""Variable SOME_VAR is activated""
else
  echo ""Variable SOME_VAR is NOT activated""
fi
</code></pre>

<p>And setting in your compose file</p>

<pre><code>environment:
  SOME_VAR: yes
</code></pre>

<p>Will result in <code>SOME_VAR</code> being <code>True</code> when the script run, hence taking the wrong case as it is not equal to <code>yes</code>.</p>

<p>So the choice <a href=""https://github.com/docker/compose/issues/1788"" rel=""noreferrer"">has been made</a> to <a href=""https://github.com/docker/compose/pull/2000"" rel=""noreferrer"">disallow boolean</a> to prevent unwanted behaviors hard to debug when you're not aware of the YAML rule.</p>

<p>I see two way to get over the problem:</p>

<ol>
<li><p>Using an <a href=""https://docs.docker.com/compose/compose-file/compose-file-v1/#envfile"" rel=""noreferrer""><code>env_file</code></a> instead, they are not parsed IIRC and should prevent the conversion.</p></li>
<li><p>As you already said, use a wrapper script around your launcher to define the value instead before launching the app, something along the line of this should do:</p>

<pre><code>AUTOAPPLY=false
if [ ""$SOME_VAR"" == ""true"" ]
then
    AUTOAPPLY=true
fi

./target/universal/stage/bin/APPNAME -Dplay.evolutions.db.default.autoApply=$AUTOAPPLY
</code></pre></li>
</ol>
",13,2017-03-17T08:54:40.677,"[' y|Y|yes|Yes|YES|n|N|no|No|NO\n|true|True|TRUE|false|False|FALSE\n|on|On|ON|off|Off|OFF\n', 'if [ ""$SOME_VAR"" == ""yes"" ];\nthen\n  echo ""Variable SOME_VAR is activated""\nelse\n  echo ""Variable SOME_VAR is NOT activated""\nfi\n', 'environment:\n  SOME_VAR: yes\n', 'AUTOAPPLY=false\nif [ ""$SOME_VAR"" == ""true"" ]\nthen\n    AUTOAPPLY=true\nfi\n\n./target/universal/stage/bin/APPNAME -Dplay.evolutions.db.default.autoApply=$AUTOAPPLY\n']"
30,552,550,CC BY-SA 3.0,2017-03-18T03:51:44.400,"<p>Before explaining what it exactly is, let me quote a really nice definition, straight <a href=""https://en.wikipedia.org/wiki/Infrastructure_as_Code"" rel=""nofollow noreferrer"">from Wikipedia</a>:</p>

<blockquote>
  <p>Infrastructure as Code (IaC) is the process of managing and
  provisioning computing infrastructure (processes, bare-metal servers,
  virtual servers, etc.) and their configuration through
  machine-processable definition files, rather than physical hardware
  configuration or the use of interactive configuration tools.</p>
</blockquote>

<p>Okay, now let's look at one such IaC tool, Terraform to understand the concept better: <a href=""https://www.terraform.io/"" rel=""nofollow noreferrer"">https://www.terraform.io/</a></p>

<p>Also, this is what Terraform say about itself: </p>

<blockquote>
  <p>Terraform enables you to safely and predictably create, change, and
  improve production infrastructure. It is an open source tool that
  codifies APIs into declarative configuration files that can be shared
  amongst team members, treated as code, edited, reviewed, and
  versioned.</p>
</blockquote>

<p>This means, one can code the entire infra. which includes creation of cloud(/infra) resources like the server instances, load balancers, etc, along with the complete configurations (which includes the basic settings tweaks, security settings, regions, etc) as code, which can be editable, versionable and of course, reviewable.</p>

<p>This is a sample example of Terraform code for provisioning AWS resources:</p>

<pre><code>resource ""aws_elb"" ""frontend"" {
  name = ""frontend-load-balancer""
  listener {
    instance_port     = 8000
    instance_protocol = ""http""
    lb_port           = 80
    lb_protocol       = ""http""
  }

  instances = [""${aws_instance.app.*.id}""]
}

resource ""aws_instance"" ""app"" {
  count = 5

  ami           = ""ami-408c7f28""
  instance_type = ""t1.micro""
}
</code></pre>

<p><strong>Bonus PS</strong>: Also, one needs to understand the differences between <a href=""https://en.wikipedia.org/wiki/Provisioning"" rel=""nofollow noreferrer"">provisioning</a> and <a href=""https://en.wikipedia.org/wiki/Orchestration_(computing)"" rel=""nofollow noreferrer"">orchestration</a> tools. Devs confuse one for the other very often and tend to make the mistake of trying to tweak and use a tool for what it is not intended to be used for.</p>
",46,2017-03-18T14:37:58.703,"['resource ""aws_elb"" ""frontend"" {\n  name = ""frontend-load-balancer""\n  listener {\n    instance_port     = 8000\n    instance_protocol = ""http""\n    lb_port           = 80\n    lb_protocol       = ""http""\n  }\n\n  instances = [""${aws_instance.app.*.id}""]\n}\n\nresource ""aws_instance"" ""app"" {\n  count = 5\n\n  ami           = ""ami-408c7f28""\n  instance_type = ""t1.micro""\n}\n']"
31,562,59,CC BY-SA 3.0,2017-03-18T13:34:03.803,"<p>Travis CI supports <a href=""https://docs.travis-ci.com/user/deployment"" rel=""nofollow noreferrer"">deployment</a> on branch release by using the following syntax:</p>

<pre><code>deploy:
  on:
    branch: release
</code></pre>

<p>The problem is that GitHub does not support it.</p>

<p>As per <a href=""https://docs.travis-ci.com/user/deployment/releases/"" rel=""nofollow noreferrer"">GitHub Releases Uploading</a> page at Travis CI:</p>

<blockquote>
  <p>Please note that deploying GitHub Releases works only for tags, not for branches.</p>
</blockquote>

<p>For GitHub the only workaround is to push tags (e.g. <code>git push origin master --tags</code>).</p>

<p>Or solution is to use different <a href=""https://docs.travis-ci.com/user/deployment"" rel=""nofollow noreferrer"">supported provider</a>.</p>
",3,2017-03-18T13:34:03.803,['deploy:\n  on:\n    branch: release\n']
32,563,21,CC BY-SA 3.0,2017-03-18T13:42:12.890,"<p>All jobs (<code>jobs/</code>) and master config files (<code>config.xml</code>) can be found in <a href=""https://wiki.jenkins-ci.org/display/JENKINS/Administering+Jenkins"" rel=""noreferrer"">Jenkins home folder</a> (<code>JENKINS_HOME </code>) in the following structure:</p>
<pre><code>JENKINS_HOME
 +- config.xml     (jenkins root configuration)
 +- *.xml          (other site-wide configuration files)
 +- userContent    (files in this directory will be served under your http://server/userContent/)
 +- fingerprints   (stores fingerprint records)
 +- plugins        (stores plugins)
 +- workspace (working directory for the version control system)
     +- [JOBNAME] (sub directory for each job)
 +- jobs
     +- [JOBNAME]      (sub directory for each job)
         +- config.xml     (job configuration file)
         +- latest         (symbolic link to the last successful build)
         +- builds
             +- [BUILD_ID]     (for each build)
                 +- build.xml      (build result summary)
                 +- log            (log file)
                 +- changelog.xml  (change log)
</code></pre>
<p>Most of the config are in XML format, so backing all <code>.xml</code> files should be enough.</p>
<blockquote>
<p>All the settings, build logs, artifact archives are stored under the JENKINS_HOME directory. Simply archive this directory to make a back up. Similarly, restoring the data is just replacing the contents of the JENKINS_HOME directory from a back up.</p>
<p>Back ups can be taken without stopping the server, but when you restore, please do stop the server.</p>
</blockquote>
<hr />
<p>For consistent backups it is good practise to keep <code>JENKINS_HOME</code> directory under Git repository.</p>
<p>For example:</p>
<pre><code>cd $JENKINS_HOME
git init
shopt -s globstar
git add **/config.xml
git commit -m'Added job config files' -a
</code></pre>
<p>and pushing the files to the external repository. You can also add the following <a href=""https://stackoverflow.com/a/38297609/55075""><code>.gitignore</code> file</a> to ignore some files.</p>
<p>Related: <a href=""https://stackoverflow.com/q/2087142/55075"">Is there a way to keep Hudson / Jenkins configuration files in source control?</a></p>
",3,2017-03-18T13:42:12.890,"['JENKINS_HOME\n +- config.xml     (jenkins root configuration)\n +- *.xml          (other site-wide configuration files)\n +- userContent    (files in this directory will be served under your http://server/userContent/)\n +- fingerprints   (stores fingerprint records)\n +- plugins        (stores plugins)\n +- workspace (working directory for the version control system)\n     +- [JOBNAME] (sub directory for each job)\n +- jobs\n     +- [JOBNAME]      (sub directory for each job)\n         +- config.xml     (job configuration file)\n         +- latest         (symbolic link to the last successful build)\n         +- builds\n             +- [BUILD_ID]     (for each build)\n                 +- build.xml      (build result summary)\n                 +- log            (log file)\n                 +- changelog.xml  (change log)\n', ""cd $JENKINS_HOME\ngit init\nshopt -s globstar\ngit add **/config.xml\ngit commit -m'Added job config files' -a\n""]"
33,622,43,CC BY-SA 3.0,2017-03-22T14:15:41.097,"<p>I was trying to do something similar (embed build status icons into email notifications) but since our build system is not publicly accessible, I ended up posting the status icons to imgur and referencing those images by storing the URL in variables according to state.</p>

<p>Here are some snippets from my email template Groovyscript:</p>

<p><strong>Defining the URLs:</strong></p>

<pre><code>def images = [:]
images[""SUCCESS""] = ""http://i.imgur.com/uXlqCxW.gif""
images[""PASSED""] = ""http://i.imgur.com/uXlqCxW.gif""
images[""UNSTABLE""] = ""http://i.imgur.com/QkQbxR3.gif""
images[""SKIPPED""] = ""http://i.imgur.com/QkQbxR3.gif""
images[""FAILURE""] = ""http://i.imgur.com/LUveOg7.gif""
images[""FAILED""] = ""http://i.imgur.com/LUveOg7.gif""
images[""ABORTED""] = ""http://i.imgur.com/jSdrWWP.gif""
images[""NOT_RUN""] = ""http://i.imgur.com/jSdrWWP.gif""
</code></pre>

<p><strong>Using the URLs in the email:</strong></p>

<pre><code>&lt;img src=""${images[build.result.toString()]}"" /&gt;
</code></pre>
",362,2017-03-29T05:06:53.750,"['def images = [:]\nimages[""SUCCESS""] = ""http://i.imgur.com/uXlqCxW.gif""\nimages[""PASSED""] = ""http://i.imgur.com/uXlqCxW.gif""\nimages[""UNSTABLE""] = ""http://i.imgur.com/QkQbxR3.gif""\nimages[""SKIPPED""] = ""http://i.imgur.com/QkQbxR3.gif""\nimages[""FAILURE""] = ""http://i.imgur.com/LUveOg7.gif""\nimages[""FAILED""] = ""http://i.imgur.com/LUveOg7.gif""\nimages[""ABORTED""] = ""http://i.imgur.com/jSdrWWP.gif""\nimages[""NOT_RUN""] = ""http://i.imgur.com/jSdrWWP.gif""\n', '<img src=""${images[build.result.toString()]}"" />\n']"
34,624,621,CC BY-SA 3.0,2017-03-22T17:43:00.713,"<h1>Snapshot Permissions</h1>

<p>Boto3 has a function that allows you to create volume permissions, which is what <a href=""https://aws.amazon.com/marketplace/help/seller-building-AMIs?ref=help_ln_sibling#topic4"" rel=""noreferrer"">AMI Sharing with AWS Marketplace</a> requires you to do. <code>snapshot.modify_attribute</code> will allow you to share your AMI with the marketplace account like so (you can also use a JSON representation if you prefer, it's in the docs):</p>

<pre><code>response = snapshot.modify_attribute(
    Attribute = 'createVolumePermission',
    OperationType = 'add',
    UserIds = [
        '679593333241', # Marketplace user ID
    ]
)
</code></pre>

<p>There is also an <a href=""http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_ModifySnapshotAttribute.html"" rel=""noreferrer"">official API function</a> that will help you achieve the permissions requirement listed in <a href=""https://aws.amazon.com/marketplace/help/seller-building-AMIs?ref=help_ln_sibling#topic4"" rel=""noreferrer"">AMI Sharing with AWS Marketplace</a> if you decide to migrate from boto3 (or if a reader isn't using boto3). If your AMI is private, you need only make this API call:</p>

<pre><code>https://ec2.amazonaws.com/?Action=ModifySnapshotAttribute
&amp;SnapshotId=ID_HERE
&amp;CreateVolumePermission.Add.1.UserId=679593333241
&amp;AUTHPARAMS
</code></pre>

<p>This should add the permission that the marketplace needs to access your AMI. As for replacing <code>ID_HERE</code> with the snapshot's ID, you can do that with boto3 by using your snapshot object's <a href=""http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.Snapshot.snapshot_id"" rel=""noreferrer"">snapshot_id</a> property <code>snapshot.snapshot_id</code> before making the API call (that being said, there's little reason for you to use this API since you have to use boto3 anyways).</p>

<h1>Product Metadata</h1>

<p>You should be able to use the <a href=""http://boto3.readthedocs.io/en/latest/reference/services/servicecatalog.html"" rel=""noreferrer"">relevant ServiceCatalog functions</a> in boto3 such as <code>create_product</code> to upload product metadata. There are also <a href=""http://docs.aws.amazon.com/servicecatalog/latest/dg/API_CreateProduct.html"" rel=""noreferrer"">equivalent official API functions</a> (this one is just CreateProduct, they're not listed in a way that allows me to link to them nicely). It's worth noting that the official API only accepts JSON whereas boto3 will generate the JSON itself. Which one is more useful to you depends on how your data is structured in your product metadata file(s). Since I don't know that I can't directly write the code to do it.</p>
",201,2017-03-22T17:43:00.713,"[""response = snapshot.modify_attribute(\n    Attribute = 'createVolumePermission',\n    OperationType = 'add',\n    UserIds = [\n        '679593333241', # Marketplace user ID\n    ]\n)\n"", 'https://ec2.amazonaws.com/?Action=ModifySnapshotAttribute\n&SnapshotId=ID_HERE\n&CreateVolumePermission.Add.1.UserId=679593333241\n&AUTHPARAMS\n']"
35,625,623,CC BY-SA 3.0,2017-03-22T18:11:09.197,"<p>Here is one script which can help you find orphaned snapshots</p>

<pre><code>comm -23 &lt;(echo $(ec2-describe-snapshots --region eu-west-1 | grep SNAPSHOT | awk '{print $2}' | sort | uniq) | tr ' ' '\n') &lt;(echo $(ec2-describe-images --region eu-west-1 | grep BLOCKDEVICEMAPPING | awk '{print $3}' | sort | uniq) | tr ' ' '\n') | tr '\n' ' '
</code></pre>

<p>(from <a href=""http://www.robertsindall.co.uk/blog/how-to-clean-up-amazon-ebs-volumes-and-snapshots/"" rel=""nofollow noreferrer"">here</a>)</p>

<p>Also you can check this article from <a href=""https://serverfault.com/questions/611831/find-all-snapshots-created-by-ami-where-ami-is-deleted"">serverfault</a></p>

<p>P.S. Of course you can change the region to reflect your</p>

<p>P.P.S. Here is updated code:</p>

<pre><code> comm -23 \
&lt;(echo $(aws ec2 describe-snapshots --region eu-west-1 |awk '/SNAPSHOT/ {print $2}' | sort -u) | tr ' ' '\n') \
&lt;(echo $(aws ec2 describe-images --region eu-west-1 |  awk '/BLOCKDEVICEMAPPING/ {print $3}' | sort -u) | tr ' ' '\n') | tr '\n' ' '
</code></pre>

<p>The sample exaplanations what the code do is:</p>

<pre><code>echo $(aws ec2 describe-snapshots --region eu-west-1 | awk '/SNAPSHOT/ {print $2}' | sort -u) | tr ' ' '\n')
</code></pre>

<p>send to STDOUT the list of snapshots. this construction:</p>

<pre><code>&lt;(...)
</code></pre>

<p>create virtual temporary filehandler to make <code>comm</code> command read from two ""files"" and compare them</p>
",57,2017-03-23T08:44:06.510,"[""comm -23 <(echo $(ec2-describe-snapshots --region eu-west-1 | grep SNAPSHOT | awk '{print $2}' | sort | uniq) | tr ' ' '\\n') <(echo $(ec2-describe-images --region eu-west-1 | grep BLOCKDEVICEMAPPING | awk '{print $3}' | sort | uniq) | tr ' ' '\\n') | tr '\\n' ' '\n"", "" comm -23 \\\n<(echo $(aws ec2 describe-snapshots --region eu-west-1 |awk '/SNAPSHOT/ {print $2}' | sort -u) | tr ' ' '\\n') \\\n<(echo $(aws ec2 describe-images --region eu-west-1 |  awk '/BLOCKDEVICEMAPPING/ {print $3}' | sort -u) | tr ' ' '\\n') | tr '\\n' ' '\n"", ""echo $(aws ec2 describe-snapshots --region eu-west-1 | awk '/SNAPSHOT/ {print $2}' | sort -u) | tr ' ' '\\n')\n"", '<(...)\n']"
36,628,623,CC BY-SA 4.0,2017-03-23T10:46:19.017,"<p>Largely inspired by the blog posts and gist already linked in the other answers, here is my take to the problem.</p>

<p>I did use some convoluted <a href=""http://jmespath.org/"" rel=""nofollow noreferrer"">JMESpath</a> functions to get a list of snapshots and not require <code>tr</code>.</p>

<p><em>Disclaimer</em>: Use at your <strong>own risks</strong>, I did my best to avoid any problem and keep sane defaults, but I won't take any blame if it cause problem to you.</p>

<pre class=""lang-sh prettyprint-override""><code>#!/bin/sh
# remove x if you don't want to see the commands
set -ex

# Some variable initialisation with sane defaults
DRUN='--dry-run'
DO_DELETE=${1:-'no'}
REGION=${2:-'eu-west-1'}
ACCOUNTID=${3:-'self'}

# Get two temporary files
SNAP_FILE=$(mktemp)
IMAGE_FILE=$(mktemp)

# Get the snapshot list and the volume list
aws --region ""$REGION"" ec2 describe-snapshots --owner-ids ""$ACCOUNTID"" --query 'Snapshots[*].[SnapshotId]' --output text &gt; ""$SNAP_FILE""
aws --region ""$REGION"" ec2 describe-images --owners ""$ACCOUNTID"" --filters Name=state,Values=available --query 'Images[*].BlockDeviceMappings[*].Ebs.[SnapshotId]' --output text &gt; ""$IMAGE_FILE""

# Check if the outputed command should be dry-run (default) or not
if [ ""$DO_DELETE"" = ""IAMSURE"" ]
then
 DRUN=''
fi

# count each snapshot id, decrease when a volume reference it, print delete command for those with no volumes
awk -v REGION=""$REGION"" -v DRUN=""$DRUN"" '
FNR==NR { snap[$1]++; next } # increment snapshots and get to next line in file immediately

{ snap[$1]-- } # we changed file, decrease the snap counter when a volume reference it

END {
 for (s in snap) { # loop over the snapshots
   if (snap[s] &gt; 0) { # if we did not decrese under 1 that means there is no volume referencing this snapshot
    cmd=""aws --region "" REGION "" "" DRUN "" ec2 delete-snapshot --snapshot-id "" s
    print(cmd)
  }
 }
}
' ""$SNAP_FILE"" ""$IMAGE_FILE""
# Clean up the temp files
rm ""$SNAP_FILE"" ""$IMAGE_FILE""
</code></pre>

<p>I hope the script itself is commented enough.</p>

<p>Default usage (no-params) will list delete commands of orphaned snapshots for the current account and region eu-west-1, extract:</p>

<pre><code>aws --region eu-west-1 --dry-run ec2 delete-snapshot --snapshot-id snap-81e5856a
aws --region eu-west-1 --dry-run ec2 delete-snapshot --snapshot-id snap-95c68c7e
aws --region eu-west-1 --dry-run ec2 delete-snapshot --snapshot-id snap-a3bf50bd
</code></pre>

<p>You can redirect this output to a file for review before sourcing it to execute all the commands.</p>

<p>If you want the script to execute the command instead of printing them, replace <code>print(cmd)</code> by <code>system(cmd)</code>.</p>

<p>Usage is as follow with a script named <code>snap_cleaner</code>:</p>

<p>for dry-run commands in us-west-1 region</p>

<pre><code>./snap_cleaner no us-west-1
</code></pre>

<p>for usable commands in eu-central-1</p>

<pre><code>./snap_cleaner IAMSURE eu-central-1 
</code></pre>

<p>A third parameter can be used to access another account (I do prefer to switch role to another account before).</p>

<p>Stripped down version of the script with awk script as a oneliner:</p>

<pre><code>#!/bin/sh
set -ex

# Some variable initialisation with sane defaults
DRUN='--dry-run'
DO_DELETE=${1:-'no'}
REGION=${2:-'eu-west-1'}
ACCOUNTID=${3:-'self'}

# Get two temporary files
SNAP_FILE=$(mktemp)
IMAGE_FILE=$(mktemp)

# Get the snapshot list and the volume list
aws --region ""$REGION"" ec2 describe-snapshots --owner-ids ""$ACCOUNTID"" --query 'Snapshots[*].[SnapshotId]' --output text &gt; ""$SNAP_FILE""
aws --region ""$REGION"" ec2 describe-images --owners ""$ACCOUNTID"" --filters Name=state,Values=available --query 'Images[*].BlockDeviceMappings[*].Ebs.[SnapshotId]' --output text &gt; ""$IMAGE_FILE""

# Check if the outputed command should be dry-run (default) or not
if [ ""$DO_DELETE"" = ""IAMSURE"" ]
then
 DRUN=''
fi

# count each snapshot id, decrease when a volume reference it, print delete command for those with no volumes
awk -v REGION=""$REGION"" -v DRUN=""$DRUN"" 'FNR==NR { snap[$1]++; next } { snap[$1]-- } END { for (s in snap) { if (snap[s] &gt; 0) { cmd=""aws --region "" REGION "" "" DRUN "" ec2 delete-snapshot --snapshot-id "" s; print(cmd) } } }' ""$SNAP_FILE"" ""$IMAGE_FILE""
# Clean up the temp files
rm ""$SNAP_FILE"" ""$IMAGE_FILE""
</code></pre>
",13,2019-02-17T15:25:15.287,"['#!/bin/sh\n# remove x if you don\'t want to see the commands\nset -ex\n\n# Some variable initialisation with sane defaults\nDRUN=\'--dry-run\'\nDO_DELETE=${1:-\'no\'}\nREGION=${2:-\'eu-west-1\'}\nACCOUNTID=${3:-\'self\'}\n\n# Get two temporary files\nSNAP_FILE=$(mktemp)\nIMAGE_FILE=$(mktemp)\n\n# Get the snapshot list and the volume list\naws --region ""$REGION"" ec2 describe-snapshots --owner-ids ""$ACCOUNTID"" --query \'Snapshots[*].[SnapshotId]\' --output text > ""$SNAP_FILE""\naws --region ""$REGION"" ec2 describe-images --owners ""$ACCOUNTID"" --filters Name=state,Values=available --query \'Images[*].BlockDeviceMappings[*].Ebs.[SnapshotId]\' --output text > ""$IMAGE_FILE""\n\n# Check if the outputed command should be dry-run (default) or not\nif [ ""$DO_DELETE"" = ""IAMSURE"" ]\nthen\n DRUN=\'\'\nfi\n\n# count each snapshot id, decrease when a volume reference it, print delete command for those with no volumes\nawk -v REGION=""$REGION"" -v DRUN=""$DRUN"" \'\nFNR==NR { snap[$1]++; next } # increment snapshots and get to next line in file immediately\n\n{ snap[$1]-- } # we changed file, decrease the snap counter when a volume reference it\n\nEND {\n for (s in snap) { # loop over the snapshots\n   if (snap[s] > 0) { # if we did not decrese under 1 that means there is no volume referencing this snapshot\n    cmd=""aws --region "" REGION "" "" DRUN "" ec2 delete-snapshot --snapshot-id "" s\n    print(cmd)\n  }\n }\n}\n\' ""$SNAP_FILE"" ""$IMAGE_FILE""\n# Clean up the temp files\nrm ""$SNAP_FILE"" ""$IMAGE_FILE""\n', 'aws --region eu-west-1 --dry-run ec2 delete-snapshot --snapshot-id snap-81e5856a\naws --region eu-west-1 --dry-run ec2 delete-snapshot --snapshot-id snap-95c68c7e\naws --region eu-west-1 --dry-run ec2 delete-snapshot --snapshot-id snap-a3bf50bd\n', './snap_cleaner no us-west-1\n', './snap_cleaner IAMSURE eu-central-1 \n', '#!/bin/sh\nset -ex\n\n# Some variable initialisation with sane defaults\nDRUN=\'--dry-run\'\nDO_DELETE=${1:-\'no\'}\nREGION=${2:-\'eu-west-1\'}\nACCOUNTID=${3:-\'self\'}\n\n# Get two temporary files\nSNAP_FILE=$(mktemp)\nIMAGE_FILE=$(mktemp)\n\n# Get the snapshot list and the volume list\naws --region ""$REGION"" ec2 describe-snapshots --owner-ids ""$ACCOUNTID"" --query \'Snapshots[*].[SnapshotId]\' --output text > ""$SNAP_FILE""\naws --region ""$REGION"" ec2 describe-images --owners ""$ACCOUNTID"" --filters Name=state,Values=available --query \'Images[*].BlockDeviceMappings[*].Ebs.[SnapshotId]\' --output text > ""$IMAGE_FILE""\n\n# Check if the outputed command should be dry-run (default) or not\nif [ ""$DO_DELETE"" = ""IAMSURE"" ]\nthen\n DRUN=\'\'\nfi\n\n# count each snapshot id, decrease when a volume reference it, print delete command for those with no volumes\nawk -v REGION=""$REGION"" -v DRUN=""$DRUN"" \'FNR==NR { snap[$1]++; next } { snap[$1]-- } END { for (s in snap) { if (snap[s] > 0) { cmd=""aws --region "" REGION "" "" DRUN "" ec2 delete-snapshot --snapshot-id "" s; print(cmd) } } }\' ""$SNAP_FILE"" ""$IMAGE_FILE""\n# Clean up the temp files\nrm ""$SNAP_FILE"" ""$IMAGE_FILE""\n']"
37,665,662,CC BY-SA 3.0,2017-03-25T18:47:05.343,"<p>Consider using the <a href=""https://github.com/rabbitmq/rabbitmq-autocluster"" rel=""nofollow noreferrer"">rabbitmq/rabbitmq-autocluster</a> plugin:</p>

<blockquote>
  <p>A RabbitMQ plugin that clusters nodes automatically using a number of peer discovery mechanisms:</p>
  
  <ul>
  <li><a href=""https://www.consul.io/"" rel=""nofollow noreferrer"">Consul</a>,</li>
  <li><a href=""https://github.com/coreos/etcd"" rel=""nofollow noreferrer"">etcd2</a></li>
  <li>DNS A records</li>
  <li>AWS EC2 tags</li>
  <li>AWS Autoscaling Groups</li>
  </ul>
</blockquote>

<p>There is a <a href=""https://github.com/aweber/rabbitmq-autocluster/wiki/AWS%20Configuration"" rel=""nofollow noreferrer"">fair bit of configuration</a> to plug in to get this setup including setting IAM policies and adding EC2 tags to the instances you want to be party to your cluster.</p>

<p>If you were to use AWS Autoscaling Groups then you would add the following to your <code>rabbitmq.config</code>:</p>

<pre><code>[
  {rabbit, [ ... ]},
  {autocluster, [
    {backend, aws},
    {aws_autoscaling, true},
    {aws_ec2_region, ""us-west-2""}
  ]}
].
</code></pre>

<p>If you are not using AWS Autoscaling Groups you can still achieve the desired result using tags on your EC2 Instances:</p>

<pre><code>[
  {rabbit, [ ... ]},
  {autocluster, [
    {backend, aws},
    {aws_ec2_tags, [{""region"", ""us-west-2""}, {""service"", ""rabbitmq""}]},
    {aws_ec2_region, ""us-east-1""},
    {aws_access_key, ""...""},
    {aws_secret_key, ""...""}
  ]}
].
</code></pre>

<p>With all of that said I strongly recommend using <a href=""https://www.consul.io/"" rel=""nofollow noreferrer"">Consul by HashiCorp</a> as your service discovery mechanism, in the long run, you get significantly more flexibility in terms of decoupling your parts of your system from each other.</p>
",397,2017-03-25T18:47:05.343,"['[\n  {rabbit, [ ... ]},\n  {autocluster, [\n    {backend, aws},\n    {aws_autoscaling, true},\n    {aws_ec2_region, ""us-west-2""}\n  ]}\n].\n', '[\n  {rabbit, [ ... ]},\n  {autocluster, [\n    {backend, aws},\n    {aws_ec2_tags, [{""region"", ""us-west-2""}, {""service"", ""rabbitmq""}]},\n    {aws_ec2_region, ""us-east-1""},\n    {aws_access_key, ""...""},\n    {aws_secret_key, ""...""}\n  ]}\n].\n']"
38,683,666,CC BY-SA 3.0,2017-03-27T05:46:22.450,"<pre><code>ENV abc=hello
ENV abc=bye def=$abc
ENV ghi=$abc
</code></pre>

<p>will result in def having a value of hello, not bye. However, ghi will have a value of bye because it is not part of the same command that set abc to bye.</p>
",830,2017-03-27T05:56:09.540,['ENV abc=hello\nENV abc=bye def=$abc\nENV ghi=$abc\n']
39,684,666,CC BY-SA 3.0,2017-03-27T07:49:21.777,"<p>The <code>ENV</code> keyword will be translated to <code>export</code> command (builin of the shell usually), if you remove the multi-line declaration you end up with this equivalent:</p>

<pre><code>export A=123 B=$A
</code></pre>

<p>What happens here is that when the shell parse the line to give it to <code>export</code> input, <code>A</code> is not yet exported and available as an environment variable.</p>

<p>Step by step this will give:</p>

<ul>
<li>You type <code>export A=123 B=$A</code> </li>
<li>The shell parse the line and pass <code>A=123 B=</code> to <code>export</code>'s stdin</li>
<li><code>export</code> parse each argument in the form <code>key=value</code> and as such export <code>A</code> to be <code>123</code> and <code>B</code> to be empty</li>
</ul>

<p>On the second form, A is available to the shell when the line is parsed, and as such the resulting <code>export</code>'s stdin is <code>B=123</code></p>
",13,2017-03-27T07:49:21.777,['export A=123 B=$A\n']
40,692,691,CC BY-SA 3.0,2017-03-27T16:59:52.407,"<p>Can't call it's the best practice but this is what we use triggered by cron, happy to see better suggestions.</p>

<pre><code>echo ""safely removing untagged images""
docker rmi $(docker images | awk '/&lt;none&gt;/{print $3}')

echo ""safely removing stopped containers""
docker rm $(docker ps -a -q)

echo ""safely removing old containers""
docker ps -a | awk '/weeks ago|months ago|days ago/{print $1}' | xargs --no-run-if-empty docker rm

echo ""safely removing old images""
docker images | awk '/weeks ago|months ago|days ago/{print $3}' | xargs --no-run-if-empty docker rmi

echo ""safely removing old volumes, custom rebuild of martin/docker-cleanup-volumes image""
docker run -v /var/run/docker.sock:/var/run/docker.sock -v $(readlink -f /var/lib/docker):/var/lib/docker --rm example/docker-cleanup-volumes

echo ""native cleanup Docker =&gt; 12""
docker system prune -f
</code></pre>
",743,2017-03-27T20:36:44.190,"['echo ""safely removing untagged images""\ndocker rmi $(docker images | awk \'/<none>/{print $3}\')\n\necho ""safely removing stopped containers""\ndocker rm $(docker ps -a -q)\n\necho ""safely removing old containers""\ndocker ps -a | awk \'/weeks ago|months ago|days ago/{print $1}\' | xargs --no-run-if-empty docker rm\n\necho ""safely removing old images""\ndocker images | awk \'/weeks ago|months ago|days ago/{print $3}\' | xargs --no-run-if-empty docker rmi\n\necho ""safely removing old volumes, custom rebuild of martin/docker-cleanup-volumes image""\ndocker run -v /var/run/docker.sock:/var/run/docker.sock -v $(readlink -f /var/lib/docker):/var/lib/docker --rm example/docker-cleanup-volumes\n\necho ""native cleanup Docker => 12""\ndocker system prune -f\n']"
41,704,703,CC BY-SA 3.0,2017-03-28T19:34:09.267,"<p><a href=""https://github.com/ansible/ansible/blob/devel/lib/ansible/constants.py"" rel=""noreferrer"">Here</a> is the definition:</p>

<pre><code>DEFAULT_VAULT_PASSWORD_FILE = get_config(p, DEFAULTS, 'vault_password_file', \
'ANSIBLE_VAULT_PASSWORD_FILE', None, value_type='path')
</code></pre>

<hr>

<p>This means that you either put in ansible.cfg or playbook:</p>

<pre><code>vault_password_file: ~/.vault_pass.txt
</code></pre>

<p>Or in your shell defined this variable:</p>

<pre><code>export ANSIBLE_VAULT_PASSWORD_FILE=~/.vault_pass.txt
</code></pre>
",228,2017-03-30T13:48:38.560,"[""DEFAULT_VAULT_PASSWORD_FILE = get_config(p, DEFAULTS, 'vault_password_file', \\\n'ANSIBLE_VAULT_PASSWORD_FILE', None, value_type='path')\n"", 'vault_password_file: ~/.vault_pass.txt\n', 'export ANSIBLE_VAULT_PASSWORD_FILE=~/.vault_pass.txt\n']"
42,715,711,CC BY-SA 4.0,2017-03-29T13:23:05.933,"<p>I'd take that as a math problem with the SLA being the probability of being OK.</p>

<p>In this case we can rely on <a href=""https://en.wikipedia.org/wiki/Probability#Mathematical_treatment"" rel=""noreferrer"">probability rules</a> to get an overall.</p>

<p>For your first case the probability that App Service (A) and Sql Service (B) are down at the same time is the product of their probability:</p>

<pre><code>P(A)*P(B) = 0.0005 * 0.0005 = 0,00000025
</code></pre>

<p>The probability that one of them is down is the sum of their probability:</p>

<pre><code>P(A)+P(B) = 0.001
</code></pre>

<p>When two events are independents the resulting formula to take in account the probability of both being down is:</p>

<pre><code>P(A,B) = P(A) + P(B) - P(A)*P(B) = 0.001 - 0,00000025 = 0,00099975
</code></pre>

<p>So the overall SLA would be <code>1 - 0,00099975 =  0,99900025</code> wich in percent is <code>99.900025 %</code></p>

<p>A simplification is the product of the first probability: <code>0.9995 * 0.9995 = 0,99900025</code>.</p>

<p>Applied to your 1h/24h outage (4,166666% of a day)  this gives (decimals are abbreviated):</p>

<pre><code>0.0416 + 0.0416 - (0.0416 * 0.0416) = 0,081597222
</code></pre>

<p>So the probability of being OK is <code>1 - 0.0816 = 0.9184</code> in percent: <code>91,84%</code></p>

<pre><code>24 * 0.0816 = 1.95 h
</code></pre>

<p>This is less than the worst case of 2 hours because there's a chance both are down at the same time.</p>

<p>Keeping that in mind, you may notice the availability for each is <code>95,84%</code> and <code>0,958333333 * 0,958333333 = 0,918402778</code> which is our <code>91.84%</code> from above (sorry for the full decimals here, but they are needed for the demonstration)</p>

<p>Now for your second case, we'll start gain from our compound probability for each region (Sorry I dismissed the change for SQL to keep it reasonable), assuming there's no independent probability for the region itself and that each region is isolated and as such a DB failure take only its region down.</p>

<p>We have the traffic manager OK probability <code>P(T) = 0.9999</code> and each app+DB couple with a OK probability <code>P(G) = 0,99900025</code> from </p>

<p>How much region we have play a role as we have to apply the product of failure probability only to get the probability both region are down as the same time:<br>
<code>0,00099975 * 0,00099975 = 0,0000009995000625</code> which means an overall availability of at least one region of <code>99,049375 %</code> </p>

<p>Now we have the overall regions availability, the product with the traffic manager one give us the overall availability of the system:</p>

<pre><code>0.9999 * 0,9999990004999375 = 0,99989900059988750625
</code></pre>

<p>The overall availability is <code>99.989900 %</code> </p>

<p>Another source as explanation is available on <a href=""https://docs.microsoft.com/en-us/azure/architecture/resiliency/#composite-slas"" rel=""noreferrer"">Azure's docs</a> (link courtesy of <a href=""https://devops.stackexchange.com/users/11333/raj-rao"">Raj Rao</a>)</p>
",13,2018-12-13T08:38:42.183,"['P(A)*P(B) = 0.0005 * 0.0005 = 0,00000025\n', 'P(A)+P(B) = 0.001\n', 'P(A,B) = P(A) + P(B) - P(A)*P(B) = 0.001 - 0,00000025 = 0,00099975\n', '0.0416 + 0.0416 - (0.0416 * 0.0416) = 0,081597222\n', '24 * 0.0816 = 1.95 h\n', '0.9999 * 0,9999990004999375 = 0,99989900059988750625\n']"
43,726,725,CC BY-SA 3.0,2017-03-30T16:13:06.910,"<p>In your <code>ansible.cfg</code> file you need to add the following line:</p>

<pre><code>ssh_args = -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no
</code></pre>

<p>You could also add those options in your <code>~/.ssh/config</code> on every machine from which you run it something like this:</p>

<pre><code>Host *
   StrictHostKeyChecking no
   UserKnownHostsFile=/dev/null
</code></pre>
",228,2017-05-27T05:25:39.413,"['ssh_args = -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\n', 'Host *\n   StrictHostKeyChecking no\n   UserKnownHostsFile=/dev/null\n']"
44,736,735,CC BY-SA 3.0,2017-03-31T06:23:54.867,"<p>The task which fails is:</p>

<pre><code>- name: copy demo app source
  copy: src=demo/app/ dest=/var/www/demo mode=0755
  notify: restart apache2
</code></pre>

<p>If you have a look at your folder structure and more specifically the <code>demo_app</code> role, you have:</p>

<pre><code>│   ├── demo_app
│   │   ├── defaults
│   │   │   └── main.yml
│   │   ├── files
│   │   │   └── app
│   │   │       ├── demo.py
│   │   │       └── requirements.txt
│   │   ├── handlers
│   │   │   └── main.yml
│   │   ├── meta
│   │   │   └── main.yml
│   │   ├── README.md
│   │   ├── tasks
│   │   │   └── main.yml
│   │   ├── templates
│   │   │   └── demo.wsgi.j2
│   │   ├── tests
│   │   │   ├── inventory
│   │   │   └── test.yml
│   │   └── vars
│   │       └── main.yml
</code></pre>

<p>The <code>copy</code> task will look for the <code>src</code> in <code>demo_app/files/</code>. So, either change your task to:</p>

<pre><code>- name: copy demo app source
  copy: src=app dest=/var/www/demo mode=0755
  notify: restart apache2
</code></pre>

<p>Or create a <code>demo</code> directory in <code>demo_app/files/</code> and place the <code>app</code> directory in it (like <code>demo_app/files/demo/app/</code>).</p>

<p>Setting an absolute path to the directory in the task will also work, but don't think it's an elegant solution.</p>
",775,2017-03-31T06:37:43.913,"['- name: copy demo app source\n  copy: src=demo/app/ dest=/var/www/demo mode=0755\n  notify: restart apache2\n', '│   ├── demo_app\n│   │   ├── defaults\n│   │   │   └── main.yml\n│   │   ├── files\n│   │   │   └── app\n│   │   │       ├── demo.py\n│   │   │       └── requirements.txt\n│   │   ├── handlers\n│   │   │   └── main.yml\n│   │   ├── meta\n│   │   │   └── main.yml\n│   │   ├── README.md\n│   │   ├── tasks\n│   │   │   └── main.yml\n│   │   ├── templates\n│   │   │   └── demo.wsgi.j2\n│   │   ├── tests\n│   │   │   ├── inventory\n│   │   │   └── test.yml\n│   │   └── vars\n│   │       └── main.yml\n', '- name: copy demo app source\n  copy: src=app dest=/var/www/demo mode=0755\n  notify: restart apache2\n']"
45,753,740,CC BY-SA 3.0,2017-04-02T12:51:06.963,"<p>A solution is to remove the <code>not empty directory</code> using <code>find</code>:</p>

<p><strong>Dockerfile</strong></p>

<pre><code>FROM alpine

RUN mkdir dir &amp;&amp; cd dir &amp;&amp; wget http://google.com &amp;&amp; cd / &amp;&amp; echo -e ""BEFORE\n"" &amp;&amp; ls &amp;&amp; find /dir -delete &amp;&amp; echo -e ""\nAFTER\n"" &amp;&amp; ls
</code></pre>

<p><strong>Outcome</strong></p>

<pre><code>Sending build context to Docker daemon  2.048kB
Step 1/2 : FROM alpine
 ---&gt; 4a415e366388
Step 2/2 : RUN mkdir dir &amp;&amp; cd dir &amp;&amp; wget http://google.com &amp;&amp; cd / &amp;&amp; echo -e ""BEFORE\n"" &amp;&amp; ls &amp;&amp; find /dir -delete &amp;&amp; echo -e ""\nAFTER\n"" &amp;&amp; ls
 ---&gt; Running in ba93a1742a76
Connecting to google.com (172.217.20.110:80)
Connecting to www.google.nl (172.217.20.99:80)
index.html           100% |*******************************| 11092   0:00:00 ETA

BEFORE

bin
dev
dir
etc
home
lib
media
mnt
proc
root
run
sbin
srv
sys
tmp
usr
var

AFTER

bin
dev
etc
home
lib
media
mnt
proc
root
run
sbin
srv
sys
tmp
usr
var
 ---&gt; 2e3109285a2d
Removing intermediate container ba93a1742a76
Successfully built 2e3109285a2d
</code></pre>
",210,2017-04-14T07:52:48.080,"['FROM alpine\n\nRUN mkdir dir && cd dir && wget http://google.com && cd / && echo -e ""BEFORE\\n"" && ls && find /dir -delete && echo -e ""\\nAFTER\\n"" && ls\n', 'Sending build context to Docker daemon  2.048kB\nStep 1/2 : FROM alpine\n ---> 4a415e366388\nStep 2/2 : RUN mkdir dir && cd dir && wget http://google.com && cd / && echo -e ""BEFORE\\n"" && ls && find /dir -delete && echo -e ""\\nAFTER\\n"" && ls\n ---> Running in ba93a1742a76\nConnecting to google.com (172.217.20.110:80)\nConnecting to www.google.nl (172.217.20.99:80)\nindex.html           100% |*******************************| 11092   0:00:00 ETA\n\nBEFORE\n\nbin\ndev\ndir\netc\nhome\nlib\nmedia\nmnt\nproc\nroot\nrun\nsbin\nsrv\nsys\ntmp\nusr\nvar\n\nAFTER\n\nbin\ndev\netc\nhome\nlib\nmedia\nmnt\nproc\nroot\nrun\nsbin\nsrv\nsys\ntmp\nusr\nvar\n ---> 2e3109285a2d\nRemoving intermediate container ba93a1742a76\nSuccessfully built 2e3109285a2d\n']"
46,765,740,CC BY-SA 3.0,2017-04-03T14:09:19.167,"<p>Building on Xiong Chiamiov's answer, which correctly identified the root cause of the problem - the <code>dir</code> reference by relative path when attempting to empty or delete that directory depends on the working directory at the time, which was not correctly set in the cases mentioned in the OP.</p>

<p>So there are 2 solutions available:</p>

<ul>
<li><p>set the proper working dir prior to executing the <code>dir</code> removal:</p>

<pre><code>RUN mkdir dir &amp;&amp; cd dir &amp;&amp; wget http://google.com &amp;&amp; cd .. %% rm -rf dir
</code></pre></li>
<li><p>use a <code>/dir</code> full path reference to that directory instead. But with care (adjust if needed) if used in cases just similar, but not identical to this one, since this approach assumes the initial working dir was <code>/</code>:</p>

<pre><code>RUN mkdir dir &amp;&amp; cd dir &amp;&amp; wget http://google.com &amp;&amp; rm -rf /dir
</code></pre></li>
</ul>
",47,2017-04-03T14:09:19.167,"['RUN mkdir dir && cd dir && wget http://google.com && cd .. %% rm -rf dir\n', 'RUN mkdir dir && cd dir && wget http://google.com && rm -rf /dir\n']"
47,774,764,CC BY-SA 3.0,2017-04-04T13:58:54.170,"<p>So after a debug session in <a href=""http://chat.stackexchange.com/rooms/56541/discussion-between-tensibai-and-tobassist"">chat</a> what is needed is to allow the user running jenkins to be able to <code>sudo docker</code> passwordless on the docker host. </p>

<p>A typical sudoers file on ubuntu could be in <code>/etc/sudoers.d/jenkins</code></p>

<pre><code>jenkins_user ALL=(ALL) NOPASSWD:ALL
</code></pre>

<p>Be warned this allow <code>jenkins_user</code> to run as root without password any command, a better file should be:</p>

<pre><code>jenkins_user ALL=(ALL) NOPASSWD:/full/path/to/docker
jenkins_user ALL=(ALL) NOPASSWD:&lt;other needed command to be run as root&gt;
</code></pre>

<p>This will allow to start the container as root and as such it gives all rights within the container itself by running as uid 0.</p>

<p>Useful resources used aside:</p>

<ul>
<li><a href=""https://wiki.jenkins-ci.org/display/JENKINS/Docker+Plugin"" rel=""nofollow noreferrer"">Jenkins docker plugin readme</a></li>
<li><a href=""https://serverfault.com/a/596988"">How to setup passwordless <code>sudo</code> on Linux?</a></li>
</ul>
",13,2017-04-04T14:01:25.980,"['jenkins_user ALL=(ALL) NOPASSWD:ALL\n', 'jenkins_user ALL=(ALL) NOPASSWD:/full/path/to/docker\njenkins_user ALL=(ALL) NOPASSWD:<other needed command to be run as root>\n']"
48,796,793,CC BY-SA 3.0,2017-04-06T09:23:37.683,"<p>Specifically in answer to your 3<sup>rd</sup> question, if you are willing to look outside of the Jenkins Ecosystem there are alternatives out there that might be of value to you. </p>

<p>For my clients who use the Microsoft Stack and have fewer than four teams, I have been recommending the use of <a href=""https://www.appveyor.com/"" rel=""nofollow noreferrer"">AppVeyor</a> it is highly tuned for the .NET Stack and integrated very naturally with <code>msbuild</code> and Wix.</p>

<p><a href=""https://i.stack.imgur.com/96imo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/96imo.png"" alt=""AppVeyor""></a></p>

<p>There are two ways of configuring AppVeyor, either through the <a href=""https://ci.appveyor.com"" rel=""nofollow noreferrer"">web-based user interface</a> or via the <a href=""https://www.appveyor.com/docs/appveyor-yml/"" rel=""nofollow noreferrer""><code>appveyor.yml</code> file</a> checked into the root of the git repository.  I would strongly recommend the latter, you are welcome to start from this template:</p>

<pre><code>version: 3.0.{build}

build:
  parallel: true
  project: EVEMon.sln

cache:
  - packages -&gt; **\packages.config

install:
  - nuget restore
</code></pre>

<p>The major drawback of AppVeyor and it's cousins <a href=""https://travis-ci.org/"" rel=""nofollow noreferrer"">TravisCI</a> and <a href=""https://circleci.com/"" rel=""nofollow noreferrer"">CircleCI</a> is they don't play particularly nicely with on-premise source code management solutions, you do really need to be using GitHub or BitBucket.</p>
",397,2017-04-06T15:56:46.897,['version: 3.0.{build}\n\nbuild:\n  parallel: true\n  project: EVEMon.sln\n\ncache:\n  - packages -> **\\packages.config\n\ninstall:\n  - nuget restore\n']
49,818,817,CC BY-SA 3.0,2017-04-08T05:02:59.307,"<p>After looking a bit further, I found it in the sample called <code>filebeat.full.yml</code></p>

<ul>
<li>So I added this section to the filebeat.yml</li>
<li>Restarted filebeat </li>
</ul>

<p>After running at 100% CPU for minute, Kibana is now immediately showing the results. That was easier than I expected.</p>

<pre><code>#==========================  Modules configuration ============================
filebeat.modules:

#------------------------------- Apache2 Module ------------------------------
- module: apache2
  # Access logs
  access:
    #enabled: true

    # Set custom paths for the log files. If left empty,
    # Filebeat will choose the paths depending on your OS.
    var.paths: [""MY-CUSTOM-PATH""]
</code></pre>
",1218,2017-04-08T05:02:59.307,"['#==========================  Modules configuration ============================\nfilebeat.modules:\n\n#------------------------------- Apache2 Module ------------------------------\n- module: apache2\n  # Access logs\n  access:\n    #enabled: true\n\n    # Set custom paths for the log files. If left empty,\n    # Filebeat will choose the paths depending on your OS.\n    var.paths: [""MY-CUSTOM-PATH""]\n']"
50,829,709,CC BY-SA 3.0,2017-04-10T09:17:44.573,"<p>Using</p>

<pre><code>ansible-playbook site.yml --vault-password-file ./mypass.sh
</code></pre>

<p>resulted in:</p>

<pre><code>ERROR! Problem running vault password script / p a t h / t o
/ e c h o _ v a u l t _ p a s s . s h ([Errno 8] Exec format error). If this is 
not a script, remove the executable bit from the file.
</code></pre>

<p>Based on <a href=""http://www.kdelemme.com/2016/07/06/use-ansible-to-deploy-with-circleci/"" rel=""nofollow noreferrer"">this post</a> the following was defined in bitbucket-pipelines:</p>

<pre><code>image: docker:latest

pipelines:
  default:
    - step:
        script:
          - echo $ANSIBLE_VAULT_PASSWORD &gt; .vault_password.txt
          - ansible-playbook -i ansible/inventory ansible/site.yml --vault-password-file .vault_password.txt
</code></pre>
",210,2017-04-10T09:17:44.573,"['ansible-playbook site.yml --vault-password-file ./mypass.sh\n', 'ERROR! Problem running vault password script / p a t h / t o\n/ e c h o _ v a u l t _ p a s s . s h ([Errno 8] Exec format error). If this is \nnot a script, remove the executable bit from the file.\n', 'image: docker:latest\n\npipelines:\n  default:\n    - step:\n        script:\n          - echo $ANSIBLE_VAULT_PASSWORD > .vault_password.txt\n          - ansible-playbook -i ansible/inventory ansible/site.yml --vault-password-file .vault_password.txt\n']"
51,832,809,CC BY-SA 3.0,2017-04-10T17:00:53.070,"<p>You don't make any mention of the scripting language you want to use, so I will talk specifically about the HTTP requests to the BitBucket API:</p>

<h2>Assumptions</h2>

<p>If you have a <a href=""https://bitbucket.org/RichardSlater/greencommitproofofconcept"" rel=""noreferrer"">BitBucket Repository</a> that has three commits in in it the first and the last are failing the build, the middle is passing:</p>

<ul>
<li>4768815 ❌</li>
<li>49d7110 ✅</li>
<li>42d357f ❌</li>
</ul>

<h2>Get the list of commits</h2>

<p>You can get the list of commits by calling the following API method:</p>

<blockquote>
  <p><code>https://api.bitbucket.org/2.0/repositories/{{owner}}/{{repo_slug}}/commits</code></p>
  
  <ul>
  <li><code>owner</code>: RichardSlater</li>
  <li><code>repo_slug</code>: greencommitproofofconcept</li>
  </ul>
</blockquote>

<p>The response looks like this:</p>

<pre><code>{
  ""pagelen"": 30,
  ""values"": [
    {
      ""hash"": ""4768815fdc27abf4be17096e7c460f7f68f5d39b"",
      ""repository"": { ... },
      ""links"": {
        ...
        ""statuses"": {
          ""href"": ""https://api.bitbucket.org/2.0/repositories/RichardSlater/greencommitproofofconcept/commit/4768815fdc27abf4be17096e7c460f7f68f5d39b/statuses""
        }
      },
      ""author"": { ... },
      ""parents"": [ ... ],
      ""date"": ""2017-04-10T11:38:18+00:00"",
      ""message"": ""README.md edited online with Bitbucket"",
      ""type"": ""commit""
    },
    {
      ""hash"": ""49d7110b98616358d16055960a4abdf2926b890d"",
      ...
    },
    {
      ""hash"": ""42d357f1df7a7d7bcf1f10a9f3a5a40d85d5b11c"",
      ...
    }
  ]
}
</code></pre>

<p>If you parse the JSON and loop over the responses you can extract out the statuses from:</p>

<pre><code>values[n].links.statuses.href
</code></pre>

<p>Where <code>n</code> is the index, i.e. <code>0</code>, <code>1</code> or <code>2</code> in the above example.  If you were to construct this from scratch it would be in the following format.</p>

<h2>Get the list of statuses from the commit</h2>

<blockquote>
  <p><code>https://api.bitbucket.org/2.0/repositories/{{owner}}/{{repo_slug}}/commit/{{sha}}/statuses""</code></p>
  
  <ul>
  <li><code>owner</code>: RichardSlater</li>
  <li><code>repo_slug</code>: greencommitproofofconcept</li>
  <li><code>sha</code>: 4768815fdc27abf4be17096e7c460f7f68f5d39b</li>
  </ul>
</blockquote>

<p><strong>Note:</strong> this is a Hypermedia API which means the urls <em>could</em> change so I would recommend using the links from the previous response rather than trying to generate them from scratch.</p>

<p>The response from the above HTTP request will be something like:</p>

<pre><code>{
  ""pagelen"": 10,
  ""values"": [
    {
      ""key"": ""POC-01"",
      ""name"": ""Build #1"",
      ""repository"": { ... },
      ""url"": ""http://devops.stackexchange.com/q/809/397"",
      ""links"": { ... },
      ""refname"": null,
      ""state"": ""FAILED"",
      ""created_on"": ""2017-04-10T13:04:28.261734+00:00"",
      ""updated_on"": ""2017-04-10T13:04:28.261759+00:00"",
      ""type"": ""build"",
      ""description"": ""Changes by Richard Slater""
    }
  ],
  ""page"": 1,
  ""size"": 1
}
</code></pre>

<p>From this response you can extract the <code>state</code> using:</p>

<pre><code>values[n].state
</code></pre>

<p>Again where <code>n</code> is the <code>status</code> - there could be many of them if one commit resulted in many builds.</p>

<p>If the state for the build you care about is <code>SUCCESSFUL</code> then you have your answer and you can immediately return the <code>sha</code> for the commit.</p>

<p>Loop over all of the commits from the first phase, if you run out of commits follow the <code>next</code> page <code>link</code> that is included in the call to <code>/commits</code>.</p>

<h2>Complete Flow Diagram</h2>

<p>At a high level the flow will look like this:</p>

<p><a href=""https://i.stack.imgur.com/IMe8G.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/IMe8G.png"" alt=""Flow Diagram""></a></p>

<p>Don't forget this is a <a href=""https://looselyconnected.wordpress.com/2011/03/09/the-richardson-maturity-model-of-rest-and-roy-fielding/"" rel=""noreferrer"">Hypermedia API</a> so wherever possible have your code follow the links in the API rather than trying to ""guess them"".</p>
",397,2017-04-11T08:54:21.933,"['{\n  ""pagelen"": 30,\n  ""values"": [\n    {\n      ""hash"": ""4768815fdc27abf4be17096e7c460f7f68f5d39b"",\n      ""repository"": { ... },\n      ""links"": {\n        ...\n        ""statuses"": {\n          ""href"": ""https://api.bitbucket.org/2.0/repositories/RichardSlater/greencommitproofofconcept/commit/4768815fdc27abf4be17096e7c460f7f68f5d39b/statuses""\n        }\n      },\n      ""author"": { ... },\n      ""parents"": [ ... ],\n      ""date"": ""2017-04-10T11:38:18+00:00"",\n      ""message"": ""README.md edited online with Bitbucket"",\n      ""type"": ""commit""\n    },\n    {\n      ""hash"": ""49d7110b98616358d16055960a4abdf2926b890d"",\n      ...\n    },\n    {\n      ""hash"": ""42d357f1df7a7d7bcf1f10a9f3a5a40d85d5b11c"",\n      ...\n    }\n  ]\n}\n', 'values[n].links.statuses.href\n', '{\n  ""pagelen"": 10,\n  ""values"": [\n    {\n      ""key"": ""POC-01"",\n      ""name"": ""Build #1"",\n      ""repository"": { ... },\n      ""url"": ""http://devops.stackexchange.com/q/809/397"",\n      ""links"": { ... },\n      ""refname"": null,\n      ""state"": ""FAILED"",\n      ""created_on"": ""2017-04-10T13:04:28.261734+00:00"",\n      ""updated_on"": ""2017-04-10T13:04:28.261759+00:00"",\n      ""type"": ""build"",\n      ""description"": ""Changes by Richard Slater""\n    }\n  ],\n  ""page"": 1,\n  ""size"": 1\n}\n', 'values[n].state\n']"
52,837,833,CC BY-SA 3.0,2017-04-11T06:50:42.650,"<p>You can't add <code>deny</code> rules to GC firewall. The default policy is <code>Deny</code>. You can only add <code>allow</code> rules - allow everything you need and let everything else get rejected. </p>

<p>Since the ports you need to block are allowed by default, you simply need to remove them. Check the name of the default rule:</p>

<pre><code>gcloud compute firewall-rules list [NAME …] [--regexp=REGEXP, -r REGEXP] [--filter=EXPRESSION] [--limit=LIMIT] [--page-size=PAGE_SIZE] [--sort-by=[FIELD,…]] [--uri] [GLOBAL-FLAG …]
</code></pre>

<p>and delete it with:</p>

<pre><code>gcloud compute firewall-rules delete NAME [NAME …] [GLOBAL-FLAG …]
</code></pre>

<p>You may check <a href=""https://cloud.google.com/sdk/gcloud/reference/compute/firewall-rules/"" rel=""noreferrer"">here</a> for more detailed explanation on how to handle Google Cloud firewall.</p>
",775,2017-04-11T06:50:42.650,"['gcloud compute firewall-rules list [NAME …] [--regexp=REGEXP, -r REGEXP] [--filter=EXPRESSION] [--limit=LIMIT] [--page-size=PAGE_SIZE] [--sort-by=[FIELD,…]] [--uri] [GLOBAL-FLAG …]\n', 'gcloud compute firewall-rules delete NAME [NAME …] [GLOBAL-FLAG …]\n']"
53,841,838,CC BY-SA 3.0,2017-04-11T08:26:49.093,"<p>I still don't get how your <code>config.yml</code> could launch ansible without a step part. Here is my findings, but I'm unsure it is what you're after, but that was too long for a comment. </p>

<p>According to the <a href=""https://circleci.com/docs/2.0/project-walkthrough/#deploy-through-circleci"" rel=""noreferrer"">documentation here</a> you have to add a <code>add_ssh_keys</code> with the fingerprint of your key as seen in the UI.</p>

<pre><code>- add_ssh_keys:
    fingerprints:
      - ""48:a0:87:54:ca:75:32:12:c6:9e:a2:77:a4:7a:08:a4""
</code></pre>
",13,2017-04-11T08:26:49.093,"['- add_ssh_keys:\n    fingerprints:\n      - ""48:a0:87:54:ca:75:32:12:c6:9e:a2:77:a4:7a:08:a4""\n']"
54,887,885,CC BY-SA 4.0,2017-04-13T17:36:29.043,"<p>Figured it out. <strong>Outside of any stages</strong> (otherwise this will just end the particular stage as a success) do the following;</p>

<pre><code>if( $VALUE1 == $VALUE2 ) {
   currentBuild.result = 'SUCCESS'
   return
}
</code></pre>

<p><code>return</code> <strong>will stop the stage or node you're running on</strong> which is why running it outside of a stage is important, while setting the <code>currentBuild.result</code> prevents it from failing.</p>
",736,2019-08-07T04:04:29.430,"[""if( $VALUE1 == $VALUE2 ) {\n   currentBuild.result = 'SUCCESS'\n   return\n}\n""]"
55,903,862,CC BY-SA 3.0,2017-04-16T09:15:52.640,"<p>The Amazon Cognito streams feature can be used to backup data.</p>

<p>Currently, Amazon does not provide a solution to backup their Cognito user Pools. You can use the following NPM package called ""<strong>cognito-backup</strong>"":</p>

<h2>Install:</h2>

<pre><code>npm install -g cognito-backup
</code></pre>

<h2>Usage</h2>

<pre><code>cognito-backup backup-users &lt;user-pool-id&gt; &lt;options&gt;  Backup all users in a single user pool
cognito-backup backup-all-users &lt;options&gt;  Backup all users in all user pools for this account
</code></pre>

<h2>Examples</h2>

<pre><code>cognito-backup backup-users eu-west-1_1_12345
cognito-backup backup-users eu-west-1_1_12345 --region eu-west-1 --file mypool.json
cognito-backup backup-all-users eu-west-1_1_12345 --region eu-west-1 --dir output
</code></pre>

<p>Source: <a href=""https://www.npmjs.com/package/cognito-backup"" rel=""noreferrer"">https://www.npmjs.com/package/cognito-backup</a></p>
",887,2017-12-16T09:10:44.713,"['npm install -g cognito-backup\n', 'cognito-backup backup-users <user-pool-id> <options>  Backup all users in a single user pool\ncognito-backup backup-all-users <options>  Backup all users in all user pools for this account\n', 'cognito-backup backup-users eu-west-1_1_12345\ncognito-backup backup-users eu-west-1_1_12345 --region eu-west-1 --file mypool.json\ncognito-backup backup-all-users eu-west-1_1_12345 --region eu-west-1 --dir output\n']"
56,904,900,CC BY-SA 3.0,2017-04-16T09:40:41.553,"<p>The output of <code>docker images</code> is really intended for humans, and it's not very parse-friendly. Instead, most Docker commands support a <a href=""https://docs.docker.com/engine/admin/formatting/"" rel=""nofollow noreferrer""><code>--format</code> flag using Go templates</a>. As you can see in the <a href=""https://docs.docker.com/engine/reference/commandline/images/#format-the-output"" rel=""nofollow noreferrer""><code>images</code> documentation</a>, you only really care about the <code>.Size</code> value, so you really want this:</p>

<pre><code>docker images --format ""{{.Size}}""
</code></pre>

<p>This just gives an output like this:</p>

<pre><code>90.6 MB
</code></pre>

<p>If you have multiple images, they will each be on a separate line. I'm going to assume you will only ever have one line, because it vastly simplifies the next steps.</p>

<p>To get rid of the <code>MB</code>, we can simply use <code>sed</code>:</p>

<pre><code>docker images --format ""{{.Size}}"" | sed ""s/MB//g""
# =&gt; 90.6
</code></pre>

<p>But, you probably <strong>don't</strong> want this for your bash script. Most shells don't support floating point comparisons, so inputting 90.6 would just fail. Instead, let's use <code>bc</code> to truncate the number first:</p>

<pre><code>docker images --format ""{{.Size}}"" | sed ""s/MB/\/1/g"" | bc
# =&gt; 90
</code></pre>

<p>Note that I've replaced the <code>MB</code> with a division by 1, which <a href=""https://stackoverflow.com/questions/20558710/bc-truncate-floating-point-number"">truncates in <code>bc</code></a>.</p>

<p>You can then pipe it into a shell script. I tested with this script:</p>

<pre><code>VAR=$(cat)

if [ $VAR -gt ""250"" ]
    then
    echo ""Image too large""
    exit 1
fi
</code></pre>

<p>Then run with:</p>

<pre><code>docker images --format ""{{.Size}}"" | sed ""s/MB/\/1/g"" | bc | ./check_size.sh
# Exits with 0 (for my example)
</code></pre>
",14,2017-04-16T12:35:20.243,"['docker images --format ""{{.Size}}""\n', '90.6 MB\n', 'docker images --format ""{{.Size}}"" | sed ""s/MB//g""\n# => 90.6\n', 'docker images --format ""{{.Size}}"" | sed ""s/MB/\\/1/g"" | bc\n# => 90\n', 'VAR=$(cat)\n\nif [ $VAR -gt ""250"" ]\n    then\n    echo ""Image too large""\n    exit 1\nfi\n', 'docker images --format ""{{.Size}}"" | sed ""s/MB/\\/1/g"" | bc | ./check_size.sh\n# Exits with 0 (for my example)\n']"
57,932,927,CC BY-SA 3.0,2017-04-17T18:37:18.980,"<p>I would personally consider a model like this:</p>

<pre><code>Timed Lambdas -&gt; Checks spot price -&gt; Push to ElastiCache
</code></pre>

<p>Then when you need instances:</p>

<pre><code>Timed lambdas -&gt; Pulls spot price from ElastiCache, sets it as environment variable on your Machine where you spin up IaC from -&gt; This is parsed as argument to IaC code and pushes out the spot price
</code></pre>

<p>You could set some tolerances, too, within the lambdas (i.e. 10, 25, 50% increases based on importance) and a hard cap of on-demand, for example. It's also a great place to build the logic to handle, for example, finding the cheapest AZ, finding the relatively cheapest spot price (<code>2xt2.medium</code> vs <code>t2.large</code>), etc.</p>
",2334,2017-04-17T18:37:18.980,"['Timed Lambdas -> Checks spot price -> Push to ElastiCache\n', 'Timed lambdas -> Pulls spot price from ElastiCache, sets it as environment variable on your Machine where you spin up IaC from -> This is parsed as argument to IaC code and pushes out the spot price\n']"
58,944,943,CC BY-SA 3.0,2017-04-18T15:52:51.677,"<p>Well that's not exactly about chef, you're basically asking how to use <code>tar</code>.</p>

<p>The command to create an archive of a folder would be<br>
<code>tar -zcvf &lt;backup_thing&gt;.tgz &lt;path_to_backup&gt;</code></p>

<p>In the tar options:</p>

<ul>
<li><code>z</code> pass the resulting tar archive to gzip for compression</li>
<li><code>c</code> instruct tar to compress (create the archive)</li>
<li><code>v</code> tells tar to be verbose, so you know at which point it is working, it has a performance impact</li>
<li><code>f &lt;path&gt;</code> tells tar to output in a file or device</li>
</ul>

<p>A correct chef resource for this would be as follow:</p>

<pre><code>execute 'Backup #{dir_name}' do
  user 'user'
  command ""tar -zcvf #{dest}/#{dir_name}_bkp_#{timestmp}.tgz #{dir_name}""
  live_stream :true # to see the progress during chef run, remove it and v in tar option if you don't care of it.
end
</code></pre>

<p>Using an execute resource avoid spawning a bash process to run tar, it is not needed, the <code>shell_out</code> class used by <code>execute</code> under the hood handles it already.</p>

<p>Be warned this is not idempotent, each run of chef will redo this backup command, that's maybe not what you're after.<br>
For an update of jenkins (or something else) out of usual maintenance I would do a manual backup, check it is ok, and then run the upgrade (via chef eventually).</p>

<p>I'd recomend taking the tutorial at <a href=""https://learn.chef.io"" rel=""noreferrer"">https://learn.chef.io</a> and reading through the documentation at <a href=""https://docs.chef.io"" rel=""noreferrer"">https://docs.chef.io</a> </p>
",13,2017-04-18T15:52:51.677,"['execute \'Backup #{dir_name}\' do\n  user \'user\'\n  command ""tar -zcvf #{dest}/#{dir_name}_bkp_#{timestmp}.tgz #{dir_name}""\n  live_stream :true # to see the progress during chef run, remove it and v in tar option if you don\'t care of it.\nend\n']"
59,946,945,CC BY-SA 3.0,2017-04-18T20:00:43.057,"<p>This templated SLS file works splendidly:</p>

<pre><code>{% if 'components' in salt.pillar.items() %}

include:
{% for component in salt.pillar.get('components').keys() %}
  - {{ component }}
{% endfor %}

{% endif %}
</code></pre>

<p>However, it requires changing my pillar key structure. From the original question, you see the structure as:</p>

<pre><code>my-minion-id:
    ----------
    components:
        - a-dependency-name
</code></pre>

<p>Instead, it needs to be:</p>

<pre><code>my-minion-id:
    ----------
    components:
        ----------
        a-dependency-name:
            None
</code></pre>

<p>Note that <code>a-dependency-name</code> is now a dict, and has a single key/value, <code>None</code>. Thus the pillar SLS file needs to change from</p>

<pre><code>components:
  - a-dependency-name
</code></pre>

<p>to</p>

<pre><code>components:
  a-dependency-name: ~
</code></pre>

<p>While you can get away with not using no-value dictionaries (and thus get rid of the <code>.keys()</code> in the template) and use lists instead, if you do that, you can't merge the <code>components</code> from multiple different pillars; each pillar Salt applies will override the <code>components</code> key from the previous, and the last pillar read will win. If you want to merge pillars (we <em>are</em> talking about role-based assignment, here), this would appear to be the necessary construct.</p>

<p>With that, the output of <code>salt my-minion-id state.show_sls components</code> is then correct:</p>

<pre><code>$ salt my-minion-id state.show_sls components
my-minion-id:
    ----------
    a-dependency-name:
      ----------
      ...
</code></pre>

<p><code>pillar.items()</code> in Jinja templates turns out not to be <em>quite</em> equivalent to <code>salt.pillar.items()</code>; if you try using <code>pillar.ls()</code>, for example, you may see the following error:</p>

<pre><code>Rendering SLS 'base:components' failed: Jinja variable 'salt.pillar object' has no attribute 'ls'
</code></pre>

<p>Whether that means one should avoid the implicit <code>salt.</code> prefix shortcut Jinja provides, or instead use a construct like <code>{% if pillar['components'] is defined %}</code> (thanks, @brousch, for the advice), I can't say.</p>
",339,2017-04-19T15:31:54.843,"[""{% if 'components' in salt.pillar.items() %}\n\ninclude:\n{% for component in salt.pillar.get('components').keys() %}\n  - {{ component }}\n{% endfor %}\n\n{% endif %}\n"", 'my-minion-id:\n    ----------\n    components:\n        - a-dependency-name\n', 'my-minion-id:\n    ----------\n    components:\n        ----------\n        a-dependency-name:\n            None\n', 'components:\n  - a-dependency-name\n', 'components:\n  a-dependency-name: ~\n', '$ salt my-minion-id state.show_sls components\nmy-minion-id:\n    ----------\n    a-dependency-name:\n      ----------\n      ...\n', ""Rendering SLS 'base:components' failed: Jinja variable 'salt.pillar object' has no attribute 'ls'\n""]"
60,947,945,CC BY-SA 3.0,2017-04-18T20:07:54.007,"<p>You can also do it like:</p>

<pre><code>{% if pillar['components'] is defined %}
include:
{% for component in pillar['components'] %}
 - {{ component }}
{% endfor %}
{% endif %}

{% if pillar['components'] is defined %}
components:
  require:
{% for component in pillar['components'] %}
 - {{ component }}
{% endfor %}
{% endif %}
</code></pre>
",2404,2017-04-18T20:07:54.007,"[""{% if pillar['components'] is defined %}\ninclude:\n{% for component in pillar['components'] %}\n - {{ component }}\n{% endfor %}\n{% endif %}\n\n{% if pillar['components'] is defined %}\ncomponents:\n  require:\n{% for component in pillar['components'] %}\n - {{ component }}\n{% endfor %}\n{% endif %}\n""]"
61,974,629,CC BY-SA 3.0,2017-04-20T09:04:44.900,"<p>There are several options that can be used here. Maybe one of the easiest is to install each function as a real script in some directory that is added to the path.  Here is how to do this:</p>

<p>First, we choose a path name where to store all these functions, it can be a a directory in our project, where other utility scripts used in our Makefile live. We call it <em>nvm_install_dir</em></p>

<p>Then we write a <code>_nvm_trampoline</code> script which use the name it is called as to trigger the right function, and create as many file aliases to <code>_nvm_trampoline</code>  as there are functions in the script.  Note the leading underscore, hinting at the “private” character of the script.</p>

<p>This script can go along the lines of</p>

<pre><code>#!/bin/sh
. ""${NVM_DIR}/nvm.sh""

if [ ""${0##*/}"" = '_nvm_driver' ]; then
    : NOP
else
    eval ""${0##*/}"" ""$@""
fi
</code></pre>

<p>Here we use <code>${0##*/}</code> to remove any path element from the name under which our script is called.  We install that script under <code>${nvm_install_dir}</code> and run once the following utility script:</p>

<pre><code>nvm_install_dir='SET-TO-ACTUAL-PARAMETER-VALUE!'
nvm_file=""${NVM_DIR}/nvm.sh""
nvm_trampoline='_nvm_trampoline'

nvm_list_functions()
{
    awk -F'[(][)]' '$1 ~ /^nvm_[^ ]*$/{print($1)}' ""${nvm_file}""
}

nvm_install()
{
    nvm_list_functions | {
        while read nvm_function; do
            ln\
                ""${nvm_install_dir}/${nvm_driver}""\
                ""${nvm_install_dir}/${nvm_function}""
            chmod 755 ""${nvm_install_dir}/${nvm_function}""
        done
    }
}

nvm_install
</code></pre>

<p>It is a good practice to pack the <em>nvm_install</em> procedure in a real function instead of just inlining its body in the script, as it gives better testing options. (It is easier to comment out the call to <em>nvm_install</em> than the body of the function, if we want to experiment with the script.)</p>

<p>Ater this, the directory pointed to by <em>nvm_install_dir</em> is populated with aliases to <code>_nvm_trampoline</code> that are executable and delegate their work to the corresponding function. We only need to add this directory to our <em>PATH</em> when running <em>make</em>.</p>

<p>A second approach would be to generate pseudo commands for each <em>nvm</em> functions, with the following script:</p>

<pre><code>nvm_file=""${NVM_DIR}/nvm.sh""

nvm_list_functions()
{
    awk -F'[(][)]' '$1 ~ /^nvm_[^ ]*$/{print($1)}' ""${nvm_file}""
}

nvm_generate()
{
    nvm_list_functions |  {
        while read nvm_function; do
            nvm_FUNCTION=$(printf '%s' ""${nvm_function}"" | tr '[a-z]' '[A-Z]')
            printf '%s=sh -c \047source ""${NVM_DIR}/nvm.sh""; %s ""$$@""\047 %s\n'\
                   ""${nvm_FUNCTION}""\
                   ""${nvm_function}""\
                   ""${nvm_function}""
        done
    }
}

nvm_generate
</code></pre>

<p>The output of this program consists of <em>make</em> variable assignments</p>

<pre><code>NVM_ECHO=sh -c 'source ""${NVM_DIR}/nvm.sh""; nvm_echo ""$$@""' nvm_echo
NVM_CD=sh -c 'source ""${NVM_DIR}/nvm.sh""; nvm_cd ""$$@""' nvm_cd
…
NVM_COMMAND_INFO=sh -c 'source ""${NVM_DIR}/nvm.sh""; nvm_command_info ""$$@""' nvm_command_info
…
</code></pre>

<p>It can be saved to a file <code>Makefile.nvm</code> or <code>nvmtools.mk</code> that can be included our Makefiles. Calling the function <code>nvm_command_info</code> is done with</p>

<pre><code>${NVM_COMMAND_INFO} arg1 arg2 …
</code></pre>

<p><hr>
Using a customised bash profile is possible, using the assignment <code>SHELL=/bin/bash --rcfile PATH-TO-CUSTOM-PROFILE -i</code> but I would consider this esoteric enough to puzzle the maintenance programmer.</p>
",271,2017-04-20T09:04:44.900,"['#!/bin/sh\n. ""${NVM_DIR}/nvm.sh""\n\nif [ ""${0##*/}"" = \'_nvm_driver\' ]; then\n    : NOP\nelse\n    eval ""${0##*/}"" ""$@""\nfi\n', 'nvm_install_dir=\'SET-TO-ACTUAL-PARAMETER-VALUE!\'\nnvm_file=""${NVM_DIR}/nvm.sh""\nnvm_trampoline=\'_nvm_trampoline\'\n\nnvm_list_functions()\n{\n    awk -F\'[(][)]\' \'$1 ~ /^nvm_[^ ]*$/{print($1)}\' ""${nvm_file}""\n}\n\nnvm_install()\n{\n    nvm_list_functions | {\n        while read nvm_function; do\n            ln\\\n                ""${nvm_install_dir}/${nvm_driver}""\\\n                ""${nvm_install_dir}/${nvm_function}""\n            chmod 755 ""${nvm_install_dir}/${nvm_function}""\n        done\n    }\n}\n\nnvm_install\n', 'nvm_file=""${NVM_DIR}/nvm.sh""\n\nnvm_list_functions()\n{\n    awk -F\'[(][)]\' \'$1 ~ /^nvm_[^ ]*$/{print($1)}\' ""${nvm_file}""\n}\n\nnvm_generate()\n{\n    nvm_list_functions |  {\n        while read nvm_function; do\n            nvm_FUNCTION=$(printf \'%s\' ""${nvm_function}"" | tr \'[a-z]\' \'[A-Z]\')\n            printf \'%s=sh -c \\047source ""${NVM_DIR}/nvm.sh""; %s ""$$@""\\047 %s\\n\'\\\n                   ""${nvm_FUNCTION}""\\\n                   ""${nvm_function}""\\\n                   ""${nvm_function}""\n        done\n    }\n}\n\nnvm_generate\n', 'NVM_ECHO=sh -c \'source ""${NVM_DIR}/nvm.sh""; nvm_echo ""$$@""\' nvm_echo\nNVM_CD=sh -c \'source ""${NVM_DIR}/nvm.sh""; nvm_cd ""$$@""\' nvm_cd\n…\nNVM_COMMAND_INFO=sh -c \'source ""${NVM_DIR}/nvm.sh""; nvm_command_info ""$$@""\' nvm_command_info\n…\n', '${NVM_COMMAND_INFO} arg1 arg2 …\n']"
62,982,981,CC BY-SA 3.0,2017-04-21T01:19:33.067,"<p>The easiest method is to have Eclipse generate an Ant build script for you.</p>

<p>Right click on your project in the Package Explorer and select <strong>Export</strong> in the context menu. Choose the export type <strong>General -> Ant Buildfiles</strong> and click <strong>Next</strong>.</p>

<p><img src=""https://i.stack.imgur.com/ssp3D.png"" alt=""Export menu screenshot""></p>

<p>On the next screen, make sure your project is selected. You can keep leave the options on their default settings. Click <strong>Finish</strong> to generate your <code>build.xml</code> file.</p>

<p><img src=""https://i.stack.imgur.com/W0WDU.png"" alt=""Generate antfile dialog screenshot""></p>

<p>Lastly, to ensure Travis CI runs the project correctly, <a href=""https://docs.travis-ci.com/user/languages/java/"" rel=""noreferrer"">create a .travis.yml in your project's root folder</a>. For Java projects, it should contain at least the following.</p>

<pre><code>language: java
jdk:
  - oraclejdk8

script: ant build
</code></pre>

<p>Source: <a href=""http://kofun.pl/various/using-trvis-ci-with-java-eclipse-project/"" rel=""noreferrer"">Kofun devblog - Using Travis CI with Java Eclipse Project</a></p>
",2449,2017-05-11T01:00:12.257,['language: java\njdk:\n  - oraclejdk8\n\nscript: ant build\n']
63,990,989,CC BY-SA 3.0,2017-04-22T07:23:16.073,"<p>How about something like this:</p>

<pre><code>hosts: all

vars:
  user_servers:
    user1:
      - testing1

  users:
    -name: user1
    -groups: '{{ user_groups }}'
    -state: present

roles:
  - name: Add filtered users
    tasks:
      - name: Filter users 
        debug: User {{ item }}
        with_items: ""{{ users | default([]) }}""
        when: {{ inventory_hostname_short }} in user_servers[item]
        register: filtered_users  

      - name: Add filtered users
        include_role: wilshersystems.users
        with_items:
        - {{ filtered_users }}
        loop_control:
        - loop_var: users
</code></pre>
",228,2017-04-22T07:23:16.073,"['hosts: all\n\nvars:\n  user_servers:\n    user1:\n      - testing1\n\n  users:\n    -name: user1\n    -groups: \'{{ user_groups }}\'\n    -state: present\n\nroles:\n  - name: Add filtered users\n    tasks:\n      - name: Filter users \n        debug: User {{ item }}\n        with_items: ""{{ users | default([]) }}""\n        when: {{ inventory_hostname_short }} in user_servers[item]\n        register: filtered_users  \n\n      - name: Add filtered users\n        include_role: wilshersystems.users\n        with_items:\n        - {{ filtered_users }}\n        loop_control:\n        - loop_var: users\n']"
64,995,994,CC BY-SA 3.0,2017-04-23T17:56:21.803,"<p>I have decided to remove the <code>ansible/group_vars/testing</code> directory and replace it with a file, i.e. <code>ansible/group_vars/testing</code> that contains the encrypted vars:</p>

<pre><code>mysecret: !vault |
          $ANSIBLE_VAULT;1.1;AES256
          66386439653236336462626566653063336164663966303231363934653561363964363833313662
          6431626536303530376336343832656537303632313433360a626438346336353331386135323734
          62656361653630373231613662633962316233633936396165386439616533353965373339616234
          3430613539666330390a313736323265656432366236633330313963326365653937323833366536
          34623731376664623134383463316265643436343438623266623965636363326136
</code></pre>

<p>Instead of running <code>ansible-vault edit ansible/group_vars/testing/vault</code> one could pipe the values that need to be encrypted to ansible-vault, i.e. <code>printf mysecret | ansible-vault encrypt</code>. The latter will encrypt <code>mysecret</code> and the output could be added to the <code>ansible/group_vars/testing</code> file. When <code>ansible-playbook</code> will be run the encrypted variables will be decrypted if the ansible vault file is specified of course.</p>

<p>If the encrypted value needs to be debugged then the following code could be used:</p>

<pre><code>- debug: msg=""Decrypted value: {{ encrypted_var }}""
</code></pre>
",210,2017-04-24T08:43:09.153,"['mysecret: !vault |\n          $ANSIBLE_VAULT;1.1;AES256\n          66386439653236336462626566653063336164663966303231363934653561363964363833313662\n          6431626536303530376336343832656537303632313433360a626438346336353331386135323734\n          62656361653630373231613662633962316233633936396165386439616533353965373339616234\n          3430613539666330390a313736323265656432366236633330313963326365653937323833366536\n          34623731376664623134383463316265643436343438623266623965636363326136\n', '- debug: msg=""Decrypted value: {{ encrypted_var }}""\n']"
65,1012,1010,CC BY-SA 3.0,2017-04-25T07:27:14.943,"<p>In Ansible: you can use <code>assert</code> or <code>fail</code> module. </p>

<pre><code>- name: ""Make sure web_sites is dictionary""
  fail: msg=""web_sites should be dictionary""
  when: web_sites is not dict  


- name: ""cluster_name should be shorter than 6 chars""
  assert: 
       that: cluster_name|len &lt;= 6
</code></pre>

<p>In Puppet: there is <a href=""https://docs.puppet.com/puppet/latest/function.html#fail"" rel=""nofollow noreferrer"">fail</a> function evaluated during parsing phase which cause parsing failure on server (see <a href=""https://stackoverflow.com/questions/7570957/is-it-possible-to-assert-in-puppet"">question on StackOverflow</a>) </p>

<pre><code> if length($cluster_name) &gt; 6 {
      fail(""Cluster name is too long. Should be less than 6 chars."")
 }
</code></pre>
",2479,2017-04-25T07:27:14.943,"['- name: ""Make sure web_sites is dictionary""\n  fail: msg=""web_sites should be dictionary""\n  when: web_sites is not dict  \n\n\n- name: ""cluster_name should be shorter than 6 chars""\n  assert: \n       that: cluster_name|len <= 6\n', ' if length($cluster_name) > 6 {\n      fail(""Cluster name is too long. Should be less than 6 chars."")\n }\n']"
66,1037,1014,CC BY-SA 3.0,2017-04-25T23:59:21.530,"<p>This might work.  I used an example X of two hours prior.</p>

<pre><code>lastBuild = currentBuild.getPreviousBuild()

if Date(lastBuild.timestamp) &lt; new Date().minusHours(2) {
  &lt;do your thing here&gt;
}
</code></pre>

<p>You may have to whitelist <code>Date()</code>.</p>

<p>Cobbled together from <a href=""https://support.cloudbees.com/hc/en-us/articles/217591038-How-to-Iterate-Through-the-Last-Successful-Builds-in-Pipeline-Job"" rel=""nofollow noreferrer"">this Cloudbees answer</a>.</p>
",2520,2017-04-26T01:01:30.627,['lastBuild = currentBuild.getPreviousBuild()\n\nif Date(lastBuild.timestamp) < new Date().minusHours(2) {\n  <do your thing here>\n}\n']
67,1050,1048,CC BY-SA 3.0,2017-04-27T19:53:09.713,"<p>what about something like that:</p>

<pre><code>%w{
        mysql-community-common-5.7.16-1.el7.x86_64.rpm
        mysql-community-libs-5.7.16-1.el7.x86_64.rpm
        mysql-community-client-5.7.16-1.el7.x86_64.rpm
        mysql-community-server-5.7.16-1.el7.x86_64.rpm
}.each do |pkg|
        remote_file ""/tmp/#{pkg}"" do
          source ""https://s3.amazonaws.com/tmp/mysql/#{pkg}""
        end

       rpm_package pkg do
        source ""/tmp/#{pkg}""
        action :install
      end
end
</code></pre>

<p>another way:</p>

<pre><code>urllist = {
  { 'url': 'http://some.url1/', 'path': '/some/path1/', 'filename': 'some.file' },
  { 'url': 'https://some.url2/', 'path': '/some/path2/', 'filename': 'another.file'}
}

urllist.each do |urlinfo|
  remote_file ""#{urlinfo['path']}/#{urlinfo['filename']}"" do
    source ""#{urlinfo['url']}/#{urlinfo['filename']}""
    owner 'someowner'
    group 'somegroup'
    mode 0755
  end
end
</code></pre>
",342,2017-04-27T21:04:02.517,"['%w{\n        mysql-community-common-5.7.16-1.el7.x86_64.rpm\n        mysql-community-libs-5.7.16-1.el7.x86_64.rpm\n        mysql-community-client-5.7.16-1.el7.x86_64.rpm\n        mysql-community-server-5.7.16-1.el7.x86_64.rpm\n}.each do |pkg|\n        remote_file ""/tmp/#{pkg}"" do\n          source ""https://s3.amazonaws.com/tmp/mysql/#{pkg}""\n        end\n\n       rpm_package pkg do\n        source ""/tmp/#{pkg}""\n        action :install\n      end\nend\n', 'urllist = {\n  { \'url\': \'http://some.url1/\', \'path\': \'/some/path1/\', \'filename\': \'some.file\' },\n  { \'url\': \'https://some.url2/\', \'path\': \'/some/path2/\', \'filename\': \'another.file\'}\n}\n\nurllist.each do |urlinfo|\n  remote_file ""#{urlinfo[\'path\']}/#{urlinfo[\'filename\']}"" do\n    source ""#{urlinfo[\'url\']}/#{urlinfo[\'filename\']}""\n    owner \'someowner\'\n    group \'somegroup\'\n    mode 0755\n  end\nend\n']"
68,1051,1048,CC BY-SA 3.0,2017-04-27T20:22:27.010,"<p>What I do for this case is using node attributes hash for a key value mapping as follow :</p>

<p>In <code>attributes/default.rb</code></p>

<pre><code>default['namespace']['files']['file1']='http://server1/path/source_fileX'
default['namespace']['files']['file2']='http://server2/path/source_fileY'
</code></pre>

<p>Or with hash notation :</p>

<pre><code>default['namespace']['files']={'file1' =&gt; 'http://server1/path/source_fileX',
'file2'=&gt;'http://server2/path/source_fileY'}
</code></pre>

<p>Then in recipe:</p>

<pre><code>node['namespace']['files'].each do |filename,src|
  remote_file ""/path/destinaton/#{filename}"" do
    source src
    mode '0644'
    action :create
  end
end
</code></pre>

<p>This way you can map a file with its source taking advantage that node attributes are a hash structure. </p>

<p>If course you can set the full path instead of just the file name and avoid the string interpolation in the recipe remote_file.</p>

<p>(Typed on phone, please forgive typos)</p>
",13,2017-04-27T20:22:27.010,"[""default['namespace']['files']['file1']='http://server1/path/source_fileX'\ndefault['namespace']['files']['file2']='http://server2/path/source_fileY'\n"", ""default['namespace']['files']={'file1' => 'http://server1/path/source_fileX',\n'file2'=>'http://server2/path/source_fileY'}\n"", 'node[\'namespace\'][\'files\'].each do |filename,src|\n  remote_file ""/path/destinaton/#{filename}"" do\n    source src\n    mode \'0644\'\n    action :create\n  end\nend\n']"
69,1074,650,CC BY-SA 3.0,2017-04-29T03:07:59.373,"<p>Yes, definitely. I do this all the time. You can specify configuration options for your pipeline and one of them is <code>skipDefaultCheckout</code>, which causes pipeline to skip the default ""Declarative: Checkout SCM"" stage.</p>

<p>The <code>skipDefaultCheckout</code> option is documented in <a href=""https://jenkins.io/doc/book/pipeline/syntax/"" rel=""noreferrer"">Pipeline Syntax</a> and here's an example Jenkinsfile showing how to use it:</p>

<pre><code>pipeline {
  agent { label 'docker' }
  options {
    skipDefaultCheckout true
  }
  stages {
    stage('commit_stage') {
      steps {
        echo 'sweet stuff here'
      }
    }
  }
}
</code></pre>
",2450,2017-04-29T19:15:23.757,"[""pipeline {\n  agent { label 'docker' }\n  options {\n    skipDefaultCheckout true\n  }\n  stages {\n    stage('commit_stage') {\n      steps {\n        echo 'sweet stuff here'\n      }\n    }\n  }\n}\n""]"
70,1081,1014,CC BY-SA 3.0,2017-05-01T13:08:20.840,"<p>Took a while and it's a little on the hacky side since I'm no Groovy expert, but I got it working with this;</p>

<pre><code>long now = System.currentTimeMillis()

node('jenkins2_dedicated_slave'){

    stage ('check time') {

        sh '''lastBuild=$(mktemp)

        curl -u [jenkins username]:[API key for user] ""http://[jenkins URL]/[job name]/lastSuccessfulBuild/api/json"" &gt; $lastBuild

        jq -j '.timestamp' &lt; $lastBuild &gt; time.txt'''

    }

    archiveArtifacts artifacts: 'time.txt'
    long lastBuild = readFile('time.txt') as Long
    int finalNum = (now - lastBuild) / (1000*60*60)

    if( finalNum &lt; 8 ) {
        currentBuild.result = 'SUCCESS'
        echo finalNum + "" hours since the last build. Downstream job not run.""
        return
    }

    stage ('downstream') {

        //run downstream job

    }
}
</code></pre>

<p>Basically this will </p>

<ol>
<li><p>Run a curl command on the Jenkins REST API to get the info on the last successful build and store it in a temp file</p></li>
<li><p>Use <a href=""https://stedolan.github.io/jq/"" rel=""nofollow noreferrer"">jq</a> to parse said info and extract the timestamp field, which is in Epoch time. This is stored to a file.</p></li>
<li><p>The file is archived to the job and then read into a variable. This timestamp is compared to the current time, (gotten at the top of the job), and if the break between them is less than eight hours the job is ""failed"" out with a success and error message.</p></li>
<li><p>If the time is over eight hours, the job continues on to build the downstream job.</p></li>
</ol>
",736,2017-05-01T13:13:25.533,"['long now = System.currentTimeMillis()\n\nnode(\'jenkins2_dedicated_slave\'){\n\n    stage (\'check time\') {\n\n        sh \'\'\'lastBuild=$(mktemp)\n\n        curl -u [jenkins username]:[API key for user] ""http://[jenkins URL]/[job name]/lastSuccessfulBuild/api/json"" > $lastBuild\n\n        jq -j \'.timestamp\' < $lastBuild > time.txt\'\'\'\n\n    }\n\n    archiveArtifacts artifacts: \'time.txt\'\n    long lastBuild = readFile(\'time.txt\') as Long\n    int finalNum = (now - lastBuild) / (1000*60*60)\n\n    if( finalNum < 8 ) {\n        currentBuild.result = \'SUCCESS\'\n        echo finalNum + "" hours since the last build. Downstream job not run.""\n        return\n    }\n\n    stage (\'downstream\') {\n\n        //run downstream job\n\n    }\n}\n']"
71,1093,1082,CC BY-SA 3.0,2017-05-04T11:23:29.873,"<p>Instead of using a symlink that will be stored as is in BitBucket one could use:</p>

<pre><code>- name: Copy docker-compose.yml
  copy:
    src: ../../../../docker-compose.yml
    dest: /path/to/docker-compose.yml
</code></pre>
",210,2017-05-04T11:23:29.873,['- name: Copy docker-compose.yml\n  copy:\n    src: ../../../../docker-compose.yml\n    dest: /path/to/docker-compose.yml\n']
72,1096,1014,CC BY-SA 3.0,2017-05-04T15:54:54.033,"<p>To synthesize Alex and Steve Johnson's answers, you could put this at the top of your downstream job:</p>

<pre><code>lastBuild = currentBuild.getPreviousBuild()
delay = 2

if Date(lastBuild.timestamp) &gt;= new Date().minusHours(delay) {
    currentBuild.result = 'SUCCESS'
    echo ""Less than ${delay} hours since the last build. Job will not run.""
    return
}
</code></pre>
",362,2017-05-04T15:54:54.033,"['lastBuild = currentBuild.getPreviousBuild()\ndelay = 2\n\nif Date(lastBuild.timestamp) >= new Date().minusHours(delay) {\n    currentBuild.result = \'SUCCESS\'\n    echo ""Less than ${delay} hours since the last build. Job will not run.""\n    return\n}\n']"
73,1104,1102,CC BY-SA 3.0,2017-05-04T19:20:01.353,"<p>You could try to run the artifactory file upload in parallel if you are using the Jenkinsfile syntax: <a href=""https://github.com/jenkinsci/pipeline-examples/blob/master/pipeline-examples/parallel-from-list/parallelFromList.groovy"" rel=""noreferrer"">https://github.com/jenkinsci/pipeline-examples/blob/master/pipeline-examples/parallel-from-list/parallelFromList.groovy</a></p>

<p>Here is a simpler example to run things in parallel if you only have a fixed number of things you want to do in parallel:</p>

<pre><code>parallel (
    ""task1"" : {
        //runTask1
    },
    ""task2"" : {
        //runTask2
    },
    ""task3"" : {
        //runTask3
    },
)
</code></pre>

<p>This can be enclosed inside a <code>node</code>, in which case they would all share the same workspace or each command can define <code>node</code> inside the task code to run into another node in which case it would have a different workspace for each task.</p>
",62,2017-05-08T16:22:10.220,"['parallel (\n    ""task1"" : {\n        //runTask1\n    },\n    ""task2"" : {\n        //runTask2\n    },\n    ""task3"" : {\n        //runTask3\n    },\n)\n']"
74,1107,1106,CC BY-SA 3.0,2017-05-05T01:22:41.987,"<p>I think Ansible serial works only for the entire play, have you tried to use roles ?</p>

<p>For example:</p>

<pre><code>- hosts:
    - web
    - db
  serial: 1
  roles:
    - { role: nginx, when: ansible_os_family == 'Debian' }
    - role2
    - role3
</code></pre>
",342,2017-05-05T01:22:41.987,"[""- hosts:\n    - web\n    - db\n  serial: 1\n  roles:\n    - { role: nginx, when: ansible_os_family == 'Debian' }\n    - role2\n    - role3\n""]"
75,1111,1110,CC BY-SA 3.0,2017-05-05T09:48:21.497,"<p>It feels dirty, but I guess something like that would work:</p>

<pre><code>- name: ec21
  [...]
  register: ec21_result

- set_fact: end_result= ""{{ ec21_result }}""
  when: ec21_result|succeeded

- name: ec22
  [...]
  register: ec22_result
  when: ec21_result|failed

- set_fact: end_result= ""{{ ec22_result }}""
  when: ec22_result|succeeded

- name: ec23
  [...]
  register: ec23_result
  when: ec22_result|failed

- set_fact: end_result= ""{{ ec23_result }}""
  when: ec23_result|succeeded

- name: Add new instance to host group
  add_host:
    hostname: ""{{ item.private_ip }}""
    groupname: launched
  with_items: ""{{ end_result.instances }}""
</code></pre>

<p>Basically setting the <code>end_result</code> as soon as you succeed a play.</p>
",2652,2017-05-05T09:48:21.497,"['- name: ec21\n  [...]\n  register: ec21_result\n\n- set_fact: end_result= ""{{ ec21_result }}""\n  when: ec21_result|succeeded\n\n- name: ec22\n  [...]\n  register: ec22_result\n  when: ec21_result|failed\n\n- set_fact: end_result= ""{{ ec22_result }}""\n  when: ec22_result|succeeded\n\n- name: ec23\n  [...]\n  register: ec23_result\n  when: ec22_result|failed\n\n- set_fact: end_result= ""{{ ec23_result }}""\n  when: ec23_result|succeeded\n\n- name: Add new instance to host group\n  add_host:\n    hostname: ""{{ item.private_ip }}""\n    groupname: launched\n  with_items: ""{{ end_result.instances }}""\n']"
76,1122,1121,CC BY-SA 3.0,2017-05-09T03:11:18.963,"<p>In Groovy you have to use double quotes to get string interpolation:</p>

<pre><code>    if ( ""$output"" != null ) {
        slackSend (channel: ""@${name}"", color: '#36A64F', message: ""Job succeeded"")
    } else {
        slackSend (channel: ""@${name}"", color: '#36A64F', message: ""Job failed"")
    }
</code></pre>

<p>You can also probably do something like this to avoid it entirely and have less duplication:</p>

<pre><code>name = '@' + readFile('name.txt')

slackSend (channel: name //etc.
</code></pre>
",62,2017-05-09T03:11:18.963,"['    if ( ""$output"" != null ) {\n        slackSend (channel: ""@${name}"", color: \'#36A64F\', message: ""Job succeeded"")\n    } else {\n        slackSend (channel: ""@${name}"", color: \'#36A64F\', message: ""Job failed"")\n    }\n', ""name = '@' + readFile('name.txt')\n\nslackSend (channel: name //etc.\n""]"
77,1135,1134,CC BY-SA 3.0,2017-05-10T02:37:09.327,"<p>A data bag is stored on the chef server itself. My chef days are behind me, but you should be able to enter the data bag content either at the create step or the edit one.</p>

<p>For the step 2, just execute the command that you copied:</p>

<pre><code>knife data bag create passwords mysql --secret-file /tmp/my_data_bag_key
</code></pre>
",62,2017-05-10T02:37:09.327,['knife data bag create passwords mysql --secret-file /tmp/my_data_bag_key\n']
78,1137,1126,CC BY-SA 3.0,2017-05-10T09:26:04.027,"<p>You have to pass only the repository not the full HTTP URL of the repository when you want to delete it from what I've read in the documentation. So the command should be:</p>

<pre><code>ansible-galaxy delete 030 ansible-firewall
</code></pre>
",2704,2017-05-10T09:26:04.027,['ansible-galaxy delete 030 ansible-firewall\n']
79,1143,1139,CC BY-SA 3.0,2017-05-11T08:44:43.793,"<p>This sequence of commands works for me:</p>

<pre><code>apt-get update
DEBIAN_FRONTEND=noninteractive apt-get upgrade -yq
</code></pre>

<p>So, <code>DEBIAN_FRONTEND=noninteractive</code> is correct but you also need the <code>-q</code> flag.</p>

<p>Source: <a href=""https://github.com/moby/moby/issues/4032"" rel=""noreferrer"">https://github.com/moby/moby/issues/4032</a></p>
",2708,2017-05-18T12:13:40.017,['apt-get update\nDEBIAN_FRONTEND=noninteractive apt-get upgrade -yq\n']
80,1144,1139,CC BY-SA 4.0,2017-05-11T09:27:49.267,"<p>Your problem is that grub file change adhere to <code>ucf</code> and not debconf, as per this <a href=""https://bugs.launchpad.net/ubuntu/+source/apt/+bug/1323772"" rel=""nofollow noreferrer"">incident on apt list</a> you're not alone.</p>

<p>As workaround I found <a href=""https://askubuntu.com/a/262445/398662"">this answer</a> on askunbuntu. Removing the <code>menu.lst</code> from the UCF configuration system should be enough, for your case:</p>

<pre><code>""provisioners"": [
  {
    ""type"": ""shell"",
    ""inline"": [
      ""sudo ucf --purge /boot/grub/menu.lst"",
      ""sudo apt-get update"",
      ""sudo UCF_FORCE_CONFFNEW=YES apt-get upgrade -y""
    ]
  }
]
</code></pre>

<p>This should avoid the grub question. Be warned that any other package using ucf  will also use the maintainer package version, for a creation from a base ami this should not be a problem, but it worth being noted.</p>
",13,2020-02-05T15:35:03.587,"['""provisioners"": [\n  {\n    ""type"": ""shell"",\n    ""inline"": [\n      ""sudo ucf --purge /boot/grub/menu.lst"",\n      ""sudo apt-get update"",\n      ""sudo UCF_FORCE_CONFFNEW=YES apt-get upgrade -y""\n    ]\n  }\n]\n']"
81,1157,1156,CC BY-SA 3.0,2017-05-12T20:51:29.143,"<p>Given how much time I spent weeks ago struggling with a closely-related issue, I wish I'd figured this out sooner.</p>

<p>The solution appears to be to use <a href=""https://docs.saltstack.com/en/latest/ref/modules/all/salt.modules.cp.html#salt.modules.cp.get_template"" rel=""noreferrer""><code>salt.modules.cp.get_template</code></a> to have the Salt minion retrieve the file, render it through the templating engine and place it in a readable place:</p>

<pre><code># salt my-minion-id cp.get_template salt://network/init.sls /root/network.sls template=jinja
my-minion-id:
    /root/network.sls
</code></pre>

<p>From there, you connect to the <code>my-minion-id</code> host and examine the file you placed at <code>/root/network.sls</code>.</p>

<p>This makes sense; <code>salt.renderers.jinja</code> is in the <code>salt.renderers</code> namespace, while the modules you have access to from the CLI are in the <code>salt.modules</code> namespace.</p>

<p>It also makes sense from a data visibility standpoint; template rendering happens on the <em>minion</em>, where grains and such are available, and I've yet to see a module that executes minion code return arbitrary output to the master (for view on the CLI, for example); the returned data is invariably well-structured and concise. (There may be such a module, but I don't know what it is. It would be a preferable solution to dropping test files onto a minion.)</p>

<p><strong>edit:</strong> @gtmanfred's answer is far better and more direct, and I've accepted that one. I'm leaving this one here for informative purposes. It's not the best solution, but it does still work.</p>
",339,2017-05-24T11:59:57.053,['# salt my-minion-id cp.get_template salt://network/init.sls /root/network.sls template=jinja\nmy-minion-id:\n    /root/network.sls\n']
82,1171,1169,CC BY-SA 3.0,2017-05-16T11:47:35.343,"<p>According to <a href=""http://docs.aws.amazon.com/cli/latest/reference/ec2/describe-volumes.html"" rel=""nofollow noreferrer"">this document</a> you can run command like:</p>

<pre><code>aws ec2 describe-volumes --region us-east-1
</code></pre>

<p>(feel free to set region you use)
and search for field in json output, named ""encrypted""</p>
",57,2017-05-16T11:47:35.343,['aws ec2 describe-volumes --region us-east-1\n']
83,1172,1169,CC BY-SA 3.0,2017-05-16T11:56:21.950,"<p>To get the number of non encrypted volumes you can run this command:</p>

<pre><code>aws ec2 describe-volumes --region &lt;your_region&gt; --filter ""Name=encrypted,Values=false"" --query ""length(Volumes[])""
</code></pre>

<p><code>length</code> will return the length of the array <code>Volumes</code> flattened by the selection operator <code>[]</code> (more details on <a href=""http://jmespath.readthedocs.io/en/latest/specification.html"" rel=""nofollow noreferrer"">JMESPath documentation</a>).<br>
As we filter the slection for non encrypted volumes (<code>--filter ""Name=encrypted,Values=false""</code>) this should allow to demonstrate to the auditor the number is 0 not encrypted volumes.</p>

<p>Same filter can be applied in the console, in the ec2 page, under 'Elastic Block Store' => 'Volumes', type <code>Encrypted : Not Encrypted</code> to filter the view to non encrypted volumes only. you may add <code>Attachment Status : Attached</code> to list only attached volumes.</p>
",13,2017-05-16T11:56:21.950,"['aws ec2 describe-volumes --region <your_region> --filter ""Name=encrypted,Values=false"" --query ""length(Volumes[])""\n']"
84,1174,1139,CC BY-SA 3.0,2017-05-16T15:34:40.867,"<p>I didn't notice any difference using -y or -q. Maybe because the question is about using ""packer"" ?  (I use bare scripts)</p>

<p>Anyway, in my case, I got rid of the dialogs for <code>apt upgrade</code> using the following sed commands around it :</p>

<pre><code>sed -i ""s/#\ conf_force_conffold=YES/conf_force_conffold=YES/g"" /etc/ucf.conf
apt-get -y upgrade
sed -i ""s/conf_force_conffold=YES/#conf_force_conffold=YES/g"" /etc/ucf.conf
</code></pre>

<p>My change is limited to the time of the upgrade.
<br>Technically, it disables the questions about keeping or not an existing configuration when upgrading grub, but only for the time of the upgrade, to avoid side effects.</p>

<p>OS : Ubuntu 16.04 LTS</p>

<p><em>Hope this helps</em></p>
",2787,2017-05-16T15:34:40.867,"['sed -i ""s/#\\ conf_force_conffold=YES/conf_force_conffold=YES/g"" /etc/ucf.conf\napt-get -y upgrade\nsed -i ""s/conf_force_conffold=YES/#conf_force_conffold=YES/g"" /etc/ucf.conf\n']"
85,1177,1176,CC BY-SA 4.0,2017-05-16T16:17:20.517,"<p>If your Zabbix agent is 2.2 or later, you could use <a href=""https://www.zabbix.com/documentation/3.0/manual/config/items/itemtypes/zabbix_agent"" rel=""nofollow noreferrer"">Zabbix agent item</a> <code>vfs.file.regexp</code> like so:</p>

<pre><code>vfs.file.regexp[/proc/meminfo,^Dirty.*([0-9]+),,,,\1]
</code></pre>

<p>If your Zabbix is 3.4 or later, you can use a <a href=""https://www.zabbix.com/documentation/4.0/manual/config/items/itemtypes/dependent_items"" rel=""nofollow noreferrer"">master item</a> to collect the data blob (perhaps with <code>vfs.file.contents</code>) and then extract and parse the desired values with <a href=""https://www.zabbix.com/documentation/3.4/manual/config/items/item#item_value_preprocessing"" rel=""nofollow noreferrer"">item value preprocessing</a>.</p>
",2789,2018-12-19T11:46:14.013,"['vfs.file.regexp[/proc/meminfo,^Dirty.*([0-9]+),,,,\\1]\n']"
86,1200,1186,CC BY-SA 3.0,2017-05-18T19:38:35.847,"<p>I'm not sure if you can do this without a loop. But you should be able to run the below in bash and get the right output:</p>

<pre><code>instances=`aws ec2 describe-instances --region us-east-1 --filters Name=instance-state-name,Values=running --query ""Reservations[*].Instances[0].InstanceId"" --output text`

for instance in $instances; 
do  
   aws ec2 describe-volumes --region us-east-1 --filters Name=encrypted,Values=true Name=attachment.status,Values=attached Name=attachment.instance-id,Values=$instance --query ""Volumes[]""; 
done
</code></pre>

<p>This will return all information on the volumes. For the ID you can change the <code>describe-volumes</code> line to:</p>

<pre><code>aws ec2 describe-volumes --filters Name=encrypted,Values=false Name=attachment.status,Values=attached Name=attachment.instance-id,Values=$instance --query ""Volumes[].Attachments[].VolumeId""
</code></pre>
",2830,2017-05-18T19:38:35.847,"['instances=`aws ec2 describe-instances --region us-east-1 --filters Name=instance-state-name,Values=running --query ""Reservations[*].Instances[0].InstanceId"" --output text`\n\nfor instance in $instances; \ndo  \n   aws ec2 describe-volumes --region us-east-1 --filters Name=encrypted,Values=true Name=attachment.status,Values=attached Name=attachment.instance-id,Values=$instance --query ""Volumes[]""; \ndone\n', 'aws ec2 describe-volumes --filters Name=encrypted,Values=false Name=attachment.status,Values=attached Name=attachment.instance-id,Values=$instance --query ""Volumes[].Attachments[].VolumeId""\n']"
87,1215,1195,CC BY-SA 3.0,2017-05-19T22:30:20.873,"<p>This is an area where Kubernetes has the correct model, there should be a load balancer between all systems which should have functional health checks.</p>

<p>Once you start to add Nagios, Zabbix or other types of monitoring to the system you start to build a large state machine.  This will break the loose coupling model and introduce inter-dependencies that inhibit the ease refactoring.  While not set in stone the key differentiation between microservices and other variants of SOA is this loose coupling.</p>

<p>If the services are fine-grained and perform a single function, implement a health check at an upstream load balancer, then monitor the active pool members.</p>

<p>As an example in HAproxy</p>

<pre><code>backend myapp
[...]
option tcp-check
tcp-check send GET\ /health HTTP/1.0\r\n
tcp-check send Host:\ foo\r\n
tcp-check send \r\n
tcp-check expect rstring ^HTTP/1.1\ 200\ Ok
tcp-check expect string container\ Good
server srv1 10.0.0.1:8080 check
server srv2 10.0.0.2:8080 check
</code></pre>

<p>In theory you don't care about the performance of an actual container, just that your overall performance is good.</p>

<p>This method makes it easy to have the system self repair and to scale with a minimal amount of complexity.</p>

<p>Basically you only have to check if the number of systems you expect are alive, and if not you spin up some more.  If you need to add capacity you simply change the number of expected nodes.</p>

<p>This also simplifies refactoring as you only need to replicate or modify this test with no external dependencies or state machine.</p>

<p>It should also reduce down time and middle of the night Pagerduty alerts as the system self repairs.</p>

<p>As for the overall systems metrics, which are needed to trace down issues like latency I would want them in a central location using a tool like elasticsearch.  If you use syslog, logstash or log4??? to collect metrics that will be far more useful in the long run.  When systems are small and simple traditional polling based monitoring may provide enough metrics but it is preferable to have them in a format that is searchable and more importantly relational to other systems.</p>

<p>Solutions like monit still have their place, but it is to monitor the long lived components like the VMs or bare metal hosting your swarm, but the containers themselves should be decoupled from that system to get the most benefits from a micro-services model.</p>
",2846,2017-05-19T22:30:20.873,['backend myapp\n[...]\noption tcp-check\ntcp-check send GET\\ /health HTTP/1.0\\r\\n\ntcp-check send Host:\\ foo\\r\\n\ntcp-check send \\r\\n\ntcp-check expect rstring ^HTTP/1.1\\ 200\\ Ok\ntcp-check expect string container\\ Good\nserver srv1 10.0.0.1:8080 check\nserver srv2 10.0.0.2:8080 check\n']
88,1223,1186,CC BY-SA 3.0,2017-05-22T11:47:20.967,"<p>Here is what I ended up using. Enjoy. </p>

<pre><code>for instance in $instances;
do
  count=`aws ec2 describe-volumes --filters Name=attachment.status,Values=attached Name=attachment.instance-id,Values=$instance --query ""Volumes[]""  | jq  -r '. | length';`
  name=`aws ec2 describe-tags --filters Name=resource-id,Values=$instance Name=key,Values=Name --query Tags[].Value | jq -r '.[0]'`
  if [ $count -gt 0 ]; then
    START=0
    END=$count
    for ((i=START; i&lt;END; i++))
    do
       #echo ""i: $i""
       encrypted=`aws ec2 describe-volumes --filters Name=attachment.status,Values=attached Name=attachment.instance-id,Values=$instance --query ""Volumes[]""  | jq  -r "".[$i].Encrypted"";`
       volumeid=`aws ec2 describe-volumes --filters Name=attachment.status,Values=attached Name=attachment.instance-id,Values=$instance --query ""Volumes[]""  | jq  -r "".[$i].VolumeId"";`
       echo ""$instance $name Volumes: $count VolumeId: $volumeid Encrypted: $encrypted ""
    done
  fi
done
</code></pre>
",465,2017-05-22T11:47:20.967,"['for instance in $instances;\ndo\n  count=`aws ec2 describe-volumes --filters Name=attachment.status,Values=attached Name=attachment.instance-id,Values=$instance --query ""Volumes[]""  | jq  -r \'. | length\';`\n  name=`aws ec2 describe-tags --filters Name=resource-id,Values=$instance Name=key,Values=Name --query Tags[].Value | jq -r \'.[0]\'`\n  if [ $count -gt 0 ]; then\n    START=0\n    END=$count\n    for ((i=START; i<END; i++))\n    do\n       #echo ""i: $i""\n       encrypted=`aws ec2 describe-volumes --filters Name=attachment.status,Values=attached Name=attachment.instance-id,Values=$instance --query ""Volumes[]""  | jq  -r "".[$i].Encrypted"";`\n       volumeid=`aws ec2 describe-volumes --filters Name=attachment.status,Values=attached Name=attachment.instance-id,Values=$instance --query ""Volumes[]""  | jq  -r "".[$i].VolumeId"";`\n       echo ""$instance $name Volumes: $count VolumeId: $volumeid Encrypted: $encrypted ""\n    done\n  fi\ndone\n']"
89,1229,1156,CC BY-SA 4.0,2017-05-23T22:34:18.897,"<p>Check out the <a href=""https://docs.saltstack.com/en/latest/ref/modules/all/salt.modules.slsutil.html"" rel=""noreferrer"">slsutil.renderer</a> module.</p>

<p>This should do what you want</p>

<pre><code>salt my-minion-id slsutil.renderer /srv/salt/network/init.sls 'jinja'
</code></pre>

<p>This module just calls the compile_template function directly for you.</p>

<p>Edit: /srv/salt/network/init.sls is the path on the minion, if you are not targeting the master as your minion, you will probably need to do the following.</p>

<pre><code>salt minion-id cp.cache_file salt://network/init.sls
salt minion-id slsutil.renderer /var/cache/salt/minion/files/base/network/init.sls
</code></pre>

<p>or point to whatever file that cache_file spits out.</p>

<p>If you are on 2018.3 or newer, you can just specify <code>salt://network/init.sls</code></p>
",2885,2018-10-27T13:07:02.217,"[""salt my-minion-id slsutil.renderer /srv/salt/network/init.sls 'jinja'\n"", 'salt minion-id cp.cache_file salt://network/init.sls\nsalt minion-id slsutil.renderer /var/cache/salt/minion/files/base/network/init.sls\n']"
90,1240,1239,CC BY-SA 3.0,2017-05-25T07:40:03.717,"<p>There are two places where Ansible looks for <code>group_vars</code> subdirectory:</p>

<ul>
<li>the playbook directory - the one containing a playbook you run</li>
<li>the inventory directory - the one specified with <code>-i</code> option at run time, or a default one (usually <code>/etc/ansible</code>, or <code>/usr/local/etc/ansible</code>)</li>
</ul>

<p>In most typical scenario you might place <code>group_vars</code> along with the <code>playbook.yml</code>.</p>

<p>The example you posted uses the second method, so to reference the files you need to add <code>-i</code> to the command:</p>

<pre><code>ansible windows -m ping -i ./windows
</code></pre>
",375,2017-05-25T07:45:46.680,['ansible windows -m ping -i ./windows\n']
91,1241,1237,CC BY-SA 3.0,2017-05-25T08:19:20.420,"<p>There is no general method and it might depend on how <code>boxcutter/ol67</code> was packed.</p>

<ol>
<li><p>The easiest method would be to define the password in the Ansible inventory file:</p>

<pre><code>[oracle-vm:vars]
ansible_ssh_user=vagrant
ansible_ssh_pass=vagrant
</code></pre></li>
<li><p>The second method would be to leave the insecure private key configured on the <code>oracle-vm</code> machine and inject the private key to the <code>ansible</code> VM:</p>

<pre><code>config.vm.provision ""shell"" do |s|
  ssh_insecure_key = File.readlines(""#{Dir.home}/.vagrant.d/insecure_private_key"").first.strip
  s.inline = &lt;&lt;-SHELL
    echo #{ssh_insecure_key} &gt;&gt; /home/vagrant/.ssh/id_rsa
    chown vagrant /home/vagrant/.ssh/id_rsa
    chmod 400 /home/vagrant/.ssh/id_rsa
  SHELL
end
</code></pre></li>
<li><p>Generate the key pair beforehand on the host machine, inject private key to Ansible VM, public key to Oracle's <code>authorized_keys</code>.</p></li>
<li><p>Generate the key pair on Ansible VM, copy the public key to Oracle VM using shell provisioner and inject <code>vagrant</code> as password for <code>ssh-copy-id</code>.</p></li>
</ol>

<p>And the list does not end here, it depends on required security.</p>
",375,2017-05-25T08:28:32.633,"['[oracle-vm:vars]\nansible_ssh_user=vagrant\nansible_ssh_pass=vagrant\n', 'config.vm.provision ""shell"" do |s|\n  ssh_insecure_key = File.readlines(""#{Dir.home}/.vagrant.d/insecure_private_key"").first.strip\n  s.inline = <<-SHELL\n    echo #{ssh_insecure_key} >> /home/vagrant/.ssh/id_rsa\n    chown vagrant /home/vagrant/.ssh/id_rsa\n    chmod 400 /home/vagrant/.ssh/id_rsa\n  SHELL\nend\n']"
92,1246,1243,CC BY-SA 3.0,2017-05-25T18:13:53.750,"<p>You aren't actually using file.managed, you are using file.append - so salt is expecting to add onto the end of an existing file. This may be the cause of your issue. Instead try:</p>

<pre><code>/home/vagrant/.bash_profile:
  file.managed:
    - name: /home/vagrant/.bash_profile
    - source: salt://config/user/.bash_profile
    - mode: 0775
    - user: vagrant
    - group: vagrant
    - template: jinja
    - replace: true
</code></pre>

<p>Also, be sure you are using the <a href=""https://repo.saltstack.com/"" rel=""nofollow noreferrer"">latest version</a> of Salt Stack, 2016.11</p>
",2845,2017-05-25T18:13:53.750,['/home/vagrant/.bash_profile:\n  file.managed:\n    - name: /home/vagrant/.bash_profile\n    - source: salt://config/user/.bash_profile\n    - mode: 0775\n    - user: vagrant\n    - group: vagrant\n    - template: jinja\n    - replace: true\n']
93,1247,1237,CC BY-SA 4.0,2017-05-25T22:44:51.087,"<p>Based on <a href=""https://devops.stackexchange.com/a/1241/375"">techraf's 3rd suggestion</a> I did the following:</p>

<ul>
<li><code>vagrant up ansible</code></li>
<li><code>ssh-keygen</code> (no password just pressed <kbd>Enter</kbd>)</li>
<li>copied <code>.ssh/id_rsa</code> and <code>.ssh/id_rsa.pub</code> to the project directory</li>
<li><code>vagrant destroy ansible</code></li>
<li>modified the <code>Vagrantfile</code> to copy the <code>id_rsa</code> to all hosts</li>
<li>modified the <code>Vagrantfile</code> to copy the <code>id_rsa.pub</code> into <code>authorized_keys</code> on all hosts</li>
<li>modified the Vagrantfile to disable host checking</li>
</ul>

<p>Vagrantfile snippet:</p>

<pre><code> config.vm.provision ""file"", source: ""id_rsa"", destination: ""/home/vagrant/.ssh/id_rsa""
 public_key = File.read(""id_rsa.pub"")
 config.vm.provision :shell, :inline =&gt;""
     echo 'Copying ansible-vm public SSH Keys to the VM'
     mkdir -p /home/vagrant/.ssh
     chmod 700 /home/vagrant/.ssh
     echo '#{public_key}' &gt;&gt; /home/vagrant/.ssh/authorized_keys
     chmod -R 600 /home/vagrant/.ssh/authorized_keys
     echo 'Host 192.168.*.*' &gt;&gt; /home/vagrant/.ssh/config
     echo 'StrictHostKeyChecking no' &gt;&gt; /home/vagrant/.ssh/config
     echo 'UserKnownHostsFile /dev/null' &gt;&gt; /home/vagrant/.ssh/config
     chmod -R 600 /home/vagrant/.ssh/config
     "", privileged: false
</code></pre>
",2901,2018-08-30T17:48:40.007,"[' config.vm.provision ""file"", source: ""id_rsa"", destination: ""/home/vagrant/.ssh/id_rsa""\n public_key = File.read(""id_rsa.pub"")\n config.vm.provision :shell, :inline =>""\n     echo \'Copying ansible-vm public SSH Keys to the VM\'\n     mkdir -p /home/vagrant/.ssh\n     chmod 700 /home/vagrant/.ssh\n     echo \'#{public_key}\' >> /home/vagrant/.ssh/authorized_keys\n     chmod -R 600 /home/vagrant/.ssh/authorized_keys\n     echo \'Host 192.168.*.*\' >> /home/vagrant/.ssh/config\n     echo \'StrictHostKeyChecking no\' >> /home/vagrant/.ssh/config\n     echo \'UserKnownHostsFile /dev/null\' >> /home/vagrant/.ssh/config\n     chmod -R 600 /home/vagrant/.ssh/config\n     "", privileged: false\n']"
94,1249,1238,CC BY-SA 3.0,2017-05-26T11:36:48.807,"<p>When I encountered a related problem, I wound up having Jinja run execute Salt modules.</p>

<p>In my case, it was <code>cmd.run</code> to run <code>mktmp</code> (and, at the end of the template, <code>rm</code> for cleanup), with <code>file.append</code> and <code>file.grep</code>, though in your case, you might be able to use Salt's <code>load_yaml</code> extension to Jinja.</p>

<p>So, something like this (rough, untested): </p>

<pre><code>{% set tmpfile = salt['cmd.run']('mktmp') -%}
{% salt['file.append']('my_key: ' ~ your_key) -%}
{% set my_key = load_yaml(tmpfile)['my_key'] -%}
{% salt['file.remove'](tmpfile) %}
</code></pre>

<p>This certainly isn't the best place to put data, but it demonstrated using calling into Salt modules from Jinja to store data. I don't know of any existing Salt modules suitable for storing ephemeral data that only lives as long as the templates compile. I'll check back later and see what other solutions might work.</p>
",339,2017-05-26T11:36:48.807,"[""{% set tmpfile = salt['cmd.run']('mktmp') -%}\n{% salt['file.append']('my_key: ' ~ your_key) -%}\n{% set my_key = load_yaml(tmpfile)['my_key'] -%}\n{% salt['file.remove'](tmpfile) %}\n""]"
95,1252,725,CC BY-SA 3.0,2017-05-26T20:44:20.143,"<p>This is typically done by setting the following value in <code>ansible.cfg</code>:</p>

<pre><code>[defaults]
host_key_checking = False
</code></pre>

<p>If you don't want to modify <code>ansible.cfg</code> you can set an environment variable like so:</p>

<pre><code>export ANSIBLE_HOST_KEY_CHECKING=False
</code></pre>

<p>Source: <a href=""http://docs.ansible.com/ansible/intro_getting_started.html#host-key-checking"" rel=""noreferrer"">http://docs.ansible.com/ansible/intro_getting_started.html#host-key-checking</a></p>
",144,2017-08-15T20:52:57.713,"['[defaults]\nhost_key_checking = False\n', 'export ANSIBLE_HOST_KEY_CHECKING=False\n']"
96,1265,1112,CC BY-SA 3.0,2017-05-31T02:40:59.890,"<p>Conceptually, this approach is not the way to go; the build directory is not a deployment directory, it's a temporary directory, to build or to deploy <strong>from</strong>, whereas on a shell executor this could be fixed.</p>

<p>So what you need is to deploy from that directory with a script as per <code>gitlab-ci.yml</code> below, to the correct directory of deployment.</p>

<pre><code>stages:
- deploy

variables:
  TARGET_DIR: /home/ab12/public_html/$CI_PROJECT_NAME

deploy:
  stage: deploy
  script:
     mkdir -pv $TARGET_DIR
     rsync -r --delete ./ $TARGET_DIR
  tags:
    - myrunner
</code></pre>

<p>This will move your <code>projectfiles</code> in /home/ab12/public_html/</p>

<p>naming your projects as <code>project1</code> .. <code>projectn</code>, all your projects could use this same <code>.gitlab-ci.yml</code> file.</p>
",2979,2017-05-31T12:20:05.913,['stages:\n- deploy\n\nvariables:\n  TARGET_DIR: /home/ab12/public_html/$CI_PROJECT_NAME\n\ndeploy:\n  stage: deploy\n  script:\n     mkdir -pv $TARGET_DIR\n     rsync -r --delete ./ $TARGET_DIR\n  tags:\n    - myrunner\n']
97,1268,1267,CC BY-SA 3.0,2017-05-31T21:03:09.283,"<p>Try piping your output to grep and then failing based off of the return code of grep:</p>

<pre><code>npm install 2&gt;&amp;1 | grep ""Error: connect ETIMEDOUT""
</code></pre>

<p>Per the <a href=""https://www.gnu.org/software/grep/manual/html_node/Exit-Status.html"" rel=""nofollow noreferrer"">grep documentation</a>,</p>

<blockquote>
  <p>the exit status is 0 if a line is selected, 1 if no lines were selected, and 2 if an error occurred.</p>
</blockquote>

<p>If needed, you can <a href=""https://stackoverflow.com/questions/15073048/bash-not-inverting-the-exit-status-of-a-command"">""not"" the return code</a> or just invert the conditional so that:</p>

<pre><code>if [ ""$?"" -ne ""0"" ]; then
    echo ""Packer failed!""
    exit 1
fi
</code></pre>

<p>becomes instead:</p>

<pre><code>if [ ""$?"" -ne ""1"" ]; then
    echo ""Packer failed!""
    exit 1
fi
</code></pre>
",2845,2017-05-31T21:03:09.283,"['npm install 2>&1 | grep ""Error: connect ETIMEDOUT""\n', 'if [ ""$?"" -ne ""0"" ]; then\n    echo ""Packer failed!""\n    exit 1\nfi\n', 'if [ ""$?"" -ne ""1"" ]; then\n    echo ""Packer failed!""\n    exit 1\nfi\n']"
98,1273,1272,CC BY-SA 3.0,2017-06-01T17:05:48.723,"<p>Based on:</p>

<blockquote>
<pre><code># Allow OpenSSH. (Note that as ufw manages its own state, simply removing
# a rule=allow task can leave those ports exposed. Either use delete=yes
# or a separate state=reset task)
</code></pre>
</blockquote>

<p>The following snippet was added to the top of the file:</p>

<pre><code>---
- name: Reset UFW
  ufw:
    state: reset
</code></pre>

<p>Once ansible was run:</p>

<pre><code>TASK [rolename : Reset UFW]
</code></pre>

<p>the undefined ports were removed</p>
",210,2017-06-01T17:05:48.723,"['# Allow OpenSSH. (Note that as ufw manages its own state, simply removing\n# a rule=allow task can leave those ports exposed. Either use delete=yes\n# or a separate state=reset task)\n', '---\n- name: Reset UFW\n  ufw:\n    state: reset\n', 'TASK [rolename : Reset UFW]\n']"
99,1282,1277,CC BY-SA 3.0,2017-06-03T02:23:22.113,"<p>Tee will be a very simple tool for logging, you can refer the following command.</p>

<pre><code>eric@eric-MacBookPro:~$ ansible -m ping all | tee &gt; /tmp/ansible.log
eric@eric-MacBookPro:~$ cat /tmp/ansible.log 
localhost | SUCCESS =&gt; {
    ""changed"": false,
    ""ping"": ""pong""
}
</code></pre>
",3013,2017-06-04T14:59:00.820,"['eric@eric-MacBookPro:~$ ansible -m ping all | tee > /tmp/ansible.log\neric@eric-MacBookPro:~$ cat /tmp/ansible.log \nlocalhost | SUCCESS => {\n    ""changed"": false,\n    ""ping"": ""pong""\n}\n']"
100,1284,1052,CC BY-SA 3.0,2017-06-03T19:09:44.193,"<p>Fabric (and Capistrano, presumably the unnamed Ruby tool you came across) are a bit unusual in that they're task runners with extra features for easily running tasks on remote hosts.  I'm not aware of any other popular tools that do exactly the same thing, but depending on your needs there are a few other options that may work for you.</p>

<p><a href=""https://en.wikipedia.org/wiki/Grunt_(software)"" rel=""noreferrer"">Grunt</a> and <a href=""https://en.wikipedia.org/wiki/Gulp.js"" rel=""noreferrer"">Gulp</a> are the foremost task runners in the Javascript ecosystem.  While not designed specifically to deploy software, they both have plugin-based systems that allow you do this, and you'll find plenty of articles of people using <a href=""https://duckduckgo.com/?q=grunt+deploy&amp;ia=software"" rel=""noreferrer"">either</a> <a href=""https://duckduckgo.com/?q=gulp+deploy&amp;ia=software"" rel=""noreferrer"">one</a> to do so.  For instance, <a href=""http://justinklemm.com/grunt-js-deployment-ssh-git/"" rel=""noreferrer"">this tutorial</a> uses <a href=""https://github.com/israelroldan/grunt-ssh"" rel=""noreferrer"">the <code>grunt-ssh</code> plugin</a> to integrate ssh with grunt, while <a href=""https://mikeeverhart.net/2016/01/deploy-code-to-remote-servers-with-gulp-js/"" rel=""noreferrer"">this one</a> relies on <a href=""https://www.npmjs.com/package/gulp-rsync"" rel=""noreferrer""><code>gulp-rsync</code></a>.</p>

<p>Using task runners to deploy code tends to be an approach favored by developers who are wearing an ops hat.  When you ask an operations engineer, they're more likely to suggest hacking this behavior into a configuration tool.  This can take many forms (for instance, packaging your app into an rpm or deb, then installing it like any other software), but I'm going to focus on what I think would be the simplest and most direct method for you.</p>

<p><a href=""https://en.wikipedia.org/wiki/Ansible_(software)"" rel=""noreferrer"">Ansible</a> is ostensibly a configuration management tool, but it really shines at <strong>task orchestration</strong>, which I would define as ""running a set of actions across a set of servers"".  <a href=""https://docs.ansible.com/ansible/index.html"" rel=""noreferrer"">The official documentation</a> is a good place to get started, but to give you an idea of what this might look like, you might have a <em>playbook</em> (a YAML file that defines a set of tasks) like this:</p>

<pre class=""lang-yaml prettyprint-override""><code>- hosts: webservers
  tasks:
    - name: update code checkout
      git:
        repo: ssh://git@github.com/mylogin/hello.git
        dest: /var/www
        version: master

    - name: restart webserver
      command: restart-command-you-run
</code></pre>

<p>When you run this file with <code>ansible-playbook</code>, it will look up your host list (as simple as an ini file, but can also be a dynamic list written in any programming language) to determine what servers exist and what groups they're in, and then run the defined tasks on the servers that you tell it to.</p>

<p>Now, you specified that you wanted to stay in the Javascript ecosystem.  However, while Ansible is a new thing for you, it doesn't have all the complexities of another programming language, since configurations are written in YAML.  It will also allow you to do much much more later, and unlike several of its competitors, uses ssh to communicate, so there's very little setup involved (nothing to install on the remote machines).</p>
",960,2017-06-03T19:09:44.193,['- hosts: webservers\n  tasks:\n    - name: update code checkout\n      git:\n        repo: ssh://git@github.com/mylogin/hello.git\n        dest: /var/www\n        version: master\n\n    - name: restart webserver\n      command: restart-command-you-run\n']
101,1289,1277,CC BY-SA 3.0,2017-06-05T07:20:17.617,"<p>I think that all you need to do is to register the output of every command you need (store it in a variable) and then simply dump the variable in a file. That way you can review it later. </p>

<pre><code>tasks:
  - name: Dump all vars
    action: template src=templates/dumpall.j2 dest=/tmp/ansible.all
</code></pre>

<p>Then in dumpall.j2:</p>

<pre><code>Module Variables (""vars""):
--------------------------------
{{ vars | to_nice_json }} 

Environment Variables (""environment""):
--------------------------------
{{ environment | to_nice_json }} 

GROUP NAMES Variables (""group_names""):
--------------------------------
{{ group_names | to_nice_json }}

GROUPS Variables (""groups""):
--------------------------------
{{ groups | to_nice_json }}

HOST Variables (""hostvars""):
--------------------------------
{{ hostvars | to_nice_json }} 
</code></pre>

<p>The example I'm using is from <a href=""https://coderwall.com/p/13lh6w/dump-all-variables"" rel=""nofollow noreferrer"">here</a></p>
",775,2017-06-05T07:27:49.990,"['tasks:\n  - name: Dump all vars\n    action: template src=templates/dumpall.j2 dest=/tmp/ansible.all\n', 'Module Variables (""vars""):\n--------------------------------\n{{ vars | to_nice_json }} \n\nEnvironment Variables (""environment""):\n--------------------------------\n{{ environment | to_nice_json }} \n\nGROUP NAMES Variables (""group_names""):\n--------------------------------\n{{ group_names | to_nice_json }}\n\nGROUPS Variables (""groups""):\n--------------------------------\n{{ groups | to_nice_json }}\n\nHOST Variables (""hostvars""):\n--------------------------------\n{{ hostvars | to_nice_json }} \n']"
102,1297,1275,CC BY-SA 3.0,2017-06-05T16:26:53.783,"<p>Based on <a href=""https://devops.stackexchange.com/a/1276/210"">@13nilux' answer</a> the following code has been created:</p>

<pre><code>- name: Check whether port 80 is available
  wait_for:
    port: 80
    state: stopped
    timeout: 10
</code></pre>

<p>When port 80 is listening the run will fail if for example nginx is listening:</p>

<pre><code>TASK [role_under_test : Check whether port 80 is available] ********************

fatal: [localhost]: FAILED! =&gt; {""changed"": false, ""elapsed"": 10, ""failed"": true, ""msg"": ""Timeout when waiting for 127.0.0.1:80 to stop.""}

 [WARNING]: Could not create retry file

'/etc/ansible/roles/role_under_test/tests/test.retry'.         [Errno 30] Read-

only file system: u'/etc/ansible/roles/role_under_test/tests/test.retry'
</code></pre>
",210,2017-06-05T16:32:01.057,"['- name: Check whether port 80 is available\n  wait_for:\n    port: 80\n    state: stopped\n    timeout: 10\n', 'TASK [role_under_test : Check whether port 80 is available] ********************\n\nfatal: [localhost]: FAILED! => {""changed"": false, ""elapsed"": 10, ""failed"": true, ""msg"": ""Timeout when waiting for 127.0.0.1:80 to stop.""}\n\n [WARNING]: Could not create retry file\n\n\'/etc/ansible/roles/role_under_test/tests/test.retry\'.         [Errno 30] Read-\n\nonly file system: u\'/etc/ansible/roles/role_under_test/tests/test.retry\'\n']"
103,1304,1277,CC BY-SA 3.0,2017-06-06T10:29:14.870,"<p>[Converting my comment to an answer]</p>

<p>One way to do it would be to write the logs to some external file, and then having a task after it which makes use of failed_when condition, and remove the log file, if the previous task was successful.</p>

<p>Something like this should help you.</p>

<pre><code> - name: Run Py script
      command: &lt;&gt;.py  &gt; &lt;&gt;.log
      become: yes
      register: PyScript
      ignore_errors: True

    - name: PyScript on success
      command: rm &lt;&gt;.log
      when: PyScript|succeeded
</code></pre>

<p>Note: This might not be the best way to handle your problem. But, this was a hack which helped me do my logging and monitoring.</p>
",46,2017-06-06T10:36:39.897,[' - name: Run Py script\n      command: <>.py  > <>.log\n      become: yes\n      register: PyScript\n      ignore_errors: True\n\n    - name: PyScript on success\n      command: rm <>.log\n      when: PyScript|succeeded\n']
104,1307,1277,CC BY-SA 4.0,2017-06-06T14:25:58.197,"<p>What I do when I've a command to execute and wish to get the log only in case of failure is as follow (prefixed by a shell comamnd like <code>/bin/sh -c '...'</code> in case the initiator doesn't use a <code>system</code> call or execute the command directly without shell):</p>
<pre><code>command 2&gt;&amp;1 &gt; command-log.txt || cat command-log.txt
</code></pre>
<p>This will redirect error and standard output to a file and display the content of the file in case of failure only. If the command is very verbose and you don't wish to keep the log when it's ok you can go with:</p>
<pre><code>command 2&gt;&amp;1 &gt; command-log.txt &amp;&amp; rm command-log.txt || cat command-log.txt
</code></pre>
<p>Quote for <code>&amp;&amp;</code> and <code>||</code> usage from <a href=""http://heirloom.sourceforge.net/sh/sh.1.html"" rel=""nofollow noreferrer"">sh manpage</a>:</p>
<blockquote>
<p>The symbol &amp;&amp; (||) causes the list following to be executed only if
the preceding pipeline returns a zero (non zero) value.</p>
</blockquote>
<p>That's probably not the most idiomatic way to do it with ansible but has the advantage of being very portable with any configuration management system giving the ability to display command stdout.</p>
",13,2020-07-30T06:52:40.987,"['command 2>&1 > command-log.txt || cat command-log.txt\n', 'command 2>&1 > command-log.txt && rm command-log.txt || cat command-log.txt\n']"
105,1315,1313,CC BY-SA 3.0,2017-06-06T21:41:31.700,"<p>I couldn't find it in Ansible, so I wrote something to help a couple of weeks ago:</p>

<pre><code>import fcntl
import json
import os
import platform
import subprocess
import socket
import struct
import re
from random import randint
import time
from ansible.module_utils.basic import *

def get_interface_info_for_ip(ip):

  ifconfig_process = subprocess.Popen(['/sbin/ifconfig'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  ifconfig_stdout_lines, ifconfig_stderr_lines = ifconfig_process.communicate()

  for ifconfig_stdout_line in ifconfig_stdout_lines.split('\n'):
    if 'mtu' in ifconfig_stdout_line.split():
      current_ifdesc = ''
      current_mtu = ''
      current_ip = ''
      current_netmask = ''
      current_mac = ''
      ifdesc_line_match = re.match(r'(?P&lt;ifdesc&gt;[a-zA-Z0-9]+):.+mtu\s+(?P&lt;mtu&gt;[0-9]+)', ifconfig_stdout_line )
      if ifdesc_line_match:
        current_ifdesc = ifdesc_line_match.groupdict()['ifdesc']
        current_mtu = ifdesc_line_match.groupdict()['mtu']

    if 'inet' in ifconfig_stdout_line.split():
      inet_line_match = re.match(r'\s+inet\s+(?P&lt;ip&gt;[0-9.]+)\s+netmask\s+(?P&lt;netmask&gt;[0-9.]+)', ifconfig_stdout_line)
      if inet_line_match:
         current_ip = inet_line_match.groupdict()['ip']
         current_netmask = inet_line_match.groupdict()['netmask']

    if 'ether' in ifconfig_stdout_line.split():
      ether_line_match = re.match(r'\s+ether\s+(?P&lt;mac&gt;[0-9a-f:]+)', ifconfig_stdout_line)
      if ether_line_match:
         current_mac = ether_line_match.groupdict()['mac']

    if current_ifdesc and current_mtu and current_ip and current_netmask and current_mac and current_ip == ip:
      return current_ifdesc, current_mtu, current_ip, current_netmask, current_mac

def main(argv=None):
    if argv is None:
      argv = sys.argv

    module = AnsibleModule(
        argument_spec = dict(
           silo_ip = dict(required=True),
        )
    )
    my_ip = module.params['ip']
    ifdesc, mtu, ip, netmask, mac = get_interface_info_for_ip(my_ip)

    module.exit_json(changed=True, ifdesc=ifdesc, ip=ip, mac=mac, netmask=netmask, mtu=mtu)

if __name__ == '__main__':
    main()
</code></pre>

<p>Call the file <code>get_ip_facts</code>, put it in your library path and call it with:</p>

<pre><code>name: get facts for ip address
get_ip_facts: ip={{ whatever_your_ip_is }}
</code></pre>
",323,2017-06-07T02:59:47.890,"[""import fcntl\nimport json\nimport os\nimport platform\nimport subprocess\nimport socket\nimport struct\nimport re\nfrom random import randint\nimport time\nfrom ansible.module_utils.basic import *\n\ndef get_interface_info_for_ip(ip):\n\n  ifconfig_process = subprocess.Popen(['/sbin/ifconfig'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n  ifconfig_stdout_lines, ifconfig_stderr_lines = ifconfig_process.communicate()\n\n  for ifconfig_stdout_line in ifconfig_stdout_lines.split('\\n'):\n    if 'mtu' in ifconfig_stdout_line.split():\n      current_ifdesc = ''\n      current_mtu = ''\n      current_ip = ''\n      current_netmask = ''\n      current_mac = ''\n      ifdesc_line_match = re.match(r'(?P<ifdesc>[a-zA-Z0-9]+):.+mtu\\s+(?P<mtu>[0-9]+)', ifconfig_stdout_line )\n      if ifdesc_line_match:\n        current_ifdesc = ifdesc_line_match.groupdict()['ifdesc']\n        current_mtu = ifdesc_line_match.groupdict()['mtu']\n\n    if 'inet' in ifconfig_stdout_line.split():\n      inet_line_match = re.match(r'\\s+inet\\s+(?P<ip>[0-9.]+)\\s+netmask\\s+(?P<netmask>[0-9.]+)', ifconfig_stdout_line)\n      if inet_line_match:\n         current_ip = inet_line_match.groupdict()['ip']\n         current_netmask = inet_line_match.groupdict()['netmask']\n\n    if 'ether' in ifconfig_stdout_line.split():\n      ether_line_match = re.match(r'\\s+ether\\s+(?P<mac>[0-9a-f:]+)', ifconfig_stdout_line)\n      if ether_line_match:\n         current_mac = ether_line_match.groupdict()['mac']\n\n    if current_ifdesc and current_mtu and current_ip and current_netmask and current_mac and current_ip == ip:\n      return current_ifdesc, current_mtu, current_ip, current_netmask, current_mac\n\ndef main(argv=None):\n    if argv is None:\n      argv = sys.argv\n\n    module = AnsibleModule(\n        argument_spec = dict(\n           silo_ip = dict(required=True),\n        )\n    )\n    my_ip = module.params['ip']\n    ifdesc, mtu, ip, netmask, mac = get_interface_info_for_ip(my_ip)\n\n    module.exit_json(changed=True, ifdesc=ifdesc, ip=ip, mac=mac, netmask=netmask, mtu=mtu)\n\nif __name__ == '__main__':\n    main()\n"", 'name: get facts for ip address\nget_ip_facts: ip={{ whatever_your_ip_is }}\n']"
106,1318,1313,CC BY-SA 3.0,2017-06-07T15:39:23.013,"<p>Peter's module not working in CentOS and I write my own module:</p>

<pre><code>#!/usr/bin/python
# encoding: utf-8

import subprocess
from ansible.module_utils.basic import *
from netaddr import IPNetwork

def get_priv_interface_info_for_ip(ip):
    network_config = subprocess.Popen([""/usr/sbin/ip"", ""-o"", ""addr"", ""show""], stdout=subprocess.PIPE)
    result = network_config.stdout.read()
    interface = """"
    network = ''
    ip_addr = ip
    for str in result.split(""\n""):
        if 'inet ' in str:
            if ip in str:
                interface = str[3:str.find("" "", 3)]
                network = IPNetwork(str[str.find(""net"", 3) + 4:str.find(""/"", 3) + 3]).cidr

    return interface, ip_addr, network

def get_pub_interface_info_for_ip(ip):
    network_config = subprocess.Popen([""/usr/sbin/ip"", ""-o"", ""addr"", ""show""], stdout=subprocess.PIPE)
    result = network_config.stdout.read()
    interface = ''
    network = ''
    ip_addr = ''
    for str in result.split(""\n""):
        if 'inet ' in str:
            if ip not in str and '127.0.0.1' not in str:
                print str
                interface = str[3:str.find("" "", 3)]
                network = IPNetwork(str[str.find(""net"", 3) + 4:str.find(""/"", 3) + 3]).cidr
                ip_addr = str[str.find(""net"", 3) + 4:str.find(""/"", 3)]

    return interface, ip_addr, network

def main(argv=None):
    if argv is None:
        argv = sys.argv

    fields = {""ip"": {""required"": True, ""type"": ""str""}}
    module = AnsibleModule(argument_spec=fields)
    my_ip = module.params['ip']
    ifname_priv, ip_priv, network_priv = get_priv_interface_info_for_ip(my_ip)
    ifname_pub, ip_pub, network_pub = get_pub_interface_info_for_ip(my_ip)


    module.exit_json(changed=True, ifname_priv=ifname_priv, ip_priv=my_ip, network_priv=str(network_priv), ifname_pub=ifname_pub, ip_pub=ip_pub, network_pub=str(network_pub))


if __name__ == '__main__':
    main()
</code></pre>

<p>It works for servers with two network interfaces and provide information about public and private network interfaces.</p>

<p>Actual version of this module could be found in <a href=""https://github.com/ATolkachev/ansible/blob/master/library/get_ip_facts.py"" rel=""nofollow noreferrer"">my GitHub</a>.</p>
",1084,2018-01-16T15:14:14.513,"['#!/usr/bin/python\n# encoding: utf-8\n\nimport subprocess\nfrom ansible.module_utils.basic import *\nfrom netaddr import IPNetwork\n\ndef get_priv_interface_info_for_ip(ip):\n    network_config = subprocess.Popen([""/usr/sbin/ip"", ""-o"", ""addr"", ""show""], stdout=subprocess.PIPE)\n    result = network_config.stdout.read()\n    interface = """"\n    network = \'\'\n    ip_addr = ip\n    for str in result.split(""\\n""):\n        if \'inet \' in str:\n            if ip in str:\n                interface = str[3:str.find("" "", 3)]\n                network = IPNetwork(str[str.find(""net"", 3) + 4:str.find(""/"", 3) + 3]).cidr\n\n    return interface, ip_addr, network\n\ndef get_pub_interface_info_for_ip(ip):\n    network_config = subprocess.Popen([""/usr/sbin/ip"", ""-o"", ""addr"", ""show""], stdout=subprocess.PIPE)\n    result = network_config.stdout.read()\n    interface = \'\'\n    network = \'\'\n    ip_addr = \'\'\n    for str in result.split(""\\n""):\n        if \'inet \' in str:\n            if ip not in str and \'127.0.0.1\' not in str:\n                print str\n                interface = str[3:str.find("" "", 3)]\n                network = IPNetwork(str[str.find(""net"", 3) + 4:str.find(""/"", 3) + 3]).cidr\n                ip_addr = str[str.find(""net"", 3) + 4:str.find(""/"", 3)]\n\n    return interface, ip_addr, network\n\ndef main(argv=None):\n    if argv is None:\n        argv = sys.argv\n\n    fields = {""ip"": {""required"": True, ""type"": ""str""}}\n    module = AnsibleModule(argument_spec=fields)\n    my_ip = module.params[\'ip\']\n    ifname_priv, ip_priv, network_priv = get_priv_interface_info_for_ip(my_ip)\n    ifname_pub, ip_pub, network_pub = get_pub_interface_info_for_ip(my_ip)\n\n\n    module.exit_json(changed=True, ifname_priv=ifname_priv, ip_priv=my_ip, network_priv=str(network_priv), ifname_pub=ifname_pub, ip_pub=ip_pub, network_pub=str(network_pub))\n\n\nif __name__ == \'__main__\':\n    main()\n']"
107,1328,1325,CC BY-SA 3.0,2017-06-09T12:57:26.737,"<p>I'm going to assume that you have a way to know if the commit is empty or not.</p>

<p>You can use the following code to mark the job as a success instead of relying on error codes. </p>

<pre><code>if( some use case ) {
    currentBuild.result = 'SUCCESS'
    echo ""Job succeeded.""
    return
}
</code></pre>

<p>You have two options for placement. Putting this inside a stage will exit only that stage as a success. Putting it outside a stage (but inside the node) will end the whole job as a success.</p>

<p>I can't be more specific without knowing your code, but I'd expect something like ""make commit, if full continue as normal, if empty build result is success"".</p>
",736,2017-06-09T12:57:26.737,"['if( some use case ) {\n    currentBuild.result = \'SUCCESS\'\n    echo ""Job succeeded.""\n    return\n}\n']"
108,1333,1322,CC BY-SA 3.0,2017-06-10T17:34:08.607,"<p>You want to use <a href=""https://github.com/sensu-extensions/sensu-extensions-occurrences/"" rel=""nofollow noreferrer"">the <code>occurrences</code> filter</a>, which is included <a href=""https://sensuapp.org/docs/0.28/reference/plugins.html#check-definition-attributes"" rel=""nofollow noreferrer"">by default in Sensu</a>.</p>

<p>First, apply the filter to your handlers:</p>

<pre><code>{
  ""handlers"": {
    ""email"": {
      ""..."": ""..."",
      ""filters"": [""occurrences""]
    }
  }
}
</code></pre>

<p>Then, in your check, you can use the <code>occurrences</code> attribute to only trigger the handler once the check fails or warns a certain number of times in a row:</p>

<pre><code>{
  ""checks"": {
    ""check-http"": {
      ""..."": ""..."",
      ""occurrences"": 2
    }
  }
}
</code></pre>
",960,2017-08-07T13:37:19.897,"['{\n  ""handlers"": {\n    ""email"": {\n      ""..."": ""..."",\n      ""filters"": [""occurrences""]\n    }\n  }\n}\n', '{\n  ""checks"": {\n    ""check-http"": {\n      ""..."": ""..."",\n      ""occurrences"": 2\n    }\n  }\n}\n']"
109,1341,1329,CC BY-SA 3.0,2017-06-13T16:54:44.800,"<p>Working off what @chupasaurus said, here's what I came up with:</p>

<pre><code>node('master') {
    dir(""../builds/${BUILD_NUMBER}/"") {
        sh ""cp -r cucumber-html-reports $WORKSPACE""
    }

    archive ""cucumber-html-reports/*""
}
</code></pre>

<p>Obviously all this does is archive the report for that build, but you can easily extend this to copy it somewhere else where it can be hosted or manipulated. Just make sure you put this after the Cucumber Reports plugin step.</p>
",362,2017-06-13T16:54:44.800,"['node(\'master\') {\n    dir(""../builds/${BUILD_NUMBER}/"") {\n        sh ""cp -r cucumber-html-reports $WORKSPACE""\n    }\n\n    archive ""cucumber-html-reports/*""\n}\n']"
110,1342,1335,CC BY-SA 3.0,2017-06-14T08:45:14.623,"<p>Largely inspired by the <a href=""https://www.terraform.io/docs/providers/aws/d/security_group.html"" rel=""nofollow noreferrer"">documentation</a> the idea is to create a terraform datasource from a filter of the available resources and then use this as entry point in your ami resource:</p>

<pre><code>variable ""security_group_id"" {}
variable ""subnet_id"" {}

data ""aws_security_group"" ""selected"" {
  filter {
    name = ""${var.ansible_ami[""security_groups_name""]}}""
  }
}

data ""aws_subnet"" ""selected"" {
  filter {
    name = ""${var.ansible_ami[""subnet_name""]}""
  }
}

resource ""aws_instance"" ""ansible"" {
    ami = ""${var.ansible_ami[""ami""]}""
    instance_type = ""${var.ansible_ami[""size""]}""
    security_groups = ""${data.aws_security_group.selected.id}""
    subnet_id = ""${data.aws_subnet.selected.id}""
    associate_public_ip_address = ""${var.ansible_ami[""enable_public_ip""]}""
    #user_data = """"
</code></pre>

<p>I'm not using terraform myself, so this could be plain wrong.</p>
",13,2017-06-15T14:32:29.783,"['variable ""security_group_id"" {}\nvariable ""subnet_id"" {}\n\ndata ""aws_security_group"" ""selected"" {\n  filter {\n    name = ""${var.ansible_ami[""security_groups_name""]}}""\n  }\n}\n\ndata ""aws_subnet"" ""selected"" {\n  filter {\n    name = ""${var.ansible_ami[""subnet_name""]}""\n  }\n}\n\nresource ""aws_instance"" ""ansible"" {\n    ami = ""${var.ansible_ami[""ami""]}""\n    instance_type = ""${var.ansible_ami[""size""]}""\n    security_groups = ""${data.aws_security_group.selected.id}""\n    subnet_id = ""${data.aws_subnet.selected.id}""\n    associate_public_ip_address = ""${var.ansible_ami[""enable_public_ip""]}""\n    #user_data = """"\n']"
111,1349,1348,CC BY-SA 3.0,2017-06-15T10:03:40.583,"<p>serverspec is using <a href=""https://net-ssh.github.io/ssh/v2/api/classes/Net/SSH/Config.html"" rel=""nofollow noreferrer"">this Ruby class</a> to ssh to servers</p>

<p>One should set the path to the key into the ~/.ssh/config file:</p>

<pre><code>Host X
    HostName X
    User Y
    PreferredAuthentications publickey
    IdentityFile ~/.ssh/Z
</code></pre>

<p>Now <code>rake spec</code> runs the test on the server.</p>
",210,2017-06-15T10:03:40.583,['Host X\n    HostName X\n    User Y\n    PreferredAuthentications publickey\n    IdentityFile ~/.ssh/Z\n']
112,1356,1355,CC BY-SA 3.0,2017-06-16T00:08:51.573,"<p>This is why configuration management software exists.
Example for Ansible and AWS:</p>

<pre><code>- name: Create a sandbox instance
  hosts: localhost
  gather_facts: False
  vars:
    timezones_path: /some/path/timezones.list
    key_name: my_keypair
    instance_type: m1.small
    security_group: my_securitygroup
    vpc_subnet: my_vpc_id
    image: my_ami_id
    region: us-east-1
  tasks:
    - name: Load timezones list
      shell: ""echo {{ item }}""
      with_lines: ""cat {{ timezones_path|quote }}""
      register: timezones

    - name: Launch instances
      ec2:
         key_name: ""{{ keypair }}""
         group: ""{{ security_group }}""
         instance_type: ""{{ instance_type }}""
         image: ""{{ image }}""
         wait: true
         region: ""{{ region }}""
         vpc_subnet_id: ""{{ vpc_subnet }}""
         assign_public_ip: yes
         count: ""{{ timezones|length }}""
      register: ec2

    - name: Add new instance to host group
      add_host:
        hostname: ""{{ item.1.public_ip }}""
        timezone: ""{{ item.0 }}""
        groupname: launched
      with_together:
        ""{{ timezones }}""
        ""{{ ec2.instances }}""

    -name: Tag instances with timezones
      ec2_tag:
        region: ""{{ region }}""
        resource: ""{{ item.id }}""
        tags:
          Timezone: ""{{ item.timezone }}""
      with_items: ""{{ groups['launched'] }}""

    - name: Wait for SSH to come up
      wait_for:
        host: ""{{ item.public_dns_name }}""
        port: 22
        delay: 60
        timeout: 320
        state: started
      with_items: ""{{ ec2.instances }}""

- name: Configure instance(s)
  hosts: launched
  become: True
  gather_facts: True
  tasks:
    - name: Run deploy script
      shell: ""/path/to/script.sh --tz {{timezone}}""
</code></pre>

<p>Path to script in last line should be for host which runs Ansible, not remote.</p>
",2956,2017-06-16T00:08:51.573,"['- name: Create a sandbox instance\n  hosts: localhost\n  gather_facts: False\n  vars:\n    timezones_path: /some/path/timezones.list\n    key_name: my_keypair\n    instance_type: m1.small\n    security_group: my_securitygroup\n    vpc_subnet: my_vpc_id\n    image: my_ami_id\n    region: us-east-1\n  tasks:\n    - name: Load timezones list\n      shell: ""echo {{ item }}""\n      with_lines: ""cat {{ timezones_path|quote }}""\n      register: timezones\n\n    - name: Launch instances\n      ec2:\n         key_name: ""{{ keypair }}""\n         group: ""{{ security_group }}""\n         instance_type: ""{{ instance_type }}""\n         image: ""{{ image }}""\n         wait: true\n         region: ""{{ region }}""\n         vpc_subnet_id: ""{{ vpc_subnet }}""\n         assign_public_ip: yes\n         count: ""{{ timezones|length }}""\n      register: ec2\n\n    - name: Add new instance to host group\n      add_host:\n        hostname: ""{{ item.1.public_ip }}""\n        timezone: ""{{ item.0 }}""\n        groupname: launched\n      with_together:\n        ""{{ timezones }}""\n        ""{{ ec2.instances }}""\n\n    -name: Tag instances with timezones\n      ec2_tag:\n        region: ""{{ region }}""\n        resource: ""{{ item.id }}""\n        tags:\n          Timezone: ""{{ item.timezone }}""\n      with_items: ""{{ groups[\'launched\'] }}""\n\n    - name: Wait for SSH to come up\n      wait_for:\n        host: ""{{ item.public_dns_name }}""\n        port: 22\n        delay: 60\n        timeout: 320\n        state: started\n      with_items: ""{{ ec2.instances }}""\n\n- name: Configure instance(s)\n  hosts: launched\n  become: True\n  gather_facts: True\n  tasks:\n    - name: Run deploy script\n      shell: ""/path/to/script.sh --tz {{timezone}}""\n']"
113,1363,1353,CC BY-SA 3.0,2017-06-17T09:08:30.577,"<p>To avoid such issues, that is why there are <a href=""http://docs.ansible.com/ansible/intro_inventory.html#hosts-and-groups"" rel=""nofollow noreferrer"">Hosts and Groups in Ansible</a>.</p>

<blockquote>
<pre><code>/etc/ansible/group_vars/raleigh # can optionally end in '.yml', '.yaml', or '.json'
/etc/ansible/group_vars/webservers
/etc/ansible/host_vars/foosball
</code></pre>
</blockquote>
",210,2017-06-17T09:08:30.577,"[""/etc/ansible/group_vars/raleigh # can optionally end in '.yml', '.yaml', or '.json'\n/etc/ansible/group_vars/webservers\n/etc/ansible/host_vars/foosball\n""]"
114,1366,1353,CC BY-SA 4.0,2017-06-18T06:30:12.443,"<p>Since I can't comment on 030's answer yet (just opened an account), I'll answer here.</p>

<p>Group vars directories are relative to the Ansible path.</p>

<p>You don't have to run Ansible from /etc/ansible.  You can run it from ~/.hidden/directory/stuff if you wish.  Just make sure to keep a directory structure.  I.e.:</p>

<pre><code>/pipeline/   # ansible playbooks are here
/pipeline/roles
/pipeline/group_vars
</code></pre>

<p>Then you can run something like</p>

<pre><code>cd /pipeline
ansible-playbook deploy_app.yml
</code></pre>

<p>Which will read group vars from the pipeline/group_vars folder.  Better to cd to your ansible root folder first since it looks for paths from the current folder you're in if it can't find them in default location (/etc/ansible), such that you can put your ansible.cfg in /pipeline without having to specify other command line arguments.  You can also optionally define specific paths inside ansible.cfg as well.</p>

<p>You can take it a step further and set up separate group vars for each environment/location/etc:</p>

<pre><code>/pipeline/prod/group_vars/all.yml
/pipeline/dev/group_vars/all.yml
</code></pre>

<p>And run as follows using include-vars.</p>

<p>ansible-playbook deploy_app.yml -i prod</p>
",3175,2019-12-23T07:26:21.120,"['/pipeline/   # ansible playbooks are here\n/pipeline/roles\n/pipeline/group_vars\n', 'cd /pipeline\nansible-playbook deploy_app.yml\n', '/pipeline/prod/group_vars/all.yml\n/pipeline/dev/group_vars/all.yml\n']"
115,1369,1353,CC BY-SA 3.0,2017-06-18T20:03:30.107,"<p>You'll notice that <a href=""https://docs.ansible.com/ansible/playbooks_best_practices.html#content-organization"" rel=""noreferrer"">the official recommendations for directory layout</a> put all of the playbooks at the root level.  This is intentional, as Ansible doesn't handle other schemes well.</p>

<p>You <em>can</em> put playbooks in a subdirectory, as you've started to do, but that will require (as you've already found) the use of relative paths from the playbooks to any other resources they use; Ansible uses the playbook path to start its search, that's just how it's written.  For the most part, that's just what you get to deal with when you make the choice to move where playbooks live.</p>

<p>However, you seem to have more nesting than you should:</p>

<pre><code>---
- hosts:  aws_instance.jenkins-agents
  user:   ec2-user
  vars_files:
    - ../../../vars/main.yaml
    - ../../../vars/vault.yaml
  ...
</code></pre>

<p>Why are you navigating up <em>three</em> directories?  I'd expect a layout that's like the official one, but with one subfolder for playbooks; then you'd end up with just</p>

<pre><code>---
- hosts:  aws_instance.jenkins-agents
  user:   ec2-user
  vars_files:
    - ../vars/main.yaml
    - ../vars/vault.yaml
  ...
</code></pre>

<p>which is a much more minor change.</p>

<hr>

<p>Secondly, it's pretty rare that you actually want to use <code>vars_files</code>.  Most variables used in Ansible either vary based on the host (and thus should go in <code>group_vars</code>/<code>host_vars</code> in the project root) or are role-specific (and thus should go in <code>vars</code>/<code>defaults</code> in the role directory).  A few documentation links:</p>

<ul>
<li><a href=""https://docs.ansible.com/ansible/intro_inventory.html#splitting-out-host-and-group-specific-data"" rel=""noreferrer"">https://docs.ansible.com/ansible/intro_inventory.html#splitting-out-host-and-group-specific-data</a></li>
<li><a href=""https://docs.ansible.com/ansible/playbooks_roles.html#roles"" rel=""noreferrer"">https://docs.ansible.com/ansible/playbooks_roles.html#roles</a></li>
<li><a href=""https://docs.ansible.com/ansible/playbooks_roles.html#role-default-variables"" rel=""noreferrer"">https://docs.ansible.com/ansible/playbooks_roles.html#role-default-variables</a></li>
</ul>

<p>Personally, I think it's best to have as little as possible in your playbooks, but delegate everything out to roles.  Here's an example entire playbook in your setup:</p>

<pre><code>- hosts: aws_instance.jenkins-agents
  roles:
    - ../roles/jenkins_agent
</code></pre>

<p>This gives you far more flexibility for re-use.</p>

<p>And if you find yourself not wanting to use relative paths for roles, you can override <a href=""https://docs.ansible.com/ansible/intro_configuration.html#roles-path"" rel=""noreferrer""><code>roles_path</code></a> in an <code>ansible.cfg</code> in the root directory where you run your Ansible commands from.</p>
",960,2017-06-18T20:03:30.107,"['---\n- hosts:  aws_instance.jenkins-agents\n  user:   ec2-user\n  vars_files:\n    - ../../../vars/main.yaml\n    - ../../../vars/vault.yaml\n  ...\n', '---\n- hosts:  aws_instance.jenkins-agents\n  user:   ec2-user\n  vars_files:\n    - ../vars/main.yaml\n    - ../vars/vault.yaml\n  ...\n', '- hosts: aws_instance.jenkins-agents\n  roles:\n    - ../roles/jenkins_agent\n']"
116,1385,1383,CC BY-SA 3.0,2017-06-21T08:03:25.903,"<p>It turned out to be an issue with port mapping. After mapping local machine port 8888 to docker's 8888 I could launch the program in browser.</p>

<pre><code>sudo docker run -p 8888:8888 jupyter/scipy-notebook 
</code></pre>
",2524,2017-06-21T08:03:25.903,['sudo docker run -p 8888:8888 jupyter/scipy-notebook \n']
117,1413,1390,CC BY-SA 3.0,2017-06-23T12:21:42.457,"<p>The <a href=""https://docs.docker.com/compose/compose-file/#environment"" rel=""noreferrer"">Docker Compose file reference states</a>, that environment variables are defined as <code>VARIABLE=value</code> array elements. For your case, the docker-compose.yml file would need to be changed to this:</p>

<pre><code>version: '3'
services:
  server:
    ports:
     - 13045:3000
    environment:
     - NODE_CONFIG='{""DATABASE_URL"":""http://db:5984""}'
</code></pre>
",3249,2017-06-23T12:21:42.457,"['version: \'3\'\nservices:\n  server:\n    ports:\n     - 13045:3000\n    environment:\n     - NODE_CONFIG=\'{""DATABASE_URL"":""http://db:5984""}\'\n']"
118,1444,1443,CC BY-SA 3.0,2017-06-27T12:29:53.823,"<p>Because fsevents is an optional dependency, the solution has been here:</p>

<pre><code>npm install --no-optional karma-phantomjs-launcher
</code></pre>
",707,2017-06-27T13:31:13.320,['npm install --no-optional karma-phantomjs-launcher\n']
119,1464,1463,CC BY-SA 3.0,2017-06-30T14:45:13.787,"<p>It appears that <a href=""https://forge.puppet.com/jhoblitt/policykit/readme"" rel=""nofollow noreferrer"">there is</a>. For future reference, the best place to look for puppet modules generally is to search <a href=""https://forge.puppet.com"" rel=""nofollow noreferrer"">Puppet Forge</a>. That is the central repository for modules and any module uploaded there can be installed using puppet by typing:</p>

<pre><code>puppet module install jhoblitt-policykit
</code></pre>

<p>But obviously, you will want to update the name of the module to be whatever you want to install.</p>
",2845,2017-06-30T14:45:13.787,['puppet module install jhoblitt-policykit\n']
120,1477,1124,CC BY-SA 3.0,2017-07-04T07:44:58.000,"<p>You can have conditionals in your declarative pipeline by using the <strong>when</strong>-block inside a stage. There is a plugin called ""environment injector"" which lets you set variables outside of the pipeline-script which is nice. Also if you put the step below the other steps, it won't execute if they fail.</p>

<pre><code> when {
    environment name: 'pushArtifact', value: 'true'
  }
  steps{
     //push artifact  
  }
</code></pre>
",3377,2017-07-04T07:44:58.000,"["" when {\n    environment name: 'pushArtifact', value: 'true'\n  }\n  steps{\n     //push artifact  \n  }\n""]"
121,1491,1487,CC BY-SA 3.0,2017-07-07T10:39:02.610,"<p>You need to collect static assets in your Django</p>

<pre><code>cd /opt/graphite/webapp &amp;&amp; PYTHONPATH=/opt/graphite/webapp django-admin.py collectstatic --noinput --settings=graphite.settings
</code></pre>

<p>Static files will be installed in <strong>/opt/graphite/static</strong>.
Then you need to configure your webserver to serve them directly.
For Nginx something like:</p>

<pre><code>location /static {
   root /opt/graphite
}
</code></pre>
",3431,2017-07-07T10:39:02.610,"['cd /opt/graphite/webapp && PYTHONPATH=/opt/graphite/webapp django-admin.py collectstatic --noinput --settings=graphite.settings\n', 'location /static {\n   root /opt/graphite\n}\n']"
122,1497,1490,CC BY-SA 4.0,2017-07-10T07:36:24.760,"<p><strong>Management Summary</strong></p>

<p>Set the <code>pull_policy</code> to <code>""never""</code> in the <code>[runners.docker]</code> section by calling:</p>

<pre><code>docker exec -it gitlab-runner \
  vi /etc/gitlab-runner/config.toml
</code></pre>

<p><strong>Detailed Description</strong></p>

<p>It seemed the problem was a confusion with images and mounted volumes.</p>

<p>The documentation says to configure runners in:</p>

<pre><code>/etc/gitlab-runner/config.toml
</code></pre>

<p>Which I did, but on the host machine.
When running <code>gitlab-runner</code> in a docker container, it mounts a volume:</p>

<pre><code>... -v /srv/gitlab-runner/config:/etc/gitlab-runner ...
</code></pre>

<p>This means, that the configuration file in <code>/etc/...</code> in the container is mounted to <code>/srv/...</code> on the host machine.</p>

<p>In this file the <code>pull_policy</code> was not set, which defaults to <code>always</code>, what ultimately caused my problem in the first place.</p>
",3427,2020-03-03T11:29:18.033,"['docker exec -it gitlab-runner \\\n  vi /etc/gitlab-runner/config.toml\n', '/etc/gitlab-runner/config.toml\n', '... -v /srv/gitlab-runner/config:/etc/gitlab-runner ...\n']"
123,1522,1245,CC BY-SA 3.0,2017-07-11T22:19:03.957,"<p>State and pillar environments are set independently.</p>

<p>Specifing</p>

<pre><code>environment: prod
</code></pre>

<p>in the minion configuration will force the minion to use the prod state, but it will still use the default pillar data. To select a pillar environment you will also need:</p>

<pre><code>pillarenv: prod
</code></pre>

<p>This also does not work in old versions of salt and <a href=""https://github.com/saltstack/salt/issues/36629"" rel=""nofollow noreferrer"">is only supported with pillar.get as of salt version 2016.3,</a> so you may be in need of an update.</p>
",2845,2017-07-11T22:19:03.957,"['environment: prod\n', 'pillarenv: prod\n']"
124,1524,1523,CC BY-SA 3.0,2017-07-11T23:12:44.230,"<p>The answer is that you can't directly. You have to set a grain on the minions first by doing something similar to:</p>

<pre><code>salt '*' cmd.run 'grep environment /etc/salt/minion | awk ""{print \""environment: \"" \$2}"" &gt;&gt; /etc/salt/grains'
salt '*' saltutil.sync_grains
salt -G environment:prod cmd.run 'df -h'
</code></pre>
",2845,2017-07-11T23:12:44.230,"['salt \'*\' cmd.run \'grep environment /etc/salt/minion | awk ""{print \\""environment: \\"" \\$2}"" >> /etc/salt/grains\'\nsalt \'*\' saltutil.sync_grains\nsalt -G environment:prod cmd.run \'df -h\'\n']"
125,1532,1527,CC BY-SA 3.0,2017-07-13T09:25:33.673,"<p>Eventually, using the <code>docker -D -l debug</code> setting for the client  I have found the log outputs (apparently currently there are no debug level messages implemented <a href=""https://github.com/moby/moby/issues/6927"" rel=""nofollow noreferrer"">as reported</a>.</p>

<pre><code>C:\Users\user\AppData\Local\Docker\log.txt
</code></pre>
",707,2017-07-13T09:25:33.673,['C:\\Users\\user\\AppData\\Local\\Docker\\log.txt\n']
126,1539,1336,CC BY-SA 3.0,2017-07-13T21:57:28.583,"<p>Few ideas to help you</p>

<ol>
<li><p>When you define a ""CodeBuild"" project, you can specify which base image it will use to execute your commands. The one you are using is not Ubuntu yet you are trying <code>apt-get</code>. Try a different base image.</p></li>
<li><p>Provide us with a better log stream.</p></li>
</ol>

<h3>Exporting Logs from CloudWatch</h3>

<p>I found that the easiest way is to export logs through command-line:</p>

<ul>
<li>click on 'View Logs' link, to find out your Log Group and Log Stream</li>
<li>install ""awscli"" and ""jq""</li>
</ul>

<p>Run substituting your log-group-name and -log-stream-name:</p>

<pre><code>aws logs get-log-events --log-group-name /aws/codebuild/Dumper  \
    --log-stream-name 0bd74b8c-74b9-4f9b-b275-167b45901aa3 | \
    jq '.events[].message' -r | grep -v '^$'
</code></pre>

<p>This should give you the output, which you can include in the question.</p>
",3498,2017-08-16T15:56:48.043,"[""aws logs get-log-events --log-group-name /aws/codebuild/Dumper  \\\n    --log-stream-name 0bd74b8c-74b9-4f9b-b275-167b45901aa3 | \\\n    jq '.events[].message' -r | grep -v '^$'\n""]"
127,1548,1546,CC BY-SA 3.0,2017-07-16T23:00:29.457,"<p>Currently my team uses Jira, and it's RapidBoard agile thing.  We aren't using real agile, but it's nice to schedule work loads for the next week.</p>

<p>Jira can be super complex, but we Have our tickets set up to:</p>

<pre><code>New --&gt;InProgress --&gt;Done
     +-&gt; Won't Do
</code></pre>

<p>It can be linked to github or to Bitstream, etc.  which is nice.  If you want more complex code reviews, Atlassian also has a code review tool (Crucible) that I really liked (used it at my previous job).</p>

<p>The real trick is to have the ability to schedule things and to track what state they are in.</p>

<p>The hardest part for us was to get people to break up large projects into multiple smaller tickets to better track progress.</p>
",3529,2017-07-16T23:00:29.457,"[""New -->InProgress -->Done\n     +-> Won't Do\n""]"
128,1554,1553,CC BY-SA 3.0,2017-07-17T20:04:26.000,"<p>The reason for the failure is that the server in question, unlike all the others, had sftp disabled. 
Why the error messages are what they are, I don't know (why the errant <code>scp transfer mechanism failed</code>?), but I don't have time right now to investigate with the debug option enabled.</p>

<p>But that was the issue, and adding <code>scp_if_ssh=True</code> to the <code>[ssh_connection]</code> section of my <code>ansible.cfg</code> solved the issue:</p>

<pre><code>[ssh_connection]                                                                   
scp_if_ssh=True 
</code></pre>
",2735,2017-07-17T20:04:26.000,['[ssh_connection]                                                                   \nscp_if_ssh=True \n']
129,1559,1558,CC BY-SA 3.0,2017-07-18T10:16:32.433,"<p>Yes, that is possible according to <a href=""https://thornelabs.net/2014/05/22/include-additional-content-in-ansible-template-file.html"" rel=""noreferrer"">this post</a>.</p>

<p>When a second jinja template was created and this was included in the base jinja it was called.</p>

<pre><code>{% include ""checks/subdue.j2"" %}
</code></pre>
",210,2017-07-18T10:16:32.433,"['{% include ""checks/subdue.j2"" %}\n']"
130,1560,1551,CC BY-SA 3.0,2017-07-19T07:31:41.617,"<p>An empty of non existent environment variable is the same thing, there's no reason Docker do not allow you to pass an empty variable as it could be a valid use case.</p>

<p>It's up to your responsibility to ensure needed environment variables are there and give an error message back when not.</p>

<p>Something along the line of:</p>

<pre><code>RUN 'if [ -z ""$AN_ENV_VAR"" ]; then echo 'Environment variable AN_ENV_VAR must be specified. Exiting.'; exit 1; fi'
</code></pre>

<p>You can play with the exit code to automate some actions on failure around your <code>docker build</code> command.</p>
",13,2017-07-19T07:31:41.617,"['RUN \'if [ -z ""$AN_ENV_VAR"" ]; then echo \'Environment variable AN_ENV_VAR must be specified. Exiting.\'; exit 1; fi\'\n']"
131,1565,1537,CC BY-SA 3.0,2017-07-19T15:27:17.640,"<p>Turns out you can hit the following URL to get an XML output of all currently running builds, including their build numbers. </p>

<pre><code>http://jenkinsURL/computer/api/xml?tree=computer[executors[currentExecutable[url]],oneOffExecutors[currentExecutable[url]]]&amp;xpath=//url&amp;wrapper=builds
</code></pre>

<p>I <code>grep</code>ed it for a count and used that for my calculations.</p>
",736,2017-07-19T15:27:17.640,"['http://jenkinsURL/computer/api/xml?tree=computer[executors[currentExecutable[url]],oneOffExecutors[currentExecutable[url]]]&xpath=//url&wrapper=builds\n']"
132,1576,1575,CC BY-SA 3.0,2017-07-21T07:49:10.183,"<p>Your python problem is the <code>\n</code> after the commands, <code>write</code> already append a newline, so your script does the following:</p>

<pre><code>$cred = Get-Credential # Start the command
# This line is ignored as extraneous after Get-Credential, but you can see it in your output.
Administrator # Send proprely to the User: prompt
# Sent to the Password: prompt
Password # Send to the shell input, causing the error at end of your log.
</code></pre>

<p>Now that's a quite hard way to automate the credential object in powershell, usually the object is build by other way like described in <a href=""https://blogs.technet.microsoft.com/gary/2009/07/23/creating-a-ps-credential-from-a-clear-text-password-in-powershell/"" rel=""noreferrer"">this blog post</a> (quoting here for completeness):</p>

<pre><code>$password = ""mypassword"" | ConvertTo-SecureString -asPlainText -Force
$username = ""nwtraders\administrator"" 
$credential = New-ObjectSystem.Management.Automation.PSCredential($username,$password)
</code></pre>

<p>And used as such:</p>

<pre><code>Get-WMIObject win32_logicaldisk -ComputerName Server1 -Credential $credential
</code></pre>
",13,2017-07-21T07:49:10.183,"['$cred = Get-Credential # Start the command\n# This line is ignored as extraneous after Get-Credential, but you can see it in your output.\nAdministrator # Send proprely to the User: prompt\n# Sent to the Password: prompt\nPassword # Send to the shell input, causing the error at end of your log.\n', '$password = ""mypassword"" | ConvertTo-SecureString -asPlainText -Force\n$username = ""nwtraders\\administrator"" \n$credential = New-ObjectSystem.Management.Automation.PSCredential($username,$password)\n', 'Get-WMIObject win32_logicaldisk -ComputerName Server1 -Credential $credential\n']"
133,1578,1577,CC BY-SA 3.0,2017-07-21T19:08:44.110,"<p>Can't answer 1 (I always thought it just uses the default /bin/sh unless specified otherwise?).</p>

<ol start=""2"">
<li><p>It will make the connection more than 10 times.  A single task will typically have an SCP or SFTP connection to copy the taskfile that'll get remotely executed, then another connection to trigger the script.  You can monitor this happening by running your playbook with -vvv, such as:</p>

<pre><code>ansible-playbook deploy_app.yml -u maplebird -vvv
</code></pre>

<p>3rd-level verbosity shows all connections to client.</p></li>
<li><p>By default, Ansible will execute tasks concurrently on all hosts up to the max configured number of forks.  So, it'll run task 1 on both hosts, then it'll run task 2 on both hosts, etc.  Forks are defined in ansible.cfg, and default to 5.  Change this variable to a higher number or comment it out:</p>

<pre><code>forks = 5
</code></pre>

<p>Optionally, you can also do a rolling batch when running playbooks by specifying the <code>serial</code> option in the playbook.  This will only concurrently execute tasks for however many hosts you've defined.</p>

<p>Say you're running a playbook against 5 hosts, and have the serial option set.  With serial = 1, it will run the full playbook 1 host at a time.  With serial = 2, it will run hosts 1 &amp; 2, then hosts 2 &amp; 3, then host 5.  Example:</p>

<pre><code>name: deploy to all webservers
hosts: webservers
serial: 2
roles:
   - deploy_application
</code></pre></li>
</ol>

<p>More reading:</p>

<p>Serial (rolling) playbook runs:</p>

<ul>
<li><a href=""http://docs.ansible.com/ansible/latest/playbooks_delegation.html#rolling-update-batch-size"" rel=""noreferrer"">http://docs.ansible.com/ansible/latest/playbooks_delegation.html#rolling-update-batch-size</a></li>
</ul>

<p>Forks:</p>

<ul>
<li><a href=""http://docs.ansible.com/ansible/latest/intro_configuration.html#forks"" rel=""noreferrer"">http://docs.ansible.com/ansible/latest/intro_configuration.html#forks</a></li>
</ul>

<p>Hope this helps.</p>
",3175,2017-07-21T19:08:44.110,"['ansible-playbook deploy_app.yml -u maplebird -vvv\n', 'forks = 5\n', 'name: deploy to all webservers\nhosts: webservers\nserial: 2\nroles:\n   - deploy_application\n']"
134,1581,1580,CC BY-SA 3.0,2017-07-22T12:25:11.827,"<p>TLDR; set workers' memory to 4G.</p>

<p>I reduced the test to the build-in Pi calculation:</p>

<pre><code>./bin/run-example SparkPi 10
</code></pre>

<p>And got the same result; apparently 1G memory is insufficient even for simplest experiments.
Increasing both master and workers memory to 4G and the problematic behaviour was not reproducible. However before the systems start computation the message still could appear but just once, seems it is printed in a waiting loop.</p>
",707,2017-07-23T19:37:11.643,['./bin/run-example SparkPi 10\n']
135,1599,1594,CC BY-SA 3.0,2017-07-26T18:18:50.570,"<p>How about user-data ?</p>

<p>I believe adding the ""#cloud-boothook"" allow to force the user-data to run at every restart.</p>

<pre><code>#cloud-boothook
#!/bin/bash
echo 'test' &gt; /home/ec2-user/user-script-output.txt
</code></pre>

<p>If so, you could fix your sudo scripts hopefully... or install / add AWS run commands configuration <a href=""https://aws.amazon.com/blogs/aws/new-ec2-run-command-remote-instance-management-at-scale/"" rel=""noreferrer"">https://aws.amazon.com/blogs/aws/new-ec2-run-command-remote-instance-management-at-scale/</a></p>

<p>For sure if it is an EBS Drive, you can detach &amp; fix and then re-attach on the original system. A bit of a pain though.</p>
",3675,2017-07-26T18:18:50.570,"[""#cloud-boothook\n#!/bin/bash\necho 'test' > /home/ec2-user/user-script-output.txt\n""]"
136,1610,1577,CC BY-SA 3.0,2017-07-27T15:39:15.040,"<p><em>(1) Which shell does Ansible use?</em></p>

<p>Ansible uses <code>/bin/sh</code> by default. On many *nix systems including RHEL / CentOS, <code>/bin/sh</code> is <code>bash</code> - however, <a href=""https://wiki.ubuntu.com/DashAsBinSh"" rel=""nofollow noreferrer"">on Ubuntu/Debian it's <code>dash</code></a> which is much more basic.</p>

<h3>Making Ansible use bash</h3>

<p>It should be possible to change this with the <code>executable = /bin/bash</code> config option <a href=""http://docs.ansible.com/ansible/latest/intro_configuration.html#executable"" rel=""nofollow noreferrer"">in ansible.cfg</a> and possibly also setting <a href=""http://docs.ansible.com/ansible/latest/intro_inventory.html"" rel=""nofollow noreferrer"">ansible_shell_type</a> in the inventory. </p>

<p>But in practice (on Ansible 2.2.2 and higher) I and <a href=""https://github.com/ansible/ansible/issues/1238#issuecomment-200362771"" rel=""nofollow noreferrer"">others</a> have found that setting <code>executable</code> in <code>ansible.cfg</code> doesn't work (whether in <code>become</code> mode or not).</p>

<p>An approach that works well, but does mean a bit more code per task, is to write this:</p>

<pre><code>- shell:
    echo hello from $0
  args:
    executable: /bin/bash
</code></pre>

<p>This should say <code>hello from /bin/bash</code>, indicating the shell is correct.</p>

<p>If you need to use <code>rvm</code>, <code>rbenv</code>, <code>pyenv</code> or similar tools that <a href=""https://github.com/rbenv/rbenv#installation"" rel=""nofollow noreferrer"">require</a> a previous <code>source ~/.bash_profile</code> (as with an interactive shell), you will need to <a href=""https://github.com/ansible/ansible/issues/1238#issuecomment-57797275"" rel=""nofollow noreferrer"">use a wrapper script</a> or <a href=""https://github.com/ansible/ansible/issues/4854#issuecomment-182582413"" rel=""nofollow noreferrer"">invoke bash within the shell task</a>.</p>
",519,2017-07-28T07:31:06.933,['- shell:\n    echo hello from $0\n  args:\n    executable: /bin/bash\n']
137,1612,1593,CC BY-SA 3.0,2017-07-28T06:22:39.313,"<p>Although i have not found out what leads to this. But i am finally able to login into my instance by following these steps:
1. As you are logged in create a user in the instance and give it a password.</p>

<pre><code>$ adduser user1
$ passwd user1
</code></pre>

<p>2. Enable password authentication in /etc/sshd_config file.
3. Login with the new user.</p>

<p>Interestingly, this user does not gets locked out as the centos user.</p>
",3178,2017-07-28T06:22:39.313,['$ adduser user1\n$ passwd user1\n']
138,1633,1629,CC BY-SA 3.0,2017-07-31T08:18:56.290,"<p>I believe you will need to do this programmatically using the AWS SDK as described in <a href=""http://docs.aws.amazon.com/sns/latest/dg/sms_publish-to-phone.html#sms_publish_sdk"" rel=""nofollow noreferrer"">Sending a Message (AWS SDKs)</a>. Here is a quote a from it:</p>

<blockquote>
  <p>To send an SMS message by using one of AWS SDKs, use the action in
  that SDK that corresponds to the Publish request in the Amazon SNS
  API. With this request, you can send an SMS message directly to a
  phone number</p>
  
  <p>...</p>
  
  <p><strong>Sending a Message (AWS SDK for Java)</strong></p>
  
  <p>The following example uses the publish method of the AmazonSNSClient
  class to send a message directly to a phone number:</p>

<pre><code>public static void main(String[] args) {
        AmazonSNSClient snsClient = new AmazonSNSClient();
        String message = ""My SMS message"";
        String phoneNumber = ""+1XXX5550100"";
        Map&lt;String, MessageAttributeValue&gt; smsAttributes = 
                new HashMap&lt;String, MessageAttributeValue&gt;();
        //&lt;set SMS attributes&gt;
        sendSMSMessage(snsClient, message, phoneNumber, smsAttributes);
}

public static void sendSMSMessage(AmazonSNSClient snsClient, String message, 
      String phoneNumber, Map&lt;String, MessageAttributeValue&gt; smsAttributes) {
        PublishResult result = snsClient.publish(new PublishRequest()
                        .withMessage(message)
                        .withPhoneNumber(phoneNumber)
                        .withMessageAttributes(smsAttributes));
        System.out.println(result); // Prints the message ID.
</code></pre>
</blockquote>
",735,2018-01-09T12:59:40.623,"['public static void main(String[] args) {\n        AmazonSNSClient snsClient = new AmazonSNSClient();\n        String message = ""My SMS message"";\n        String phoneNumber = ""+1XXX5550100"";\n        Map<String, MessageAttributeValue> smsAttributes = \n                new HashMap<String, MessageAttributeValue>();\n        //<set SMS attributes>\n        sendSMSMessage(snsClient, message, phoneNumber, smsAttributes);\n}\n\npublic static void sendSMSMessage(AmazonSNSClient snsClient, String message, \n      String phoneNumber, Map<String, MessageAttributeValue> smsAttributes) {\n        PublishResult result = snsClient.publish(new PublishRequest()\n                        .withMessage(message)\n                        .withPhoneNumber(phoneNumber)\n                        .withMessageAttributes(smsAttributes));\n        System.out.println(result); // Prints the message ID.\n']"
139,1638,1626,CC BY-SA 3.0,2017-07-31T18:10:56.163,"<p>Amazon's IAM roles generally grant a role access to a particular ARN (Amazon Resource Name). Amazon notes <a href=""http://docs.aws.amazon.com/AmazonS3/latest/dev/s3-arn-format.html"" rel=""noreferrer"">on their pages</a> that for S3 a resource</p>

<blockquote>
  <p>...can be a bucket-name or a bucket-name/object-key.</p>
</blockquote>

<p><a href=""https://aws.amazon.com/blogs/security/writing-iam-policies-how-to-grant-access-to-an-amazon-s3-bucket/"" rel=""noreferrer"">They also provide a helpful example for doing just this</a> which appears as follows:</p>

<pre><code>{
  ""Version"": ""2012-10-17"",
  ""Statement"": [
    {
      ""Effect"": ""Allow"",
      ""Action"": [""s3:ListBucket""],
      ""Resource"": [""arn:aws:s3:::test""]
    },
    {
      ""Effect"": ""Allow"",
      ""Action"": [
        ""s3:PutObject"",
        ""s3:GetObject"",
        ""s3:DeleteObject""
      ],
      ""Resource"": [""arn:aws:s3:::test/*""]
    }
  ]
}
</code></pre>
",2845,2017-07-31T18:10:56.163,"['{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [""s3:ListBucket""],\n      ""Resource"": [""arn:aws:s3:::test""]\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""s3:PutObject"",\n        ""s3:GetObject"",\n        ""s3:DeleteObject""\n      ],\n      ""Resource"": [""arn:aws:s3:::test/*""]\n    }\n  ]\n}\n']"
140,1643,1637,CC BY-SA 3.0,2017-08-02T01:51:13.620,"<p>For building docker image using <code>docker-compose</code> you can add <code>build:</code> field to the service you want to build and assign to it the path of the <code>Dockerfile</code> for example:</p>

<pre><code>version: '2'
services:
  web:
    build: .
    ports:
     - ""8080:80""
    volumes:
     - /project:/var/www/html
</code></pre>

<p>This example define a web service which:</p>

<ul>
<li>Uses an image that’s built from the <code>Dockerfile</code> in the current directory.</li>
<li>Forwards the exposed port 80 on the container to port 8080 on the
host machine</li>
<li>Mounts the project directory on the host to <code>/project</code> inside the
container, allowing you to modify the code without having to rebuild
the image.</li>
</ul>

<p>To build the image, simply issue the build command via docker-compose, as such: <code>docker-compose build</code>.</p>
",3752,2017-10-31T22:11:56.537,"['version: \'2\'\nservices:\n  web:\n    build: .\n    ports:\n     - ""8080:80""\n    volumes:\n     - /project:/var/www/html\n']"
141,1645,1640,CC BY-SA 3.0,2017-08-02T02:01:22.387,"<p>The case is <code>dpkg-reconfigure tzdata</code> simply creates <code>/etc/localtime</code> as a copy, hardlink or symlink (a symlink is preferred) to a file in <code>/usr/share/zoneinfo</code>. So it is possible to do this entirely from your <code>Dockerfile</code>. Consider:</p>

<pre><code>ENV TZ=Asia/Kolkata
RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezone
</code></pre>

<p>And as a bonus, <code>TZ</code> will be set correctly in the container as well.</p>

<p>This is also distribution-agnostic, so it works with pretty much anything Linux.</p>

<p>The original answer: <a href=""https://serverfault.com/questions/683605/docker-container-time-timezone-will-not-reflect-changes"">https://serverfault.com/questions/683605/docker-container-time-timezone-will-not-reflect-changes</a></p>
",3752,2017-08-02T04:35:13.420,['ENV TZ=Asia/Kolkata\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone\n']
142,1657,1655,CC BY-SA 3.0,2017-08-03T17:33:01.773,"<p>First, <a href=""https://stackoverflow.com/questions/40350456/docker-any-way-to-list-open-sockets-inside-a-running-docker-container"">confirm that the container is actually listening for connections and has properly bound to the interface</a>. If not, you probably need to fix the <code>bind-address=</code> and/or <code>port=</code> directives in your my.cnf.</p>

<p>Otherwise, you probably have an issue with your GRANTs. Check that the IP/subnet is correctly authorized in the mysql.user table with the command</p>

<pre><code>select user,host from mysql.user
</code></pre>

<p>If the host field is incorrect, you will need to fix it using a UPDATE</p>
",2845,2017-08-03T17:33:01.773,"['select user,host from mysql.user\n']"
143,1659,1658,CC BY-SA 3.0,2017-08-03T19:39:08.507,"<p>AFAIK there is no built-in module for this purpose, but you can use <code>shell</code> + <code>nc</code>:</p>

<pre><code>---
- hosts: all
  tasks:
    - shell: nc -z -w 1 -G 1 my.hostname.com {{ item }} || echo ""Port {{ item }} is closed""
      with_items: [80,443,8443]
</code></pre>
",3509,2017-08-03T19:39:08.507,"['---\n- hosts: all\n  tasks:\n    - shell: nc -z -w 1 -G 1 my.hostname.com {{ item }} || echo ""Port {{ item }} is closed""\n      with_items: [80,443,8443]\n']"
144,1661,1655,CC BY-SA 3.0,2017-08-04T03:37:04.347,"<p>Since the response is <code>Access denied for user</code> so the port and the ip address is correct.</p>

<p>I guess the only issue as @James said  will be in the permission, you have to allow <code>root</code> access to mysql from elk and php containers, you can do it in easy way but it's not secure:</p>

<pre><code>GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'password';
</code></pre>

<ul>
<li><code>%</code>: mean match all</li>
</ul>

<p>or you can specify who has the access per domain name or ip:</p>

<pre><code>GRANT ALL PRIVILEGES ON *.* TO 'root'@'172.18.0.2' IDENTIFIED BY 'password';
GRANT ALL PRIVILEGES ON *.* TO 'root'@'172.18.0.3' IDENTIFIED BY 'password';
</code></pre>

<p>PS: don't forget to change the password to match you root password</p>
",3752,2017-08-04T03:37:04.347,"[""GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'password';\n"", ""GRANT ALL PRIVILEGES ON *.* TO 'root'@'172.18.0.2' IDENTIFIED BY 'password';\nGRANT ALL PRIVILEGES ON *.* TO 'root'@'172.18.0.3' IDENTIFIED BY 'password';\n""]"
145,1664,1658,CC BY-SA 4.0,2017-08-04T13:34:02.313,"<p>You can use the Ansible <a href=""https://docs.ansible.com/ansible/latest/collections/ansible/builtin/wait_for_module.html"" rel=""nofollow noreferrer"">wait_for</a> module which checks a specific TCP port is open.</p>
<p>Since in this case, all ports should be open already, we can use a minimal no. of retries, just enough to cover network issues:</p>
<pre><code>- name: Check all port numbers are accessible from the current host
  wait_for:
    host: mywebserver.com
    port: &quot;{{ item }}&quot;
    state: started         # Port should be open
    delay: 0               # No wait before first check (sec)
    timeout: 3             # Stop checking after timeout (sec)
  ignore_errors: yes
  with_items:
    - 443
    - 80
    - 80443
</code></pre>
<p>By default, Ansible will check once every second (configurable in Ansible 2.3 using the <code>sleep</code> attribute), so this will check 3 times per port.</p>
<p>Run this in a playbook against your inventory of 400+ hosts - Ansible will check in parallel that all hosts can reach <code>mywebserver.com</code> on those ports.</p>
<ul>
<li>the parallelism is subject to the <a href=""http://docs.ansible.com/ansible/latest/intro_configuration.html#forks"" rel=""nofollow noreferrer"">forks setting</a> in your <code>ansible.cfg</code>.</li>
</ul>
<p>We use <code>ignore_errors: yes</code> here so that any errors are marked in red but do not stop execution.</p>
<p>Open ports are reported as <code>ok</code> items in output and closed ports are reported as <code>failed</code> (you must use <code>-vv</code> flag on <code>ansible-playbook</code> to see this output).</p>
<h3>Fine-tuning output</h3>
<p>If you want more specific output for the success and failure cases, the code must be more complex, adding a second task:</p>
<ul>
<li><code>wait_for</code> task must <code>register</code> a variable</li>
<li>the second task produces output using <code>debug</code> based on success/failure condition (e.g. using Jinja2 <a href=""https://stackoverflow.com/a/14215034/992887"">conditional expression</a>)</li>
<li>then you need to put both these tasks in an include file (without any <code>with_items</code> loop), and write a main playbook task that uses an <code>include</code> ... <code>with_items</code> to call the include file once per port.</li>
</ul>
",519,2020-10-16T06:32:18.853,"['- name: Check all port numbers are accessible from the current host\n  wait_for:\n    host: mywebserver.com\n    port: ""{{ item }}""\n    state: started         # Port should be open\n    delay: 0               # No wait before first check (sec)\n    timeout: 3             # Stop checking after timeout (sec)\n  ignore_errors: yes\n  with_items:\n    - 443\n    - 80\n    - 80443\n']"
146,1673,1671,CC BY-SA 3.0,2017-08-06T20:05:37.597,"<p>It seems that <code>docker build</code> opens a new shell and <code>export</code> is needed. The following command created a Linux binary:</p>

<pre><code>export GOOS=linux; go build hello-world.go
</code></pre>
",210,2017-08-06T20:05:37.597,['export GOOS=linux; go build hello-world.go\n']
147,1676,1322,CC BY-SA 3.0,2017-08-07T09:58:18.903,"<p><a href=""https://sensuapp.org/docs/0.28/reference/plugins.html#check-definition-attributes"" rel=""nofollow noreferrer"">https://sensuapp.org/docs/0.28/reference/plugins.html#check-definition-attributes</a></p>

<p>The <code>occurrences</code> as defined in the other answer was required (+1). The <code>refresh</code> and <code>interval</code> were needed as well.</p>

<p>Refresh and occurrences had to be assigned to a check. It was not needed to change the handlers.</p>

<pre><code>""a-check"": {
  ""command"": ""echo hello""
  ""occurrences"": 6,
  ""refresh"": 60,
  ""interval"": 10
},
</code></pre>

<p><a href=""https://gist.github.com/calebhailey/8a30a00c6aadfebf7f767444f0a3df49"" rel=""nofollow noreferrer"">https://gist.github.com/calebhailey/8a30a00c6aadfebf7f767444f0a3df49</a></p>

<p>The <code>interval</code> means after how many seconds a check is executed. The refresh means that after <code>60 seconds</code> a notification is sent and the occurrences mean that if within 60 seconds the event was triggered 6 times that a notification will be sent.</p>

<p>It seems like the formula is as follows:</p>

<p><code>occurrences</code> * <code>interval</code> = <code>refresh</code></p>

<p><code>10</code>          * <code>10</code>       = <code>100</code></p>
",210,2017-08-07T12:21:38.077,"['""a-check"": {\n  ""command"": ""echo hello""\n  ""occurrences"": 6,\n  ""refresh"": 60,\n  ""interval"": 10\n},\n']"
148,1677,1674,CC BY-SA 3.0,2017-08-07T11:29:35.587,"<p>One you use <a href=""https://chocolatey.org/packages/Opera"" rel=""nofollow noreferrer"">chocolatey</a> to install Opera. Upgrading is also supported:</p>

<pre><code>choco upgrade opera 
</code></pre>
",210,2017-08-07T11:29:35.587,['choco upgrade opera \n']
149,1685,1682,CC BY-SA 3.0,2017-08-08T21:19:32.067,"<p>The command being run by the <code>external</code> provider here is equivalent to the following:</p>

<pre><code>bash ""export ENC_HOOK_URL=$(aws --profile ${AWS_PROFILE} \
kms encrypt --key-id ${KMS_ALIAS} --plaintext ${HOOK_URL} --output json \
--region ${AWS_REGION})""
</code></pre>

<p>Bash is failing here because when used in this way it expects its first argument to be the filename of a script to run.</p>

<p>The <code>-c</code> option changes this interpretation so that it will instead expect this argument to be an <em>inline script</em> to run, which seems to be what you intended here. This could be expressed in the Terraform configuration like this:</p>

<pre><code>data ""external"" ""encrypt_url"" {  
  program = [""bash"", ""-c"", ""export ENC_HOOK_URL=$(aws --profile $${AWS_PROFILE} kms encrypt --key-id $${KMS_ALIAS} --plaintext $${HOOK_URL} --output json --region $${AWS_REGION})""]
}
</code></pre>

<p>Along with adding the <code>-c</code> option, it also seems like this script doesn't actually do anything, instead just assigning a result to a variable. Given that you asked the AWS command to produce JSON, I think perhaps the following will do what you want:</p>

<pre><code>data ""external"" ""encrypt_url"" {  
  program = [""bash"", ""-c"", ""aws --profile $${AWS_PROFILE} kms encrypt --key-id $${KMS_ALIAS} --plaintext $${HOOK_URL} --output json --region $${AWS_REGION}""]
}
</code></pre>

<p>In the interests of readability though, I'd recommend moving this command into an external script file (e.g. <code>encrypt_url.sh</code>) and then referencing it from the config:</p>

<pre><code>#!/usr/bin/env bash

aws --profile ${AWS_PROFILE} \
    kms encrypt --key-id ${KMS_ALIAS} \
                --plaintext ${HOOK_URL} \
                --output json \
                --region ${AWS_REGION}
</code></pre>

<p>...</p>

<pre><code>data ""external"" ""encrypt_url"" {  
  program = [""bash"", ""${path.module}/encrypt_url.sh""]
}
</code></pre>

<p>This avoids the need for escaping the dollar signs, allows you to edit it in your text editor's shell script highlighting mode, and allows the script to be easily run outside of Terraform for testing purposes.</p>
",2463,2017-08-08T21:19:32.067,"['bash ""export ENC_HOOK_URL=$(aws --profile ${AWS_PROFILE} \\\nkms encrypt --key-id ${KMS_ALIAS} --plaintext ${HOOK_URL} --output json \\\n--region ${AWS_REGION})""\n', 'data ""external"" ""encrypt_url"" {  \n  program = [""bash"", ""-c"", ""export ENC_HOOK_URL=$(aws --profile $${AWS_PROFILE} kms encrypt --key-id $${KMS_ALIAS} --plaintext $${HOOK_URL} --output json --region $${AWS_REGION})""]\n}\n', 'data ""external"" ""encrypt_url"" {  \n  program = [""bash"", ""-c"", ""aws --profile $${AWS_PROFILE} kms encrypt --key-id $${KMS_ALIAS} --plaintext $${HOOK_URL} --output json --region $${AWS_REGION}""]\n}\n', '#!/usr/bin/env bash\n\naws --profile ${AWS_PROFILE} \\\n    kms encrypt --key-id ${KMS_ALIAS} \\\n                --plaintext ${HOOK_URL} \\\n                --output json \\\n                --region ${AWS_REGION}\n', 'data ""external"" ""encrypt_url"" {  \n  program = [""bash"", ""${path.module}/encrypt_url.sh""]\n}\n']"
150,1686,1684,CC BY-SA 3.0,2017-08-08T22:10:49.920,"<p>There are a few different ways to achieve goals of this sort, each with some different tradeoffs. I'm going to describe the most common ones below.</p>

<hr>

<p>The simplest approach is to use <a href=""https://www.terraform.io/docs/configuration/resources.html#create_before_destroy"" rel=""noreferrer"">Terraform's <code>create_before_destroy</code> mechanism</a> with autoscaling groups. An example of this pattern is included in <a href=""https://www.terraform.io/docs/providers/aws/r/launch_configuration.html#using-with-autoscaling-groups"" rel=""noreferrer"">the <code>aws_launch_configuration</code> documentation</a>.</p>

<p>In this scenario, changing the AMI id causes the launch configuration to be re-created. Due to <code>create_before_destroy</code>, the new configuration is created first, then a new autoscaling group is created, adding the new instances to an attached ELB. The <code>min_elb_capacity</code> argument to <code>aws_autoscaling_group</code> can be used to ensure that a given number of instances are present and healthy in the attached ELB before considering the autoscaling group to be created, thus delaying the destruction of the old autoscaling group and launch configuration until the new one is serving requests.</p>

<p>The downside of this approach is the lack of control it represents. Since Terraform is thinking of the entire set of changes as a single run, it's impossible to pause after creating the new instances to allow other checks to be carried out before destroying the old ones. As a consequence, the ELB healthcheck is the only input to deciding if the new release is ""good"", and rolling back is impossible once the old resources have been destroyed.</p>

<hr>

<p>A second common approach is to adopt a sort of ""blue/green deployment"" pattern with explicit changes to two clusters. This is done by putting all of the per-release resources in a child module, and instantiating that module twice with different arguments. In the top-level module this would look something like the following:</p>

<pre><code>resource ""aws_elb"" ""example"" {
  instances = ""${concat(module.blue.ec2_instance_ids, module.green.ec2_instance_ids)}""

  # ...
}

module ""blue"" {
  source = ""./app""

  ami_id = ""ami-1234""
  count  = 10
}

module ""green"" {
  source = ""./app""

  ami_id = ""ami-5678""
  count  = 0
}
</code></pre>

<p>The principle of operation here is that in the ""steady state"" (no deployment in progress) only one of these modules has a non-zero count, and the other one has zero. During a deployment, they are both set to the same non-zero count, but with different <code>ami_id</code> values. Each deployment swaps which of the modules is the ""active"" module, with both being active <em>during</em> the deployment.</p>

<p>When using this approach, each step is a distinct Terraform operation:</p>

<ol>
<li>change count of the <em>inactive</em> module to nonzero and set its AMI id</li>
<li>apply the change with Terraform, thus activating the new module</li>
<li>verify that the new release is good</li>
<li>change count of the older module to zero</li>
<li>apply the change with Terraform, thus deactivating the old module</li>
</ol>

<p>Although this has more steps, it allows arbitrary verification and an arbitrary amount of time to pass during step 3. It also allows ""rolling back"" by resetting the previously-inactive cluster count to zero.</p>

<p>Since both the old and new clusters exist in the same configuration, there is the risk of using this pattern incorrectly and prematurely destroying the active cluster. This can be mitigated by carefully reviewing Terraform's plan to make sure it leaves the old cluster untouched, but Terraform itself can't guarantee this.</p>

<p>Also, since both clusters are using the same child module configuration, it can be tricky to make updates to that configuration while retaining the blue/green separation. If changes are made that would require Terraform to replace the running instances, it's necessary to temporarily have two copies of the module code on disk, make the <code>source</code> arguments point to separate copies, and make the change only to the copy used by the inactive module.</p>

<hr>

<p>The final approach I'll present is the most extreme and manual, but it does the best job of meeting your requirements and retaining control. This is, in effect, the most literal interpretation of your current CloudFormation workflow, and is a more concrete version of the approach you talked about in your question.</p>

<p>In this approach, there are two entirely-separate Terraform configurations, which I will call ""version-agnostic"" (things that must survive between versions, such as your ELB) and ""version-specific"" (the resources that are re-created for each new version).</p>

<p>The version-agnostic configuration will contain the ELB and will, as you suspected, export its id for consumption by the version-specific configuration:</p>

<pre><code>terraform {
  required_version = ""&gt;= 0.9.4""
  backend ""s3"" {
    bucket = ""example-company-terraform-state""
    key    = ""exampleapp/version-agnostic""
    region = ""eu-central-1""
  }
}

resource ""aws_elb"" ""example"" {
  # ...
}

output ""elb_id"" {
  value = ""${aws_elb.example.id}""
}
</code></pre>

<p>This configuration can be initialized, planned and applied as usual, creating an ELB with no attached instances to start.</p>

<p>The version-specific configuration would be similar to the ""app"" child module in the previous approach, but this time as a top-level module. The backend configuration for this module would omit the S3 key, since this will change for each new release as you expected:</p>

<pre><code>terraform {
  required_version = ""&gt;= 0.9.4""
  backend ""s3"" {
    bucket = ""example-company-terraform-state""
    region = ""eu-central-1""
  }
}
</code></pre>

<p>The specific key can then be set (or re-set) when running <code>terraform init</code>:</p>

<pre><code>$ terraform init -reconfigure -backend-config=""key=exampleapp/20170808-1""
</code></pre>

<p>Here I chose to use a ""current date, release index"" tuple as an identifier for a release. By running <code>terraform init</code> with a new value for this argument, an entirely separate state is created, independent of the last. Using <code>-reconfigure</code> tells Terraform that you don't wish to migrate the old state to the new, but rather to just switch directly to the new state path, possibly creating a new state in the process.</p>

<p>You can then run <code>terraform show</code> to confirm that indeed the state is empty (and thus operations won't affect existing resources) and then run a plan/apply cycle as normal.</p>

<p>Once you're satisfied with the new release, you can switch back to the previous version and destroy it.</p>

<p>The version-specific configuration will need the id of the ELB from the version-agnostic configuration in order to populate the <code>load_balancers</code> attribute of <code>aws_autoscaling_group</code>. To get access to this, we can use the <code>terraform_remote_state</code> data source to read the values from its state in S3:</p>

<pre><code>data ""terraform_remote_state"" ""version_agnostic"" {
  backend = ""s3""
  config {
    bucket = ""example-company-terraform-state""
    key    = ""exampleapp/version-agnostic""
    region = ""eu-central-1""
  }
}

resource ""aws_autoscaling_group"" ""example"" {
  # ...

  load_balancers = [""${data.terraform_remote_state.version_agnostic.elb_id}""]
}
</code></pre>

<p>With a system of this complexity, it would likely be best to run Terraform via some sort of wrapper script or orchestration to make the release process less onerous. For example, such a script might automatically generate the new version number to avoid the risk of a human operator mistyping the date or accidentally conflicting with an existing one. There's some recommendations and caveats about running Terraform via scripts in the guide <a href=""https://www.terraform.io/guides/running-terraform-in-automation.html"" rel=""noreferrer""><em>Running Terraform in Automation</em></a>.</p>

<hr>

<p>Although the third option here is the most direct mapping of your CloudFormation approach, the second option is more commonly used due to it striking a reasonable compromise between control and workflow overhead.</p>
",2463,2017-08-08T22:10:49.920,"['resource ""aws_elb"" ""example"" {\n  instances = ""${concat(module.blue.ec2_instance_ids, module.green.ec2_instance_ids)}""\n\n  # ...\n}\n\nmodule ""blue"" {\n  source = ""./app""\n\n  ami_id = ""ami-1234""\n  count  = 10\n}\n\nmodule ""green"" {\n  source = ""./app""\n\n  ami_id = ""ami-5678""\n  count  = 0\n}\n', 'terraform {\n  required_version = "">= 0.9.4""\n  backend ""s3"" {\n    bucket = ""example-company-terraform-state""\n    key    = ""exampleapp/version-agnostic""\n    region = ""eu-central-1""\n  }\n}\n\nresource ""aws_elb"" ""example"" {\n  # ...\n}\n\noutput ""elb_id"" {\n  value = ""${aws_elb.example.id}""\n}\n', 'terraform {\n  required_version = "">= 0.9.4""\n  backend ""s3"" {\n    bucket = ""example-company-terraform-state""\n    region = ""eu-central-1""\n  }\n}\n', '$ terraform init -reconfigure -backend-config=""key=exampleapp/20170808-1""\n', 'data ""terraform_remote_state"" ""version_agnostic"" {\n  backend = ""s3""\n  config {\n    bucket = ""example-company-terraform-state""\n    key    = ""exampleapp/version-agnostic""\n    region = ""eu-central-1""\n  }\n}\n\nresource ""aws_autoscaling_group"" ""example"" {\n  # ...\n\n  load_balancers = [""${data.terraform_remote_state.version_agnostic.elb_id}""]\n}\n']"
151,1687,1593,CC BY-SA 3.0,2017-08-09T11:27:15.030,"<p>One way I get locked out while developing is by changing the permissions on any of the directories or files associated with the keys used by <code>ssh</code>.  This happens to me when I untar files or run some installation script while initializing the machine that touches the <code>ec2-user</code> account.</p>

<p>Make sure the permissions are like:</p>

<pre><code>1&gt; ls -ld $HOME $HOME/.ssh
drwx------ 15 ec2-user ec2-user 4096 Aug  1 13:15 /home/ec2-user/
drwx------  2 ec2-user ec2-user 4096 Jun 10 11:18 /home/ec2-user/.ssh/

2&gt; ls -l $HOME/.ssh/authorized_keys
-rw------- 1 ec2-user ec2-user 385 Jun 10 11:18 /home/ec2-user/.ssh/authorized_keys
</code></pre>

<p>If not, and you are logged in as <code>ec2-user</code>, you can change them with </p>

<pre><code>sudo chown ec2-user:ec2-user ~ec2-user ~ec2-user/.ssh ~ec2-user/.ssh/authorized_keys
chmod 700 ~ec2-user ~ec2-user/.ssh
chmod 600 ~ec2-user/.ssh/authorized_keys
</code></pre>

<p>To protect myself against my own mistakes, I create a new user and copy the <code>ec2-user</code> key over.  That account is used as a backup and not part of any script.  Once I tested everything, I remove the account.</p>
",3851,2017-08-11T15:21:40.847,"['1> ls -ld $HOME $HOME/.ssh\ndrwx------ 15 ec2-user ec2-user 4096 Aug  1 13:15 /home/ec2-user/\ndrwx------  2 ec2-user ec2-user 4096 Jun 10 11:18 /home/ec2-user/.ssh/\n\n2> ls -l $HOME/.ssh/authorized_keys\n-rw------- 1 ec2-user ec2-user 385 Jun 10 11:18 /home/ec2-user/.ssh/authorized_keys\n', 'sudo chown ec2-user:ec2-user ~ec2-user ~ec2-user/.ssh ~ec2-user/.ssh/authorized_keys\nchmod 700 ~ec2-user ~ec2-user/.ssh\nchmod 600 ~ec2-user/.ssh/authorized_keys\n']"
152,1696,1695,CC BY-SA 3.0,2017-08-10T12:33:16.040,"<p>From your comment above: </p>

<blockquote>
  <p>The main difficult is launch the second lambda with a delay from the
  first one and without doing a pooling constantly</p>
</blockquote>

<p>As using SQS queues are an option for you, you can make <a href=""http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/MonitorSQSwithCloudWatch.html"" rel=""nofollow noreferrer"">CloudWatch alarms which can monitor for activity in the queues</a>, and link them up with SNS, which can be used as a trigger for LambdaB.</p>

<p>So, your flow can be:</p>

<pre><code>Lambda1 --&gt; SQS --&gt; CloudWatch metric linked to an alarm --&gt; SNS --&gt; Lambda2
</code></pre>
",46,2017-08-10T12:33:16.040,['Lambda1 --> SQS --> CloudWatch metric linked to an alarm --> SNS --> Lambda2\n']
153,1697,1692,CC BY-SA 3.0,2017-08-10T15:21:17.483,"<p>One could pass <a href=""https://docs.docker.com/v1.7/reference/run/"" rel=""nofollow noreferrer"">environment variables</a> when running docker, e.g.:</p>

<blockquote>
  <p>Additionally, the operator can set any environment variable in the
  container by using one or more -e flags, even overriding those
  mentioned above, or already defined by the developer with a Dockerfile
  ENV:</p>

<pre><code>$ docker run -e ""deep=purple"" --rm ubuntu /bin/bash -c export
</code></pre>
</blockquote>
",210,2017-08-10T15:21:17.483,"['$ docker run -e ""deep=purple"" --rm ubuntu /bin/bash -c export\n']"
154,1727,1711,CC BY-SA 3.0,2017-08-12T22:40:49.677,"<p>SaltStack provides a method for modifying grains and adding additional information to the grains dictionary in several different ways by either setting them in the /etc/salt/minion config and/or through the /etc/salt/grains file. </p>

<p>For example:
1. add grains to the minion config. Note, simply include the grains key here:</p>

<blockquote>
<pre><code>id: minion-07
grains:
  roles:
    - production
  region: nl-amsterdam
</code></pre>
</blockquote>

<ol start=""2"">
<li>add custom grains within the /etc/salt/grains file. Note, add grains without prefacing them with grains:</li>
</ol>

<blockquote>
<pre><code>   roles:
       - production
     region: nl-amsterdam
</code></pre>
</blockquote>

<ol start=""3"">
<li>Alternatively you may set roles via command line shell from master or from salt minion: </li>
</ol>

<blockquote>
  <p><code>salt 'your minion' grains.setval roles [production, dev, qa]</code></p>
  
  <p><code>salt-call grains.setval roles [production, dev, qa]</code></p>
</blockquote>

<p>For matching grains I usually use Jinja2. Or you may refer to commandline/config file approaches: </p>

<blockquote>
  <p><code>salt -C 'G@roles:production' test.ping</code></p>
</blockquote>

<p>By using sytnax in the top.sls file:</p>

<blockquote>
<pre><code>base:
  'roles:production':
    - match: grain
    - salt.master
  'roles:dev':
    - match: grain
    - api-dev
</code></pre>
</blockquote>

<p>Alternatively you may consider using environments in SaltStack, see here for more details: <a href=""https://docs.saltstack.com/en/latest/ref/states/top.html#environments"" rel=""nofollow noreferrer"">https://docs.saltstack.com/en/latest/ref/states/top.html#environments</a></p>

<p>However, roles are more suitable for running specific states, at least We use them in our our company. So up to you what is the best ;) </p>
",3899,2017-08-12T23:02:37.800,"['id: minion-07\ngrains:\n  roles:\n    - production\n  region: nl-amsterdam\n', '   roles:\n       - production\n     region: nl-amsterdam\n', ""base:\n  'roles:production':\n    - match: grain\n    - salt.master\n  'roles:dev':\n    - match: grain\n    - api-dev\n""]"
155,1728,1148,CC BY-SA 3.0,2017-08-13T08:20:46.610,"<p>Yes you can change the name of the RDS instance, but it is highly discouraged to do so in LIVE Production environment. It would change the EndPoint which might impact other resources actively accessing the RDS server (like an application server).</p>

<p>This would probably require a property / env-variable change in your code or configs (which would ideally end up for a release of config through config management)</p>

<p>To avoid disruption (In future) and rollout changes with lesser RTO , you can create an intermediate DNS entry (CNAME) in Route53 for your RDS server and use the intermediate URL in your application. When the RDS server name changes you could just change the DNS CNAME of the new RDS Endpoint. <strong>NOTE:</strong> During the name change your RDS server would be unavailable (with old name) for few minutes and this might cause disruption</p>

<p>That being said, you are already biased on a solution (change of RDS names) for your problem. BuT</p>

<p>There are multiple solutions for your actual problem (managing RDS servers for each project)</p>

<p>A. Try to avoid using AWS Console as much as possible. Why dont you start looking into AWS CLI (which can pull the tags) and write a wrapper Python/Bash script to list all the RDS servers - with Project Names, from this output you could manage these servers, like take a snapshot , backup etc. You can also use mysql --login-path (If you are on mysql for DB administration)
<a href=""https://opensourcedbms.com/dbms/passwordless-authentication-using-mysql_config_editor-with-mysql-5-6/"" rel=""nofollow noreferrer"">https://opensourcedbms.com/dbms/passwordless-authentication-using-mysql_config_editor-with-mysql-5-6/</a>.  </p>

<p>B. (Cost agnostic approach) If you have anyways decided to change the RDS Names, then there is something you can do without any impact. </p>

<pre><code>B.1 When the next code/config release happens try to bring in the intermediate DNS change into action.

B.2 (Optional) Enable Multi AZ in RDS (HA and twice the price). This will help your application to access the secondary active slave when there is any disruption due to name change. There is an option called Reboot with failover which would reboot the master while failing over to the active secondary 

B.3 Enable replication (read-replica) (this will give you a new RDS end-point). Name the read replica properly with your project names

B.4. Once replication is complete (and during your SLA / maintenance window) promote your read replica (this will break replication) and make the intermediate DNS point to the new RDS (with your proper names)
</code></pre>

<blockquote>
  <p><strong>NOTE</strong>  All the above approaches would not guarantee data integrity and improper data updates due to in-flight transactions. So it is
  always better to stop all transactions (by stopping all application
  accessing and deploying a maintenance page and do the operations)</p>
</blockquote>
",2962,2017-08-13T08:20:46.610,['B.1 When the next code/config release happens try to bring in the intermediate DNS change into action.\n\nB.2 (Optional) Enable Multi AZ in RDS (HA and twice the price). This will help your application to access the secondary active slave when there is any disruption due to name change. There is an option called Reboot with failover which would reboot the master while failing over to the active secondary \n\nB.3 Enable replication (read-replica) (this will give you a new RDS end-point). Name the read replica properly with your project names\n\nB.4. Once replication is complete (and during your SLA / maintenance window) promote your read replica (this will break replication) and make the intermediate DNS point to the new RDS (with your proper names)\n']
156,1730,1692,CC BY-SA 3.0,2017-08-13T08:51:20.703,"<p>As you are trying to manage multiple servers you should start looking into any config management tools.</p>

<p>You could start looking into Ansible, as it is easier to setup and manage than other CM tools like Chef and Puppet (which have their own dependent resources to manage and run) .</p>

<p>Ansible is agentless, SSH based config tool written on python. (But it does not require you to code in py)</p>

<p>You just have to learn yml syntax (Jinja2) which is pretty easy . Its just a set of instructions on how to configure the server</p>

<p>Now coming to your use case</p>

<ol>
<li><p>When you say that you push the docker images to multiple server across globe (which means you have a central node which can connect to all servers). This node can behave like the Ansible master (Where you install all ansible dependencies) </p>

<p>If its is Deb based I have the scripts handy</p>

<pre><code>    sudo apt-get -y install python-dev 
    sudo apt-get -y install libffi-dev
    sudo apt-get -y install libssl-dev
    sudo pip install paramiko 
    sudo pip install PyYAML 
    sudo pip install Jinja2 
    sudo pip install httplib2 
    sudo pip install six 
    sudo pip install markupsafe  
    sudo pip install ansible
</code></pre></li>
<li><p>After you install ansible write a sample playbook  (with just a echo command)
<a href=""http://docs.ansible.com/ansible/latest/playbooks_intro.html"" rel=""nofollow noreferrer"">http://docs.ansible.com/ansible/latest/playbooks_intro.html</a></p></li>
<li><p>Lists all your servers in the inventory file
<a href=""http://docs.ansible.com/ansible/latest/intro_inventory.html"" rel=""nofollow noreferrer"">http://docs.ansible.com/ansible/latest/intro_inventory.html</a></p></li>
<li><p>Execute your playbook for testing with below command
ansible-playbook  -i  --extra-vars ""key=Value""</p></li>
<li><p>Modify your playbook to include Docker image and set env variables of your credentials. Encrypt your creds using Bcrypt or some util</p></li>
<li><p>Store your playbooks in Git or other Source control</p></li>
</ol>

<p>Happy Coding in Ansible.</p>
",2962,2017-08-13T08:51:20.703,['    sudo apt-get -y install python-dev \n    sudo apt-get -y install libffi-dev\n    sudo apt-get -y install libssl-dev\n    sudo pip install paramiko \n    sudo pip install PyYAML \n    sudo pip install Jinja2 \n    sudo pip install httplib2 \n    sudo pip install six \n    sudo pip install markupsafe  \n    sudo pip install ansible\n']
157,1733,1671,CC BY-SA 3.0,2017-08-13T20:18:47.533,"<p>You can easily set the target operating system and processor architecture using the environment variables <strong>GOOS</strong> and <strong>GOARCH</strong> respectively. So, as you want to build it for linux operating system, following command with above environment variables will do, </p>

<pre><code>$ GOOS=linux GOARCH=amd64 go build -o hello main.go
</code></pre>

<p>Here is the <a href=""https://golang.org/doc/install/source#environment"" rel=""nofollow noreferrer"">list of all the supported operating system</a> with which you can easily do cross compilation using Go lang. </p>
",3766,2017-08-13T20:18:47.533,['$ GOOS=linux GOARCH=amd64 go build -o hello main.go\n']
158,1753,1750,CC BY-SA 3.0,2017-08-14T15:31:54.450,"<p>Each instruction you create in your Dockerfile results in a new image layer being created. Each layer brings additional data that are not always part of the resulting image. For example, if you add a file in one layer, but remove it in another layer later, the final image’s size will include the added file size in a form of a special ""whiteout"" file although you removed it.</p>

<p>Let's say you have the following Dockerfile:</p>

<pre><code>FROM centos:6

RUN yum -y update 
RUN yum -y install epel-release
</code></pre>

<p>The resulting image size will be</p>

<pre><code>bigimage     latest        3c5cbfbb4116        2 minutes ago    407MB
</code></pre>

<p>As opposite, with ""similar"" Dockerfile:</p>

<pre><code>FROM centos:6

RUN yum -y update  &amp;&amp; yum -y install epel-release
</code></pre>

<p>The resulting image size will be</p>

<pre><code>smallimage     latest        7edeafc01ffe        3 minutes ago    384MB
</code></pre>

<p>You will get even smaller size, if you clean the yum cache in a single RUN statement.</p>

<p>So you want to keep balance between readability/easy of maintenance and number of layers/image size.</p>
",3533,2017-08-14T15:31:54.450,"['FROM centos:6\n\nRUN yum -y update \nRUN yum -y install epel-release\n', 'bigimage     latest        3c5cbfbb4116        2 minutes ago    407MB\n', 'FROM centos:6\n\nRUN yum -y update  && yum -y install epel-release\n', 'smallimage     latest        7edeafc01ffe        3 minutes ago    384MB\n']"
159,1755,1750,CC BY-SA 3.0,2017-08-14T16:00:42.640,"<p>A docker image is actually a linked list of filesystem layers. Each instruction in a <em>Dockerfile</em> creates a filesystem layer that describes the differences in the filesystem before and after execution of the corresponding instruction. The <code>docker inspect</code> subcommand can be used on a docker image to reveal its nature of being a linked list of filesystem layers.</p>

<p>The number of layers used in an image is important</p>

<ul>
<li>when pushing or pulling images, as it affects the number of concurrent uploads or downloads occuring.</li>
<li>when starting a container, as the layers are combined together to produce the filesystem used in the container; the more layers are involved, the worse the performance is, but the different filesystem backends are affected differently by this.</li>
</ul>

<p>This has several consequences for how images should be built. The first and most important advice I can give is:</p>

<blockquote>
  <p><strong>Advice #1</strong> Make sure that the build steps where your source code is involved comes as late as possible in the <em>Dockerfile</em> and are not tied to previous commands using a <code>&amp;&amp;</code> or a <code>;</code>.</p>
</blockquote>

<p>The reason for this, is that all the previous steps will be cached and the corresponding layers will not need to be downloaded over and over again. This means faster builds and faster releases, which is probably what you want.  Interestingly enough, it is surprisingly hard to make optimal use of the docker cache.</p>

<p>My second advice is less important but I find it very useful from a maintenance view point:</p>

<blockquote>
  <p><strong>Advice #2</strong> Do not write complex commands in the <em>Dockerfile</em> but rather use scripts that are to be copied and executed.</p>
</blockquote>

<p>A <em>Dockerfile</em> following this advice would look like</p>

<pre><code>COPY apt_setup.sh /root/
RUN sh -x /root/apt_setup.sh
COPY install_pacakges.sh /root/
RUN sh -x /root/install_packages.sh
</code></pre>

<p>and so on.  The advice of binding several commands with <code>&amp;&amp;</code> has only a limited scope. It is much easier to write with scripts, where you can use functions, etc. to avoid redundancy or for documentation purposes.</p>

<p>People interested by pre-processors and willing to avoid the small overhead caused by the <code>COPY</code> steps and are actually generating on-the-fly a <em>Dockerfile</em> where the</p>

<pre><code>COPY apt_setup.sh /root/
RUN sh -x /root/apt_setup.sh
</code></pre>

<p>sequences are replaced by</p>

<pre><code>RUN base64 --decode … | sh -x
</code></pre>

<p>where the <code>…</code> is the base64-encoded version of <code>apt_setup.sh</code>.</p>

<p>My third advice is for people who wants to limit the size and the number of layers at the possible cost of longer builds.</p>

<blockquote>
  <p><strong>Advice #3</strong> Use the <code>with</code>-idiom to avoid files present in intermediary layers but not in the resulting filesystem.</p>
</blockquote>

<p>A file added by some docker instruction and removed by some later instruction is not present in the resulting filesystem but it is mentioned two times in the docker layers constituting the docker image in construction. Once, with name and full content in the layer resulting from the instruction adding it, and once as a deletion notice in the layer resulting from the instruction removing it.</p>

<p>For instance, assume we temporarily need a C compiler and some image and consider the </p>

<pre><code># !!! THIS DISPLAYS SOME PROBLEM --- DO NOT USE !!!
RUN apt-get install -y gcc
RUN gcc --version
RUN apt-get --purge autoremove -y gcc
</code></pre>

<p>(A more realistic example would build some software with the compiler instead of merely asserting its presence with the <code>--version</code> flag.)</p>

<p>The Dockerfile snippet creates three layers, the first one contains the full gcc suite so that even if it is not present in the final filesystem the corresponding data is still part of the image in same manner and need to be downloaded, uploaded and unpacked whenever the final image is.</p>

<p>The <code>with</code>-idiom is a common form in functional programming to isolate resource ownership and resource releasing from the logic using it. It is easy to transpose this idiom to shell-scripting, and we can rephrase the previous commands as the following script, to be used with <code>COPY &amp; RUN</code> as in <em>Advice #2.</em></p>

<pre><code># with_c_compiler SIMPLE-COMMAND
#  Execute SIMPLE-COMMAND in a sub-shell with gcc being available.

with_c_compiler()
(
    set -e
    apt-get install -y gcc
    ""$@""
    trap 'apt-get --purge autoremove -y gcc' EXIT
)

with_c_compiler\
    gcc --version
</code></pre>

<p>Complex commands can be turned into function so that they can be fed to the <code>with_c_compiler</code>. It is also possible to chain calls of several <code>with_whatever</code> functions, but maybe not very desirable. (Using more esoteric features of the shell, it is certainly possible to make the <code>with_c_compiler</code> accept complex commands, but it is in all aspects preferable to wrap these complex commands into functions.)</p>

<p>If we want to ignore Advice #2, the resulting Dockerfile snippet would be</p>

<pre><code>RUN apt-get install -y gcc\
 &amp;&amp; gcc --version\
 &amp;&amp; apt-get --purge autoremove -y gcc
</code></pre>

<p>which is not so easy to read and maintain because of the obfuscation. See how the shell-script variant outs emphasis on the important part <code>gcc --version</code> while the chained-<code>&amp;&amp;</code> variant buries that part in the middle of noise.</p>
",271,2017-08-21T15:35:04.807,"['COPY apt_setup.sh /root/\nRUN sh -x /root/apt_setup.sh\nCOPY install_pacakges.sh /root/\nRUN sh -x /root/install_packages.sh\n', 'COPY apt_setup.sh /root/\nRUN sh -x /root/apt_setup.sh\n', 'RUN base64 --decode … | sh -x\n', '# !!! THIS DISPLAYS SOME PROBLEM --- DO NOT USE !!!\nRUN apt-get install -y gcc\nRUN gcc --version\nRUN apt-get --purge autoremove -y gcc\n', '# with_c_compiler SIMPLE-COMMAND\n#  Execute SIMPLE-COMMAND in a sub-shell with gcc being available.\n\nwith_c_compiler()\n(\n    set -e\n    apt-get install -y gcc\n    ""$@""\n    trap \'apt-get --purge autoremove -y gcc\' EXIT\n)\n\nwith_c_compiler\\\n    gcc --version\n', 'RUN apt-get install -y gcc\\\n && gcc --version\\\n && apt-get --purge autoremove -y gcc\n']"
160,1759,1757,CC BY-SA 3.0,2017-08-14T17:27:30.807,"<p>AFAIK Kickstart is only usable for the initial installation of the OS, but not for subsequent package maintenance upgrades/downgrades.</p>

<p>Unless I miss something (quite possible, I don't have much experience w/ them) the Linux distros managed by configuration management tools require a minimum level of health from the OS (and some package requirements, at least in some cases) to be able to operate those tools, say to perform a rollback. At least NixOS appears to not have such requirement (or rather it is already fullfilled at the OS level). From <a href=""https://nixos.org/nixos/about.html"" rel=""noreferrer"">About NixOS</a>:</p>

<blockquote>
  <p>Rollbacks</p>
  
  <p>Because the files of a new configuration don’t overwrite old ones, you
  can (atomically) roll back to a previous configuration. For instance,
  if after a nixos-rebuild switch you discover that you don’t like the
  new configuration, you can just go back:</p>

<pre><code>$ nixos-rebuild switch --rollback
</code></pre>
  
  <p>In fact, all old system configurations automatically show up in the
  <a href=""https://nixos.org/nixos/screenshots/nixos-grub.png"" rel=""noreferrer"">Grub boot menu</a>. So if the new configuration crashes or doesn’t
  boot properly, you can just roll back by selecting an older
  configuration in the Grub boot menu. Rollbacks are very fast: it
  doesn’t involve lots of files having to be restored from copies.</p>
</blockquote>
",47,2017-08-14T17:27:30.807,['$ nixos-rebuild switch --rollback\n']
161,1764,1762,CC BY-SA 3.0,2017-08-15T15:43:03.597,"<p>Yes - there are at least two options available for managing files in the manner you describe. The first such way is to manage the entire directory using <a href=""https://docs.saltstack.com/en/latest/ref/states/all/salt.states.file.html#salt.states.file.directory"" rel=""nofollow noreferrer"">file.directory</a>:</p>

<pre><code>/opt/apiv2:
  file.directory:
    - user: root
    - group: root
    - dir_mode: 755
    - file_mode: 644
    - recurse:
      - user
      - group
      - mode
</code></pre>

<p>The second way can manage a manifest of several files at many paths is to use the <code>source_hash</code> feature of <a href=""https://docs.saltstack.com/en/latest/ref/states/all/salt.states.file.html#salt.states.file.managed"" rel=""nofollow noreferrer"">file.managed</a>:</p>

<p>This allows you to provide a source tar file and a file containing md5sum hashes:</p>

<pre><code>apiv2-0.7.3.tar.gz:
  file.managed:
    - name: /tmp/apiv2-0.7.3.tar.gz
    - source: salt:///apiv2/distrib/apiv2-0.7.3.tar.gz
    - source_hash: salt:///apiv2/distrib/manifest-0.7.3.hash
</code></pre>

<p>You would then create a text file on your salt server /srv/salt/apiv2/distrib/manifest-0.7.3.hash with contents similar to:</p>

<pre><code>37b51d194a7513e45b56f6524f2d51f2    /opt/apiv2/apiv2.properties
acbd18db4cc2f85cedef654fccc4a4d8    /opt/apiv2/repo/bootstrap.jar
73feffa4b7f6bb68e44cf984c85f6e88    /opt/apiv1/apiv1.properties
</code></pre>

<p>Your <em>might</em> even be able to use templating,</p>

<pre><code>apiv2-0.7.3.tar.gz:
  file.managed:
    - name: /tmp/apiv2-0.7.3.tar.gz
    - source: salt:///apiv2/distrib/apiv2-0.7.3.tar.gz
    - source_hash: salt:///apiv2/distrib/manifest-0.7.3.hash
    - template: jinja
</code></pre>

<p>however Salt Stack might want to push down the file each time because after the templates are rendered, the hash will have changed, so the creators might just have elected to throw an error if you try these two features together. In short, Your Mileage May Vary<sup>TM</sup></p>
",2845,2017-08-15T20:30:28.353,"['/opt/apiv2:\n  file.directory:\n    - user: root\n    - group: root\n    - dir_mode: 755\n    - file_mode: 644\n    - recurse:\n      - user\n      - group\n      - mode\n', 'apiv2-0.7.3.tar.gz:\n  file.managed:\n    - name: /tmp/apiv2-0.7.3.tar.gz\n    - source: salt:///apiv2/distrib/apiv2-0.7.3.tar.gz\n    - source_hash: salt:///apiv2/distrib/manifest-0.7.3.hash\n', '37b51d194a7513e45b56f6524f2d51f2    /opt/apiv2/apiv2.properties\nacbd18db4cc2f85cedef654fccc4a4d8    /opt/apiv2/repo/bootstrap.jar\n73feffa4b7f6bb68e44cf984c85f6e88    /opt/apiv1/apiv1.properties\n', 'apiv2-0.7.3.tar.gz:\n  file.managed:\n    - name: /tmp/apiv2-0.7.3.tar.gz\n    - source: salt:///apiv2/distrib/apiv2-0.7.3.tar.gz\n    - source_hash: salt:///apiv2/distrib/manifest-0.7.3.hash\n    - template: jinja\n']"
162,1777,1775,CC BY-SA 3.0,2017-08-18T14:25:50.640,"<p>I just figure it out. The problem is not with the service or the swarm, it's with the network.</p>

<p>When I use <code>driver: overlay</code> the default <code>subnet</code> is <code>10.0.0.0/24</code> which result in 254 address. So I change the mask in the <code>subnet</code>, to 22, which result in 1022 address, I added:</p>

<pre><code>ipam:
  config:
    -subnet: 10.0.0.0/22
</code></pre>

<p>And now the network section in the <code>docker-compose</code> file looks like this:</p>

<pre><code>networks:
  web:
    driver: overlay
    ipam:
      config:
        - subnet: 10.0.0.0/22
</code></pre>
",3985,2017-08-18T14:25:50.640,"['ipam:\n  config:\n    -subnet: 10.0.0.0/22\n', 'networks:\n  web:\n    driver: overlay\n    ipam:\n      config:\n        - subnet: 10.0.0.0/22\n']"
163,1778,1692,CC BY-SA 3.0,2017-08-18T15:36:36.180,"<p>One solution would be to create a base image with OpenVPN and global configurations and child images for the certs.</p>

<p>The base <code>Dockerfile</code> might look like this.</p>

<pre><code>FROM debian:latest
RUN apt-get update &amp;&amp; apt-get -y install \
  openvpn \
  easy-rsa \
  etc

RUN &lt;any needed configurations&gt;
</code></pre>

<p><code>docker build -t openvpn:baseimage .</code></p>

<p>The cert <code>Dockerfile</code>.</p>

<pre><code>FROM openvpn:baseimage
COPY certs /etc/easy-rsa/

CMD openvpn
</code></pre>

<p><code>docker build -t useast:1 .</code></p>

<p>You could push the certs to the respective nodes with some kind of management tool and <code>build</code> the child images there. The base image would live in an available registry. Once the base image is cached on each node in Docker, the builds should be quick. </p>

<p>There are multiple solutions to this problem depending on what's best for the given environment.           </p>
",741,2017-08-18T15:36:36.180,"['FROM debian:latest\nRUN apt-get update && apt-get -y install \\\n  openvpn \\\n  easy-rsa \\\n  etc\n\nRUN <any needed configurations>\n', 'FROM openvpn:baseimage\nCOPY certs /etc/easy-rsa/\n\nCMD openvpn\n']"
164,1797,1769,CC BY-SA 3.0,2017-08-20T19:14:13.423,"<p>Just browsing through the available options, it looks like the <code>nova meta</code> actions may be available as <code>openstack server set</code>:</p>

<pre><code>$ openstack help server set
usage: openstack server set [-h] [--name &lt;new-name&gt;] [--root-password]
                            [--property &lt;key=value&gt;] [--state &lt;state&gt;]
                            &lt;server&gt;

Set server properties

positional arguments:
  &lt;server&gt;              Server (name or ID)

optional arguments:
  -h, --help            show this help message and exit
  --name &lt;new-name&gt;     New server name
  --root-password       Set new root password (interactive only)
  --property &lt;key=value&gt;
                        Property to add/change for this server (repeat option
                        to set multiple properties)
  --state &lt;state&gt;       New server state (valid value: active, error)
</code></pre>

<p>E.g., if I run:</p>

<pre><code>openstack server set myserver --property foo=bar
</code></pre>

<p>And then run:</p>

<pre><code>openstack server show myserver
</code></pre>

<p>I see:</p>

<pre><code>[...]
| properties                           | foo='bar'                                                |
[...]
</code></pre>
",4011,2017-08-20T19:14:13.423,"['$ openstack help server set\nusage: openstack server set [-h] [--name <new-name>] [--root-password]\n                            [--property <key=value>] [--state <state>]\n                            <server>\n\nSet server properties\n\npositional arguments:\n  <server>              Server (name or ID)\n\noptional arguments:\n  -h, --help            show this help message and exit\n  --name <new-name>     New server name\n  --root-password       Set new root password (interactive only)\n  --property <key=value>\n                        Property to add/change for this server (repeat option\n                        to set multiple properties)\n  --state <state>       New server state (valid value: active, error)\n', 'openstack server set myserver --property foo=bar\n', 'openstack server show myserver\n', ""[...]\n| properties                           | foo='bar'                                                |\n[...]\n""]"
165,1803,1782,CC BY-SA 3.0,2017-08-21T07:26:37.180,"<p>This is a simple thumb rule one could follow </p>

<ul>
<li>Use version control (git, svn, cvs) for the work product created by humans</li>
<li>Use artifact management tool (artifactory, nexus, apache archiva) for the software bundle (artifacts) created by the system thru build or packaging process</li>
</ul>

<blockquote>
<pre><code>HUMAN           ==&gt;            System
GIT/SVN  (build/packaging)     artifactory/archiva
</code></pre>
</blockquote>
",3720,2017-08-21T07:26:37.180,['HUMAN           ==>            System\nGIT/SVN  (build/packaging)     artifactory/archiva\n']
166,1808,1795,CC BY-SA 3.0,2017-08-21T13:47:49.513,"<p>Hm, i'll answer myself here I guess.</p>

<p>The problem was, I had ""broken"" volumes.</p>

<p>So, I've made a little script to ""reset"" docker and install wordpress.
Careful it removes everything.</p>

<pre><code>#!/bin/bash

# remove images
docker rmi $(docker images -q)  
# remove containers
docker stop $(docker ps -aq)
docker rm $(docker ps -aq)    
# remove volumes
docker volume rm $(docker volume ls -q)

echo ""Type mysql root password : ""
read mspass

docker run --name wordpressdb -e MYSQL_ROOT_PASSWORD=$mspass -e MYSQL_DATABASE=wordpress -d mysql:5.7

docker run -e WORDPRESS_DB_PASSWORD=$mspass --name wordpress --link wordpressdb:mysql -p 127.0.0.2:8080:80 -v ""$PWD/"":/var/www/html -d wordpress
</code></pre>
",4008,2017-08-21T13:47:49.513,"['#!/bin/bash\n\n# remove images\ndocker rmi $(docker images -q)  \n# remove containers\ndocker stop $(docker ps -aq)\ndocker rm $(docker ps -aq)    \n# remove volumes\ndocker volume rm $(docker volume ls -q)\n\necho ""Type mysql root password : ""\nread mspass\n\ndocker run --name wordpressdb -e MYSQL_ROOT_PASSWORD=$mspass -e MYSQL_DATABASE=wordpress -d mysql:5.7\n\ndocker run -e WORDPRESS_DB_PASSWORD=$mspass --name wordpress --link wordpressdb:mysql -p 127.0.0.2:8080:80 -v ""$PWD/"":/var/www/html -d wordpress\n']"
167,1809,1804,CC BY-SA 3.0,2017-08-21T14:10:40.727,"<p>There are two important parameters that you can use wisely to deal with AWS ECS task definition. </p>

<p><a href=""http://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html"" rel=""nofollow noreferrer"">memory</a>: </p>

<blockquote>
  <p>The hard limit (in MiB) of memory to present to the container. If your
  container attempts to exceed the memory specified here, the container
  is killed.</p>
</blockquote>

<p><a href=""http://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html"" rel=""nofollow noreferrer"">memoryReservation</a>: </p>

<blockquote>
  <p>Docker attempts to keep the container memory to this soft limit;
  however, your container can consume more memory when it needs to.</p>
</blockquote>

<p>I recommend you to go with <strong>memoryReservation</strong>. So your task definition will look like this. </p>

<pre><code>{
  ""family"": ""my-alpine"",
  ""networkMode"": ""bridge"",
  ""containerDefinitions"": [
    {
      ""image"": ""alpine:latest"",
      ""name"": ""my-alpine"",
      ""memoryReservation"": 100,
      ...
      ...
    }
  ]
}
</code></pre>
",4023,2017-08-21T14:10:40.727,"['{\n  ""family"": ""my-alpine"",\n  ""networkMode"": ""bridge"",\n  ""containerDefinitions"": [\n    {\n      ""image"": ""alpine:latest"",\n      ""name"": ""my-alpine"",\n      ""memoryReservation"": 100,\n      ...\n      ...\n    }\n  ]\n}\n']"
168,1813,1812,CC BY-SA 3.0,2017-08-21T15:34:11.783,"<p>k8s have documentation page about volumes and their types <a href=""https://kubernetes.io/docs/concepts/storage/volumes/"" rel=""nofollow noreferrer"">https://kubernetes.io/docs/concepts/storage/volumes/</a></p>

<p>So in short you need to define <code>spec.volumes</code> and <code>spec.containers[].volumeMounts</code> like:</p>

<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: test-pd
spec:
  containers:
  - image: gcr.io/google_containers/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /cache
      name: cache-volume
  volumes:
  - name: cache-volume
    emptyDir: {}
</code></pre>
",3939,2017-08-21T15:34:11.783,['apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pd\nspec:\n  containers:\n  - image: gcr.io/google_containers/test-webserver\n    name: test-container\n    volumeMounts:\n    - mountPath: /cache\n      name: cache-volume\n  volumes:\n  - name: cache-volume\n    emptyDir: {}\n']
169,1826,225,CC BY-SA 3.0,2017-08-22T18:59:26.337,"<p>You can read book about best practices for git: <a href=""https://git-scm.com/book/en/v2"" rel=""nofollow noreferrer"">https://git-scm.com/book/en/v2</a></p>

<p>Example for some git strategy in project:</p>

<ol>
<li>Creates branch named like a task, feature/XXX-1</li>
<li>Sending task for review</li>
<li>If not review, fixes and again review</li>
<li>If reviewed go to test</li>
<li>If test not passed, fixed and again review/tests</li>
</ol>

<p>First time review:</p>

<pre><code>git pull dev
git checkout -b feature/XXX-1
git add .
git commit -m 'XXX-1 My task'
git push origin feature/XXX-1
</code></pre>

<p>If need fixed after review:</p>

<pre><code>git push origin :feature/XXX-1
git reset --soft HEAD~1
git add .
git commit -m 'XXX-1 My task fix'
git push origin feature/XXX-1
</code></pre>
",3642,2017-08-22T19:06:52.237,"[""git pull dev\ngit checkout -b feature/XXX-1\ngit add .\ngit commit -m 'XXX-1 My task'\ngit push origin feature/XXX-1\n"", ""git push origin :feature/XXX-1\ngit reset --soft HEAD~1\ngit add .\ngit commit -m 'XXX-1 My task fix'\ngit push origin feature/XXX-1\n""]"
170,1829,1828,CC BY-SA 3.0,2017-08-22T22:38:39.033,"<p>It <em>might</em> be possible, depending on your version control system.</p>

<p>In Git, for example, for a dir structure like this:</p>

<pre><code>dir_in_question/
  .git/
  .gitignore
  builds/
  config.xml
</code></pre>

<p>I can prevent git from seeing any of the changes under the <code>builds</code> directory simply by adding inside <code>.gitignore</code> (which I prefer to add to the git as well) this line:</p>

<pre><code>builds/
</code></pre>

<p>Another thing to try would be to make <code>builds</code> a symlink to a location outside the version control system, typically another filesystem. As a side effect you'd gain protection against builds filling up the jenkins' filesystem :)</p>
",47,2017-08-22T22:50:37.693,"['dir_in_question/\n  .git/\n  .gitignore\n  builds/\n  config.xml\n', 'builds/\n']"
171,1836,849,CC BY-SA 3.0,2017-08-23T12:18:56.637,"<p>CircleCI now allows you to use a <a href=""https://circleci.com/docs/2.0/configuration-reference/#machine"" rel=""noreferrer"" title=""CircleCI reference: machine executor"">machine executor</a> which provisions a separate VM for you, with Ubuntu 14.04 and Docker version 17.06.0-ce installed. This allows you to turn on experimental features for the Docker daemon.</p>

<p>You need to use the <a href=""https://circleci.com/docs/2.0/configuration-reference/#machine"" rel=""noreferrer"" title=""CircleCI reference: machine executor""><code>machine</code></a> key instead of the <code>docker</code> key, to run your job in a separate virtual machine instead of just a Docker container.</p>

<p>You can only choose 2 images for the machine:</p>

<ul>
<li><code>circleci/classic:latest</code>: Ubuntu 14.04 with Docker 17.03.0-ce, or</li>
<li><code>circleci/classic:edge</code>: Ubuntu 14.04 with Docker 17.06.0-ce - the one with experimental features.</li>
</ul>

<p>You'll also need to install dependencies on the machine yourself, as it is quite bare. For example, if you need PHP for your tests, you'll need to run <code>sudo apt-get install -y php5</code>.</p>

<p>Here is a sample <em>.circleci/config.yml</em> that builds a Docker image using experimental feature <code>docker build --squash</code>:</p>

<blockquote>
  <p>.circleci/config.yml
  </p>

<pre><code>version: 2
jobs:
  build:
    # Run in a separate virtual machine instead of a Docker container.
    machine:
      enabled: true
      # Use Ubuntu 14.04 with bleeding edge Docker daemon 17.06.0-ce.
      image: circleci/classic:edge
    steps:
      - checkout
      - run:
          command: |
            # Restart Docker with experimental features on.
            sudo sh -c 'echo '\''DOCKER_OPTS=""--experimental=true""'\'' &gt;&gt; /etc/default/docker'
            sudo service docker restart

            # Install dependencies for tests etc.
            sudo apt-get update
            sudo apt-get install -y php5

            # Build image with experimental feature --squash.
            docker build --squash -t myuser/myimage .

            # Login and push Docker image to registry.
            docker login -u $DOCKER_USER -p $DOCKER_PASS
            docker push myuser/myimage
</code></pre>
</blockquote>
",4058,2017-08-23T14:24:19.490,"['version: 2\njobs:\n  build:\n    # Run in a separate virtual machine instead of a Docker container.\n    machine:\n      enabled: true\n      # Use Ubuntu 14.04 with bleeding edge Docker daemon 17.06.0-ce.\n      image: circleci/classic:edge\n    steps:\n      - checkout\n      - run:\n          command: |\n            # Restart Docker with experimental features on.\n            sudo sh -c \'echo \'\\\'\'DOCKER_OPTS=""--experimental=true""\'\\\'\' >> /etc/default/docker\'\n            sudo service docker restart\n\n            # Install dependencies for tests etc.\n            sudo apt-get update\n            sudo apt-get install -y php5\n\n            # Build image with experimental feature --squash.\n            docker build --squash -t myuser/myimage .\n\n            # Login and push Docker image to registry.\n            docker login -u $DOCKER_USER -p $DOCKER_PASS\n            docker push myuser/myimage\n']"
172,1837,1830,CC BY-SA 3.0,2017-08-23T15:47:05.487,"<p>If you want just to deploy faster to server(propably not only Glassfish) you can just write code in gradle to do that. 
Example taken from <a href=""https://www.schuermann.eu/2013/08/03/gradle-glassfish.html"" rel=""nofollow noreferrer"">here</a></p>

<pre><code>/**
 *  ~/.gradle/gradle.properties:
 *  glassfishHome=/path/to/glassfish_home
 *
 *  or in Netbeans, right click project, Properties, Manage Build in Tasks, Run
 *  Add line to Arguments: -Dorg.gradle.project.glassfishHome=/path/to/glassfish_home
 *
 *  For more information about Exec tasks see
 *  http://www.gradle.org/docs/current/dsl/org.gradle.api.tasks.Exec.html
 */
task run(dependsOn: 'war', type:Exec) {
    workingDir ""${glassfishHome}${File.separator}bin""

    if (System.properties['os.name'].toLowerCase().contains('windows')) {
        commandLine 'cmd', '/c', 'asadmin.bat'
    } else {
        commandLine ""./asadmin""
    }

    args ""deploy"", ""--force=true"", ""${war.archivePath}""
//from: https://www.schuermann.eu/2013/08/03/gradle-glassfish.html
}
</code></pre>

<p>In other words just use your asadmin</p>
",4061,2017-08-23T15:47:05.487,"['/**\n *  ~/.gradle/gradle.properties:\n *  glassfishHome=/path/to/glassfish_home\n *\n *  or in Netbeans, right click project, Properties, Manage Build in Tasks, Run\n *  Add line to Arguments: -Dorg.gradle.project.glassfishHome=/path/to/glassfish_home\n *\n *  For more information about Exec tasks see\n *  http://www.gradle.org/docs/current/dsl/org.gradle.api.tasks.Exec.html\n */\ntask run(dependsOn: \'war\', type:Exec) {\n    workingDir ""${glassfishHome}${File.separator}bin""\n\n    if (System.properties[\'os.name\'].toLowerCase().contains(\'windows\')) {\n        commandLine \'cmd\', \'/c\', \'asadmin.bat\'\n    } else {\n        commandLine ""./asadmin""\n    }\n\n    args ""deploy"", ""--force=true"", ""${war.archivePath}""\n//from: https://www.schuermann.eu/2013/08/03/gradle-glassfish.html\n}\n']"
173,1853,1851,CC BY-SA 3.0,2017-08-25T21:49:16.340,"<p><a href=""https://www.digitalocean.com/community/tutorials/how-to-use-roles-and-environments-in-chef-to-control-server-configurations"" rel=""nofollow noreferrer"">https://www.digitalocean.com/community/tutorials/how-to-use-roles-and-environments-in-chef-to-control-server-configurations</a></p>

<blockquote>
  <p>For instance, if a node is in the ""production"" environment, you could
  want to run a special recipe in your ""nginx"" cookbook to bring that
  server up to production policy requirements. You could also have a
  recipe in the nginx cookbook meant to configure special changes for
  testing servers.</p>
</blockquote>

<p>Example</p>

<blockquote>
<pre><code>name ""web_server""
description ""A role to configure our front-line web servers""
run_list ""recipe[apt]"", ""recipe[nginx]""
env_run_lists ""production"" =&gt; [""recipe[nginx::config_prod]""], ""testing"" =&gt; [""recipe[nginx::config_test]""]
</code></pre>
</blockquote>
",210,2017-08-25T21:49:16.340,"['name ""web_server""\ndescription ""A role to configure our front-line web servers""\nrun_list ""recipe[apt]"", ""recipe[nginx]""\nenv_run_lists ""production"" => [""recipe[nginx::config_prod]""], ""testing"" => [""recipe[nginx::config_test]""]\n']"
174,1868,1846,CC BY-SA 3.0,2017-08-28T22:04:47.440,"<p>I'm not entirely sure what you're trying to ask in your question, so I'm answering the question I believe you're trying to ask.</p>

<p>A build does not necessarily have a single commit author.  It has a list of committers, which can be empty or can contain many committers.  To create this list, you can use this snippet in a scripted Pipeline (note that you may need to disable the sandbox in order to use <code>.collect()</code>):</p>

<pre><code>changeAuthors = currentBuild.changeSets.collect { set -&gt;
  set.collect { entry -&gt; entry.author.fullName }
}.flatten()
</code></pre>

<p>I use this with Git as my SCM; I'm not sure if it works with other SCMs.</p>

<p>See also the following questions on StackOverflow (some answers may be outdated):</p>

<ul>
<li><a href=""https://stackoverflow.com/questions/30398465/how-to-get-culprits-or-committers-inside-a-jenkins-workflow-with-one-or-more-scm"">How to get culprits or committers inside a Jenkins workflow with one or more SCMs</a></li>
<li><a href=""https://stackoverflow.com/questions/37755586/how-do-you-pull-git-committer-information-for-jenkins-pipeline"">How do you pull git committer information for Jenkins pipeline</a></li>
</ul>
",4115,2017-08-28T22:04:47.440,['changeAuthors = currentBuild.changeSets.collect { set ->\n  set.collect { entry -> entry.author.fullName }\n}.flatten()\n']
175,1873,1872,CC BY-SA 3.0,2017-08-29T04:54:40.460,"<p>First make sure that you added the public key to the right repo with the right permission, usually I add it to 'Access keys' so the user has read only permission, then to make sure that is working add the private key to you system so you can use it with using git:</p>

<pre><code>ssh-add private-key
git clone &lt;your git repo&gt;
</code></pre>

<p>If it's working, add those credential to you jenkins and use them later </p>
",3752,2017-08-29T04:54:40.460,['ssh-add private-key\ngit clone <your git repo>\n']
176,1874,1869,CC BY-SA 3.0,2017-08-29T08:45:33.723,"<p>Adding my brick to the list here, I'm at a point where updating continuously the monitoring system to add new instances and cleanup old ones is a pain.</p>

<p>As such I've turn toward <a href=""https://prometheus.io/"" rel=""noreferrer"">prometeus</a> which works with a simple contract, an exporter does the collection job (could be the <a href=""https://github.com/prometheus/cloudwatch_exporter"" rel=""noreferrer"">cloudwatch_exporter</a> on AWS or when using <a href=""https://github.com/firehol/netdata"" rel=""noreferrer"">netdata</a> querying it (either a central one or each separately, but the latter lost the advantage of auto-discovery) (doc for the netdata part <a href=""https://github.com/firehol/netdata/wiki/Using-Netdata-with-Prometheus"" rel=""noreferrer"">here</a>) and there's also a node exporter from prometeus team.</p>

<p>The main advantage behind prometheus is the use of <a href=""https://prometheus.io/docs/querying/functions/"" rel=""noreferrer"">mathematics functions</a> and grouping in the alert definition by label from the metric name. This allow to define alerts on various way, for my infrastructure monitoring I work with standard deviation or standard variance to avoid fixed level of alert on cpu usage, it alerts me if the stddev goes up by 20%.</p>

<p>So for your case you could export your database or push the metrics to prometeus and assuming a metric name <code>client_queries</code> with the client name as the label <code>client</code> you could do something along the line of this (untested of course and just to illustrate):</p>

<pre><code>ALERT ClientQueryDriftUp
  IF avg(client_queries[5m]) &gt; avg(client_queries[5m] offset 1w) * 1.2
  ANNOTATIONS {
    summary = ""{{ $labels.client }} query has gone up over 20% of last week"",
    description = ""{{ $labels.client}} query average is high ! (current average value: {{ $value }}s)"",
  }
</code></pre>

<p>Or if you just want an alert if the difference between averages is over 1 second (assuming values are in milliseconds) you can use this IF condition:</p>

<pre><code>abs(avg(client_queries[5m]) - avg(client_queries[5m] offset 1w)) &gt; 1000
</code></pre>

<p>Of course this answer is just an overview on how it can tackle your problem and is far from exhaustive about it.</p>
",13,2017-08-29T08:45:33.723,"['ALERT ClientQueryDriftUp\n  IF avg(client_queries[5m]) > avg(client_queries[5m] offset 1w) * 1.2\n  ANNOTATIONS {\n    summary = ""{{ $labels.client }} query has gone up over 20% of last week"",\n    description = ""{{ $labels.client}} query average is high ! (current average value: {{ $value }}s)"",\n  }\n', 'abs(avg(client_queries[5m]) - avg(client_queries[5m] offset 1w)) > 1000\n']"
177,1876,1840,CC BY-SA 3.0,2017-08-29T12:55:52.377,"<p>The current organisation of the code and configuration you describe is structured by the technical solutions involved.  This is a bad design that will add a lot of overhead in our maintenance activities and will add a lot of traps in our way as well. Instead, that organisation should be structured around the <a href=""https://devops.stackexchange.com/questions/466/what-is-an-artifact-or-artefact"">artefacts</a> we are deploying.</p>

<p>The reason for this is that we want to consider artefacts (<em>e.g.</em> a docker image or a software package) as the objects of the following verbs:</p>

<ul>
<li>build</li>
<li>test</li>
<li>deploy</li>
</ul>

<p>to consider a minimal set of automated tasks we want to perform. If we want to change something about how the test verb is implemented, it is easy to visit the folder corresponding to that artefact in the appropriate repository and then discover the jenkins-specific automation items that needs to be updated.  Instead, if the automation recipes are structured around technical solutions, then we need to figure out of the blue that jenkins is involved in the test procedures and find there the artefact related automation items.  In complex situations, the organisation around technical solutions makes updates very hard, because we have to know a priori all the technical solutions involved in some service to update them accordingly.</p>

<p>For instance a repository containing the code for a website and a micro-service “a” could have the following sub-directories dedicated to operations:</p>

<pre><code>./ops/website
./ops/micro-service-a
</code></pre>

<p>each having three scripts called <code>build</code>, <code>test</code> and <code>deploy</code>.  Now that the organisation of automation items has somehow been clarified, let's turn our attention to configuration.</p>

<p>The main conditions and requirements about the configuration organisation are set by the <code>deploy</code> verb when applied on a service-like artefact.  The <code>deploy</code> verb should have the following parameters:</p>

<ul>
<li>the version of the artefact to deploy,</li>
<li>the deployment target of the artefact, which describes the concrete environment where the deployed artefact will run (<em>e.g.</em> a cluster and endpoints it should talk to)</li>
<li>the credentials it should use to connect to other endpoints (<em>e.g.</em> databases)</li>
<li>the runtime configuration of (like how long cache entries should live, etc.)</li>
</ul>

<p>From the operational perspective, this breakdown of the parametrisation matches the natural degrees of freedom of the deployment problem – aside from the credentials that could be bundled with the runtime configuration, but it is better to separate them to avoid spreading them carelessly.</p>
",271,2017-08-29T13:06:48.840,['./ops/website\n./ops/micro-service-a\n']
178,1892,1872,CC BY-SA 3.0,2017-08-31T10:15:58.537,"<p>Hello guys I have found the solution, 
So I create ssh keys from my <strong>Jenkins Server</strong>, and then called the private key from my code, this is how it looks like on my project structure:</p>

<pre><code>root@staging:~/project# tree
.
├── deployment.yaml
├── server
│   └── host
└── the_private_key

1 directory, 3 files
</code></pre>

<p>and my deployment.yaml:</p>

<pre><code>---
- hosts: staging
  become_user: sudo
  tasks:
  - name: populate my project
    git: repo=git@bitbucket.org:source/source.git
         version=master
         dest=/var/www/test/
         key_file=the_private_key
         accept_hostkey=yes
</code></pre>

<p>And then I copied <strong>Jenkins Server</strong> public key to <strong>Target Server</strong>, then everything worked well</p>
",4117,2017-08-31T10:15:58.537,"['root@staging:~/project# tree\n.\n├── deployment.yaml\n├── server\n│\xa0\xa0 └── host\n└── the_private_key\n\n1 directory, 3 files\n', '---\n- hosts: staging\n  become_user: sudo\n  tasks:\n  - name: populate my project\n    git: repo=git@bitbucket.org:source/source.git\n         version=master\n         dest=/var/www/test/\n         key_file=the_private_key\n         accept_hostkey=yes\n']"
179,1893,149,CC BY-SA 3.0,2017-08-31T10:30:33.197,"<p>There are a few reasons which might have caused the gap. Most likely the exporter isn't reachable in which case the <code>up</code> timeseries will be 0. You can alert on this like this (taken from <a href=""https://prometheus.io/docs/alerting/rules/#templating"" rel=""nofollow noreferrer"">https://prometheus.io/docs/alerting/rules/#templating</a>):</p>

<pre><code># Alert for any instance that is unreachable for &gt;5 minutes.
ALERT InstanceDown
  IF up == 0
  FOR 5m
  LABELS { severity = ""page"" }
  ANNOTATIONS {
    summary = ""Instance {{ $labels.instance }} down"",
    description = ""{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes."",
  }
</code></pre>

<p>On the status page you should also see that it's down including an error message. Unfortunately there is no way to see past error but there is an issue to track this: <a href=""https://github.com/prometheus/prometheus/issues/2820"" rel=""nofollow noreferrer"">https://github.com/prometheus/prometheus/issues/2820</a></p>

<p>Your Prometheus server can be also overloaded causing scraping to stop which too would explain the gaps. In that case you should see <code>Storage needs throttling. Scrapes and rule evaluations will be skipped.</code> errors in the log and increases in the <code>prometheus_target_skipped_scrapes_total</code> metrics. You should alert on that too, e.g:</p>

<pre><code>ALERT PrometheusSkipsScrapes
  IF rate(prometheus_target_skipped_scrapes_total[2m]) &gt; 0
  FOR 5m
</code></pre>
",4147,2017-08-31T10:30:33.197,"['# Alert for any instance that is unreachable for >5 minutes.\nALERT InstanceDown\n  IF up == 0\n  FOR 5m\n  LABELS { severity = ""page"" }\n  ANNOTATIONS {\n    summary = ""Instance {{ $labels.instance }} down"",\n    description = ""{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes."",\n  }\n', 'ALERT PrometheusSkipsScrapes\n  IF rate(prometheus_target_skipped_scrapes_total[2m]) > 0\n  FOR 5m\n']"
180,1910,1129,CC BY-SA 3.0,2017-09-01T14:33:33.800,"<p><a href=""https://forums.developer.apple.com/thread/75038"" rel=""nofollow noreferrer"">https://forums.developer.apple.com/thread/75038</a></p>

<blockquote>
  <p>Hi!</p>
  
  <p>I think I've got it figured out...</p>
  
  <p>instead of:</p>

<pre><code>-exportProvisioningProfile ""MyProvisioningProfile""
</code></pre>
  
  <p>use:</p>

<pre><code>PROVISIONING_PROFILE_SPECIFIER=""MyProvisioningProfile""
</code></pre>
  
  <p>We've got unity building the project every time and it doesn't fill in
  the PROVISIONING_PROFILE or PROVISIONING_PROFILE_SPECIFIER. And it
  looks like it will figure out the alphabet soup that belongs to
  PROVISIONING_PROFILE by looking it up itself provided you have
  downloaded it already.</p>
</blockquote>
",210,2017-09-01T15:47:11.580,"['-exportProvisioningProfile ""MyProvisioningProfile""\n', 'PROVISIONING_PROFILE_SPECIFIER=""MyProvisioningProfile""\n']"
181,1911,987,CC BY-SA 3.0,2017-09-01T15:42:57.807,"<p>As Tensibai mentioned, you can extract this info from <a href=""http://man7.org/linux/man-pages/man5/proc.5.html"" rel=""noreferrer"">the <code>/proc</code> filesystem</a>, but in most cases you need to determine the trending yourself. There are several places which could be of interest:</p>

<ul>
<li><strong>/proc/[pid]/statm</strong></li>
</ul>

<blockquote>
<pre><code>          Provides information about memory usage, measured in pages.
          The columns are:

              size       (1) total program size
                         (same as VmSize in /proc/[pid]/status)
              resident   (2) resident set size
                         (same as VmRSS in /proc/[pid]/status)
              shared     (3) number of resident shared pages (i.e., backed by a file)
                         (same as RssFile+RssShmem in /proc/[pid]/status)
              text       (4) text (code)
              lib        (5) library (unused since Linux 2.6; always 0)
              data       (6) data + stack
              dt         (7) dirty pages (unused since Linux 2.6; always 0)
</code></pre>
</blockquote>

<pre><code>cat /proc/31520/statm
1217567 835883 84912 29 0 955887 0
</code></pre>

<ul>
<li>memory-related fields in <strong>/proc/[pid]/status</strong> (notably <code>Vm*</code> and <code>Rss*</code>), might be preferable if you also collect other info from this file</li>
</ul>

<blockquote>
<pre><code>          * VmPeak: Peak virtual memory size.

          * VmSize: Virtual memory size.

          * VmLck: Locked memory size (see mlock(3)).

          * VmPin: Pinned memory size (since Linux 3.2).  These are
            pages that can't be moved because something needs to
            directly access physical memory.

          * VmHWM: Peak resident set size (""high water mark"").

          * VmRSS: Resident set size.  Note that the value here is the
            sum of RssAnon, RssFile, and RssShmem.

          * RssAnon: Size of resident anonymous memory.  (since Linux
            4.5).

          * RssFile: Size of resident file mappings.  (since Linux 4.5).

          * RssShmem: Size of resident shared memory (includes System V
            shared memory, mappings from tmpfs(5), and shared anonymous
            mappings).  (since Linux 4.5).

          * VmData, VmStk, VmExe: Size of data, stack, and text
            segments.

          * VmLib: Shared library code size.

          * VmPTE: Page table entries size (since Linux 2.6.10).

          * VmPMD: Size of second-level page tables (since Linux 4.0).

          * VmSwap: Swapped-out virtual memory size by anonymous private
            pages; shmem swap usage is not included (since Linux
            2.6.34).
</code></pre>
</blockquote>

<pre><code>server:/&gt; egrep '^(Vm|Rss)' /proc/31520/status
VmPeak:  6315376 kB
VmSize:  4870332 kB
VmLck:         0 kB
VmPin:         0 kB
VmHWM:   5009608 kB
VmRSS:   3344300 kB
VmData:  3822572 kB
VmStk:      1040 kB
VmExe:       116 kB
VmLib:    146736 kB
VmPTE:      8952 kB
VmSwap:        0 kB
</code></pre>

<p>Some processes can, through their behaviour and not through their actual memory footprint, contribute to the overall system memory starvation and eventual demise. So it might also be of interest to look at the <a href=""https://linux-mm.org/OOM_Killer"" rel=""noreferrer"">OOM Killer</a> related information, which already takes into account some trending information:</p>

<ul>
<li><strong>/proc/[pid]/oom_score</strong></li>
</ul>

<blockquote>
<pre><code>          This file displays the current score that the kernel gives to
          this process for the purpose of selecting a process for the
          OOM-killer.  A higher score means that the process is more
          likely to be selected by the OOM-killer.  The basis for this
          score is the amount of memory used by the process, with
          increases (+) or decreases (-) for factors including:

          * whether the process creates a lot of children using fork(2)
            (+);

          * whether the process has been running a long time, or has
            used a lot of CPU time (-);

          * whether the process has a low nice value (i.e., &gt; 0) (+);

          * whether the process is privileged (-); and

          * whether the process is making direct hardware access (-).

          The oom_score also reflects the adjustment specified by the
          oom_score_adj or oom_adj setting for the process.
</code></pre>
</blockquote>

<pre><code>server:/&gt; cat proc/31520/oom_score
103
</code></pre>

<ul>
<li><strong>/proc/[pid]/oom_score_adj</strong> (or its deprecated predecessor <strong>/proc/[pid]/oom_adj</strong>, if need be)</li>
</ul>

<blockquote>
<pre><code>          This file can be used to adjust the badness heuristic used to
          select which process gets killed in out-of-memory conditions.

          The badness heuristic assigns a value to each candidate task
          ranging from 0 (never kill) to 1000 (always kill) to determine
          which process is targeted.  The units are roughly a proportion
          along that range of allowed memory the process may allocate
          from, based on an estimation of its current memory and swap
          use.  For example, if a task is using all allowed memory, its
          badness score will be 1000.  If it is using half of its
          allowed memory, its score will be 500.

          There is an additional factor included in the badness score:
          root processes are given 3% extra memory over other tasks.

          The amount of ""allowed"" memory depends on the context in which
          the OOM-killer was called.  If it is due to the memory
          assigned to the allocating task's cpuset being exhausted, the
          allowed memory represents the set of mems assigned to that
          cpuset (see cpuset(7)).  If it is due to a mempolicy's node(s)
          being exhausted, the allowed memory represents the set of
          mempolicy nodes.  If it is due to a memory limit (or swap
          limit) being reached, the allowed memory is that configured
          limit.  Finally, if it is due to the entire system being out
          of memory, the allowed memory represents all allocatable
          resources.

          The value of oom_score_adj is added to the badness score
          before it is used to determine which task to kill.  Acceptable
          values range from -1000 (OOM_SCORE_ADJ_MIN) to +1000
          (OOM_SCORE_ADJ_MAX).  This allows user space to control the
          preference for OOM-killing, ranging from always preferring a
          certain task or completely disabling it from OOM killing.  The
          lowest possible value, -1000, is equivalent to disabling OOM-
          killing entirely for that task, since it will always report a
          badness score of 0.

          Consequently, it is very simple for user space to define the
          amount of memory to consider for each task.  Setting an
          oom_score_adj value of +500, for example, is roughly
          equivalent to allowing the remainder of tasks sharing the same
          system, cpuset, mempolicy, or memory controller resources to
          use at least 50% more memory.  A value of -500, on the other
          hand, would be roughly equivalent to discounting 50% of the
          task's allowed memory from being considered as scoring against
          the task.

          For backward compatibility with previous kernels,
          /proc/[pid]/oom_adj can still be used to tune the badness
          score.  Its value is scaled linearly with oom_score_adj.

          Writing to /proc/[pid]/oom_score_adj or /proc/[pid]/oom_adj
          will change the other with its scaled value.
</code></pre>
</blockquote>

<pre><code>server:/&gt; cat proc/31520/oom_score_adj 
0
</code></pre>
",47,2017-09-01T15:50:11.330,"['          Provides information about memory usage, measured in pages.\n          The columns are:\n\n              size       (1) total program size\n                         (same as VmSize in /proc/[pid]/status)\n              resident   (2) resident set size\n                         (same as VmRSS in /proc/[pid]/status)\n              shared     (3) number of resident shared pages (i.e., backed by a file)\n                         (same as RssFile+RssShmem in /proc/[pid]/status)\n              text       (4) text (code)\n              lib        (5) library (unused since Linux 2.6; always 0)\n              data       (6) data + stack\n              dt         (7) dirty pages (unused since Linux 2.6; always 0)\n', 'cat /proc/31520/statm\n1217567 835883 84912 29 0 955887 0\n', '          * VmPeak: Peak virtual memory size.\n\n          * VmSize: Virtual memory size.\n\n          * VmLck: Locked memory size (see mlock(3)).\n\n          * VmPin: Pinned memory size (since Linux 3.2).  These are\n            pages that can\'t be moved because something needs to\n            directly access physical memory.\n\n          * VmHWM: Peak resident set size (""high water mark"").\n\n          * VmRSS: Resident set size.  Note that the value here is the\n            sum of RssAnon, RssFile, and RssShmem.\n\n          * RssAnon: Size of resident anonymous memory.  (since Linux\n            4.5).\n\n          * RssFile: Size of resident file mappings.  (since Linux 4.5).\n\n          * RssShmem: Size of resident shared memory (includes System V\n            shared memory, mappings from tmpfs(5), and shared anonymous\n            mappings).  (since Linux 4.5).\n\n          * VmData, VmStk, VmExe: Size of data, stack, and text\n            segments.\n\n          * VmLib: Shared library code size.\n\n          * VmPTE: Page table entries size (since Linux 2.6.10).\n\n          * VmPMD: Size of second-level page tables (since Linux 4.0).\n\n          * VmSwap: Swapped-out virtual memory size by anonymous private\n            pages; shmem swap usage is not included (since Linux\n            2.6.34).\n', ""server:/> egrep '^(Vm|Rss)' /proc/31520/status\nVmPeak:  6315376 kB\nVmSize:  4870332 kB\nVmLck:         0 kB\nVmPin:         0 kB\nVmHWM:   5009608 kB\nVmRSS:   3344300 kB\nVmData:  3822572 kB\nVmStk:      1040 kB\nVmExe:       116 kB\nVmLib:    146736 kB\nVmPTE:      8952 kB\nVmSwap:        0 kB\n"", '          This file displays the current score that the kernel gives to\n          this process for the purpose of selecting a process for the\n          OOM-killer.  A higher score means that the process is more\n          likely to be selected by the OOM-killer.  The basis for this\n          score is the amount of memory used by the process, with\n          increases (+) or decreases (-) for factors including:\n\n          * whether the process creates a lot of children using fork(2)\n            (+);\n\n          * whether the process has been running a long time, or has\n            used a lot of CPU time (-);\n\n          * whether the process has a low nice value (i.e., > 0) (+);\n\n          * whether the process is privileged (-); and\n\n          * whether the process is making direct hardware access (-).\n\n          The oom_score also reflects the adjustment specified by the\n          oom_score_adj or oom_adj setting for the process.\n', 'server:/> cat proc/31520/oom_score\n103\n', '          This file can be used to adjust the badness heuristic used to\n          select which process gets killed in out-of-memory conditions.\n\n          The badness heuristic assigns a value to each candidate task\n          ranging from 0 (never kill) to 1000 (always kill) to determine\n          which process is targeted.  The units are roughly a proportion\n          along that range of allowed memory the process may allocate\n          from, based on an estimation of its current memory and swap\n          use.  For example, if a task is using all allowed memory, its\n          badness score will be 1000.  If it is using half of its\n          allowed memory, its score will be 500.\n\n          There is an additional factor included in the badness score:\n          root processes are given 3% extra memory over other tasks.\n\n          The amount of ""allowed"" memory depends on the context in which\n          the OOM-killer was called.  If it is due to the memory\n          assigned to the allocating task\'s cpuset being exhausted, the\n          allowed memory represents the set of mems assigned to that\n          cpuset (see cpuset(7)).  If it is due to a mempolicy\'s node(s)\n          being exhausted, the allowed memory represents the set of\n          mempolicy nodes.  If it is due to a memory limit (or swap\n          limit) being reached, the allowed memory is that configured\n          limit.  Finally, if it is due to the entire system being out\n          of memory, the allowed memory represents all allocatable\n          resources.\n\n          The value of oom_score_adj is added to the badness score\n          before it is used to determine which task to kill.  Acceptable\n          values range from -1000 (OOM_SCORE_ADJ_MIN) to +1000\n          (OOM_SCORE_ADJ_MAX).  This allows user space to control the\n          preference for OOM-killing, ranging from always preferring a\n          certain task or completely disabling it from OOM killing.  The\n          lowest possible value, -1000, is equivalent to disabling OOM-\n          killing entirely for that task, since it will always report a\n          badness score of 0.\n\n          Consequently, it is very simple for user space to define the\n          amount of memory to consider for each task.  Setting an\n          oom_score_adj value of +500, for example, is roughly\n          equivalent to allowing the remainder of tasks sharing the same\n          system, cpuset, mempolicy, or memory controller resources to\n          use at least 50% more memory.  A value of -500, on the other\n          hand, would be roughly equivalent to discounting 50% of the\n          task\'s allowed memory from being considered as scoring against\n          the task.\n\n          For backward compatibility with previous kernels,\n          /proc/[pid]/oom_adj can still be used to tune the badness\n          score.  Its value is scaled linearly with oom_score_adj.\n\n          Writing to /proc/[pid]/oom_score_adj or /proc/[pid]/oom_adj\n          will change the other with its scaled value.\n', 'server:/> cat proc/31520/oom_score_adj \n0\n']"
182,1916,1683,CC BY-SA 3.0,2017-09-03T06:13:53.890,"<p>You can use the <code>checkout scm</code> step whenever you need the source:</p>

<pre><code>pipeline {
  agent none
  options { skipDefaultCheckout() }
  stages {
    stage('Build') {
      agent { node { label 'builder' } }
      steps {
        checkout scm
        echo 'build-the-app'
        stash(name: 'app', includes: 'outputs')
      }
    }
    stage('Test') {
      agent { node { label 'tester' } }
      steps {
        unstash 'app'
        echo 'test-the-app'
      }
    }
  }
}
</code></pre>
",2450,2017-09-03T06:13:53.890,"[""pipeline {\n  agent none\n  options { skipDefaultCheckout() }\n  stages {\n    stage('Build') {\n      agent { node { label 'builder' } }\n      steps {\n        checkout scm\n        echo 'build-the-app'\n        stash(name: 'app', includes: 'outputs')\n      }\n    }\n    stage('Test') {\n      agent { node { label 'tester' } }\n      steps {\n        unstash 'app'\n        echo 'test-the-app'\n      }\n    }\n  }\n}\n""]"
183,1921,1920,CC BY-SA 3.0,2017-09-04T13:39:42.980,"<p>I have just managed how to escape characters.</p>

<p>The solution is to add: ""\"" before the character.</p>

<pre><code>checkout([\$class:....
</code></pre>
",4197,2017-09-04T13:39:42.980,['checkout([\\$class:....\n']
184,1946,1943,CC BY-SA 3.0,2017-09-07T08:12:33.183,"<p><strong>The host on which the containers are running</strong></p>

<p>Run the docker security bench on every node that runs docker containers <a href=""https://github.com/docker/docker-bench-security"" rel=""noreferrer"">https://github.com/docker/docker-bench-security</a></p>

<p>Running the following command on a node that runs docker containers:</p>

<pre><code>docker run -it --net host --pid host --cap-add audit_control \
    -e DOCKER_CONTENT_TRUST=$DOCKER_CONTENT_TRUST \
    -v /var/lib:/var/lib \
    -v /var/run/docker.sock:/var/run/docker.sock \
    -v /usr/lib/systemd:/usr/lib/systemd \
    -v /etc:/etc --label docker_bench_security \
    docker/docker-bench-security
</code></pre>

<p>returns a list of checks:</p>

<pre><code>[INFO] 1 - Host Configuration

[WARN] 1.1  - Ensure a separate partition for containers has been created

[NOTE] 4.2  - Ensure that containers use trusted base images

[PASS] 4.6  - Ensure HEALTHCHECK instructions have been added to the container image
</code></pre>

<p>Quote from the repository README:</p>

<blockquote>
  <p>The Docker Bench for Security is a script that checks for dozens of
  common best-practices around deploying Docker containers in
  production. The tests are all automated, and are inspired by the <a href=""https://benchmarks.cisecurity.org/tools2/docker/CIS_Docker_Community_Edition_Benchmark_v1.1.0.pdf"" rel=""noreferrer"">CIS
  Docker Community Edition Benchmark
  v1.1.0</a>.</p>
</blockquote>

<p>Some of the issues that are reported by the security bench could be solved by reading <a href=""https://docs.docker.com/engine/security/security/"" rel=""noreferrer"">the official docker security article</a> and comparing it with the bullets that are defined in the question the following things are important as well:</p>

<ul>
<li>protect the docker daemon socket by implementing ssl</li>
<li>content trust using notary and <code>DOCKER_CONTENT_TRUST</code> variable</li>
</ul>
",210,2017-09-07T15:06:31.313,"['docker run -it --net host --pid host --cap-add audit_control \\\n    -e DOCKER_CONTENT_TRUST=$DOCKER_CONTENT_TRUST \\\n    -v /var/lib:/var/lib \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v /usr/lib/systemd:/usr/lib/systemd \\\n    -v /etc:/etc --label docker_bench_security \\\n    docker/docker-bench-security\n', '[INFO] 1 - Host Configuration\n\n[WARN] 1.1  - Ensure a separate partition for containers has been created\n\n[NOTE] 4.2  - Ensure that containers use trusted base images\n\n[PASS] 4.6  - Ensure HEALTHCHECK instructions have been added to the container image\n']"
185,1959,1957,CC BY-SA 3.0,2017-09-08T04:07:11.573,"<p>Compared to just adding the user to the docker group the second links solution is not any more secure.</p>

<p>Note how that page still can launch with the <code>--privileged</code> flag, and that it is running unconfined.</p>

<p><code>unconfined_u:unconfined_r:unconfined_t</code></p>

<p>This means that the container can access all resources including the hosts disks and hardware.  It is security through obscurity, which is not security.  Anyone who knows how to use <code>mknod</code> or walk the /sys and /proc trees could easily compromise the host and all containers with zero logging.</p>

<p>The reality is that docker shifts both complexity and the security boundaries.  All users who can launch container or hit the API need to be restricted to trusted users in that security context.</p>

<p><code>--privileged</code> disables all apparmor and selinux policies which is actually far less secure than a native package.</p>

<p>Namespaces are not a security function and depend on apparmor and selinux to enforce reasonable constraints.</p>

<p>Docker notes this on this page.</p>

<p><a href=""https://docs.docker.com/engine/security/security/#control-groups"" rel=""nofollow noreferrer"">https://docs.docker.com/engine/security/security/#control-groups</a></p>

<p>'First of all, only trusted users should be allowed to control your Docker daemon.'</p>

<p>The security functions of docker/kube are not administrative boundaries like classical unix permissions, they are tools to prevent non-privileged containers from breaking out.</p>

<p>In a docker world the administrative boundary becomes the host, and the selection and segmentation required to isolate applications or users within that context needs to be applied at that boundary.</p>

<p>The benefits of this shift in complexity and responsibility generally outweigh the risks if implemented with those changes in mind.</p>

<p>TLDR</p>

<p>Docker API user == Sudo ALL user</p>

<p>Running a container with the --privlaged flag == running a web service as suid or as the root user.</p>

<p><strong>Edited per the OP's request for additional information</strong></p>

<p>The referenced issue with breakout int he OP's edit was an non <strong>uid0</strong> privilege escalation.</p>

<p>Unfortunately, due to the need to perform root only actions Docker needs to enable some capabilities so that apt/dnf can install packages etc...</p>

<p>This need does pose a risk if production workloads are run in this default configuration and one should adopt the security principle of least privilege for production workloads.</p>

<p><code>--privileged</code> disables <em>apparmor/selinux</em> and opens up <em>capabilities</em></p>

<p>I am using ubuntu but it may be useful to work through the following steps. First start a default container with <em>docker run -i --rm -t debian bash</em></p>

<p>From the parent host find the PID for bash using <em>ps</em> and note that the process is owned <em>root</em>.  If you look in <code>/proc/$PID/status</code> you will see the contexts it is running under.</p>

<pre><code># egrep '^Cap(Prm|Inh|Eff)' /proc/16026/status
 CapInh:    00000000a80425fb
 CapPrm:    00000000a80425fb
 CapEff:    00000000a80425fb
</code></pre>

<p>You will want to refer to <em>man 7 man capabilities</em> and <em>/usr/include/linux/capability.h</em> for better info but a summer is</p>

<p>CapInh = The Inherited capabilities (what docker provided)
CapPrm = The capabilities due to permissions (inside the container OS)
CapEff = The effective capabilities</p>

<p>You can decode these to human readable form by running:</p>

<pre><code>$ capsh --decode=00000000a80425fb
</code></pre>

<p>Now do the same with <code>$ docker run -i --rm --privileged -t debian bash</code> and you will find that the effective capabilities are <code>0000003fffffffff</code></p>

<p>Also just do a <code>dir /dev</code> in both VM's and you will see just how much access a privileged container has.</p>

<p>By looking at <code>/etc/apparmor.d/docker</code> for apparmor systems or the lables in SElinux you will see the implications.</p>

<p>Going back to the principle of least privileges, I would ensure that my docker container is running process as a unprivileged user and with as few enabled capabilities as possible.</p>

<p>As an example, you can test this by running it first by dropping all caps.</p>

<pre><code>$ docker run -i --rm -t --cap-drop=all -t debian bash
</code></pre>

<p>This can be validated through the <code>/proc/$PID/status</code> method above.</p>

<pre><code>CapInh: 0000000000000000
CapPrm: 0000000000000000
CapEff: 0000000000000000
</code></pre>

<p>Note it is all zeros, from CapInh.  Then if I had to enable features for the application I would use <code>--cap-add</code> <em>after</em> the <code>--cap-drop=all</code></p>

<p>Example, <code>--cap-drop=all</code> will break ping:</p>

<pre><code># ping -c 1 www.google.com
ping: Lacking privilege for raw socket.
</code></pre>

<p>So we can add the <code>cap_net_raw</code> cap. Docker expects the arguments with the <code>cap_</code> prefix removed so the command is <code>docker run -i --rm -t --cap-drop=all --cap-add=net_raw -t debian bash</code></p>

<pre><code># ping -c 1 www.google.com
PING www.google.com (216.58.216.164): 56 data bytes
64 bytes from 216.58.216.164: icmp_seq=0 ttl=54 time=4.779 ms
</code></pre>

<p>But be very careful adding them as an example.</p>

<p>cap_sys_module will allow a container to add or remove kernel modules from the parent host.</p>

<p>cap_sys_rawio will open memory and <em>all</em> block devices to attack</p>

<p>cap_sys_admin is super dangerous.</p>

<p>So in this case I would see if you can make things run in this context.</p>

<p>$ docker run -i --rm -t --cap-drop=all -u nobody:nogroup -t debian bash</p>

<p>Hopefully the robustness of apparmor and selinux profiles improves over time, but if that is not enough for your security needs you can look in there too.</p>

<p>Really, avoiding the <em>--privileged</em> flag and using principle of least privilege will make the most impact. Especially if you take advantage of the ephemeral nature of containers to keep packages up to date.</p>

<p>If you need more Red Hat covers some basic seccomp options here.</p>

<p><a href=""https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html/container_security_guide/linux_capabilities_and_seccomp"" rel=""nofollow noreferrer"">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html/container_security_guide/linux_capabilities_and_seccomp</a></p>
",2846,2017-09-09T23:31:53.950,"[""# egrep '^Cap(Prm|Inh|Eff)' /proc/16026/status\n CapInh:    00000000a80425fb\n CapPrm:    00000000a80425fb\n CapEff:    00000000a80425fb\n"", '$ capsh --decode=00000000a80425fb\n', '$ docker run -i --rm -t --cap-drop=all -t debian bash\n', 'CapInh: 0000000000000000\nCapPrm: 0000000000000000\nCapEff: 0000000000000000\n', '# ping -c 1 www.google.com\nping: Lacking privilege for raw socket.\n', '# ping -c 1 www.google.com\nPING www.google.com (216.58.216.164): 56 data bytes\n64 bytes from 216.58.216.164: icmp_seq=0 ttl=54 time=4.779 ms\n']"
186,1961,1960,CC BY-SA 3.0,2017-09-08T06:25:44.323,"<p>If <code>/var/log/mysql:/var/log/mysql</code> is defined as a volume then the content that reside in the container's <code>/var/log/mysql/</code> will be stored in the <code>/var/log/mysql/</code> folder on the host.</p>

<p>It could be possible that it is not possible to mount the <code>/var/lib/mysql</code> as SElinux or app armor is preventing this.</p>

<p><a href=""https://hub.docker.com/_/mysql/"" rel=""nofollow noreferrer"">https://hub.docker.com/_/mysql/</a></p>

<blockquote>
  <p>Note that users on host systems with SELinux enabled may see issues
  with this. The current workaround is to assign the relevant SELinux
  policy type to the new data directory so that the container will be
  allowed to access it:</p>

<pre><code>$ chcon -Rt svirt_sandbox_file_t /my/own/datadir
</code></pre>
</blockquote>
",210,2017-09-08T10:20:37.583,['$ chcon -Rt svirt_sandbox_file_t /my/own/datadir\n']
187,1980,1978,CC BY-SA 3.0,2017-09-11T13:00:56.343,"<p>Ok, let's assume you'll pull the latest version of branch prod from a git repo, here's what it would take with chef on a basic illustrative purpose:</p>

<pre><code>git ""/opt/my_application"" do
  source ""https://&lt;git_host&gt;/&lt;you_repo_url&gt;/&lt;repo.git&gt;""
  revision ""production""
  action :sync
  notifies :run,""execute[app_config]""
end

execute ""app_config"" do
  command ""npm install""
  cwd ""/opt/my_application""
  action :nothing
end
</code></pre>

<p>For more advanced use cases you can have a look at the <a href=""https://github.com/poise/application"" rel=""nofollow noreferrer"">poise</a> application cookbooks, it includes a <a href=""https://github.com/poise/application_javascript"" rel=""nofollow noreferrer"">javascript plugin</a> for node.js application.</p>

<p>chef is fully open source, either client or server side (out of the fancy UI) and on all OSes including windows.</p>
",13,2017-09-11T13:00:56.343,"['git ""/opt/my_application"" do\n  source ""https://<git_host>/<you_repo_url>/<repo.git>""\n  revision ""production""\n  action :sync\n  notifies :run,""execute[app_config]""\nend\n\nexecute ""app_config"" do\n  command ""npm install""\n  cwd ""/opt/my_application""\n  action :nothing\nend\n']"
188,1983,1940,CC BY-SA 3.0,2017-09-11T15:07:33.703,"<p>You might not be able to get this done on the free tier. Puppet for example isn't going to want to start because of the RAM limitations. The AWS free tier uses thje t2.micro instance which only has <a href=""https://aws.amazon.com/ec2/instance-types/"" rel=""noreferrer"">1GB of RAM</a>. Your operating system alone probably needs 512 to run at idle. This leaves you a mere 512 MB or ram for all of the things that you listed.</p>

<p>While the issue with puppet not starting <a href=""https://docs.puppet.com/puppetserver/latest/install_from_packages.html#settings"" rel=""noreferrer"">can be overcome</a> by editing <code>/etc/sysconfig/puppetserver</code> and setting something like:</p>

<pre><code>JAVA_ARGS=""-Xms512m -Xmx512m""
</code></pre>

<p>(this issue arises because puppet expects 2 GB or RAM out of the box)</p>

<p>You are bound to find that running all of these on a single server is debilitating and painful with only 1 GB of RAM. You should probably consider using something like <a href=""https://www.virtualbox.org/wiki/VirtualBox"" rel=""noreferrer"">virtualbox</a> on your PC or laptop so that you can get some more ram than that offered by the AWS free tier. I'd say you want at least 4 or maybe 8 GB of RAM. While this probably <em>can</em> be done, I don't recommend it. You may have to stop one service to run another which then makes it difficult to have one talk to the other (eg, ansible talk to Jenkins while puppet is running, for example.)</p>
",2845,2017-09-11T15:07:33.703,"['JAVA_ARGS=""-Xms512m -Xmx512m""\n']"
189,1987,1976,CC BY-SA 3.0,2017-09-11T19:42:32.010,"<p>I prefer <a href=""https://docs.gitlab.com/ce/ci/docker/using_docker_build.html"" rel=""nofollow noreferrer"">DIND</a> as every run start with a clean sheet. Otherwise the docker image will be built on the gitlab host itself.</p>

<ul>
<li>installation of gitlab runner</li>
<li>registration of runner</li>
</ul>

<blockquote>
<pre><code>sudo gitlab-ci-multi-runner register -n \
  --url https://gitlab.com/ \
  --registration-token REGISTRATION_TOKEN \
  --executor docker \
  --description ""My Docker Runner"" \
  --docker-image ""docker:latest"" \
  --docker-privileged
</code></pre>
</blockquote>

<ul>
<li>commit and push .gitlab-ci.yml</li>
</ul>

<blockquote>
<pre><code>image: docker:latest

# When using dind, it's wise to use the overlayfs driver for
# improved performance.
variables:
  DOCKER_DRIVER: overlay2

services:
- docker:dind

before_script:
- docker info

build:
  stage: build
  script:
  - docker build -t my-docker-image .
  - docker run my-docker-image /script/to/run/tests
</code></pre>
</blockquote>
",210,2017-09-11T19:42:32.010,"['sudo gitlab-ci-multi-runner register -n \\\n  --url https://gitlab.com/ \\\n  --registration-token REGISTRATION_TOKEN \\\n  --executor docker \\\n  --description ""My Docker Runner"" \\\n  --docker-image ""docker:latest"" \\\n  --docker-privileged\n', ""image: docker:latest\n\n# When using dind, it's wise to use the overlayfs driver for\n# improved performance.\nvariables:\n  DOCKER_DRIVER: overlay2\n\nservices:\n- docker:dind\n\nbefore_script:\n- docker info\n\nbuild:\n  stage: build\n  script:\n  - docker build -t my-docker-image .\n  - docker run my-docker-image /script/to/run/tests\n""]"
190,1988,623,CC BY-SA 3.0,2017-09-11T22:59:08.663,"<p>I used the following script on GitHub by Rodrigue Koffi (bonclay7) and it works pretty good.</p>

<p><a href=""https://github.com/bonclay7/aws-amicleaner"" rel=""noreferrer"">https://github.com/bonclay7/aws-amicleaner</a></p>

<p>Command:</p>

<pre><code>amicleaner --check-orphans
</code></pre>

<p>From the documentation <a href=""http://techblog.d2-si.eu/2017/06/15/cleaning-your-amazon-machine-images.html"" rel=""noreferrer"">blog post</a> it does some more things:</p>

<blockquote>
  <p>It actually does a bit more than that, at of today it allows:</p>
  
  <ul>
  <li>Removing a list of images and associated snapshots</li>
  <li>Mapping AMIs:
  
  <ul>
  <li>Using names</li>
  <li>Using tags</li>
  </ul></li>
  <li>Filtering AMIs:
  
  <ul>
  <li>used by running instances</li>
  <li>from autoscaling groups (launch configurations) with a desired capacity set to 0</li>
  <li>from launch configurations detached from autoscaling groups</li>
  </ul></li>
  <li>Specifying how many AMIs you want to keep</li>
  <li>Cleaning orphan snapshots</li>
  <li>A bit of reporting</li>
  </ul>
</blockquote>
",4297,2017-09-12T07:51:46.423,['amicleaner --check-orphans\n']
191,1990,1976,CC BY-SA 3.0,2017-09-12T08:57:41.220,"<p>Gitlab CI supports running all of your builds inside Docker containers so you have a clean build environment every time. I'd recommend starting with the basic <a href=""https://docs.gitlab.com/runner/executors/docker.html"" rel=""nofollow noreferrer"">Docker executor</a> but there is also an opportunity to <a href=""https://docs.gitlab.com/runner/install/autoscaling.html"" rel=""nofollow noreferrer"">autoscale your runners</a> using <a href=""https://docs.docker.com/machine/"" rel=""nofollow noreferrer"">Docker Machine</a> or to <a href=""https://docs.gitlab.com/runner/executors/kubernetes.html"" rel=""nofollow noreferrer"">execute the runners on a Kubernetes pod</a>.</p>

<p>If you need to use Docker as part of your build (such as building, tagging and pushing images) then you can either use <a href=""https://docs.gitlab.com/ce/ci/docker/using_docker_build.html#use-docker-in-docker-executor"" rel=""nofollow noreferrer"">Docker in Docker</a> or, preferably, <a href=""https://docs.gitlab.com/ce/ci/docker/using_docker_build.html#use-docker-socket-binding"" rel=""nofollow noreferrer"">bind mount the Docker socket</a> of the host into your runner allowing it to run Docker containers as a sibling rather than child process. Note that the <a href=""https://jpetazzo.github.io/"" rel=""nofollow noreferrer"">original author of DIND</a> <a href=""https://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/"" rel=""nofollow noreferrer"">recommends</a> using bind mounting instead of DIND, especially for CI.</p>

<p>To bind mount the Docker socket register your runner with the following command:</p>

<pre><code>sudo gitlab-runner register -n \
  --url https://gitlab.com/ \
  --registration-token REGISTRATION_TOKEN \
  --executor docker \
  --description ""My Docker Runner"" \
  --docker-image ""docker:latest"" \
  --docker-volumes /var/run/docker.sock:/var/run/docker.sock
</code></pre>

<p>And then in your <code>.gitlab-ci.yml</code> file you can define your job as so:</p>

<pre><code>image: docker:latest

before_script:
- docker info

build:
  stage: build
  script:
  - docker build -t my-docker-image .
  - docker run my-docker-image /script/to/run/tests
</code></pre>

<p>Using just the basic <code>docker</code> image rather than the <code>docker:dind</code> image</p>
",4018,2017-09-12T08:57:41.220,"['sudo gitlab-runner register -n \\\n  --url https://gitlab.com/ \\\n  --registration-token REGISTRATION_TOKEN \\\n  --executor docker \\\n  --description ""My Docker Runner"" \\\n  --docker-image ""docker:latest"" \\\n  --docker-volumes /var/run/docker.sock:/var/run/docker.sock\n', 'image: docker:latest\n\nbefore_script:\n- docker info\n\nbuild:\n  stage: build\n  script:\n  - docker build -t my-docker-image .\n  - docker run my-docker-image /script/to/run/tests\n']"
192,1993,1969,CC BY-SA 3.0,2017-09-12T15:02:15.730,"<p>Could you please try the commands above between all hosts ?</p>

<p>INSIDE HOST A: </p>

<pre><code>nc -zv HOST_B_IP_ADDRESS 2377,4789,7946
nc -zv HOST_C_IP_ADDRESS 2377,4789,7946
</code></pre>

<p>INSIDE HOST B: </p>

<pre><code>nc -zv HOST_A_IP_ADDRESS 2377,4789,7946
nc -zv HOST_C_IP_ADDRESS 2377,4789,7946
</code></pre>

<p>INSIDE HOST C: </p>

<pre><code>nc -zv HOST_A_IP_ADDRESS 2377,4789,7946
nc -zv HOST_B_IP_ADDRESS 2377,4789,7946
</code></pre>

<p>As explained in <a href=""https://docs.docker.com/engine/swarm/swarm-tutorial/#open-protocols-and-ports-between-the-hosts"" rel=""nofollow noreferrer"">https://docs.docker.com/engine/swarm/swarm-tutorial/#open-protocols-and-ports-between-the-hosts</a>, some ports must be available between hosts in order for Docker Swarm to work correctly.</p>

<p>The error reported sounds like a port related problem. 
Maybe is there another application in one of these hosts already using one of the ports needed by Docker ? Maybe a firewall configuration ?</p>
",4290,2017-09-12T15:02:15.730,"['nc -zv HOST_B_IP_ADDRESS 2377,4789,7946\nnc -zv HOST_C_IP_ADDRESS 2377,4789,7946\n', 'nc -zv HOST_A_IP_ADDRESS 2377,4789,7946\nnc -zv HOST_C_IP_ADDRESS 2377,4789,7946\n', 'nc -zv HOST_A_IP_ADDRESS 2377,4789,7946\nnc -zv HOST_B_IP_ADDRESS 2377,4789,7946\n']"
193,2000,1985,CC BY-SA 3.0,2017-09-13T12:19:44.043,"<p>Run:</p>

<pre><code>$ sudo touch /usr/local/etc/ansible/hosts
$ sudo vi /usr/local/etc/ansible/hosts
</code></pre>

<p>To create a file and then open it.</p>
",4313,2017-09-13T12:19:44.043,['$ sudo touch /usr/local/etc/ansible/hosts\n$ sudo vi /usr/local/etc/ansible/hosts\n']
194,2022,2021,CC BY-SA 3.0,2017-09-15T13:21:36.553,"<p><a href=""https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226"" rel=""nofollow noreferrer"">https://rominirani.com/tutorial-getting-started-with-kubernetes-on-your-windows-laptop-with-minikube-3269b54a226</a></p>

<pre><code>user@host ~ $ minikube start --kubernetes-version=""v1.7.5""
Starting local Kubernetes v1.7.5 cluster...
Starting VM...
</code></pre>
",210,2017-09-15T13:21:36.553,"['user@host ~ $ minikube start --kubernetes-version=""v1.7.5""\nStarting local Kubernetes v1.7.5 cluster...\nStarting VM...\n']"
195,2023,1995,CC BY-SA 3.0,2017-09-15T14:02:55.227,"<p>This question was kindly answered on StackOverflow. For anyone else looking for an answer:</p>

<pre><code>&lt;PropertyGroup&gt;
  &lt;BuildParameters&gt;
    Configuration=Debug;
    Platform=Any CPU;
        SomeOtherProperty=Foo
  &lt;/BuildParameters&gt;
&lt;/PropertyGroup&gt;
…
&lt;PropertyGroup&gt;
  &lt;!-- this property can even be extended afterwards, e.g. when a condition is needed --&gt;
  &lt;BuildParameters Condition="" '$(ShallAppendThings)' == 'true' ""&gt;
    $(BuildParameters);
    AnotherProperty=SomeValue
  &lt;/BuildParameters&gt;
&lt;/PropertyGroup&gt;
…

&lt;MSBuild Projects=""$(SolutionFile)"" Targets=""Build"" Properties=""$(BuildProperties)"" /&gt;
</code></pre>

<p>source:
<a href=""https://stackoverflow.com/questions/46226120/how-to-pass-dynamic-properties-to-an-msbuild-task"">https://stackoverflow.com/questions/46226120/how-to-pass-dynamic-properties-to-an-msbuild-task</a></p>
",3646,2017-09-15T14:02:55.227,"['<PropertyGroup>\n  <BuildParameters>\n    Configuration=Debug;\n    Platform=Any CPU;\n        SomeOtherProperty=Foo\n  </BuildParameters>\n</PropertyGroup>\n…\n<PropertyGroup>\n  <!-- this property can even be extended afterwards, e.g. when a condition is needed -->\n  <BuildParameters Condition="" \'$(ShallAppendThings)\' == \'true\' "">\n    $(BuildParameters);\n    AnotherProperty=SomeValue\n  </BuildParameters>\n</PropertyGroup>\n…\n\n<MSBuild Projects=""$(SolutionFile)"" Targets=""Build"" Properties=""$(BuildProperties)"" />\n']"
196,2024,1981,CC BY-SA 3.0,2017-09-15T14:23:24.017,"<p><a href=""https://github.com/030/ansible-certbot"" rel=""nofollow noreferrer"">https://github.com/030/ansible-certbot</a></p>

<p>main.yml</p>

<pre><code>- include: Debian.yml
when: ansible_os_family == 'Debian'
</code></pre>

<p>put everything that is required on debian like apt in Debian.yml and yum in Centos.yml.</p>

<p>In summary, it is possible to let all OS types use the same role if the OS specific things are put in separate files.</p>

<p>This is a more comprehensive example <a href=""https://github.com/geerlingguy/ansible-role-mysql/blob/master/tasks/main.yml"" rel=""nofollow noreferrer"">https://github.com/geerlingguy/ansible-role-mysql/blob/master/tasks/main.yml</a></p>
",210,2017-09-15T14:23:24.017,"[""- include: Debian.yml\nwhen: ansible_os_family == 'Debian'\n""]"
197,2025,1981,CC BY-SA 3.0,2017-09-15T16:32:08.357,"<p>So I managed to keep the same structure roughly, and managed to separate how the machines are generated, however still is a bit fuzzy and can probably be improved to be more efficient!</p>

<hr>

<p><strong>site.yml</strong></p>

<pre><code>- name: Apply common configuration to all nodes
  hosts: all
  roles:
    - common

- name: Configure and deploy test node 1
  hosts: build-test-node
  roles:
    - build-machine-test-1

- name: Configure and deploy test node 2
  hosts: build-test-node-2
  roles:
    - build-machine-test-2
</code></pre>

<hr>

<p><strong>environments/test/groups</strong></p>

<pre><code>[win_test_1_nodes]
win_build_machine_1

[mac_test_1_nodes]
mac_build_machine_1

[win_test_2_nodes]
win_build_machine_2

[mac_test_2_nodes]
mac_build_machine_2
</code></pre>

<hr>

<p><strong>environments/test/hosts</strong></p>

<pre><code>win_build_machine_1   ansible_host=......
win_build_machine_2   ansible_host=......
mac_build_machine_1   ansible_host=......
mac_build_machine_2   ansible_host=......
</code></pre>

<hr>

<p><strong>environments/test/meta</strong></p>

<pre><code>[win_test_1_nodes]
[mac_test_1_nodes]
[win_test_2_nodes]
[mac_test_2_nodes]

[win:children]
win_test_1_nodes
win_test_2_nodes

[mac:children]
mac_test_1_nodes
mac_test_2_nodes

[build-machine-test-1:children]
win_test_1_nodes
mac_test_1_nodes

[build-machine-test-2:children]
win_test_2_nodes
mac_test_2_nodes
</code></pre>

<hr>

<p>This solution allows more test nodes to be generated with separate roles added to them, and can just be added to the correct group for the machine to be provisioned.</p>
",4289,2017-09-15T16:32:08.357,"['- name: Apply common configuration to all nodes\n  hosts: all\n  roles:\n    - common\n\n- name: Configure and deploy test node 1\n  hosts: build-test-node\n  roles:\n    - build-machine-test-1\n\n- name: Configure and deploy test node 2\n  hosts: build-test-node-2\n  roles:\n    - build-machine-test-2\n', '[win_test_1_nodes]\nwin_build_machine_1\n\n[mac_test_1_nodes]\nmac_build_machine_1\n\n[win_test_2_nodes]\nwin_build_machine_2\n\n[mac_test_2_nodes]\nmac_build_machine_2\n', 'win_build_machine_1   ansible_host=......\nwin_build_machine_2   ansible_host=......\nmac_build_machine_1   ansible_host=......\nmac_build_machine_2   ansible_host=......\n', '[win_test_1_nodes]\n[mac_test_1_nodes]\n[win_test_2_nodes]\n[mac_test_2_nodes]\n\n[win:children]\nwin_test_1_nodes\nwin_test_2_nodes\n\n[mac:children]\nmac_test_1_nodes\nmac_test_2_nodes\n\n[build-machine-test-1:children]\nwin_test_1_nodes\nmac_test_1_nodes\n\n[build-machine-test-2:children]\nwin_test_2_nodes\nmac_test_2_nodes\n']"
198,2037,1239,CC BY-SA 3.0,2017-09-16T01:14:26.677,"<p>There are a few GitHub repos regarding Ansible best practices, and I've found <a href=""https://github.com/enginyoyen/ansible-best-practises"" rel=""nofollow noreferrer"">enginyoyen/ansible-best-practices</a> helpful not only in your case but also to understand the playbook/inventory/role/task differences in a full-blown Ansible project. </p>

<p>Some highlights: (<code>/</code> refers to the <strong>project's</strong> home directory)</p>

<ul>
<li>Your variables do indeed go in <code>/group_vars/</code>

<ul>
<li><code>/group_vars/windows.yml</code> will be automatically read by hosts you assign to the windows <strong>group</strong> </li>
<li><code>/group_vars/db.yml</code> will be automatically read by hosts you assign to the db <strong>group</strong> and so on</li>
</ul></li>
<li>You may also include files with names like <code>/host_vars/win_host_1.yml</code> which will be read only by that host </li>
<li><p>The groups from <code>/group_vars/</code> are defined in your inventory file<strong>s</strong> (plural)</p>

<pre><code>[windows]
win_host1.example.com
win_host_2.example.com
</code></pre></li>
<li><p>Inventory files have names like <code>/production.yml</code> and <code>/staging.yml</code> to help ensure code in different states of readiness is deployed to (ideally) identical environments.</p></li>
</ul>

<p>Other highlights not directly answering your question</p>

<ul>
<li>A <em>role</em> is a file made of the <em>tasks</em> required to do something, like install <code>nginx</code>. They have names like <code>/roles/install_nginx.yml</code></li>
<li>Playbooks have names like <code>/playbooks/win_hosts.yml</code> which do nothing but match the <em>groups</em> from your inventory files with the <em>roles</em> you want hosts in those groups to run. </li>
<li><strong>When you run <code>ansible-playbook</code> your <code>$HOME</code> should be  <code>/playbooks/</code></strong> so that the different inventory files are referred as <code>ansible-playbook -i ../production.yml win_hosts.yml</code></li>
<li>This is also the place to put a custom ansible config file, <code>/playbooks/ansible.cfg</code></li>
<li>There's also a way to manage <em>external</em> roles from Ansible Galaxy or GitHub and keep them separate from custom roles you built, but still in your project directory instead of <code>/etc/ansible/roles/</code> where <code>ansible-galaxy</code> puts them by default.</li>
<li>A nice little bash script to install Ansible </li>
</ul>
",222,2017-09-16T01:14:26.677,['[windows]\nwin_host1.example.com\nwin_host_2.example.com\n']
199,2041,2038,CC BY-SA 3.0,2017-09-16T14:28:12.983,"<p>I think that according to chef documentation you should use <code>normal</code> with node data.</p>

<blockquote>
  <p>A normal attribute is a setting that persists in the node object. A
  normal attribute has a higher attribute precedence than a default
  attribute.</p>
</blockquote>

<p>you can read about it here:</p>

<p><a href=""https://docs.chef.io/attributes.html"" rel=""nofollow noreferrer"">https://docs.chef.io/attributes.html</a></p>

<p><a href=""https://docs.chef.io/knife_node.html"" rel=""nofollow noreferrer"">https://docs.chef.io/knife_node.html</a></p>

<p>some example:</p>

<pre><code>  ""normal"": {
    ""ebs"": {
      ""devices"": [
        {
          ""mount_device"": ""/dev/xvdf"",
          ""encrypt"": true,
          ""volume_mapping"": [
            {
              ""device"": ""/dev/xvdf""
            }
          ]
        }
      ]
    },
</code></pre>

<p>In you recipe:</p>

<pre><code>if node.ebs.devices[0]['mount_device'] == '/dev/xvdf' and node.ebs.devices[0]['encrypt'] ...
</code></pre>

<p>Another example with <code>node['myattribute']</code></p>

<pre><code>   ""normal"": {
        ""myattribute"": ""myvalue""
        },
</code></pre>
",342,2017-09-16T14:47:49.773,"['  ""normal"": {\n    ""ebs"": {\n      ""devices"": [\n        {\n          ""mount_device"": ""/dev/xvdf"",\n          ""encrypt"": true,\n          ""volume_mapping"": [\n            {\n              ""device"": ""/dev/xvdf""\n            }\n          ]\n        }\n      ]\n    },\n', ""if node.ebs.devices[0]['mount_device'] == '/dev/xvdf' and node.ebs.devices[0]['encrypt'] ...\n"", '   ""normal"": {\n        ""myattribute"": ""myvalue""\n        },\n']"
200,2042,2027,CC BY-SA 3.0,2017-09-17T03:02:04.953,"<p>The error you see in your container is:</p>

<blockquote>
  <p>etcd.EtcdConnectionFailed: Connection to etcd failed due to MaxRetryError(u""HTTPConnectionPool(host=u'localhost', port=2379): Max retries exceeded with url: /v2/keys/my_module/nodes (Caused by NewConnectionError(': Failed to establish a new connection: [Errno 111] Connection refused',))"",)</p>
</blockquote>

<p>If you take a close look there, you can see that it's trying to connect to <code>localhost</code>.  Inside your container, <code>localhost</code> is means ""the current container"" (much like <code>localhost</code> on your host means ""the current host""). If you want to connect to an <code>etcd</code> instance <em>outside</em> of the container, you'll need to use the ip address (or hostname) of another server.</p>

<p>If you're running (a) running Docker locally, (b) etcd on your host is listening on all addresses, and (c) there are no firewall rules that would otherwise prohibit the connection, then you can use the address of the Docker bridge associated with your container as the address of your host.  This will be the default gateway as seen from inside the container.  You can extract the address with something like:</p>

<pre><code>ip route show | awk '$1 == ""default"" {print $3}'
</code></pre>
",4011,2017-09-17T03:02:04.953,"['ip route show | awk \'$1 == ""default"" {print $3}\'\n']"
201,2043,1958,CC BY-SA 3.0,2017-09-17T08:38:56.583,"<blockquote>
  <p>What are the general ways to tackle this problem?</p>
</blockquote>

<p>The ideal way to resolve your problem would be to dockerise your application, as it would remove any worries you have about compatibility between your build and running servers. Installing dependencies using pip in a Dockerfile is trivial, and as long as you're deploying the same container image you never need to worry about inconsistency.</p>

<p>Edit: as luck would have it I actually found myself wanting to have a venv that worked both inside and outside Docker, so I came up with the following:</p>

<pre><code>python3.6 -m venv --copies venv
sed -i '43s/.*/VIRTUAL_ENV=""$(cd ""$(dirname ""$(dirname ""${BASH_SOURCE[0]}"" )"")"" \&amp;\&amp; pwd)""/' venv/bin/activate
sed -i '1s/.*/#!\/usr\/bin\/env python/' venv/bin/pip*
</code></pre>
",4369,2018-01-22T05:33:34.667,"['python3.6 -m venv --copies venv\nsed -i \'43s/.*/VIRTUAL_ENV=""$(cd ""$(dirname ""$(dirname ""${BASH_SOURCE[0]}"" )"")"" \\&\\& pwd)""/\' venv/bin/activate\nsed -i \'1s/.*/#!\\/usr\\/bin\\/env python/\' venv/bin/pip*\n']"
202,2044,1960,CC BY-SA 3.0,2017-09-17T08:43:35.020,"<p>If you're running a RedHat-based distribution e.g. Fedora or CentOS, you may have SELinux turned on by default. You can automatically permit your containers to access files on the hosts by mounting with the <code>:Z</code> option, like so:</p>

<pre><code>  volumes:
   - ./database:/var/lib/mysql:Z
   - ./_conf/mariadb.cnf:/etc/mysql/my.cnf:Z
   - ./logs:/var/log/mysql:Z
</code></pre>
",4369,2017-09-17T08:43:35.020,['  volumes:\n   - ./database:/var/lib/mysql:Z\n   - ./_conf/mariadb.cnf:/etc/mysql/my.cnf:Z\n   - ./logs:/var/log/mysql:Z\n']
203,2045,1805,CC BY-SA 3.0,2017-09-17T08:49:37.970,"<p>It's a bit hacky, but you can always do something like:</p>

<pre><code>check_process:
  cmd.run:
    name: ps aux | grep '[f]oobar'
</code></pre>

<p>The exit code will be non-0 and the state will fail if <code>foobar</code> doesn't exist.</p>
",4369,2018-01-07T00:52:56.847,"[""check_process:\n  cmd.run:\n    name: ps aux | grep '[f]oobar'\n""]"
204,2052,2034,CC BY-SA 3.0,2017-09-18T05:00:36.677,"<p>You might use docker builder pattern. Briefly you need to create Dockerfile.build which adds <code>pom.xml</code> and run <code>mvn dependency:resolve</code>:</p>

<pre><code>FROM maven:latest
ADD ./pom.xml /src/pom.xml
WORKDIR /src
RUN mvn dependency:resolve
</code></pre>

<p>Rebuild that image every time prior build. Docker will use cached image if ./pom.xml has not changed. </p>

<p>Docker 17.05 introduced 'multi-stage builds' feature which implements this pattern. More information is available here: <a href=""https://docs.docker.com/engine/userguide/eng-image/multistage-build/"" rel=""nofollow noreferrer"">https://docs.docker.com/engine/userguide/eng-image/multistage-build/</a></p>
",4378,2017-09-18T05:00:36.677,['FROM maven:latest\nADD ./pom.xml /src/pom.xml\nWORKDIR /src\nRUN mvn dependency:resolve\n']
205,2060,2058,CC BY-SA 3.0,2017-09-18T11:51:59.530,"<p>You can have more than if statement per state. The issue is that your conditional doesn't seem actually be checking the hostname, it's just passing everything. Try this:</p>

<pre><code>{% if grains['host'] in ['dev-server2', 'test-server2'] %}
</code></pre>
",4369,2017-09-18T11:51:59.530,"[""{% if grains['host'] in ['dev-server2', 'test-server2'] %}\n""]"
206,2062,2061,CC BY-SA 3.0,2017-09-18T14:12:22.303,"<ul>
<li>k8s is a container orchestration tool</li>
<li>a dockerfile is used to build an image</li>
<li>k8s is able to run docker containers</li>
</ul>

<p>One could use yaml files to <a href=""https://kubernetes.io/docs/concepts/workloads/controllers/deployment/"" rel=""nofollow noreferrer"">deploy containers</a>:</p>

<blockquote>
<pre><code>apiVersion: apps/v1beta1 # for versions before 1.6.0 use extensions/v1beta1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
</code></pre>
</blockquote>
",210,2017-09-18T14:18:30.847,['apiVersion: apps/v1beta1 # for versions before 1.6.0 use extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n']
207,2074,2004,CC BY-SA 3.0,2017-09-18T21:31:44.167,"<p>The conflict is occurring between <code>ngc</code> and <code>webpack</code>.  When <code>rimraf aot &amp;&amp; ngc -p ./tsconfig-aot.json</code> is moved to its own script and executed prior to <code>test</code> and <code>build:prod:aot</code> then running <code>test</code> and <code>build:prod:aot</code> with <code>npm-run-all</code> will work as expected.  </p>

<p>Also, running with PowerShell is not necessarily a good idea since it interprets some of the output differently than the Windows shell.  For example, some packages will write out ""warnings"" to the error stream.</p>

<pre><code>""build:prod:aot"": ""rimraf aot &amp;&amp; ngc -p ./tsconfig-aot.json"",
""webpack:prod"": ""SET NODE_ENV=production&amp;&amp; webpack"",
""test"": ""SET NODE_ENV=test&amp;&amp; karma start karma.conf.js"",
""buildAndTest"": ""npm-run-all build:prod:aot --parallel test webpack:prod""
</code></pre>
",4322,2017-09-18T21:31:44.167,"['""build:prod:aot"": ""rimraf aot && ngc -p ./tsconfig-aot.json"",\n""webpack:prod"": ""SET NODE_ENV=production&& webpack"",\n""test"": ""SET NODE_ENV=test&& karma start karma.conf.js"",\n""buildAndTest"": ""npm-run-all build:prod:aot --parallel test webpack:prod""\n']"
208,2087,2086,CC BY-SA 3.0,2017-09-19T15:36:02.403,"<p><a href=""https://docs.gitlab.com/ee/ci/yaml/#stages"" rel=""nofollow noreferrer"">stages</a> are required</p>

<pre><code>stages:
  - stage1

stage1:
  stage: stage1
  script:
    - echo hello
</code></pre>

<p>Could you try the following:</p>

<pre><code>before_script:
  - pushd . &amp;&amp; uru 233 &amp;&amp; popd &amp;&amp; set HOME=c:\ &amp;&amp; ruby -v &amp;&amp; bundle install

stages:
  - rspec
  - rubocop
  - flay

rspec:
  stage: rspec
  script:
    - bundle exec rspec

rubocop:
  stage: rubocop
  script:
    - bundle exec rubocop

flay:
  stage: flay
  script:
    - bundle exec flay *
</code></pre>
",210,2017-09-19T16:05:57.323,"['stages:\n  - stage1\n\nstage1:\n  stage: stage1\n  script:\n    - echo hello\n', 'before_script:\n  - pushd . && uru 233 && popd && set HOME=c:\\ && ruby -v && bundle install\n\nstages:\n  - rspec\n  - rubocop\n  - flay\n\nrspec:\n  stage: rspec\n  script:\n    - bundle exec rspec\n\nrubocop:\n  stage: rubocop\n  script:\n    - bundle exec rubocop\n\nflay:\n  stage: flay\n  script:\n    - bundle exec flay *\n']"
209,2092,2019,CC BY-SA 3.0,2017-09-20T21:47:53.027,"<p>It seems you're trying to define the artifacts globally, that won't work with multiple paths since you're overwriting the definition of the key. Instead you should define the paths per job.</p>

<p>artifacts:
    expire_in: 1 week</p>

<pre><code>build:buildjob
    paths:
    - build/test1
    - build/test2
    - build/test3
    expire_in: 15 mins

test:testjob
      paths:
        - build/*.dmg
      artifacts:
        expire_in: 1 week
</code></pre>
",2313,2017-09-20T21:47:53.027,['build:buildjob\n    paths:\n    - build/test1\n    - build/test2\n    - build/test3\n    expire_in: 15 mins\n\ntest:testjob\n      paths:\n        - build/*.dmg\n      artifacts:\n        expire_in: 1 week\n']
210,2107,1725,CC BY-SA 3.0,2017-09-21T16:11:06.360,"<p>I'm thinking about different approach to your problem. Instead of adding maven repository into the image, I will mount a volume to $HOME/.m2/repository, and another volume to $PROJECT_DIR</p>

<pre><code>ENV PROJECT_DIR=/project
VOLUME /repository
VOLUME ${PROJECT_DIR}
RUN mkdir -p $HOME/.m2 /repository &amp;&amp; ln -s /repository $HOME/.m2/repository
</code></pre>

<p>After that, add a condition check in component.sh whether this is the first run and then build the required component.</p>

<pre><code>...
if [[ ! -e $PROJECT_DIR/app_is_ready ]]; then
  cd $PROJECT_DIR
  mvn clean install -P test
  touch $PROJECT_DIR/app_is_ready
fi
&lt;&lt;actual run commands&gt;&gt;
</code></pre>

<p>Please be note that the example code is not handling the race condition of two (or more) instances using the same volume for PROJECT_DIR started at the same time.</p>

<p>Hope this help!</p>
",4446,2017-09-21T16:11:06.360,"['ENV PROJECT_DIR=/project\nVOLUME /repository\nVOLUME ${PROJECT_DIR}\nRUN mkdir -p $HOME/.m2 /repository && ln -s /repository $HOME/.m2/repository\n', '...\nif [[ ! -e $PROJECT_DIR/app_is_ready ]]; then\n  cd $PROJECT_DIR\n  mvn clean install -P test\n  touch $PROJECT_DIR/app_is_ready\nfi\n<<actual run commands>>\n']"
211,2116,2115,CC BY-SA 3.0,2017-09-22T08:36:54.087,"<p>For an <code>auto-scaling-group</code> this is the most concise syntax available.</p>

<p>For most other resources you use the <code>tags</code> syntax which looks like:</p>

<pre><code>tags {
  Key1 = ""value1""
  Key2 = ""value2""
}
</code></pre>
",503,2017-09-22T08:36:54.087,"['tags {\n  Key1 = ""value1""\n  Key2 = ""value2""\n}\n']"
212,2130,2128,CC BY-SA 3.0,2017-09-24T14:37:30.173,"<p>First, try setting <a href=""https://docs.puppet.com/puppet/latest/configuration.html#dnsaltnames"" rel=""nofollow noreferrer"">dns_alt_names</a> in /etc/puppet/puppet.conf:</p>

<pre><code>[main]
    dns_alt_names = www.puppetmaster.com
[master]
    autosign = true
</code></pre>

<p>Then see if your puppet-agent -t run works properly. be sure that you have properly set your server on the puppet client in /etc/puppet/puppet.conf too:</p>

<pre><code>[agent]
    server = www.puppetmaster.com
</code></pre>
",2845,2017-09-24T14:37:30.173,"['[main]\n    dns_alt_names = www.puppetmaster.com\n[master]\n    autosign = true\n', '[agent]\n    server = www.puppetmaster.com\n']"
213,2131,2019,CC BY-SA 3.0,2017-09-24T21:26:05.840,"<p>This has been answered over on <a href=""https://stackoverflow.com/questions/46241987/multiple-paths-with-different-expiry-time-in-gitlab-ci-runners"">SO</a> using a work around seeing as it doesn't seem possible according to the documents.</p>

<p>Basically, this can be done in 3 stages.</p>

<p><strong>Stage 1:</strong> Build and store all artifacts.</p>

<pre><code>build_stage:
  script:
    - build
  artifacts:
    paths:
    - build/*.dmg
    - build/test1
    - build/test2
    - build/test3
    expire_in: 15 mins
</code></pre>

<p><strong>Stage 2.1:</strong> Do the next official stage of the job (ie run tests in my scenario) using the artifacts <code>build/test1, build/test2</code> and <code>build/test3</code>.</p>

<pre><code>test_stage:
  script:
    - test
  dependencies:
  - build
</code></pre>

<p><strong>Stage 2.2:</strong> Running concurrently with Stage 2.1 you can just have an empty job but sets a new artifact expiry date.</p>

<pre><code>overwrite_artifact_stage:
  script:
    - echo 'saving artifact'
  artifacts:
    paths:
    - build/*.dmg
    expire_in: 1 week
</code></pre>
",4289,2017-09-24T21:26:05.840,"['build_stage:\n  script:\n    - build\n  artifacts:\n    paths:\n    - build/*.dmg\n    - build/test1\n    - build/test2\n    - build/test3\n    expire_in: 15 mins\n', 'test_stage:\n  script:\n    - test\n  dependencies:\n  - build\n', ""overwrite_artifact_stage:\n  script:\n    - echo 'saving artifact'\n  artifacts:\n    paths:\n    - build/*.dmg\n    expire_in: 1 week\n""]"
214,2136,2119,CC BY-SA 3.0,2017-09-25T13:32:54.053,"<p>Weird Docker. I changed the <em>WORKDIR</em> in the <em>Dockerfile</em> and it worked:</p>

<pre><code>FROM postgres:9.6

WORKDIR /builds/user/
ADD repo/script.sql /docker-entrypoint-initdb.d/
</code></pre>

<p><strong>EDIT</strong>
The <code>/builds</code> folder does not exist on the host system. I thought that adding it to the runner's config would create a volume container that would be shared between containers. But no. So I removed it from the runner config, <em>/etc/gitlab-runner/config.toml</em>:</p>

<pre><code>[[runners]]
  name = ""My Docker Runner""
  url = ""http://host""
  token = ""xxxxxxxxxxxxxxxxxxxx""
  executor = ""docker""
  [runners.docker]
    tls_verify = false
    image = ""docker:latest""
    privileged = false
    disable_cache = false
    volumes = [""/var/run/docker.sock:/var/run/docker.sock"", ""/cache""]
  [runners.cache]
</code></pre>
",4465,2017-09-25T14:01:58.117,"['FROM postgres:9.6\n\nWORKDIR /builds/user/\nADD repo/script.sql /docker-entrypoint-initdb.d/\n', '[[runners]]\n  name = ""My Docker Runner""\n  url = ""http://host""\n  token = ""xxxxxxxxxxxxxxxxxxxx""\n  executor = ""docker""\n  [runners.docker]\n    tls_verify = false\n    image = ""docker:latest""\n    privileged = false\n    disable_cache = false\n    volumes = [""/var/run/docker.sock:/var/run/docker.sock"", ""/cache""]\n  [runners.cache]\n']"
215,2141,2127,CC BY-SA 3.0,2017-09-26T08:24:58.670,"<p>I'd go with <a href=""https://docs.chef.io/recipes.html#node-run-state"" rel=""nofollow noreferrer""><code>node.run_state</code></a> to store a transient variable in a run and define it in a <a href=""https://docs.chef.io/resource_ruby_block.html"" rel=""nofollow noreferrer""><code>ruby_block</code></a> so it happens at converge time, something like this:</p>

<pre><code>yum_package 'somepackage'

ruby_block 'set myvar' do
  block do
    node.run_state['my_var'] = Mixlib::ShellOut.new('/bin/somecommand').run_command.stdout.strip
  end
end
</code></pre>

<p>As far as I know requiring 'mixlib/shellout' is not necessary.</p>
",13,2017-09-26T08:24:58.670,"[""yum_package 'somepackage'\n\nruby_block 'set myvar' do\n  block do\n    node.run_state['my_var'] = Mixlib::ShellOut.new('/bin/somecommand').run_command.stdout.strip\n  end\nend\n""]"
216,2148,2146,CC BY-SA 3.0,2017-09-26T14:50:55.053,"<p>Here is some documentation on the Jenkins pipeline linter and its commands. Do you need to validate <strong>before</strong> a commit? If not, it would be really trivial to run the linting command prior to your pipeline running, and simply fail if it does not pass. </p>

<p>From <a href=""https://jenkins.io/doc/book/pipeline/development/#linter"" rel=""noreferrer"">Command-line Pipeline Linter</a>:</p>

<blockquote>
  <p>Jenkins can validate, or ""<a href=""https://en.wikipedia.org/wiki/Lint_(software)"" rel=""noreferrer"">lint</a>"", a Declarative Pipeline from the
  command line before actually running it. This can be done using a
  Jenkins CLI command or by making an HTTP POST request with appropriate
  parameters. We recommended using the <a href=""https://jenkins.io/doc/book/managing/cli/#ssh"" rel=""noreferrer"">SSH interface</a> to run the
  linter. See the <a href=""https://jenkins.io/doc/book/managing/cli/"" rel=""noreferrer"">Jenkins CLI documentation</a> for details on how to
  properly configure Jenkins for secure command-line access.</p>
  
  <p><em>Linting via the CLI with SSH</em></p>

<pre><code># ssh (Jenkins CLI)
# JENKINS_SSHD_PORT=[sshd port on master]
# JENKINS_HOSTNAME=[Jenkins master hostname]
ssh -p $JENKINS_SSHD_PORT $JENKINS_HOSTNAME declarative-linter &lt; Jenkinsfile
</code></pre>
  
  <p><em>Linting via HTTP POST using <code>curl</code></em></p>

<pre><code># curl (REST API)
# Assuming ""anonymous read access"" has been enabled on your Jenkins instance.
# JENKINS_URL=[root URL of Jenkins master]
# JENKINS_CRUMB is needed if your Jenkins master has CRSF protection enabled as it should
JENKINS_CRUMB=`curl ""$JENKINS_URL/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\"":\"",//crumb)""`
curl -X POST -H $JENKINS_CRUMB -F ""jenkinsfile=&lt;Jenkinsfile"" $JENKINS_URL/pipeline-model-converter/validate
</code></pre>
  
  <p><strong>Examples</strong></p>
  
  <p>Below are two examples of the Pipeline Linter in action. This first
  example shows the output of the linter when it is passed an invalid
  <code>Jenkinsfile</code>, one that is missing part of the <code>agent</code> declaration.</p>
  
  <p><em>Jenkinsfile</em></p>

<pre><code>pipeline {
  agent
  stages {
    stage ('Initialize') {
      steps {
        echo 'Placeholder.'
      }
    }
  }
}
</code></pre>
  
  <p><em>Linter output for invalid Jenkinsfile</em></p>

<pre><code># pass a Jenkinsfile that does not contain an ""agent"" section
ssh -p 8675 localhost declarative-linter &lt; ./Jenkinsfile
Errors encountered validating Jenkinsfile:
WorkflowScript: 2: Not a valid section definition: ""agent"". Some extra configuration is required. @ line 2, column 3.
     agent
     ^

WorkflowScript: 1: Missing required section ""agent"" @ line 1, column 1.
   pipeline &amp;#125;
   ^
</code></pre>
  
  <p>In this second example, the <code>Jenkinsfile</code> has been updated to include
  the missing <code>any</code> on <code>agent</code>. The linter now reports that the Pipeline
  is valid.</p>
  
  <p><em>Jenkinsfile</em></p>

<pre><code>pipeline {
  agent any
  stages {
    stage ('Initialize') {
      steps {
        echo 'Placeholder.'
      }
    }
  }
}
</code></pre>
  
  <p><em>Linter output for valid Jenkinsfile</em></p>

<pre><code>ssh -p 8675 localhost declarative-linter &lt; ./Jenkinsfile
Jenkinsfile successfully validated.
</code></pre>
</blockquote>
",4328,2017-10-05T21:04:44.417,"['# ssh (Jenkins CLI)\n# JENKINS_SSHD_PORT=[sshd port on master]\n# JENKINS_HOSTNAME=[Jenkins master hostname]\nssh -p $JENKINS_SSHD_PORT $JENKINS_HOSTNAME declarative-linter < Jenkinsfile\n', '# curl (REST API)\n# Assuming ""anonymous read access"" has been enabled on your Jenkins instance.\n# JENKINS_URL=[root URL of Jenkins master]\n# JENKINS_CRUMB is needed if your Jenkins master has CRSF protection enabled as it should\nJENKINS_CRUMB=`curl ""$JENKINS_URL/crumbIssuer/api/xml?xpath=concat(//crumbRequestField,\\"":\\"",//crumb)""`\ncurl -X POST -H $JENKINS_CRUMB -F ""jenkinsfile=<Jenkinsfile"" $JENKINS_URL/pipeline-model-converter/validate\n', ""pipeline {\n  agent\n  stages {\n    stage ('Initialize') {\n      steps {\n        echo 'Placeholder.'\n      }\n    }\n  }\n}\n"", '# pass a Jenkinsfile that does not contain an ""agent"" section\nssh -p 8675 localhost declarative-linter < ./Jenkinsfile\nErrors encountered validating Jenkinsfile:\nWorkflowScript: 2: Not a valid section definition: ""agent"". Some extra configuration is required. @ line 2, column 3.\n     agent\n     ^\n\nWorkflowScript: 1: Missing required section ""agent"" @ line 1, column 1.\n   pipeline &#125;\n   ^\n', ""pipeline {\n  agent any\n  stages {\n    stage ('Initialize') {\n      steps {\n        echo 'Placeholder.'\n      }\n    }\n  }\n}\n"", 'ssh -p 8675 localhost declarative-linter < ./Jenkinsfile\nJenkinsfile successfully validated.\n']"
217,2186,2185,CC BY-SA 3.0,2017-09-28T10:56:06.090,"<p>If it doesn't outright fail you can expect to see a cycle warning where you've created a loop in Terraform and it's trying to fulfil your request for <code>asg-name</code> before the asg has been created.</p>

<p>To get what you need you'll need to have something like the following:</p>

<h1><strong>module_apps/module_apps.tf</strong></h1>

<pre><code>resource ""aws_autoscaling_group"" ""example"" {
  name = ""${var.asg_name}""
}
</code></pre>

<h1><strong>module_init.tf</strong></h1>

<pre><code>variable ""asg_name"" { default = ""asg-ad"" }

module ""module_init"" {
  source = ""../module_apps""

  asg_name = ""${var.asg_name}""
}

output ""asg_name"" {
  value = ""${var.asg_name}""
}
</code></pre>

<p>This way, if you call <code>module_init</code> somewhere else you'll have <code>asg_name</code> available to you. Always be careful of trying to use an output of a module to create the module, Terraform doesn't handle loops like that well and the errors can be confusing to diagnose.</p>
",503,2017-09-28T11:40:30.563,"['resource ""aws_autoscaling_group"" ""example"" {\n  name = ""${var.asg_name}""\n}\n', 'variable ""asg_name"" { default = ""asg-ad"" }\n\nmodule ""module_init"" {\n  source = ""../module_apps""\n\n  asg_name = ""${var.asg_name}""\n}\n\noutput ""asg_name"" {\n  value = ""${var.asg_name}""\n}\n']"
218,2189,2143,CC BY-SA 3.0,2017-09-28T12:45:17.113,"<p>You can try to use scripting syntax into the declarative pipeline. For some step there is no declarative syntax yet. I had the same problem trying to use the <code>docker</code> global variable as a step.</p>

<pre><code>stage ('Docker Build') {
  steps {
    // prepare docker build context
    sh ""cp target/project.war ./tmp-docker-build-context""

    // Build and push image with Jenkins' docker-plugin
    script {
      withDockerServer([uri: ""tcp://&lt;my-docker-socket&gt;""]) {
        withDockerRegistry([credentialsId: 'docker-registry-credentials', url: ""https://&lt;my-docker-registry&gt;/""]) {
            // we give the image the same version as the .war package
            def image = docker.build(""&lt;myDockerRegistry&gt;/&lt;myDockerProjectRepo&gt;:${branchVersion}"", ""--build-arg PACKAGE_VERSION=${branchVersion} ./tmp-docker-build-context"")
            image.push()
        }
      }
    }
  }
}
</code></pre>
",4544,2017-09-28T12:45:17.113,"['stage (\'Docker Build\') {\n  steps {\n    // prepare docker build context\n    sh ""cp target/project.war ./tmp-docker-build-context""\n\n    // Build and push image with Jenkins\' docker-plugin\n    script {\n      withDockerServer([uri: ""tcp://<my-docker-socket>""]) {\n        withDockerRegistry([credentialsId: \'docker-registry-credentials\', url: ""https://<my-docker-registry>/""]) {\n            // we give the image the same version as the .war package\n            def image = docker.build(""<myDockerRegistry>/<myDockerProjectRepo>:${branchVersion}"", ""--build-arg PACKAGE_VERSION=${branchVersion} ./tmp-docker-build-context"")\n            image.push()\n        }\n      }\n    }\n  }\n}\n']"
219,2192,2191,CC BY-SA 3.0,2017-09-28T16:42:49.333,"<p>Luckily there is a <code>hudson.util.Secret.decrypt()</code> function which can be used for this, so:</p>

<ol>
<li>In Jenkins, go to: <code>/script</code> page.</li>
<li><p>Run the following command:</p>

<pre><code>println(hudson.util.Secret.decrypt(""{XXX=}""))
</code></pre>

<p>or:</p>

<pre><code>println(hudson.util.Secret.fromString(""{XXX=}"").getPlainText())
</code></pre>

<p>where <code>{XXX=}</code> is your encrypted password. This will print the plain password.</p>

<p>To do opposite, run:</p>

<pre><code>println(hudson.util.Secret.fromString(""some_text"").getEncryptedValue())
</code></pre></li>
</ol>

<p><sup>Source: <a href=""https://gist.github.com/tuxfight3r/eca9442ff76649b057ab"" rel=""noreferrer"">gist at <code>tuxfight3r/jenkins-decrypt.groovy</code></a>.</sup></p>

<hr>

<p>Alternatively check the following scripts: <a href=""https://github.com/tweksteen/jenkins-decrypt"" rel=""noreferrer""><code>tweksteen/jenkins-decrypt</code></a>,
 <a href=""https://gist.github.com/menski/8f9980999ed43246b9b2"" rel=""noreferrer""><code>menski/jenkins-decrypt.py</code></a>.</p>

<hr>

<p>For more details, check: <a href=""http://xn--thibaud-dya.fr/jenkins_credentials.html"" rel=""noreferrer"">Credentials storage in Jenkins</a>.</p>
",3,2017-09-28T22:15:34.657,"['println(hudson.util.Secret.decrypt(""{XXX=}""))\n', 'println(hudson.util.Secret.fromString(""{XXX=}"").getPlainText())\n', 'println(hudson.util.Secret.fromString(""some_text"").getEncryptedValue())\n']"
220,2203,1933,CC BY-SA 3.0,2017-09-29T23:23:03.240,"<p>My suggestion is to set job parameterized with two options, and just set up variables in the Shell Build step, like this:</p>

<pre><code>if [ ""$VAR"" == ""1"" ]; then
    value1=""1.0.0""
    value2=""myname""
    value3=""build/libs""
elif [ ""$VAR"" == ""2"" ]; then
    value1=""2.0.0""
    value2=""myname2""
    value3=""var/lib""
fi

echo ${var.value1}
echo ${var.value2}
echo ${var.value3}
</code></pre>
",4561,2017-09-29T23:23:03.240,"['if [ ""$VAR"" == ""1"" ]; then\n    value1=""1.0.0""\n    value2=""myname""\n    value3=""build/libs""\nelif [ ""$VAR"" == ""2"" ]; then\n    value1=""2.0.0""\n    value2=""myname2""\n    value3=""var/lib""\nfi\n\necho ${var.value1}\necho ${var.value2}\necho ${var.value3}\n']"
221,2213,2209,CC BY-SA 3.0,2017-10-02T11:38:23.547,"<p>There would be many reason for it. If you are writing/updating <code>JENKINS_HOME/config.xml</code>, then the possibility of a syntax error may be in <code>config.xml</code>. So you can recover it with the following steps:</p>

<p>Step 1: Stop jenkins service</p>

<pre><code>cmd&gt; service jenkins stop
</code></pre>

<p>step 2: <code>mv JENKINS_HOME/config.xml</code>  to another file for backup </p>

<pre><code>cmd&gt; mv JENKINS_HOME/config.xml JENKINS_HOME/config.xml_bak
</code></pre>

<p>step 3: Start jenkins service </p>

<pre><code>cmd&gt; service jenkins start
</code></pre>
",4573,2017-10-02T13:51:39.953,"['cmd> service jenkins stop\n', 'cmd> mv JENKINS_HOME/config.xml JENKINS_HOME/config.xml_bak\n', 'cmd> service jenkins start\n']"
222,2223,1588,CC BY-SA 3.0,2017-10-03T10:35:54.627,"<p><a href=""https://github.com/elastic/stack-docker/blob/master/docker-compose.yml"" rel=""nofollow noreferrer"">https://github.com/elastic/stack-docker/blob/master/docker-compose.yml</a></p>

<p>This is an official docker-compose for running Elasticsearch, and will make a good starting point for whatever you're trying to achieve. This would be the key part:</p>

<pre><code>  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:${TAG}
    environment: ['http.host=0.0.0.0', 'transport.host=127.0.0.1', 'ELASTIC_PASSWORD=${ELASTIC_PASSWORD}']
    ports: ['127.0.0.1:9200:9200']
    networks: ['stack']
</code></pre>

<p>But I'd recommend cloning the entire repository locally and running <code>docker-compose up</code> to experiment.</p>
",4369,2017-10-03T10:35:54.627,"[""  elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:${TAG}\n    environment: ['http.host=0.0.0.0', 'transport.host=127.0.0.1', 'ELASTIC_PASSWORD=${ELASTIC_PASSWORD}']\n    ports: ['127.0.0.1:9200:9200']\n    networks: ['stack']\n""]"
223,2224,2027,CC BY-SA 3.0,2017-10-03T10:41:47.317,"<p>One option is to use the <code>host</code> network driver. If you run the container with the host network driver, <code>localhost</code> will resolve and route to your local machine where etcd is running.</p>

<pre><code>docker run --network=host --userns=host -p 8084:8084 my_python_image
</code></pre>

<p>When using the host network driver, the IP of the container will be the same as your local machine's IP address, giving it access to all of the services that are listening on it.</p>

<p>The <code>--userns</code> flag is required for kernels that have namespacing enabled and provides additional permissions to the container in order for it to use host networking.</p>
",4369,2017-10-03T10:48:46.743,['docker run --network=host --userns=host -p 8084:8084 my_python_image\n']
224,2226,2190,CC BY-SA 3.0,2017-10-03T11:26:54.033,"<p>There is currently an issue open to share Gradle cache between containers:</p>

<p><a href=""https://github.com/gradle/gradle/issues/851"" rel=""nofollow noreferrer"">https://github.com/gradle/gradle/issues/851</a></p>

<p>I think the best solution at the moment is to bake as many dependencies in to the Docker image as possible, and then use a volume to share between sequential builds, limiting it to one concurrent build per host. You can mount the cache on to the host with a docker-compose.yml like so:</p>

<pre><code>version: '3'
services:
  gradle:
    image: gradle:4.0.1-jdk8-alpine  # I'd suggest using this as a base to build your own Gradle image with dependencies baked in
    working_dir: /usr/src/app
    volumes:
      - ./:/usr/src/app:Z
      - ./.gradle:/home/gradle/.gradle:Z
</code></pre>

<p>Alternatively, another solution would be to look at network-level caching e.g. Squid.</p>
",4369,2017-10-03T11:26:54.033,"[""version: '3'\nservices:\n  gradle:\n    image: gradle:4.0.1-jdk8-alpine  # I'd suggest using this as a base to build your own Gradle image with dependencies baked in\n    working_dir: /usr/src/app\n    volumes:\n      - ./:/usr/src/app:Z\n      - ./.gradle:/home/gradle/.gradle:Z\n""]"
225,2228,1626,CC BY-SA 3.0,2017-10-03T11:43:32.087,"<p>To provide access for specific bucket, you can define the following policy for that user or group:</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""s3:ListBucket"",
                ""s3:GetBucketLocation"",
                ""s3:ListBucketMultipartUploads""
            ],
            ""Resource"": [
                ""arn:aws:s3:::my-bucket""
            ]
        },
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""s3:AbortMultipartUpload"",
                ""s3:DeleteObject"",
                ""s3:DeleteObjectVersion"",
                ""s3:GetObject"",
                ""s3:GetObjectAcl"",
                ""s3:GetObjectVersion"",
                ""s3:GetObjectVersionAcl"",
                ""s3:PutObject"",
                ""s3:PutObjectAcl"",
                ""s3:PutObjectVersionAcl""
            ],
            ""Resource"": [
                ""arn:aws:s3:::my-bucket/*""
            ]
        },
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""s3:ListAllMyBuckets""
            ],
            ""Resource"": ""arn:aws:s3:::*""
        }
    ]
}
</code></pre>

<p><sup>Where <code>my-bucket</code> is your name of your bucket.</sup></p>

<p>Then send them the Console URL for that bucket, e.g.</p>

<ul>
<li><code>https://s3.console.aws.amazon.com/s3/buckets/BUCKET_NAME/</code></li>
</ul>

<p>Related:</p>

<ul>
<li><a href=""https://stackoverflow.com/q/6615168/55075"">Is there an S3 policy for limiting access to only see/access one bucket?</a></li>
</ul>
",3,2017-10-03T11:43:32.087,"['{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""s3:ListBucket"",\n                ""s3:GetBucketLocation"",\n                ""s3:ListBucketMultipartUploads""\n            ],\n            ""Resource"": [\n                ""arn:aws:s3:::my-bucket""\n            ]\n        },\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""s3:AbortMultipartUpload"",\n                ""s3:DeleteObject"",\n                ""s3:DeleteObjectVersion"",\n                ""s3:GetObject"",\n                ""s3:GetObjectAcl"",\n                ""s3:GetObjectVersion"",\n                ""s3:GetObjectVersionAcl"",\n                ""s3:PutObject"",\n                ""s3:PutObjectAcl"",\n                ""s3:PutObjectVersionAcl""\n            ],\n            ""Resource"": [\n                ""arn:aws:s3:::my-bucket/*""\n            ]\n        },\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""s3:ListAllMyBuckets""\n            ],\n            ""Resource"": ""arn:aws:s3:::*""\n        }\n    ]\n}\n']"
226,2229,1534,CC BY-SA 3.0,2017-10-03T12:06:21.317,"<p>Most of the persisted data is written to:
<code>C:\ProgramData\docker</code></p>

<p>you should have directories here such as:</p>

<pre><code>.\windowsfilter 
.\volumes 
.\config 
.\image 
</code></pre>

<p>etc</p>

<p>The layer and image data is stored under these.</p>
",4587,2017-10-03T13:39:39.047,['.\\windowsfilter \n.\\volumes \n.\\config \n.\\image \n']
227,2231,1017,CC BY-SA 3.0,2017-10-03T15:44:30.207,"<p>According <a href=""https://www.vagrantup.com/docs/cli/ssh.html"" rel=""nofollow noreferrer"">to the docs</a> one should use:</p>

<pre><code>vagrant ssh [name|id]
</code></pre>

<p>If there is a single node then use <code>vagrant ssh</code> and in case of multi-node define the name or id of the VM, e.g. <code>vagrant ssh box1</code></p>

<p>If one would like to ssh between boxes then one could create an ssh key and provision the private key to each box and add the public key to authorized_keys file.</p>

<p><a href=""https://www.vagrantup.com/docs/provisioning/file.html"" rel=""nofollow noreferrer"">https://www.vagrantup.com/docs/provisioning/file.html</a></p>

<blockquote>
<pre><code>Vagrant.configure(""2"") do |config|
  # ... other configuration

  config.vm.provision ""file"", source: ""~/.gitconfig"", destination: "".gitconfig""
end
</code></pre>
</blockquote>
",210,2017-10-03T16:20:11.203,"['vagrant ssh [name|id]\n', 'Vagrant.configure(""2"") do |config|\n  # ... other configuration\n\n  config.vm.provision ""file"", source: ""~/.gitconfig"", destination: "".gitconfig""\nend\n']"
228,2236,2217,CC BY-SA 3.0,2017-10-03T18:34:18.850,"<p>You can try this, it works for me:</p>

<ol>
<li><p>Create a user named ""git""</p>

<pre><code>$ sudo adduser git
$ su git
$ cd ~
$ mkdir .ssh &amp;&amp; chmod 700 .ssh
$ touch .ssh/authorized_keys &amp;&amp; chmod 600 .ssh/authorized_keys
</code></pre></li>
<li><p>If you don't have ssh keys for ""nou"" user then, from ""nou"" user run</p>

<pre><code>$ ssh-keygen
</code></pre>

<p>and accept all defaults.</p></li>
<li><p>Add ""nou"" user's ssh public key to git user ~/.ssh/authorized_keys</p>

<pre><code>$ sudo cat nou_user_home/.ssh/id_rsa.pub &gt;&gt; git_user_home/.ssh/authorized_keys
</code></pre></li>
</ol>

<p>After this try below command from ""nou"" user:</p>

<pre><code>docker build git@localhost:/home/nou/code/lib.git
</code></pre>

<p>If <code>Dockerfile</code> is not at the root of cloned repository then:</p>

<pre><code>docker build -f folder_containing_dockerfile/Dockerfile 
git@localhost:/home/nou/code/lib.git
</code></pre>

<p>If this all works fine then you can try with your <code>docker-compose</code> file.</p>
",4593,2017-10-14T06:41:26.560,"['$ sudo adduser git\n$ su git\n$ cd ~\n$ mkdir .ssh && chmod 700 .ssh\n$ touch .ssh/authorized_keys && chmod 600 .ssh/authorized_keys\n', '$ ssh-keygen\n', '$ sudo cat nou_user_home/.ssh/id_rsa.pub >> git_user_home/.ssh/authorized_keys\n', 'docker build git@localhost:/home/nou/code/lib.git\n', 'docker build -f folder_containing_dockerfile/Dockerfile \ngit@localhost:/home/nou/code/lib.git\n']"
229,2240,2081,CC BY-SA 3.0,2017-10-04T06:58:11.917,"<p><a href=""https://github.com/arminc/clair-scanner"" rel=""nofollow noreferrer"">Clair-scanner</a> is able to scan the images locally.</p>

<p><a href=""https://github.com/arminc/clair-scanner/issues/13"" rel=""nofollow noreferrer"">https://github.com/arminc/clair-scanner/issues/13</a></p>

<blockquote>
<pre><code>docker run --net=host -d --name db arminc/clair-db:2017-09-18
docker run --net=host --add-host postgres:127.0.0.1 -d --name clair --net=host arminc/clair-local-scan:v2.0.1
./clair-scanner nginx:1.11.6-alpine example-nginx.yaml http://127.0.0.1:6060 127.0.0.1
</code></pre>
</blockquote>
",210,2017-10-04T06:58:11.917,['docker run --net=host -d --name db arminc/clair-db:2017-09-18\ndocker run --net=host --add-host postgres:127.0.0.1 -d --name clair --net=host arminc/clair-local-scan:v2.0.1\n./clair-scanner nginx:1.11.6-alpine example-nginx.yaml http://127.0.0.1:6060 127.0.0.1\n']
230,2243,2207,CC BY-SA 3.0,2017-10-04T12:41:44.493,"<p>One could use <a href=""http://serverspec.org/"" rel=""nofollow noreferrer"">serverspec</a> to test whether a service like nginx is exposing ports, .e.g:</p>

<pre><code>require 'spec_helper'

describe port(80) do
  it { should be_listening }
end

describe port(443) do
  it { should be_listening }
end
</code></pre>

<p>Once the serverspec code has been written one could create a script that starts the nginx, subsequently runs the serverspec and finally destroys the nginx.</p>
",210,2017-10-04T12:41:44.493,"[""require 'spec_helper'\n\ndescribe port(80) do\n  it { should be_listening }\nend\n\ndescribe port(443) do\n  it { should be_listening }\nend\n""]"
231,2244,2241,CC BY-SA 3.0,2017-10-04T14:00:50.990,"<p>You will need to write a script that parses and queries this data because as far as I'm aware, there is not a tool or cli function that performs this. Luckily, you can gather all of this information with the CLI. </p>

<ol>
<li><p><a href=""http://docs.aws.amazon.com/cli/latest/reference/organizations/list-accounts.html"" rel=""nofollow noreferrer"">List</a> and parse all of the accounts in your org. </p>

<pre><code>aws organizations list-accounts
</code></pre></li>
<li><p>For each account, <a href=""http://docs.aws.amazon.com/cli/latest/reference/s3api/list-buckets.html"" rel=""nofollow noreferrer"">list</a> and parse all of the buckets. </p>

<pre><code>aws s3api list-buckets --query ""Buckets[].Name""
</code></pre></li>
<li><p>Finally, get the size of each bucket within each account. You can use the same cli command you were before, but be warned that you are going to be listing the individual size of each item within the bucket. You can also use this cli command to get bucket size.</p>

<pre><code>aws s3api list-objects --bucket BUCKETNAME --output json --query ""
[sum(Contents[].Size), length(Contents[])]""
</code></pre></li>
</ol>
",4328,2017-10-04T14:00:50.990,"['aws organizations list-accounts\n', 'aws s3api list-buckets --query ""Buckets[].Name""\n', 'aws s3api list-objects --bucket BUCKETNAME --output json --query ""\n[sum(Contents[].Size), length(Contents[])]""\n']"
232,2245,2241,CC BY-SA 3.0,2017-10-04T14:41:30.177,"<p><strong>Resolution 1</strong></p>

<p>So I solved this with the following script. I originally posted the question just in case there was an easier way that I was not aware of.</p>

<pre><code>#!/bin/bash
aws_profile=('profile1' 'profile2' 'profile3');

#loop AWS profiles
for i in ""${aws_profile[@]}""; do
  echo ""${i}""
  buckets=($(aws --profile ""${i}"" --region your_region s3 ls s3:// --recursive | awk '{print $3}'))

  #loop S3 buckets
  for j in ""${buckets[@]}""; do
  echo ""${j}""
  aws --profile ""${i}"" --region your_region s3 ls s3://""${j}"" --recursive --human-readable --summarize | awk END'{print}'
  done

done
</code></pre>

<p><strong>Resolution 2</strong></p>

<p>Using <strong>Dashboards</strong> in <strong>CloudWatch</strong> in the AWS console.</p>

<p>You can then simply specify all S3 buckets and add the numbers stats to show the storage size metrics.</p>

<p>This won't cost you plenty of API calls and can be significantly faster depending on the size of the s3 buckets(takes quite awhile to get the size on very large buckets). </p>

<p><strong>Verdict</strong></p>

<p>Creating the Dashboard (<strong>Resolution 2</strong>) on each AWS account was the most efficient option <strong>for me</strong> cause it is way quicker for me to log in and grab the metrics manually from each AWS account than to wait for the scripts API calls to finish. :( </p>
",887,2017-12-16T09:11:57.543,"['#!/bin/bash\naws_profile=(\'profile1\' \'profile2\' \'profile3\');\n\n#loop AWS profiles\nfor i in ""${aws_profile[@]}""; do\n  echo ""${i}""\n  buckets=($(aws --profile ""${i}"" --region your_region s3 ls s3:// --recursive | awk \'{print $3}\'))\n\n  #loop S3 buckets\n  for j in ""${buckets[@]}""; do\n  echo ""${j}""\n  aws --profile ""${i}"" --region your_region s3 ls s3://""${j}"" --recursive --human-readable --summarize | awk END\'{print}\'\n  done\n\ndone\n']"
233,2249,1525,CC BY-SA 3.0,2017-10-05T16:30:44.673,"<p>In groovy script, you need to reference environment variables in a different way than in bash.</p>

<p>So probably this line is causing trouble: </p>

<pre><code>branch: ('origin/pr/${pullRequestId}/from')
</code></pre>

<p>Try using:</p>

<pre><code>branch: ('origin/pr/' + env.pullRequestId + '/from')
</code></pre>
",4618,2017-10-05T18:24:35.110,"[""branch: ('origin/pr/${pullRequestId}/from')\n"", ""branch: ('origin/pr/' + env.pullRequestId + '/from')\n""]"
234,2253,650,CC BY-SA 3.0,2017-10-06T09:37:29.337,"<p>In case you're not using the Declarative Pipeline, you can avoid checking out from SCM by:</p>

<pre><code>node {
        skipDefaultCheckout()
        //...
}
</code></pre>
",4626,2017-10-06T09:37:29.337,['node {\n        skipDefaultCheckout()\n        //...\n}\n']
235,2254,2250,CC BY-SA 3.0,2017-10-06T10:26:04.907,"<p>One could use <a href=""https://docs.docker.com/engine/admin/volumes/volumes/#use-a-read-only-volume"" rel=""nofollow noreferrer"">read-only volumes</a>. </p>

<blockquote>
<pre><code>docker run -d \
  -it \
  --name=nginxtest \
  -v nginx-vol:/usr/share/nginx/html:ro \
  nginx:latest
</code></pre>
</blockquote>

<p>If one would like to use the same volume in multiple containers then one could specify the following when running each container:</p>

<pre><code>-v vol:/usr/share/nginx/html:ro
</code></pre>

<p>Note: one could use <code>ro</code> to ensure that the volume is read-only to prevent that multiple containers will write at the same time to the same volume and prevent issues.</p>
",210,2017-10-06T10:28:27.333,"['docker run -d \\\n  -it \\\n  --name=nginxtest \\\n  -v nginx-vol:/usr/share/nginx/html:ro \\\n  nginx:latest\n', '-v vol:/usr/share/nginx/html:ro\n']"
236,2277,2262,CC BY-SA 3.0,2017-10-09T08:32:47.660,"<p>To take your points one by one:</p>

<blockquote>
  <p>but in the interests of good system hygiene I would like to avoid as much as possible duplication</p>
</blockquote>

<p>Can you ensure your system ruby will evolve at the same pace as the Chef's ruby ? Main point of chef coming as a bundle with its own ruby comes back from Chef 10 which was installed via a simple gem command and was usually a problem switching between ruby needed for applications and ruby needed by chef, the same goes for gem dependencies. I would advise against mixing system and chef ruby.</p>

<blockquote>
  <p>the Gems I have in the system Ruby come from the known-good local Yum repo and are installed via RPM over the LAN whereas chef_gem goes off to the public Internet</p>
</blockquote>

<p>While I understand and agree with the worrying about recent pipy events, there's two things here:</p>

<ul>
<li>Your system ruby install gems from yum repository because your system ruby's <code>gem</code> command has been tweaked for that, that's specific to your distribution. -</li>
<li>Chef's ruby use usual ruby method going to rubygems.org, as any ruby installed by rbenv or any other way than yum install would do.</li>
</ul>

<p>If you really want to use a local repo you'll have to <a href=""http://guides.rubygems.org/run-your-own-gem-server/"" rel=""nofollow noreferrer"">set up a gem server</a> (alternatively, some artifact repositories can handle that also) and set-up the sources for gem using chef's <a href=""http://guides.rubygems.org/command-reference/#gem-sources"" rel=""nofollow noreferrer""><code>gem sources</code></a> in <code>/opt/chef/embedded/bin</code>.</p>

<p>If you're using a chef client above 13.0 your can use the <code>rubygems_url</code> in client.rb to tweak that:</p>

<blockquote>
<pre><code>rubygems_url
</code></pre>
  
  <p>The location to source rubygems. It can be set to a string or array of
  strings for URIs to set as rubygems sources. This allows individuals
  to setup an internal mirror of rubygems for “airgapped” environments.
  Default value: <a href=""https://www.rubygems.org"" rel=""nofollow noreferrer"">https://www.rubygems.org</a>.<br>
  Changed in Chef Client 13.0.</p>
</blockquote>

<p>And finally:</p>

<blockquote>
  <p>I have tried setting ENV['GEM_PATH'] in my recipe both before and
  inside a ruby_block but this appears to have no effect, I get a
  failure on require</p>
</blockquote>

<p>Chef omnibus package hardcode some values specially to avoid interfering with the system ruby, I think the GEM_PATH environment variable is ignored when searching for gem you <code>require</code> within the recipe code. I don't think there's a workaround for this, and again you're heading to a compatibility problem on mid term as you'll have a drift between chef's ruby and system ruby.</p>
",13,2017-10-09T08:32:47.660,['rubygems_url\n']
237,2278,1937,CC BY-SA 3.0,2017-10-10T02:17:12.273,"<p>I had the same issue with node. The thing is files in the container are owned by ""root:root"". Try adding docker args <code>-u root:root</code>:</p>

<pre><code>docker { 
    image 'node:8'
    args '-u root:root'
}
</code></pre>
",4674,2017-10-10T02:17:12.273,"[""docker { \n    image 'node:8'\n    args '-u root:root'\n}\n""]"
238,2300,2297,CC BY-SA 3.0,2017-10-12T12:40:08.020,"<p>To give visability to the error messages mount a volume to your container so after it crashes the logs are available ... problem otherwise is once crashed the logs go away ... for example this docker-compose.yaml excerpt is how to mount a volume</p>

<pre><code>  nodejs-enduser:
    image: your-image-name
    restart: always
    volumes:
      - /pathA:/pathB  
</code></pre>

<p>pathA is full path to some logging dir on host where container is launched from</p>

<p>pathB is path processes write to from inside container</p>

<p>If you wrap your docker launch using something like supervisord then its config defines where standard out / stderr are written to ... that is  /pathB  ... then the app inside the container just writes to stdout / stderr </p>

<p>Alternative approach is to spin up an empty container then once running you log into it using <code>docker exec -ti container-id bash</code>  Once inside you then manually issue your Dockerfile commands to install and execute the app ( nodejs ) where you can then see the errors as they happen ... here is the Dockerfile for this do nothing container</p>

<pre><code>FROM ubuntu:16.04

ENV TERM linux
ENV DEBIAN_FRONTEND noninteractive

RUN apt-get update
RUN apt-get install -y wget  curl   net-tools

# COPY .bashrc /root/
#  list your normal Dockerfile code COPY steps here 

CMD [""/bin/bash""]
</code></pre>

<p>now build above Dockerfile</p>

<pre><code>docker build --tag stens_ubuntu .
</code></pre>

<p>and run</p>

<pre><code>docker run -d  stens_ubuntu  sleep infinity
</code></pre>

<p>now log into it</p>

<pre><code>docker exec -it $( docker ps | grep stens_ubuntu | cut -d' ' -f1 )  bash
</code></pre>

<p>here you are at the command prompt inside the running container where you now issue whichever commands you need to run your normal app as listed in your original Dockerfile   ... beauty is now you are interactively seeing the error happen ... until it crashes however the messages will be shown</p>
",192,2017-10-12T13:02:44.267,"['  nodejs-enduser:\n    image: your-image-name\n    restart: always\n    volumes:\n      - /pathA:/pathB  \n', 'FROM ubuntu:16.04\n\nENV TERM linux\nENV DEBIAN_FRONTEND noninteractive\n\nRUN apt-get update\nRUN apt-get install -y wget  curl   net-tools\n\n# COPY .bashrc /root/\n#  list your normal Dockerfile code COPY steps here \n\nCMD [""/bin/bash""]\n', 'docker build --tag stens_ubuntu .\n', 'docker run -d  stens_ubuntu  sleep infinity\n', ""docker exec -it $( docker ps | grep stens_ubuntu | cut -d' ' -f1 )  bash\n""]"
239,2319,2310,CC BY-SA 3.0,2017-10-13T21:48:17.670,"<p>You may try something like this: </p>

<pre><code>node('my_kubernetes_pod') {
    passedBuilds = []

    lastSuccessfulBuild(passedBuilds, currentBuild);

    def changeLog = getChangeLog(passedBuilds)
    echo ""changeLog ${changeLog}""
}

def lastSuccessfulBuild(passedBuilds, build) {
    if ((build != null) &amp;&amp; (build.result != 'SUCCESS')) {
        passedBuilds.add(build)
        lastSuccessfulBuild(passedBuilds, build.getPreviousBuild())
    }
}

@NonCPS
def getChangeLog(passedBuilds) {
    def log = """"
    for (int x = 0; x &lt; passedBuilds.size(); x++) {
        def currentBuild = passedBuilds[x];
        def changeLogSets = currentBuild.rawBuild.changeSets
        for (int i = 0; i &lt; changeLogSets.size(); i++) {
            def entries = changeLogSets[i].items
            for (int j = 0; j &lt; entries.length; j++) {
                def entry = entries[j]
                log += ""* ${entry.msg} by ${entry.author} \n""
            }
        }
    }
    return log;
}
</code></pre>

<p>Additionally, you may try out ""Changes Since Last Success Plugin"":
<a href=""https://wiki.jenkins.io/display/JENKINS/Changes+Since+Last+Success+Plugin"" rel=""noreferrer"">https://wiki.jenkins.io/display/JENKINS/Changes+Since+Last+Success+Plugin</a></p>

<p>But it will not work together with pipeline, this is a separate approach.</p>
",3899,2017-10-13T21:48:17.670,"['node(\'my_kubernetes_pod\') {\n    passedBuilds = []\n\n    lastSuccessfulBuild(passedBuilds, currentBuild);\n\n    def changeLog = getChangeLog(passedBuilds)\n    echo ""changeLog ${changeLog}""\n}\n\ndef lastSuccessfulBuild(passedBuilds, build) {\n    if ((build != null) && (build.result != \'SUCCESS\')) {\n        passedBuilds.add(build)\n        lastSuccessfulBuild(passedBuilds, build.getPreviousBuild())\n    }\n}\n\n@NonCPS\ndef getChangeLog(passedBuilds) {\n    def log = """"\n    for (int x = 0; x < passedBuilds.size(); x++) {\n        def currentBuild = passedBuilds[x];\n        def changeLogSets = currentBuild.rawBuild.changeSets\n        for (int i = 0; i < changeLogSets.size(); i++) {\n            def entries = changeLogSets[i].items\n            for (int j = 0; j < entries.length; j++) {\n                def entry = entries[j]\n                log += ""* ${entry.msg} by ${entry.author} \\n""\n            }\n        }\n    }\n    return log;\n}\n']"
240,2326,1508,CC BY-SA 3.0,2017-10-15T12:21:14.683,"<blockquote>
  <p>How to ensure that each tag has a unique semantic version number for
  the specific images?</p>
</blockquote>

<p>One could create a tag that consists of multiple elements, e.g. a combination of a timestamp, git commit hash and semantic version. The latter has to be set manually, while the first two could be automated. Such a tag could look as follows:</p>

<pre><code>20171015141729-58617f500f7efe236c7ba6a1dfdf37a478b4c878-0.1.4
</code></pre>

<p>This tag contains the date of build, the commit and the semantic version. If a docker image runs in production and a bug is found then one knows the version of the product, the code that is inside and when the image was built and under what circumstances.</p>

<blockquote>
  <p>Who should be the authority on tracking / incrementing a build
  version?</p>
</blockquote>

<p>In my opinion this should be the responsibility of the CI as this is able to automate processes and as the creation of tags could be automated such a tool is the right tool for the job.</p>
",210,2017-10-15T12:21:14.683,['20171015141729-58617f500f7efe236c7ba6a1dfdf37a478b4c878-0.1.4\n']
241,2328,2312,CC BY-SA 3.0,2017-10-15T14:37:09.083,"<p>One could replace</p>

<pre><code>rewrite /(.*) /ipns/QmdpoFuwY/$1 break;
</code></pre>

<p>with</p>

<pre><code>rewrite ^(.*[^/]) /ipns/QmdpoFuwY/$1 break;
</code></pre>

<p>and try again.</p>

<p>The issue was solved by inspecting the logs. If for example one navigated to <code>/foo/</code> instead of <code>/foo/</code> the log indicated:</p>

<pre><code>2017/10/15 14:51:28 [error] 7#7: *1 ""/etc/nginx/html/index.html/foo.html"" is not found (20: Not a directory)
</code></pre>

<p>It turned out that the regex did not match <code>/foo/</code>. One could also enable the rewrite logging to facilitate debugging:</p>

<pre><code>rewrite_log on;
</code></pre>
",210,2017-10-15T14:55:45.317,"['rewrite /(.*) /ipns/QmdpoFuwY/$1 break;\n', 'rewrite ^(.*[^/]) /ipns/QmdpoFuwY/$1 break;\n', '2017/10/15 14:51:28 [error] 7#7: *1 ""/etc/nginx/html/index.html/foo.html"" is not found (20: Not a directory)\n', 'rewrite_log on;\n']"
242,2334,2332,CC BY-SA 3.0,2017-10-16T13:53:21.823,"<p>A not very devopsy, but quite simple and effective solution with no security implications (no credential exchange or authentication required) would be to establish a file-based ""message"" exchange scheme, in a ""mailbox"" - a well-known filesystem location (setup once and owned by <code>root</code>) with 2 directories:</p>

<ul>
<li>one owned by the jenkins user which creates <strong>request</strong> files containing deployment request information, one for each site</li>
<li>one owned by the apache group where each site dedicated users create their own <strong>response</strong> files containing request handling information for deployment requests for their site</li>
</ul>

<p>When jenkins processing reaches a deployment stage for a particular site it creates a corresponding <strong>request</strong> file with the necessary information in it.</p>

<p>Each site user periodically (cron-driven, for example) checks for <strong>request</strong> files pertaining to their site, handle the request as appropriate, following their own site policies and provide status updates in the respective <strong>response</strong> files, which the jenkins user checks periodically.</p>

<p>When a request handling is completed the jenkins user removes the <strong>request</strong> file, signalling that it received the ""message"" and then the site user periodical job can remove the corresponding <strong>response</strong> file.</p>

<p>The names of the <strong>request</strong> and <strong>response</strong> files can be used to encode the particular site and request identification, so that the periodical checks don't have to fumble through multiple files.</p>

<p>The scheme can easily work across machines (if, for example, some of the sites are migrated to other servers) simply by placing the ""mailbox"" on a shared filesystem accessible from all those machines.</p>

<p>OK, an example, as requested. Just a basic skeleton, in python, hopefully self-documenting.</p>

<p>Prerequisites:</p>

<pre><code>sudo mkdir -p /var/message_box/requests
sudo chown jenkins /var/message_box/requests
sudo chmod go-w /var/message_box/requests
sudo mkdir /var/message_box/responses
sudo chgrp apache /var/message_box/responses
sudo chmod g+w /var/message_box/responses
</code></pre>

<p>The <code>mailbox.py</code> file:</p>

<pre><code>#!/usr/bin/python2.7 -u

import logging, os, re, getpass, sys, time, yaml

class Mailbox(object):

    base_dir = '/var/message_box'
    request_filename_format = '%s.%s.yaml'  # username.id.yaml

    def __init__(self):
        pass

    @property
    def request_dir(self):
        return os.path.join(self.base_dir, 'requests')

    @property
    def response_dir(self):
        return os.path.join(self.base_dir, 'responses')

    def msg_filename(self, user, request_id):
        return self.request_filename_format % (user, request_id)

    def request_file(self, user, request_id):
        return os.path.join(self.request_dir, self.msg_filename(user, request_id))

    def response_file(self, user, request_id):
        return os.path.join(self.response_dir, self.msg_filename(user, request_id))

    def create_msg_file(self, user, request_id, data, is_response=False):
        assert user and request_id and data and isinstance(data, dict)
        msg_file = self.response_file(user, request_id) if is_response else \
                   self.request_file(user, request_id)
        with open(msg_file, 'w') as fd:
            fd.write(yaml.dump(data))

    def msg_file_data(self, user, request_id, is_response=False):
        msg_file = self.response_file(user, request_id) if is_response else \
                   self.request_file(user, request_id)
        if os.path.exists(msg_file):
            with open(msg_file) as fd:
                data = yaml.load(fd.read())
            if data and isinstance(data, dict):  # expected data format
                return data
        return None

    def create_request(self, user, request_id, data):
        self.create_msg_file(user, request_id, data)
        logging.info('created request %s for %s' % (request_id, user))

    def create_response(self, request_id, status, response_data=None):
        assert status
        user = getpass.getuser()
        self.create_msg_file(user, request_id, {'status': status, 'data': response_data}, is_response=True)
        logging.info('created response %s with status %s for %s' % (request_id, status, user))


    def handle_requests(self):
        user = getpass.getuser()
        while True:  # keep handling requests indefinitely
            time.sleep(1)  # new request polling rate, in seconds
            for filename in os.listdir(self.request_dir):
                m = re.match('(.*)\.(.*)\.yaml', filename)
                if not m:  # not a valid request filename
                    continue
                [username, request_id] = m.groups()
                if username != user:  # not a request for this user
                    continue
                if os.path.exists(self.response_file(user, request_id)):
                    # request handling already started
                    # you may add here recovery code for request handling interrupted for whatever reason
                    continue
                msg_data = self.msg_file_data(user, request_id)
                if not msg_data:  # unexpected data format
                    continue

                logging.info('received request %s: %s' % (request_id, msg_data))

                # mark the request handling start
                self.create_response(request_id, 'in_progress')

                time.sleep(5)  # mock-up, replace with whatever request handling means

                # mark the request handling done
                self.create_response(request_id, 'done')  # you can add response data to the dict if needed

                logging.info('handled request %s, waiting for confirmation' % request_id)

                while True:  # wait for confirmation receipt before cleaning up
                    time.sleep(1)  # confirmation receipt polling rate, in seconds
                    if not os.path.exists(self.request_file(user, request_id)):
                        # the deletion of the request file is the confirmation receipt
                        logging.info('confirmation for request %s received, cleaning up' % request_id)
                        os.unlink(self.response_file(user, request_id))  # cleanup response file
                        break


    def execute_deployment(self, deployment_id, deployment_user, deployment_data):

        self.create_request(deployment_user, deployment_id, deployment_data)
        started = False
        while True:  # wait until it's done
            time.sleep(1)  # polling rate, in seconds
            msg_data = self.msg_file_data(deployment_user, deployment_id, is_response=True)
            if msg_data:
                status = msg_data.get('status')
                if status:
                    if not started:
                        logging.info('request %s handling started' % deployment_id)
                        started = True
                    if status == 'done':  # job completed
                        logging.info('request %s handling completed, cleaning up' % deployment_id)
                        # cleanup request file, which is the confirmation receipt
                        os.unlink(self.request_file(deployment_user, deployment_id))
                        break

def usage(err_msg, option_parser):
    if err_msg:
        logging.error('%s\n\n%s\n' % (err_msg, option_parser.format_help()))
    sys.exit(-1)


if __name__ == ""__main__"":
    import optparse

    logging.basicConfig(level=logging.DEBUG, format=""%(levelname)5s  %(asctime)s %(filename)s:%(lineno)d] %(message)s"")
    os.umask(022)

    p = optparse.OptionParser()
    p.add_option('-c', '--command', action='store', dest='command', choices=['deploy', 'handler'],
                 help='command/mode: &lt;deploy|handler&gt;, mandatory', default=None)
    p.add_option('-i', '--ID', action='store', dest='id',
                 help='deployment ID, mandatory for deploy command', default=None)
    p.add_option('-u', '--user', action='store', dest='user',
                 help='deployment user, mandatory for deploy command', default=None)
    p.add_option('-a', '--artifact', action='store', dest='artifact',
                 help='deployment artifact, mandatory for deploy command', default=None)

    opts, _ = p.parse_args()

    if not opts.command:
        usage('command is mandatory', p)

    mailbox = Mailbox()

    if opts.command == 'deploy':
        if not opts.id or not opts.user or not opts.artifact:
            usage('ID and user must be specified for deploy command', p)
        data = {'artifact': opts.artifact}
        mailbox.execute_deployment(opts.id, opts.user, data)

    elif opts.command == 'handler':
        mailbox.handle_requests()
</code></pre>

<p>The jenkins user driving the deployments, deployment info hacked to a string for this example - 'artifact' :</p>

<pre><code>$ ./mailbox.py -c deploy -i 20 -u dancorn -a artifact
 INFO  2017-10-17 13:32:34,663 mailbox.py:49] created request 20 for dancorn
 INFO  2017-10-17 13:32:35,666 mailbox.py:109] request 20 handling started
 INFO  2017-10-17 13:32:40,678 mailbox.py:112] request 20 handling completed, cleaning up
$ ./mailbox.py -c deploy -i 123 -u dancorn -a artifact
 INFO  2017-10-17 13:33:32,359 mailbox.py:49] created request 123 for dancorn
 INFO  2017-10-17 13:33:33,362 mailbox.py:109] request 123 handling started
 INFO  2017-10-17 13:33:38,375 mailbox.py:112] request 123 handling completed, cleaning up
$
</code></pre>

<p>The apache users would launch the handler which in this example remains running (could be converted to a daemon, or a cron-driven approach):</p>

<pre><code>$ ./mailbox.py -c handler
 INFO  2017-10-17 13:32:34,819 mailbox.py:77] received request 20: {'artifact': 'artifact'}
 INFO  2017-10-17 13:32:34,821 mailbox.py:55] created response 20 with status in_progress for dancorn
 INFO  2017-10-17 13:32:39,827 mailbox.py:55] created response 20 with status done for dancorn
 INFO  2017-10-17 13:32:39,827 mailbox.py:87] handled request 20, waiting for confirmation
 INFO  2017-10-17 13:32:40,828 mailbox.py:93] confirmation for request 20 received, cleaning up
 INFO  2017-10-17 13:33:32,888 mailbox.py:77] received request 123: {'artifact': 'artifact'}
 INFO  2017-10-17 13:33:32,889 mailbox.py:55] created response 123 with status in_progress for dancorn
 INFO  2017-10-17 13:33:37,891 mailbox.py:55] created response 123 with status done for dancorn
 INFO  2017-10-17 13:33:37,891 mailbox.py:87] handled request 123, waiting for confirmation
 INFO  2017-10-17 13:33:38,893 mailbox.py:93] confirmation for request 123 received, cleaning up
</code></pre>
",47,2017-10-17T18:00:32.723,"['sudo mkdir -p /var/message_box/requests\nsudo chown jenkins /var/message_box/requests\nsudo chmod go-w /var/message_box/requests\nsudo mkdir /var/message_box/responses\nsudo chgrp apache /var/message_box/responses\nsudo chmod g+w /var/message_box/responses\n', '#!/usr/bin/python2.7 -u\n\nimport logging, os, re, getpass, sys, time, yaml\n\nclass Mailbox(object):\n\n    base_dir = \'/var/message_box\'\n    request_filename_format = \'%s.%s.yaml\'  # username.id.yaml\n\n    def __init__(self):\n        pass\n\n    @property\n    def request_dir(self):\n        return os.path.join(self.base_dir, \'requests\')\n\n    @property\n    def response_dir(self):\n        return os.path.join(self.base_dir, \'responses\')\n\n    def msg_filename(self, user, request_id):\n        return self.request_filename_format % (user, request_id)\n\n    def request_file(self, user, request_id):\n        return os.path.join(self.request_dir, self.msg_filename(user, request_id))\n\n    def response_file(self, user, request_id):\n        return os.path.join(self.response_dir, self.msg_filename(user, request_id))\n\n    def create_msg_file(self, user, request_id, data, is_response=False):\n        assert user and request_id and data and isinstance(data, dict)\n        msg_file = self.response_file(user, request_id) if is_response else \\\n                   self.request_file(user, request_id)\n        with open(msg_file, \'w\') as fd:\n            fd.write(yaml.dump(data))\n\n    def msg_file_data(self, user, request_id, is_response=False):\n        msg_file = self.response_file(user, request_id) if is_response else \\\n                   self.request_file(user, request_id)\n        if os.path.exists(msg_file):\n            with open(msg_file) as fd:\n                data = yaml.load(fd.read())\n            if data and isinstance(data, dict):  # expected data format\n                return data\n        return None\n\n    def create_request(self, user, request_id, data):\n        self.create_msg_file(user, request_id, data)\n        logging.info(\'created request %s for %s\' % (request_id, user))\n\n    def create_response(self, request_id, status, response_data=None):\n        assert status\n        user = getpass.getuser()\n        self.create_msg_file(user, request_id, {\'status\': status, \'data\': response_data}, is_response=True)\n        logging.info(\'created response %s with status %s for %s\' % (request_id, status, user))\n\n\n    def handle_requests(self):\n        user = getpass.getuser()\n        while True:  # keep handling requests indefinitely\n            time.sleep(1)  # new request polling rate, in seconds\n            for filename in os.listdir(self.request_dir):\n                m = re.match(\'(.*)\\.(.*)\\.yaml\', filename)\n                if not m:  # not a valid request filename\n                    continue\n                [username, request_id] = m.groups()\n                if username != user:  # not a request for this user\n                    continue\n                if os.path.exists(self.response_file(user, request_id)):\n                    # request handling already started\n                    # you may add here recovery code for request handling interrupted for whatever reason\n                    continue\n                msg_data = self.msg_file_data(user, request_id)\n                if not msg_data:  # unexpected data format\n                    continue\n\n                logging.info(\'received request %s: %s\' % (request_id, msg_data))\n\n                # mark the request handling start\n                self.create_response(request_id, \'in_progress\')\n\n                time.sleep(5)  # mock-up, replace with whatever request handling means\n\n                # mark the request handling done\n                self.create_response(request_id, \'done\')  # you can add response data to the dict if needed\n\n                logging.info(\'handled request %s, waiting for confirmation\' % request_id)\n\n                while True:  # wait for confirmation receipt before cleaning up\n                    time.sleep(1)  # confirmation receipt polling rate, in seconds\n                    if not os.path.exists(self.request_file(user, request_id)):\n                        # the deletion of the request file is the confirmation receipt\n                        logging.info(\'confirmation for request %s received, cleaning up\' % request_id)\n                        os.unlink(self.response_file(user, request_id))  # cleanup response file\n                        break\n\n\n    def execute_deployment(self, deployment_id, deployment_user, deployment_data):\n\n        self.create_request(deployment_user, deployment_id, deployment_data)\n        started = False\n        while True:  # wait until it\'s done\n            time.sleep(1)  # polling rate, in seconds\n            msg_data = self.msg_file_data(deployment_user, deployment_id, is_response=True)\n            if msg_data:\n                status = msg_data.get(\'status\')\n                if status:\n                    if not started:\n                        logging.info(\'request %s handling started\' % deployment_id)\n                        started = True\n                    if status == \'done\':  # job completed\n                        logging.info(\'request %s handling completed, cleaning up\' % deployment_id)\n                        # cleanup request file, which is the confirmation receipt\n                        os.unlink(self.request_file(deployment_user, deployment_id))\n                        break\n\ndef usage(err_msg, option_parser):\n    if err_msg:\n        logging.error(\'%s\\n\\n%s\\n\' % (err_msg, option_parser.format_help()))\n    sys.exit(-1)\n\n\nif __name__ == ""__main__"":\n    import optparse\n\n    logging.basicConfig(level=logging.DEBUG, format=""%(levelname)5s  %(asctime)s %(filename)s:%(lineno)d] %(message)s"")\n    os.umask(022)\n\n    p = optparse.OptionParser()\n    p.add_option(\'-c\', \'--command\', action=\'store\', dest=\'command\', choices=[\'deploy\', \'handler\'],\n                 help=\'command/mode: <deploy|handler>, mandatory\', default=None)\n    p.add_option(\'-i\', \'--ID\', action=\'store\', dest=\'id\',\n                 help=\'deployment ID, mandatory for deploy command\', default=None)\n    p.add_option(\'-u\', \'--user\', action=\'store\', dest=\'user\',\n                 help=\'deployment user, mandatory for deploy command\', default=None)\n    p.add_option(\'-a\', \'--artifact\', action=\'store\', dest=\'artifact\',\n                 help=\'deployment artifact, mandatory for deploy command\', default=None)\n\n    opts, _ = p.parse_args()\n\n    if not opts.command:\n        usage(\'command is mandatory\', p)\n\n    mailbox = Mailbox()\n\n    if opts.command == \'deploy\':\n        if not opts.id or not opts.user or not opts.artifact:\n            usage(\'ID and user must be specified for deploy command\', p)\n        data = {\'artifact\': opts.artifact}\n        mailbox.execute_deployment(opts.id, opts.user, data)\n\n    elif opts.command == \'handler\':\n        mailbox.handle_requests()\n', '$ ./mailbox.py -c deploy -i 20 -u dancorn -a artifact\n INFO  2017-10-17 13:32:34,663 mailbox.py:49] created request 20 for dancorn\n INFO  2017-10-17 13:32:35,666 mailbox.py:109] request 20 handling started\n INFO  2017-10-17 13:32:40,678 mailbox.py:112] request 20 handling completed, cleaning up\n$ ./mailbox.py -c deploy -i 123 -u dancorn -a artifact\n INFO  2017-10-17 13:33:32,359 mailbox.py:49] created request 123 for dancorn\n INFO  2017-10-17 13:33:33,362 mailbox.py:109] request 123 handling started\n INFO  2017-10-17 13:33:38,375 mailbox.py:112] request 123 handling completed, cleaning up\n$\n', ""$ ./mailbox.py -c handler\n INFO  2017-10-17 13:32:34,819 mailbox.py:77] received request 20: {'artifact': 'artifact'}\n INFO  2017-10-17 13:32:34,821 mailbox.py:55] created response 20 with status in_progress for dancorn\n INFO  2017-10-17 13:32:39,827 mailbox.py:55] created response 20 with status done for dancorn\n INFO  2017-10-17 13:32:39,827 mailbox.py:87] handled request 20, waiting for confirmation\n INFO  2017-10-17 13:32:40,828 mailbox.py:93] confirmation for request 20 received, cleaning up\n INFO  2017-10-17 13:33:32,888 mailbox.py:77] received request 123: {'artifact': 'artifact'}\n INFO  2017-10-17 13:33:32,889 mailbox.py:55] created response 123 with status in_progress for dancorn\n INFO  2017-10-17 13:33:37,891 mailbox.py:55] created response 123 with status done for dancorn\n INFO  2017-10-17 13:33:37,891 mailbox.py:87] handled request 123, waiting for confirmation\n INFO  2017-10-17 13:33:38,893 mailbox.py:93] confirmation for request 123 received, cleaning up\n""]"
243,2373,2342,CC BY-SA 3.0,2017-10-19T22:34:10.353,"<pre><code>docker run -ti --rm \
  -v $PWD:/workdir \
  -v $HOME/.ssh:/root/.ssh \
  --user $(id -u):$(id -g) \
  dockerizedxyz ""$@""
</code></pre>

<p>As long as you're not doing anything funny with the entrypoint in the container, this will leave files owned as the user that invoked Docker.</p>
",4369,2017-10-19T22:34:10.353,"['docker run -ti --rm \\\n  -v $PWD:/workdir \\\n  -v $HOME/.ssh:/root/.ssh \\\n  --user $(id -u):$(id -g) \\\n  dockerizedxyz ""$@""\n']"
244,2381,1832,CC BY-SA 3.0,2017-10-20T19:56:33.313,"<p>One could use the <a href=""https://wiki.jenkins.io/display/JENKINS/PollSCM+Plugin"" rel=""nofollow noreferrer"">PollSCM plugin</a>.</p>

<p><a href=""https://jenkins.io/doc/book/pipeline/syntax/"" rel=""nofollow noreferrer"">https://jenkins.io/doc/book/pipeline/syntax/</a></p>

<pre><code>triggers { pollSCM('H 4/* 0 0 1-5') }
</code></pre>

<blockquote>
  <p>The pollSCM trigger is only available in Jenkins 2.22 or later.</p>
</blockquote>
",210,2017-10-20T19:56:33.313,"[""triggers { pollSCM('H 4/* 0 0 1-5') }\n""]"
245,2393,2392,CC BY-SA 3.0,2017-10-23T06:33:50.193,"<p>I've tried your case, and it works fine on my side:</p>

<pre><code>version: '2'
  services:
    test:
      image: ubuntu:16.04
      command: sleep 9999
    extra_hosts:
      - ""${HOSTNAME}:1.1.1.1""
      - ""test.com:1.1.1.1""
</code></pre>

<p>and here is what I get in the container</p>

<pre><code>cat /etc/hosts
...
1.1.1.1 a1.test.com
1.1.1.1 test.com
</code></pre>
",3533,2017-10-23T06:33:50.193,"['version: \'2\'\n  services:\n    test:\n      image: ubuntu:16.04\n      command: sleep 9999\n    extra_hosts:\n      - ""${HOSTNAME}:1.1.1.1""\n      - ""test.com:1.1.1.1""\n', 'cat /etc/hosts\n...\n1.1.1.1 a1.test.com\n1.1.1.1 test.com\n']"
246,2398,2394,CC BY-SA 3.0,2017-10-24T01:23:52.537,"<h2>If editing critical flat-files across multiple servers in one place is too scary..</h2>

<p>One approach I have often recommended is to let system users reside in /etc/passwd files, and to add an additional Name Service Switch (NSS) source for humans that need to log in. For big projects (lots of users authenticating against the PAM user data), that means LDAP, and for small ones (few can be hundreds of such users), nss_db + pam_userdb.</p>

<p>With multiple NSS and PAM sources for users, you can avoid disabling a server when the human user accounts distribution fails for whatever reason. Services (like your privileged Ansible account) should always depend ONLY on the standard /etc/passwd files. LDAP (or even MySQL) is probably overkill for some cases (like yours). </p>

<p>Consider the old BDB backed gems, designed originally (for big FTP file distribution servers) to provide faster logins than /etc files, but otherwise work nearly the same. They store the same passwd and groups flat files' content, but loaded into a (now non GPL) BerkeleyDB NOSQL key/value database file which is faster to read. For this purpose, it's just an extra place to store user/group authentication/authorization data.</p>

<h2>NSS</h2>

<p><a href=""https://en.wikipedia.org/wiki/Name_Service_Switch"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Name_Service_Switch</a></p>

<p><a href=""https://www.systutorials.com/docs/linux/man/5-nsswitch.conf/"" rel=""nofollow noreferrer"">https://www.systutorials.com/docs/linux/man/5-nsswitch.conf/</a></p>

<p><a href=""https://sourceforge.net/p/nssdb/home/Home/"" rel=""nofollow noreferrer"">https://sourceforge.net/p/nssdb/home/Home/</a></p>

<h2>PAM</h2>

<p><a href=""https://en.wikipedia.org/wiki/Linux_PA"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Linux_PA</a></p>

<p><a href=""https://www.systutorials.com/docs/linux/man/8-pam_userdb/"" rel=""nofollow noreferrer"">https://www.systutorials.com/docs/linux/man/8-pam_userdb/</a></p>

<p><a href=""https://www.cyberciti.biz/tips/centos-redhat-vsftpd-ftp-with-virtual-users.html"" rel=""nofollow noreferrer"">https://www.cyberciti.biz/tips/centos-redhat-vsftpd-ftp-with-virtual-users.html</a></p>

<h2>steps</h2>

<ol>
<li>collect your passwd, shadow, and group files on a secure server with
the nss_db Makefile</li>
<li>build the nss passwd and group db files using the provided nss_db
Makefile</li>
<li><p>extract the users and password hashes from shadow file and build PAM db file</p>

<pre><code>awk -F: '{print $1;print$2}' shadow &gt; users.txt # used like the vsftpd vusers.txt example

db_load -T -t hash -f users.txt pam-users.db
</code></pre></li>
<li><p>distribute the files to somewhere appropriate on your target servers
(maybe /var/db/authdb/*.db)</p></li>
<li><p>set up the target servers' pam.conf and nsswitch.conf files to use
these db files</p></li>
<li><p>Steps 1-4 are the repeatable build/deploy process.</p></li>
</ol>

<h2>why?</h2>

<ul>
<li>Once you have working pam/nss configs, your risk of breaking services
by updating/corrupting user auth/auth is very low.</li>
<li>User authentication will work on each server with no external network dependencies like LDAP or MySQL etc.</li>
<li>You can treat the DB files as immutable artifacts on the farm to reduce/prevent user auth snowflakes even if you can't have immutable servers.</li>
</ul>
",4822,2017-10-24T07:54:08.167,"[""awk -F: '{print $1;print$2}' shadow > users.txt # used like the vsftpd vusers.txt example\n\ndb_load -T -t hash -f users.txt pam-users.db\n""]"
247,2410,2408,CC BY-SA 3.0,2017-10-24T14:02:36.953,"<p>This question has two approaches, and both has answers on SO:</p>

<ol>
<li><p>Convert all Ansible output to JSON with <code>json</code> stdout callback and parse it with your favourite tools. The <code>eos_command</code> output for each device will be under different host key in the resulting json.
See <a href=""https://stackoverflow.com/a/39037249/2795592"">this</a> and <a href=""https://stackoverflow.com/a/44717744/2795592"">this</a>.</p></li>
<li><p>Make <code>run_once</code> task to collect data from other hosts, like this:</p>

<pre><code>- debug:
    msg: ""{{ ansible_play_hosts | map('extract', hostvars, 'result') | map(attribute='stdout_lines') | list }}""
  run_once: yes
</code></pre>

<p>See <a href=""https://stackoverflow.com/a/43908569/2795592"">this</a>.</p></li>
</ol>
",3509,2017-10-24T14:02:36.953,"['- debug:\n    msg: ""{{ ansible_play_hosts | map(\'extract\', hostvars, \'result\') | map(attribute=\'stdout_lines\') | list }}""\n  run_once: yes\n']"
248,2433,2411,CC BY-SA 3.0,2017-10-27T15:12:11.313,"<p>Varnish is monitored with what they call VSM. It's a file in your container. If you bind mount the folder where the files is, you can share the same folder / files in other containers that will be able to read it, and thus will be able to monitor your varnish instance.
See the note about <a href=""https://varnish-cache.org/docs/trunk/reference/vsm.html#vsm-and-containers"" rel=""nofollow noreferrer"">VSM and containers</a> in varnish docs.
I have been able to launch a <code>varnishstat</code> with statistics in a container with varnish in the image, but no varnish running, like this:</p>

<pre><code>docker run --rm -it \
       --entrypoint=/bin/sh \
       -v /var/lib/docker/overlay2/$hash/merged/usr/local/var/varnish/$hostname:/varnish \
      emgag/varnish:5.1.3 varnishstat -N /varnish/_.vsm
</code></pre>
",559,2017-10-27T15:30:52.900,['docker run --rm -it \\\n       --entrypoint=/bin/sh \\\n       -v /var/lib/docker/overlay2/$hash/merged/usr/local/var/varnish/$hostname:/varnish \\\n      emgag/varnish:5.1.3 varnishstat -N /varnish/_.vsm\n']
249,2435,2434,CC BY-SA 3.0,2017-10-27T19:47:22.990,"<p><a href=""https://hub.docker.com/r/docker/compose/"" rel=""nofollow noreferrer"">According to this reply</a> it should run by issuing:</p>

<blockquote>
<pre><code>docker run -ti --rm -v `pwd`/docker-compose.yaml:/docker-compose.yml -v
/var/run/docker.sock:/var/run/docker.sock docker/compose:1.16.1 up
</code></pre>
</blockquote>
",210,2017-10-27T19:47:22.990,['docker run -ti --rm -v `pwd`/docker-compose.yaml:/docker-compose.yml -v\n/var/run/docker.sock:/var/run/docker.sock docker/compose:1.16.1 up\n']
250,2438,1406,CC BY-SA 3.0,2017-10-28T01:58:20.477,"<p>Your question is sitting unanswered here because you're way ""out in the weeds"" - running pretty idiosyncratic batch scripts that seem to leverage cygwin on Windows, in short, you're in the ""wtf"" category here.  That's ok!  In this work, all of us are in this place for a lot of our day.</p>

<p>I suggest you consider switching these up for powershell tasks, you can use: </p>

<pre><code>node {
    powershell 'get-process ""Openvpn"" | stop-process -force'
}
</code></pre>

<p>to help with this.  This will simplify your build server and remove external dependencies on cygwin- which if you've ever grappled with at any scale, is a real monster.  It's tough to install automatically, tough to keep up to date, a vuln factory, and poorly maintained.</p>

<p>Perhaps even bigger picture though, using a VPN tunnel in a deployment process is slightly unorthodox.  You might consider pushing an artifact to a repository that both Jenkins and your target server have access to, then polling from the target server for the presence of a new build, then installing it.  Or simply decouple your build and deploy phases with a manual step- one where you log into your production environment to kick off a deployment after a build/test succeeds.  </p>
",2276,2017-10-28T01:58:20.477,"['node {\n    powershell \'get-process ""Openvpn"" | stop-process -force\'\n}\n']"
251,2446,2445,CC BY-SA 3.0,2017-10-28T18:46:40.167,"<p>My idea of where the hostname was coming from was wrong. According to the <a href=""https://kubernetes.io/docs/concepts/services-networking/service/"" rel=""nofollow noreferrer"">docs</a>:</p>

<blockquote>
  <p>Every Service defined in the cluster (including the DNS server itself) is assigned a DNS name.</p>
</blockquote>

<p>and</p>

<blockquote>
  <p>Currently when a pod is created, its hostname is the Pod’s metadata.name value.</p>
</blockquote>

<p>So the hostname is actually the name of the service. The last sentence in my question says I did not change the service in anyway. That was an unintentional lie. I did change the service name, or else <code>selenium-hub</code> as the hostname would have worked.</p>

<p>Changing <code>HUB_PORT_4444_TCP_ADDR</code> to the <code>.metadata.name</code> of the <em>service</em> got me closer. The connection was timing out, though.</p>

<p>I believed some of the configuration was wrong in my service yaml. So instead of using my yaml file, I created the service via:
<code>kubectl expose deployment &lt;deployment name here&gt;</code></p>

<p>This created a service and I checked the selenium-hub and the node was finally connected. So there was an issue in my service yaml. To get the correct configuration I exported the currently working service:
<code>kubectl get svc &lt;service name here&gt; -o yaml --export</code></p>

<p>I copied the exported configuration to my service yaml file and it also worked. Here was the difference between the service yamls</p>

<pre><code>old yaml (copied from GitHub example above)
---
apiVersion: v1
kind: Service
metadata:
  name: selenium-hub-service
  labels:
    app: selenium-grid
spec:
  ports:
  - port: 4444
    targetPort: 4444
    protocol: TCP ------------- [added in new config]
    name: port0 ------------- [deleted in new config]
  selector:
    app: selenium-hub
  type: NodePort ------------- [deleted in new config]
  sessionAffinity: None
</code></pre>

<p>I am not sure why adding <code>.spec.ports[0].protocol</code> and deleting <code>.spec.type</code> and <code>.spec.ports[0].name</code> fixed the issue. If anyone could clarify in the comments I would appreciate it.</p>
",4939,2017-10-28T18:52:00.770,['old yaml (copied from GitHub example above)\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: selenium-hub-service\n  labels:\n    app: selenium-grid\nspec:\n  ports:\n  - port: 4444\n    targetPort: 4444\n    protocol: TCP ------------- [added in new config]\n    name: port0 ------------- [deleted in new config]\n  selector:\n    app: selenium-hub\n  type: NodePort ------------- [deleted in new config]\n  sessionAffinity: None\n']
252,2454,1905,CC BY-SA 3.0,2017-10-29T13:45:22.873,"<blockquote>
  <p>What I ultimately want is to have these old, archived reviews be
  searchable and for all the links to work more or less as expected for
  the sake of convenience.</p>
</blockquote>

<p>As already indicated in one of the comments, <a href=""https://stackoverflow.com/a/19695143/2777965"">wget</a> could be used to retrieve the content:</p>

<pre><code>wget -r --no-parent devops.com
</code></pre>

<p>will create a devops.com folder and put all files in this directory.</p>
",210,2017-10-29T13:45:22.873,['wget -r --no-parent devops.com\n']
253,2462,2442,CC BY-SA 3.0,2017-10-29T20:31:02.020,"<p>edit your /etc/ssh/sshd_config and add</p>

<pre><code>AuthorizedKeysFile    /etc/ssh/all_users_authorized_keys
</code></pre>

<p>Put your pubkey in that file, and restart the sshd.</p>

<p>See:
<a href=""https://www.ssh.com/ssh/authorized_keys/openssh"" rel=""nofollow noreferrer"">https://www.ssh.com/ssh/authorized_keys/openssh</a></p>

<p>The default behavior (which we are all probably familiar with) is </p>

<pre><code>AuthorizedKeysFile    %h/.ssh/authorized_keys
</code></pre>
",4822,2017-10-29T20:31:02.020,"['AuthorizedKeysFile    /etc/ssh/all_users_authorized_keys\n', 'AuthorizedKeysFile    %h/.ssh/authorized_keys\n']"
254,2472,1470,CC BY-SA 3.0,2017-10-31T13:21:17.900,"<p>Example in AWS cli that should work to get the ASG name</p>

<pre><code>a=curl 'http://169.254.169.254/latest/meta-data/instance-id'; aws autoscaling describe-auto-scaling-instances --instance-ids $a --query 'AutoScalingInstances[*].AutoScalingGroupName'
</code></pre>
",4954,2017-10-31T13:21:17.900,"[""a=curl 'http://169.254.169.254/latest/meta-data/instance-id'; aws autoscaling describe-auto-scaling-instances --instance-ids $a --query 'AutoScalingInstances[*].AutoScalingGroupName'\n""]"
255,2475,2468,CC BY-SA 3.0,2017-10-31T18:06:36.833,"<p>I am going to put some concreteness to @Tensibai's recommendation in the comments. I began looking into Ingress and Ingress controllers, but my knowledge/implementation was wrong. I successfully connected via an Ingress, but I felt, at least my implementation, it still depended on the node the ingress was running on.</p>

<p>So, I began looking at ELB on AWS. I couldn't find any good tutorials on implementing this specific for AWS. The official <a href=""https://kubernetes.io/docs/tasks/access-application-cluster/load-balance-access-application-cluster/"" rel=""nofollow noreferrer"">docs</a> actually helped more than I was aware. It ended up being embarrassingly easy. I made a single change to my service yaml:</p>

<pre><code>type: NodePort
</code></pre>

<p>to</p>

<pre><code>type: LoadBalancer
</code></pre>

<p>and applied it via <code>kubectl apply -f my-file.yaml</code></p>

<p>You can then find the external IP: </p>

<pre><code>$ kubectl get svc
NAME             TYPE           CLUSTER-IP      EXTERNAL-IP        PORT(S)
my-service       LoadBalancer   100.99.98.97    12.34.56.78        444:31415/TCP
</code></pre>

<p>One part I was not expecting is that the first port <code>444</code> is used, rather than the NodePort (<code>31415</code> in my case).</p>

<p>To access my app I would use: <code>12.34.56.78:444</code></p>

<p>The second part I was not expecting is that the external IP, in my case on AWS, was an ELB. It was created automatically in AWS. I am not sure if kubernetes does this, or kops? Maybe someone can clarify in the comments.</p>
",4939,2017-10-31T18:06:36.833,"['type: NodePort\n', 'type: LoadBalancer\n', '$ kubectl get svc\nNAME             TYPE           CLUSTER-IP      EXTERNAL-IP        PORT(S)\nmy-service       LoadBalancer   100.99.98.97    12.34.56.78        444:31415/TCP\n']"
256,2492,1575,CC BY-SA 3.0,2017-11-03T01:18:24.333,"<p>I am by no means an expert but there is an alternative to creating a script containing 'plain text' passwords, which obviously isn't very secure.</p>

<p>I have written the following code snippet based on this article <a href=""https://mcpmag.com/articles/2011/09/06/powershell-get-credential-cmdlet.aspx"" rel=""nofollow noreferrer"">Who Are You? Or, Slipping By the Get-Credential Cmdlet</a> by <a href=""https://plus.google.com/u/0/+JefferyHicks"" rel=""nofollow noreferrer"">Jeff Hicks</a> and now use this in order to automate a remote session.</p>

<pre><code># Create a secure string for the password
$Username = Read-Host ""Enter Username""
$Password = Read-Host ""Enter Password"" -AsSecureString

# Create the PSCredential object
$Credentials = New-Object System.Management.Automation.PSCredential($Username,$Password)

# Server Variable
$Server = Read-Host ""Enter Server Name""

# Create Remote Session
Enter-PSSession -ComputerName $Server -Credential $Credentials
</code></pre>

<p>When running this code, you will get the following output:-</p>

<pre><code>PS Scripts:\&gt; .\Snippets\Enter-SecureCreds.ps1
Enter Username: ##YOUR-USERNAME#
Enter Password: *************
Enter Server Name: 192.168.1.10
</code></pre>

<p>Password is obfuscated with * when entered.</p>

<p>As advised in Jeff's article</p>

<blockquote>
  <p>This credential only exists for as long as your PowerShell session is
  open. But be careful, because even though the password is stored as a
  secure string, if I have interactive access to the console session, I
  can still see the password by invoking the GetNetworkCredential()
  method:</p>
</blockquote>

<pre><code>PS S:\&gt; $Credential.GetNetworkCredential()

UserName          Password          Domain
--------          --------          ------ 
admin             P@ssw0rd          mydomain
</code></pre>

<blockquote>
  <p>This isn't necessarily a security violation, unless you walk away and
  leave your session wide open for anyone to access. There may also be
  situations where you have a legacy application that can't use a
  PSCredential and you need to pass values like username and password to
  it. Just be aware.</p>
  
  <p>IMPORTANT: It is a security no-no to hard-code any password in any
  plain text file. Ideally, you'll want to provide some secure mechanism
  for the script user to provide the necessary password. Also, don't
  forget to secure your console if you are keeping the credential
  object.</p>
</blockquote>

<p>I hope you find this as useful as I have.</p>
",,2017-11-03T01:18:24.333,"['# Create a secure string for the password\n$Username = Read-Host ""Enter Username""\n$Password = Read-Host ""Enter Password"" -AsSecureString\n\n# Create the PSCredential object\n$Credentials = New-Object System.Management.Automation.PSCredential($Username,$Password)\n\n# Server Variable\n$Server = Read-Host ""Enter Server Name""\n\n# Create Remote Session\nEnter-PSSession -ComputerName $Server -Credential $Credentials\n', 'PS Scripts:\\> .\\Snippets\\Enter-SecureCreds.ps1\nEnter Username: ##YOUR-USERNAME#\nEnter Password: *************\nEnter Server Name: 192.168.1.10\n', 'PS S:\\> $Credential.GetNetworkCredential()\n\nUserName          Password          Domain\n--------          --------          ------ \nadmin             P@ssw0rd          mydomain\n']"
257,2496,2428,CC BY-SA 3.0,2017-11-03T16:09:30.933,"<p>It looks like you're using the wrong brackets? I think you need to use a list:</p>

<pre><code>variable ""azs"" {
  description = ""Run the EC2 Instances in these Availability Zones""
  type = ""list""
  default = [""us-east-1a"", ""us-east-1b"", ""us-east-1c""]
}
</code></pre>

<p><a href=""https://blog.gruntwork.io/terraform-tips-tricks-loops-if-statements-and-gotchas-f739bbae55f9"" rel=""nofollow noreferrer"">Source</a></p>
",4854,2017-11-03T16:09:30.933,"['variable ""azs"" {\n  description = ""Run the EC2 Instances in these Availability Zones""\n  type = ""list""\n  default = [""us-east-1a"", ""us-east-1b"", ""us-east-1c""]\n}\n']"
258,2507,2506,CC BY-SA 3.0,2017-11-07T16:06:31.190,"<p>Unverified as it sounds brittle to me to start a container outside of k8s supervision, but you should be able to mount <code>/var/run/docker.sock</code> with a <a href=""https://kubernetes.io/docs/concepts/storage/volumes/#hostpath"" rel=""noreferrer"">hostPath volume</a>.</p>

<p>Example variation from the documentation:</p>

<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: test-pd
spec:
  containers:
  - image: gcr.io/google_containers/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /var/run/docker.sock
      name: docker-sock-volume
  volumes:
  - name: docker-sock-volume
    hostPath:
      # location on host
      path: /var/run/docker.sock
      # this field is optional
      type: File
</code></pre>

<p>I think a simple mount should be enough to allow communication from docker client within the container to docker daemon on host but in case you get a write permission error it means you need to run your container as privileged container
 using a <a href=""https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container"" rel=""noreferrer"">securityContext</a> object like such (just an extract from above to show the addition, values taken from <a href=""https://kubernetes.io/docs/api-reference/v1.8/#securitycontext-v1-core"" rel=""noreferrer"">the documentation</a>):</p>

<pre><code>spec:
  containers:
  - image: gcr.io/google_containers/test-webserver
    securityContext:
      privileged: true
    name: test-container
</code></pre>
",13,2017-11-08T06:53:44.347,"['apiVersion: v1\nkind: Pod\nmetadata:\n  name: test-pd\nspec:\n  containers:\n  - image: gcr.io/google_containers/test-webserver\n    name: test-container\n    volumeMounts:\n    - mountPath: /var/run/docker.sock\n      name: docker-sock-volume\n  volumes:\n  - name: docker-sock-volume\n    hostPath:\n      # location on host\n      path: /var/run/docker.sock\n      # this field is optional\n      type: File\n', 'spec:\n  containers:\n  - image: gcr.io/google_containers/test-webserver\n    securityContext:\n      privileged: true\n    name: test-container\n']"
259,2512,2511,CC BY-SA 3.0,2017-11-08T18:05:37.853,"<p>Yes, it is possible. The entire subject is discussed in <a href=""https://docs.docker.com/registry/recipes/mirror/#run-a-registry-as-a-pull-through-cache"" rel=""nofollow noreferrer"">Registry as a pull through cache</a>, from where the below quotes are taken. </p>

<p>Basically you need to configure the cache as a proxy for Docker Hub:</p>

<blockquote>
  <p><strong>Configure the cache</strong></p>
  
  <p>To configure a Registry to run as a pull through cache, the addition
  of a <code>proxy</code> section is required to the config file.</p>
  
  <p>In order to access private images on the Docker Hub, a username and
  password can be supplied.</p>

<pre><code>proxy:
  remoteurl: https://registry-1.docker.io
  username: [username]
  password: [password]
</code></pre>
</blockquote>

<p>Of course, you also need to configure your docker daemon to use your local cache (but I presume that may be already done from the context of the question):</p>

<blockquote>
  <p><strong>Configure the Docker daemon</strong></p>
  
  <p>Either pass the <code>--registry-mirror</code> option when starting <code>dockerd</code>
  manually, or edit <code>/etc/docker/daemon.json</code> and add the
  <code>registry-mirrors</code> key and value, to make the change persistent.</p>

<pre><code>{
  ""registry-mirrors"": [""https://&lt;my-docker-mirror-host&gt;""]
}
</code></pre>
</blockquote>
",47,2017-11-08T18:05:37.853,"['proxy:\n  remoteurl: https://registry-1.docker.io\n  username: [username]\n  password: [password]\n', '{\n  ""registry-mirrors"": [""https://<my-docker-mirror-host>""]\n}\n']"
260,2527,2526,CC BY-SA 3.0,2017-11-10T16:19:03.023,"<h1>wrong argument order to <code>su</code></h1>

<p><code>$ZOO_USER</code> needs to be the first argument to <code>su</code> with the <code>""$@""</code> coming afterwards.</p>

<pre><code>su -c ""$0"" ""$ZOO_USER"" ""$@""
</code></pre>

<p>It is ok for the options to come before the username.  It is a good idea to keep them in double quotes so that there aren't issues if someone accidentally puts spaces into it.</p>

<p>Your error message reinforces that this is an order of arguments problem.</p>

<h1>even better</h1>

<p>Based on comments this would be even better:</p>

<pre><code>su -c ""$0"" ""$ZOO_USER"" -- ""$@""
</code></pre>

<h2>su man page excerpt</h2>

<blockquote>
  <p>Additional arguments may be provided after the username, in which case they are supplied to the user's login shell. In particular, an argument of
  <code>-c</code> will cause the next argument to be treated as a command by most command interpreters. The command will be executed by the shell specified in <code>/etc/passwd</code> for the target user.</p>
  
  <p>You can use the <code>--</code> argument to separate <code>su</code> options from the arguments supplied to the shell.</p>
</blockquote>

<h2>busybox docs excerpt:</h2>

<p>In a comment the OP asked about why this wouldn't work in Alpine Linux.  Since alpine is based on <code>busybox</code> I looked up the busybox docs. 
 According to the <a href=""https://busybox.net/downloads/BusyBox.html"" rel=""nofollow noreferrer"">docs busybox doesn't support</a> sending additional arguments to <code>su</code>:</p>

<pre><code>su
su [OPTIONS] [-] [username]

Change user id or become root

Options:

        -p, -m  Preserve environment
        -c CMD  Command to pass to 'sh -c'
        -s SH   Shell to use instead of default shell
</code></pre>
",739,2017-11-17T04:01:53.687,"['su -c ""$0"" ""$ZOO_USER"" ""$@""\n', 'su -c ""$0"" ""$ZOO_USER"" -- ""$@""\n', ""su\nsu [OPTIONS] [-] [username]\n\nChange user id or become root\n\nOptions:\n\n        -p, -m  Preserve environment\n        -c CMD  Command to pass to 'sh -c'\n        -s SH   Shell to use instead of default shell\n""]"
261,2537,2517,CC BY-SA 3.0,2017-11-12T14:04:55.253,"<p><a href=""https://github.com/kubernetes/kubernetes/blob/master/cluster/centos/master/scripts/apiserver.sh"" rel=""nofollow noreferrer"">https://github.com/kubernetes/kubernetes/blob/master/cluster/centos/master/scripts/apiserver.sh</a></p>

<blockquote>
<pre><code># Insecure kube configuration parameters go under here when node['kubernetes']['secure']['enabled'] == 'false'
&lt;% if node['kubernetes']['secure']['enabled'] == 'false' -%&gt;
KUBE_API_ADDRESS=""--insecure-bind-address=0.0.0.0""
...

# Secure kube configuration parameters go under here when node['kubernetes']['secure']['enabled'] == 'true'
&lt;% if node['kubernetes']['secure']['enabled'] == 'true' -%&gt;
KUBE_API_ADDRESS=""--bind-address=0.0.0.0 --insecure-bind-address=127.0.0.1 ""
...
</code></pre>
</blockquote>

<p>It seems that the <code>KUBE_API_ADDRESS</code> will only listen to 0.0.0.0 if kubernetes has been secured.</p>
",210,2017-11-12T14:18:08.507,"['# Insecure kube configuration parameters go under here when node[\'kubernetes\'][\'secure\'][\'enabled\'] == \'false\'\n<% if node[\'kubernetes\'][\'secure\'][\'enabled\'] == \'false\' -%>\nKUBE_API_ADDRESS=""--insecure-bind-address=0.0.0.0""\n...\n\n# Secure kube configuration parameters go under here when node[\'kubernetes\'][\'secure\'][\'enabled\'] == \'true\'\n<% if node[\'kubernetes\'][\'secure\'][\'enabled\'] == \'true\' -%>\nKUBE_API_ADDRESS=""--bind-address=0.0.0.0 --insecure-bind-address=127.0.0.1 ""\n...\n']"
262,2538,2518,CC BY-SA 3.0,2017-11-12T14:25:16.453,"<p><a href=""https://kubernetes.io/docs/getting-started-guides/centos/centos_manual_config/"" rel=""nofollow noreferrer"">https://kubernetes.io/docs/getting-started-guides/centos/centos_manual_config/</a></p>

<blockquote>
<pre><code># Address range to use for services
KUBE_SERVICE_ADDRESSES=""--service-cluster-ip-range=10.254.0.0/16""
</code></pre>
</blockquote>
",210,2017-11-12T14:25:16.453,"['# Address range to use for services\nKUBE_SERVICE_ADDRESSES=""--service-cluster-ip-range=10.254.0.0/16""\n']"
263,2539,2519,CC BY-SA 3.0,2017-11-12T14:34:33.230,"<p>According to <a href=""https://github.com/kubernetes/kubernetes/issues/9040"" rel=""nofollow noreferrer"">this Q&amp;A</a> and <a href=""https://github.com/kubernetes/kubernetes/blob/96fecb2833c47b75267581cc4587a653f364268e/cluster/centos/master/scripts/apiserver.sh#L61"" rel=""nofollow noreferrer"">this code</a> the <code>--portal_net</code> was renamed to <code>--service-cluster-ip-range</code> since version 0.18.</p>

<blockquote>
<pre><code># --service-cluster-ip-range=&lt;nil&gt;: A CIDR notation IP range from which to assign service cluster IPs.
# This must not overlap with any IP ranges assigned to nodes for pods.
KUBE_SERVICE_ADDRESSES=""--service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE}""
</code></pre>
</blockquote>
",210,2017-11-12T14:34:33.230,"['# --service-cluster-ip-range=<nil>: A CIDR notation IP range from which to assign service cluster IPs.\n# This must not overlap with any IP ranges assigned to nodes for pods.\nKUBE_SERVICE_ADDRESSES=""--service-cluster-ip-range=${SERVICE_CLUSTER_IP_RANGE}""\n']"
264,2551,2550,CC BY-SA 3.0,2017-11-14T12:15:57.450,"<p>you create a Docker Swarm stack file:</p>

<pre><code>---
version: '3.1'

services:   
  ubuntu:
    image: ubuntu # or your custom Docker image
      deploy:
        replicas: 10000
</code></pre>

<p>Then, with <code>docker stack</code> you can run your 10000 Ubuntu's on one or - probably better in this case - a set of Swarm hosts. This could be bare metal or AWS. Enjoy!</p>

<p>For MAC address is very interesting question which I hope other colleagues here can answer. Geolocation should be no problem as this is AFAIK a system setting - virtual OS does not implement a physical GPS sensor.</p>

<p><a href=""https://docs.docker.com/engine/reference/run/#network-settings"" rel=""noreferrer"">Docs</a> give an example how to set a fixed MAC address on <code>docker run</code> - possibly this can be translated to the stack YML file as well.</p>

<pre><code>docker run --mac-address="".."" ...
</code></pre>
",707,2017-11-14T14:54:27.450,"[""---\nversion: '3.1'\n\nservices:   \n  ubuntu:\n    image: ubuntu # or your custom Docker image\n      deploy:\n        replicas: 10000\n"", 'docker run --mac-address="".."" ...\n']"
265,2563,2546,CC BY-SA 3.0,2017-11-16T04:00:00.843,"<p>The onboarding experience should be almost as simple as telling your new developer to just clone the repo and run <code>docker-compose up</code>. Personally I wouldn't bother worrying about IDE integration because people might prefer to use different IDEs.</p>

<p>Every project/application (if you have multiple) should be able to run separately and each project/application should have it's own codebase. That's a concept from <a href=""https://12factor.net/codebase"" rel=""noreferrer"">The Twelve-Factor App</a> methodology.</p>

<p>In the root of each project add a <code>Dockerfile</code> and a <code>docker-compose.yml</code> file. </p>

<blockquote>
  <p>NOTE: I created <a href=""https://codemason.io/docs/craft-kits"" rel=""noreferrer"">Craft Kits</a> which you can use to automatically generate these files for the framework/language you're using with one command (e.g. <code>mason craft nodejs</code>), you don't even need to know Docker.</p>
</blockquote>

<p>The <code>Dockerfile</code> will build your application into an image, installing and dependencies your application needs to run. This image is the image that runs your app.</p>

<pre><code>FROM node:8.8-alpine

# Set our workdir
WORKDIR /app

# Install and cache app dependencies
COPY package.json /app
RUN npm install 

# Add project files
COPY . /app

# start app
CMD [ ""npm"", ""start"" ]
</code></pre>

<p>The <code>docker-compose.yml</code> file will spin up your environment. It will define all the services Docker should start for your application</p>

<pre><code>version: '2'
services:
  web:
    build: .
    volumes:
      - ./:/app
    ports:
      - ""3000:3000""

  mongodb:
    image: mongodb
    volumes:
      - ./storage/data/mongodb:/data/db
    ports:
      - ""27017:27017""
</code></pre>

<p>When you onboard a new developer, you can just tell them to <code>git clone</code> your repo and to fire up their development environment by running:  </p>

<pre><code>docker-compose up -d 
</code></pre>

<p>The advantage of this approach when you are developing locally, running <code>docker-compose up</code> will mount your code as a volume. </p>

<p>Then when you want to deploy, when you build your <code>Dockerfile</code> it will copy your code into your image so everything is packaged up nicely and easily moved around.</p>

<p>We use the same approach for apps on <a href=""https://codemason.io"" rel=""noreferrer"">Codemason</a>, my service for building, managing and scaling container-based applications. When you push new code, we automatically build an image from your Dockerfile. Since that image contains everything your app needs to run, it can be easily launched on any server and scaled up/down across multiple servers. </p>
",5198,2017-11-16T04:00:00.843,"['FROM node:8.8-alpine\n\n# Set our workdir\nWORKDIR /app\n\n# Install and cache app dependencies\nCOPY package.json /app\nRUN npm install \n\n# Add project files\nCOPY . /app\n\n# start app\nCMD [ ""npm"", ""start"" ]\n', 'version: \'2\'\nservices:\n  web:\n    build: .\n    volumes:\n      - ./:/app\n    ports:\n      - ""3000:3000""\n\n  mongodb:\n    image: mongodb\n    volumes:\n      - ./storage/data/mongodb:/data/db\n    ports:\n      - ""27017:27017""\n', 'docker-compose up -d \n']"
266,2570,2557,CC BY-SA 3.0,2017-11-16T15:35:26.603,"<p>This has worked - the following query has to return content-type application/xml:</p>

<pre><code> /solr/COLLECTION/select?q=*:*&amp;rows=0
</code></pre>
",707,2017-11-16T15:35:26.603,[' /solr/COLLECTION/select?q=*:*&rows=0\n']
267,2608,2520,CC BY-SA 3.0,2017-11-19T19:08:36.193,"<p>I would check that all nodes are active and ready with command</p>

<pre><code>docker node ls
</code></pre>

<p>With </p>

<pre><code>docker swarm leave
</code></pre>

<p>and</p>

<pre><code>docker swarm join \
--token &lt;SWMTKN token&gt; \
&lt;manager private IP&gt;
</code></pre>

<p>you may rejoin malfunctioning node. </p>
",2805,2017-11-19T19:08:36.193,"['docker node ls\n', 'docker swarm leave\n', 'docker swarm join \\\n--token <SWMTKN token> \\\n<manager private IP>\n']"
268,2614,2569,CC BY-SA 4.0,2017-11-21T18:08:44.130,"<p>You could look at tools such as <a href=""https://www.getpostman.com/"" rel=""nofollow noreferrer"">Postman</a> which focuses on testing REST APIs with JavaScript - it has some nice features but you lose the use of Python.</p>

<p>Instead, I'd suggest looking at REST-related plugins for <a href=""https://docs.pytest.org/en/latest/"" rel=""nofollow noreferrer"">pytest</a>, a Python test framework that simplifies your test code, while still running tests written using <code>unittest</code>. </p>

<ul>
<li>For example, writing <a href=""http://pythontesting.net/framework/pytest/pytest-fixtures-nuts-bolts/#real"" rel=""nofollow noreferrer"">parameterised tests</a> avoids boring and error-prone duplicate test code.</li>
</ul>

<p>Pytest has a huge set of plugins that simplify various tasks, including:</p>

<ul>
<li><p><a href=""https://taverntesting.github.io/"" rel=""nofollow noreferrer"">Tavern</a>, which specialises in testing REST APIs and seems highly relevant here - sort of ""Postman for Python unit tests"". </p></li>
<li><p><a href=""https://pypi.python.org/pypi/pytest-curl-report"" rel=""nofollow noreferrer"">pytest-curl-report</a> - when  testing with the <code>requests</code> library, will print a <code>curl</code> command you can use to reproduce the error from shell. </p></li>
<li><p><a href=""https://testinfra.readthedocs.io/en/latest/"" rel=""nofollow noreferrer"">Testinfra</a> - focuses on server testing (e.g. state of OS packages, files, processes, etc, usually tested on remote servers) - strongly recommended if you also need this type  e.g. to test Ansible code.</p>

<ul>
<li>For those who use Puppet or Chef, Testinfra is similar to Beaker (with RSpec), ServerSpec or InSpec.</li>
</ul></li>
</ul>

<p>If you don't like Tavern, you can of course use <code>pycurl</code> with <code>pytest</code>, which makes it easier to diagnose exactly what failed. This example from the <a href=""https://pypi.python.org/pypi/pytest-curl-report"" rel=""nofollow noreferrer"">pytest-curl-report site</a> uses only generic pytest features:</p>

<pre><code>$ py.test test.py
============================= test session starts ==============================
platform darwin -- Python 2.7.9 -- py-1.4.27 -- pytest-2.6.4
plugins: curl-report, httpbin, cache, capturelog, cov, flakes, pep8
collected 1 items

test.py F

=================================== FAILURES ===================================
______________________________ test_requests_get _______________________________

    def test_requests_get():
        r = requests.get('http://httpbin.org/get')
&gt;       assert False
E       assert False

test.py:7: AssertionError
</code></pre>

<p>Pytest lets you write all tests with a plain <code>assert</code>, and optionally include a helpful message as part of the output.  For example, one of your tests could be written:</p>

<pre><code>def test_2():
    assert pycurl.response(""some_url"").matches (""xxx""), ""xxx not found in response""
</code></pre>
",519,2018-12-04T13:21:25.477,"[""$ py.test test.py\n============================= test session starts ==============================\nplatform darwin -- Python 2.7.9 -- py-1.4.27 -- pytest-2.6.4\nplugins: curl-report, httpbin, cache, capturelog, cov, flakes, pep8\ncollected 1 items\n\ntest.py F\n\n=================================== FAILURES ===================================\n______________________________ test_requests_get _______________________________\n\n    def test_requests_get():\n        r = requests.get('http://httpbin.org/get')\n>       assert False\nE       assert False\n\ntest.py:7: AssertionError\n"", 'def test_2():\n    assert pycurl.response(""some_url"").matches (""xxx""), ""xxx not found in response""\n']"
269,2639,1049,CC BY-SA 3.0,2017-11-23T23:47:46.347,"<p>One could <a href=""https://developer.atlassian.com/bitbucket/server/docs/latest/how-tos/updating-build-status-for-commits.html"" rel=""nofollow noreferrer"">update the build status in bitbucket</a> as follows:</p>

<blockquote>
  <p>Adding a build result to a commit</p>
  
  <p>To associate a build result with a particular commit, you need to POST
  a JSON object to the build status REST resource at:</p>
  
  <p><code>https://&lt;bitbucket-base-url&gt;/rest/build-status/1.0/commits/&lt;commit-hash&gt;</code></p>
  
  <p>The format of the JSON object that should be used as the request body
  is:</p>

<pre><code>{
    ""state"": ""&lt;INPROGRESS|SUCCESSFUL|FAILED&gt;"",
    ""key"": ""&lt;build-key&gt;"",
    ""name"": ""&lt;build-name&gt;"",
    ""url"": ""&lt;build-url&gt;"",
    ""description"": ""&lt;build-description&gt;""
}
</code></pre>
</blockquote>

<p>One could run such a snippet by codefresh at the end of the build using a script to notify bitbucket regarding the build status of a commit.</p>

<blockquote>
  <p>One green build</p>
  
  <p>The following curl command will add a build to the commit
  9e72f04322c4a1f240e0b3158c67c3c19cdd16e7:</p>

<pre><code>curl -u username:password -H ""Content-Type: application/json"" -X POST
http://localhost:7990/bitbucket/rest/build-status/1.0/commits/9e72f04322c4a1f240e0b3158c67c3c19cdd16e7
-d @build0.json
</code></pre>
  
  <p>Where build0.json contains:</p>

<pre><code>{
    ""state"": ""SUCCESSFUL"",
    ""key"": ""REPO-MASTER"",
    ""name"": ""REPO-MASTER-42"",
    ""url"": ""https://bamboo.example.com/browse/REPO-MASTER-42"",
    ""description"": ""Changes by John Doe""
}
</code></pre>
</blockquote>
",210,2017-11-23T23:52:52.817,"['{\n    ""state"": ""<INPROGRESS|SUCCESSFUL|FAILED>"",\n    ""key"": ""<build-key>"",\n    ""name"": ""<build-name>"",\n    ""url"": ""<build-url>"",\n    ""description"": ""<build-description>""\n}\n', 'curl -u username:password -H ""Content-Type: application/json"" -X POST\nhttp://localhost:7990/bitbucket/rest/build-status/1.0/commits/9e72f04322c4a1f240e0b3158c67c3c19cdd16e7\n-d @build0.json\n', '{\n    ""state"": ""SUCCESSFUL"",\n    ""key"": ""REPO-MASTER"",\n    ""name"": ""REPO-MASTER-42"",\n    ""url"": ""https://bamboo.example.com/browse/REPO-MASTER-42"",\n    ""description"": ""Changes by John Doe""\n}\n']"
270,2642,2641,CC BY-SA 3.0,2017-11-24T09:35:38.490,"<p>You're missing the <code>--non-interactive</code> tag to your registration command.</p>

<p>Full command should be:</p>

<pre><code>gitlab-runner register --non-interactive --locked false --run-untagged true --tag-list java --name foo --registration-token %token% --url https://myurl --executor shell
</code></pre>

<p>Relevant documentation for <a href=""https://gitlab.com/gitlab-org/gitlab-runner/blob/master/docs/commands/README.md#non-interactive-registration"" rel=""nofollow noreferrer"">non-interactive registration</a>.</p>
",4289,2017-11-24T09:35:38.490,['gitlab-runner register --non-interactive --locked false --run-untagged true --tag-list java --name foo --registration-token %token% --url https://myurl --executor shell\n']
271,2664,1476,CC BY-SA 3.0,2017-11-26T11:29:58.667,"<p>As @Tensibai already indicated in one of the comments, some packages are missing:</p>

<pre><code>Use 'zypper addrepo' or 'zypper modifyrepo' commands to add or enable repositories.
</code></pre>

<p>Either use <code>zypper addrepo</code> or <code>zypper modifyrepo</code> in your dockerfile to solve the issue.</p>
",210,2017-11-26T11:29:58.667,"[""Use 'zypper addrepo' or 'zypper modifyrepo' commands to add or enable repositories.\n""]"
272,2672,1734,CC BY-SA 3.0,2017-11-26T12:17:51.843,"<p>According to <a href=""https://github.com/apache/incubator-openwhisk"" rel=""nofollow noreferrer"">this GitHub readme</a> </p>

<blockquote>
  <p>OpenWhisk is a serverless event-based programming service.</p>
</blockquote>

<p>In order to get an idea how to setup this tool on a cluster one could run the following code that is defined in the readme:</p>

<blockquote>
<pre><code># Clone openwhisk
git clone --depth=1 https://github.com/apache/incubator-openwhisk.git openwhisk

# Change directory to tools/vagrant
cd openwhisk/tools/vagrant

# Run script to create vm and run hello action
./hello
</code></pre>
</blockquote>
",210,2017-11-26T12:17:51.843,['# Clone openwhisk\ngit clone --depth=1 https://github.com/apache/incubator-openwhisk.git openwhisk\n\n# Change directory to tools/vagrant\ncd openwhisk/tools/vagrant\n\n# Run script to create vm and run hello action\n./hello\n']
273,2700,2643,CC BY-SA 3.0,2017-11-26T19:30:22.453,"<p>I ran into the same issue and found this docker-compose file that is able to start postgres and sonarqube.</p>

<p><a href=""https://github.com/SonarSource/docker-sonarqube/blob/master/recipes.md"" rel=""nofollow noreferrer"">https://github.com/SonarSource/docker-sonarqube/blob/master/recipes.md</a></p>

<blockquote>
<pre><code>version: ""2""

services:
  sonarqube:
    image: sonarqube
    ports:
      - ""9000:9000""
    networks:
      - sonarnet
    environment:
      - SONARQUBE_JDBC_URL=jdbc:postgresql://db:5432/sonar
    volumes:
      - sonarqube_conf:/opt/sonarqube/conf
      - sonarqube_data:/opt/sonarqube/data
      - sonarqube_extensions:/opt/sonarqube/extensions
      - sonarqube_bundled-plugins:/opt/sonarqube/lib/bundled-plugins

  db:
    image: postgres
    networks:
      - sonarnet
    environment:
      - POSTGRES_USER=sonar
      - POSTGRES_PASSWORD=sonar
    volumes:
      - postgresql:/var/lib/postgresql
      # This needs explicit mapping due to https://github.com/docker-library/postgres/blob/4e48e3228a30763913ece952c611e5e9b95c8759/Dockerfile.template#L52
      - postgresql_data:/var/lib/postgresql/data

networks:
  sonarnet:
    driver: bridge

volumes:
  sonarqube_conf:
  sonarqube_data:
  sonarqube_extensions:
  sonarqube_bundled-plugins:
  postgresql:
  postgresql_data:
</code></pre>
</blockquote>
",210,2017-11-26T19:30:22.453,"['version: ""2""\n\nservices:\n  sonarqube:\n    image: sonarqube\n    ports:\n      - ""9000:9000""\n    networks:\n      - sonarnet\n    environment:\n      - SONARQUBE_JDBC_URL=jdbc:postgresql://db:5432/sonar\n    volumes:\n      - sonarqube_conf:/opt/sonarqube/conf\n      - sonarqube_data:/opt/sonarqube/data\n      - sonarqube_extensions:/opt/sonarqube/extensions\n      - sonarqube_bundled-plugins:/opt/sonarqube/lib/bundled-plugins\n\n  db:\n    image: postgres\n    networks:\n      - sonarnet\n    environment:\n      - POSTGRES_USER=sonar\n      - POSTGRES_PASSWORD=sonar\n    volumes:\n      - postgresql:/var/lib/postgresql\n      # This needs explicit mapping due to https://github.com/docker-library/postgres/blob/4e48e3228a30763913ece952c611e5e9b95c8759/Dockerfile.template#L52\n      - postgresql_data:/var/lib/postgresql/data\n\nnetworks:\n  sonarnet:\n    driver: bridge\n\nvolumes:\n  sonarqube_conf:\n  sonarqube_data:\n  sonarqube_extensions:\n  sonarqube_bundled-plugins:\n  postgresql:\n  postgresql_data:\n']"
274,2706,2312,CC BY-SA 3.0,2017-11-27T02:26:41.640,"<p>Your nginx code is incorrect, for example, because you're effectively losing the extra functionality afforded by <a href=""http://nginx.org/r/proxy_redirect"" rel=""nofollow noreferrer"">http://nginx.org/r/proxy_redirect</a> default value of <code>default</code>.</p>

<p>As per the documentation at <a href=""http://nginx.org/r/proxy_pass"" rel=""nofollow noreferrer"">http://nginx.org/r/proxy_pass</a>, the correct way would be to map location on the front-end and back-end directly within the <code>proxy_pass</code>, especially if you don't need to be using any variables:</p>

<pre><code>location / {
    proxy_pass http://127.0.0.1:8080/ipns/QmdpoFuwY/;
}
</code></pre>

<hr>

<p>Otherwise, back to your question, there is absolutely no reason to have <code>/foo</code> and <code>/foo/</code> point to the same resource.</p>

<p>In fact, it would be perfectly legal for one to be internally expanded to <code>/foo.html</code>, whereas for the other to <code>/foo/index.html</code>, so, the fact that different results are returned is entirely normal, and doesn't need to be fixed.</p>
",5388,2017-11-27T02:26:41.640,['location / {\n    proxy_pass http://127.0.0.1:8080/ipns/QmdpoFuwY/;\n}\n']
275,2725,2711,CC BY-SA 3.0,2017-11-28T06:50:38.127,"<p>I tried storing the slave job part status in a file and stashing it on node and then unstashing it back on master. It works but I am looking for a cleaner way. Following is the current approach i am using:</p>

<pre><code>def branches = [:]
def allNodes = Jenkins.getInstance().getNodes()
for (int i =0; i &lt; allNodes.size(); i++) {
String nodeName = allNodes[i].name.toString()
branches[nodeName] = {
    node(nodeName) { 
    .
    .
    String outputFile = nodeName + ""-output""
    writeFile file: outputFile, text: result.toString()
    stash includes: ""*output"", name: outputFile
    }
}
parallel branches

for (int i = 0; i &lt; allNodes.size(); i++) 
{
    String filename = allNodes[i].name.toString() + ""-output""
    unstash filename
    def value = readFile filename

    // Mark node offline based on the variable value
}
</code></pre>
",5393,2017-11-28T06:50:38.127,"['def branches = [:]\ndef allNodes = Jenkins.getInstance().getNodes()\nfor (int i =0; i < allNodes.size(); i++) {\nString nodeName = allNodes[i].name.toString()\nbranches[nodeName] = {\n    node(nodeName) { \n    .\n    .\n    String outputFile = nodeName + ""-output""\n    writeFile file: outputFile, text: result.toString()\n    stash includes: ""*output"", name: outputFile\n    }\n}\nparallel branches\n\nfor (int i = 0; i < allNodes.size(); i++) \n{\n    String filename = allNodes[i].name.toString() + ""-output""\n    unstash filename\n    def value = readFile filename\n\n    // Mark node offline based on the variable value\n}\n']"
276,2748,1635,CC BY-SA 4.0,2017-11-30T22:42:38.740,"<p>According to <a href=""https://developers.redhat.com/blog/2014/05/05/running-systemd-within-docker-container/"" rel=""nofollow noreferrer"">this blog</a>, it is possible to run systemd inside a docker container by building the following dockerfile:</p>

<blockquote>
<pre><code>FROM fedora:rawhide
MAINTAINER ""Dan Walsh"" &lt;dwalsh@redhat.com&gt;
ENV container docker
RUN yum -y update; yum clean all
RUN yum -y install systemd; yum clean all;
(cd /lib/systemd/system/sysinit.target.wants/; for i in *; do [ $i == systemd-tmpfiles-setup.service ] || rm -f $i; done);
rm -f /lib/systemd/system/multi-user.target.wants/*;
rm -f /etc/systemd/system/*.wants/*;
rm -f /lib/systemd/system/local-fs.target.wants/*;
rm -f /lib/systemd/system/sockets.target.wants/*udev*;
rm -f /lib/systemd/system/sockets.target.wants/*initctl*;
rm -f /lib/systemd/system/basic.target.wants/*;
rm -f /lib/systemd/system/anaconda.target.wants/*;
VOLUME [ ""/sys/fs/cgroup"" ]
CMD [""/usr/sbin/init""]
</code></pre>
</blockquote>

<p>using this command:</p>

<blockquote>
<pre><code>docker build -t httpd_rawhide .
</code></pre>
</blockquote>

<p>The author indicates that the built docker image could be used as a base image</p>

<blockquote>
<pre><code>FROM systemd_rawhide
RUN yum -y install httpd; yum clean all; systemctl enable httpd.service
EXPOSE 80
CMD [""/usr/sbin/init""]
</code></pre>
</blockquote>

<p>and if the container is run</p>

<blockquote>
<pre><code>docker run –privileged -ti -v /sys/fs/cgroup:/sys/fs/cgroup:ro -p 80:80 httpd_rawhide
</code></pre>
</blockquote>

<p>systemd will run inside the docker container. It is also possible to run multiple services using systemd. According to the creator of this blog it would be possible to run both mariadb and http inside the same container.</p>

<p>Based on this blog and other articles I read my conclusion is that it is technically possible to run systemd inside a docker container, but I would recommend to avoid running systemd inside a container. </p>

<p>First of all, if systemd is able to run inside a container then this means that it is possible to run multiple services like the author did. From a docker perspective this is not recommended as docker is meant to scale horizontally, i.e. if the load increases of http then addtional docker images should be started. </p>

<p>Second, if such a systemd container will be deployed on an orchestration platform like docker swarm. Will that work? I have some doubts whether that will work. </p>

<p>Third, Running systemd by mounting the cgroup in a privileged container does not look very secure. </p>

<p>In conclusion, although you indicated that the script requires systemd, either rewrite the code or use something else. Running systemd inside a docker container should be avoided in my opinion.</p>
",210,2019-03-29T19:51:37.623,"['FROM fedora:rawhide\nMAINTAINER ""Dan Walsh"" <dwalsh@redhat.com>\nENV container docker\nRUN yum -y update; yum clean all\nRUN yum -y install systemd; yum clean all;\n(cd /lib/systemd/system/sysinit.target.wants/; for i in *; do [ $i == systemd-tmpfiles-setup.service ] || rm -f $i; done);\nrm -f /lib/systemd/system/multi-user.target.wants/*;\nrm -f /etc/systemd/system/*.wants/*;\nrm -f /lib/systemd/system/local-fs.target.wants/*;\nrm -f /lib/systemd/system/sockets.target.wants/*udev*;\nrm -f /lib/systemd/system/sockets.target.wants/*initctl*;\nrm -f /lib/systemd/system/basic.target.wants/*;\nrm -f /lib/systemd/system/anaconda.target.wants/*;\nVOLUME [ ""/sys/fs/cgroup"" ]\nCMD [""/usr/sbin/init""]\n', 'docker build -t httpd_rawhide .\n', 'FROM systemd_rawhide\nRUN yum -y install httpd; yum clean all; systemctl enable httpd.service\nEXPOSE 80\nCMD [""/usr/sbin/init""]\n', 'docker run –privileged -ti -v /sys/fs/cgroup:/sys/fs/cgroup:ro -p 80:80 httpd_rawhide\n']"
277,2758,2633,CC BY-SA 3.0,2017-12-01T11:15:45.780,"<p>You'd better add this CA to a bundle of valid CA and keep using it for all cases with </p>

<pre><code>git config --add --global http.sslcainfo=/path/to/cabundle
git config --add --global http.sslbackend=openssl
</code></pre>

<p>Using <a href=""https://curl.haxx.se/docs/caextract.html"" rel=""nofollow noreferrer"">https://curl.haxx.se/docs/caextract.html</a> as starting CA bundle sounds a good idea in my opinion.</p>
",13,2017-12-01T11:15:45.780,['git config --add --global http.sslcainfo=/path/to/cabundle\ngit config --add --global http.sslbackend=openssl\n']
278,2760,1525,CC BY-SA 4.0,2017-12-01T12:33:35.090,"<p>To expand on <a href=""https://devops.stackexchange.com/a/2249"">the answer above</a> - try using:</p>

<pre><code>branch: ""origin/pr/${pullRequestId}/from""
</code></pre>

<p>Because in groovy, string interpolation is not done for simple strings - i.e. strings within single quotes. See <a href=""http://groovy-lang.org/syntax.html#_string_interpolation"" rel=""nofollow noreferrer"">http://groovy-lang.org/syntax.html#_string_interpolation</a> for details on that.</p>
",5493,2019-05-22T20:25:14.047,"['branch: ""origin/pr/${pullRequestId}/from""\n']"
279,2763,2656,CC BY-SA 3.0,2017-12-02T17:29:51.277,"<p>While it's true that the version of python reported there doesn't have SNI support, I thought that RedHat backported it. But anyways, if not, you can do that yourself:</p>

<pre><code>yum -y install gcc python-devel libffi-devel openssl-devel
pip install pyopenssl ndg-httpsclient pyasn1
</code></pre>

<p>(This works for <code>requests</code> at least, I'm not sure about Ansible.)</p>

<p>On a broader note:</p>

<blockquote>
  <p>But CentOS 7 ships with python 2.7.5. You can't upgrade it because get_url has the same issue with SSL and so you would have to download the python source with validate_certs=no.</p>
</blockquote>

<p>That's only the case if the server you're downloading Python from relies on SNI. I imagine most of their mirrors do not.</p>

<p>But really, you shouldn't be compiling Python on every individual server. You should do it once, either on a machine that you freeze into an image that you launch further machines off of, or you package it as an rpm and the machines just download that and install it. This allows you to control the download process.</p>

<p>Even simpler: download the package on your desktop (via verified https). Copy it to your file storage. Download from there onto your servers. There's no need to download directly from python.org every time, and it's more reliable to have a local copy anyways.</p>
",960,2017-12-02T17:29:51.277,['yum -y install gcc python-devel libffi-devel openssl-devel\npip install pyopenssl ndg-httpsclient pyasn1\n']
280,2766,2731,CC BY-SA 3.0,2017-12-03T13:26:18.993,"<p>To me it is not completely clear what you are trying to achieve and why the attempts are not a solution for the problem. If I would need to solve this issue I would like @Tensibai and other Q&amp;As indicated, do a docker pull first on a system with internet connectivity, save the docker image, copy it to the machine without internet connectivity, load the image and run it.</p>

<p><strong>Demonstration</strong></p>

<p>There are no images on system A:</p>

<pre><code>userA@systemA ~ $ docker images
REPOSITORY        TAG               IMAGE ID          CREATED             SIZE
userA@systemA ~ $
</code></pre>

<p>Pull an image from dockerhub:</p>

<pre><code>userA@systemA ~ $
docker pull nginx
Using default tag: latest
latest: Pulling from library/nginx
bc95e04b23c0: Pull complete 
f3186e650f4e: Pull complete 
9ac7d6621708: Pull complete 
Digest: sha256:b81f317384d7388708a498555c28a7cce778a8f291d90021208b3eba3fe74887
Status: Downloaded newer image for nginx:latest
userA@systemA ~ $ docker images
REPOSITORY        TAG               IMAGE ID            CREATED             SIZE
nginx             latest            9e7424e5dbae        10 days ago         108MB
</code></pre>

<p>Save docker image:</p>

<pre><code>userA@systemA ~ $ docker save nginx -o nginx.tar
</code></pre>

<p>Copy docker image to systemB and load it.</p>

<pre><code>userB@systemB ~ $ docker load -i nginx.tar
cec7521cdf36: Loading layer  58.44MB/58.44MB
350d50e58b6c: Loading layer  53.76MB/53.76MB
63c39cd4a775: Loading layer  3.584kB/3.584kB
Loaded image: nginx:latest
userB@systemB ~ $ docker images
REPOSITORY        TAG               IMAGE ID            CREATED             SIZE
nginx             latest            9e7424e5dbae        10 days ago         108MB
</code></pre>
",210,2017-12-03T13:35:59.387,"['userA@systemA ~ $ docker images\nREPOSITORY        TAG               IMAGE ID          CREATED             SIZE\nuserA@systemA ~ $\n', 'userA@systemA ~ $\ndocker pull nginx\nUsing default tag: latest\nlatest: Pulling from library/nginx\nbc95e04b23c0: Pull complete \nf3186e650f4e: Pull complete \n9ac7d6621708: Pull complete \nDigest: sha256:b81f317384d7388708a498555c28a7cce778a8f291d90021208b3eba3fe74887\nStatus: Downloaded newer image for nginx:latest\nuserA@systemA ~ $ docker images\nREPOSITORY        TAG               IMAGE ID            CREATED             SIZE\nnginx             latest            9e7424e5dbae        10 days ago         108MB\n', 'userA@systemA ~ $ docker save nginx -o nginx.tar\n', 'userB@systemB ~ $ docker load -i nginx.tar\ncec7521cdf36: Loading layer  58.44MB/58.44MB\n350d50e58b6c: Loading layer  53.76MB/53.76MB\n63c39cd4a775: Loading layer  3.584kB/3.584kB\nLoaded image: nginx:latest\nuserB@systemB ~ $ docker images\nREPOSITORY        TAG               IMAGE ID            CREATED             SIZE\nnginx             latest            9e7424e5dbae        10 days ago         108MB\n']"
281,2770,2412,CC BY-SA 3.0,2017-12-03T14:40:09.080,"<p><a href=""https://www.mongodb.com/blog/post/running-mongodb-as-a-microservice-with-docker-and-kubernetes"" rel=""nofollow noreferrer"">https://www.mongodb.com/blog/post/running-mongodb-as-a-microservice-with-docker-and-kubernetes</a></p>

<blockquote>
  <p>MongoDB database nodes are stateful. In the event that a container
  fails, and is rescheduled, it's undesirable for the data to be lost
  (it could be recovered from other nodes in the replica set, but that
  takes time). To solve this, features such as the Volume abstraction in
  Kubernetes can be used to map what would otherwise be an ephemeral
  MongoDB data directory in the container to a persistent location where
  the data survives container failure and rescheduling.</p>
</blockquote>

<p>Like @Tensibai indicated the issue is related to the replication. According to <a href=""http://blog.kubernetes.io/2017/01/running-mongodb-on-kubernetes-with-statefulsets.html"" rel=""nofollow noreferrer"">this blog</a> it could be solved as follows.</p>

<blockquote>
<pre><code> apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: mongo
spec:
  serviceName: ""mongo""
  replicas: 3
  template:
    metadata:
      labels:
        role: mongo
        environment: test
    spec:
      terminationGracePeriodSeconds: 10
      containers:
        - name: mongo
          image: mongo
          command:
            - mongod
            - ""--replSet""
            - rs0
            - ""--smallfiles""
            - ""--noprealloc""
          ports:
            - containerPort: 27017
          volumeMounts:
            - name: mongo-persistent-storage
              mountPath: /data/db
        - name: mongo-sidecar
          image: cvallance/mongo-k8s-sidecar
          env:
            - name: MONGO_SIDECAR_POD_LABELS
              value: ""role=mongo,environment=test""
  volumeClaimTemplates:
  - metadata:
      name: mongo-persistent-storage
      annotations:
        volume.beta.kubernetes.io/storage-class: ""fast""
    spec:
      accessModes: [ ""ReadWriteOnce"" ]
      resources:
        requests:
          storage: 100Gi
</code></pre>
</blockquote>
",210,2017-12-03T14:40:09.080,"[' apiVersion: apps/v1beta1\nkind: StatefulSet\nmetadata:\n  name: mongo\nspec:\n  serviceName: ""mongo""\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        role: mongo\n        environment: test\n    spec:\n      terminationGracePeriodSeconds: 10\n      containers:\n        - name: mongo\n          image: mongo\n          command:\n            - mongod\n            - ""--replSet""\n            - rs0\n            - ""--smallfiles""\n            - ""--noprealloc""\n          ports:\n            - containerPort: 27017\n          volumeMounts:\n            - name: mongo-persistent-storage\n              mountPath: /data/db\n        - name: mongo-sidecar\n          image: cvallance/mongo-k8s-sidecar\n          env:\n            - name: MONGO_SIDECAR_POD_LABELS\n              value: ""role=mongo,environment=test""\n  volumeClaimTemplates:\n  - metadata:\n      name: mongo-persistent-storage\n      annotations:\n        volume.beta.kubernetes.io/storage-class: ""fast""\n    spec:\n      accessModes: [ ""ReadWriteOnce"" ]\n      resources:\n        requests:\n          storage: 100Gi\n']"
282,2772,2731,CC BY-SA 4.0,2017-12-03T14:56:17.250,"<p>It turned out that the <a href=""https://mobyproject.org/"" rel=""nofollow noreferrer"">Moby Project</a> has a shell script on the <a href=""https://github.com/moby/moby/"" rel=""nofollow noreferrer"">Moby Github</a> which can download images from <a href=""https://hub.docker.com/"" rel=""nofollow noreferrer"">Docker Hub</a> in a format that can be imported into Docker:</p>
<ul>
<li><a href=""https://raw.githubusercontent.com/moby/moby/master/contrib/download-frozen-image-v2.sh"" rel=""nofollow noreferrer"">download-frozen-image-v2.sh</a></li>
</ul>
<p>The usage syntax for the script is given by the following:</p>
<pre class=""lang-bash prettyprint-override""><code>download-frozen-image-v2.sh target_dir image[:tag][@digest] ...
</code></pre>
<p>The image can then be imported with <code>tar</code> and <code>docker load</code>:</p>
<pre class=""lang-bash prettyprint-override""><code>tar -cC 'target_dir' . | docker load
</code></pre>
<p>To verify that the script works as expected, I downloaded an Ubuntu image from Docker Hub and loaded it into Docker:</p>
<pre class=""lang-bash prettyprint-override""><code>user@host:~$ bash download-frozen-image-v2.sh ubuntu ubuntu:latest
user@host:~$ tar -cC 'ubuntu' . | docker load
user@host:~$ docker run --rm -ti ubuntu bash
root@1dd5e62113b9:/#
</code></pre>
<p>In practice I would have to first copy the data from the internet client (which does <em>not</em> have Docker installed) to the target/destination machine (which <em>does</em> have Docker installed):</p>
<pre class=""lang-bash prettyprint-override""><code>user@nodocker:~$ bash download-frozen-image-v2.sh ubuntu ubuntu:latest
user@nodocker:~$ tar -C 'ubuntu' -cf 'ubuntu.tar' .
user@nodocker:~$ scp ubuntu.tar user@hasdocker:~
</code></pre>
<p>and then load and use the image on the target host:</p>
<pre class=""lang-bash prettyprint-override""><code>user@hasdocker:~ docker load ubuntu.tar
user@hasdocker:~ docker run --rm -ti ubuntu bash
root@1dd5e62113b9:/#
</code></pre>
",3070,2021-03-17T13:51:01.263,"['download-frozen-image-v2.sh target_dir image[:tag][@digest] ...\n', ""tar -cC 'target_dir' . | docker load\n"", ""user@host:~$ bash download-frozen-image-v2.sh ubuntu ubuntu:latest\nuser@host:~$ tar -cC 'ubuntu' . | docker load\nuser@host:~$ docker run --rm -ti ubuntu bash\nroot@1dd5e62113b9:/#\n"", ""user@nodocker:~$ bash download-frozen-image-v2.sh ubuntu ubuntu:latest\nuser@nodocker:~$ tar -C 'ubuntu' -cf 'ubuntu.tar' .\nuser@nodocker:~$ scp ubuntu.tar user@hasdocker:~\n"", 'user@hasdocker:~ docker load ubuntu.tar\nuser@hasdocker:~ docker run --rm -ti ubuntu bash\nroot@1dd5e62113b9:/#\n']"
283,2786,1635,CC BY-SA 3.0,2017-12-04T17:41:12.210,"<p>You didn't mention what distribution you're using inside your container (which would have implications w/r/t which version of systemd you're using), but the following will successfully boot a CentOS container running systemd:</p>

<pre><code>docker run -it --rm \
  -e container=docker \
  --tmpfs /run \
  --tmpfs /tmp \
  -v /sys/fs/cgroup:/sys/fs/cgroup:ro \
  --cap-add SYS_ADMIN \
  centos /sbin/init
</code></pre>

<p>This is with Docker 17.05.0-ce; older versions may require additional flags.  Using a stock <code>centos:7</code> image, your initial environment inside the container looks like this:</p>

<pre><code># systemctl status
    State: running
     Jobs: 0 queued
   Failed: 0 units
    Since: Mon 2017-12-04 17:47:15 UTC; 45s ago
[...]
</code></pre>

<p>And:</p>

<pre><code># ps -fe
UID        PID  PPID  C STIME TTY          TIME CMD
root         1     0  0 17:47 ?        00:00:00 /sbin/init
root        16     1  0 17:47 ?        00:00:00 /usr/lib/systemd/systemd-journald
dbus        26     1  0 17:47 ?        00:00:00 /bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation
root        28     1  0 17:47 ?        00:00:00 /usr/lib/systemd/systemd-logind
root        30     1  0 17:47 console  00:00:00 /sbin/agetty --noclear --keep-baud console 115200 38400 9600 vt220
root        32     0  0 17:47 ?        00:00:00 bash
root        58    32  0 17:48 ?        00:00:00 ps -fe
</code></pre>

<p>Note that I'm using <code>--rm</code> here not because it's necessary but because I'm terrible at cleaning things up after the fact.  It's not necessary to get the container to run.</p>

<blockquote>
  <p>but looks like most of them compromise the security of the container and the host</p>
</blockquote>

<p>Well, running systemd does require privileges beyond those granted to a typical Docker container (hence the <code>--cap-add</code>).  Whether this has security implications for your environment or not depends on what you're doing.</p>
",4011,2017-12-04T17:49:36.110,"['docker run -it --rm \\\n  -e container=docker \\\n  --tmpfs /run \\\n  --tmpfs /tmp \\\n  -v /sys/fs/cgroup:/sys/fs/cgroup:ro \\\n  --cap-add SYS_ADMIN \\\n  centos /sbin/init\n', '# systemctl status\n    State: running\n     Jobs: 0 queued\n   Failed: 0 units\n    Since: Mon 2017-12-04 17:47:15 UTC; 45s ago\n[...]\n', '# ps -fe\nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 17:47 ?        00:00:00 /sbin/init\nroot        16     1  0 17:47 ?        00:00:00 /usr/lib/systemd/systemd-journald\ndbus        26     1  0 17:47 ?        00:00:00 /bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation\nroot        28     1  0 17:47 ?        00:00:00 /usr/lib/systemd/systemd-logind\nroot        30     1  0 17:47 console  00:00:00 /sbin/agetty --noclear --keep-baud console 115200 38400 9600 vt220\nroot        32     0  0 17:47 ?        00:00:00 bash\nroot        58    32  0 17:48 ?        00:00:00 ps -fe\n']"
284,2792,2728,CC BY-SA 3.0,2017-12-05T10:51:18.180,"<p>I found out how to do it without pipeline. It only has to do with command line script:</p>

<pre><code>start """" C:\MyApp\MyApp.exe &gt;&gt; text.txt
</code></pre>

<p>This call is asynchronous (i.e., the command line won't wait for MyApp.exe to return). If you want it to wait, you can use the /w flag, like this:</p>

<pre><code>start /w """" C:\MyApp\MyApp.exe &gt;&gt; text.txt
</code></pre>
",5431,2017-12-05T12:58:48.480,"['start """" C:\\MyApp\\MyApp.exe >> text.txt\n', 'start /w """" C:\\MyApp\\MyApp.exe >> text.txt\n']"
285,2800,2794,CC BY-SA 3.0,2017-12-05T17:17:15.067,"<p>Assuming the following:</p>

<ul>
<li>YOUR_PC, has Redis client, SSH client, SSH access to SSH_SERVER</li>
<li>SSH_SERVER, has SSH server, redis access to REDIS_SERVER</li>
<li>REDIS_SERVER, has Redis server</li>
</ul>

<p>Set up the tunnel from YOUR_PC, port 1234, to REDIS_SERVER:REDIS_PORT, via SSH_SERVER</p>

<pre><code>ssh SSH_SERVER -L 1234:REDIS_SERVER:REDIS_PORT
</code></pre>

<p>On another terminal, on YOUR_PC, run the redis client (based on <a href=""https://stackoverflow.com/a/40678950"">https://stackoverflow.com/a/40678950</a>):</p>

<pre><code>redis-cli -h localhost -p 1234
</code></pre>
",5587,2017-12-05T20:53:30.437,"['ssh SSH_SERVER -L 1234:REDIS_SERVER:REDIS_PORT\n', 'redis-cli -h localhost -p 1234\n']"
286,2818,795,CC BY-SA 3.0,2017-12-07T12:35:37.057,"<p>I managed to use docker-compose to push images to a remote host by using the following image.</p>

<p><a href=""https://hub.docker.com/r/tmaier/docker-compose/"" rel=""nofollow noreferrer"" title=""tmaier/docker-compose"">tmaier/docker-compose:latest</a></p>

<p>This is the basic <a href=""https://hub.docker.com/r/_/docker/"" rel=""nofollow noreferrer"" title=""docker image"">docker image</a> with docker-compose installed.</p>

<p>My <code>bitbucket-pipelines.yml</code> looks like this:</p>

<pre><code>- step:
    image: tmaier/docker-compose:latest
    script:
        - (umask  077 ; echo $DOCKER_PRIVATE_KEY | base64 -d &gt; ./keys/key.pem)
        - export DOCKER_CERT_PATH=./keys/
        - export DOCKER_TLS_VERIFY=""1""
        - export DOCKER_HOST=tcp://&lt;DOCKER_HOST_IP&gt;:2376
        - docker login --username $DOCKER_HUB_USERNAME --password $DOCKER_HUB_PASSWORD
        - docker-compose up -d &lt;service&gt;
</code></pre>

<p>I have checked-in in my repo the <code>ca.pem</code> and <code>cert.pem</code> needed by docker-compose in the <code>keys</code> directory. The private key is saved base64encoded, as a secure variable in Bitbucket pipelines environment variables, so I just decode it and paste it to <code>keys/key.pem</code> in the pipeline as the first step.</p>

<p>Keep in mind that i used <code>docker login</code> after setting the enviroment variables for the remote host.</p>
",5619,2017-12-07T12:35:37.057,"['- step:\n    image: tmaier/docker-compose:latest\n    script:\n        - (umask  077 ; echo $DOCKER_PRIVATE_KEY | base64 -d > ./keys/key.pem)\n        - export DOCKER_CERT_PATH=./keys/\n        - export DOCKER_TLS_VERIFY=""1""\n        - export DOCKER_HOST=tcp://<DOCKER_HOST_IP>:2376\n        - docker login --username $DOCKER_HUB_USERNAME --password $DOCKER_HUB_PASSWORD\n        - docker-compose up -d <service>\n']"
287,2822,2749,CC BY-SA 3.0,2017-12-07T20:22:25.767,"<p>You can use a remote backend as a data source. That is working well for us thus far but this project is not very mature and we will likely refactor a time or ten.</p>

<pre><code>data ""terraform_remote_state"" ""network"" {
  backend = ""s3""
  config {
    // some variables related to config would likely go here
  }
}
</code></pre>

<p>then for the teams not managing the network to consume that data you could create an instance like (special attention to the <code>subnet_id</code> here):</p>

<pre><code>resource ""aws_instance"" ""oracle_ec2"" {
  ami           = ""${lookup(var.ami, var.region)}""
  instance_type = ""${var.instance_type}""
  key_name      = ""${var.key_name}""
  subnet_id     = ""${data.terraform_remote_state.network.subnet_id}""
}
</code></pre>

<p>The network team should be able to manage the networking infrastructure and you should be able to consume those values based on current state. </p>

<p><a href=""https://www.terraform.io/docs/providers/terraform/d/remote_state.html"" rel=""noreferrer"">Terraform Remote State Data Source</a></p>

<blockquote>
  <p>2) If new instances launch as t2.large(Instance type passed as variable) while old ones run on t2.micro</p>
</blockquote>

<p>If you change the instance type from <code>t2.micro</code> to <code>t2.large</code> then yes the <code>t2.micro</code> instances will be destroyed and replaced with the <code>t2.large</code>. The name of the game is immutability outside of meta data changes like altering tags. Look into lifecycle hooks to alleviate some of this pain</p>

<pre><code>lifecycle {
  create_before_destroy = true
}
</code></pre>

<blockquote>
  <p>will it recreate old instances too if I just increase the count</p>
</blockquote>

<p>No, current instances would not be destroyed. Terraform will check the state to see how many instances you currently have. If more instances are necessary, terraform will know how many instances to create and create the instances necessary</p>

<blockquote>
  <p>Also, is there a way to automate this process i.e. append something like a template for new EC2 instance to existing .tf file.</p>
</blockquote>

<p>Not sure what exactly you mean by this one. What I will say is that having the data coupled to the instance itself makes instance immutability and using terraform more difficult. A (untested and unproven) thought and potential solution in my head is to:</p>

<pre><code>//create an ebs volume
resource ""aws_ebs_volume"" ""oracle-data"" {
  ...
}

//attach that volume to the instance
resource ""aws_volume_attachment"" ""oracle-data-attachment"" {
  ...
}
</code></pre>

<p>with some bash involved for an init script that creates and mounts the new volume to be used in conjunction with the <code>aws_volume_attachment</code> resource. That could potentially create a new instance preserving the EBS volume then reattaching it to the new instance.</p>
",5628,2017-12-07T20:22:25.767,"['data ""terraform_remote_state"" ""network"" {\n  backend = ""s3""\n  config {\n    // some variables related to config would likely go here\n  }\n}\n', 'resource ""aws_instance"" ""oracle_ec2"" {\n  ami           = ""${lookup(var.ami, var.region)}""\n  instance_type = ""${var.instance_type}""\n  key_name      = ""${var.key_name}""\n  subnet_id     = ""${data.terraform_remote_state.network.subnet_id}""\n}\n', 'lifecycle {\n  create_before_destroy = true\n}\n', '//create an ebs volume\nresource ""aws_ebs_volume"" ""oracle-data"" {\n  ...\n}\n\n//attach that volume to the instance\nresource ""aws_volume_attachment"" ""oracle-data-attachment"" {\n  ...\n}\n']"
288,2847,2791,CC BY-SA 3.0,2017-12-10T10:35:04.097,"<p>The tomcat is reachable on port 8080 instead of 8888 when the following is defined in the question</p>

<blockquote>
<pre><code>docker run -it --rm -p 8888:8080 tomcat:8.0
</code></pre>
</blockquote>

<p><a href=""https://docs.docker.com/engine/reference/commandline/run/"" rel=""nofollow noreferrer"">Documentation</a></p>

<blockquote>
  <p>Publish or expose port (-p, –expose)</p>

<pre><code>$ docker run -p 127.0.0.1:80:8080 ubuntu bash
</code></pre>
  
  <p>This binds port 8080 of the container to port 80 on 127.0.0.1 of the
  host machine. The Docker User Guide explains in detail how to
  manipulate ports in Docker.</p>

<pre><code>$ docker run --expose 80 ubuntu bash
</code></pre>
  
  <p>This exposes port 80 of the container without publishing the port to
  the host system’s interfaces.</p>
</blockquote>

<p>Based on the documentation, the first port is the internal port, i.e. 8080 and the second one, i.e. 8888 the external or exposed one.</p>
",210,2017-12-10T10:40:22.183,"['docker run -it --rm -p 8888:8080 tomcat:8.0\n', '$ docker run -p 127.0.0.1:80:8080 ubuntu bash\n', '$ docker run --expose 80 ubuntu bash\n']"
289,2848,1688,CC BY-SA 3.0,2017-12-10T10:57:05.210,"<p>There is a comprehensive <a href=""https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#troubleshooting-tips"" rel=""nofollow noreferrer"">document</a> about k8s' DNS. According to this document one could validate whether the DNS is working by running:</p>

<p>busybox.yaml</p>

<blockquote>
<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: busybox
  namespace: default
spec:
  containers:
  - image: busybox
    command:
      - sleep
      - ""3600""
    imagePullPolicy: IfNotPresent
    name: busybox
  restartPolicy: Always
</code></pre>
</blockquote>

<p>and deploy it by issuing:</p>

<blockquote>
<pre><code>kubectl create -f busybox.yaml
</code></pre>
</blockquote>

<p>Once deployed, one could run:</p>

<blockquote>
<pre><code>kubectl get pods busybox
</code></pre>
</blockquote>

<p>and validate whether the DNS is working:</p>

<blockquote>
<pre><code>kubectl exec -ti busybox -- nslookup kubernetes.default
</code></pre>
</blockquote>

<p>There are additional validation steps that could be executed, including:</p>

<blockquote>
<pre><code>kubectl exec busybox cat /etc/resolv.conf
</code></pre>
</blockquote>

<p>verify the DNS policy, check whether the DNS pod runs, checking erros in the DNS pod:</p>

<blockquote>
<pre><code>kubectl logs --namespace=kube-system $(kubectl get pods --namespace=kube-system -l k8s-app=kube-dns -o name) -c kubedns
kubectl logs --namespace=kube-system $(kubectl get pods --namespace=kube-system -l k8s-app=kube-dns -o name) -c dnsmasq
kubectl logs --namespace=kube-system $(kubectl get pods --namespace=kube-system -l k8s-app=kube-dns -o name) -c sidecar
</code></pre>
</blockquote>

<p>does the DNS service run?</p>

<blockquote>
<pre><code>kubectl get svc --namespace=kube-system
</code></pre>
</blockquote>

<p>exposed DNS endpoints?</p>

<blockquote>
<pre><code>kubectl get ep kube-dns --namespace=kube-system
</code></pre>
</blockquote>

<p>There are also multiple known issues regarding the k8s' DNS:</p>

<blockquote>
  <p>Linux’s libc is impossibly stuck (see this bug from 2005) with limits
  of just 3 DNS nameserver records and 6 DNS search records. Kubernetes
  needs to consume 1 nameserver record and 3 search records. This means
  that if a local installation already uses 3 nameservers or uses more
  than 3 searches, some of those settings will be lost. As a partial
  workaround, the node can run dnsmasq which will provide more
  nameserver entries, but not more search entries. You can also use
  kubelet’s --resolv-conf flag.</p>
</blockquote>
",210,2017-12-10T10:57:05.210,"['apiVersion: v1\nkind: Pod\nmetadata:\n  name: busybox\n  namespace: default\nspec:\n  containers:\n  - image: busybox\n    command:\n      - sleep\n      - ""3600""\n    imagePullPolicy: IfNotPresent\n    name: busybox\n  restartPolicy: Always\n', 'kubectl create -f busybox.yaml\n', 'kubectl get pods busybox\n', 'kubectl exec -ti busybox -- nslookup kubernetes.default\n', 'kubectl exec busybox cat /etc/resolv.conf\n', 'kubectl logs --namespace=kube-system $(kubectl get pods --namespace=kube-system -l k8s-app=kube-dns -o name) -c kubedns\nkubectl logs --namespace=kube-system $(kubectl get pods --namespace=kube-system -l k8s-app=kube-dns -o name) -c dnsmasq\nkubectl logs --namespace=kube-system $(kubectl get pods --namespace=kube-system -l k8s-app=kube-dns -o name) -c sidecar\n', 'kubectl get svc --namespace=kube-system\n', 'kubectl get ep kube-dns --namespace=kube-system\n']"
290,2852,2592,CC BY-SA 3.0,2017-12-10T11:49:53.630,"<p>According to this <a href=""https://www.vagrantup.com/docs/provisioning/ansible.html"" rel=""nofollow noreferrer"">documentation</a> it is possible to install ansible and run a ansible playbook by using the following snippet:</p>

<blockquote>
<pre><code>Vagrant.configure(""2"") do |config|

  #
  # Run Ansible from the Vagrant Host
  #
  config.vm.provision ""ansible"" do |ansible|
    ansible.playbook = ""playbook.yml""
  end

end
</code></pre>
</blockquote>
",210,2017-12-10T11:49:53.630,"['Vagrant.configure(""2"") do |config|\n\n  #\n  # Run Ansible from the Vagrant Host\n  #\n  config.vm.provision ""ansible"" do |ansible|\n    ansible.playbook = ""playbook.yml""\n  end\n\nend\n']"
291,2863,2859,CC BY-SA 3.0,2017-12-11T08:01:21.447,"<p>I found a way to set environmental variables globally from a file!
I'm using envInject for loading variables from a file.</p>

<p>For example, lets say I have a file that is called ""versionNumber.txt"" and that it's created during the build process. Maybe I update it in every build, or any other way. then I create a prosFile that can be identified by the envInject, by running a batch script:</p>

<pre><code>set /p VERSION_NUM=&lt;versionNumber.txt
</code></pre>

<p>Let's assume my version number was 1.5.5.10. so now my VERSION_NUM equals that string.
now VERSION_NUM has the value that I want. But it's local, it won't help me. so I rewrite it to a file in the following format (also, using a batch script):</p>

<pre><code>echo VERSION_NUM=%VERSION_NUM% &gt; C:\Temp\prosFile
</code></pre>

<p>now I have a file that contains the following content:</p>

<pre><code>VERSION_NUM=1.5.5.10
</code></pre>

<p>And now I just need to load the file using the envInject plugin:</p>

<p><a href=""https://i.stack.imgur.com/drZCv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/drZCv.png"" alt=""Loading environmental variables from &quot;prosFile&quot; file""></a></p>

<p>And now I have an environmental variable named VERSION_NUM that can be used anywhere in Jenkins. But I wanted to make it the subject of my email, so I'll simply do (in windows, in linux it might be different):</p>

<p><a href=""https://i.stack.imgur.com/66cLI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/66cLI.png"" alt=""Version Number as the email subject""></a></p>

<p>That's it!</p>
",5431,2017-12-11T08:08:57.770,"['set /p VERSION_NUM=<versionNumber.txt\n', 'echo VERSION_NUM=%VERSION_NUM% > C:\\Temp\\prosFile\n', 'VERSION_NUM=1.5.5.10\n']"
292,2879,2834,CC BY-SA 3.0,2017-12-12T16:57:45.637,"<p>At the bottom line I found this method as stable and reliable, in case you want to deploy via ansible.</p>

<pre><code>### This play deploys a webapp war to an tomcat server

- name: Copy the war file {{ webapp_name }}.war as {{ webapp_name }}.war.tmp to {{ webapp_destination_folder }}
  win_copy:
    src: files/{{ webapp_name }}.war
    dest: ""{{ webapp_destination_folder }}\\{{ webapp_name }}.war.tmp""
    force: yes 

- name: Remove current war file {{ webapp_destination_folder }}\{{ webapp_name }}.war
  win_file:
    path: ""{{ webapp_destination_folder }}\\{{ webapp_name }}.war""
    state: absent

- name: Wait until the webapp folder {{ webapp_destination_folder }}\{{ webapp_name }} is deleted
  win_wait_for:
    path: ""{{ webapp_destination_folder }}\\{{ webapp_name }}xxx""
    state: absent
  register: folder_info

- name: rename the {{ webapp_name }}.war.tmp to {{ webapp_name }}.war
  win_command: ""cmd.exe /c rename {{ webapp_destination_folder }}\\{{ webapp_name }}.war.tmp {{ webapp_name }}.war""
  register: cmd_result 
</code></pre>
",5363,2017-12-12T16:57:45.637,"['### This play deploys a webapp war to an tomcat server\n\n- name: Copy the war file {{ webapp_name }}.war as {{ webapp_name }}.war.tmp to {{ webapp_destination_folder }}\n  win_copy:\n    src: files/{{ webapp_name }}.war\n    dest: ""{{ webapp_destination_folder }}\\\\{{ webapp_name }}.war.tmp""\n    force: yes \n\n- name: Remove current war file {{ webapp_destination_folder }}\\{{ webapp_name }}.war\n  win_file:\n    path: ""{{ webapp_destination_folder }}\\\\{{ webapp_name }}.war""\n    state: absent\n\n- name: Wait until the webapp folder {{ webapp_destination_folder }}\\{{ webapp_name }} is deleted\n  win_wait_for:\n    path: ""{{ webapp_destination_folder }}\\\\{{ webapp_name }}xxx""\n    state: absent\n  register: folder_info\n\n- name: rename the {{ webapp_name }}.war.tmp to {{ webapp_name }}.war\n  win_command: ""cmd.exe /c rename {{ webapp_destination_folder }}\\\\{{ webapp_name }}.war.tmp {{ webapp_name }}.war""\n  register: cmd_result \n']"
293,2889,2867,CC BY-SA 3.0,2017-12-13T08:12:38.930,"<p>So it actually only took one line of code:</p>

<p>1) First take the SSH public key from the settings page inside the appveyor project and make sure you put it into the authorized_keys inside user_that_you_are_going_to_login_with_from_appveyor/.ssh/authorized_keys</p>

<p>2) To clear the folder before deploying to it on a Ubuntu server</p>

<pre><code>before_deploy:    
  ssh user@host -t ""rm -r -v /pathtofolder/*;exit; bash --login""
</code></pre>

<p>3) Now about the restart of the app I wanted to use after_deploy however there is a problem with that. After deploy fires straight after deploy and doesn't wait untill upload is finished. I wanted to use it to run </p>

<pre><code>systemctl restart myapp
</code></pre>

<p>However the problem seemed to solved itself because systemctl restarted my app at the moment when it was substituted with a new one or maybe at the moment when I call it the first time after the files have been reloaded. So far it seems I have a new app running after I run the script.</p>
",5675,2017-12-13T08:12:38.930,"['before_deploy:    \n  ssh user@host -t ""rm -r -v /pathtofolder/*;exit; bash --login""\n', 'systemctl restart myapp\n']"
294,2903,2901,CC BY-SA 3.0,2017-12-14T17:02:49.020,"<p>Got it from <a href=""http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-attribute-updatepolicy.html"" rel=""nofollow noreferrer"">official documentation</a> of UpdatePolicy . Indeed, we can suspend processes by using the <code>UpdatePolicy</code> attribute for the <code>AWS::AutoScaling::AutoScalingGroup</code> resource : </p>

<ul>
<li><p>So instead of <code>SuspendedProcesses</code>, the right term is <code>SuspendProcesses</code>.</p></li>
<li><p>Also instead of putting <code>SuspendProcesses</code> under <code>Properties</code>, it should be under <code>UpdatePolicy &gt; AutoScalingRollingUpdate</code> .</p></li>
</ul>

<p>_</p>

<pre><code>  MyAutoScalingGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      DesiredCapacity: 1
      MinSize: 1
      MaxSize: 1
      LaunchConfigurationName: !Ref MyLaunchConfiguration
      AvailabilityZones: !GetAZs
    UpdatePolicy:
      AutoScalingRollingUpdate:
        SuspendProcesses:
        - AZRebalance
        - Terminate
</code></pre>
",4637,2017-12-14T17:02:49.020,['  MyAutoScalingGroup:\n    Type: AWS::AutoScaling::AutoScalingGroup\n    Properties:\n      DesiredCapacity: 1\n      MinSize: 1\n      MaxSize: 1\n      LaunchConfigurationName: !Ref MyLaunchConfiguration\n      AvailabilityZones: !GetAZs\n    UpdatePolicy:\n      AutoScalingRollingUpdate:\n        SuspendProcesses:\n        - AZRebalance\n        - Terminate\n']
295,2905,175,CC BY-SA 3.0,2017-12-14T20:00:04.560,"<p>You can also build a list of parameter objects, then pass that into the build step:</p>

<pre><code>def paramsMap = [:]
paramsMap['param1'] = 'value1'
paramsMap['param2'] = 'value2'
def paramsObjects = []
paramsMap.each {
  key, value -&gt;
    paramsObjects.push([$class: 'StringParameterValue', name: key, value: value])
}
build job: jobName, parameters: paramsObjects
</code></pre>

<p>paramsObjects would look like this:</p>

<pre><code>[
    [$class:StringParameterValue, name:param1, value:value1],
    [$class:StringParameterValue, name:param2, value:value2]
]
</code></pre>
",5743,2017-12-14T20:00:04.560,"[""def paramsMap = [:]\nparamsMap['param1'] = 'value1'\nparamsMap['param2'] = 'value2'\ndef paramsObjects = []\nparamsMap.each {\n  key, value ->\n    paramsObjects.push([$class: 'StringParameterValue', name: key, value: value])\n}\nbuild job: jobName, parameters: paramsObjects\n"", '[\n    [$class:StringParameterValue, name:param1, value:value1],\n    [$class:StringParameterValue, name:param2, value:value2]\n]\n']"
296,2907,2906,CC BY-SA 3.0,2017-12-14T21:08:29.367,"<p>Yes, this can be done. The following should do the trick:</p>

<pre><code>""{%- for ip, az in seed.iteritems() %} 
  {%- if 'us-east-1a' in az %}
    {%- if firstloop is not defined %}
    {%- set firstloop = 1 %}
{{- ip }}
    {%- else %}
{{- "" "" + ip}}
    {%- endif %}    
  {%- endif %}
{%- endfor%}""
</code></pre>

<p>To test it with <a href=""https://cryptic-cliffs-32040.herokuapp.com/"" rel=""nofollow noreferrer"">https://cryptic-cliffs-32040.herokuapp.com/</a>, you can use the following JSON:</p>

<pre><code>{
    ""seed"": {
      ""10.18.13.12"": ""us-east-1a"",
      ""10.18.37.93"": ""us-east-1b"", 
      ""10.18.68.147"": ""us-east-1a"",
      ""10.18.21.55"": ""us-east-1b""
    }
}
</code></pre>

<p>You might give the <a href=""http://jinja.pocoo.org/docs/2.10/templates/"" rel=""nofollow noreferrer"">documentation</a> a read if you are going to be doing much jinja templating. I have found it indispensible.</p>
",2845,2017-12-14T22:00:07.407,"['""{%- for ip, az in seed.iteritems() %} \n  {%- if \'us-east-1a\' in az %}\n    {%- if firstloop is not defined %}\n    {%- set firstloop = 1 %}\n{{- ip }}\n    {%- else %}\n{{- "" "" + ip}}\n    {%- endif %}    \n  {%- endif %}\n{%- endfor%}""\n', '{\n    ""seed"": {\n      ""10.18.13.12"": ""us-east-1a"",\n      ""10.18.37.93"": ""us-east-1b"", \n      ""10.18.68.147"": ""us-east-1a"",\n      ""10.18.21.55"": ""us-east-1b""\n    }\n}\n']"
297,2913,2911,CC BY-SA 3.0,2017-12-16T05:50:39.457,"<p>I got the answer on StackOverflow :</p>

<p>You can pass the xml file name as parameter to the maven test command. First need to change the pom file as follows.</p>

<pre><code>&lt;plugin&gt;
    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
    &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;
    &lt;version&gt;2.19.1&lt;/version&gt;
        &lt;configuration&gt;
            &lt;suiteXmlFiles&gt;
                &lt;suiteXmlFile&gt;${SuiteXmlFile}&lt;/suiteXmlFile&gt;
            &lt;/suiteXmlFiles&gt;
        &lt;/configuration&gt;
&lt;/plugin&gt;
</code></pre>

<p>Then, you pass the different file name for each execution in goals and options like :</p>

<pre><code>test -DSuiteXmlFile=mytestng1.xml
</code></pre>

<p>For second xml file :</p>

<pre><code>test -DSuiteXmlFile=mytestng1.xml
</code></pre>

<p>You can configure each Jenkins job with different parameter.</p>
",5605,2017-12-16T05:50:39.457,"['<plugin>\n    <groupId>org.apache.maven.plugins</groupId>\n    <artifactId>maven-surefire-plugin</artifactId>\n    <version>2.19.1</version>\n        <configuration>\n            <suiteXmlFiles>\n                <suiteXmlFile>${SuiteXmlFile}</suiteXmlFile>\n            </suiteXmlFiles>\n        </configuration>\n</plugin>\n', 'test -DSuiteXmlFile=mytestng1.xml\n', 'test -DSuiteXmlFile=mytestng1.xml\n']"
298,2916,2914,CC BY-SA 3.0,2017-12-17T14:54:45.900,"<blockquote>
<p><strong>Important</strong></p>
<p>Since AWS CloudFormation templates use the JSON syntax for specifying objects and data, you will need to add an additional backslash to any backslash characters in your regular expression, or JSON will interpret these as escape characters.</p>
<p>For example, if you include a <code>\d</code> in your regular expression to match a digit character, you will need to write it as <code>\\d</code> in your JSON template.</p>
</blockquote>
<p><a href=""http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-regexes.html"" rel=""nofollow noreferrer"">http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-regexes.html</a></p>
<p>The very same applies to your <code>\s</code> expressions. Use <code>\\s</code> and it works.</p>
<p><strong>EDIT:</strong></p>
<p>Looking back the question I started to wonder the missing quotation marks on your definition. I found out the expessions are yaml format that is the second way to define things in aws.</p>
<p>If you should follow the yaml syntax, the right way to give string values is like this:</p>
<pre><code>AllowedPattern = '/[^\s@]+@[^\s@]+\.[^\s@]+/'
</code></pre>
<p><a href=""https://aws.amazon.com/blogs/aws/aws-cloudformation-update-yaml-cross-stack-references-simplified-substitution/"" rel=""nofollow noreferrer"">https://aws.amazon.com/blogs/aws/aws-cloudformation-update-yaml-cross-stack-references-simplified-substitution/</a></p>
<p><strong>EDIT:</strong></p>
<blockquote>
<p>Use quotes if your value includes special characters, (e.g. :, {, }, [, ], ,, &amp;, *, #, ?, |, -, &lt;, &gt;, =, !, %, @, ).</p>
</blockquote>
<p><a href=""https://stackoverflow.com/questions/19109912/do-i-need-quotes-for-strings-in-yaml"">https://stackoverflow.com/questions/19109912/do-i-need-quotes-for-strings-in-yaml</a></p>
",2805,2017-12-18T17:30:15.197,"[""AllowedPattern = '/[^\\s@]+@[^\\s@]+\\.[^\\s@]+/'\n""]"
299,2931,2928,CC BY-SA 4.0,2017-12-20T09:28:30.143,"<p>Ok tried to understand your problem exactly... This is what is happening:</p>

<pre><code>$ echo '{""value"": ""New"", ""onclick"": ""CreateNewDoc()""}' | jq | grep value
jq - commandline JSON processor [version 1.5-1-a5b5cbe]
Usage: jq [options] &lt;jq filter&gt; [file...]
[rest of output is omitted for brevity]
</code></pre>

<p>The important thing to notice here is the usage line (emphasis is mine):</p>

<blockquote>
  <p>Usage: jq [options] <strong>&lt;jq filter&gt;</strong> [file...]</p>
</blockquote>

<p>The filter is not optional, if you don't give one, jq tries to parse the rest of the command line as its filter and throws an error. A workaround for your case here is:</p>

<pre><code>$ echo '{""value"": ""New"", ""onclick"": ""CreateNewDoc()""}' | jq '.' | grep value
  ""value"": ""New"",
</code></pre>

<p>which indeed greps the ""value"" line as the filter passed is '.' - this just pretty prints the json content, but that's far from the best use of jq. If you wish to get only this line it would be better do:</p>

<pre><code>$ echo '{""value"": ""New"", ""onclick"": ""CreateNewDoc()""}' | jq '.value'
""New""
</code></pre>

<p>If you wish to get the output without quotes then you can add add <code>-r</code> option to jq like so:</p>

<pre><code>$ echo '{""value"": ""New"", ""onclick"": ""CreateNewDoc()""}' | jq -r '.value'
New
</code></pre>

<p>from <code>jq --help</code>:</p>

<blockquote>
  <p>-r     output raw strings, not JSON texts;</p>
</blockquote>

<p>that's a little introduction to jq, that's probably not enough to solve your problem at all but as you didn't specify your problem I can't help more than that.</p>
",13,2020-05-22T17:32:15.087,"['$ echo \'{""value"": ""New"", ""onclick"": ""CreateNewDoc()""}\' | jq | grep value\njq - commandline JSON processor [version 1.5-1-a5b5cbe]\nUsage: jq [options] <jq filter> [file...]\n[rest of output is omitted for brevity]\n', '$ echo \'{""value"": ""New"", ""onclick"": ""CreateNewDoc()""}\' | jq \'.\' | grep value\n  ""value"": ""New"",\n', '$ echo \'{""value"": ""New"", ""onclick"": ""CreateNewDoc()""}\' | jq \'.value\'\n""New""\n', '$ echo \'{""value"": ""New"", ""onclick"": ""CreateNewDoc()""}\' | jq -r \'.value\'\nNew\n']"
300,2936,2423,CC BY-SA 3.0,2017-12-20T21:30:17.333,"<p>I finally solved this by using Docker image layer caching for the npm install, following <a href=""https://stackoverflow.com/a/35774741/1258525"">this answer</a></p>

<p>This means I moved the npm install out of the Docker slave image and into the actually frontend image, here is my final Docker file that truly caches the npm install in between builds if package.config has no changes:</p>

<pre><code>FROM centos:7
MAINTAINER Brian Ogden

# Not currently being used but may come in handy
ARG ENVIRONMENT
ENV NODE_VERSION 6.11.1

RUN yum -y update &amp;&amp; \
    yum clean all &amp;&amp; \
    yum -y install http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm \
    yum -y makecache &amp;&amp; \
    yum -y install nginx-1.12.0 wget

# Cleanup some default NGINX configuration files we don’t need
RUN rm /etc/nginx/conf.d/default.conf

#############################################
# NodeJs Install
#############################################

#Download NodeJs package
RUN wget -q -O - https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.gz \
    | tar --strip-components=1 -xzf - -C /usr/local

# https://stackoverflow.com/a/35774741/1258525
# use changes to package.json to force Docker not to use the cache
# when we change our application's nodejs dependencies:
COPY ./package.json /tmp/package.json
RUN cd /tmp &amp;&amp; npm install
RUN mkdir /app &amp;&amp; cp -a /tmp/node_modules /app/

WORKDIR /app
COPY . /app

RUN npm run build-$ENVIRONMENT

RUN cd /app &amp;&amp; cp -a dist/* /usr/share/nginx/html
COPY ./docker/conf/frontend.conf /etc/nginx/conf.d/frontend.conf
COPY ./docker/conf/nginx.conf /etc/nginx/nginx.conf


EXPOSE 80

CMD [""nginx""]
</code></pre>
",4790,2017-12-21T00:16:24.960,"['FROM centos:7\nMAINTAINER Brian Ogden\n\n# Not currently being used but may come in handy\nARG ENVIRONMENT\nENV NODE_VERSION 6.11.1\n\nRUN yum -y update && \\\n    yum clean all && \\\n    yum -y install http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpm \\\n    yum -y makecache && \\\n    yum -y install nginx-1.12.0 wget\n\n# Cleanup some default NGINX configuration files we don’t need\nRUN rm /etc/nginx/conf.d/default.conf\n\n#############################################\n# NodeJs Install\n#############################################\n\n#Download NodeJs package\nRUN wget -q -O - https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.gz \\\n    | tar --strip-components=1 -xzf - -C /usr/local\n\n# https://stackoverflow.com/a/35774741/1258525\n# use changes to package.json to force Docker not to use the cache\n# when we change our application\'s nodejs dependencies:\nCOPY ./package.json /tmp/package.json\nRUN cd /tmp && npm install\nRUN mkdir /app && cp -a /tmp/node_modules /app/\n\nWORKDIR /app\nCOPY . /app\n\nRUN npm run build-$ENVIRONMENT\n\nRUN cd /app && cp -a dist/* /usr/share/nginx/html\nCOPY ./docker/conf/frontend.conf /etc/nginx/conf.d/frontend.conf\nCOPY ./docker/conf/nginx.conf /etc/nginx/nginx.conf\n\n\nEXPOSE 80\n\nCMD [""nginx""]\n']"
301,2949,2939,CC BY-SA 3.0,2017-12-22T10:19:12.507,"<p>In Terraform, <strong>value_specs</strong> are a way of injecting extra key/value pairs into the create request to help with random vendor-specific data. Anyhow this is a workaround option and also it works well with OpenStack provider but I haven't tried with AWS. Could you please try this approach and post your comments. </p>

<pre><code>value_specs {   
      Attrkey = AttrValue 
}
</code></pre>
",4501,2017-12-22T10:21:29.120,['value_specs {   \n      Attrkey = AttrValue \n}\n']
302,2966,2941,CC BY-SA 3.0,2017-12-26T23:04:10.207,"<p>Yes, this is pretty easy with Jenkinsfiles with no need for any third-party plugins or anything along those lines: use the <a href=""https://jenkins.io/doc/pipeline/steps/pipeline-build-step/"" rel=""nofollow noreferrer"">built-in Pipeline build step</a>.</p>

<p>I use this to trigger builds of projects in a dependency chain, so that after one project builds successfully, other projects that depend on it will pull in the updated dependency and build against it.</p>

<p>Here is what this looks like in a Jenkinsfile:</p>

<pre><code>build repoName
</code></pre>

<p>where <code>repoName</code> is a variable containing the name of the repository you wish to build.</p>

<p>Things can get a little more complicated, such as if you're using folders or Multibranch Pipelines:</p>

<pre><code>build ""${projectName}/${repoName}/${branchName}""
</code></pre>

<p>This example builds a job within a Multibranch project where the variables are:</p>

<ul>
<li><code>projectName</code> - the name of my Multibranch project</li>
<li><code>repoName</code> - the name of the repository</li>
<li><code>branchName</code> - the name of the branch to build, usually <code>master</code></li>
</ul>

<p>Or this example builds a job with parameters and also triggers the build asynchronously (parent job won't wait for child job to complete before moving on to the next step):</p>

<pre><code>build(
  jobName,
  wait: false,
  parameters: [
    [
      $class: 'BooleanParameterValue',
      name: 'someBooleanParameter',
      value: true,
    ],
    [
      $class: 'StringParameterValue',
      name: 'someStringParameter',
      value: 'some string value',
    ],
  ],
)
</code></pre>

<p>As you can see, the invocation of <code>build</code> can get relatively complex.  See the documentation linked above for more complete information.</p>
",4115,2017-12-28T18:18:18.873,"['build repoName\n', 'build ""${projectName}/${repoName}/${branchName}""\n', ""build(\n  jobName,\n  wait: false,\n  parameters: [\n    [\n      $class: 'BooleanParameterValue',\n      name: 'someBooleanParameter',\n      value: true,\n    ],\n    [\n      $class: 'StringParameterValue',\n      name: 'someStringParameter',\n      value: 'some string value',\n    ],\n  ],\n)\n""]"
303,2971,2969,CC BY-SA 3.0,2017-12-27T22:10:18.227,"<blockquote>
  <p>some have required and optional arguments that I forget about from
  time to time</p>
</blockquote>

<p><a href=""http://docs.ansible.com/ansible/latest/playbooks_variables.html#variables-defined-in-inventory"" rel=""nofollow noreferrer"">http://docs.ansible.com/ansible/latest/playbooks_variables.html#variables-defined-in-inventory</a></p>

<blockquote>
  <p>Ok, so if you are writing a redistributable role with reasonable
  defaults, put those in the roles/x/defaults/main.yml file. This means
  the role will bring along a default value but ANYTHING in Ansible will
  override it. It’s just a default. That’s why it says “defaults” :) See
  Roles for more info about this:</p>

<pre><code>---
# file: roles/x/defaults/main.yml
# if not overridden in inventory or as a parameter, this is the value that will be used
http_port: 80
</code></pre>
  
  <p>If you are writing a role and want to ensure the value in the role is
  absolutely used in that role, and is not going to be overridden by
  inventory, you should put it in roles/x/vars/main.yml like so, and
  inventory values cannot override it. -e however, still will:</p>
</blockquote>

<p>In summary, always set reasonable defaults, e.g. a software version that exists instead of using a non-existing one or empty variable and if there is a constant, put it in the vars directory.</p>

<p>There is a number of <a href=""https://galaxy.ansible.com/"" rel=""nofollow noreferrer"">galaxy playbooks</a> that could be checked:</p>

<ul>
<li><a href=""https://github.com/geerlingguy/ansible-role-nginx"" rel=""nofollow noreferrer"">https://github.com/geerlingguy/ansible-role-nginx</a></li>
<li><a href=""https://github.com/shelleg/ansible-role-gradle"" rel=""nofollow noreferrer"">https://github.com/shelleg/ansible-role-gradle</a></li>
<li><a href=""https://galaxy.ansible.com/030/firefox/"" rel=""nofollow noreferrer"">https://galaxy.ansible.com/030/firefox/</a></li>
</ul>
",210,2017-12-27T22:18:38.110,"['---\n# file: roles/x/defaults/main.yml\n# if not overridden in inventory or as a parameter, this is the value that will be used\nhttp_port: 80\n']"
304,2979,2978,CC BY-SA 3.0,2017-12-28T16:59:21.597,"<p>Make separate tasks file <code>make_site.yml</code>:</p>

<pre><code>---
- name: Install apache site conf
  template:
    src: apache-sites-{{ site }}-conf.j2
    dest: /etc/apache2/sites-available/{{ site }}.conf
    mode: 0644

- name: Enable site apache conf
  command: a2ensite {{ site }}
  args:
    creates: /etc/apache2/sites-enabled/{{ site }}.conf
</code></pre>

<p>And in your playbook:</p>

<pre><code>- include_tasks: make_site.yml
  with_items:
    - sitea
    - siteb
    - sitec
    - sited
  loop_control:
    loop_var: site
</code></pre>
",3509,2017-12-28T16:59:21.597,"['---\n- name: Install apache site conf\n  template:\n    src: apache-sites-{{ site }}-conf.j2\n    dest: /etc/apache2/sites-available/{{ site }}.conf\n    mode: 0644\n\n- name: Enable site apache conf\n  command: a2ensite {{ site }}\n  args:\n    creates: /etc/apache2/sites-enabled/{{ site }}.conf\n', '- include_tasks: make_site.yml\n  with_items:\n    - sitea\n    - siteb\n    - sitec\n    - sited\n  loop_control:\n    loop_var: site\n']"
305,2985,795,CC BY-SA 4.0,2017-12-28T22:06:06.267,"<p>Here is my solution: (bitbucket-pipelines.yml)</p>

<pre><code>pipelines:
  default:
    - step:
        script:
          - export DOCKER_COMPOSE_VERSION=1.18.0
          - export DOCKER_COMPOSE_URL=https://github.com/docker/compose/releases/download/${DOCKER_COMPOSE_VERSION}/docker-compose-$(uname -s)-$(uname -m)
          - curl -L $DOCKER_COMPOSE_URL &gt; docker-compose
          - chmod +x docker-compose
          - mv docker-compose /usr/local/bin
          - docker-compose build --force-rm --no-cache --pull
</code></pre>
",5902,2019-12-20T10:46:00.547,['pipelines:\n  default:\n    - step:\n        script:\n          - export DOCKER_COMPOSE_VERSION=1.18.0\n          - export DOCKER_COMPOSE_URL=https://github.com/docker/compose/releases/download/${DOCKER_COMPOSE_VERSION}/docker-compose-$(uname -s)-$(uname -m)\n          - curl -L $DOCKER_COMPOSE_URL > docker-compose\n          - chmod +x docker-compose\n          - mv docker-compose /usr/local/bin\n          - docker-compose build --force-rm --no-cache --pull\n']
306,2988,2967,CC BY-SA 3.0,2017-12-29T01:07:19.197,"<p>Research indicated that the <a href=""https://docs.docker.com/engine/admin/volumes/"" rel=""noreferrer"">anonymous volumes</a> were created by <code>influxdb</code> and <code>grafana/grafana</code>. </p>

<blockquote>
  <p>Anonymous volumes are not given an explicit name when they are first
  mounted into a container, so Docker gives them a random name that is
  guaranteed to be unique within a given Docker host. Besides the name,
  named and anonymous volumes behave in the same ways.</p>
</blockquote>

<p><strong>Results</strong></p>

<pre><code>version: ""3""
services:
  influxdb:
    image: influxdb:latest
    container_name: influxdb
    ports:
      - ""8086:8086""
    #env_file:
    #  - 'env.influxdb'
    networks:
      - backend
    volumes:
      - influxdb-data:/var/lib/influxdb

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - ""3000:3000""
    #env_file:
    #  - 'env.grafana'
    #  - 'secrets.grafana'
    networks:
      - backend
    volumes:
      - grafana-data:/var/lib/grafana

networks:
  backend:

volumes:
  influxdb-data:
  grafana-data:
</code></pre>

<p>results in:</p>

<pre><code>DRIVER              VOLUME NAME
local               604a07040367512b09c618c6dcc71a7f55390c9c23de6ab08be7466414ed62da
local               7f4b630073b31b6e772d3edef6da81b48643525edfc34281ea13fbd6b86ec270
local               devopsstackexchange_grafana-data
local               devopsstackexchange_influxdb-data
</code></pre>

<p>and everytime when <code>docker-compose down</code> and subsequenlty <code>up</code> is run the number of anonymous volumes doubles.</p>

<p><em>What will happen if nginx will be pulled instead of influxdb and grafana?</em></p>

<pre><code>DRIVER              VOLUME NAME
local               devopsstackexchange_grafana-data
local               devopsstackexchange_influxdb-data
</code></pre>

<p>and after <code>docker-compose down &amp;&amp; docker-compose up -d</code>?</p>

<pre><code>DRIVER              VOLUME NAME
local               devopsstackexchange_grafana-data
local               devopsstackexchange_influxdb-data
</code></pre>

<p>It looks like that certain images created the additional anonymous volumes. Let's replace influxdb with nginx and use grafana.</p>

<pre><code>DRIVER              VOLUME NAME
local               15b80416ab06abb629d9f634a0feff08f7c560f31d614b9b430855c16cdb75c7
local               205a6f19cbf992c95b2e3be9f2fb1ca9ecec35fce550d0b7a4b9f32b0ef163b1
local               474108f5b7b14fba92a3e5a980f3bf851388b2ee25d7417df5c42d9f176e084b
local               5830a31a470ec8a42ddae7a37bb50487f3f36360318b2f9f5301b338507782b4
local               9f00868a2fec0cfc0d34dc12d0879d39487a13128863722f400ad4c47df2d340
local               devopsstackexchange_grafana-data
local               devopsstackexchange_influxdb-data
local               f47b1b7bbec8e50b32a7c39704c7c218165b284298d852313fa24bc7cbe6acc5
</code></pre>

<p>Everytime docker compose was run again, three anonymous volumes were created by the <code>grafana/grafana</code> docker image. Let's replace influxdb with nginx and revert the grafana to nginx:</p>

<pre><code>DRIVER              VOLUME NAME
local               devopsstackexchange_grafana-data
local               devopsstackexchange_influxdb-data
</code></pre>

<p>and it remains two if restarted.</p>

<p>It looks like that grafana is causing the issue.</p>

<p><strong>Why are three new anonymous volumes created everytime grafana/grafana is restarted?</strong></p>

<p><a href=""https://github.com/grafana/grafana-docker/blob/master/Dockerfile#L16"" rel=""noreferrer"">The grafana/grafana dockerfile</a> indicates that three anonymous volumes will be created:</p>

<blockquote>
<pre><code>VOLUME [""/var/lib/grafana"", ""/var/log/grafana"", ""/etc/grafana""]
</code></pre>
</blockquote>

<p><a href=""https://docs.docker.com/engine/reference/builder/#volume"" rel=""noreferrer"">https://docs.docker.com/engine/reference/builder/#volume</a></p>

<blockquote>
<pre><code>FROM ubuntu
RUN mkdir /myvol
RUN echo ""hello world"" &gt; /myvol/greeting
VOLUME /myvol
</code></pre>
  
  <p>This Dockerfile results in an image that causes docker run, to create
  a new mount point at /myvol and copy the greeting file into the newly
  created volume.</p>
</blockquote>

<p><code>docker volume inspect &lt;volume name, e.g. 34cfafd4603dbc7e71a83e2520f978c8307b084143b3192de65a1995dc1d2f86&gt;</code> returned grafana data when the path that was returned was checked of two out of three anonymous volumes:</p>

<pre><code>sudo ls /var/lib/docker/volumes/a0ecd00df8fc68ef36e777c7bf9ec5a496ee30e313b86889487501a53fa2e28e/_data
grafana.ini  ldap.toml
</code></pre>

<p>and</p>

<pre><code>sudo ls /var/lib/docker/volumes/34cfafd4603dbc7e71a83e2520f978c8307b084143b3192de65a1995dc1d2f86/_data
grafana.db  plugins
</code></pre>
",210,2017-12-29T01:28:35.470,"['version: ""3""\nservices:\n  influxdb:\n    image: influxdb:latest\n    container_name: influxdb\n    ports:\n      - ""8086:8086""\n    #env_file:\n    #  - \'env.influxdb\'\n    networks:\n      - backend\n    volumes:\n      - influxdb-data:/var/lib/influxdb\n\n  grafana:\n    image: grafana/grafana:latest\n    container_name: grafana\n    ports:\n      - ""3000:3000""\n    #env_file:\n    #  - \'env.grafana\'\n    #  - \'secrets.grafana\'\n    networks:\n      - backend\n    volumes:\n      - grafana-data:/var/lib/grafana\n\nnetworks:\n  backend:\n\nvolumes:\n  influxdb-data:\n  grafana-data:\n', 'DRIVER              VOLUME NAME\nlocal               604a07040367512b09c618c6dcc71a7f55390c9c23de6ab08be7466414ed62da\nlocal               7f4b630073b31b6e772d3edef6da81b48643525edfc34281ea13fbd6b86ec270\nlocal               devopsstackexchange_grafana-data\nlocal               devopsstackexchange_influxdb-data\n', 'DRIVER              VOLUME NAME\nlocal               devopsstackexchange_grafana-data\nlocal               devopsstackexchange_influxdb-data\n', 'DRIVER              VOLUME NAME\nlocal               devopsstackexchange_grafana-data\nlocal               devopsstackexchange_influxdb-data\n', 'DRIVER              VOLUME NAME\nlocal               15b80416ab06abb629d9f634a0feff08f7c560f31d614b9b430855c16cdb75c7\nlocal               205a6f19cbf992c95b2e3be9f2fb1ca9ecec35fce550d0b7a4b9f32b0ef163b1\nlocal               474108f5b7b14fba92a3e5a980f3bf851388b2ee25d7417df5c42d9f176e084b\nlocal               5830a31a470ec8a42ddae7a37bb50487f3f36360318b2f9f5301b338507782b4\nlocal               9f00868a2fec0cfc0d34dc12d0879d39487a13128863722f400ad4c47df2d340\nlocal               devopsstackexchange_grafana-data\nlocal               devopsstackexchange_influxdb-data\nlocal               f47b1b7bbec8e50b32a7c39704c7c218165b284298d852313fa24bc7cbe6acc5\n', 'DRIVER              VOLUME NAME\nlocal               devopsstackexchange_grafana-data\nlocal               devopsstackexchange_influxdb-data\n', 'VOLUME [""/var/lib/grafana"", ""/var/log/grafana"", ""/etc/grafana""]\n', 'FROM ubuntu\nRUN mkdir /myvol\nRUN echo ""hello world"" > /myvol/greeting\nVOLUME /myvol\n', 'sudo ls /var/lib/docker/volumes/a0ecd00df8fc68ef36e777c7bf9ec5a496ee30e313b86889487501a53fa2e28e/_data\ngrafana.ini  ldap.toml\n', 'sudo ls /var/lib/docker/volumes/34cfafd4603dbc7e71a83e2520f978c8307b084143b3192de65a1995dc1d2f86/_data\ngrafana.db  plugins\n']"
307,2994,2989,CC BY-SA 3.0,2017-12-30T15:48:17.530,"<p>It looks like you are using <a href=""/questions/tagged/docker-machine"" class=""post-tag"" title=""show questions tagged &#39;docker-machine&#39;"" rel=""tag"">docker-machine</a> instead of <a href=""/questions/tagged/docker"" class=""post-tag"" title=""show questions tagged &#39;docker&#39;"" rel=""tag"">docker</a>.</p>

<p><a href=""https://docs.docker.com/machine/get-started/#create-a-machine"" rel=""nofollow noreferrer"">https://docs.docker.com/machine/get-started/#create-a-machine</a></p>

<blockquote>
  <p>Get the environment commands for your new VM.</p>
  
  <p>As noted in the output of the docker-machine create command, you need
  to tell Docker to talk to the new machine. You can do this with the
  docker-machine env command.</p>

<pre><code> $ docker-machine env default
 export DOCKER_TLS_VERIFY=""1""
 export DOCKER_HOST=""tcp://172.16.62.130:2376""
 export DOCKER_CERT_PATH=""/Users/&lt;yourusername&gt;/.docker/machine/machines/default""
 export DOCKER_MACHINE_NAME=""default""
 # Run this command to configure your shell:
 # eval ""$(docker-machine env default)""
</code></pre>
</blockquote>

<p>Why did this solution work?</p>

<p>According to <a href=""https://docs.docker.com/machine/get-started/#unset-environment-variables-in-the-current-shell"" rel=""nofollow noreferrer"">this documentation</a> the variables have to be set over and over again.</p>

<blockquote>
  <p>Unset environment variables in the current shell</p>
  
  <p>You might want to use the current shell to connect to a different
  Docker Engine. This would be the case if, for example, you are running
  Docker for Mac concurrent with Docker Toolbox and want to talk to two
  different Docker Engines, or running swarms on Docker Cloud and want
  to switch between managing the swarm and using Docker hosts. In both
  scenarios, you have the option to switch the environment for the
  current shell to talk to different Docker engines.</p>

<pre><code>Run env|grep DOCKER to check whether DOCKER environment variables are set.

$ env | grep DOCKER
DOCKER_HOST=tcp://192.168.99.100:2376
DOCKER_MACHINE_NAME=default
DOCKER_TLS_VERIFY=1
DOCKER_CERT_PATH=/Users/victoriabialas/.docker/machine/machines/default

If it returns output (as shown in the example), you can unset the DOCKER environment variables.

Use one of two methods to unset DOCKER environment variables in the current shell.

    Run the unset command on the following DOCKER environment variables.

    unset DOCKER_TLS_VERIFY
    unset DOCKER_CERT_PATH
    unset DOCKER_MACHINE_NAME
    unset DOCKER_HOST

    Alternatively, run a shortcut command docker-machine env -u to show the command you need to run to unset all DOCKER variables:

    $ docker-machine env -u
    unset DOCKER_TLS_VERIFY
    unset DOCKER_HOST
    unset DOCKER_CERT_PATH
    unset DOCKER_MACHINE_NAME
    # Run this command to configure your shell:
    # eval $(docker-machine env -u)

    Run eval $(docker-machine env -u) to unset all DOCKER variables in the current shell.

Now, after running either of the above commands, this command should return no output.

 $ env | grep DOCKER

If you are running Docker for Mac, you can run Docker commands to talk to the Docker Engine installed with that app.

If you are running swarms on Docker Cloud, you can re-run the export command you used to connect to the swarm.

Since Docker for Windows is incompatible with Toolbox, this scenario isn’t applicable because Docker for Windows uses the Docker
</code></pre>
  
  <p>Engine and Docker Machine that come with it.</p>
</blockquote>
",210,2017-12-30T15:56:41.490,"[' $ docker-machine env default\n export DOCKER_TLS_VERIFY=""1""\n export DOCKER_HOST=""tcp://172.16.62.130:2376""\n export DOCKER_CERT_PATH=""/Users/<yourusername>/.docker/machine/machines/default""\n export DOCKER_MACHINE_NAME=""default""\n # Run this command to configure your shell:\n # eval ""$(docker-machine env default)""\n', 'Run env|grep DOCKER to check whether DOCKER environment variables are set.\n\n$ env | grep DOCKER\nDOCKER_HOST=tcp://192.168.99.100:2376\nDOCKER_MACHINE_NAME=default\nDOCKER_TLS_VERIFY=1\nDOCKER_CERT_PATH=/Users/victoriabialas/.docker/machine/machines/default\n\nIf it returns output (as shown in the example), you can unset the DOCKER environment variables.\n\nUse one of two methods to unset DOCKER environment variables in the current shell.\n\n    Run the unset command on the following DOCKER environment variables.\n\n    unset DOCKER_TLS_VERIFY\n    unset DOCKER_CERT_PATH\n    unset DOCKER_MACHINE_NAME\n    unset DOCKER_HOST\n\n    Alternatively, run a shortcut command docker-machine env -u to show the command you need to run to unset all DOCKER variables:\n\n    $ docker-machine env -u\n    unset DOCKER_TLS_VERIFY\n    unset DOCKER_HOST\n    unset DOCKER_CERT_PATH\n    unset DOCKER_MACHINE_NAME\n    # Run this command to configure your shell:\n    # eval $(docker-machine env -u)\n\n    Run eval $(docker-machine env -u) to unset all DOCKER variables in the current shell.\n\nNow, after running either of the above commands, this command should return no output.\n\n $ env | grep DOCKER\n\nIf you are running Docker for Mac, you can run Docker commands to talk to the Docker Engine installed with that app.\n\nIf you are running swarms on Docker Cloud, you can re-run the export command you used to connect to the swarm.\n\nSince Docker for Windows is incompatible with Toolbox, this scenario isn’t applicable because Docker for Windows uses the Docker\n']"
308,2996,2980,CC BY-SA 3.0,2017-12-30T16:26:49.033,"<p>After reading <a href=""http://docs.gunicorn.org/en/stable/run.html#commands"" rel=""nofollow noreferrer"">the commands chapter</a> and finding <a href=""https://github.com/benoitc/gunicorn/issues/1533"" rel=""nofollow noreferrer"">this sample</a>, it looks like that the custom <code>GUNICORN_CMD_ARGS</code> could be omitted by just passing the arguments directly:</p>

<pre><code>command: gunicorn thymedata:app --bind=127.0.0.1:8001 --workers=3
</code></pre>

<p>If one really would like to use variables then it could be done as follows:</p>

<pre><code>command: gunicorn thymedata:app --bind=${GUNICORN_BIND_ADDRESS} --workers=${GUNICORN_WORKERS}
</code></pre>

<p>.env</p>

<pre><code>GUNICORN_BIND_ADDRESS=127.0.0.1:8001
GUNICORN_WORKERS=3
</code></pre>
",210,2017-12-30T16:26:49.033,"['command: gunicorn thymedata:app --bind=127.0.0.1:8001 --workers=3\n', 'command: gunicorn thymedata:app --bind=${GUNICORN_BIND_ADDRESS} --workers=${GUNICORN_WORKERS}\n', 'GUNICORN_BIND_ADDRESS=127.0.0.1:8001\nGUNICORN_WORKERS=3\n']"
309,2997,2956,CC BY-SA 3.0,2017-12-30T17:21:12.650,"<p>It looks like your k8s cluster has not been deployed well. I have verified that it works to deploy the nginx by using the template as defined in the question.</p>

<p>In contrast to your cluster, the cluster I am using has several k8s images to host the dashboard etc.</p>

<pre><code>        ""Images"": [
            {
                ""Names"": [
                    ""gcr.io/google_containers/kubernetes-dashboard-amd64:v1.6.3""
                ],
                ""SizeBytes"": 138972432
            },
            {
                ""Names"": [
                    ""gcr.io/google_containers/kubernetes-dashboard-amd64@sha256:71a0de5c6a21cb0c2fbcad71a4fef47acd3e61cd78109822d35e1742f9d8140d"",
                    ""gcr.io/google_containers/kubernetes-dashboard-amd64:v1.8.0""
                ],
                ""SizeBytes"": 119155776
            },
</code></pre>

<p>Also in order to deploy images, at least some namespaces should be returned. </p>

<pre><code>$ kubectl get ns
NAME          STATUS    AGE
default       Active    37m
kube-public   Active    37m
kube-system   Active    37m
</code></pre>
",210,2017-12-30T17:52:04.477,"['        ""Images"": [\n            {\n                ""Names"": [\n                    ""gcr.io/google_containers/kubernetes-dashboard-amd64:v1.6.3""\n                ],\n                ""SizeBytes"": 138972432\n            },\n            {\n                ""Names"": [\n                    ""gcr.io/google_containers/kubernetes-dashboard-amd64@sha256:71a0de5c6a21cb0c2fbcad71a4fef47acd3e61cd78109822d35e1742f9d8140d"",\n                    ""gcr.io/google_containers/kubernetes-dashboard-amd64:v1.8.0""\n                ],\n                ""SizeBytes"": 119155776\n            },\n', '$ kubectl get ns\nNAME          STATUS    AGE\ndefault       Active    37m\nkube-public   Active    37m\nkube-system   Active    37m\n']"
310,2998,1262,CC BY-SA 3.0,2017-12-30T18:10:58.173,"<p><a href=""https://gatling.io/docs/2.3/extensions/jenkins_plugin/"" rel=""nofollow noreferrer"">https://gatling.io/docs/2.3/extensions/jenkins_plugin/</a></p>

<p><a href=""https://wiki.jenkins.io/display/JENKINS/Gatling+Plugin"" rel=""nofollow noreferrer"">https://wiki.jenkins.io/display/JENKINS/Gatling+Plugin</a></p>

<blockquote>
  <p>Configuration</p>

<pre><code>Install Gatling Plugin (via Manage Jenkins -&gt; Manage Plugins)
Configure your project to execute Gatling simulations, for example using the Maven plugin (see Maven plugin documentation)
Configure your job :
    For a maven job: add ""Track a Gatling load simulation"" as a new post-build action. Beware that neither your Jenkin's path nor your
</code></pre>
  
  <p>job's name should contain any space.
          For a pipeline job: add a line to your pipeline script: gatlingArchive()</p>
  
  <p>Optional configuration: You can publish Gatling results with the
  Jenkins JUnit plugin. Your Gatling simulation needs to have some
  assertions, as each Junit testcase is a different Gatling assertion.</p>

<pre><code>Configure the Jenkins plugin with the following Test report XMLs: target/gatling/assertions-*.xml
Execute Gatling with the following option: -Dgatling.useOldJenkinsJUnitSupport=true, for example: mvn gatling:execute -Dgatling.useOldJenkinsJUnitSupport=true
</code></pre>
</blockquote>
",210,2017-12-30T18:10:58.173,"['Install Gatling Plugin (via Manage Jenkins -> Manage Plugins)\nConfigure your project to execute Gatling simulations, for example using the Maven plugin (see Maven plugin documentation)\nConfigure your job :\n    For a maven job: add ""Track a Gatling load simulation"" as a new post-build action. Beware that neither your Jenkin\'s path nor your\n', 'Configure the Jenkins plugin with the following Test report XMLs: target/gatling/assertions-*.xml\nExecute Gatling with the following option: -Dgatling.useOldJenkinsJUnitSupport=true, for example: mvn gatling:execute -Dgatling.useOldJenkinsJUnitSupport=true\n']"
311,3000,2166,CC BY-SA 3.0,2017-12-31T04:19:20.543,"<p>Well, there is no rename, it is a <a href=""https://kb.vmware.com/s/article/1029513"" rel=""nofollow noreferrer"">multi-step process</a>, which involves renaming a bunch of entries inside the vmx file, using <a href=""https://www.vmware.com/support/ws45/doc/disks_vdiskmanager_eg_ws.html"" rel=""nofollow noreferrer"">vmware-vdiskmanager to rename to vmdk</a> and in general doing a bunch of potentially problematic actions if you don't know what you are doing.</p>

<p>You could probably write a quick Perl script to do all that <a href=""https://www.vmware.com/support/developer/viperltoolkit/doc/perl_toolkit_guide.html"" rel=""nofollow noreferrer"">using this guide</a>.</p>

<p>Another option would be to clone it and delete the original, but it is resource intensive and does way too much work for what it is worth. The code below is untested:</p>

<pre><code>vmrun -T fusion stop ""/Volumes/vms/old/old.vmx""
vmrun -T fusion clone ""/Volumes/vms/old/old.vmx"" ""/Volumes/vms/new/new.vmx"" full --cloneName=new
vmrun -T fusion deleteVM ""/Volumes/vms/old/old.vmx""
vmrun -T fusion start ""/Volumes/vms/new/new.vmx""
</code></pre>
",228,2017-12-31T04:19:20.543,"['vmrun -T fusion stop ""/Volumes/vms/old/old.vmx""\nvmrun -T fusion clone ""/Volumes/vms/old/old.vmx"" ""/Volumes/vms/new/new.vmx"" full --cloneName=new\nvmrun -T fusion deleteVM ""/Volumes/vms/old/old.vmx""\nvmrun -T fusion start ""/Volumes/vms/new/new.vmx""\n']"
312,3003,1088,CC BY-SA 3.0,2017-12-31T11:54:41.520,"<blockquote>
  <p>I looked at Jenkins plugins for vault, but they only work for fetching secrets from Vault.</p>
</blockquote>

<p>It depends how the current configuration looks like that is used to deploy apps. </p>

<p><a href=""https://github.com/jenkinsci/hashicorp-vault-plugin"" rel=""nofollow noreferrer"">https://github.com/jenkinsci/hashicorp-vault-plugin</a></p>

<p>If one uses Jenkins pipelines, then one could replace the keyId with the one that is defined in Hashicorp vault.</p>

<blockquote>
<pre><code>node {
  // define the secrets and the env variables
  def secrets = [
      [$class: 'VaultSecret', path: 'secret/testing', secretValues: [
          [$class: 'VaultSecretValue', envVar: 'testing', vaultKey: 'value_one'],
          [$class: 'VaultSecretValue', envVar: 'testing_again', vaultKey: 'value_two']]],
      [$class: 'VaultSecret', path: 'secret/another_test', secretValues: [
          [$class: 'VaultSecretValue', envVar: 'another_test', vaultKey: 'value']]]
  ]

  // optional configuration, if you do not provide this the next higher configuration
  // (e.g. folder or global) will be used
  def configuration = [$class: 'VaultConfiguration',
                       vaultUrl: 'http://my-very-other-vault-url.com',
                       vaultCredentialId: 'my-vault-cred-id']

  // inside this block your credentials will be available as env variables
  wrap([$class: 'VaultBuildWrapper', configuration: configuration, vaultSecrets: secrets]) {
      sh 'echo $testing'
      sh 'echo $testing_again'
      sh 'echo $another_test'
  }
}
</code></pre>
</blockquote>
",210,2017-12-31T11:54:41.520,"[""node {\n  // define the secrets and the env variables\n  def secrets = [\n      [$class: 'VaultSecret', path: 'secret/testing', secretValues: [\n          [$class: 'VaultSecretValue', envVar: 'testing', vaultKey: 'value_one'],\n          [$class: 'VaultSecretValue', envVar: 'testing_again', vaultKey: 'value_two']]],\n      [$class: 'VaultSecret', path: 'secret/another_test', secretValues: [\n          [$class: 'VaultSecretValue', envVar: 'another_test', vaultKey: 'value']]]\n  ]\n\n  // optional configuration, if you do not provide this the next higher configuration\n  // (e.g. folder or global) will be used\n  def configuration = [$class: 'VaultConfiguration',\n                       vaultUrl: 'http://my-very-other-vault-url.com',\n                       vaultCredentialId: 'my-vault-cred-id']\n\n  // inside this block your credentials will be available as env variables\n  wrap([$class: 'VaultBuildWrapper', configuration: configuration, vaultSecrets: secrets]) {\n      sh 'echo $testing'\n      sh 'echo $testing_again'\n      sh 'echo $another_test'\n  }\n}\n""]"
313,3005,1622,CC BY-SA 3.0,2017-12-31T12:48:05.517,"<p>Correct me if I am wrong, but that is one of the reasons why docker orchestration tools exists like docker-swarm to be able to deploy multiple docker containers by using one command line.</p>

<blockquote>
  <p>Create a service with 5 replica tasks (–replicas)</p>
  
  <p>Use the --replicas flag to set the number of replica tasks for a replicated service. The following command creates a redis service with
  5 replica tasks:</p>

<pre><code>$ docker service create --name redis --replicas=5 redis:3.0.6

4cdgfyky7ozwh3htjfw0d12qv
</code></pre>
</blockquote>

<p>If for example 1000 identical containers that use a different environment variable have to be deployed, multiple <code>docker service create</code> could be added to a script, instead of copy-paste multiple times in one docker-compose file.</p>
",210,2017-12-31T12:48:05.517,['$ docker service create --name redis --replicas=5 redis:3.0.6\n\n4cdgfyky7ozwh3htjfw0d12qv\n']
314,3008,2871,CC BY-SA 3.0,2017-12-31T21:38:10.500,"<p>Either use the <code>--query</code> attribute</p>

<pre><code>aws rds describe-db-snapshots --query ""DBSnapshots[?Encrypted].DBSnapshotIdentifier""
</code></pre>

<p>If the <code>[?Encrypted]</code> does not work, try <code>[?Encrypted == 'true']</code> as the first is from JMESPath improved filters. The quotes might need to be backticks in some case. It all depends.</p>

<p>Second way:</p>

<pre><code>aws rds describe-db-snapshots --output json | jq '.DBSnapshots | map(select(has(""Encrypted""))) | .[].DBSnapshotIndetifier'
</code></pre>

<p>One of them should work. Might need a bit messing around as I don't have your output to tune the <code>jq</code> command. Feel free to edit and fix the answer.</p>
",228,2018-01-13T16:33:39.330,"['aws rds describe-db-snapshots --query ""DBSnapshots[?Encrypted].DBSnapshotIdentifier""\n', 'aws rds describe-db-snapshots --output json | jq \'.DBSnapshots | map(select(has(""Encrypted""))) | .[].DBSnapshotIndetifier\'\n']"
315,3009,2967,CC BY-SA 3.0,2018-01-01T01:53:58.097,"<p>Check the volumes defined in the <code>Dockerfile</code> with the <code>VOLUME</code> instruction.</p>

<p>If you don't want volume with random names to be automatically created, you can provide a host path to be bind-mounted to the volume, check the <code>-v</code> or <code>--mount</code> options, <a href=""https://docs.docker.com/engine/admin/volumes/volumes/#choose-the--v-or-mount-flag"" rel=""nofollow noreferrer"">https://docs.docker.com/engine/admin/volumes/volumes/#choose-the--v-or-mount-flag</a></p>

<p>For example:</p>

<pre><code>-v /srv/lib/grafana:/var/lib/grafana
</code></pre>
",5922,2018-01-01T01:53:58.097,['-v /srv/lib/grafana:/var/lib/grafana\n']
316,3025,2947,CC BY-SA 3.0,2018-01-04T05:25:30.743,"<p>Docker actually provides DNS support for networking between containers. This means that if you define your database connection as:</p>

<pre><code>http://redis:6379
</code></pre>

<p>This will resolve <code>redis</code> to the correct network address, given that you fulfill the following:</p>

<ul>
<li>All containers are on the same network</li>
<li>The containers have been named</li>
</ul>

<p>This can either be done manually by starting both instances via the <a href=""https://docs.docker.com/engine/reference/commandline/cli/"" rel=""nofollow noreferrer"">cli</a> or automated with a <a href=""https://docs.docker.com/compose/gettingstarted/"" rel=""nofollow noreferrer"">docker compose</a> script, which is <em>my recommendation</em>. In the compose script, from version 3, you would define the both services (aka the containers):</p>

<pre><code>version: ""3""
services:
  web:
    build: ./web
    container_name: web
    networks:
      - backend
    command: bash -c ""./start.sh""

  redis:
    image: redis:3.2
    container_name: redis
    networks:
      - backend
</code></pre>

<p>And at the end of the file, define the network both instances should be connected to:</p>

<pre><code>networks:
  backend:
</code></pre>
",5879,2018-01-04T05:25:30.743,"['http://redis:6379\n', 'version: ""3""\nservices:\n  web:\n    build: ./web\n    container_name: web\n    networks:\n      - backend\n    command: bash -c ""./start.sh""\n\n  redis:\n    image: redis:3.2\n    container_name: redis\n    networks:\n      - backend\n', 'networks:\n  backend:\n']"
317,3036,2871,CC BY-SA 3.0,2018-01-06T10:11:04.803,"<p>You will require a <strong>script</strong> that interacts with the <strong>AWS cli</strong> to accomplish your goal.</p>

<p>To list encrypted drives I use the following query when describing the DB snapshots <code>--query 'DBSnapshots[*].[DBSnapshotArn,Encrypted]'</code></p>

<p>I have put together the following script which will <strong>look for all encrypted DBS snapshots and then copy all of them to a different region</strong>. It can also be modified to copy unencrypted snapshots to a different region and then encrypt them.</p>

<blockquote>
  <p>I have explained the script in the comments. It is quite <strong>dirty</strong>...
  so feel free to <strong>improve</strong> it!</p>
</blockquote>

<pre><code>#!/usr/bin/env bash
#
# Copy encrypted or unencrypted DBSnapshots to an encrypted DBSnapshot in a different region
#

aws_profile="""" 
aws_source_region="""" 
aws_dest_region="""" 
aws_kms_key_id="""" #destination kms key ID 
num=1

aws --profile ""${aws_profile}"" --region ""${aws_source_region}"" rds describe-db-snapshots \
  --query 'DBSnapshots[*].[DBSnapshotArn,Encrypted]' \  
  --output text &gt; rds-snapshots-list.txt

echo ""Encrypted snapshots"" 
awk '{IGNORECASE=1}{if ($2 == ""True"") print}' rds-snapshots-list.txt #Show list of encrypted snapshots 
echo ""Unencrypted snapshots"" 
awk '{IGNORECASE=1}{if ($2 == ""False"") print}' rds-snapshots-list.txt #Show list of unencrypted snapshots

IFS=$'\n' read -d '' -r -a rds_list_lines &lt; rds-snapshots-list.txt #Move txt file content into an array

echo ""Copying encrypted snapshots from ${aws_source_region} to ${aws_dest_region}"" 
for i in ""${rds_list_lines[@]}""; do #Loop through array   
if [[ ""${i}"" == *""True""* ]]; then #Check for encrypted rds snapshot &amp; if true copy snapshot
    source_snapshot_ident=""$( echo ""${i}"" | sed 's/[[:blank:]]True.*//')"" #Remove all spaces tabs and the word true
    target_snapshot_ident=""$( echo ""$source_snapshot_ident"" | sed 's/.*:snapshot:rds:.//')snapshotcopy$num"" #Name of target snapshot with incrementing number
    ((num++))

    aws --profile ""${aws_profile}"" --region ""${aws_dest_region}"" rds copy-db-snapshot \
      --source-db-snapshot-identifier ""${source_snapshot_ident}"" \
      --target-db-snapshot-identifier ""${target_snapshot_ident}"" \
      --source-region ""${aws_source_region}"" \
      --kms-key-id ""${aws_kms_key_id}""   
fi 
done
</code></pre>
",887,2018-01-16T07:03:29.483,"['#!/usr/bin/env bash\n#\n# Copy encrypted or unencrypted DBSnapshots to an encrypted DBSnapshot in a different region\n#\n\naws_profile="""" \naws_source_region="""" \naws_dest_region="""" \naws_kms_key_id="""" #destination kms key ID \nnum=1\n\naws --profile ""${aws_profile}"" --region ""${aws_source_region}"" rds describe-db-snapshots \\\n  --query \'DBSnapshots[*].[DBSnapshotArn,Encrypted]\' \\  \n  --output text > rds-snapshots-list.txt\n\necho ""Encrypted snapshots"" \nawk \'{IGNORECASE=1}{if ($2 == ""True"") print}\' rds-snapshots-list.txt #Show list of encrypted snapshots \necho ""Unencrypted snapshots"" \nawk \'{IGNORECASE=1}{if ($2 == ""False"") print}\' rds-snapshots-list.txt #Show list of unencrypted snapshots\n\nIFS=$\'\\n\' read -d \'\' -r -a rds_list_lines < rds-snapshots-list.txt #Move txt file content into an array\n\necho ""Copying encrypted snapshots from ${aws_source_region} to ${aws_dest_region}"" \nfor i in ""${rds_list_lines[@]}""; do #Loop through array   \nif [[ ""${i}"" == *""True""* ]]; then #Check for encrypted rds snapshot & if true copy snapshot\n    source_snapshot_ident=""$( echo ""${i}"" | sed \'s/[[:blank:]]True.*//\')"" #Remove all spaces tabs and the word true\n    target_snapshot_ident=""$( echo ""$source_snapshot_ident"" | sed \'s/.*:snapshot:rds:.//\')snapshotcopy$num"" #Name of target snapshot with incrementing number\n    ((num++))\n\n    aws --profile ""${aws_profile}"" --region ""${aws_dest_region}"" rds copy-db-snapshot \\\n      --source-db-snapshot-identifier ""${source_snapshot_ident}"" \\\n      --target-db-snapshot-identifier ""${target_snapshot_ident}"" \\\n      --source-region ""${aws_source_region}"" \\\n      --kms-key-id ""${aws_kms_key_id}""   \nfi \ndone\n']"
318,3042,2978,CC BY-SA 3.0,2018-01-08T16:05:49.950,"<p>I found a solution using file globs.  Since I have a configuration file for each site, I can simply use the list of those files to iterate over all of them.   That way I don't have the list of sites in my task file even once, let alone twice.   All I need to do to add a site is add a file.</p>

<p>To make things a little easier I created a directory for the templates:</p>

<ul>
<li><code>roles/webserver/templates/apache-sites/sitea.conf.j2</code></li>
<li><code>roles/webserver/templates/apache-sites/siteb.conf.j2</code></li>
<li><code>roles/webserver/templates/apache-sites/sitec.conf.j2</code></li>
<li><code>roles/webserver/templates/apache-sites/sited.conf.j2</code></li>
</ul>

<p>Then in <code>roles/webserver/tasks/main.yml</code> I can use that list of files and some regular expressions:</p>

<pre><code>---
- block:
  - name: Install apache site conf
    template: src={{item}} dest=/etc/apache2/sites-available/{{item|regex_replace("".*/"","""")|regex_replace(""\.j2$"","""")}} mode=0644
    with_fileglob:
    - ""roles/webserver/templates/apache-sites/*""
  - name: Enable site apache conf
    command: a2ensite {{item|regex_replace("".*/"","""")|regex_replace(""\.conf\.j2$"","""")}}
    args:
      creates: /etc/apache2/sites-enabled/{{item|regex_replace("".*/"","""")|regex_replace(""\.j2$"","""")}}
    with_fileglob:
    - ""roles/webserver/templates/apache-sites/*""
  become: yes
</code></pre>

<p>This technique could even be used with empty dummy files to create a list for other applications.</p>
",5842,2018-01-08T16:24:58.400,"['---\n- block:\n  - name: Install apache site conf\n    template: src={{item}} dest=/etc/apache2/sites-available/{{item|regex_replace("".*/"","""")|regex_replace(""\\.j2$"","""")}} mode=0644\n    with_fileglob:\n    - ""roles/webserver/templates/apache-sites/*""\n  - name: Enable site apache conf\n    command: a2ensite {{item|regex_replace("".*/"","""")|regex_replace(""\\.conf\\.j2$"","""")}}\n    args:\n      creates: /etc/apache2/sites-enabled/{{item|regex_replace("".*/"","""")|regex_replace(""\\.j2$"","""")}}\n    with_fileglob:\n    - ""roles/webserver/templates/apache-sites/*""\n  become: yes\n']"
319,3048,3040,CC BY-SA 3.0,2018-01-09T10:17:16.730,"<p>It seems ther reason for this was that the SMB connections would disconnect.
using </p>

<pre><code>net config server /autodisconnect:-1
</code></pre>

<p>in a ""run as administrator"" command window fixed it.</p>

<p>as explained here:
<a href=""https://www.vagrantup.com/docs/synced-folders/smb.html#preventing-idle-disconnects"" rel=""nofollow noreferrer"">https://www.vagrantup.com/docs/synced-folders/smb.html#preventing-idle-disconnects</a></p>
",5994,2018-01-09T10:17:16.730,['net config server /autodisconnect:-1\n']
320,3074,3069,CC BY-SA 3.0,2018-01-12T17:41:24.810,"<p>Variables are static, literal inputs to your configuration that come from either the command line or from <code>tfvars</code> files. It is not possible to use interpolations here, since the variable values are processed before interpolation begins in order to make them available to other expressions.</p>

<hr>

<p>If the goal is to define the S3 bucket name in one place and re-use it several times in the same configuration, the <em><a href=""https://www.terraform.io/docs/configuration/locals.html"" rel=""nofollow noreferrer"">Local Values</a></em> feature can do this if you are using Terraform v0.10.4 or newer. You can declare the named value in one of your <code>.tf</code> files:</p>

<pre><code>locals {
  s3_bucket_name = ""tf-${terraform.workspace}""
}
</code></pre>

<p>You can then interpolate this value in various places in your configuration using the name <code>local.s3_bucket_name</code>, like this:</p>

<pre><code>resource ""aws_s3_bucket"" ""s3"" {
  bucket = ""${local.s3_bucket_name}""
  ...
}
</code></pre>

<p>Local values are conceptually similar to <a href=""https://www.terraform.io/docs/configuration/outputs.html"" rel=""nofollow noreferrer"">module outputs</a> but they are exposed within the same module they are defined in, rather than passing a value up to the parent module.</p>

<hr>

<p>If the goal is to allow this generated default name to be overriden optionally by a variable, then that can be achieved with some conditional logic:</p>

<pre><code>variable ""override_s3_bucket_name"" {
  default = """"
}

locals {
  s3_bucket_name = ""${var.override_s3_bucket_name != """" ? var.override_s3_bucket_name : ""tf-${terraform.workspace}""}""
}

resource ""aws_s3_bucket"" ""s3"" {
  bucket = ""${local.s3_bucket_name}""
  ...
}
</code></pre>

<p>The above will generate a default name based on the selected workspace if <code>override_s3_bucket_name</code> is not set, but if that variable is set then its value will be used instead.</p>
",2463,2018-01-12T17:41:24.810,"['locals {\n  s3_bucket_name = ""tf-${terraform.workspace}""\n}\n', 'resource ""aws_s3_bucket"" ""s3"" {\n  bucket = ""${local.s3_bucket_name}""\n  ...\n}\n', 'variable ""override_s3_bucket_name"" {\n  default = """"\n}\n\nlocals {\n  s3_bucket_name = ""${var.override_s3_bucket_name != """" ? var.override_s3_bucket_name : ""tf-${terraform.workspace}""}""\n}\n\nresource ""aws_s3_bucket"" ""s3"" {\n  bucket = ""${local.s3_bucket_name}""\n  ...\n}\n']"
321,3077,3071,CC BY-SA 3.0,2018-01-13T17:02:01.197,"<p>As mentioned in the question and the comments on it, this isn't an area in which Ansible excels.  The ""best"" solution depends a bit on the type of file you're dealing with, and the structure of it.</p>

<p>The cleanest way to deal with these sorts of changes in Ansible is to <a href=""https://docs.ansible.com/ansible/latest/template_module.html"" rel=""nofollow noreferrer"">templatize</a> the entire thing; this allows you to see the entire file at once, rather than piecing it together through many places, and is much less fragile than pattern- or line-based approaches.  When you need to add configuration in multiple places (for instance, different roles), that's when dynamic-loading directives become very useful, like Apache httpd's <code>Include</code>:</p>

<pre><code>Include /etc/httpd/conf.d/*.conf
</code></pre>

<p>This then allows you to write individual configuration files from different places, and let the client software concatenate them.  However, as far as I can tell from a quick search, Tomcat doesn't support this, so you would need to operate with a single template file.</p>

<p><code>lineinfile</code> is a hacky solution that's very fragile, and <code>template</code> is almost always a better option.  However, in this case, the node that you're adding is a self-closing one, so as long as it is top-level, it can go anywhere and <code>lineinfile</code> will work (I know you say it won't, but I'll get back to that).  <code>xml</code> is a similar option that's a bit less fragile.</p>

<p>Those two you've ruled out because they can't delete the comment you have in the file.  However, I'll argue that that's an improper requirement (in most cases, and probably yours).</p>

<p>When using a configuration management tool, the source of truth shifts from the files themselves on servers to the configuration that's checked in to master.  If someone wants to edit the file, they'll do so by editing the configuration management scripts, not by editing the file directly on the server.  Therefore, there is no need for comments in the resultant file that lives on the server, except perhaps one at the top that says ""this is auto-generated, go look at source control instead"".  The comment should be <em>in your templating code</em> - and as long as the result compiles and works correctly, you shouldn't care at all what it looks like.</p>
",960,2018-01-13T17:02:01.197,['Include /etc/httpd/conf.d/*.conf\n']
322,3078,2969,CC BY-SA 3.0,2018-01-13T17:41:12.197,"<p>If an extra variable is truly required, you can add <a href=""https://docs.ansible.com/ansible/latest/assert_module.html"" rel=""nofollow noreferrer""><code>assert</code></a> statements at the top of the role to stop it from executing if they're not defined:</p>

<pre><code>┌─[jamesph@geror] - [~/temp] - [Sat Jan 13, 09:40]
└─[$]&gt; cat assert.yml
- hosts: localhost
  vars:
    foo: False
  tasks:
    - assert:
        that:
          - ""foo is defined""
          - ""bar is defined""
┌─[jamesph@geror] - [~/temp] - [Sat Jan 13, 09:40]
└─[$]&gt; ansible-playbook assert.yml
 [WARNING]: Unable to parse /etc/ansible/hosts as an inventory source

 [WARNING]: No inventory was parsed, only implicit localhost is available

 [WARNING]: Could not match supplied host pattern, ignoring: all

 [WARNING]: provided hosts list is empty, only localhost is available


PLAY [localhost] *************************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [localhost]

TASK [assert] ****************************************************************************************
fatal: [localhost]: FAILED! =&gt; {
    ""assertion"": ""bar is defined"",
    ""changed"": false,
    ""evaluated_to"": false
}
    to retry, use: --limit @/Users/jamesph/temp/assert.retry

PLAY RECAP *******************************************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=1
</code></pre>
",960,2018-01-13T17:41:12.197,"['┌─[jamesph@geror] - [~/temp] - [Sat Jan 13, 09:40]\n└─[$]> cat assert.yml\n- hosts: localhost\n  vars:\n    foo: False\n  tasks:\n    - assert:\n        that:\n          - ""foo is defined""\n          - ""bar is defined""\n┌─[jamesph@geror] - [~/temp] - [Sat Jan 13, 09:40]\n└─[$]> ansible-playbook assert.yml\n [WARNING]: Unable to parse /etc/ansible/hosts as an inventory source\n\n [WARNING]: No inventory was parsed, only implicit localhost is available\n\n [WARNING]: Could not match supplied host pattern, ignoring: all\n\n [WARNING]: provided hosts list is empty, only localhost is available\n\n\nPLAY [localhost] *************************************************************************************\n\nTASK [Gathering Facts] *******************************************************************************\nok: [localhost]\n\nTASK [assert] ****************************************************************************************\nfatal: [localhost]: FAILED! => {\n    ""assertion"": ""bar is defined"",\n    ""changed"": false,\n    ""evaluated_to"": false\n}\n    to retry, use: --limit @/Users/jamesph/temp/assert.retry\n\nPLAY RECAP *******************************************************************************************\nlocalhost                  : ok=1    changed=0    unreachable=0    failed=1\n']"
323,3079,2978,CC BY-SA 3.0,2018-01-13T18:11:57.770,"<p>Konstantin gave a good answer; here is an additional flavor on it.</p>

<p>I will commonly define the lists as variables, and just write two separate loops over the same variable:</p>

<pre><code>┌─[jamesph@geror] - [~/temp] - [Sat Jan 13, 10:06]
└─[$]&gt; cat loops-1.yml
- hosts: localhost
  gather_facts: no
  vars:
    menu:
      - Egg and Spam
      - Spam, bacon, sausage and Spam
      - Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam
  tasks:
    - debug:
        msg: ""We have {{ item }}""
      with_items: ""{{ menu }}""
    - debug:
        msg: ""I love {{ item }}!""
      with_items: ""{{ menu }}""
┌─[jamesph@geror] - [~/temp] - [Sat Jan 13, 10:06]
└─[$]&gt; ansible-playbook loops-1.yml
 [WARNING]: Unable to parse /etc/ansible/hosts as an inventory source

 [WARNING]: No inventory was parsed, only implicit localhost is available

 [WARNING]: Could not match supplied host pattern, ignoring: all

 [WARNING]: provided hosts list is empty, only localhost is available


PLAY [localhost] **********************************************************************************************************************

TASK [debug] **************************************************************************************************************************
ok: [localhost] =&gt; (item=Egg and Spam) =&gt; {
    ""changed"": false,
    ""item"": ""Egg and Spam"",
    ""msg"": ""We have Egg and Spam""
}
ok: [localhost] =&gt; (item=Spam, bacon, sausage and Spam) =&gt; {
    ""changed"": false,
    ""item"": ""Spam, bacon, sausage and Spam"",
    ""msg"": ""We have Spam, bacon, sausage and Spam""
}
ok: [localhost] =&gt; (item=Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam) =&gt; {
    ""changed"": false,
    ""item"": ""Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam"",
    ""msg"": ""We have Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam""
}

TASK [debug] **************************************************************************************************************************
ok: [localhost] =&gt; (item=Egg and Spam) =&gt; {
    ""changed"": false,
    ""item"": ""Egg and Spam"",
    ""msg"": ""I love Egg and Spam!""
}
ok: [localhost] =&gt; (item=Spam, bacon, sausage and Spam) =&gt; {
    ""changed"": false,
    ""item"": ""Spam, bacon, sausage and Spam"",
    ""msg"": ""I love Spam, bacon, sausage and Spam!""
}
ok: [localhost] =&gt; (item=Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam) =&gt; {
    ""changed"": false,
    ""item"": ""Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam"",
    ""msg"": ""I love Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam!""
}

PLAY RECAP ****************************************************************************************************************************
localhost                  : ok=2    changed=0    unreachable=0    failed=0
</code></pre>

<p>This works nicely with <a href=""https://docs.ansible.com/ansible/latest/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable"" rel=""nofollow noreferrer"">variable precedence</a>, for instance by defining different sets of servers per environment.  It also works when you need to perform various other non-looped tasks in-between the two loops.</p>
",960,2018-01-13T18:11:57.770,"['┌─[jamesph@geror] - [~/temp] - [Sat Jan 13, 10:06]\n└─[$]> cat loops-1.yml\n- hosts: localhost\n  gather_facts: no\n  vars:\n    menu:\n      - Egg and Spam\n      - Spam, bacon, sausage and Spam\n      - Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam\n  tasks:\n    - debug:\n        msg: ""We have {{ item }}""\n      with_items: ""{{ menu }}""\n    - debug:\n        msg: ""I love {{ item }}!""\n      with_items: ""{{ menu }}""\n┌─[jamesph@geror] - [~/temp] - [Sat Jan 13, 10:06]\n└─[$]> ansible-playbook loops-1.yml\n [WARNING]: Unable to parse /etc/ansible/hosts as an inventory source\n\n [WARNING]: No inventory was parsed, only implicit localhost is available\n\n [WARNING]: Could not match supplied host pattern, ignoring: all\n\n [WARNING]: provided hosts list is empty, only localhost is available\n\n\nPLAY [localhost] **********************************************************************************************************************\n\nTASK [debug] **************************************************************************************************************************\nok: [localhost] => (item=Egg and Spam) => {\n    ""changed"": false,\n    ""item"": ""Egg and Spam"",\n    ""msg"": ""We have Egg and Spam""\n}\nok: [localhost] => (item=Spam, bacon, sausage and Spam) => {\n    ""changed"": false,\n    ""item"": ""Spam, bacon, sausage and Spam"",\n    ""msg"": ""We have Spam, bacon, sausage and Spam""\n}\nok: [localhost] => (item=Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam) => {\n    ""changed"": false,\n    ""item"": ""Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam"",\n    ""msg"": ""We have Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam""\n}\n\nTASK [debug] **************************************************************************************************************************\nok: [localhost] => (item=Egg and Spam) => {\n    ""changed"": false,\n    ""item"": ""Egg and Spam"",\n    ""msg"": ""I love Egg and Spam!""\n}\nok: [localhost] => (item=Spam, bacon, sausage and Spam) => {\n    ""changed"": false,\n    ""item"": ""Spam, bacon, sausage and Spam"",\n    ""msg"": ""I love Spam, bacon, sausage and Spam!""\n}\nok: [localhost] => (item=Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam) => {\n    ""changed"": false,\n    ""item"": ""Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam"",\n    ""msg"": ""I love Spam, Spam, Spam, Spam, Spam, Spam, baked beans, Spam, Spam, Spam and Spam!""\n}\n\nPLAY RECAP ****************************************************************************************************************************\nlocalhost                  : ok=2    changed=0    unreachable=0    failed=0\n']"
324,3085,3083,CC BY-SA 3.0,2018-01-16T06:05:06.790,"<p>SELinux prevent the docker filesystem to work in the intended way, to fix this issue just add the :Z flag at the end of the volume declaration. It goes something like this:</p>

<pre><code>docker run -d -p 8080:80 -v {my_php_app_path}:/var/www/html:Z nimmis/apache-php7
</code></pre>
",6089,2018-01-16T06:05:06.790,['docker run -d -p 8080:80 -v {my_php_app_path}:/var/www/html:Z nimmis/apache-php7\n']
325,3090,3073,CC BY-SA 3.0,2018-01-16T23:45:09.720,"<p>Managed to solve it with the following code:</p>

<pre><code>pipeline {
    agent { label ""master""}
    stages {
        stage('1') {
            steps {
                script {
                    def tests = [:]
                    for (f in findFiles(glob: '**/html/*.html')) {
                        tests[""${f}""] = {
                            node {
                                stage(""${f}"") {
                                    echo '${f}'
                                }
                            }
                        }
                    }
                    parallel tests
                }
            }
        }       
    }
}
</code></pre>
",6066,2018-04-16T09:41:07.233,"['pipeline {\n    agent { label ""master""}\n    stages {\n        stage(\'1\') {\n            steps {\n                script {\n                    def tests = [:]\n                    for (f in findFiles(glob: \'**/html/*.html\')) {\n                        tests[""${f}""] = {\n                            node {\n                                stage(""${f}"") {\n                                    echo \'${f}\'\n                                }\n                            }\n                        }\n                    }\n                    parallel tests\n                }\n            }\n        }       \n    }\n}\n']"
326,3107,3104,CC BY-SA 4.0,2018-01-17T16:54:47.053,"<p>You can execute the safeRestart command using either the Jenkins Rest API (<em>[jenkins_url]/safeRestart</em>) or you can execute the command via the <a href=""https://wiki.jenkins.io/display/JENKINS/Jenkins+CLI"" rel=""noreferrer"">Jenkins CLI</a>.</p>

<pre><code>sudo /etc/init.d/jenkins safeRestart
</code></pre>

<blockquote>
  <p>Running a CLI command </p>
  
  <p>The general syntax is as follows (the design is
  similar to tools like svn/git):</p>
  
  <p>java -jar jenkins-cli.jar [-s JENKINS_URL] command [options...]
  [arguments...] </p>
  
  <p>JENKINS_URL can be specified via the environment
  variable $JENKINS_URL. This environment variable is automatically set
  when Jenkins fork a process during builds, which allows you to use
  Jenkins CLI from inside the build without explicitly configuring the
  URL.</p>
</blockquote>

<p>NOTE: When running the safeRestart command, any jobs set to be executed during the restart will be queued up and executed when the server is back online. Make sure this does not cause any conflicts upon reboot!</p>
",4328,2018-07-16T14:03:14.520,['sudo /etc/init.d/jenkins safeRestart\n']
327,3108,3102,CC BY-SA 3.0,2018-01-17T22:39:00.873,"<p>From <a href=""https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_passrole.html"" rel=""noreferrer"">Granting a User Permissions to Pass a Role to an AWS Service</a>:</p>

<blockquote>
  <p>To pass a role (and its permissions) to an AWS service, a user must
  have permissions to <em>pass the role</em> to the service. This helps
  administrators ensure that only approved users can configure a service
  with a role that grants permissions. To allow a user to pass a role to
  an AWS service, you must grant the <code>PassRole</code> permission to the user's
  IAM user, role, or group.</p>
  
  <p>When a user passes a role ARN as a parameter to any API that uses the
  role to assign permissions to the service, the service checks whether
  that user has the <code>iam:PassRole</code> permission. To limit the user to
  passing only approved roles, you can filter the <code>iam:PassRole</code>
  permission with the <code>Resources</code> element of the IAM policy statement.</p>
</blockquote>

<p>Is this what you're looking for? </p>

<p>An example from the above-metioned page:</p>

<blockquote>
  <p>Example 1</p>
  
  <p>Imagine that you want to grant a user the ability to pass any of an
  approved set of roles to the Amazon EC2 service upon launching an
  instance. You need three elements:</p>
  
  <ul>
  <li><p>An IAM <em>permissions policy</em> attached to the role that determines what the role can do. Scope permissions to only the actions that the role
  needs to perform, and to only the resources that the role needs for
  those actions. You can use AWS managed or customer-created IAM
  permissions policy.</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": {
        ""Effect"": ""Allow"",
        ""Action"": [ ""A list of the permissions the role is allowed to use"" ],
        ""Resource"": [ ""A list of the resources the role is allowed to access"" ]
    }
} 
</code></pre></li>
  <li><p>A <em>trust policy</em> for the role that allows the service to assume the role. For example, you could attach the following trust policy to the
  role with the <code>UpdateAssumeRolePolicy</code> action. This trust policy allows
  Amazon EC2 to use the role and the permissions attached to the role.</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": {
        ""Sid"": ""TrustPolicyStatementThatAllowsEC2ServiceToAssumeTheAttachedRole"",
        ""Effect"": ""Allow"",
        ""Principal"": { ""Service"": ""ec2.amazonaws.com"" },
       ""Action"": ""sts:AssumeRole""
    }
}       
</code></pre></li>
  <li><p>An IAM <em>permissions policy</em> attached to the IAM user that allows the user to pass only those policies that are approved. <code>iam:PassRole</code>
  usually is accompanied by <code>iam:GetRole</code> so that the user can get the
  details of the role to be passed. In this example, the user can pass
  only roles that exist in the specified account with names that begin
  with <code>EC2-roles-for-XYZ-</code>:</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": [{
        ""Effect"": ""Allow"",
        ""Action"": [
            ""iam:GetRole"",
            ""iam:PassRole""
        ],
        ""Resource"": ""arn:aws:iam::&lt;account-id&gt;:role/EC2-roles-for-XYZ-*""
    }]
}
</code></pre></li>
  </ul>
  
  <p>Now the user can start an Amazon EC2 instance with an assigned role.
  Applications running on the instance can access temporary credentials
  for the role through the instance profile metadata. The permission
  policies attached to the role determine what the instance can do.</p>
</blockquote>

<p>The procedure(s) to attach a policy to a user/role (inlining it might work as well) are described in <a href=""https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_manage-attach-detach.html"" rel=""noreferrer"">Attaching and Detaching IAM Policies</a>:</p>

<blockquote>
  <p><strong>To attach a managed policy (console)</strong></p>
  
  <ol>
  <li><p>Sign in to the AWS Management Console and open the IAM console at <a href=""https://console.aws.amazon.com/iam/"" rel=""noreferrer"">https://console.aws.amazon.com/iam/</a>.</p></li>
  <li><p>In the navigation pane, choose <strong>Policies</strong>.</p></li>
  <li><p>In the list of policies, select the check box next to the name of the policy to attach. You can use the <strong>Filter</strong> menu and the search
  box to filter the list of policies.</p></li>
  <li><p>Choose <strong>Policy actions</strong>, and then choose <strong>Attach</strong>.</p></li>
  <li><p>Select one or more identities to attach the policy to. You can use the <strong>Filter</strong> menu and the search box to filter the list of principal
  entities. After selecting the identities, choose <strong>Attach policy</strong>.</p></li>
  </ol>
</blockquote>

<p>...</p>

<blockquote>
  <p><strong>To embed an inline policy for a user or role (console)</strong></p>
  
  <ol>
  <li><p>Sign in to the AWS Management Console and open the IAM console at <a href=""https://console.aws.amazon.com/iam/"" rel=""noreferrer"">https://console.aws.amazon.com/iam/</a>.</p></li>
  <li><p>In the navigation pane, choose <strong>Users</strong> or <strong>Roles</strong>.</p></li>
  <li><p>In the list, choose the name of the user or role to embed a policy in.</p></li>
  <li><p>Choose the <strong>Permissions</strong> tab.</p></li>
  <li><p>Scroll to the bottom of the page and choose <strong>Add inline policy</strong>.</p>
  
  <p><strong>Note</strong></p>
  
  <p>You cannot embed an inline policy in a <a href=""https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_terms-and-concepts.html#iam-term-service-linked-role"" rel=""noreferrer"">service-linked role</a> in IAM. Because the linked service defines whether you can modify the
  permissions of the role, you might be able to add additional policies
  from the service console, API, or AWS CLI. To view the service-linked
  role documentation for a service, see <a href=""https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_aws-services-that-work-with-iam.html"" rel=""noreferrer"">AWS Services That Work with
  IAM</a> and choose <strong>Yes</strong> in the <strong>Service-Linked Role</strong> column for
  your service.</p></li>
  <li><p>Choose from the following methods to view the steps required to create your policy:</p>
  
  <ul>
  <li><p><a href=""https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_create.html#access_policies_create-copy"" rel=""noreferrer"">Import an Existing Managed Policy</a> – You can import a managed policy within your account and then edit the policy to customize it to
  your specific requirements. A managed policy can be an AWS managed
  policy or a customer managed policy that you created previously.</p></li>
  <li><p><a href=""https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_create.html#access_policies_create-visual-editor"" rel=""noreferrer"">Create a Policy with the Visual Editor</a> – You can construct a new policy from scratch in the visual editor. If you use the visual
  editor, you do not have to understand JSON syntax.</p></li>
  <li><p><a href=""https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_create.html#access_policies_create-json-editor"" rel=""noreferrer"">Create a Policy on the JSON Tab</a> – In the JSON tab, you can use <strong>JSON</strong> syntax to create a policy. You can type a new JSON policy document or paste an <a href=""https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_examples.html"" rel=""noreferrer"">example policy</a>.</p></li>
  </ul></li>
  <li><p>After you create an inline policy, it is automatically embedded in your user or role.</p></li>
  </ol>
</blockquote>
",47,2018-01-18T03:55:40.463,"['{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": {\n        ""Effect"": ""Allow"",\n        ""Action"": [ ""A list of the permissions the role is allowed to use"" ],\n        ""Resource"": [ ""A list of the resources the role is allowed to access"" ]\n    }\n} \n', '{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": {\n        ""Sid"": ""TrustPolicyStatementThatAllowsEC2ServiceToAssumeTheAttachedRole"",\n        ""Effect"": ""Allow"",\n        ""Principal"": { ""Service"": ""ec2.amazonaws.com"" },\n       ""Action"": ""sts:AssumeRole""\n    }\n}       \n', '{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [{\n        ""Effect"": ""Allow"",\n        ""Action"": [\n            ""iam:GetRole"",\n            ""iam:PassRole""\n        ],\n        ""Resource"": ""arn:aws:iam::<account-id>:role/EC2-roles-for-XYZ-*""\n    }]\n}\n']"
328,3128,3127,CC BY-SA 3.0,2018-01-19T19:26:12.683,"<p>According to the help menu, the recursive option does not seem to exist.</p>

<pre><code>user@localhost ~ $ kubectl cp --help
Copy files and directories to and from containers.

Examples:
  # !!!Important Note!!!
  # Requires that the 'tar' binary is present in your container
  # image.  If 'tar' is not present, 'kubectl cp' will fail.

  # Copy /tmp/foo_dir local directory to /tmp/bar_dir in a remote pod in the default namespace
  kubectl cp /tmp/foo_dir &lt;some-pod&gt;:/tmp/bar_dir

  # Copy /tmp/foo local file to /tmp/bar in a remote pod in a specific container
  kubectl cp /tmp/foo &lt;some-pod&gt;:/tmp/bar -c &lt;specific-container&gt;

  # Copy /tmp/foo local file to /tmp/bar in a remote pod in namespace &lt;some-namespace&gt;
  kubectl cp /tmp/foo &lt;some-namespace&gt;/&lt;some-pod&gt;:/tmp/bar

  # Copy /tmp/foo from a remote pod to /tmp/bar locally
  kubectl cp &lt;some-namespace&gt;/&lt;some-pod&gt;:/tmp/foo /tmp/bar

Options:
  -c, --container='': Container name. If omitted, the first container in the pod will be chosen

Usage:
  kubectl cp &lt;file-spec-src&gt; &lt;file-spec-dest&gt; [options]

Use ""kubectl options"" for a list of global command-line options (applies to all commands).
</code></pre>

<p>In order to copy files recursively, all files could be put in a directory and when this folder is copied to the pod, all files were copied:</p>
",210,2018-01-19T19:55:12.837,"['user@localhost ~ $ kubectl cp --help\nCopy files and directories to and from containers.\n\nExamples:\n  # !!!Important Note!!!\n  # Requires that the \'tar\' binary is present in your container\n  # image.  If \'tar\' is not present, \'kubectl cp\' will fail.\n\n  # Copy /tmp/foo_dir local directory to /tmp/bar_dir in a remote pod in the default namespace\n  kubectl cp /tmp/foo_dir <some-pod>:/tmp/bar_dir\n\n  # Copy /tmp/foo local file to /tmp/bar in a remote pod in a specific container\n  kubectl cp /tmp/foo <some-pod>:/tmp/bar -c <specific-container>\n\n  # Copy /tmp/foo local file to /tmp/bar in a remote pod in namespace <some-namespace>\n  kubectl cp /tmp/foo <some-namespace>/<some-pod>:/tmp/bar\n\n  # Copy /tmp/foo from a remote pod to /tmp/bar locally\n  kubectl cp <some-namespace>/<some-pod>:/tmp/foo /tmp/bar\n\nOptions:\n  -c, --container=\'\': Container name. If omitted, the first container in the pod will be chosen\n\nUsage:\n  kubectl cp <file-spec-src> <file-spec-dest> [options]\n\nUse ""kubectl options"" for a list of global command-line options (applies to all commands).\n']"
329,3132,3081,CC BY-SA 3.0,2018-01-20T16:50:28.277,"<p>You have two arguments that are empty:</p>

<pre><code>&lt;application-desc main-class=""hudson.remoting.jnlp.Main""&gt;
  &lt;argument&gt;32ba31ca5f150c2b3491802b0b60e56574d970a9e601cebad656a113fe325a85&lt;/argument&gt;
  &lt;argument&gt;FQDNofWindowsSlave&lt;/argument&gt;
  &lt;argument&gt;-workDir&lt;/argument&gt;
  &lt;argument/&gt;
  &lt;argument&gt;-internalDir&lt;/argument&gt;
  &lt;argument/&gt;
  &lt;argument&gt;-url&lt;/argument&gt;
  &lt;argument&gt;http://FQDNofJenkinsServer:8080/&lt;/argument&gt;
&lt;/application-desc&gt;
</code></pre>

<p>Your error message has a comma in it:</p>

<blockquote>
  <p>BadFieldException[ The field  has an
  invalid value: ,]</p>
</blockquote>

<p>Other bad argument error messages on the internet have comma separated lists of bad arguments: </p>

<blockquote>
  <p>BadFieldException[ The field codebase has an invalid value:
  $$codebase,$$codebase]</p>
</blockquote>

<p>So I'd guess those two empty arguments are the problem. </p>
",6184,2018-01-20T16:50:28.277,"['<application-desc main-class=""hudson.remoting.jnlp.Main"">\n  <argument>32ba31ca5f150c2b3491802b0b60e56574d970a9e601cebad656a113fe325a85</argument>\n  <argument>FQDNofWindowsSlave</argument>\n  <argument>-workDir</argument>\n  <argument/>\n  <argument>-internalDir</argument>\n  <argument/>\n  <argument>-url</argument>\n  <argument>http://FQDNofJenkinsServer:8080/</argument>\n</application-desc>\n']"
330,3138,3126,CC BY-SA 3.0,2018-01-21T13:55:30.403,"<p>I was able to find the root of issue. The problem was in the configuration of salt master. After every change of reactor config, I must run <code>salt-call state.highstate</code> command on master to sync reactor source code changes with it. I missed this step and thus my reactor config differed from my original source code in IDE. So once I ran mentioned command, everything became in sync. Thanks everybody for help! </p>

<p>P.S. regarding mentioned error, it occurred because I used kwarg in dev.sls for pillar and represented pillar as list: </p>

<pre><code>&gt;     kwarg:
&gt;      - pillar:
&gt;          temp_var_transmit: {{ payload }}
</code></pre>

<p>Kwarg can not contain a list in this case. It may contain key:value format only. So the correct way is either use without kwarg as I did or remove hyphen near pillar.</p>
",3899,2018-01-21T14:04:10.993,['>     kwarg:\n>      - pillar:\n>          temp_var_transmit: {{ payload }}\n']
331,3163,3155,CC BY-SA 3.0,2018-01-23T09:58:25.877,"<p>For Ubuntu 16.04 should be something like this</p>

<pre><code>tasks
- name: Install Certbot.
  package: ""name=letsencrypt state=present""
</code></pre>

<p>Or you can use a role from Github: <a href=""https://github.com/geerlingguy/ansible-role-certbot"" rel=""nofollow noreferrer"">https://github.com/geerlingguy/ansible-role-certbot</a></p>
",2285,2018-01-23T09:58:25.877,"['tasks\n- name: Install Certbot.\n  package: ""name=letsencrypt state=present""\n']"
332,3176,2048,CC BY-SA 3.0,2018-01-24T15:44:53.327,"<p>You need to follow these steps:</p>

<ul>
<li>Set <code>ECS_CLUSTER=devcluster</code> in <code>/etc/ecs/ecs.config</code></li>
<li>Stop all tasks/containers</li>
<li>Remove checkpoint file - <code>/var/lib/ecs/data/ecs_agent_data.json</code></li>
<li>Start ECS agent again as explained here - <a href=""https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-install.html"" rel=""noreferrer"">https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-agent-install.html</a></li>
</ul>

<p>To make sure it uses correct cluster, check logs - <code>docker logs ecs-agent</code>. It should have a message like:</p>

<pre><code>[INFO] Registration completed successfully. I am running as 'arn:aws:ecs:eu-west-1:ACCOUNT_ID:container-instance/CLUSTER_ID' in cluster 'devcluster'
</code></pre>
",6235,2018-01-24T15:52:54.710,"[""[INFO] Registration completed successfully. I am running as 'arn:aws:ecs:eu-west-1:ACCOUNT_ID:container-instance/CLUSTER_ID' in cluster 'devcluster'\n""]"
333,3180,2115,CC BY-SA 3.0,2018-01-25T00:17:57.223,"<p>The <code>aws_autoscaling_group</code> does support a list of tags now (<a href=""https://www.terraform.io/docs/providers/aws/r/autoscaling_group.html#tags"" rel=""nofollow noreferrer"">https://www.terraform.io/docs/providers/aws/r/autoscaling_group.html#tags</a>). But this looks a bit different to the syntax of other terraform resources:</p>

<pre><code>tags = [
  {
    key                 = ""explicit1""
    value               = ""value1""
    propagate_at_launch = true
  },
  {
    key                 = ""explicit2""
    value               = ""value2""
    propagate_at_launch = true
  },
]
</code></pre>

<p>This also allows to dynamically build tags via interpolation.</p>
",6108,2018-01-25T00:17:57.223,"['tags = [\n  {\n    key                 = ""explicit1""\n    value               = ""value1""\n    propagate_at_launch = true\n  },\n  {\n    key                 = ""explicit2""\n    value               = ""value2""\n    propagate_at_launch = true\n  },\n]\n']"
334,3183,3178,CC BY-SA 3.0,2018-01-25T10:53:19.527,"<p>After long playing with it and consulting on slack DevOps chat, I was able to figure it out. Here is a workable curl: </p>

<pre><code>curl -sSk -H \""Authorization: Bearer ${KUBE_TOKEN}\"" -H 'Content-Type: application/merge-patch+json' -X 'PATCH' $URL_NAME/api/v1/namespaces/kube-system/replicationcontrollers/kube-registry-v0 -d '{""spec"": {""replicas"":  1}}'
</code></pre>

<p>One of the important components here is ""<code>Content-Type: application/merge-patch+json</code>"" Without it specification, Kubernetes will not recognize data in API request correctly. </p>
",3899,2018-01-25T10:53:19.527,"['curl -sSk -H \\""Authorization: Bearer ${KUBE_TOKEN}\\"" -H \'Content-Type: application/merge-patch+json\' -X \'PATCH\' $URL_NAME/api/v1/namespaces/kube-system/replicationcontrollers/kube-registry-v0 -d \'{""spec"": {""replicas"":  1}}\'\n']"
335,3202,1538,CC BY-SA 3.0,2018-01-26T13:51:39.543,"<p>I have actually solved the problem by cloning repository directly in codebuild:</p>

<p>Pass GitHub token:</p>

<pre><code>      - { Name: GITHUB_TOKEN, Value: {Ref: GitHubToken } }
      - { Name: GITHUB_BRANCH, Value: {Ref: GitHubBranch } }
</code></pre>

<p>#
Execute git clone in install step:</p>

<pre><code>      - git clone --single-branch --depth=1 -b $GITHUB_BRANCH https://gitorgname:$GITHUB_TOKEN@github.com/gitorgname/reponame.git  src/reponame
</code></pre>

<p>I found that this solution is easier to implement, does not rely on Lambdas and even though performs two pulls, works quite reliably.</p>
",3498,2018-01-26T15:06:55.530,"['      - { Name: GITHUB_TOKEN, Value: {Ref: GitHubToken } }\n      - { Name: GITHUB_BRANCH, Value: {Ref: GitHubBranch } }\n', '      - git clone --single-branch --depth=1 -b $GITHUB_BRANCH https://gitorgname:$GITHUB_TOKEN@github.com/gitorgname/reponame.git  src/reponame\n']"
336,3204,2281,CC BY-SA 3.0,2018-01-26T16:50:32.010,"<p>Thanks for your conclusion, it fits in mine too. </p>

<p>In my situation, I have projects of different types like pure Java, .NET and some packaged in Docker. For the moment, the number of jobs to build is not consequent but I'm afraid about some jobs creation peak for specific project before a major release for example... </p>

<p>I only configured shared runner with tags (dotnet, java, docker,...) and the project specifies the correct tag in their .gitlab-ci.yml :</p>

<pre><code>job:
 tags:
  - java
</code></pre>

<p>If I detect/anticipate a peak of job creation, I can <a href=""https://docs.gitlab.com/ee/ci/runners/README.html#locking-a-specific-runner-from-being-enabled-for-other-projects"" rel=""nofollow noreferrer"">assign</a> temporary a runner to a project. Of course the peak detection and the lock/unlock can be automatized with <a href=""https://docs.gitlab.com/ce/api/runners.html"" rel=""nofollow noreferrer"">Runner API</a> but it's not my case for the moment.</p>
",5716,2018-01-26T16:50:32.010,['job:\n tags:\n  - java\n']
337,3208,3127,CC BY-SA 3.0,2018-01-26T23:14:14.493,"<p><code>kubectl cp</code> by default does recursive copies when given a directory, although it seems to be picky about trailing slashes.  If <code>foo</code> is the directory you'd like to copy, simply run</p>

<pre><code>kubectl cp /path/to/foo &lt;pod-id&gt;:/path/in/container/
</code></pre>
",960,2018-01-26T23:14:14.493,['kubectl cp /path/to/foo <pod-id>:/path/in/container/\n']
338,3209,3155,CC BY-SA 3.0,2018-01-26T23:26:26.700,"<p>Here is the direct Ansible translation of your bash install script:</p>

<pre><code>- apt_repository:
    repo: 'ppa:certbot/certbot'

- apt:
    name: ""{{ item }}""
    update_cache: yes
  with_items:
    - nginx
    - python-certbox-nginx
</code></pre>
",960,2018-01-26T23:26:26.700,"['- apt_repository:\n    repo: \'ppa:certbot/certbot\'\n\n- apt:\n    name: ""{{ item }}""\n    update_cache: yes\n  with_items:\n    - nginx\n    - python-certbox-nginx\n']"
339,3210,3186,CC BY-SA 3.0,2018-01-26T23:33:12.867,"<blockquote>
  <p>What does using a time series data store mean for CI?</p>
</blockquote>

<p>Nothing in the context of that job description.  CI and time series databases are separate entries in the list.  To put it another way:</p>

<pre><code>infrastructure_pieces = [
    'CI servers',
    'push button deploys',
    'time series data stores',
    'metrics dashboards',
    'centralized logging',
]

for infrastructure_piece in infrastructure_pieces:
    assert(candidate.important_of(infrastructure_piece) == 'CRITICAL')
</code></pre>

<p>That is, the job involves maintaining CI, but it also involves monitoring production servers and applications using TSDBs, and various other activities.</p>
",960,2018-01-26T23:33:12.867,"[""infrastructure_pieces = [\n    'CI servers',\n    'push button deploys',\n    'time series data stores',\n    'metrics dashboards',\n    'centralized logging',\n]\n\nfor infrastructure_piece in infrastructure_pieces:\n    assert(candidate.important_of(infrastructure_piece) == 'CRITICAL')\n""]"
340,3214,3213,CC BY-SA 3.0,2018-01-29T12:03:13.863,"<p><code>crond.yml</code> in your example is not a playbook. It is a tasks file (list of tasks), while playbook is a list of plays.</p>

<p>A play must have <code>hosts</code> directive at minimum. Please see <a href=""http://docs.ansible.com/ansible/latest/playbooks_intro.html#hosts-and-users"" rel=""nofollow noreferrer"">http://docs.ansible.com/ansible/latest/playbooks_intro.html#hosts-and-users</a></p>

<p>This is a playbook:</p>

<pre><code>- hosts: localhost
  tasks:
    - cron:
        user: ""root""
        minute: ""30""
        hour: ""02""
        job: '/usr/bin/rsync -avhz -e ""ssh"" --rsync-path=""sudo rsync"" -H --delete --numeric-ids &lt;ipaddress&gt;:""/data/rsnapshot-backups/&lt;ipaddress&gt;"" /data/rsnapshot-backup'
        state: present
</code></pre>
",3509,2018-01-29T12:24:52.073,"['- hosts: localhost\n  tasks:\n    - cron:\n        user: ""root""\n        minute: ""30""\n        hour: ""02""\n        job: \'/usr/bin/rsync -avhz -e ""ssh"" --rsync-path=""sudo rsync"" -H --delete --numeric-ids <ipaddress>:""/data/rsnapshot-backups/<ipaddress>"" /data/rsnapshot-backup\'\n        state: present\n']"
341,3216,3213,CC BY-SA 3.0,2018-01-29T13:40:46.927,"<p>I got around this by adding my crond.yml task to the global playbook and now call it via tags (ansible-playbook -vvv -i ""localhost,"" -c local site.yml --tags backups).</p>

<p>I added the cron_file section to define the location of the cron job as /etc/cron.d/rsync.cron rather than the root users crontab. I then added state: present to ensure that the cronjob exists on the server and doesn't delete other entries in the file.</p>

<p>I also updated the job section of the task to remove the '{{ }}' and replace with double quotes surrounding the command as well as '\'s around any double quoted strings like below:</p>

<pre><code>- cron:
    name: ""Copy all rsnapshot backups from &lt;hostname&gt;""
    minute: ""30""
    hour: ""02""
    job: ""/usr/bin/rsync -avhz -e \""ssh\"" --rsync-path=\""sudo rsync\"" -H --delete --numeric-ids &lt;ipaddress&gt;:\""/data/rsnapshot-backups/&lt;ipaddress&gt;\"" /data/rsnapshot-backup""
    user: root
    cron_file: rsync.cron
    state: present
</code></pre>
",3055,2018-01-29T14:30:48.940,"['- cron:\n    name: ""Copy all rsnapshot backups from <hostname>""\n    minute: ""30""\n    hour: ""02""\n    job: ""/usr/bin/rsync -avhz -e \\""ssh\\"" --rsync-path=\\""sudo rsync\\"" -H --delete --numeric-ids <ipaddress>:\\""/data/rsnapshot-backups/<ipaddress>\\"" /data/rsnapshot-backup""\n    user: root\n    cron_file: rsync.cron\n    state: present\n']"
342,3224,3177,CC BY-SA 3.0,2018-01-30T13:53:23.103,"<p>Make sure you connect your traefik instance to the client docker-network (as specified on the bottom of <a href=""https://docs.traefik.io/configuration/backends/docker/"" rel=""nofollow noreferrer"">this page</a>):</p>

<pre><code>When running inside a container, Træfik will need network access through:

docker network connect &lt;network&gt; &lt;traefik-container&gt;
</code></pre>
",6087,2018-01-30T13:53:23.103,"['When running inside a container, Træfik will need network access through:\n\ndocker network connect <network> <traefik-container>\n']"
343,3230,3229,CC BY-SA 3.0,2018-01-31T12:02:33.943,"<p>You can get to know if your site is up and running in the following way,</p>

<p>Map both the ports of inside container to the host using <strong>-p</strong> option and try to <code>curl localhost:port</code></p>

<p><em>Scenario:-</em></p>

<p>Run your container with the following command,</p>

<pre><code>docker run -d --name website -p 80:80 -p 22:22 mob
</code></pre>

<p>Explanation:-  <code>-p host_port:container's_port</code></p>

<p>Now, <code>curl localhost:80</code> or <code>localhost:22</code></p>

<p>If your service is running properly, you will have got the response</p>

<p>P.S:- Make sure nothing is running in 80 and 20 on host before running the <strong>docker run</strong> command</p>
",6325,2018-01-31T15:24:15.957,['docker run -d --name website -p 80:80 -p 22:22 mob\n']
344,3237,1935,CC BY-SA 3.0,2018-02-01T07:57:13.497,"<p>I also have the same idea(different config files for different pipeline).
I use the pipeline.properties to store my variable. </p>

<pre><code>properties = readProperties file: 'pipeline.properties'
echo ""Immediate one ${properties.repo}""
</code></pre>

<p><strong>Drawbacks:</strong>
Due to the groovy early evaluation problems. The value will be null when you use the ${properties.repo} in some shared library closure (eg, agent { label $properties.agentLabel }, the agentLabel will be null).</p>

<p>See:
<a href=""https://stackoverflow.com/questions/46630168/in-a-declarative-jenkins-pipeline-can-i-set-the-agent-label-dynamically"">https://stackoverflow.com/questions/46630168/in-a-declarative-jenkins-pipeline-can-i-set-the-agent-label-dynamically</a></p>

<p><a href=""http://jenkins-ci.361315.n4.nabble.com/can-i-use-variable-to-specify-the-agent-label-in-my-declarative-pipeline-td4897177.html"" rel=""nofollow noreferrer"">http://jenkins-ci.361315.n4.nabble.com/can-i-use-variable-to-specify-the-agent-label-in-my-declarative-pipeline-td4897177.html</a></p>
",6339,2018-02-01T07:57:13.497,"['properties = readProperties file: \'pipeline.properties\'\necho ""Immediate one ${properties.repo}""\n']"
345,3245,3244,CC BY-SA 3.0,2018-02-01T21:17:09.967,"<p>If your variable is <strong>not</strong> declared in Bamboo (either by injections, build/deploy variables etc.) it will <strong>not</strong> inject the variable and will use the string as is. It should only render the variable as an empty string if that is the value you set for that particular variable. As an example, my build plan has the following variables:</p>

<pre><code>Variable Name    Value
version.major    1
version.minor    12
</code></pre>

<p>In my build plan, I have the following script job:</p>

<pre><code>echo ""${bamboo.substituteVar}""
echo ""${bamboo.version.major}""
echo ""${bamboo.version.minor}""
</code></pre>

<p>In my logs, the output will be:</p>

<blockquote>
  <p>C:\Users\TestUser\bamboo-home\xml-data\build-dir\12345678\MANG-TC-TBV>echo
  ""${bamboo.substituteVar}""</p>
  
  <p>""${bamboo.substituteVar}""</p>
  
  <p>C:\Users\TestUser\bamboo-home\xml-data\build-dir\12345678\MANG-TC-TBV>echo ""1""</p>
  
  <p>""1""</p>
  
  <p>C:\Users\TestUser\bamboo-home\xml-data\build-dir\12345678\MANG-TC-TBV>echo ""12""</p>
  
  <p>""12""</p>
</blockquote>

<p>As long as your variables and namespaces are unique and descriptive for the plan you are working on, you should not have any issues with name conflicts. If it is replacing it with an empty string, my guess is that you may have that variable created somewhere in Bamboo, but no value assigned to it. </p>
",4328,2018-02-01T21:57:19.240,"['Variable Name    Value\nversion.major    1\nversion.minor    12\n', 'echo ""${bamboo.substituteVar}""\necho ""${bamboo.version.major}""\necho ""${bamboo.version.minor}""\n']"
346,3249,3244,CC BY-SA 3.0,2018-02-02T10:25:43.593,"<p>I don't know the inner of bamboo, but I assume it works like a bash script.</p>

<p>What happens is that variables are replaced before execution, in bash that would be <code>echo ""echo $VAR"" &gt; test.sh</code> and test.sh will only contain ""echo"" because VAR is replaced by it's value before the command is executed.<br>
If you want test.sh to contain <code>echo $VAR</code> you have to tell bash to ignore the replacement on the first call by escaping the $ sign:</p>

<p><code>echo ""echo \$var"" &gt; test.sh</code> will give <code>echo  $VAR</code> in the file.</p>

<p>In the same note, the notation <code>${VAR}</code> and <code>$VAR</code> are the same, using braces is a good practice when you do concatenation like in <code>echo ""Size is ${VAR}Kb""</code> as without the braces like this <code>$VARKb</code> bash would try to find a variable named <code>VARKb</code> and return an empty value.</p>

<p>To address PrestonM different behavior, I assume there's either
 - the fact running under windows with the powershell interpreter doesn't behave the same
 - or just that bamboo has a special case for variables prefixed with <code>bamboo.</code> and as such escape them.</p>

<p>If someone want to test you may try:</p>

<pre><code>echo ""${VAR}""
echo ""${bamboo.VAR}""
echo ""\${VAR}""
</code></pre>

<p>and edit the results in this answer.</p>
",13,2018-02-02T10:31:08.177,"['echo ""${VAR}""\necho ""${bamboo.VAR}""\necho ""\\${VAR}""\n']"
347,3259,3252,CC BY-SA 3.0,2018-02-03T09:04:25.690,"<p>One solution that might fit your scenario are <a href=""http://modules.sourceforge.net/"" rel=""nofollow noreferrer"">environment modules</a>. Given that you only need the compilers on Linux, and have access via a network share (nfs/Samba). To load a toolchain into your terminal, just type</p>

<pre><code>module load gcc
</code></pre>

<p>and let autocompletion fill in the version number. It is basically Python’s virtualenv for any Linux program/toolchain/SDK. I have used it extensively and can warmly recommend this tool.</p>

<p>Each compiler would have their own folder which is subdivided by version which allows you to have direct access to all versions. Configuration is defined server-side with PATH and other environment variables. User-side,  a bash script has to be installed into users’ <code>.bashrc</code></p>
",5879,2018-02-03T09:04:25.690,['module load gcc\n']
348,3269,3264,CC BY-SA 3.0,2018-02-06T13:40:27.197,"<p>To run ipconfig from the AWS Systems Manager Run Command:</p>

<pre><code>$ aws ssm send-command --document-name ""AWS-RunPowerShellScript"" --instance-ids ""&lt;your instance id&gt;"" --parameters commands=ipconfig
</code></pre>

<p><sup>Note: If you've got the error, consider specifying the right <code>--region</code>.</sup></p>

<p>This assumes you have your AWS credentials and CLI configured properly. See <a href=""https://docs.aws.amazon.com/systems-manager/latest/userguide/walkthrough-cli.html"" rel=""noreferrer"">Systems Manager Run Command Walkthrough Using the AWS CLI</a> for more information.</p>

<hr>

<p>Here is the practical shell command example of sending and getting the command output:</p>

<pre><code>cmdid=$(aws ssm send-command --instance-ids ""i-ch3ng3th1s"" --document-name ""AWS-RunPowerShellScript"" --parameters commands=ipconfig --query ""Command.CommandId"" --output text)
aws ssm list-command-invocations --command-id ""$cmdid"" --details --query ""CommandInvocations[*].CommandPlugins[*].Output[]"" --output text
</code></pre>
",6258,2018-02-06T15:47:59.173,"['$ aws ssm send-command --document-name ""AWS-RunPowerShellScript"" --instance-ids ""<your instance id>"" --parameters commands=ipconfig\n', 'cmdid=$(aws ssm send-command --instance-ids ""i-ch3ng3th1s"" --document-name ""AWS-RunPowerShellScript"" --parameters commands=ipconfig --query ""Command.CommandId"" --output text)\naws ssm list-command-invocations --command-id ""$cmdid"" --details --query ""CommandInvocations[*].CommandPlugins[*].Output[]"" --output text\n']"
349,3273,3272,CC BY-SA 3.0,2018-02-06T18:12:10.063,"<p>You have two mistakes:</p>

<ol>
<li><p><code>name</code> as parameter of <code>file</code> module. It is an alias of <code>path</code>, so you actually try to create directory <code>add dir</code>.</p></li>
<li><p>Unnecessary single quotes in <code>path</code>, giving you actual paths like <code>etc/ansible/roles/webservers/'handlers'</code>.</p></li>
</ol>

<p>Try with:</p>

<pre><code>...
- name: add dir
  file:
    path: '/etc/ansible/roles/webservers/{{ item }}'
...
</code></pre>
",3509,2018-02-06T18:12:10.063,"[""...\n- name: add dir\n  file:\n    path: '/etc/ansible/roles/webservers/{{ item }}'\n...\n""]"
350,3274,3253,CC BY-SA 4.0,2018-02-06T19:45:12.550,"<p>Thanks to this <a href=""https://stackoverflow.com/questions/46264954/connection-refused-while-connecting-to-upstream-when-using-nginx-as-reverse-prox"">question and answer here</a>, I was able realize that I had two issues going on:</p>

<ol>
<li>the containers have different default Docker networks because I am using two different docker-compose.yml files, I had envisioned my Ngnix proxy working independently from any of my API containers entirely, including the docker-compose, more on that issue below</li>
<li>the second issue is simply when I tried to proxy to 127.0.0.1:5023 that is localhost inside the Ngnix container, not the network outside of the Nginx proxy container</li>
</ol>

<p>So the different default networks being created by docker-compose for my Nginx proxy docker container and my api docker container are because I am using two different docker-compose.yml files. This is because I have Jenkins builds for many API microservices so the have independent docker-compose files and I needed a Nginx proxy to forward requests on port 80 to each microservice.</p>

<p>To test this out, created a docker-compose.yml for both containers, the API and the Nginx proxy:</p>

<pre><code>version: '3'

services:
  reverseproxy:
    build: 
      context: ./
      dockerfile: docker/nginxproxy/docker/Dockerfile
    image: tsl.devops.reverseproxy.image
    container_name: tsl.devops.reverseproxy.container
    ports:
      - ""80:80""
  apistaging:
    build: 
      context: ./
      dockerfile: docker/staging/Dockerfile
    image: tsl.api.example.image
    container_name: tsl.api.example.container
    ports:
      - ""5023:5023""
    environment: 
      ASPNETCORE_URLS: http://+:5023
</code></pre>

<p>Yes there was still an issue, the proxy pass to http//:127.0.0.1:5023, that forward remains in the Nginx Docker container and never finds the API running on the Docker host, I simply needed to use the docker-compose.yml service name to get to it:</p>

<pre><code>upstream accountstaging {
    server apistaging:5023;
}

server {

    listen 80;
    server_name account.staging.mysite.com;

    location / {
        proxy_pass         http://accountstaging;
        proxy_redirect     off;
        proxy_set_header   Host $host;
        proxy_set_header   X-Real-IP $remote_addr;
        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header   X-Forwarded-Host $server_name;
    }
}
</code></pre>
",4790,2018-09-07T18:35:21.580,"['version: \'3\'\n\nservices:\n  reverseproxy:\n    build: \n      context: ./\n      dockerfile: docker/nginxproxy/docker/Dockerfile\n    image: tsl.devops.reverseproxy.image\n    container_name: tsl.devops.reverseproxy.container\n    ports:\n      - ""80:80""\n  apistaging:\n    build: \n      context: ./\n      dockerfile: docker/staging/Dockerfile\n    image: tsl.api.example.image\n    container_name: tsl.api.example.container\n    ports:\n      - ""5023:5023""\n    environment: \n      ASPNETCORE_URLS: http://+:5023\n', 'upstream accountstaging {\n    server apistaging:5023;\n}\n\nserver {\n\n    listen 80;\n    server_name account.staging.mysite.com;\n\n    location / {\n        proxy_pass         http://accountstaging;\n        proxy_redirect     off;\n        proxy_set_header   Host $host;\n        proxy_set_header   X-Real-IP $remote_addr;\n        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header   X-Forwarded-Host $server_name;\n    }\n}\n']"
351,3287,3282,CC BY-SA 3.0,2018-02-07T12:58:23.790,"<p>This quite much goes to what internal policies you have on handling sensitive data. </p>

<p>I'd like to tell you my approach to this and explain what I see as pros and cons. I keep the Ansible Vault password in a file on the control machine and have a environment variable pointing to it:</p>

<pre><code>export ANSIBLE_VAULT_PASSWORD_FILE=/deep/dark/place
</code></pre>

<p>I have that on my workstation (as I need to test &amp; develop playbooks), some colleagues have it as well, and of course we have it on the main Ansible control machine. </p>

<p>Pros:</p>

<ul>
<li>not in a shared location/repository (it's a non versioned file as you say)</li>
<li>one does not need to know your Ansible vault password to run a play (this is under the condition that you have a CI tool, e.g. Jenkins, where you can easily launch playbooks) </li>
</ul>

<p>Cons:</p>

<ul>
<li>not easy to rotate the password</li>
<li>everyone who works on your playbooks needs to have it on his workstation</li>
</ul>

<p>The cons do have mitigations, but again it's up to the policies and rules you have adopted in you day to day operations. </p>
",775,2018-02-07T12:58:23.790,['export ANSIBLE_VAULT_PASSWORD_FILE=/deep/dark/place\n']
352,3292,3279,CC BY-SA 3.0,2018-02-07T18:01:27.193,"<p>Note: I didn't use this yet, the answer is based solely on documentation.</p>

<p>A GitlabCI pipeline can be triggered via API, see <a href=""https://docs.gitlab.com/ee/ci/triggers/"" rel=""nofollow noreferrer"">Triggering pipelines through the API</a>. </p>

<blockquote>
  <p>Triggers can be used to force a pipeline rerun of a specific <code>ref</code> (branch or tag) with an API call.</p>
</blockquote>

<p>You would first need to <a href=""https://docs.gitlab.com/ee/ci/triggers/#adding-a-new-trigger"" rel=""nofollow noreferrer"">create a trigger</a> for that pipeline.</p>

<p>Then you can <a href=""https://docs.gitlab.com/ee/ci/triggers/#triggering-a-pipeline"" rel=""nofollow noreferrer"">activate that trigger</a> (from your jenkins job in this case):</p>

<blockquote>
  <p>To trigger a job you need to send a <code>POST</code> request to GitLab's API
  endpoint:</p>

<pre><code>POST /projects/:id/trigger/pipeline
</code></pre>
  
  <p>The required parameters are the <a href=""https://docs.gitlab.com/ee/ci/triggers/#authentication-tokens"" rel=""nofollow noreferrer"">trigger's <code>token</code></a> and the Git
  <code>ref</code> on which the trigger will be performed. Valid refs are the
  branch and the tag.</p>
</blockquote>

<p>Such triggers support <a href=""https://docs.gitlab.com/ee/ci/triggers/#making-use-of-trigger-variables"" rel=""nofollow noreferrer"">variable passing</a>:</p>

<blockquote>
  <p>You can pass any number of arbitrary variables in the trigger API call
  and they will be available in GitLab CI so that they can be used in
  your <code>.gitlab-ci.yml</code> file. The parameter is of the form:</p>

<pre><code>variables[key]=value
</code></pre>
</blockquote>

<p>You can use the variables inside <code>.gitlab-ci.yml</code> like this:</p>

<blockquote>
<pre><code>upload_package:
  stage: package
  script:
  - if [ -n ""${UPLOAD_TO_S3}"" ]; then make upload; fi
</code></pre>
</blockquote>

<p>And</p>

<blockquote>
  <p>You can then trigger a rebuild while you pass the <code>UPLOAD_TO_S3</code>
  variable and the script of the <code>upload_package</code> job will run:</p>

<pre><code>curl --request POST \
  --form token=TOKEN \
  --form ref=master \
  --form ""variables[UPLOAD_TO_S3]=true"" \
  https://gitlab.example.com/api/v4/projects/9/trigger/pipeline
</code></pre>
</blockquote>

<p>This kind of POST requests is what you would to do in your jenkins job. But take a closer look at the triggers, you might find a way to do what you want without jenkins.</p>
",47,2018-02-07T18:01:27.193,"['POST /projects/:id/trigger/pipeline\n', 'variables[key]=value\n', 'upload_package:\n  stage: package\n  script:\n  - if [ -n ""${UPLOAD_TO_S3}"" ]; then make upload; fi\n', 'curl --request POST \\\n  --form token=TOKEN \\\n  --form ref=master \\\n  --form ""variables[UPLOAD_TO_S3]=true"" \\\n  https://gitlab.example.com/api/v4/projects/9/trigger/pipeline\n']"
353,3293,3290,CC BY-SA 3.0,2018-02-07T18:03:58.983,"<p>The following one-liner in shell works for me:</p>

<pre><code>aws ec2 describe-security-groups --group-ids $(aws ec2 describe-instances --instance-id $id --query ""Reservations[].Instances[].SecurityGroups[].GroupId[]"" --output text) --output text
</code></pre>

<p>Where <code>$id</code> is my instance-id.</p>
",3,2018-02-07T18:03:58.983,"['aws ec2 describe-security-groups --group-ids $(aws ec2 describe-instances --instance-id $id --query ""Reservations[].Instances[].SecurityGroups[].GroupId[]"" --output text) --output text\n']"
354,3297,3296,CC BY-SA 3.0,2018-02-07T22:03:22.777,"<p>The route table is associated with VPC, which is associated with the instance.</p>

<p>Given <code>$id</code> shell variable has the instance ID, e.g.</p>

<pre><code>id=i-0xyz # Replace i-0xyz with the real Instance ID.
</code></pre>

<p>here is the shell command to get VPCs associated with the instance and assign to <code>$vpcs</code> variable:</p>

<pre><code>vpcs=$(aws ec2 describe-instances --instance-id $id --query 'Reservations[].Instances[].NetworkInterfaces[].VpcId' --output text)
</code></pre>

<p>Then to list the route tables associated with VPC, run:</p>

<pre><code>aws ec2 describe-route-tables --filters ""Name=vpc-id,Values=$vpcs""
</code></pre>

<p>To get just the route ids, add: <code>--query ""RouteTables[].RouteTableId[]""</code> parameter.</p>
",3,2018-02-07T22:03:22.777,"['id=i-0xyz # Replace i-0xyz with the real Instance ID.\n', ""vpcs=$(aws ec2 describe-instances --instance-id $id --query 'Reservations[].Instances[].NetworkInterfaces[].VpcId' --output text)\n"", 'aws ec2 describe-route-tables --filters ""Name=vpc-id,Values=$vpcs""\n']"
355,3298,3296,CC BY-SA 3.0,2018-02-07T22:11:12.580,"<p>You can achieve this by determining which subnet the ec2 instance belongs to, then check which route table the subnet is associated with.</p>

<pre><code>#!/bin/bash

instanceId='YOU-INSTANCE-ID'

#finds the subnetId that the instance belongs to
subnetId=$(aws ec2 describe-instances \
           --instance-id $instanceId \
           --query ""Reservations[*].Instances[].SubnetId"" \
           --output text)

routingTableId=$(aws ec2 describe-route-tables \
                 --query ""RouteTables[*].Associations[?SubnetId=='$subnetId'].RouteTableId"" \
                 --output text)

echo $routingTableId
</code></pre>
",6412,2018-02-07T22:11:12.580,"['#!/bin/bash\n\ninstanceId=\'YOU-INSTANCE-ID\'\n\n#finds the subnetId that the instance belongs to\nsubnetId=$(aws ec2 describe-instances \\\n           --instance-id $instanceId \\\n           --query ""Reservations[*].Instances[].SubnetId"" \\\n           --output text)\n\nroutingTableId=$(aws ec2 describe-route-tables \\\n                 --query ""RouteTables[*].Associations[?SubnetId==\'$subnetId\'].RouteTableId"" \\\n                 --output text)\n\necho $routingTableId\n']"
356,3303,3262,CC BY-SA 3.0,2018-02-08T00:49:19.810,"<p>Indeed, releases don't appear to have been registered on GitHub, the <code>releases</code> list returned by the REST is empty, most likely explaining the 404 returned for <code>releases/latest</code>:</p>

<pre><code>curl -i https://api.github.com/repos/apache/tomcat/releases
HTTP/1.1 200 OK
...

[

]
</code></pre>

<p>There are however tags registered, including some apparently mapping to the 9.0.X versions:</p>

<pre><code>curl -i https://api.github.com/repos/apache/tomcat/tags | &amp; grep '""name""'
    ""name"": ""TONCAT_9_0_0_M23"",
    ""name"": ""TOMCAT_9_0_5"",
    ""name"": ""TOMCAT_9_0_4"",
    ""name"": ""TOMCAT_9_0_3"",
    ""name"": ""TOMCAT_9_0_2"",
    ""name"": ""TOMCAT_9_0_1"",
    ""name"": ""TOMCAT_9_0_0"",
    ""name"": ""TOMCAT_9_0_0_m27"",
    ...
    ""name"": ""TOMCAT_9_0_0_M6"",
</code></pre>

<p>Example of a tag info, which <em>might</em> be of use:</p>

<pre><code>  {
    ""name"": ""TOMCAT_9_0_5"",
    ""zipball_url"": ""https://api.github.com/repos/apache/tomcat/zipball/TOMCAT_9_0_5"",
    ""tarball_url"": ""https://api.github.com/repos/apache/tomcat/tarball/TOMCAT_9_0_5"",
    ""commit"": {
      ""sha"": ""e0fdefed3d9e2a4dbfd36a5a79e75e0eadaa201d"",
      ""url"": ""https://api.github.com/repos/apache/tomcat/commits/e0fdefed3d9e2a4dbfd36a5a79e75e0eadaa201d""
    }
  },
</code></pre>

<p>But the info doesn't appear consistent with the info on the Tomcat 
homepage you referenced: </p>

<ul>
<li>the <code>9.0.5</code> version isn't listed as released on the homepage</li>
<li>only <code>9.X</code> versions show up, older ones don't</li>
</ul>

<p>So I'm not sure if this is helpful.</p>
",47,2018-02-08T00:49:19.810,"['curl -i https://api.github.com/repos/apache/tomcat/releases\nHTTP/1.1 200 OK\n...\n\n[\n\n]\n', 'curl -i https://api.github.com/repos/apache/tomcat/tags | & grep \'""name""\'\n    ""name"": ""TONCAT_9_0_0_M23"",\n    ""name"": ""TOMCAT_9_0_5"",\n    ""name"": ""TOMCAT_9_0_4"",\n    ""name"": ""TOMCAT_9_0_3"",\n    ""name"": ""TOMCAT_9_0_2"",\n    ""name"": ""TOMCAT_9_0_1"",\n    ""name"": ""TOMCAT_9_0_0"",\n    ""name"": ""TOMCAT_9_0_0_m27"",\n    ...\n    ""name"": ""TOMCAT_9_0_0_M6"",\n', '  {\n    ""name"": ""TOMCAT_9_0_5"",\n    ""zipball_url"": ""https://api.github.com/repos/apache/tomcat/zipball/TOMCAT_9_0_5"",\n    ""tarball_url"": ""https://api.github.com/repos/apache/tomcat/tarball/TOMCAT_9_0_5"",\n    ""commit"": {\n      ""sha"": ""e0fdefed3d9e2a4dbfd36a5a79e75e0eadaa201d"",\n      ""url"": ""https://api.github.com/repos/apache/tomcat/commits/e0fdefed3d9e2a4dbfd36a5a79e75e0eadaa201d""\n    }\n  },\n']"
357,3308,3263,CC BY-SA 3.0,2018-02-08T15:11:09.540,"<p>This gives a short commit message</p>

<pre><code>git show -s $GIT_COMMIT --format=""format:%s""
</code></pre>

<p>I'd probably put this in the ""Excute shell"" command box</p>

<p>Hope this helps!</p>
",4954,2018-02-08T15:11:09.540,"['git show -s $GIT_COMMIT --format=""format:%s""\n']"
358,3310,2554,CC BY-SA 3.0,2018-02-08T15:31:04.630,"<p>If you install the manager webapp with a default set up of tomcat then it is possible to use this to install and restart applications, see </p>

<p><a href=""https://tomcat.apache.org/tomcat-7.0-doc/manager-howto.html#Reload_An_Existing_Application"" rel=""nofollow noreferrer"">https://tomcat.apache.org/tomcat-7.0-doc/manager-howto.html#Reload_An_Existing_Application</a></p>

<p>I feel that you are asking the wrong question however.  The problem is not how to restart Tomcat but how to be sure that it has restarted</p>

<p>Set a host, tomcat_port and check path then use shell code like this</p>

<pre><code>while [ ""$response_code"" != ""200"" ]
do
        echo ""Checking whether tomcat (${host}:${tomcat_port}/$check) is alive...""
        response_code=`curl -sL -w ""%{http_code}"" ""http://${host}:${tomcat_port}/${check}"" -o /dev/null`
        echo ""Received response code $response_code""
        if [ ""$response_code"" != ""200"" ]
        then
                echo ""Waiting for a bit...""
                sleep 15s
        fi;
done;
echo ""Tomcat is alive!""
</code></pre>

<p>This will wait until the Tomcat comes back - or the containing Jenkins job will time out eventually</p>
",4954,2018-02-08T15:31:04.630,"['while [ ""$response_code"" != ""200"" ]\ndo\n        echo ""Checking whether tomcat (${host}:${tomcat_port}/$check) is alive...""\n        response_code=`curl -sL -w ""%{http_code}"" ""http://${host}:${tomcat_port}/${check}"" -o /dev/null`\n        echo ""Received response code $response_code""\n        if [ ""$response_code"" != ""200"" ]\n        then\n                echo ""Waiting for a bit...""\n                sleep 15s\n        fi;\ndone;\necho ""Tomcat is alive!""\n']"
359,3314,2626,CC BY-SA 3.0,2018-02-08T20:43:51.287,"<p>I found the missing piece in the <a href=""https://wiki.jenkins.io/display/JENKINS/Lockable+Resources+Plugin"" rel=""nofollow noreferrer"">Lockable resource plugin</a>.</p>

<pre><code>lock(label: 'server-pool', quantity: 1) {
   ...
}
</code></pre>

<p>Now the servers to be used for testing don't need to be managed as slaves at all and that greatly simplifies things.</p>
",5316,2018-02-08T20:43:51.287,"[""lock(label: 'server-pool', quantity: 1) {\n   ...\n}\n""]"
360,3316,3313,CC BY-SA 3.0,2018-02-09T15:05:15.490,"<p>Please check in Fastlane docs Launch Arguments under Advanced Snapshot section <a href=""https://docs.fastlane.tools/getting-started/ios/screenshots/"" rel=""nofollow noreferrer"">https://docs.fastlane.tools/getting-started/ios/screenshots/</a> I think it can help</p>

<blockquote>
  <p>Launch Arguments</p>
  
  <p>You can provide additional arguments to your app on launch. These
  strings will be available in your app (eg. not in the testing target)
  through <code>NSProcessInfo.processInfo().arguments</code>. Alternatively, use
  user-default syntax (<code>-key value</code>) and they will be available as
  key-value pairs in <code>NSUserDefaults.standardUserDefaults()</code>.</p>

<pre><code>launch_arguments([
  ""-firstName Felix -lastName Krause""
])

name.text = NSUserDefaults.standardUserDefaults().stringForKey(""firstName"")
// name.text = ""Felix""
</code></pre>
  
  <p><em>snapshot</em> includes <code>-FASTLANE_SNAPSHOT YES</code>, which will set a temporary user default for the key <code>FASTLANE_SNAPSHOT</code>, you may use
  this to detect when the app is run by <em>snapshot</em>.</p>

<pre><code>if NSUserDefaults.standardUserDefaults().boolForKey(""FASTLANE_SNAPSHOT"")
</code></pre>
  
  <p>{
          // runtime check that we are in snapshot mode
      }</p>
  
  <p>Specify multiple argument strings and snapshot will generate
  screenshots for each combination of arguments, devices, and languages.
  This is useful for comparing the same screenshots with different
  feature flags, dynamic text sizes, and different data sets.</p>

<pre><code># Snapfile for A/B Test Comparison
launch_arguments([
  ""-secretFeatureEnabled YES"",
  ""-secretFeatureEnabled NO""
])
</code></pre>
</blockquote>
",6441,2018-02-09T16:59:41.607,"['launch_arguments([\n  ""-firstName Felix -lastName Krause""\n])\n\nname.text = NSUserDefaults.standardUserDefaults().stringForKey(""firstName"")\n// name.text = ""Felix""\n', 'if NSUserDefaults.standardUserDefaults().boolForKey(""FASTLANE_SNAPSHOT"")\n', '# Snapfile for A/B Test Comparison\nlaunch_arguments([\n  ""-secretFeatureEnabled YES"",\n  ""-secretFeatureEnabled NO""\n])\n']"
361,3319,3318,CC BY-SA 3.0,2018-02-09T18:55:13.740,"<p>It is possible to declare group and host vars <a href=""http://docs.ansible.com/ansible/latest/playbooks_best_practices.html"" rel=""nofollow noreferrer"">http://docs.ansible.com/ansible/latest/playbooks_best_practices.html</a></p>

<blockquote>
<pre><code>group_vars/
   group1                 # here we assign variables to particular groups
   group2                 # """"
host_vars/
   hostname1              # if systems need specific variables, put them here
   hostname2              # """"
</code></pre>
</blockquote>
",210,2018-02-09T18:55:13.740,"['group_vars/\n   group1                 # here we assign variables to particular groups\n   group2                 # """"\nhost_vars/\n   hostname1              # if systems need specific variables, put them here\n   hostname2              # """"\n']"
362,3320,3318,CC BY-SA 3.0,2018-02-09T20:32:27.213,"<p>Elaborating on @030's answer, here's how you can use variables for modules:</p>

<ol>
<li><p>You need to group the target hosts in groups, for the example I'm using <code>server1.example.com</code> as member of <code>hosts1</code> group and <code>server2.example.com</code> as member of <code>hosts2</code> group.</p></li>
<li><p>You create group variables:</p>

<ul>
<li>group_vars/hosts1</li>
<li>group_vars/hosts2</li>
</ul></li>
</ol>

<p>Both files contain a variable named <code>module</code> with different value, in the test I use <code>stat</code>.</p>

<ol start=""3"">
<li>Your playbook will look like this:</li>
</ol>

<p><code>test.yml</code></p>

<pre><code>---
 - hosts: all        
   user: me        
   tasks:
     - name: test module variables
       action: ""{{ module }} path=/home/me/myfile""
</code></pre>

<p>The result of the play:</p>

<pre><code>[me@myserver]$ ansible-playbook test.yml -i test

PLAY [all] ********************************************************************************

TASK [Gathering Facts] ********************************************************************
ok: [server1.example.com]
ok: [server2.example.com]

TASK [test module variables] **************************************************************
ok: [server1.example.com]
ok: [server2.example.com]

PLAY RECAP ********************************************************************************
server1.example.com        : ok=2    changed=0    unreachable=0    failed=0
server2.example.com        : ok=2    changed=0    unreachable=0    failed=0
</code></pre>
",775,2018-02-10T06:18:23.063,"['---\n - hosts: all        \n   user: me        \n   tasks:\n     - name: test module variables\n       action: ""{{ module }} path=/home/me/myfile""\n', '[me@myserver]$ ansible-playbook test.yml -i test\n\nPLAY [all] ********************************************************************************\n\nTASK [Gathering Facts] ********************************************************************\nok: [server1.example.com]\nok: [server2.example.com]\n\nTASK [test module variables] **************************************************************\nok: [server1.example.com]\nok: [server2.example.com]\n\nPLAY RECAP ********************************************************************************\nserver1.example.com        : ok=2    changed=0    unreachable=0    failed=0\nserver2.example.com        : ok=2    changed=0    unreachable=0    failed=0\n']"
363,3323,3321,CC BY-SA 3.0,2018-02-09T23:18:02.713,"<p><em>Note: this answer shows how to find branches that have been *updated* a long time ago, not branches that have been *created* (i.e., spliced off of some parent) a long time ago. I believe this is what the OP actually wanted (as opposed to the title he chose for the question), as this would lead to good candidates for deletion.</em></p>

<p>You have to recall that a branch in git is nothing ""physical"". It is, by definition, and literally, <em>only</em> a simple text file in <code>.git/refs</code> which only has its file name (which is the branch name) and the hash of the tip/head commit. It has no date information or <em>anything</em> else.</p>

<p>So <code>git branch</code> will not help you here. </p>

<p>The object type that has dates associated with it are commits, in git. So you have to list commits. This is done with <code>git log</code>. </p>

<p>So a working command would be:</p>

<pre><code>git log --remotes --before 2018-01-01 --no-walk --decorate
</code></pre>

<p>You can read up the details on <a href=""https://www.git-scm.com/docs/git-log"" rel=""noreferrer"">https://www.git-scm.com/docs/git-log</a> , but in short, it means </p>

<ul>
<li><code>--remotes</code>: start with any and all remote branches (substitute <code>--branches</code> for local branches)</li>
<li><code>--before ...</code>: only list commits older than the date given</li>
<li><code>--no-walk</code>: only list the very first commit for each branch, don't walk back the history</li>
<li><code>--decorate</code>: display all tag and branch names associated, just in case</li>
</ul>

<p>This will give you all branch heads that are older than your given date.</p>
",4175,2018-02-09T23:30:36.367,['git log --remotes --before 2018-01-01 --no-walk --decorate\n']
364,3355,3349,CC BY-SA 3.0,2018-02-14T23:13:57.747,"<p>Your mistake is that you are did not register the <em>app</em> service on the <em>app-net</em> network. To allow containers to connect with one another, they have to share a network and then use the image name as the domain name. Docker provides a network internal DNS service.</p>

<pre><code>version: '3'
services:
  couchdb:
    image: couchdb:latest
    restart: always
    volumes:
      - couchdb-data-volume:/usr/local/var/lib/couchdb
    env_file: .env.docker
    ports:
      - ""12345:5986""
    networks:
      app-net:

  app:
    build: .
    image: app
    container_name: app
    restart: always
    depends_on:
      - couchdb
    env_file: .env.docker  
    networks:
      - app-net

volumes:
  couchdb-data-volume:

networks:
  app-net:
</code></pre>

<p>The URL from the <em>app</em> to the <em>couchdb</em> service would be <code>http://couchdb:5986</code>. To test this, open bash inside the <em>app</em> service with <code>docker exec -it app</code>. This depends on the <em>container_name</em> setting.</p>
",5879,2018-02-14T23:13:57.747,"['version: \'3\'\nservices:\n  couchdb:\n    image: couchdb:latest\n    restart: always\n    volumes:\n      - couchdb-data-volume:/usr/local/var/lib/couchdb\n    env_file: .env.docker\n    ports:\n      - ""12345:5986""\n    networks:\n      app-net:\n\n  app:\n    build: .\n    image: app\n    container_name: app\n    restart: always\n    depends_on:\n      - couchdb\n    env_file: .env.docker  \n    networks:\n      - app-net\n\nvolumes:\n  couchdb-data-volume:\n\nnetworks:\n  app-net:\n']"
365,3382,3375,CC BY-SA 3.0,2018-02-20T16:40:48.497,"<p>You do not want to be parsing HTML in a programmatic way. Avoid it at all costs, if you can. It would be a nightmare to support on-going. There's actually a JSON output that Mozilla provides of all the versions:</p>

<p><a href=""https://product-details.mozilla.org/1.0/firefox_versions.json"" rel=""nofollow noreferrer"">https://product-details.mozilla.org/1.0/firefox_versions.json</a></p>

<p><strong>Edit:</strong> Here is a simple bash script example that will always return the latest Firefox version. Make sure you have <code>jq</code> &amp; <code>curl</code> installed on your system:</p>

<pre><code>curl -s https://product-details.mozilla.org/1.0/firefox_versions.json | jq -r .LATEST_FIREFOX_VERSION
</code></pre>

<p>This returns:</p>

<p><code>58.0.2</code></p>
",6578,2018-02-21T16:20:25.157,['curl -s https://product-details.mozilla.org/1.0/firefox_versions.json | jq -r .LATEST_FIREFOX_VERSION\n']
366,3383,3380,CC BY-SA 3.0,2018-02-20T17:04:14.977,"<blockquote>
  <p>Trying to connect from outside fails</p>
</blockquote>

<p>Are you actually connecting from <em>outside</em>? Flask is binding to localhost (127.0.0.1) and that will only be reachable from within the container. If you're on your local machine, you'll need flask to bind to all IP's:</p>

<pre><code>from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello():
    return ""Hello World!""

if __name__ == ""__main__"":
    app.run(host='0.0.0.0')
</code></pre>

<p>That works for me successfully.</p>
",6578,2018-02-23T15:27:27.460,"['from flask import Flask\napp = Flask(__name__)\n\n@app.route(\'/\')\ndef hello():\n    return ""Hello World!""\n\nif __name__ == ""__main__"":\n    app.run(host=\'0.0.0.0\')\n']"
367,3386,3375,CC BY-SA 3.0,2018-02-20T23:16:39.747,"<p>I pulled this from the <a href=""https://github.com/chef-cookbooks/firefox"" rel=""nofollow noreferrer"">Firefox Chef cookbook</a> (in particular <a href=""https://github.com/chef-cookbooks/firefox/blob/master/libraries/default.rb"" rel=""nofollow noreferrer"">this</a> .rb file). This an example of the request they use to get the latest version based on OS and language. </p>

<pre><code>https://download.mozilla.org/?product=firefox-latest#&amp;os=win#&amp;lang=#en-US
</code></pre>

<p>It adheres to the following format:</p>

<pre><code>https://download.mozilla.org/?product=firefox-{VERSION_NUMBER}#&amp;os={OS_ABBREVIATION}#&amp;lang=#{LANGUAGE_ABBREVIATION}
</code></pre>

<p>I searched around for official api documentation, but couldn't find anything. If I do, I will post a link to it in this answer. </p>
",4328,2018-02-21T00:44:54.367,"['https://download.mozilla.org/?product=firefox-latest#&os=win#&lang=#en-US\n', 'https://download.mozilla.org/?product=firefox-{VERSION_NUMBER}#&os={OS_ABBREVIATION}#&lang=#{LANGUAGE_ABBREVIATION}\n']"
368,3389,3372,CC BY-SA 3.0,2018-02-21T13:52:37.890,"<p>Here is a helper Bash script which uses <a href=""https://docs.aws.amazon.com/cli/latest/reference/ssm/send-command.html"" rel=""nofollow noreferrer""><code>aws ssm send-command</code></a> with <a href=""https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/tutorial_run_command.html"" rel=""nofollow noreferrer""><code>--output-s3-bucket-name</code></a> parameter to run the command and the result is stored in the S3 bucket, then displayed to the standard output.</p>

<pre><code>#/usr/bin/env bash -xe
# Script to run PowerShell script on the Windows instance, then uploads the output to S3 bucket.
instanceId=""$1""
bucketName=""$2""
bucketDir=""Output""
[ $# -le 2 ] &amp;&amp; { echo ""Usage: $0 instance_id bucket_name command""; exit 1; }
aws s3 ls ${bucketName} &gt; /dev/null
cmdId=$(aws ssm send-command --instance-ids ""$instanceId"" --document-name ""AWS-RunPowerShellScript"" --query ""Command.CommandId"" --output text  --output-s3-bucket-name ""$bucketName"" --output-s3-key-prefix ""$bucketDir"" --parameters commands=""'${@:3}'"")
while [ ""$(aws ssm list-command-invocations --command-id ""$cmdId"" --query ""CommandInvocations[].Status"" --output text)"" == ""InProgress"" ]; do sleep 1; done
outputPath=$(aws ssm list-command-invocations --command-id ""$cmdId"" --details --query ""CommandInvocations[].CommandPlugins[].OutputS3KeyPrefix"" --output text)
aws s3 ls s3://${bucketName}/${outputPath}/stderr.txt &amp;&amp; aws s3 cp --quiet s3://${bucketName}/${outputPath}/stderr.txt /dev/stderr
aws s3 cp --quiet s3://${bucketName}/${outputPath}/stdout.txt /dev/stdout
</code></pre>

<p>Example:</p>

<pre><code>./run_ec2_ps_cmd_s3.sh i-0xyz my-bucket-name 'While ($i -le 10) {(Invoke-WebRequest -UseBasicParsing -Uri http://example.com).Content; $i++}'
</code></pre>
",3,2018-02-21T13:58:17.803,"['#/usr/bin/env bash -xe\n# Script to run PowerShell script on the Windows instance, then uploads the output to S3 bucket.\ninstanceId=""$1""\nbucketName=""$2""\nbucketDir=""Output""\n[ $# -le 2 ] && { echo ""Usage: $0 instance_id bucket_name command""; exit 1; }\naws s3 ls ${bucketName} > /dev/null\ncmdId=$(aws ssm send-command --instance-ids ""$instanceId"" --document-name ""AWS-RunPowerShellScript"" --query ""Command.CommandId"" --output text  --output-s3-bucket-name ""$bucketName"" --output-s3-key-prefix ""$bucketDir"" --parameters commands=""\'${@:3}\'"")\nwhile [ ""$(aws ssm list-command-invocations --command-id ""$cmdId"" --query ""CommandInvocations[].Status"" --output text)"" == ""InProgress"" ]; do sleep 1; done\noutputPath=$(aws ssm list-command-invocations --command-id ""$cmdId"" --details --query ""CommandInvocations[].CommandPlugins[].OutputS3KeyPrefix"" --output text)\naws s3 ls s3://${bucketName}/${outputPath}/stderr.txt && aws s3 cp --quiet s3://${bucketName}/${outputPath}/stderr.txt /dev/stderr\naws s3 cp --quiet s3://${bucketName}/${outputPath}/stdout.txt /dev/stdout\n', ""./run_ec2_ps_cmd_s3.sh i-0xyz my-bucket-name 'While ($i -le 10) {(Invoke-WebRequest -UseBasicParsing -Uri http://example.com).Content; $i++}'\n""]"
369,3390,3264,CC BY-SA 3.0,2018-02-21T13:53:58.407,"<p>Here is a helper Bash script which uses <a href=""https://docs.aws.amazon.com/cli/latest/reference/ssm/send-command.html"" rel=""nofollow noreferrer""><code>aws ssm send-command</code></a> to run the commands:</p>

<pre><code>#/usr/bin/env bash -x
# Script to run PowerShell script on the Windows instance.
instanceId=""$1""
cmdId=$(aws ssm send-command --instance-ids ""$instanceId"" --document-name ""AWS-RunPowerShellScript"" --query ""Command.CommandId"" --output text --parameters commands=""'${@:2}'"")
[ $? -ne 0 ] &amp;&amp; { echo ""Usage: $0 instance_id command""; exit 1; }
while [ ""$(aws ssm list-command-invocations --command-id ""$cmdId"" --query ""CommandInvocations[].Status"" --output text)"" == ""InProgress"" ]; do sleep 1; done
aws ssm list-command-invocations --command-id ""$cmdId"" --details --query ""CommandInvocations[*].CommandPlugins[*].Output[]"" --output text
</code></pre>

<p>Usage:</p>

<pre><code> ./run_ec2_ps_cmd.sh instance-id command
</code></pre>

<p>Example:</p>

<pre><code>$ ./run_ec2_ps_cmd.sh i-xyz hostname
ip-xyz
</code></pre>

<p><sup>To execute larger outputs, see: <a href=""https://devops.stackexchange.com/q/3372/3"">How to avoid output being truncated when running AWS SSM command?</a></sup></p>
",3,2018-02-21T13:53:58.407,"['#/usr/bin/env bash -x\n# Script to run PowerShell script on the Windows instance.\ninstanceId=""$1""\ncmdId=$(aws ssm send-command --instance-ids ""$instanceId"" --document-name ""AWS-RunPowerShellScript"" --query ""Command.CommandId"" --output text --parameters commands=""\'${@:2}\'"")\n[ $? -ne 0 ] && { echo ""Usage: $0 instance_id command""; exit 1; }\nwhile [ ""$(aws ssm list-command-invocations --command-id ""$cmdId"" --query ""CommandInvocations[].Status"" --output text)"" == ""InProgress"" ]; do sleep 1; done\naws ssm list-command-invocations --command-id ""$cmdId"" --details --query ""CommandInvocations[*].CommandPlugins[*].Output[]"" --output text\n', ' ./run_ec2_ps_cmd.sh instance-id command\n', '$ ./run_ec2_ps_cmd.sh i-xyz hostname\nip-xyz\n']"
370,3398,3112,CC BY-SA 3.0,2018-02-21T18:39:14.267,"<p>I recommend Chocolatey. There are more and more companies that are adopting this. For example, if one would like to install Gradle and navigates to the <a href=""https://gradle.org/install/"" rel=""nofollow noreferrer"">installation page</a>:</p>

<blockquote>
  <p>Chocolatey is “the package manager for Windows”.</p>

<pre><code>$ choco install gradle
</code></pre>
</blockquote>
",210,2018-02-21T18:39:14.267,['$ choco install gradle\n']
371,3401,3393,CC BY-SA 3.0,2018-02-21T18:47:04.897,"<p>What about using a CI tool? Create a parallel job and the jobs will run parallel. For example, one could use Jenkins:</p>

<p><a href=""https://jenkins.io/blog/2017/09/25/declarative-1/"" rel=""nofollow noreferrer"">https://jenkins.io/blog/2017/09/25/declarative-1/</a></p>

<blockquote>
<pre><code>stage('run-parallel-branches') {
  steps {
    parallel(
      a: {
        echo ""This is branch a""
      },
      b: {
        echo ""This is branch b""
      }
    )
  }
}
</code></pre>
</blockquote>

<p>but there are other CI tools that could do the same.</p>
",210,2018-02-21T18:47:04.897,"['stage(\'run-parallel-branches\') {\n  steps {\n    parallel(\n      a: {\n        echo ""This is branch a""\n      },\n      b: {\n        echo ""This is branch b""\n      }\n    )\n  }\n}\n']"
372,3403,3394,CC BY-SA 3.0,2018-02-21T18:52:30.600,"<p><a href=""https://www.google.nl/search?q=how%2Bto%2Bcreate%2Ba%2Bchef%2Bpackage"" rel=""nofollow noreferrer"">https://www.google.nl/search?q=how%2Bto%2Bcreate%2Ba%2Bchef%2Bpackage</a></p>

<p>returns:</p>

<p><a href=""https://docs.chef.io/resource_package.html"" rel=""nofollow noreferrer"">https://docs.chef.io/resource_package.html</a></p>

<p>and</p>

<p><a href=""https://docs.chef.io/resource_examples.html"" rel=""nofollow noreferrer"">https://docs.chef.io/resource_examples.html</a></p>

<p>The latter provides code snippets, like how to copy files:</p>

<blockquote>
  <p><strong>Create a file from a copy</strong></p>
  
  <p>The following example shows how to copy a file from one directory to
  another, locally on a node:</p>

<pre><code>file '/root/1.txt' do
  content IO.read('/tmp/1.txt')
  action :create
end
</code></pre>
</blockquote>

<p>More example could be found in <a href=""https://supermarket.chef.io/cookbooks/mysql"" rel=""nofollow noreferrer"">the supermarket</a>. In order to write chef books one could investigate how some recipes are structured like <a href=""https://github.com/chef-cookbooks/mysql"" rel=""nofollow noreferrer"">mysql</a>.</p>
",210,2018-02-21T21:08:42.940,"[""file '/root/1.txt' do\n  content IO.read('/tmp/1.txt')\n  action :create\nend\n""]"
373,3404,3226,CC BY-SA 3.0,2018-02-21T19:28:59.827,"<p>I would recommend against importing if at all possible. You can use built-in functionality to achieve the same results. Also be aware of ""<a href=""https://jenkins.io/doc/book/managing/script-approval/"" rel=""nofollow noreferrer"">In-process Script Approval</a>""</p>

<p><a href=""https://stackoverflow.com/a/42662243/1678094"">https://stackoverflow.com/a/42662243/1678094</a></p>



<pre class=""lang-java prettyprint-override""><code>// GET
def get = new URL(""https://httpbin.org/get"").openConnection();
def getRC = get.getResponseCode();
println(getRC);
if(getRC.equals(200)) {
    println(get.getInputStream().getText());
}


// POST
def post = new URL(""https://httpbin.org/post"").openConnection();
def message = '{""message"":""this is a message""}'
post.setRequestMethod(""POST"")
post.setDoOutput(true)
post.setRequestProperty(""Content-Type"", ""application/json"")
post.getOutputStream().write(message.getBytes(""UTF-8""));
def postRC = post.getResponseCode();
println(postRC);
if(postRC.equals(200)) {
    println(post.getInputStream().getText());
}
</code></pre>

<p>You can also override the request method:</p>

<p><a href=""https://stackoverflow.com/a/32503192/1678094"">https://stackoverflow.com/a/32503192/1678094</a></p>

<pre class=""lang-java prettyprint-override""><code>conn.setRequestProperty(""X-HTTP-Method-Override"", ""PATCH"");
conn.setRequestMethod(""POST"");
</code></pre>
",6579,2018-02-21T21:49:58.077,"['// GET\ndef get = new URL(""https://httpbin.org/get"").openConnection();\ndef getRC = get.getResponseCode();\nprintln(getRC);\nif(getRC.equals(200)) {\n    println(get.getInputStream().getText());\n}\n\n\n// POST\ndef post = new URL(""https://httpbin.org/post"").openConnection();\ndef message = \'{""message"":""this is a message""}\'\npost.setRequestMethod(""POST"")\npost.setDoOutput(true)\npost.setRequestProperty(""Content-Type"", ""application/json"")\npost.getOutputStream().write(message.getBytes(""UTF-8""));\ndef postRC = post.getResponseCode();\nprintln(postRC);\nif(postRC.equals(200)) {\n    println(post.getInputStream().getText());\n}\n', 'conn.setRequestProperty(""X-HTTP-Method-Override"", ""PATCH"");\nconn.setRequestMethod(""POST"");\n']"
374,3406,3394,CC BY-SA 3.0,2018-02-21T21:23:40.120,"<p>Very basic recipe exemple to install filebeat on ubuntu (I do use more or less the same approach for elasticsearch, kibana and logstash):</p>

<pre><code>apt_repository 'elk' do
  uri 'https://artifacts.elastic.co/packages/5.x/apt'
  distribution 'stable'
  components ['main']
  key 'https://artifacts.elastic.co/GPG-KEY-elasticsearch'
  cache_rebuild true
end

package 'filebeat' do
  action :upgrade # To keep up to date with releases from elastic.co
end

service 'filebeat' do
  action [:enable, :start]
end

template '/etc/filebeat/filebeat.yml' do
  source 'filebeat.yml.erb'
  mode '0600'
  notifies :restart, 'service[filebeat]'
end
</code></pre>

<p>Basically, adding a repository, installing package, enabling and starting the service, render a config and restart the service when it changes. On ubuntu the package set the service scripts so I don't have to manage it here.</p>

<p>The template is my default configuration using some node attributes depending on environment. See <a href=""https://docs.chef.io/resource_template.html"" rel=""nofollow noreferrer"">https://docs.chef.io/resource_template.html</a> for more details on how to use them.</p>

<p>According to your question I would strongly sugest you to follow the tutorial paths at <a href=""https://learn.chef.io"" rel=""nofollow noreferrer"">https://learn.chef.io</a> to grasp the basics about chef.</p>
",13,2018-02-21T21:23:40.120,"[""apt_repository 'elk' do\n  uri 'https://artifacts.elastic.co/packages/5.x/apt'\n  distribution 'stable'\n  components ['main']\n  key 'https://artifacts.elastic.co/GPG-KEY-elasticsearch'\n  cache_rebuild true\nend\n\npackage 'filebeat' do\n  action :upgrade # To keep up to date with releases from elastic.co\nend\n\nservice 'filebeat' do\n  action [:enable, :start]\nend\n\ntemplate '/etc/filebeat/filebeat.yml' do\n  source 'filebeat.yml.erb'\n  mode '0600'\n  notifies :restart, 'service[filebeat]'\nend\n""]"
375,3409,3408,CC BY-SA 3.0,2018-02-22T08:17:56.200,"<p>Note: this answer is based solely on documentation, I didn't try it.</p>

<p>From <a href=""https://www.terraform.io/docs/providers/external/data_source.html"" rel=""nofollow noreferrer"">External Data Source</a> (emphasis mine):</p>

<blockquote>
  <p>The following arguments are supported:</p>
  
  <ul>
  <li><a href=""https://www.terraform.io/docs/providers/external/data_source.html#program"" rel=""nofollow noreferrer"">program</a> - (Required) A list of strings, whose first element is the program to run and whose subsequent elements are optional command
  line arguments to the program. <strong>Terraform does not execute the
  program through a shell</strong>, so it is not necessary to escape shell
  metacharacters nor add quotes around arguments containing spaces.</li>
  </ul>
</blockquote>

<p>Expanding <code>~</code> to the home directory is a capability of the shell, not of <code>ssh-keygen</code> and since in the 1st example <code>ssh-keygen</code> is invoked, it literally attempts to open a file named <code>~/.ssh/id_rsa</code>. Which fails because a <code>~</code> directory doesn't exist (I'm not sure if that's what you mean by <code>presumably happens because ~ expansion doesn't</code>).</p>

<p>In the 2nd example you're passing the <code>ssh-keygen</code> command as a query, not as arguments to <code>bash</code>. Probably what's executed is not what you're expecting.</p>

<p>I'd try:</p>

<pre><code>data ""external"" ""local_key"" {
  program = [
    ""bash"", ""-c"", ""ssh-keygen"", ""-y"", ""-f ~/.ssh/id_rsa""
  ]
}
</code></pre>

<p>But I'm not sure if <code>bash</code> itself (or <code>ssh-keygen</code> for that matter) follows the External Program Protocol required  (also on the above referenced page). You may need to write your own script to wrap the cmd you desire while also providing the data according to the protocol. Invoke that script as the program instead of <code>bash</code> or <code>ssh-keygen</code>.</p>

<p>Finally, the entire external data source page doesn't appear to suggest that <code>export</code> would be designed for interactive programs and <code>ssh-keygen -y -f ~/.ssh/id_rsa</code> asks for the user passphrase interactively. YMMV.</p>
",47,2018-02-22T08:17:56.200,"['data ""external"" ""local_key"" {\n  program = [\n    ""bash"", ""-c"", ""ssh-keygen"", ""-y"", ""-f ~/.ssh/id_rsa""\n  ]\n}\n']"
376,3410,3408,CC BY-SA 3.0,2018-02-22T09:02:19.363,"<p>So what happens in first case is, as Dan's already said, there's no shell used and as such nothing to expand the <code>~</code>. Quoting the <a href=""https://www.terraform.io/docs/providers/external/data_source.html#program"" rel=""noreferrer"">documentation about program</a>:</p>

<blockquote>
  <p>Terraform does not execute the program through a shell</p>
</blockquote>

<p>On the second case, bash receive in stdin something like this:</p>

<pre><code>{ ""-c"": ""ssh-keygen -y -f ~/.ssh/id_rsa"" }
</code></pre>

<p>And this looks like a command block for bash, but -c is not a valid command.</p>

<p>What could work could be this kind of program (assuming no specific input):</p>

<pre><code>jq -n --arg pubkey ""$(ssh-keygen -y -f ~/.ssh/id_rsa)"" '{""pubkey"":$pubkey}'
</code></pre>

<p>So something like this should work to get the key in <code>local_key[""pubkey""]</code> if I understand the documentation properly:</p>

<pre><code>data ""external"" ""local_key"" {
  program = [
    ""bash"", ""-c jq -n --arg pubkey \""$(ssh-keygen -y -f ~/.ssh/id_rsa)\"" '{\""pubkey\"":$pubkey}'""
  ]
}
</code></pre>

<p>There's a need to use bash for a one liner to take advantage of command subsitution. You can also do a .sh script like:</p>

<pre><code>#!/bin/sh
jq -n --arg pubkey ""$(ssh-keygen -y -f ~/.ssh/id_rsa)"" '{\""pubkey\"":$pubkey}'
</code></pre>

<p>And call this script in the <code>program</code> parameter.</p>
",13,2018-02-22T09:02:19.363,"['{ ""-c"": ""ssh-keygen -y -f ~/.ssh/id_rsa"" }\n', 'jq -n --arg pubkey ""$(ssh-keygen -y -f ~/.ssh/id_rsa)"" \'{""pubkey"":$pubkey}\'\n', 'data ""external"" ""local_key"" {\n  program = [\n    ""bash"", ""-c jq -n --arg pubkey \\""$(ssh-keygen -y -f ~/.ssh/id_rsa)\\"" \'{\\""pubkey\\"":$pubkey}\'""\n  ]\n}\n', '#!/bin/sh\njq -n --arg pubkey ""$(ssh-keygen -y -f ~/.ssh/id_rsa)"" \'{\\""pubkey\\"":$pubkey}\'\n']"
377,3416,3379,CC BY-SA 4.0,2018-02-22T19:06:50.760,"<p>You can pass your data using environment variables or through job parameters. </p>

<p>Here's an example of setting environment variables in a pipeline:</p>



<pre class=""lang-java prettyprint-override""><code>pipeline {
    agent any
    environment {
        FILE = ""Makefile""
        SERVER = ""example.com""
        VERSION = ""v1.1.0""
    }
    stages {
        stage ('build') {
            steps {
                echo ""VERSION is: $VERSION""
                bat ""script.exe ${version} ${server} ${file}""
            }
        }
    }
}
</code></pre>

<p>If you want to use parameters instead you could do so in the following pipeline example:</p>

<pre class=""lang-java prettyprint-override""><code>pipeline {
  agent any
  parameters {
    string(description: 'file', name: 'file')
    string(description: 'server', name: 'server')
    string(description: 'version', name: 'version')
  }
  stages {
    stage(""foo"") {
      steps {
        echo ""VERSION is: ${params.version}""
        bat ""script.exe ${params.version} ${params.server} ${params.file}""
      }
    }
  }
}
</code></pre>

<p>See the following documentation for building a parameterized pipeline:
<a href=""https://github.com/jenkinsci/pipeline-model-definition-plugin/wiki/Parametrized-pipelines"" rel=""nofollow noreferrer"">https://github.com/jenkinsci/pipeline-model-definition-plugin/wiki/Parametrized-pipelines</a></p>

<p>If you're using a freestyle job it's slightly different but you can find detailed instructions here:
<a href=""https://wiki.jenkins.io/display/JENKINS/Parameterized+Build"" rel=""nofollow noreferrer"">https://wiki.jenkins.io/display/JENKINS/Parameterized+Build</a></p>
",6579,2018-07-20T18:53:22.937,"['pipeline {\n    agent any\n    environment {\n        FILE = ""Makefile""\n        SERVER = ""example.com""\n        VERSION = ""v1.1.0""\n    }\n    stages {\n        stage (\'build\') {\n            steps {\n                echo ""VERSION is: $VERSION""\n                bat ""script.exe ${version} ${server} ${file}""\n            }\n        }\n    }\n}\n', 'pipeline {\n  agent any\n  parameters {\n    string(description: \'file\', name: \'file\')\n    string(description: \'server\', name: \'server\')\n    string(description: \'version\', name: \'version\')\n  }\n  stages {\n    stage(""foo"") {\n      steps {\n        echo ""VERSION is: ${params.version}""\n        bat ""script.exe ${params.version} ${params.server} ${params.file}""\n      }\n    }\n  }\n}\n']"
378,3422,3229,CC BY-SA 3.0,2018-02-23T13:21:45.543,"<p>It depends on what you want to archive. If your container is intended to be accessed from outside, you need port mapping: <code>-p $HOSTPORT:$CONTAINERPORT</code> So you can use <code>-p 80:80</code> as an argument for <code>docker run</code> to expose port 80. </p>

<p>If this is not the case (e.g. backend server that is accessed by a reverse proxy) you could simply use <code>docker exec</code> to execute your <code>curl</code> command in the container. This also has the advantage that no external IP is needed, simply use <code>localhost</code>. It's also an better option to expose port 22 for ssh.</p>

<pre><code>docker exec -it $CONTAINERNAME bash
</code></pre>

<p>where <code>bash</code> can be replaced by any login shell for interactive mode. You can also directly pass a command here like this: </p>

<pre><code>docker exec -it $CONTAINERNAME curl http://localhost
</code></pre>

<p>The <code>execute</code> command has the benefit that it can be used in already running containers. So for example you could check if a service in the container is gone after a period of time. </p>
",6643,2018-02-23T13:21:45.543,"['docker exec -it $CONTAINERNAME bash\n', 'docker exec -it $CONTAINERNAME curl http://localhost\n']"
379,3430,3089,CC BY-SA 3.0,2018-02-24T13:31:44.360,"<p>There is a <a href=""https://github.com/github/hub"" rel=""nofollow noreferrer""><code>hub</code> utility</a> from GitHub which extend your git with extra features and commands. This includes creating the releases on the GitHub.</p>

<pre><code>$ hub release --help
usage: git release
   or: git release create [-d] [-p] [-a &lt;ASSETS_FILE&gt;] [-m &lt;MESSAGE&gt;|-f &lt;FILE&gt;] &lt;TAG&gt;
Retrieves releases from GitHub for the project that the ""origin"" remote points to.
</code></pre>
",3,2018-02-24T13:31:44.360,"['$ hub release --help\nusage: git release\n   or: git release create [-d] [-p] [-a <ASSETS_FILE>] [-m <MESSAGE>|-f <FILE>] <TAG>\nRetrieves releases from GitHub for the project that the ""origin"" remote points to.\n']"
380,3437,3081,CC BY-SA 4.0,2018-02-25T04:15:59.417,"<p>Jenkins provides <code>agent.jar</code> and a secret required to make a connection from the node to the master. Make sure the node is configured properly (<em>Manage Jenkins</em> → <em>Manage Nodes</em> → <em>Node</em>)</p>

<p><a href=""https://i.stack.imgur.com/lkkp4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lkkp4.png"" alt=""Enter image description here""></a></p>

<p>Ensure Java 1.8 is present on the Windows agent. Download the <code>agent.jar</code> file on the Windows machine, and run the command Jenkins provides, using Windows command prompt.</p>

<pre><code>java -jar agent.jar -jnlpUrl http://localhost:8080/computer/example/slave-agent.jnlp -secret e6073ce49423ed54df4a24f918973f50dc760dd440013d3b30403c4a2c7501fd -workDir ""c:\jenkins""
</code></pre>
",6579,2018-07-20T18:18:11.470,"['java -jar agent.jar -jnlpUrl http://localhost:8080/computer/example/slave-agent.jnlp -secret e6073ce49423ed54df4a24f918973f50dc760dd440013d3b30403c4a2c7501fd -workDir ""c:\\jenkins""\n']"
381,3439,3150,CC BY-SA 3.0,2018-02-25T08:53:42.520,"<p>Side note: personally I dislike using a <em>minimum</em> version: you never know beforehand how the language will evolve and if a certain future version will still be compatible with your code. For example many 2.7-compatible scripts can't actually work with python 3.X, setting 2.7 as the minimum version won't cut it.</p>

<p>I prefer to explicitly list as allowed the (existing) versions that I can test and confirm to be compatible. Any future version can be added later on, after such confirmation is obtained.</p>

<p>If you agree with the above then the <a href=""https://github.com/linkedin/pygradle/blob/master/docs/plugins/python.md"" rel=""nofollow noreferrer""><code>com.linkedin.python</code></a> plugin can apparently perform such version checks (it doesn't looks like it supports a <em>minimum</em> version):</p>

<blockquote>
  <p><strong>Default and allowed Python version</strong></p>
  
  <p>This plugin enforces a set of default and allowed Python versions. For
  example, you can specify <code>pythonVersion = '3'</code> and you will get
  whatever the default Python 3 version is. Similarly <code>pythonVersion =
  '2'</code> gets you whatever the default Python 2 version is.</p>
  
  <p>This plugin also enforces a set of allowed Python versions. If you
  choose a Python version that is not allowed, you will see an error
  messages such as:</p>

<pre><code>Python 3.2 not allowed; choose from [2.6, 2.7, 3.4, 3.5, 3.6]
</code></pre>
  
  <p>If you see this error message, you must adjust your <code>pythonVersion</code>
  setting to one of the allowed values.</p>
  
  <p>Consumers of this extension can change the default Python 2, Python 3,
  and allowed versions by making a call on the <code>PythonDetails</code> object,
  either the one returned by <code>PythonExtension.getDetails()</code> or on any
  <code>PythonDetails</code> instance you create, e.g. in Groovy:</p>

<pre><code>pythonDetails.setPythonDefaultVersions('2.7', '3.6', ['2.7', '3.5', '3.6'])
</code></pre>
</blockquote>

<p>But I'm not familiar with pygradle, I can't really tell exactly how the plugin works and/or is configured to do the job.</p>
",47,2018-02-25T08:53:42.520,"['Python 3.2 not allowed; choose from [2.6, 2.7, 3.4, 3.5, 3.6]\n', ""pythonDetails.setPythonDefaultVersions('2.7', '3.6', ['2.7', '3.5', '3.6'])\n""]"
382,3445,3418,CC BY-SA 3.0,2018-02-25T18:15:17.130,"<p>It appears that you are trying to run ansible locally <strong>inside</strong> the container but instead you are running it locally on the machine you use to run packer on(the provisioning one).</p>

<p>To run ansible in <a href=""https://www.packer.io/docs/provisioners/ansible-local.html"" rel=""nofollow noreferrer"">local mode</a> you need to update the ansible part of your packer file to:</p>

<pre><code>    {
        ""type"": ""ansible-local"",
        ""playbook_file"": ""./kubeadm.yml""
    }
</code></pre>

<p>Also, I would suggest to add <code>connection: local</code> to your ansible playbook, to avoid unnecessary attempts for ssh connections.</p>

<pre><code>- name: install kubeadm
  hosts: localhost
  connection: local
  roles:
    - { role: djx339.k8s-kubeadm-install }
</code></pre>
",6634,2018-02-25T19:14:43.147,"['    {\n        ""type"": ""ansible-local"",\n        ""playbook_file"": ""./kubeadm.yml""\n    }\n', '- name: install kubeadm\n  hosts: localhost\n  connection: local\n  roles:\n    - { role: djx339.k8s-kubeadm-install }\n']"
383,3448,3443,CC BY-SA 3.0,2018-02-25T21:53:08.840,"<p><a href=""http://api.releasesoftwaremoreoften.com/latestversion?name=oraclejdk8"" rel=""nofollow noreferrer"">http://api.releasesoftwaremoreoften.com/latestversion?name=oraclejdk8</a>
<a href=""http://api.releasesoftwaremoreoften.com/latestversion?name=oraclejdk9"" rel=""nofollow noreferrer"">http://api.releasesoftwaremoreoften.com/latestversion?name=oraclejdk9</a></p>

<p>Running:</p>

<pre><code>curl -s http://releasesoftwaremoreoften.com/latestversion?name=oraclejdk9 | jq .latestVersion
</code></pre>

<p>returns:</p>

<pre><code>9.0.4
</code></pre>

<p>and </p>

<pre><code>curl -s http://releasesoftwaremoreoften.com/latestversion?name=oraclejdk8 | jq .latestVersion
</code></pre>

<p>returns:</p>

<pre><code>8u162
</code></pre>
",210,2018-03-03T10:03:21.160,"['curl -s http://releasesoftwaremoreoften.com/latestversion?name=oraclejdk9 | jq .latestVersion\n', '9.0.4\n', 'curl -s http://releasesoftwaremoreoften.com/latestversion?name=oraclejdk8 | jq .latestVersion\n', '8u162\n']"
384,3450,3449,CC BY-SA 3.0,2018-02-26T08:52:52.693,"<p>Jenkins allows you to construct a CI/CD pipeline that meets your requirements. Here's an example of a pipeline using an input step to decide which environment to deploy to. All you would need to do is wire the stages together.</p>

<p><a href=""https://i.stack.imgur.com/cHE9M.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/cHE9M.png"" alt=""blueocean""></a></p>

<p>Here's an example of the pipeline code (declarative) used to create the example:</p>

<pre class=""lang-java prettyprint-override""><code>pipeline {
  agent any
  stages {
    stage('Deploy Staging') {
      steps {
        echo 'deploying to staging'
      }
    }
    stage('Test Staging') {
      steps {
        echo 'testing staging env'
      }
    }
    stage('Blue/Green?') {
      steps {
        input(message: 'Blue/Green?', id: 'deploy', ok: 'deploy?', parameters: [choice(choices: 'blue\ngreen', description: 'Select an environment', name: 'PROD_ENV')])
      }
    }
  }
}
</code></pre>

<p>Other tools that provide similar capabilities are Rundeck, Stackstorm or Ansible Tower.</p>
",6579,2018-02-26T08:52:52.693,"[""pipeline {\n  agent any\n  stages {\n    stage('Deploy Staging') {\n      steps {\n        echo 'deploying to staging'\n      }\n    }\n    stage('Test Staging') {\n      steps {\n        echo 'testing staging env'\n      }\n    }\n    stage('Blue/Green?') {\n      steps {\n        input(message: 'Blue/Green?', id: 'deploy', ok: 'deploy?', parameters: [choice(choices: 'blue\\ngreen', description: 'Select an environment', name: 'PROD_ENV')])\n      }\n    }\n  }\n}\n""]"
385,3455,3454,CC BY-SA 3.0,2018-02-26T14:31:34.063,"<p>As documented <a href=""http://docs.ansible.com/ansible/devel/plugins/connection.html"" rel=""nofollow noreferrer"">here</a>, ansible does not support telnet as connection plugin. This means you cannot use ansible to connect to a remote machine via telnet and execute any of the ansible modules.</p>

<p>However, you can use <code>connection: local</code> for local connection(run ansible against the machine that is running it) and send <a href=""http://docs.ansible.com/ansible/2.4/telnet_module.html"" rel=""nofollow noreferrer""><code>telnet</code> commands</a> from the machine where ansible runs.</p>

<p>Example playbook will look something like that:</p>

<pre><code>---
- hosts: localhost
  connection: local
  gather_facts: false

  tasks:
    - name: my first telnet task
      telnet:
        username: user
        password: pass
        command:
          - my command
</code></pre>
",6634,2018-02-27T19:30:07.190,['---\n- hosts: localhost\n  connection: local\n  gather_facts: false\n\n  tasks:\n    - name: my first telnet task\n      telnet:\n        username: user\n        password: pass\n        command:\n          - my command\n']
386,3457,3436,CC BY-SA 3.0,2018-02-26T22:59:32.107,"<p>I have found a solution so I'll leave it here for others.</p>

<p>using docker </p>

<pre><code>#!/usr/bin/env groovy

pipeline{
agent buildsvr

  stages{
    stage('Checkout and build Docker Source'){
      steps{
        checkout([
          $class: 'GitSCM',
          branches: [[name: '*/master']],
          doGenerateSubmoduleConfigurations: false,
          submoduleCfg: [],
          userRemoteConfigs: [[
            credentialsId: 'asdf787c-5fd4-4dfb-81ad-873jhf107223',
            url: 
'git@mydockersourcerepo.git']]])
        sh 'pushd docker &amp;&amp; docker build -t ${image}:latest . &amp;&amp; popd '
      }
    }
    stage('Checkout Target Source'){
      steps{
        script{
          checkout([
            $class: 'GitSCM',
            branches: [[name: 'mybranch']],
            doGenerateSubmoduleConfigurations: false,
            extensions: [[
              $class: 'SubmoduleOption',
              disableSubmodules: false,
              parentCredentials: false,
              recursiveSubmodules: true, reference: '',
              trackingSubmodules: true
              relativeTargetDir: 'source']],
            submoduleCfg: [],
            userRemoteConfigs: [[
              credentialsId: 'Bitbucket-Jenkins',
              url: 'ssh://git@sourcerepo.git']]])
        }
      }
    }
    stage('Build Source Target'){
      steps{
       script{
          sh 'docker-compose up'
        }
      }
    }
  }
  post{
    success{
      script{
        sh 'docker tag ${image} 10.90.239.223:5000:/${image} &amp;&amp; docker push 
10.90.239.223:5000:/${image}'
      }
    }
  }
}
</code></pre>
",6153,2018-02-26T22:59:32.107,"[""#!/usr/bin/env groovy\n\npipeline{\nagent buildsvr\n\n  stages{\n    stage('Checkout and build Docker Source'){\n      steps{\n        checkout([\n          $class: 'GitSCM',\n          branches: [[name: '*/master']],\n          doGenerateSubmoduleConfigurations: false,\n          submoduleCfg: [],\n          userRemoteConfigs: [[\n            credentialsId: 'asdf787c-5fd4-4dfb-81ad-873jhf107223',\n            url: \n'git@mydockersourcerepo.git']]])\n        sh 'pushd docker && docker build -t ${image}:latest . && popd '\n      }\n    }\n    stage('Checkout Target Source'){\n      steps{\n        script{\n          checkout([\n            $class: 'GitSCM',\n            branches: [[name: 'mybranch']],\n            doGenerateSubmoduleConfigurations: false,\n            extensions: [[\n              $class: 'SubmoduleOption',\n              disableSubmodules: false,\n              parentCredentials: false,\n              recursiveSubmodules: true, reference: '',\n              trackingSubmodules: true\n              relativeTargetDir: 'source']],\n            submoduleCfg: [],\n            userRemoteConfigs: [[\n              credentialsId: 'Bitbucket-Jenkins',\n              url: 'ssh://git@sourcerepo.git']]])\n        }\n      }\n    }\n    stage('Build Source Target'){\n      steps{\n       script{\n          sh 'docker-compose up'\n        }\n      }\n    }\n  }\n  post{\n    success{\n      script{\n        sh 'docker tag ${image} 10.90.239.223:5000:/${image} && docker push \n10.90.239.223:5000:/${image}'\n      }\n    }\n  }\n}\n""]"
387,3472,3282,CC BY-SA 3.0,2018-02-27T21:55:06.840,"<blockquote>
  <p>The idea is to put all our sensitive data [...]</p>
</blockquote>

<p>The meaning of ""all"" in this sentence should be analyzed very carefully before implementing the solution that you plan.</p>

<p>Ansible vault is a very useful tool, but it should be used only to store secrets that are:</p>

<ol>
<li>Specifically needed for the ansible deployments</li>
<li>Easily made useless to owners that should become unaware of them, but that may illegitimately ""remember"" them (typically off-boarded employees)</li>
</ol>

<p>The second point is critical.</p>

<p>Many people, and potentially the whole DevOps team, will have access to the ansible vault password and therefore all the secrets.</p>

<p>Therefore, for all the secrets stored in the vault, a condition should hold for which a person or machine with <strong>unauthorized</strong> access to them should be incapable of making any use of them if so is desired.</p>

<p>In concrete terms, if you use ansible to deploy a database and its users, you can store the passwords in the vault, but you will have to be very careful (and most likely consider another solution) if that service will be available from the Internet and without the need for any VPN authentication!</p>

<p>Users (DevOps) exposed to the secret, should be incapable of using ""remembered"" passwords if one security barrier is imposed on them (e.g., VPN access revoked). In addition to this, access to the source code repository (where the vault is stored) should be revoked as well before passwords are changed.</p>

<p>Under these conditions, ansible vault is a very useful tool.</p>

<p>Trying to store a secret that could be used by any person or machine on the Internet in the vault would be instead a mistake (e.g., VPN credentials of users).</p>

<blockquote>
  <p>Is there any other options, which is the best (and secure) way to store ansible-vault password</p>
</blockquote>

<p>Under the conditions from the previous paragraph, I think that a good practice would be:</p>

<ol>
<li>Store the vault password in an external secure vault (something like <a href=""https://www.vaultproject.io/"" rel=""noreferrer"">Vault from HashiCorp</a> or any SaaS for credentials management)</li>
<li>Allow access to the external vault item to DevOps (they will need the password for testing) and the CI/CD system or ansible controller</li>
<li><p>Keep a <strong>convention to use secrets</strong>! You will not be able to review changes to the secrets and you will not be able to grep for ansible variables in secrets files! So be thorough since the beginning. A good convention is to name all variables stored in the ansible vault with a <code>secret_</code> prefix. When you will see something like:</p>

<p>postgres.yml:</p>

<pre><code>postgres_password: ""{{ secret_postgres_password }}""
</code></pre>

<p>you will know that the value is stored in the ansible vault.</p></li>
</ol>
",5922,2018-02-28T09:59:47.403,"['postgres_password: ""{{ secret_postgres_password }}""\n']"
388,3486,3483,CC BY-SA 3.0,2018-02-28T13:37:56.083,"<p>That's a known issue .. since image layers are built using containers, data saved to folders does not make it to the next layer or your final container</p>

<pre><code>Removing intermediate container b3ff83bbf273
</code></pre>

<p>If you want data to persist between updated containers you have to manually map data to the host outside the container-specific mount points.</p>

<p>For example, when creating a container use the -v option to map a volume:</p>

<pre><code>docker run -d -v /var/container_data/mysql:/var/lib/mysql mysql_image
</code></pre>

<p>For a detailed documentation 
<a href=""https://docs.docker.com/engine/reference/run/#volume-shared-filesystems"" rel=""nofollow noreferrer"">https://docs.docker.com/engine/reference/run/#volume-shared-filesystems</a></p>
",800,2018-02-28T13:37:56.083,"['Removing intermediate container b3ff83bbf273\n', 'docker run -d -v /var/container_data/mysql:/var/lib/mysql mysql_image\n']"
389,3489,3488,CC BY-SA 3.0,2018-02-28T16:49:36.013,"<p>I've always had issues with using <code>ansible</code> to provision Windows machines with Packer due to the <code>winrm</code> connections breaking, <a href=""https://github.com/hashicorp/packer/issues/4904"" rel=""nofollow noreferrer"">example issue</a>.</p>

<p>A workaround which you can do is to use the <code>shell-local</code> on your host machine which calls the Ansible playbook with the new host (although you would need to give it the IP address of your Windows Docker machine).</p>

<p>I've added the example which I did to get a test working. This uploads <code>ip.cmd</code> to the Windows virtual machine, which gets its IP address, and is then downloaded back to the <code>destination</code>. The ansible playbook is then called against that.</p>

<pre><code>""provisioners"": [
        {
            ""type"": ""file"",
            ""source"": ""ip.cmd"",
            ""destination"": ""C:/tmp/ip.cmd""
        },
        {
            ""type"": ""windows-shell"",
            ""inline"": [
                ""echo [{{ user `ansible_group` }}] &gt; C:/tmp/hosts"",
                ""C:/tmp/ip.cmd""
            ]
        },
        {
            ""type"": ""file"",
            ""direction"": ""download"",
            ""source"": ""C:/tmp/hosts"",
            ""destination"": ""./ansible/hosts""
        },
        {
            ""type"": ""shell-local"",
            ""command"": ""ANSIBLE_CONFIG=./ansible.cfg ansible-playbook -v -i ./ansible/hosts -l \""{{ user `ansible_group` }}\"" -e \""ansible_user={{ user `username` }} ansible_password={{ user `password` }} ansible_become_pass={{ user `password` }} ansible_port=5986 ansible_connection=winrm ansible_winrm_server_cert_validation=ignore \"" ./ansible/site.yml""
        }
</code></pre>

<p>where <code>ip.cmd</code> gets the IP address of the Windows host:</p>

<pre><code>@echo off
FOR /F ""tokens=2,3"" %%A IN ('ping %computername% -n 1 -4') DO IF ""from""== ""%%A"" set ""IP=%%~B""
echo %IP:~0,-1% &gt;&gt; C:/tmp/hosts
</code></pre>

<p><a href=""https://groups.google.com/forum/#!starred/packer-tool/AXZSY6UoBNo"" rel=""nofollow noreferrer"">source</a></p>
",4289,2018-02-28T16:49:36.013,"['""provisioners"": [\n        {\n            ""type"": ""file"",\n            ""source"": ""ip.cmd"",\n            ""destination"": ""C:/tmp/ip.cmd""\n        },\n        {\n            ""type"": ""windows-shell"",\n            ""inline"": [\n                ""echo [{{ user `ansible_group` }}] > C:/tmp/hosts"",\n                ""C:/tmp/ip.cmd""\n            ]\n        },\n        {\n            ""type"": ""file"",\n            ""direction"": ""download"",\n            ""source"": ""C:/tmp/hosts"",\n            ""destination"": ""./ansible/hosts""\n        },\n        {\n            ""type"": ""shell-local"",\n            ""command"": ""ANSIBLE_CONFIG=./ansible.cfg ansible-playbook -v -i ./ansible/hosts -l \\""{{ user `ansible_group` }}\\"" -e \\""ansible_user={{ user `username` }} ansible_password={{ user `password` }} ansible_become_pass={{ user `password` }} ansible_port=5986 ansible_connection=winrm ansible_winrm_server_cert_validation=ignore \\"" ./ansible/site.yml""\n        }\n', '@echo off\nFOR /F ""tokens=2,3"" %%A IN (\'ping %computername% -n 1 -4\') DO IF ""from""== ""%%A"" set ""IP=%%~B""\necho %IP:~0,-1% >> C:/tmp/hosts\n']"
390,3499,3498,CC BY-SA 3.0,2018-03-01T15:45:39.180,"<p>Different approaches can be useful for different setups. You can use <em>tags</em> in some cases, or <em>conditional includes</em> (as you describe) in other cases.</p>

<blockquote>
  <p>On the other hand, it generates quite a payload of “skipped” tasks in ansible logs, which raises a red sign to me.</p>
</blockquote>

<p>You should get familiar with <a href=""https://serverfault.com/questions/875247/whats-the-difference-between-include-tasks-and-import-tasks"">difference between static and dynamic includes</a> in Ansible.</p>

<p>So if you use static includes, you will get a lot of skipped tasks, because every task in every file is added to execution queue but most of them are skipped because of <code>when</code> statement.</p>

<p><code>tasks/main.yml</code> of your role with actions <code>install</code>/<code>uninstall</code>:</p>

<pre><code>- include: install.yml
  when: action == 'install'
- include: uninstall.yml
  when: action == 'uninstall'
</code></pre>

<p>But if you use dynamic includes, only required tasks are added to execution queue and <code>skipped</code> message is displayed for skipped includes.</p>

<p><code>tasks/main.yml</code>:</p>

<pre><code>- include_tasks: install.yml
  when: action == 'install'
- include_tasks: uninstall.yml
  when: action == 'uninstall'
</code></pre>

<p>More on that, you can avoid <code>skipped</code> message altogether like this:</p>

<p><code>tasks/main.yml</code>:</p>

<pre><code>- include_tasks: '{{ action }}.yml'
</code></pre>

<p>The drawback of dynamic includes is that you can't do complete static analysis of your playbook (like syntax checks, etc.) because many things are know only in runtime.</p>
",3509,2018-03-01T15:45:39.180,"[""- include: install.yml\n  when: action == 'install'\n- include: uninstall.yml\n  when: action == 'uninstall'\n"", ""- include_tasks: install.yml\n  when: action == 'install'\n- include_tasks: uninstall.yml\n  when: action == 'uninstall'\n"", ""- include_tasks: '{{ action }}.yml'\n""]"
391,3507,3442,CC BY-SA 3.0,2018-03-01T19:10:53.827,"<p>If you want to keep it simple, try the generic webhook trigger plugin.</p>

<p><a href=""https://plugins.jenkins.io/generic-webhook-trigger"" rel=""nofollow noreferrer"">https://plugins.jenkins.io/generic-webhook-trigger</a></p>

<p>You can trigger a build by sending an http POST using a JSON body or URL parameters.</p>

<p><a href=""https://i.stack.imgur.com/e5Zod.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/e5Zod.png"" alt=""generic-webhook-trigger""></a></p>

<p>Parse the JSON request</p>

<pre><code>def req = readJSON text: payload
</code></pre>

<p>Now you can use it in your pipeline assuming you had a deploy function.</p>

<pre><code>deploy(req.environment, req.branch)
</code></pre>

<p>I must agree with @Tensibai. Two CI/CD systems on the surface does seem overly complex. You might want to consider sticking with one if possible.</p>
",6579,2018-03-01T19:10:53.827,"['def req = readJSON text: payload\n', 'deploy(req.environment, req.branch)\n']"
392,3522,3451,CC BY-SA 3.0,2018-03-02T19:16:34.270,"<p>I can provide some personal experience here. I worked at a company that had the same need. The product was a BeagleBone (like an Arduino or Raspberry Pi) that ran our software and sent data back to our SaaS. It had to be installed inside customer networks, and be a little black box that they didn't touch.</p>

<p>When I walked into this company, management of the systems was a nightmare. Networking was a nightmare. OS updates, keeping them online, shipping new versions of the software, etc... it was a nightmare.</p>

<p>The path we ended up choosing ended up working really well: The entire application and supporting packages was shipped as a Docker container. That allowed us to easily ship application code changes and control versions of any supporting software (ffmpg, gcc, etc...).</p>

<p>With the application abstracted, that simply left making the OS as minimal as possible. All we needed was a dead simple OS that could run docker. One of our low level engineers actually made our own in-house fork of Debian (if I remember) and we shipped that embedded directly into the devices.</p>

<p>We already had a service contract with all of our customers to service these machines yearly, so when our field technician went on-site, the procedure was to replace the entire unit with a fresh hardware that came with the latest embedded OS. We didn't have to make many OS changes just to run Docker, so often times swapping wasn't even necessary. But out of procedure, we always swapped hardware whether it was an emergency service call or the yearly maintenance.</p>

<p>I can't say if this would be a standard approach or not, but just that it worked really well for us and was a life saver. It sounds like your idea of shipping the OS as an immutable image is along the same lines.</p>

<p><strong>Edit</strong>: When I left, we were still using home grown bash scripts to automate the Docker container deployments, but the idea was to move toward a config management tool (Like Chef, Salt, or Ansible). The basic premise is that you have a <em>private</em> Docker registry somewhere, then on the devices you would simply run a couple commands:</p>

<pre><code>docker pull my-private-registry/my-custom-image:latest
docker run my-custom-image:latest
</code></pre>

<p>If you are going to always be using the 'latest' tag, you could then have your devices ship with a cronjob that has then always shut down their local running Docker container, and re-pull the 'latest' tag every week during a scheduled maintenance window.</p>
",6578,2018-03-05T22:51:50.603,['docker pull my-private-registry/my-custom-image:latest\ndocker run my-custom-image:latest\n']
393,3532,3526,CC BY-SA 3.0,2018-03-03T13:07:08.107,"<p>Unlike the declarative pipelines in Jenkins, bitbucket does not seem to have such functionality. In order to prevent code duplication a script was created and the current bitbucket-pipelines looks as follows:</p>

<pre><code>options:
  docker: true

pipelines:
  default:
    - step:
        script:
          - ./build-script.sh API true true
    - step:
        script:
          - ./build-script.sh Write true true
        deployment: production
</code></pre>
",210,2018-03-03T13:07:08.107,['options:\n  docker: true\n\npipelines:\n  default:\n    - step:\n        script:\n          - ./build-script.sh API true true\n    - step:\n        script:\n          - ./build-script.sh Write true true\n        deployment: production\n']
394,3538,3537,CC BY-SA 3.0,2018-03-04T06:16:21.967,"<p>What is the Kubernetes version? Is it >1.8 ? (which has RBAC enabled by default).</p>

<p>The error message says that the Kubernetes Dashboard service account is not allowed to list configmaps in default namespace. RBAC by default is deny-all. You need to explicitly grant permissions.</p>

<p>You can create the following <code>ClusterRoleBinding</code> to grant dashboard full admin privileges.</p>

<pre><code>apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: kubernetes-dashboard
  labels:
    k8s-app: kubernetes-dashboard
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: kubernetes-dashboard
  namespace: kube-system
</code></pre>

<p>Save the above block into <code>dashboard-rolebinding.yaml</code> and create it on the cluster:</p>

<pre><code>kubectl create -f dashboard-rolebinding.yaml
</code></pre>

<p><strong>IMPORTANT</strong>: Make sure your dashboard is secured from outside before doing this. Otherwise anyone can have complete access to your cluster. Here is a great article about securing  kubernetes dashboard, from Heptio: <a href=""https://blog.heptio.com/on-securing-the-kubernetes-dashboard-16b09b1b7aca"" rel=""nofollow noreferrer"">https://blog.heptio.com/on-securing-the-kubernetes-dashboard-16b09b1b7aca</a> writted by Joe Beda himself.</p>
",6760,2018-03-04T06:16:21.967,"['apiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: kubernetes-dashboard\n  labels:\n    k8s-app: kubernetes-dashboard\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cluster-admin\nsubjects:\n- kind: ServiceAccount\n  name: kubernetes-dashboard\n  namespace: kube-system\n', 'kubectl create -f dashboard-rolebinding.yaml\n']"
395,3560,3539,CC BY-SA 3.0,2018-03-07T12:21:54.393,"<p>You could use environment variables e.g.:</p>

<pre><code>export VERSION=2
</code></pre>

<p>docker-compose.yml:</p>

<pre><code>...
  serviceName:
    image: ""imageName:${VERSION}""
  ....
</code></pre>
",6769,2018-03-07T12:21:54.393,"['export VERSION=2\n', '...\n  serviceName:\n    image: ""imageName:${VERSION}""\n  ....\n']"
396,3563,3539,CC BY-SA 3.0,2018-03-07T14:43:19.830,"<p>Another way to execute the @golfNintyNine answer is putting inside docker-compose.yml the environment variable:</p>

<pre><code>serviceName:
image: ""imageName:${VERSION}""
</code></pre>

<p>And then executing simply:</p>

<pre><code>$ VERSION=2 docker-compose up
</code></pre>

<p>Also you can put all together inside script file like this:</p>

<pre><code>#!/bin/bash

function usage {
    cat &lt;&lt; EOF &gt;&amp;2
Version argument is required, please use -v or --version.
EOF
    exit 1
}


OPTS=`getopt -o v: -l version: -- ""$@""`


if [ $? != 0 ] ; then usage ; fi

eval set -- ""$OPTS""

while true; do
    case ""$1"" in
        -v | --version ) export VERSION=""$2""; shift 2;;
        -- ) shift; break ;;
    esac
done

if [ -z $VERSION ]
then
    usage
fi

docker-compose up
</code></pre>
",6775,2018-03-07T14:43:19.830,"['serviceName:\nimage: ""imageName:${VERSION}""\n', '$ VERSION=2 docker-compose up\n', '#!/bin/bash\n\nfunction usage {\n    cat << EOF >&2\nVersion argument is required, please use -v or --version.\nEOF\n    exit 1\n}\n\n\nOPTS=`getopt -o v: -l version: -- ""$@""`\n\n\nif [ $? != 0 ] ; then usage ; fi\n\neval set -- ""$OPTS""\n\nwhile true; do\n    case ""$1"" in\n        -v | --version ) export VERSION=""$2""; shift 2;;\n        -- ) shift; break ;;\n    esac\ndone\n\nif [ -z $VERSION ]\nthen\n    usage\nfi\n\ndocker-compose up\n']"
397,3597,2624,CC BY-SA 3.0,2018-03-09T20:18:44.130,"<p>Take a look at <a href=""http://docs.ansible.com/ansible/latest/playbooks_delegation.html#delegation"" rel=""nofollow noreferrer"">Delegation</a> - you can delegate the execution of tasks to a different host from within a playbook:</p>

<pre><code>  - name: enable the server in haproxy
    haproxy: 'state=enabled backend=myapplb host={{ inventory_hostname }} socket=/var/lib/haproxy/stats'
    delegate_to: ""{{ item }}""
    with_items: groups.lbservers
</code></pre>
",2807,2018-03-09T20:18:44.130,"['  - name: enable the server in haproxy\n    haproxy: \'state=enabled backend=myapplb host={{ inventory_hostname }} socket=/var/lib/haproxy/stats\'\n    delegate_to: ""{{ item }}""\n    with_items: groups.lbservers\n']"
398,3600,3599,CC BY-SA 3.0,2018-03-10T02:48:11.400,"<p>Here's a solution I've used in cases like this - I utilize <a href=""http://docs.ansible.com/ansible/2.4/intro.html"" rel=""nofollow noreferrer"">Ansible</a> to manage Docker containers, and <a href=""http://docs.ansible.com/ansible/2.4/vault.html"" rel=""nofollow noreferrer"">Ansible Vault</a> to store secrets for those containers. </p>

<h3>Ansible Playbook to run MongoDB container</h3>

<p>Your <code>playbook.yml</code> may look something like this:</p>

<pre><code>- name: run mongodb docker container
  docker_container:
    name: mongo-container
    image: mongo
    ports:
      - ""27017:27017""
    env:
      MONGO_INITDB_DATABASE: ""{{secret_db_name}}""
      MONGO_INITDB_ROOT_USERNAME: ""{{secret_db_user}}""
      MONGO_INITDB_ROOT_PASSWORD: ""{{secret_db_pass}}""
</code></pre>

<ul>
<li>As you might notice, the <a href=""http://docs.ansible.com/ansible/latest/docker_container_module.html"" rel=""nofollow noreferrer""><code>docker_container</code></a> syntax looks a lot like what you'd write in a Docker Compose YML file.</li>
<li>The difference is that your <em>secrets</em> are managed in variables (the <code>{{}}</code> is <a href=""http://docs.ansible.com/ansible/latest/playbooks_variables.html#using-variables-about-jinja2"" rel=""nofollow noreferrer"">Ansible Jinja2 variables</a>).</li>
<li>Here's a list of <a href=""http://docs.ansible.com/ansible/latest/list_of_cloud_modules.html#docker"" rel=""nofollow noreferrer"">Ansible Modules</a> for interacting with Docker.</li>
</ul>

<h3>Vault file to manage your <code>mongodb</code> secrets</h3>

<p>The <code>vault.yml</code> file would contain the definitions of your secrets in an encrypted form.</p>

<pre><code>secret_db_name: foodb
secret_db_user: foo
secret_db_pass: bar@123
</code></pre>

<p>You can use <a href=""http://docs.ansible.com/ansible/2.4/vault.html"" rel=""nofollow noreferrer""><code>ansible-vault</code> commands</a> to create encrypted files  (for e.g in version-control). </p>

<h3>Getting it all together</h3>

<p>When you want to run your Docker container, you would run an Ansible command</p>

<p><code>ansible-playbook playbook.yml --ask-vault-pass</code></p>

<p>Which would </p>

<ul>
<li>ask you for your vault password file, </li>
<li>decrypt the vault file and pass the variables to the playbook;</li>
<li>run the docker mongodb container with your secret credentials </li>
</ul>

<p>All whilst ensuring your credentials are not publicly visible.</p>

<h3>Notes</h3>

<ul>
<li>I've used this approach to provision Dockerized databases on remote managed servers in a declarative way.</li>
<li>You introduce one more tool, a 'wrapper' around Docker. In my experience DevOps <em>toolchains</em> work better than utilizing single tools. However, this may or may not be a constraint for you. </li>
</ul>
",6544,2018-03-10T02:52:16.913,"['- name: run mongodb docker container\n  docker_container:\n    name: mongo-container\n    image: mongo\n    ports:\n      - ""27017:27017""\n    env:\n      MONGO_INITDB_DATABASE: ""{{secret_db_name}}""\n      MONGO_INITDB_ROOT_USERNAME: ""{{secret_db_user}}""\n      MONGO_INITDB_ROOT_PASSWORD: ""{{secret_db_pass}}""\n', 'secret_db_name: foodb\nsecret_db_user: foo\nsecret_db_pass: bar@123\n']"
399,3601,3588,CC BY-SA 3.0,2018-03-10T06:50:04.133,"<p>For example you want to create a file you can use :</p>

<pre><code> name: Create file
 shell: ""touch abc""
 become_user: &lt;username&gt;
 become: yes
</code></pre>

<p>This is equivalent to ::
sudo su username -c ""touch abc""</p>
",6861,2018-03-10T06:50:04.133,"[' name: Create file\n shell: ""touch abc""\n become_user: <username>\n become: yes\n']"
400,3605,3588,CC BY-SA 3.0,2018-03-10T13:10:18.447,"<p>Become super user at the play level and become another user at the task level:</p>

<pre><code>- hosts: all
  become: yes
  tasks:

    - file:
        path: /tmp/test
        state: touch
      become_user: www-data
</code></pre>

<p>Validation:</p>

<pre><code>$ ls -l /tmp | grep test
-rw-r--r-- 1 www-data www-data    0 Mär 10 14:08 test
</code></pre>

<p>For very simple cases, a workaround like the following could also help, but this doesn't really scale, as you cannot use ansible modules with this strategy:</p>

<pre><code>- name: test
  command: ""sudo -u www-data whoami""
  become: true
</code></pre>

<p>Output (extract): <code>""stdout"": ""www-data""</code></p>
",5922,2018-03-10T13:10:18.447,"['- hosts: all\n  become: yes\n  tasks:\n\n    - file:\n        path: /tmp/test\n        state: touch\n      become_user: www-data\n', '$ ls -l /tmp | grep test\n-rw-r--r-- 1 www-data www-data    0 Mär 10 14:08 test\n', '- name: test\n  command: ""sudo -u www-data whoami""\n  become: true\n']"
401,3619,3609,CC BY-SA 3.0,2018-03-12T23:08:11.423,"<p>For using kube-lego you can follow this step:</p>

<p>Visit <a href=""https://github.com/jetstack/kube-lego/tree/master/examples/gce"" rel=""nofollow noreferrer"">https://github.com/jetstack/kube-lego/tree/master/examples/gce</a> and follow instructions to have a kube-lego namespace working.</p>

<p>Create an ingress like this:</p>

<pre><code>    apiVersion: extensions/v1beta1
    kind: Ingress
    metadata:
      name: app-ingress
      annotations:
        kubernetes.io/tls-acme: ""true""
        kubernetes.io/ingress.class: ""gce""
    spec:
      backend:
        serviceName: backend-service
        servicePort: 80
      tls:
      - hosts:
        - example.com
        - api.example.com
        secretName: app-ingress-tls
      rules:
      - host: example.com
        http:
          path:
          - path: /*
            backend:
              serviceName: backend-service
              servicePort: 443
      - host: api.example.com
        http:
          path:
          - path: /*
            backend:
              serviceName: backend-service
              servicePort: 443
</code></pre>

<p>remember to replace backend-service with your own service name and exampl.com with your domain.</p>

<p>You can put as more host sections as you need, each host section should be associated with a domain on the tls section.</p>

<p>Use the app-ingress-tls secret to mount as a volume on your service.</p>
",6775,2018-03-12T23:08:11.423,"['    apiVersion: extensions/v1beta1\n    kind: Ingress\n    metadata:\n      name: app-ingress\n      annotations:\n        kubernetes.io/tls-acme: ""true""\n        kubernetes.io/ingress.class: ""gce""\n    spec:\n      backend:\n        serviceName: backend-service\n        servicePort: 80\n      tls:\n      - hosts:\n        - example.com\n        - api.example.com\n        secretName: app-ingress-tls\n      rules:\n      - host: example.com\n        http:\n          path:\n          - path: /*\n            backend:\n              serviceName: backend-service\n              servicePort: 443\n      - host: api.example.com\n        http:\n          path:\n          - path: /*\n            backend:\n              serviceName: backend-service\n              servicePort: 443\n']"
402,3620,3616,CC BY-SA 3.0,2018-03-13T08:17:34.317,"<p>Managed to get rid of error by </p>

<pre><code>pip install awscli --force-reinstall --upgrade
</code></pre>

<p>then from rundeck interface:</p>

<pre><code>aws configure set aws_access_key_id default_access_key
aws configure set aws_secret_access_key default_secret_key
aws configure set default.region us-west-2
</code></pre>
",6523,2018-03-13T16:49:31.343,"['pip install awscli --force-reinstall --upgrade\n', 'aws configure set aws_access_key_id default_access_key\naws configure set aws_secret_access_key default_secret_key\naws configure set default.region us-west-2\n']"
403,3635,3633,CC BY-SA 3.0,2018-03-14T11:33:37.463,"<p>I am accessing my home network with a VPN running in a docker container in my home server.</p>

<p>That sounds similar to what you want to do.</p>

<p>Here's how I configured it (using <a href=""https://hub.docker.com/r/kylemanna/openvpn/"" rel=""nofollow noreferrer"">this docker image</a> - note that the documentation of the docker image should be enough)</p>

<ol>
<li><p>Use a “convenience” environment variable to store the path to your persistent storage location that will be bind-mounted to the container.</p>

<pre><code>OVPN_DATA=""/n7wings/openvpn/""
</code></pre></li>
<li><p>Run an ephemeral instance (–rm) of the image to initialize the data directory of the container (ovpn-host should be the hostname of your openvpn server)</p>

<pre><code>docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_genconfig -u udp://ovpn-host
</code></pre></li>
<li><p>Run an interactive ephemeral instance of the image to generate the opevnpn CA certificate and server key (you will have to type your passphrase for the private key) </p>

<pre><code>docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn ovpn_initpki
</code></pre></li>
<li><p>Run the VPN service: start and detach the container (-d) and map a host port to the UDP container port where the openvpn server process is listening (1194). In this example the host port will be 1195</p>

<pre><code>docker run -v $OVPN_DATA:/etc/openvpn -d -p 1195:1194/udp --cap-add=NET_ADMIN kylemanna/openvpn
</code></pre></li>
<li><p>Generate client configuration (i.e., add a user to the VPN). If you omit the nopass option, the client key will be encrypted with a passphrase. </p>

<pre><code>docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa build-client-full vince nopass
</code></pre>

<p>The client key will be in <code>${OVPN_DATA}/pki/private</code> and the certificate in <code>${OVPN_DATA}/pki/issued</code></p></li>
<li><p>Retrieve the client configuration to a local file:</p>

<pre><code>docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_getclient vince &gt; vince.ovpn
</code></pre></li>
</ol>

<p>If you need to add more users, just repeat the last two steps to create a user configuration on the server and retrieve the ovpn file.</p>

<p>Full reference: <a href=""https://thealarmclocksixam.com/2017/03/07/setup-your-vpn-in-docker-with-openvpn-in-5-minutes/"" rel=""nofollow noreferrer"">https://thealarmclocksixam.com/2017/03/07/setup-your-vpn-in-docker-with-openvpn-in-5-minutes/</a></p>
",5922,2018-03-14T12:55:32.233,"['OVPN_DATA=""/n7wings/openvpn/""\n', 'docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_genconfig -u udp://ovpn-host\n', 'docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn ovpn_initpki\n', 'docker run -v $OVPN_DATA:/etc/openvpn -d -p 1195:1194/udp --cap-add=NET_ADMIN kylemanna/openvpn\n', 'docker run -v $OVPN_DATA:/etc/openvpn --rm -it kylemanna/openvpn easyrsa build-client-full vince nopass\n', 'docker run -v $OVPN_DATA:/etc/openvpn --rm kylemanna/openvpn ovpn_getclient vince > vince.ovpn\n']"
404,3637,3633,CC BY-SA 3.0,2018-03-14T13:07:25.770,"<blockquote>
  <p>I just want to ""get inside"" the internal network I have shared with my VPS [...] using SSH/RDP/etc. with a single connection instead of having 10 profiles in PuTTY for each server.</p>
</blockquote>

<p>For what it worth you can achieve that pretty simply using your ssh client as a socks server and configuring your clients (RDP/Browse/Ssh client) to use a localhost: as a socks proxy and then access your inner network. A SSH tunnel is a tunnel as secure as a VPN tunnel; main difference with a VPN is there's no routing involved.</p>

<blockquote>
  <p>through a VPN for added security and commodity</p>
</blockquote>

<p>Forget this idea a VPN is for security, you won't add security to your network with a VPN, that's no more security than a SSH tunnel and usually even less when not properly configured. The commodity point is absolutely valid and a good reason to go this way :)</p>

<hr>

<p>So clearly you can, I wonder why  you want the VPN server to run within docker as this add a routing complexity you should avoid if you're not comfortable with the overall routing involved before. </p>

<p>Anyway the generic scheme for a request would be:</p>

<pre><code>client stations --&gt; client station routing table --&gt; client VPN interface --&gt; VPN host server --&gt; target network
</code></pre>

<p>The problem involved is understanding a VPN is made of a tunel <strong>AND</strong> routing configuration, this needs some configuration to avoid breaking your connection to the VPN server once the tunnel is established (usual caveat is the vpn client setting up a new default route and thus breaking your workstation ability to talk with the VPN server through local gateway). </p>

<p>The VPN client job is to establish the tunnel and then configure your client station routing table to route packets for the destination network through the tunnel interface.</p>

<p><a href=""https://devops.stackexchange.com/a/3635/13"">Vincenzo's answer</a> to your question give the methodology to start an openVPN server container so I'll let you start from there but I highly encourage you to read more about the subject to avoid a false sense of security.</p>
",13,2018-03-14T13:07:25.770,['client stations --> client station routing table --> client VPN interface --> VPN host server --> target network\n']
405,3640,2917,CC BY-SA 3.0,2018-03-15T09:14:03.597,"<pre><code>def repository = 'git@somerepo' 
import hudson.tasks.Shell
job = Jenkins.instance.createProject(FreeStyleProject, 'TestJob')
job.setDescription(""Some description"") 
job.displayName = 'SomeTestJob(TESTING groovy)' 
job.scm = new hudson.plugins.git.GitSCM(repository) 
job.scm.branches = [new BranchSpec('*/master')]
job.save()
</code></pre>

<p>Thanks a lot Michael Durrant for giving that link !</p>
",5776,2018-03-15T09:14:03.597,"['def repository = \'git@somerepo\' \nimport hudson.tasks.Shell\njob = Jenkins.instance.createProject(FreeStyleProject, \'TestJob\')\njob.setDescription(""Some description"") \njob.displayName = \'SomeTestJob(TESTING groovy)\' \njob.scm = new hudson.plugins.git.GitSCM(repository) \njob.scm.branches = [new BranchSpec(\'*/master\')]\njob.save()\n']"
406,3642,3582,CC BY-SA 3.0,2018-03-15T14:12:35.963,"<p>I figured out the issue. The ""Question:"" parameter needs to be omitted:<br>
    ---<br>
    - hosts: localhost<br>
      connection: local<br>
      gather_facts: false  </p>

<pre><code>  tasks:
    - name: Expect Attempt
      expect:
        echo: yes
        command: telnet 10.233.82.7 2033
        responses:
          Connected to port 33. :  ""echo""
          login: ""admin""
          Password: ""password""
</code></pre>
",6591,2018-03-15T14:20:24.493,"['  tasks:\n    - name: Expect Attempt\n      expect:\n        echo: yes\n        command: telnet 10.233.82.7 2033\n        responses:\n          Connected to port 33. :  ""echo""\n          login: ""admin""\n          Password: ""password""\n']"
407,3644,3639,CC BY-SA 3.0,2018-03-15T16:15:12.620,"<p>A capture group is a <a href=""https://www.regular-expressions.info/refcapture.html"" rel=""nofollow noreferrer"">type of backreference</a>. Saltstack, being python based, <a href=""https://docs.python.org/2/library/re.html"" rel=""nofollow noreferrer"">uses the re.match object</a> to do regular expression matching, which <a href=""https://stackoverflow.com/questions/15163092/python-regex-backreference-a-matching-regex-group"">appears to support backreferences</a>, so these backreferences are allowed.</p>
<p>However, you be unable to pass the value of the backreference <code>\1</code> in the <code>- include_pat</code> field back to <code>- name</code> because the <code>- name</code> field is never processed by the <code>re.match</code> object. Even if it were, variable scope would prevent you from sharing the backreference between <code>re.match</code> calls.</p>
<p>Instead, you will need to do one of the following:</p>
<ul>
<li><p>Rename all the files in <code>- source</code> from <code>myfile.conf.template</code> to <code>myfile.conf</code></p>
</li>
<li><p>Use cmd.run to do a <a href=""https://blogs.technet.microsoft.com/heyscriptingguy/2013/11/22/use-powershell-to-rename-files-in-bulk/"" rel=""nofollow noreferrer"">batch</a> file <a href=""https://stackoverflow.com/questions/17271586/rename-multiple-files-in-cmd"">rename</a> after your <code>file.recurse</code> and add to your <code>file.recurse</code> an <a href=""https://docs.saltstack.com/en/latest/ref/states/requisites.html#onchanges"" rel=""nofollow noreferrer"">onchanges</a> pointed to a previous event in order to defeat the idempotency (that is, to prevent it from writing out the .template files every time salt runs). You will also be sure to use a <a href=""https://docs.saltstack.com/en/latest/ref/states/requisites.html#require"" rel=""nofollow noreferrer"">require</a> and <code>onchanges</code> in your cmd.run that references <code>copy_template</code></p>
<p>This will have the unfortunate side-effect that you will never be able to update your jinja templates. You will only be able to deploy them the first time - at least not without first deleting what is there, and then re-writing and re-copying from the source.</p>
</li>
<li><p>Use <code>file.managed</code> for every template file.</p>
</li>
</ul>
<p>For example:</p>
<pre><code>copy_template1:
  file.managed:
    - name: '{{ service_path }}\template1.conf'
    - template: jinja
    - source: {{ pillar['locations']['systemtoolsfolder'] }}\template1.conf.template
copy_template2:
  file.managed:
    - name: '{{ service_path }}\template2.conf'
    - template: jinja
    - source: {{ pillar['locations']['systemtoolsfolder'] }}\template2.conf.template
...
and so forth
</code></pre>
",2845,2018-03-16T20:54:42.830,"[""copy_template1:\n  file.managed:\n    - name: '{{ service_path }}\\template1.conf'\n    - template: jinja\n    - source: {{ pillar['locations']['systemtoolsfolder'] }}\\template1.conf.template\ncopy_template2:\n  file.managed:\n    - name: '{{ service_path }}\\template2.conf'\n    - template: jinja\n    - source: {{ pillar['locations']['systemtoolsfolder'] }}\\template2.conf.template\n...\nand so forth\n""]"
408,3655,3648,CC BY-SA 3.0,2018-03-16T17:38:06.857,"<p>One could use conditional builds <a href=""https://docs.travis-ci.com/user/conditional-builds-stages-jobs/"" rel=""nofollow noreferrer"">https://docs.travis-ci.com/user/conditional-builds-stages-jobs/</a></p>

<p>If code is merged into master one could decide to deploy code to production, but I personally prefer a human intervention by a Product Owner.</p>

<blockquote>
<pre><code>jobs:
  include:
      if: branch = master
</code></pre>
</blockquote>

<p>or</p>

<blockquote>
<pre><code>stages:
  - name: deploy
    # require the branch name to be master
    if: branch = master
</code></pre>
</blockquote>

<p>At other projects I preferred to deploy only tags to enforce the git flow (tags should be created otherwise no deployment to production).</p>

<blockquote>
<pre><code>stages:
  - name: deploy
    # require the tag name to match a regular expression
    if: tag =~ ^v1
</code></pre>
</blockquote>

<p>One could also try (I did not try it yet) whether the <code>if</code> works in combination with script sections:</p>

<p><a href=""https://github.com/030/ansible-firefox/blob/master/.travis.yml"" rel=""nofollow noreferrer"">https://github.com/030/ansible-firefox/blob/master/.travis.yml</a></p>

<p>Last remark: I would avoid creating such scripts (the ones you included in the question) as most CI tools contain condition checks.</p>
",210,2018-03-16T17:38:06.857,"['jobs:\n  include:\n      if: branch = master\n', 'stages:\n  - name: deploy\n    # require the branch name to be master\n    if: branch = master\n', 'stages:\n  - name: deploy\n    # require the tag name to match a regular expression\n    if: tag =~ ^v1\n']"
409,3657,3572,CC BY-SA 3.0,2018-03-16T17:59:08.260,"<p>One could use the <code>apt</code> module of Ansible. <a href=""http://docs.ansible.com/ansible/latest/apt_module.html"" rel=""nofollow noreferrer"">http://docs.ansible.com/ansible/latest/apt_module.html</a></p>

<p>The <code>apt</code> module uses <code>apt</code> and apt itself is able to check whether a package has already been installed and will prevent that it will be installed as it has already been installed.</p>

<p>I use this module myself as well. As the idempotence test passes it indicates that it will not install certbot if it has been installed already.</p>

<p><a href=""https://github.com/030/ansible-certbot/blob/master/tasks/Debian.yml#L10"" rel=""nofollow noreferrer"">https://github.com/030/ansible-certbot/blob/master/tasks/Debian.yml#L10</a></p>

<pre><code>- name: certbot installed
  apt:
    name: certbot
    state: latest
</code></pre>
",210,2018-03-16T17:59:08.260,['- name: certbot installed\n  apt:\n    name: certbot\n    state: latest\n']
410,3669,3664,CC BY-SA 3.0,2018-03-19T16:01:07.683,"<p><code>withEnv</code> doesn't persist environment variables.  Instead, you need to tell <code>withEnv</code> what steps to run with that environment by passing it a block.   Here is what I think you want your code to look like:</p>

<pre><code>#!groovy

node('superhost01'){
  String HOSTNAME=""host01""
  String USERNAME=""tech_user""
  withEnv(['PATH=/data/jdbc_connector']) {
    stage('Prepare') {
      checkout scm
    }

    stage('Deploy') {
      sh """"""
      scp -r config.yaml ${USERNAME}@${HOSTNAME}:$PATH
      """"""
    }
  }
}
</code></pre>

<p>As a side note, I suspect you actually want to set <code>PATH</code> to <code>/data/jdbc_connector:$PATH</code>, otherwise your checkout step will not be able to find git and your deploy step will not be able to find scp.</p>
",4115,2018-03-19T16:01:07.683,"['#!groovy\n\nnode(\'superhost01\'){\n  String HOSTNAME=""host01""\n  String USERNAME=""tech_user""\n  withEnv([\'PATH=/data/jdbc_connector\']) {\n    stage(\'Prepare\') {\n      checkout scm\n    }\n\n    stage(\'Deploy\') {\n      sh """"""\n      scp -r config.yaml ${USERNAME}@${HOSTNAME}:$PATH\n      """"""\n    }\n  }\n}\n']"
411,3677,3676,CC BY-SA 3.0,2018-03-20T01:30:59.190,"<p>I needed to install a new perl module</p>

<pre><code>yum install perl-parent
</code></pre>

<p>then I had to install <code>make</code> to install other dependencies:</p>

<pre><code>cpan
o conf make '/usr/bin/make' #or path to your make
o conf commit
</code></pre>
",6992,2018-03-20T01:30:59.190,"['yum install perl-parent\n', ""cpan\no conf make '/usr/bin/make' #or path to your make\no conf commit\n""]"
412,3684,1087,CC BY-SA 3.0,2018-03-20T19:47:22.173,"<p>I recently ran into the same error. In my case, I had rebased a branch and was attempting to push to the remote. One of the pulled commits had changed the structure of a few directories, and git refused to push after the rebase, throwing:</p>

<pre><code>fatal: ambiguous argument 'path/to/scripts': unknown revision or path not in the working tree.
Use '--' to separate paths from revisions, like this:
'git &lt;command&gt; [&lt;revision&gt;...] -- [&lt;file&gt;...]'
Cannot open directory /absolute/path/to/scripts: No such file or directory
error: failed to push some refs to 'git@host:repo'
</code></pre>

<p>I tore apart all of my git configs and could not find the cause of this anywhere. The culprit turned out to be a pre-push git hook, left over from some previous config we used to use, which included some operations on the now-defunct directory.</p>

<p>While this clearly wasn't the cause of the OP's issue, thought I'd post this here in case someone else gets bitten. Beware the git hooks...</p>
",7006,2018-03-20T19:47:22.173,"[""fatal: ambiguous argument 'path/to/scripts': unknown revision or path not in the working tree.\nUse '--' to separate paths from revisions, like this:\n'git <command> [<revision>...] -- [<file>...]'\nCannot open directory /absolute/path/to/scripts: No such file or directory\nerror: failed to push some refs to 'git@host:repo'\n""]"
413,3689,3687,CC BY-SA 3.0,2018-03-21T12:44:57.647,"<p>There's a generator for policies in IAM (Into IAM -> Policies -> Create), choosing connect gives me the following policy:</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
            ""Sid"": ""VisualEditor0"",
            ""Effect"": ""Allow"",
            ""Action"": [
                ""connect:DescribeInstance"",
                ""connect:CreateInstance"",
                ""connect:ModifyInstance"",
                ""connect:ListInstances"",
                ""connect:GetFederationTokens"",
                ""connect:DestroyInstance"",
                ""connect:GetFederationToken""
            ],
            ""Resource"": ""*""
        }
    ]
}
</code></pre>

<p>There's a warning on the action part saying:</p>

<ul>
<li>connect:DescribeInstance action requires 7 more actions to provide full permissions</li>
<li>connect:CreateInstance action requires 13 more actions to provide full permissions</li>
<li>connect:ModifyInstance action requires 10 more actions to provide full permissions</li>
</ul>

<p>Each of them says:</p>

<p>To allow an entity to call 'DescribeInstance', grant all of the following required permissions.</p>

<ul>
<li>firehose:DescribeDeliveryStream</li>
<li>firehose:ListDeliveryStreams</li>
<li>kinesis:DescribeStream</li>
<li>kinesis:ListStreams</li>
<li>kms:DescribeKey</li>
<li>kms:ListAliases</li>
<li>s3:ListAllMyBuckets</li>
</ul>

<p>To allow an entity to call 'CreateInstance', grant all of the following required permissions.</p>

<ul>
<li>ds:CreateAlias</li>
<li>ds:DeleteDirectory</li>
<li>ds:DescribeDirectories</li>
<li>firehose:DescribeDeliveryStream</li>
<li>firehose:ListDeliveryStreams</li>
<li>kinesis:DescribeStream</li>
<li>kinesis:ListStreams</li>
<li>kms:CreateGrant</li>
<li>kms:DescribeKey</li>
<li>kms:ListAliases</li>
<li>kms:RetireGrant</li>
<li>s3:CreateBucket</li>
<li>s3:ListAllMyBuckets</li>
</ul>

<p>To allow an entity to call 'ModifyInstance', grant all of the following required permissions.</p>

<ul>
<li>firehose:DescribeDeliveryStream</li>
<li>firehose:ListDeliveryStreams</li>
<li>kinesis:DescribeStream</li>
<li>kinesis:ListStreams</li>
<li>kms:CreateGrant</li>
<li>kms:DescribeKey</li>
<li>kms:ListAliases</li>
<li>kms:RetireGrant</li>
<li>s3:CreateBucket</li>
<li>s3:ListAllMyBuckets</li>
</ul>

<p>Which once compiled gives the following policy when not filtering on any resource:</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
            ""Sid"": ""VisualEditor0"",
            ""Effect"": ""Allow"",
            ""Action"": [
                ""connect:DescribeInstance"",
                ""connect:ModifyInstance"",
                ""connect:GetFederationTokens"",
                ""s3:CreateBucket"",
                ""kinesis:DescribeStream"",
                ""kms:RetireGrant"",
                ""connect:DestroyInstance"",
                ""firehose:DescribeDeliveryStream"",
                ""kinesis:ListStreams"",
                ""connect:CreateInstance"",
                ""s3:ListAllMyBuckets"",
                ""connect:ListInstances"",
                ""kms:ListAliases"",
                ""ds:DescribeDirectories"",
                ""kms:DescribeKey"",
                ""firehose:ListDeliveryStreams"",
                ""ds:CreateAlias"",
                ""kms:CreateGrant"",
                ""connect:GetFederationToken"",
                ""ds:DeleteDirectory""
            ],
            ""Resource"": ""*""
        }
    ]
}
</code></pre>
",13,2018-03-21T12:44:57.647,"['{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Sid"": ""VisualEditor0"",\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""connect:DescribeInstance"",\n                ""connect:CreateInstance"",\n                ""connect:ModifyInstance"",\n                ""connect:ListInstances"",\n                ""connect:GetFederationTokens"",\n                ""connect:DestroyInstance"",\n                ""connect:GetFederationToken""\n            ],\n            ""Resource"": ""*""\n        }\n    ]\n}\n', '{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Sid"": ""VisualEditor0"",\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""connect:DescribeInstance"",\n                ""connect:ModifyInstance"",\n                ""connect:GetFederationTokens"",\n                ""s3:CreateBucket"",\n                ""kinesis:DescribeStream"",\n                ""kms:RetireGrant"",\n                ""connect:DestroyInstance"",\n                ""firehose:DescribeDeliveryStream"",\n                ""kinesis:ListStreams"",\n                ""connect:CreateInstance"",\n                ""s3:ListAllMyBuckets"",\n                ""connect:ListInstances"",\n                ""kms:ListAliases"",\n                ""ds:DescribeDirectories"",\n                ""kms:DescribeKey"",\n                ""firehose:ListDeliveryStreams"",\n                ""ds:CreateAlias"",\n                ""kms:CreateGrant"",\n                ""connect:GetFederationToken"",\n                ""ds:DeleteDirectory""\n            ],\n            ""Resource"": ""*""\n        }\n    ]\n}\n']"
414,3691,1257,CC BY-SA 3.0,2018-03-21T16:42:59.903,"<p>This seems to be <a href=""https://github.com/openshift/origin/issues/14742"" rel=""nofollow noreferrer"">a proxy issue</a> in your config. It is solved by <a href=""https://docs.openshift.org/latest/install_config/http_proxies.html#configuring-no-proxy"" rel=""nofollow noreferrer"">setting NO_PROXY</a> as follows:</p>

<blockquote>
  <p>Edit the proxy environment variables in the OpenShift Origin control files. Ensure all of the files in the cluster are correct.</p>
</blockquote>

<pre><code>HTTP_PROXY=http://&lt;user&gt;:&lt;password&gt;@&lt;ip_addr&gt;:&lt;port&gt;/
HTTPS_PROXY=https://&lt;user&gt;:&lt;password&gt;@&lt;ip_addr&gt;:&lt;port&gt;/
NO_PROXY=master.hostname.example.com,10.1.0.0/16,172.30.0.0/16 
</code></pre>

<blockquote>
  <p>Supports host names and <a href=""https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing"" rel=""nofollow noreferrer"">CIDRs</a>. Must include the <a href=""https://en.wikipedia.org/wiki/Software-defined_networking"" rel=""nofollow noreferrer"">SDN network</a> and service IP ranges 10.1.0.0/16,172.30.0.0/16 by default.</p>
</blockquote>
",2805,2018-03-21T16:42:59.903,"['HTTP_PROXY=http://<user>:<password>@<ip_addr>:<port>/\nHTTPS_PROXY=https://<user>:<password>@<ip_addr>:<port>/\nNO_PROXY=master.hostname.example.com,10.1.0.0/16,172.30.0.0/16 \n']"
415,3699,3690,CC BY-SA 4.0,2018-03-22T13:50:24.680,"<p>Try do pull your image manually first.</p>
<pre><code>docker pull ${DOCKER_REGISTRY}imageNameX:${VERSION}
</code></pre>
<p>And then re-run your compose-file</p>
<p>It may be a bug using a private registry, or something simple as you don't have enough disk space to pull the image.</p>
",7040,2020-10-26T18:34:54.647,['docker pull ${DOCKER_REGISTRY}imageNameX:${VERSION}\n']
416,3706,3688,CC BY-SA 4.0,2018-03-23T12:21:02.610,"<p>Tensibai was correct, the telnet session in the <code>expect</code> module had to end. </p>

<p>Holding down the key combination <kbd>Ctrl</kbd>+<kbd>]</kbd> to exit wasn't going to work, so an optional escape character was chosen in the telnet command like so:</p>

<pre><code>telnet -e ! 10.224.223.10
</code></pre>
",6591,2018-08-17T20:57:54.890,['telnet -e ! 10.224.223.10\n']
417,3716,3715,CC BY-SA 3.0,2018-03-26T06:36:03.057,"<pre><code>docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}'  `id`
</code></pre>

<p>To get the IP Address of docker container.</p>

<p>Then try curl ip-address:8000.</p>
",6668,2018-03-26T06:36:03.057,"[""docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}'  `id`\n""]"
418,3718,3717,CC BY-SA 3.0,2018-03-26T08:50:40.940,"<p>I found the solution!!!</p>

<p>Views Flask-Security is packaged with a default template for each view it presents to a user. Templates are located within a sub-folder named security. The following is a list of view templates:</p>

<pre><code>security/forgot_password.html
security/login_user.html
security/register_user.html
security/reset_password.html
security/change_password.html
security/send_confirmation.html
security/send_login.html
</code></pre>

<p>Overriding these templates is simple:</p>

<ul>
<li>Create a folder named security within your application’s templates folder</li>
<li>Create a template with the same name for the template you wish to override</li>
</ul>
",7098,2018-03-26T20:30:40.087,['security/forgot_password.html\nsecurity/login_user.html\nsecurity/register_user.html\nsecurity/reset_password.html\nsecurity/change_password.html\nsecurity/send_confirmation.html\nsecurity/send_login.html\n']
419,3724,3722,CC BY-SA 3.0,2018-03-26T15:12:36.347,"<p>I faced the same error .. You probably want to run <a href=""https://github.com/ansible/ansible/blob/devel/examples/scripts/ConfigureRemotingForAnsible.ps1"" rel=""nofollow noreferrer"">ConfigureRemotingForAnsible.ps1</a> script with <code>-ForceNewSSLCert</code> option on your remote machines.</p>

<pre><code>.\ConfigureRemotingForAnsible.ps1 -ForceNewSSLCert
</code></pre>
",800,2018-03-26T15:12:36.347,['.\\ConfigureRemotingForAnsible.ps1 -ForceNewSSLCert\n']
420,3729,3727,CC BY-SA 3.0,2018-03-26T18:57:40.033,"<p>One way to solve this it to use multiple pipelines. The first pipeline runs the test in docker. When that has been completed, one could call another job</p>

<p><a href=""https://jenkins.io/doc/pipeline/steps/pipeline-build-step/"" rel=""nofollow noreferrer"">https://jenkins.io/doc/pipeline/steps/pipeline-build-step/</a></p>

<p><a href=""https://support.cloudbees.com/hc/en-us/articles/221400287-How-to-pass-parameter-to-downstream-job-in-Pipeline-job-"" rel=""nofollow noreferrer"">https://support.cloudbees.com/hc/en-us/articles/221400287-How-to-pass-parameter-to-downstream-job-in-Pipeline-job-</a></p>

<blockquote>
<pre><code>node {
    paramAValue = ""paramAValue""
    paramBValue = ""paramBValue""
    build job: 'downstream-freestyle', parameters: [[$class:  'StringParameterValue', name: 'ParamA', value: paramAValue], [$class:
       'StringParameterValue', name: 'ParamB', value: paramBValue]]
}
</code></pre>
</blockquote>

<p>that runs docker-compose on Jenkins itself.</p>
",210,2018-03-26T18:57:40.033,"['node {\n    paramAValue = ""paramAValue""\n    paramBValue = ""paramBValue""\n    build job: \'downstream-freestyle\', parameters: [[$class:  \'StringParameterValue\', name: \'ParamA\', value: paramAValue], [$class:\n       \'StringParameterValue\', name: \'ParamB\', value: paramBValue]]\n}\n']"
421,3743,3742,CC BY-SA 3.0,2018-03-27T09:40:03.020,"<p>Found the problem:</p>

<p>I was using the human readable key name from the GUI.
Need to use the key's UUId ID instead (this is specified next to the name in credentials screen)</p>

<pre><code>steps {
            sshagent ( ['THIS-SHOULD-HAVE-BEEN-A-UNIQUE-ID-INSTEAD-OF-A-NAME']) {
</code></pre>
",7128,2018-03-27T09:40:03.020,"[""steps {\n            sshagent ( ['THIS-SHOULD-HAVE-BEEN-A-UNIQUE-ID-INSTEAD-OF-A-NAME']) {\n""]"
422,3746,3733,CC BY-SA 3.0,2018-03-27T12:31:53.617,"<h2>TL;DR</h2>

<p>There are a number of use cases for port mapping, but for DevOps at scale the primary reason is generally to enable mapping well-known service ports to available ports on the host. This matters when you're running large numbers of containers that use the same port by default, and you don't want to manually assign or track alternative port numbers.</p>

<h2>A <em>Very</em> Short Port Primer</h2>

<p>As a general rule, a port can only map to a single service or process on each host (multiplexing ports and multi-port services are something of an exception). Only 65,536 ports are available for services to bind, with the lowest 1,024 generally reserved for binding by the root user. Services also typically bind to well-known ports such as 22, 53, or 5432 to make the service easy to find. All of these issues matter, but it's often the last issue that typically concerns Docker hosts most.</p>

<h2>Mapping Container Ports</h2>

<p>Imagine that you have multiple PostgreSQL containers on a single host. By default, each wants to bind to port 5432 as its default. While you could certainly modify each container or run-command to bind the container's service to a unique host port, this quickly becomes a hassle at scale.</p>

<p>Instead, Docker and other container managers make it easy to <em>map</em> ports between the host OS and the container. For example:</p>

<pre><code># launch three PostgreSQL instances
for i in {1..3}; do
    docker run --rm -d -P postgres:alpine
done

# show port mappings for each container
docker container ls -q --filter=""ancestor=postgres:alpine"" |
    xargs -n1 docker port
5432/tcp -&gt; 0.0.0.0:32773
5432/tcp -&gt; 0.0.0.0:32772
5432/tcp -&gt; 0.0.0.0:32771
</code></pre>

<p>This shows that you have three instances of PostgreSQL, all happily listening on the default port of 5432 <em>inside</em> their containers. However, each instance is listening on a different port (32771, 32772, and 32773) on the Docker host!</p>

<p>At scale, you would typically use DNS, autodiscovery, linking, or container networking to help clients and applications find the right PostgreSQL instance to connect with. With just a few instances running, parsing <code>docker ps</code> may be sufficient for your needs. Your specific use case may vary.</p>
",549,2018-03-27T12:31:53.617,"['# launch three PostgreSQL instances\nfor i in {1..3}; do\n    docker run --rm -d -P postgres:alpine\ndone\n\n# show port mappings for each container\ndocker container ls -q --filter=""ancestor=postgres:alpine"" |\n    xargs -n1 docker port\n5432/tcp -> 0.0.0.0:32773\n5432/tcp -> 0.0.0.0:32772\n5432/tcp -> 0.0.0.0:32771\n']"
423,3760,3735,CC BY-SA 3.0,2018-03-28T11:34:53.980,"<p>You did everything right, it is the correct InSpec test and use with Docker!</p>

<p>You encountered a bug in InSpec that is related to InSpec's netstat output parsing combination with Alpine's netstat output. </p>

<p>See InSpec's output for <code>postgres</code> container instead of <code>postgres:alpine</code>:</p>

<pre><code>$ inspec exec docker_test.rb -t docker://1c8162517c22                                                               1d15h master[a5ff79d3]

Profile: tests from docker_test.rb (tests from docker_test.rb)
Version: (not specified)
Target:  docker://1c8162517c229ff8c87ab3e8c909f46b4370d7c63a65c0f973a5c10fdebda800

  Port 5432
     ✔  should be listening

Test Summary: 1 successful, 0 failures, 0 skipped
</code></pre>

<p>In your case, the problem is that Apline's netstat reports a different output then other Linux eg. Ubuntu, CentOS:</p>

<pre><code># netstat -tulpen
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       User       Inode      PID/Program name    
tcp        0      0 0.0.0.0:5432            0.0.0.0:*               LISTEN      999        108791     -                   
tcp6       0      0 :::5432                 :::*                    LISTEN      999        108792     -  
</code></pre>

<p>On Alpine, the inode output is missing:</p>

<pre><code>netstat -tulpen
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:5432            0.0.0.0:*               LISTEN      -
tcp        0      0 :::5432                 :::*                    LISTEN      -
</code></pre>

<p>That is why InSpec is not able to parse the netstat output. It is clearly a bug in InSpec. As a mitigation, I recommend to install the <code>iproute2</code> package for alpine containers via <code>apk add iproute2</code>. InSpec prefers <code>ss</code> over <code>netstat</code>. Please report this bug to <a href=""https://github.com/chef/inspec/issues/new"" rel=""nofollow noreferrer"">InSpec team</a>.</p>
",7149,2018-03-28T11:34:53.980,"['$ inspec exec docker_test.rb -t docker://1c8162517c22                                                               1d15h master[a5ff79d3]\n\nProfile: tests from docker_test.rb (tests from docker_test.rb)\nVersion: (not specified)\nTarget:  docker://1c8162517c229ff8c87ab3e8c909f46b4370d7c63a65c0f973a5c10fdebda800\n\n  Port 5432\n     ✔  should be listening\n\nTest Summary: 1 successful, 0 failures, 0 skipped\n', '# netstat -tulpen\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       User       Inode      PID/Program name    \ntcp        0      0 0.0.0.0:5432            0.0.0.0:*               LISTEN      999        108791     -                   \ntcp6       0      0 :::5432                 :::*                    LISTEN      999        108792     -  \n', 'netstat -tulpen\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    \ntcp        0      0 0.0.0.0:5432            0.0.0.0:*               LISTEN      -\ntcp        0      0 :::5432                 :::*                    LISTEN      -\n']"
424,3764,3763,CC BY-SA 3.0,2018-03-28T14:22:30.953,"<p>I'd use the shell module to run a simple pwd then use register to capture that </p>

<pre><code>name: current_working_directory
    shell: pwd
    register: current_working_directory
</code></pre>

<p>you can then reuse this anywhere </p>

<pre><code>{{  current_working_directory.stdout }}
</code></pre>
",7152,2018-03-28T14:22:30.953,"['name: current_working_directory\n    shell: pwd\n    register: current_working_directory\n', '{{  current_working_directory.stdout }}\n']"
425,3771,3768,CC BY-SA 3.0,2018-03-29T15:12:42.347,"<p>I checked out the Jenkins source code, and I believe Jenkins uses the last 3 <em>successful</em> or <em>unstable</em> builds for its estimation. If it out of the last 6 builds it can't find 3 <em>successful</em> or <em>unstable</em> builds, it uses 1 or more of the last <em>completed</em> (not aborted) builds. It then takes the total duration time of the ""candidates"" and simply divides it by the number of candidates (i.e. mean of the durations). Here is the code I based this off of that can be found in the Job.java file in the <a href=""https://github.com/jenkinsci/jenkins"" rel=""nofollow noreferrer"">Jenkins repo</a>:</p>

<pre><code>    /**
     * Returns candidate build for calculating the estimated duration of the current run.
     * 
     * Returns the 3 last successful (stable or unstable) builds, if there are any.
     * Failing to find 3 of those, it will return up to 3 last unsuccessful builds.
     * 
     * In any case it will not go more than 6 builds into the past to avoid costly build loading.
     */
    @SuppressWarnings(""unchecked"")
    protected List&lt;RunT&gt; getEstimatedDurationCandidates() {
        List&lt;RunT&gt; candidates = new ArrayList&lt;RunT&gt;(3);
        RunT lastSuccessful = getLastSuccessfulBuild();
        int lastSuccessfulNumber = -1;
        if (lastSuccessful != null) {
            candidates.add(lastSuccessful);
            lastSuccessfulNumber = lastSuccessful.getNumber();
        }

        int i = 0;
        RunT r = getLastBuild();
        List&lt;RunT&gt; fallbackCandidates = new ArrayList&lt;RunT&gt;(3);
        while (r != null &amp;&amp; candidates.size() &lt; 3 &amp;&amp; i &lt; 6) {
            if (!r.isBuilding() &amp;&amp; r.getResult() != null &amp;&amp; r.getNumber() != lastSuccessfulNumber) {
                Result result = r.getResult();
                if (result.isBetterOrEqualTo(Result.UNSTABLE)) {
                    candidates.add(r);
                } else if (result.isCompleteBuild()) {
                    fallbackCandidates.add(r);
                }
            }
            i++;
            r = r.getPreviousBuild();
        }

        while (candidates.size() &lt; 3) {
            if (fallbackCandidates.isEmpty())
                break;
            RunT run = fallbackCandidates.remove(0);
            candidates.add(run);
        }

        return candidates;
    }

    public long getEstimatedDuration() {
        List&lt;RunT&gt; builds = getEstimatedDurationCandidates();

        if(builds.isEmpty())     return -1;

        long totalDuration = 0;
        for (RunT b : builds) {
            totalDuration += b.getDuration();
        }
        if(totalDuration==0) return -1;

        return Math.round((double)totalDuration / builds.size());
    }
</code></pre>
",4328,2018-04-02T13:27:51.740,"['    /**\n     * Returns candidate build for calculating the estimated duration of the current run.\n     * \n     * Returns the 3 last successful (stable or unstable) builds, if there are any.\n     * Failing to find 3 of those, it will return up to 3 last unsuccessful builds.\n     * \n     * In any case it will not go more than 6 builds into the past to avoid costly build loading.\n     */\n    @SuppressWarnings(""unchecked"")\n    protected List<RunT> getEstimatedDurationCandidates() {\n        List<RunT> candidates = new ArrayList<RunT>(3);\n        RunT lastSuccessful = getLastSuccessfulBuild();\n        int lastSuccessfulNumber = -1;\n        if (lastSuccessful != null) {\n            candidates.add(lastSuccessful);\n            lastSuccessfulNumber = lastSuccessful.getNumber();\n        }\n\n        int i = 0;\n        RunT r = getLastBuild();\n        List<RunT> fallbackCandidates = new ArrayList<RunT>(3);\n        while (r != null && candidates.size() < 3 && i < 6) {\n            if (!r.isBuilding() && r.getResult() != null && r.getNumber() != lastSuccessfulNumber) {\n                Result result = r.getResult();\n                if (result.isBetterOrEqualTo(Result.UNSTABLE)) {\n                    candidates.add(r);\n                } else if (result.isCompleteBuild()) {\n                    fallbackCandidates.add(r);\n                }\n            }\n            i++;\n            r = r.getPreviousBuild();\n        }\n\n        while (candidates.size() < 3) {\n            if (fallbackCandidates.isEmpty())\n                break;\n            RunT run = fallbackCandidates.remove(0);\n            candidates.add(run);\n        }\n\n        return candidates;\n    }\n\n    public long getEstimatedDuration() {\n        List<RunT> builds = getEstimatedDurationCandidates();\n\n        if(builds.isEmpty())     return -1;\n\n        long totalDuration = 0;\n        for (RunT b : builds) {\n            totalDuration += b.getDuration();\n        }\n        if(totalDuration==0) return -1;\n\n        return Math.round((double)totalDuration / builds.size());\n    }\n']"
426,3772,3763,CC BY-SA 3.0,2018-03-29T17:28:20.133,"<p>You can use <code>env</code> lookup plugins. Plugins are always evaluated in the context of ""parent"" ansible process on the control host.</p>

<pre><code>- debug:
    msg: ""{{ lookup('env', 'PWD') }}""
</code></pre>

<p>More lookup plugins can be found here: <a href=""http://docs.ansible.com/ansible/latest/user_guide/playbooks_lookups.html"" rel=""noreferrer"">http://docs.ansible.com/ansible/latest/user_guide/playbooks_lookups.html</a></p>
",3509,2018-04-01T10:17:54.027,"['- debug:\n    msg: ""{{ lookup(\'env\', \'PWD\') }}""\n']"
427,3779,3709,CC BY-SA 3.0,2018-03-30T17:14:07.933,"<p>If I correct understand Your problem, You want to build app with diffrent ccs and images.</p>

<p>Jenkins suports maven and simplest way is to use maven profiles plus <a href=""https://maven.apache.org/plugins/maven-war-plugin/examples/adding-filtering-webresources.html"" rel=""nofollow noreferrer"">maven-war-plugin</a> 
eg.:</p>

<pre><code>&lt;build&gt;
&lt;plugins&gt;
    &lt;plugin&gt;
        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
        &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt;
        &lt;configuration&gt;
            &lt;webResources&gt;
                &lt;webResource&gt;
                    &lt;directory&gt;src/main/profile/webapp/${images.folder}&lt;/directory&gt;
                    &lt;targetPath&gt;images&lt;/targetPath&gt;
                &lt;/webResource&gt;
            &lt;/webResources&gt;
        &lt;/configuration&gt;
    &lt;/plugin&gt;
&lt;/plugins&gt;
</code></pre>

<p></p>

<pre><code>&lt;profiles&gt;
&lt;profile&gt;
    &lt;id&gt;prod_client_1&lt;/id&gt;
    &lt;properties&gt;
        &lt;images.folder&gt;prod_client_1&lt;/images.folder&gt;
    &lt;/properties&gt;
&lt;/profile&gt;
&lt;profile&gt;
    &lt;id&gt;prod_client_2&lt;/id&gt;
    &lt;properties&gt;
        &lt;images.folder&gt;prod_client_2&lt;/images.folder&gt;
    &lt;/properties&gt;
&lt;/profile&gt;
</code></pre>

<p></p>

<p>For other resources filtering <a href=""http://maven.apache.org/plugins/maven-resources-plugin/examples/include-exclude.html"" rel=""nofollow noreferrer"">maven-resources-plugin</a></p>

<p>At least should be helpful this approach <a href=""https://blog.sonatype.com/2008/04/how-to-share-resources-across-projects-in-maven/"" rel=""nofollow noreferrer"">sharing resources across projects</a></p>
",7172,2018-03-30T17:14:07.933,"['<build>\n<plugins>\n    <plugin>\n        <groupId>org.apache.maven.plugins</groupId>\n        <artifactId>maven-war-plugin</artifactId>\n        <configuration>\n            <webResources>\n                <webResource>\n                    <directory>src/main/profile/webapp/${images.folder}</directory>\n                    <targetPath>images</targetPath>\n                </webResource>\n            </webResources>\n        </configuration>\n    </plugin>\n</plugins>\n', '<profiles>\n<profile>\n    <id>prod_client_1</id>\n    <properties>\n        <images.folder>prod_client_1</images.folder>\n    </properties>\n</profile>\n<profile>\n    <id>prod_client_2</id>\n    <properties>\n        <images.folder>prod_client_2</images.folder>\n    </properties>\n</profile>\n']"
428,3784,1371,CC BY-SA 3.0,2018-03-31T21:50:48.523,"<p>As far as I know, I think Octopus doesn't packages anything. The package should come from your CI Tool (Jenkins or TeamCity maybe?)</p>

<p>Having said that, I would <em>check on your previous step</em> in the CI/CD chain to see how are you packaging your solution, and filter those folders there, before packaging.</p>

<p>That will also help you:</p>

<ul>
<li>Reducing the package size </li>
<li>Increase speed in the deployment process</li>
<li>Avoid storing unnecessary files</li>
</ul>

<p><strong>High-level suggested CI/CD Chain summary</strong></p>

<p>CI Tool</p>

<pre><code>1. Compile/Test (if you're working with a compiled language)
2. Package only required folders
3. Push to Octopus
</code></pre>

<p>Octopus (CD Tool)</p>

<pre><code>1. Store and manage final packages
</code></pre>
",7093,2018-03-31T21:50:48.523,"[""1. Compile/Test (if you're working with a compiled language)\n2. Package only required folders\n3. Push to Octopus\n"", '1. Store and manage final packages\n']"
429,3786,3785,CC BY-SA 3.0,2018-04-01T11:39:57.080,"<p>My bad, I was searching using the wrong keyword, I just found out that ignoring a file or dir is quite easy, you just need to add an gitignore style block to your yamllint config file, as :</p>

<pre><code>ignore: |
  *globalParamName.sls
  *platform.sls
</code></pre>

<p>See the official doc <a href=""https://yamllint.readthedocs.io/en/stable/configuration.html#ignoring-paths"" rel=""nofollow noreferrer"">here</a>.</p>
",6356,2018-04-01T11:39:57.080,['ignore: |\n  *globalParamName.sls\n  *platform.sls\n']
430,3797,3794,CC BY-SA 3.0,2018-04-02T18:29:51.587,"<p><code>git push origin 1.0.15</code> should work and a new tag should be added to the tags in gitlab</p>

<p><a href=""https://docs.gitlab.com/ee/university/training/topics/tags.html"" rel=""nofollow noreferrer"">https://docs.gitlab.com/ee/university/training/topics/tags.html</a></p>

<blockquote>
<pre><code>git checkout master

# Lightweight tag
git tag my_lightweight_tag

# Annotated tag
git tag -a v1.0 -m ‘Version 1.0’
git tag

git push origin --tags
</code></pre>
</blockquote>
",210,2018-04-02T18:29:51.587,['git checkout master\n\n# Lightweight tag\ngit tag my_lightweight_tag\n\n# Annotated tag\ngit tag -a v1.0 -m ‘Version 1.0’\ngit tag\n\ngit push origin --tags\n']
431,3801,3799,CC BY-SA 3.0,2018-04-03T14:52:04.220,"<p>Have you checked the documentation for <a href=""https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/"" rel=""nofollow noreferrer"">cron-jobs</a>? You can use the <code>run</code> command. </p>

<pre><code>$ kubectl run hello --schedule=""*/1 * * * *"" --restart=OnFailure --image=busybox -- /bin/sh -c ""date; echo Hello from the Kubernetes cluster""
cronjob ""hello"" created
</code></pre>

<p>This way you can loop through your customers in a bash script to deploy your containers. </p>

<p>Not knowing the big picture its hard to answer completely, but I also think ansible templates would work for this. You could turn your above config file into a jinja2 template. You could pass your customers in as a JSON dict and use with_items to loop through them or treat your customers as an inventory. This would give you an easy way to deal with certain ""snowflake"" customers.</p>

<p>EDIT: as far as doing this with Vanilla Kubernetes, I don't think it's possible. You could add your own custom controller and extend the kubernetes API. This would allow you to creat an API object that defines a customer, and then have a custom controller pick that up and create your cron job. Check out <a href=""https://github.com/coreos/prometheus-operator"" rel=""nofollow noreferrer"">https://github.com/coreos/prometheus-operator</a> as they have implemented such a solution to allow multiple teams to run there own Prometheus solution on the same cluster.</p>
",4427,2018-04-03T14:52:04.220,"['$ kubectl run hello --schedule=""*/1 * * * *"" --restart=OnFailure --image=busybox -- /bin/sh -c ""date; echo Hello from the Kubernetes cluster""\ncronjob ""hello"" created\n']"
432,3810,3798,CC BY-SA 3.0,2018-04-04T18:16:34.703,"<p>Unfortunately I had to <a href=""https://wiki.jenkins.io/display/JENKINS/Permissive+Script+Security+Plugin"" rel=""nofollow noreferrer"">disable the Groovy sandbox</a> because I ran into so many situations where methods I wanted to use in my jobs did not appear available for whitelist on the script security page.  Instead of adding a bunch of individual method calls to a whitelist or disabling the sandbox, you can also use a <a href=""https://jenkins.io/doc/book/pipeline/shared-libraries/"" rel=""nofollow noreferrer"">global shared library</a>, since global shared libraries are automatically whitelisted in the sandbox.  (The shared library approach worked well for me at first, but eventually I ran into situations where I did not feel that the code I was writing was appropriate for a shared library, so I just disabled the sandbox as it had never provided any benefit to me anyway.  Just as a warning, disabling the sandbox is usually fine in single-tenancy situations, but not in multi-tenancy Jenkins instances.)</p>

<p>As for your code, unfortunately <a href=""http://javadoc.jenkins-ci.org/hudson/triggers/SCMTrigger.SCMTriggerCause.html"" rel=""nofollow noreferrer""><code>SCMTriggerCause</code></a> doesn't appear to have any properties pointing to the actual URL of the SCM source (I can't confirm this as I don't use SCM polling on my Jenkins instance).  Instead you could try something like this:</p>

<pre><code>currentBuild.rawBuild.changeSets.collect { it.browser.repoUrl }
</code></pre>
",4115,2018-04-04T18:16:34.703,['currentBuild.rawBuild.changeSets.collect { it.browser.repoUrl }\n']
433,3811,3353,CC BY-SA 3.0,2018-04-04T18:20:20.817,"<p>The main issue I see is that you are calling Terraform at the end of every python loop. This is creating new ""state"" file. That will make it really hard to manage what you are creating. This is how I would do it. </p>

<pre><code>users = []
count = 0
for customer in data['customers']:
    username = customer['email'].split('@')[0]
    instances = customer['instances']
    count += instances
    users.extend([username] * instances)
    #print(Added {} to build list with {} instances."".format(username, instances))
myfunc(count, users)
</code></pre>

<p>then I would change...</p>

<pre><code>def myfunc(count, users):

  tf = Terraform(working_dir='/home/ja/terraform-course/demo-2b', variables={'count':count,'INSTANCE_USERS':users})
  tf.plan(no_color=IsFlagged, refresh=False, capture_output=False)
  approve = {""auto-approve"": True}
  print(tf.plan())
  print(tf.apply(**approve))
  return
</code></pre>

<p>and finally the Terraform.</p>

<pre><code>resource ""aws_key_pair"" ""mykey"" {
  key_name = ""mykey""
  public_key = ""${file(""${var.PATH_TO_PUBLIC_KEY}"")}""
}

resource ""aws_instance"" ""win-example"" {
  ami = ""${lookup(var.WIN_AMIS, var.AWS_REGION)}""
  instance_type = ""t2.medium""
  count=""${var.count}""

  key_name = ""${aws_key_pair.mykey.key_name}""
  user_data = &lt;&lt;EOF
&lt;powershell&gt;
net user ${var.INSTANCE_USERS[count.index]} '${var.INSTANCE_PASSWORD}' /add /y
net localgroup administrators ${var.INSTANCE_USERS[count.index]} /add

winrm quickconfig -q
winrm set winrm/config/winrs '@{MaxMemoryPerShellMB=""300""}'
winrm set winrm/config '@{MaxTimeoutms=""1800000""}'
winrm set winrm/config/service '@{AllowUnencrypted=""true""}'
winrm set winrm/config/service/auth '@{Basic=""true""}'

netsh advfirewall firewall add rule name=""WinRM 5985"" protocol=TCP dir=in localport=5985 action=allow
netsh advfirewall firewall add rule name=""WinRM 5986"" protocol=TCP dir=in localport=5986 action=allow

net stop winrm
sc.exe config winrm start=auto
net start winrm
&lt;/powershell&gt;
EOF

  provisioner ""file"" {
    source = ""test.txt""
    destination = ""C:/test.txt""
  }
  connection {
    type = ""winrm""
    timeout = ""10m""
    user = ""${var.INSTANCE_USERNAME[count.index]}""
    password = ""${var.INSTANCE_PASSWORD}""
  }

tags {
Name=""${var.INSTANCE_USERS[count.index]}""
}
}
</code></pre>

<p>What I did was change your code so we now create a list of the users, that match the length of the count. That way we can call Terraform just once, and use the <code>count.index</code> on our users list to make sure we create the correct amount of instances per user.</p>

<p>You can read more about <code>count.index</code> <a href=""https://www.terraform.io/docs/configuration/interpolation.html"" rel=""nofollow noreferrer"">here</a>. I have always found reading and understanding more complicated code makes me better. Try reading some of the modules from the <a href=""https://registry.terraform.io/"" rel=""nofollow noreferrer"">Terraform Registry</a>. The <a href=""https://github.com/terraform-aws-modules/terraform-aws-vpc/blob/master/main.tf"" rel=""nofollow noreferrer"">vpc</a> module gives good examples of using count.</p>

<p>If you still need help drop me a comment. </p>
",4427,2018-04-04T18:20:20.817,"['users = []\ncount = 0\nfor customer in data[\'customers\']:\n    username = customer[\'email\'].split(\'@\')[0]\n    instances = customer[\'instances\']\n    count += instances\n    users.extend([username] * instances)\n    #print(Added {} to build list with {} instances."".format(username, instances))\nmyfunc(count, users)\n', 'def myfunc(count, users):\n\n  tf = Terraform(working_dir=\'/home/ja/terraform-course/demo-2b\', variables={\'count\':count,\'INSTANCE_USERS\':users})\n  tf.plan(no_color=IsFlagged, refresh=False, capture_output=False)\n  approve = {""auto-approve"": True}\n  print(tf.plan())\n  print(tf.apply(**approve))\n  return\n', 'resource ""aws_key_pair"" ""mykey"" {\n  key_name = ""mykey""\n  public_key = ""${file(""${var.PATH_TO_PUBLIC_KEY}"")}""\n}\n\nresource ""aws_instance"" ""win-example"" {\n  ami = ""${lookup(var.WIN_AMIS, var.AWS_REGION)}""\n  instance_type = ""t2.medium""\n  count=""${var.count}""\n\n  key_name = ""${aws_key_pair.mykey.key_name}""\n  user_data = <<EOF\n<powershell>\nnet user ${var.INSTANCE_USERS[count.index]} \'${var.INSTANCE_PASSWORD}\' /add /y\nnet localgroup administrators ${var.INSTANCE_USERS[count.index]} /add\n\nwinrm quickconfig -q\nwinrm set winrm/config/winrs \'@{MaxMemoryPerShellMB=""300""}\'\nwinrm set winrm/config \'@{MaxTimeoutms=""1800000""}\'\nwinrm set winrm/config/service \'@{AllowUnencrypted=""true""}\'\nwinrm set winrm/config/service/auth \'@{Basic=""true""}\'\n\nnetsh advfirewall firewall add rule name=""WinRM 5985"" protocol=TCP dir=in localport=5985 action=allow\nnetsh advfirewall firewall add rule name=""WinRM 5986"" protocol=TCP dir=in localport=5986 action=allow\n\nnet stop winrm\nsc.exe config winrm start=auto\nnet start winrm\n</powershell>\nEOF\n\n  provisioner ""file"" {\n    source = ""test.txt""\n    destination = ""C:/test.txt""\n  }\n  connection {\n    type = ""winrm""\n    timeout = ""10m""\n    user = ""${var.INSTANCE_USERNAME[count.index]}""\n    password = ""${var.INSTANCE_PASSWORD}""\n  }\n\ntags {\nName=""${var.INSTANCE_USERS[count.index]}""\n}\n}\n']"
434,3818,3806,CC BY-SA 3.0,2018-04-05T22:14:38.443,"<p>Please read <a href=""https://docs.ansible.com/ansible/2.4/vault.html"" rel=""nofollow noreferrer"">https://docs.ansible.com/ansible/2.4/vault.html</a>
Since Ansible 2.4 one could use <code>--vault-id @prompt</code>.</p>

<p>Encrypt a file using ansible-vault:</p>

<pre><code>ansible-vault encrypt /path/to/encrypted/file
</code></pre>

<p>Run the playbook and it will result in:</p>

<pre><code>fatal: [localhost]: FAILED! =&gt; {""msg"": ""A vault password or secret must be
specified to decrypt /path/to/encrypted/file""}
</code></pre>

<p>There are multiple options to decrypt files, including <code>@prompt</code>:</p>

<pre><code>ansible-playbook some-playbook --vault-id @prompt
</code></pre>

<p>will prompt:</p>

<pre><code>Vault password (default):
</code></pre>

<p>Once the vault password has been entered, the playbook should succeed.</p>
",210,2018-04-06T17:49:29.857,"['ansible-vault encrypt /path/to/encrypted/file\n', 'fatal: [localhost]: FAILED! => {""msg"": ""A vault password or secret must be\nspecified to decrypt /path/to/encrypted/file""}\n', 'ansible-playbook some-playbook --vault-id @prompt\n', 'Vault password (default):\n']"
435,3824,3823,CC BY-SA 3.0,2018-04-06T13:23:59.163,"<p>Got it working by aws curl <a href=""https://github.com/okigan/awscurl"" rel=""nofollow noreferrer"">https://github.com/okigan/awscurl</a></p>

<pre><code>awscurl --service iam 'https://iam.amazonaws.com/?Action=ListUsers&amp;Version=2010-05-08'
</code></pre>
",6523,2018-04-06T13:23:59.163,"[""awscurl --service iam 'https://iam.amazonaws.com/?Action=ListUsers&Version=2010-05-08'\n""]"
436,3828,3825,CC BY-SA 3.0,2018-04-07T04:07:00.053,"<p>For a given instance, you would first use <code>aws ec2 describe-instances</code> to get the information JSON for your instance.</p>

<p>The information also contains the keypair name used to create that instance.</p>

<p>E.g. for an instance <code>i-0e2x8xd7xxx</code>  (Note: I use the awesome tool <code>jq</code> to do JSON parsing but you can use any other solution)</p>

<pre><code>aws ec2 describe-instances --instance-ids i-0e2x8xd7xxx | jq '.Reservations[].Instances[].KeyName'
</code></pre>

<p>Output:</p>

<pre><code>""my_key_name""
</code></pre>

<p>You can store that in a variable, say <code>$keypair_name</code> and then pass it into your <code>aws ec2 get-password-data</code> command.</p>

<p>You would also need to pass in the path on your machine where your keypairs are located e.g. <code>$keypair_path</code>.</p>

<p>For example:</p>

<pre><code>aws ec2 get-password-data --priv-launch-key $keypair_path/$keypair_name .....
</code></pre>
",6544,2018-04-07T04:12:47.630,"[""aws ec2 describe-instances --instance-ids i-0e2x8xd7xxx | jq '.Reservations[].Instances[].KeyName'\n"", '""my_key_name""\n', 'aws ec2 get-password-data --priv-launch-key $keypair_path/$keypair_name .....\n']"
437,3830,3806,CC BY-SA 3.0,2018-04-07T07:34:38.060,"<h3>Vault password</h3>

<p>First of all, you should get familiar with the fact that vault password file can be executable script. In this case Ansible executes it and expects to receive password as its output.</p>

<p>For example you can use <code>gpg-agent</code> or <code>keychain</code> to store your actual password and unlock it when required. Read more in this blog post: <a href=""https://benincosa.com/?p=3235"" rel=""noreferrer"">https://benincosa.com/?p=3235</a></p>

<p>If you are a bit paranoid, you can add notification when your password script is called, like this:</p>

<pre><code>#!/bin/bash
PARENT_PROCESS=$(ps -p $PPID -o args | tail -n 1)
osascript -e ""display notification \""Vault password used by ${PARENT_PROCESS}\"" with title \""Ansible\"" sound name \""default\""""
gpg --batch --use-agent --no-tty --decrypt key.gpg 2&gt;/dev/null
</code></pre>

<p>This vault password script uses <code>key.gpg</code> as actual vault key and also shows popup notification (for MacOS) with parent process name when script is used. Gpg-agent caches unlock password for some time, so there is no need to enter password every time you start playbook.</p>

<p>Just set <code>vault_password_file = ./vault_pass.sh</code> in your <code>ansible.cfg</code>.</p>

<h3>Environment</h3>

<p>You said that you use <code>azure_rm.py</code> as dynamic inventory script. This means that you have to set credentials into your environment variables before you start ansible-playbook for it to be able to use them.</p>

<p>You can make two files:</p>

<p><code>secure_env</code> (encrypted with vault):</p>

<pre><code>export AZURE_SECRET=xxx;export AZURE_SUBSCRIPTION_ID=xxx;
</code></pre>

<p><code>set_env</code> (plain text):</p>

<pre><code>echo -n ""Setting secure vars... ""
eval $(ansible-vault view secure_env)
echo ""done.""
</code></pre>

<p>When you open new terminal to execute your automation tasks, you have to run:</p>

<pre><code>source set_env
</code></pre>

<p>At this moment, bash evaluates <code>set_env</code> and <code>secure_env</code> (decrypted via ansible-vault). After this command you have Azure credentials defined for the current shell, so you can execute playbooks as usual:</p>

<pre><code>ansible-playbook provision-my-azure-instances.yml
</code></pre>

<p>So using this two approaches, you can store <code>key.gpg</code> and <code>secure_env</code> in your repository; then in the new terminal call <code>source set_env</code> once, enter gpg password once (to unlock future use of key.gpg); then call <code>ansible-playbook</code> as many times as you like without any passwords.</p>
",3509,2018-04-07T07:34:38.060,"['#!/bin/bash\nPARENT_PROCESS=$(ps -p $PPID -o args | tail -n 1)\nosascript -e ""display notification \\""Vault password used by ${PARENT_PROCESS}\\"" with title \\""Ansible\\"" sound name \\""default\\""""\ngpg --batch --use-agent --no-tty --decrypt key.gpg 2>/dev/null\n', 'export AZURE_SECRET=xxx;export AZURE_SUBSCRIPTION_ID=xxx;\n', 'echo -n ""Setting secure vars... ""\neval $(ansible-vault view secure_env)\necho ""done.""\n', 'source set_env\n', 'ansible-playbook provision-my-azure-instances.yml\n']"
438,3840,3823,CC BY-SA 3.0,2018-04-09T12:34:46.797,"<p>The referred documentation from the question 
<a href=""https://docs.aws.amazon.com/IAM/latest/APIReference/API_ListAttachedUserPolicies.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/IAM/latest/APIReference/API_ListAttachedUserPolicies.html</a></p>

<p>has this example of a request:</p>

<pre><code>https://iam.amazonaws.com/?Action=ListAttachedUserPolicies
&amp;UserName=Alice
&amp;Version=2010-05-08
&amp;AUTHPARAMS
</code></pre>

<p>AUTHPARAMS are explained 
<a href=""https://docs.aws.amazon.com/general/latest/gr/signature-version-2.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/general/latest/gr/signature-version-2.html</a></p>

<p>(version 4 is preferred)
<a href=""https://docs.aws.amazon.com/general/latest/gr/sigv4-calculate-signature.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/general/latest/gr/sigv4-calculate-signature.html</a></p>

<p>So you have to calculate a digest from the request together with your secret key and you have to do it exactly as it is explained in the documentation - which means be careful about every letter including spaces. </p>
",3525,2018-04-09T12:34:46.797,['https://iam.amazonaws.com/?Action=ListAttachedUserPolicies\n&UserName=Alice\n&Version=2010-05-08\n&AUTHPARAMS\n']
439,3841,3825,CC BY-SA 3.0,2018-04-09T12:41:02.910,"<p>Based on <a href=""https://devops.stackexchange.com/a/3828/3"">@Vish answer</a>, I've created the following shell script:</p>

<pre><code>#/usr/bin/env bash
# Script to show password data of the EC2 instance.
[ $# -eq 0 ] &amp;&amp; { echo ""Usage: $0 instance_id ...""; exit; }
keyname=$(aws ec2 describe-instances --query 'Reservations[].Instances[].KeyName' --output text --instance-ids $1)
pemfile=$(find ~/.ssh -name ""*$keyname*.pem"" -print -quit)
if [ -z ""$pemfile"" ]; then
  aws ec2 get-password-data --instance-id $1
else
  aws ec2 get-password-data --instance-id $1 --priv-launch-key $pemfile
fi
</code></pre>

<p>which aims to decrypt the password based on the key pair name. By default it's looking for the PEM file in user's <code>~/.ssh</code> folder.</p>

<p>Usage:</p>

<pre><code>./show_ec2_password_data.sh i-instance_id
</code></pre>
",3,2018-04-09T12:41:02.910,"['#/usr/bin/env bash\n# Script to show password data of the EC2 instance.\n[ $# -eq 0 ] && { echo ""Usage: $0 instance_id ...""; exit; }\nkeyname=$(aws ec2 describe-instances --query \'Reservations[].Instances[].KeyName\' --output text --instance-ids $1)\npemfile=$(find ~/.ssh -name ""*$keyname*.pem"" -print -quit)\nif [ -z ""$pemfile"" ]; then\n  aws ec2 get-password-data --instance-id $1\nelse\n  aws ec2 get-password-data --instance-id $1 --priv-launch-key $pemfile\nfi\n', './show_ec2_password_data.sh i-instance_id\n']"
440,3842,3460,CC BY-SA 3.0,2018-04-09T16:40:20.997,"<p>I am assuming you are using <a href=""https://jenkins.io/doc/book/pipeline/jenkinsfile/"" rel=""nofollow noreferrer"">Jenkinsfile</a>. You can do for example:</p>

<pre><code>pipeline {
    agent any

    stages {
        stage('Build') {
            steps {
                echo 'Building..'
            }
        }
        stage('Test') {
            steps {
                echo 'Testing..'
            }
        }
        stage('Deploy') {
             when { branch 'master' } /* when in master branch */
             steps {
                echo 'Deploying....'
                deleteDir() /* clean up our workspace */
            }
        }
    }
}
</code></pre>
",7331,2018-04-09T16:40:20.997,"[""pipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                echo 'Building..'\n            }\n        }\n        stage('Test') {\n            steps {\n                echo 'Testing..'\n            }\n        }\n        stage('Deploy') {\n             when { branch 'master' } /* when in master branch */\n             steps {\n                echo 'Deploying....'\n                deleteDir() /* clean up our workspace */\n            }\n        }\n    }\n}\n""]"
441,3845,3844,CC BY-SA 3.0,2018-04-09T19:37:51.763,"<p>It looks like that the official Consul documentation is more up to date than the link that was posted in the question.</p>

<p>If one starts with the <a href=""https://www.consul.io/intro/getting-started/install.html"" rel=""nofollow noreferrer"">Getting Started guide</a>, then one could start a consul agent in no time and the documentation also explains how to proceed.</p>

<pre><code>user@localhost /tmp $ ./consul agent -dev
==&gt; Starting Consul agent...
==&gt; Consul agent running!
           Version: 'v1.0.6'
           Node ID: '777c5475-bc78-6e38-75a6-42038eef7cb8'
         Node name: 'localhost.localdomain'
        Datacenter: 'dc1' (Segment: '&lt;all&gt;')
            Server: true (Bootstrap: false)
       Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, DNS: 8600)
      Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302)
           Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false

==&gt; Log data will now stream in as it occurs:

    2018/04/09 21:33:04 [DEBUG] Using random ID ""777c5475-bc78-6e38-75a6-42038eef7cb8"" as node ID
</code></pre>
",210,2018-04-09T19:37:51.763,"['user@localhost /tmp $ ./consul agent -dev\n==> Starting Consul agent...\n==> Consul agent running!\n           Version: \'v1.0.6\'\n           Node ID: \'777c5475-bc78-6e38-75a6-42038eef7cb8\'\n         Node name: \'localhost.localdomain\'\n        Datacenter: \'dc1\' (Segment: \'<all>\')\n            Server: true (Bootstrap: false)\n       Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, DNS: 8600)\n      Cluster Addr: 127.0.0.1 (LAN: 8301, WAN: 8302)\n           Encrypt: Gossip: false, TLS-Outgoing: false, TLS-Incoming: false\n\n==> Log data will now stream in as it occurs:\n\n    2018/04/09 21:33:04 [DEBUG] Using random ID ""777c5475-bc78-6e38-75a6-42038eef7cb8"" as node ID\n']"
442,3853,3510,CC BY-SA 3.0,2018-04-10T12:39:42.407,"<p>The general design pattern is one container = one running service - see the initial comment at <a href=""https://docs.docker.com/config/containers/multi-service_container/"" rel=""nofollow noreferrer"">https://docs.docker.com/config/containers/multi-service_container/</a></p>

<p>Now, after spending about a year developing a multi-service application relying heavily on docker this is what works for me:</p>

<p>Avoid creating files inside the container unless it is your storage engine - in which case use volumes (recommended by Docker and also common sense) - we use Elasticsearch for that. </p>

<p>If I need multiple custom configurations I am trying to either load it from somewhere (DB, Environment) or I mount the configuration as a volume like </p>

<pre><code>-v config.yml:/usr/src/app/config.yml
</code></pre>

<p>In general, we have one service = one repository, but sometimes you have to copy all the dependencies in order to just create one script. So we have one repository where these scripts are aggregated and I change the CMD with an environment variable like this:</p>

<pre><code>CMD cd /usr/src/app &amp;&amp; python -u $RUN_SCRIPT
</code></pre>

<p>It can be probably improved with a combination of ENTRYPOINT and CMD as described here <a href=""http://goinbigdata.com/docker-run-vs-cmd-vs-entrypoint/"" rel=""nofollow noreferrer"">http://goinbigdata.com/docker-run-vs-cmd-vs-entrypoint/</a></p>

<p>Then we use various <code>docker-compose.yml</code> files for getting the setup we need. </p>

<p>For some operations (like DB setup) we either run one container like </p>

<pre><code>docker run --network ournetwork init-profiling
</code></pre>

<p>or I can run a command inside that container</p>

<pre><code>docker run -it --network ournetwork init-profiling bash
# run_command.sh
^D
</code></pre>

<p>We spent some time minimizing the footprint of containers, they can quickly get bloated. For example, we use a common base image for our python containers. Also, things like <code>pip freeze</code> do make sense only if you use a separate virtual environment for each repository/container.</p>

<p>We do not use swarm/kubernetes for now, so I cannot add any additional guidelines for that. </p>
",3525,2018-04-10T12:39:42.407,"['-v config.yml:/usr/src/app/config.yml\n', 'CMD cd /usr/src/app && python -u $RUN_SCRIPT\n', 'docker run --network ournetwork init-profiling\n', 'docker run -it --network ournetwork init-profiling bash\n# run_command.sh\n^D\n']"
443,3854,3794,CC BY-SA 3.0,2018-04-10T13:35:25.287,"<p>I tried to change docker image and added couple steps for git tag. Below is the answer worked for me,</p>

<pre><code>image: maven

stages:
- build
- deploy
- tag

maven_build:
stage: build

  script:
   - mvn clean package
   artifacts:
  paths:
   - target/*.jar

  after_script:
   - ls -a
   - cd target &amp;&amp; ls -a
   - git --version
   - git remote remove origin
   - git remote set-url origin https://""username:passwd""@gitlab.com/accountname/projectname
   - git tag -a 1.0.15 -m ""Version created by gitlab-ci Build""
   - git push origin 1.0.15
  only:
    - master
</code></pre>
",1208,2018-04-10T13:35:25.287,"['image: maven\n\nstages:\n- build\n- deploy\n- tag\n\nmaven_build:\nstage: build\n\n  script:\n   - mvn clean package\n   artifacts:\n  paths:\n   - target/*.jar\n\n  after_script:\n   - ls -a\n   - cd target && ls -a\n   - git --version\n   - git remote remove origin\n   - git remote set-url origin https://""username:passwd""@gitlab.com/accountname/projectname\n   - git tag -a 1.0.15 -m ""Version created by gitlab-ci Build""\n   - git push origin 1.0.15\n  only:\n    - master\n']"
444,3863,1835,CC BY-SA 3.0,2018-04-12T09:42:27.470,"<p>I am not sure if that is possible or not but you can write same command in bash script</p>

<pre><code>#!/bin/bash

ansible-playbook playbookname.yaml &gt; output.txt

# Then grep from output.txt what you want

grep -A 5 ""PLAY"" output.txt
</code></pre>

<p>May not be good way but will achieve what you want.</p>
",3785,2018-04-12T09:42:27.470,"['#!/bin/bash\n\nansible-playbook playbookname.yaml > output.txt\n\n# Then grep from output.txt what you want\n\ngrep -A 5 ""PLAY"" output.txt\n']"
445,3873,3872,CC BY-SA 3.0,2018-04-13T04:35:35.967,"<p>Solution to this problem is to create an overlay filesytem over a read-only mount, but if you try to do it directly, overlay will refuse to put upper and work directories on another overlay filesystem. The trick is to create a tmpfs for the upper and work directories like this:</p>

<p>Create a script called run-in-c.sh</p>

<pre><code>#!/bin/bash
NAME=$1
shift
HOSTNAME=dock${NAME}
CONTAINER=dc-${USER}-${NAME}
REPOSITORY=${HOME}/repository
BASEIMAGE=hub.docker.io/my-org/my-base-container
OVERLAY=/mnt/overlay
LOWERDIR=/mnt/lower
UPPERDIR=${OVERLAY}/upper
WORKDIR=${OVERLAY}/work
TARGET=/mnt/repository
# PRIVILEGED=""--privileged""
PRIVILEGED=""--cap-add SYS_ADMIN""
docker container create --name $CONTAINER $PRIVILEGED --hostname $HOSTNAME --volume ${CO}:${LOWERDIR}:ro $BASEIMAGE
docker container start $CONTAINER
docker container exec $CONTAINER mkdir -p $OVERLAY
docker container exec $CONTAINER mount -t tmpfs tmpfs $OVERLAY
docker container exec $CONTAINER mkdir -p $WORKDIR $UPPERDIR $TARGET
docker container exec $CONTAINER mount -t overlay overlay -o lowerdir=${LOWERDIR},upperdir=${UPPERDIR},workdir=${WORKDIR} $TARGET
docker container exec -it --workdir $TARGET $CONTAINER $*
docker container stop $CONTAINER
docker container rm $CONTAINER
</code></pre>

<p>Then you can run commands in the container as:</p>

<pre><code>run-in-c.sh test01 'cd dir &amp;&amp; command args'
</code></pre>

<p>or simply get interactive shell with:</p>

<pre><code>run-in-c.sh naming-stuff-is-too-hard bash
</code></pre>
",228,2018-04-13T04:35:35.967,"['#!/bin/bash\nNAME=$1\nshift\nHOSTNAME=dock${NAME}\nCONTAINER=dc-${USER}-${NAME}\nREPOSITORY=${HOME}/repository\nBASEIMAGE=hub.docker.io/my-org/my-base-container\nOVERLAY=/mnt/overlay\nLOWERDIR=/mnt/lower\nUPPERDIR=${OVERLAY}/upper\nWORKDIR=${OVERLAY}/work\nTARGET=/mnt/repository\n# PRIVILEGED=""--privileged""\nPRIVILEGED=""--cap-add SYS_ADMIN""\ndocker container create --name $CONTAINER $PRIVILEGED --hostname $HOSTNAME --volume ${CO}:${LOWERDIR}:ro $BASEIMAGE\ndocker container start $CONTAINER\ndocker container exec $CONTAINER mkdir -p $OVERLAY\ndocker container exec $CONTAINER mount -t tmpfs tmpfs $OVERLAY\ndocker container exec $CONTAINER mkdir -p $WORKDIR $UPPERDIR $TARGET\ndocker container exec $CONTAINER mount -t overlay overlay -o lowerdir=${LOWERDIR},upperdir=${UPPERDIR},workdir=${WORKDIR} $TARGET\ndocker container exec -it --workdir $TARGET $CONTAINER $*\ndocker container stop $CONTAINER\ndocker container rm $CONTAINER\n', ""run-in-c.sh test01 'cd dir && command args'\n"", 'run-in-c.sh naming-stuff-is-too-hard bash\n']"
446,3879,3878,CC BY-SA 3.0,2018-04-14T14:12:17.697,"<h1>Linux, without docker</h1>

<p>In Linux, you can create arbitrarily many IP address for each interface. A comment in <a href=""https://serverfault.com/questions/328146/max-number-virtual-ip-addresses-per-nic"">https://serverfault.com/questions/328146/max-number-virtual-ip-addresses-per-nic</a> reports success with 2000, and hearsay of 5000 successful IPs.</p>

<p>So. Pick any Linux box on your intranet, which could of course be a VM, and create as many IPs on its single ethernet interface (MAC address) as you wish.</p>

<p>Say you're using the 10.0.0.0/8 private network, then you can execute lots of these:</p>

<pre><code>ifconfig eth0:1 10.0.0.2 netmask 255.0.0.0
ifconfig eth0:2 10.0.0.3 netmask 255.0.0.0
...
ifconfig eth0:260 10.0.1.6 netmask 255.0.0.0
...
</code></pre>

<p>You should be able to use <code>curl --interface eth0:3</code> (or maybe <code>--interface 10.0.0.3</code>) to use a specific source address. For <code>wget</code>, it's <code>--bind-address=10.0.0.3</code> etc. Start the curls in the background (""&amp;"") and they will run more or less concurrently - or look for some test driver (different question) to run them for you.</p>

<p>This will give you lots of requests from separate IP addresses, but all conveniently running on one machine.</p>

<h1>Docker, trivially</h1>

<p>With docker: just make an image, as small as humanly possible, which connects to your server. You can use <code>curl</code> without any special options.</p>

<p>Then fire up your 1000 docker containers, just like you usually would. Each will automatically get an IP address on the internal docker network (172.x.0.0/16 by default).</p>

<p><a href=""https://stackoverflow.com/questions/21799382/is-there-a-maximum-number-of-containers-running-on-a-docker-host"">https://stackoverflow.com/questions/21799382/is-there-a-maximum-number-of-containers-running-on-a-docker-host</a> indicates that it is possible with hardware that is not too uncommon today; a naive 1000 docker containers used roughly 3 GB of RAM for them. That question also has some hints on options you can use to decrease the memory needs. Aside from memory, there won't be too much overhead, i.e. CPU wise it should comparable.</p>

<h1>Docker, with special networking</h1>

<p><code>docker network</code> opens up manually created networking for you. You should be able to cobble something together (just check the individual <code>--help</code> pages, it's all pretty self explanatory), and combine that with the <code>ifconfig</code> approach explained above. This would mean that you only need one container for your <code>curl</code>s, and start 1000's of them inside that container.</p>

<p>I would try to just run your 1000 containers, first, though, unless you are limited in the RAM department, for ease of use.</p>

<h1>About the <code>curl</code>...</h1>

<p>Whatever you do, don't just start a single <code>curl</code> in each instance, but have each runner be an endless loop of back-to-back <code>curl</code> calls. This way, you avoid long gaps inbetween where your individual jobs are being started and stopped; this is obviously especially important for the ""1000 docker containers"" variation. In the answer linked above, they note that it took them some good amount of minutes to start up those thousands of containers, so you do not want to do that over and over again.</p>

<p>And you might as well get rid of <code>curl</code> altogether and create small networking app in the language of your choice (Perl, Ruby, C, Java...) to avoid process startup overhead.</p>
",4175,2018-04-15T08:00:41.267,['ifconfig eth0:1 10.0.0.2 netmask 255.0.0.0\nifconfig eth0:2 10.0.0.3 netmask 255.0.0.0\n...\nifconfig eth0:260 10.0.1.6 netmask 255.0.0.0\n...\n']
447,3892,3883,CC BY-SA 3.0,2018-04-16T09:14:12.773,"<p>Once parsed your config create one and only one pipeline, with various inputs, various filters and various outputs. </p>

<p>You have to use some conditional constructs to apply filter and output only to specific messages, usually using a special tag or field set on input.</p>

<p>Some exemple are available in <a href=""https://www.elastic.co/guide/en/logstash/current/config-examples.html#using-conditionals"" rel=""nofollow noreferrer"">logstash documentation</a>:</p>

<blockquote>
<pre><code>output {
  if [type] == ""apache"" {
    if [status] =~ /^5\d\d/ {
      nagios { ...  }
    } else if [status] =~ /^4\d\d/ {
      elasticsearch { ... }
    }
    statsd { increment =&gt; ""apache.%{status}"" }
  }
}
</code></pre>
</blockquote>
",13,2018-04-16T09:14:12.773,"['output {\n  if [type] == ""apache"" {\n    if [status] =~ /^5\\d\\d/ {\n      nagios { ...  }\n    } else if [status] =~ /^4\\d\\d/ {\n      elasticsearch { ... }\n    }\n    statsd { increment => ""apache.%{status}"" }\n  }\n}\n']"
448,3896,3857,CC BY-SA 3.0,2018-04-16T15:24:04.107,"<p>I dealt with the same issue. Some people recommended using the Gitlab group ""secrets"" and using <code>before_script</code>. Since I knew I was also going to deploy and would need other tools on my runner like ""helm"", I made my own docker container. I still keep my config for my clusters in a base64 encoded group secret but I set it like this in the dockerfile.</p>

<pre><code>ENV kube_config=$kube_config
RUN echo -n ${kube_config} | base64 -d &gt; ~/.kube/config
</code></pre>

<p>Now just set an environment variable for your gitlab runner to point to your new image.</p>

<pre><code>KUBERNETES_IMAGE: registry.gitlab.com/MY_USERNAME/MY_REPO_NAME/MY_IMAGE_NAME:latest
</code></pre>

<p>Don't forget to test your new container!</p>

<pre><code>stages:
  - build
  - test
  - release

variables:
  CONTAINER_TEST_IMAGE: $CI_REGISTRY_IMAGE/gitlab_runner:$CI_COMMIT_REF_NAME
  CONTAINER_RELEASE_IMAGE: $CI_REGISTRY_IMAGE/gitlab_runner:latest

before_script:
  - apt-get update &amp;&amp; apt-get install docker.io -y
  - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY

Build Image:
  stage: build
  script:
    - docker build --build-arg kube_config=${kube_config} -t ${CONTAINER_TEST_IMAGE} .
    - docker push ${CONTAINER_TEST_IMAGE}
  except:
    - master

Test Kubectl:
  stage: test
  script:
    - docker pull ${CONTAINER_TEST_IMAGE}
    - docker run --rm ${CONTAINER_TEST_IMAGE} kubectl get deployments -n kube-system
  except:
    - master

Test Helm:
  stage: test
  script:
    - docker pull ${CONTAINER_TEST_IMAGE}
    - docker run --rm ${CONTAINER_TEST_IMAGE} helm ls
  except:
    - master

Test Docker:
  stage: test
  script:
    - docker pull ${CONTAINER_TEST_IMAGE}
    - docker run --rm -v /var/run/docker.sock:/var/run/docker.sock ${CONTAINER_TEST_IMAGE} docker images
  except:
    - master

release-image:
  stage: release
  script:
    - docker pull $CONTAINER_TEST_IMAGE
    - docker tag $CONTAINER_TEST_IMAGE $CONTAINER_RELEASE_IMAGE
    - docker push $CONTAINER_RELEASE_IMAGE
  only:
    - master
</code></pre>

<p>Edit: Missed this part.. <strong>I'm using a shell runner.</strong></p>

<p>So post of what I said is probably not relevant. How ever I do think there is some advantages to building and deploying with a gitlab runner directly on a cluster.</p>
",4427,2018-04-16T15:36:18.943,"['ENV kube_config=$kube_config\nRUN echo -n ${kube_config} | base64 -d > ~/.kube/config\n', 'KUBERNETES_IMAGE: registry.gitlab.com/MY_USERNAME/MY_REPO_NAME/MY_IMAGE_NAME:latest\n', 'stages:\n  - build\n  - test\n  - release\n\nvariables:\n  CONTAINER_TEST_IMAGE: $CI_REGISTRY_IMAGE/gitlab_runner:$CI_COMMIT_REF_NAME\n  CONTAINER_RELEASE_IMAGE: $CI_REGISTRY_IMAGE/gitlab_runner:latest\n\nbefore_script:\n  - apt-get update && apt-get install docker.io -y\n  - docker login -u gitlab-ci-token -p $CI_JOB_TOKEN $CI_REGISTRY\n\nBuild Image:\n  stage: build\n  script:\n    - docker build --build-arg kube_config=${kube_config} -t ${CONTAINER_TEST_IMAGE} .\n    - docker push ${CONTAINER_TEST_IMAGE}\n  except:\n    - master\n\nTest Kubectl:\n  stage: test\n  script:\n    - docker pull ${CONTAINER_TEST_IMAGE}\n    - docker run --rm ${CONTAINER_TEST_IMAGE} kubectl get deployments -n kube-system\n  except:\n    - master\n\nTest Helm:\n  stage: test\n  script:\n    - docker pull ${CONTAINER_TEST_IMAGE}\n    - docker run --rm ${CONTAINER_TEST_IMAGE} helm ls\n  except:\n    - master\n\nTest Docker:\n  stage: test\n  script:\n    - docker pull ${CONTAINER_TEST_IMAGE}\n    - docker run --rm -v /var/run/docker.sock:/var/run/docker.sock ${CONTAINER_TEST_IMAGE} docker images\n  except:\n    - master\n\nrelease-image:\n  stage: release\n  script:\n    - docker pull $CONTAINER_TEST_IMAGE\n    - docker tag $CONTAINER_TEST_IMAGE $CONTAINER_RELEASE_IMAGE\n    - docker push $CONTAINER_RELEASE_IMAGE\n  only:\n    - master\n']"
449,3913,3906,CC BY-SA 3.0,2018-04-19T12:27:03.920,"<p>AWS has something built in called <a href=""https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AlarmThatSendsEmail.html"" rel=""nofollow noreferrer"">cloudwatch alarms</a> that can handle the basics.</p>
<p>You could also use a Lambda Function. Give it access to the ASG, and then have cloudwatch configured so once the min amount of traffic starts coming in it sends an <a href=""https://docs.aws.amazon.com/lambda/latest/dg/invoking-lambda-function.html"" rel=""nofollow noreferrer"">Event</a> to the Lambda.</p>
<pre><code>{
  &quot;ASG&quot;: &quot;MyASGName&quot;
  &quot;Action&quot;: &quot;Start&quot;
}
</code></pre>
<p>And once the traffic goes below the min.</p>
<pre><code>{
  &quot;ASG&quot;: &quot;MyASGName&quot;
  &quot;Action&quot;: &quot;Stop&quot;
}
</code></pre>
<p>You could also build on this over time to control Vertical and Horizontal scaling.</p>
<p>EDIT: I actually prefer the Lambda. I always seem to run into these weird use cases where we can't shut down any of the instances, we have to do some math or investigation on which instances to shut down. In these situations a python lambda running boto3 is really helpful.</p>
",4427,2018-04-19T14:36:47.227,"['{\n  ""ASG"": ""MyASGName""\n  ""Action"": ""Start""\n}\n', '{\n  ""ASG"": ""MyASGName""\n  ""Action"": ""Stop""\n}\n']"
450,3938,147,CC BY-SA 3.0,2018-04-23T14:41:24.443,"<p>After resizing the EBS volume, here is what I just executed when I needed to expand a ZFS pool:</p>

<pre><code>parted -l # Get the list of partitions 
parted /dev/xvdf rm 9 # Remove the buffer partition
parted /dev/xvdf resizepart 1 100% # Resize the partition
zpool online -e &lt;zfs partition name&gt; /dev/xvdf # Expand the zpool and the filesystem it holds
</code></pre>
",62,2018-04-23T16:27:04.913,['parted -l # Get the list of partitions \nparted /dev/xvdf rm 9 # Remove the buffer partition\nparted /dev/xvdf resizepart 1 100% # Resize the partition\nzpool online -e <zfs partition name> /dev/xvdf # Expand the zpool and the filesystem it holds\n']
451,3946,3945,CC BY-SA 3.0,2018-04-23T22:09:46.643,"<p>So I wrote this powershell script to be ran by the deployment group agents who have access to the server locally.</p>

<pre><code>Param(
[string]$JenkinsPatArg
)
$isRunningLocal = $false
$jenkinsUrlBase = ""[public ipaddress]""

if(Test-Connection -ComputerName ""[private ipaddress/DNS name]"" -Quiet) 
{
    $isRunningLocal = $true
    $jenkinsUrlBase = ""[private ipaddress/dns name]""
}

$buildDefinitionName = $env:RELEASE_ARTIFACTS_GAMEZIP_DEFINITIONNAME
$buildTeamProject = [Uri]::EscapeDataString($env:SYSTEM_TEAMPROJECT)
$targetBuildNumber = $env:RELEASE_ARTIFACTS_[Artifact Alias]_BUILDNUMBER

$Auth = ""$($env:username):$($JenkinsPatArg)""

$Bytes = [System.Text.Encoding]::UTF8.GetBytes($Auth)
$Base64bytes = [System.Convert]::ToBase64String($Bytes)
$Headers = @{ ""Authorization"" = ""Basic $Base64bytes""}

Write-Host ""Searching for $($targetBuildNumber) in project $($buildTeamProject)-&gt;$($buildDefinitionName)""

$correctBuild

Write-Host ""Querying: http://$($jenkinsUrlBase):[port number]/job/$($buildTeamProject)/job/$($buildDefinitionName)/api/json?tree=builds[id,url,actions[buildNumber]]""

ForEach($build in (Invoke-RestMethod -Uri ""http://$($jenkinsUrlBase):[port number]/job/$($buildTeamProject)/job/$($buildDefinitionName)/api/json?tree=builds[id,url,actions[buildNumber]]"" -ContentType json -Headers $Headers).builds)
{

    if($build.actions.buildNumber -eq $targetBuildNumber)
    {
        $correctBuild = $build
        Write-Host $build.id
        Write-Host $build.url
        Write-Host $build.actions.buildNumber
        break

    }
}

if($correctBuild -eq $null)
{
    Write-Error ""Build not found.  Must rebuild source to obtain artifact""
    return;
}

if($isRunningLocal){$correctBuild.url = $correctBuild.url.Replace(""[public ip address]"", ""[local ipaddress/DNS name]"")}

$targetZip = ""$Env:temp/$($buildDefinitionName)_$($correctBuild.id).zip""

(Invoke-RestMethod -Uri ""$($correctBuild.url)/artifact/$($buildDefinitionName)/*zip*/$($buildDefinitionName)_$($correctBuild.id).zip"" -ContentType Application/zip -Headers $Headers -OutFile $targetZip)

Add-Type -AssemblyName System.IO.Compression.FileSystem;[System.IO.Compression.ZipFile]::ExtractToDirectory($targetZip, $env:targetDirectory);
#Expand-Archive -Path $targetZip -DestinationPath $env:targetDirectory -Force
Remove-Item $targetZip;
</code></pre>

<p>passing in the a personal API key (created by Jenkins user manager to use by visual studio team services), this script first checks if it is can access the server using local connections, if so set the variables appropriately.</p>

<p>From there we create local handlers for environmental variables.  Our release artifact name defined in VSTS is the same as that in our jenkins server.  The build number used is created by VSTS and passed to jenkins and stored by the VSTS plugin(<a href=""https://wiki.jenkins-ci.org/display/JENKINS/Team+Foundation+Server+Plugin"" rel=""nofollow noreferrer"">Jenkins TFS Plugin download</a>).  We get this version number from the environment as the artifact build number.  We also ensure that our team project path url is windows URL encoded <a href=""https://stackoverflow.com/questions/23548386/how-do-i-replace-spaces-with-20-in-powershell?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa"">brief explanation</a>.  Next we hold our authentication which is stored as a variable in our VSTS variables.  The <code>$JenkinsPatArg</code> is marked as secret. As such, we must pass it in as it isn't visible as an environment variable.  We then encode the authentication and add it to our request headers.</p>

<p>We then add a debug line to print what target we are looking for and what project we are looking in, just to make sure we are looking for the right thing.  We create a variable to hold the build information that we find and do one more debug write stating what are query url is so that we can manually run it if we run into any issues.</p>

<p>Next we then run this url query against the build server and iterate over all the builds returned.  The query filters out all the JSON to just the build ID, it's absolute url, and the VSTS build number.  We check to see if the build we are examining has the same build number as the artifact we are deploying, if so store it in the <code>$correctBuild</code> variable, print the was found for debugging, and exit the loop.</p>

<p>Coming out of the loop we check to see if we found a result.  If we did not find a build (due to it being cleaned up most likely) we inform the user that the artifact needs to be rebuild from source.  Otherwise we download the artifact zip to a temporary location from the jenkins server and extract it to the target directory, defined as a variable.  Lastly we delete the downloaded zip.</p>

<p>This is ran as a powershell script task and due to it's length, can not be an inline script.  So to deploy this, i have a devops git repo for my scripts and I just include this as an artifact that is downloaded and ran.  This task is preceded by other tasks which stop the current process from running, and delete the current files in place before running this task.  After this task is ran, more scripts are ran to run the downloaded artifacts.</p>

<p>I hope this helps someone else trying to coordinate and link VSTS builds with Jenkins artifacts.</p>
",3062,2018-04-23T22:09:46.643,"['Param(\n[string]$JenkinsPatArg\n)\n$isRunningLocal = $false\n$jenkinsUrlBase = ""[public ipaddress]""\n\nif(Test-Connection -ComputerName ""[private ipaddress/DNS name]"" -Quiet) \n{\n    $isRunningLocal = $true\n    $jenkinsUrlBase = ""[private ipaddress/dns name]""\n}\n\n$buildDefinitionName = $env:RELEASE_ARTIFACTS_GAMEZIP_DEFINITIONNAME\n$buildTeamProject = [Uri]::EscapeDataString($env:SYSTEM_TEAMPROJECT)\n$targetBuildNumber = $env:RELEASE_ARTIFACTS_[Artifact Alias]_BUILDNUMBER\n\n$Auth = ""$($env:username):$($JenkinsPatArg)""\n\n$Bytes = [System.Text.Encoding]::UTF8.GetBytes($Auth)\n$Base64bytes = [System.Convert]::ToBase64String($Bytes)\n$Headers = @{ ""Authorization"" = ""Basic $Base64bytes""}\n\nWrite-Host ""Searching for $($targetBuildNumber) in project $($buildTeamProject)->$($buildDefinitionName)""\n\n$correctBuild\n\nWrite-Host ""Querying: http://$($jenkinsUrlBase):[port number]/job/$($buildTeamProject)/job/$($buildDefinitionName)/api/json?tree=builds[id,url,actions[buildNumber]]""\n\nForEach($build in (Invoke-RestMethod -Uri ""http://$($jenkinsUrlBase):[port number]/job/$($buildTeamProject)/job/$($buildDefinitionName)/api/json?tree=builds[id,url,actions[buildNumber]]"" -ContentType json -Headers $Headers).builds)\n{\n\n    if($build.actions.buildNumber -eq $targetBuildNumber)\n    {\n        $correctBuild = $build\n        Write-Host $build.id\n        Write-Host $build.url\n        Write-Host $build.actions.buildNumber\n        break\n\n    }\n}\n\nif($correctBuild -eq $null)\n{\n    Write-Error ""Build not found.  Must rebuild source to obtain artifact""\n    return;\n}\n\nif($isRunningLocal){$correctBuild.url = $correctBuild.url.Replace(""[public ip address]"", ""[local ipaddress/DNS name]"")}\n\n$targetZip = ""$Env:temp/$($buildDefinitionName)_$($correctBuild.id).zip""\n\n(Invoke-RestMethod -Uri ""$($correctBuild.url)/artifact/$($buildDefinitionName)/*zip*/$($buildDefinitionName)_$($correctBuild.id).zip"" -ContentType Application/zip -Headers $Headers -OutFile $targetZip)\n\nAdd-Type -AssemblyName System.IO.Compression.FileSystem;[System.IO.Compression.ZipFile]::ExtractToDirectory($targetZip, $env:targetDirectory);\n#Expand-Archive -Path $targetZip -DestinationPath $env:targetDirectory -Force\nRemove-Item $targetZip;\n']"
452,3952,3951,CC BY-SA 3.0,2018-04-24T21:03:28.290,"<p>I see two approaches  :</p>

<h2>Save current branch name on a variable and check it in a if statement</h2>

<pre><code>CURRENT_BRANCH = '...' // some value or parameter

stage('only on master') {
  if (CURRENT_BRANCH == 'master') {
  input {
    ...
  }
}

// be sure to check if input was set or define a default value
</code></pre>

<p>or </p>

<h2>Run a shell script to know if current folder is a git repo on master</h2>

<p>The following command check if current folder is a git repository  printing ""true"" ( or returning a error if does not have repo)</p>

<pre><code>git rev-parse --is-inside-work-tree
</code></pre>

<p>The next, print the current branch name </p>

<pre><code>git branch | grep \* | cut -d ' ' -f2
</code></pre>

<p>Use both to create a script that sets an environment variable.
Check the value on your pipeline, to show the input</p>

<pre><code>stage('only on master') {

  // Set true on IS_ON_MASTER if current branch is master, 
  // otherwise set false

  sh ./check-branch-master.sh 

  if (env.IS_ON_MASTER) {
  input {
    ...
  }
}
</code></pre>
",6651,2018-04-24T21:03:28.290,"[""CURRENT_BRANCH = '...' // some value or parameter\n\nstage('only on master') {\n  if (CURRENT_BRANCH == 'master') {\n  input {\n    ...\n  }\n}\n\n// be sure to check if input was set or define a default value\n"", 'git rev-parse --is-inside-work-tree\n', ""git branch | grep \\* | cut -d ' ' -f2\n"", ""stage('only on master') {\n\n  // Set true on IS_ON_MASTER if current branch is master, \n  // otherwise set false\n\n  sh ./check-branch-master.sh \n\n  if (env.IS_ON_MASTER) {\n  input {\n    ...\n  }\n}\n""]"
453,3964,3957,CC BY-SA 3.0,2018-04-25T22:44:12.823,"<p>Simply write a <code>Dockerfile</code> which uses that image as a base. Then you can replace individual files (like the entrypoint) easily.</p>

<p>Also, instead of replacing, you could rename the original entry script, create your own, which does whatever it needs to do, and then just calls the original.</p>

<p>Somewhat like this:</p>

<ul>
<li><p>Dockerfile:</p>

<pre><code>FROM fancy-base-image:1.2.3
RUN mv docker-entrypoint.sh docker-entrypoint-original.sh
ADD docker-entrypoint.sh
</code></pre></li>
<li><p>docker-entrypoint.sh:</p>

<pre><code>#!/bin/bash
echo Do something.
./docker-entrypoint-original.sh
echo Do something else
</code></pre></li>
</ul>

<p>Obviously this is just a fake example, you'll have to adjust for directory and file names and such.</p>
",4175,2018-04-25T22:44:12.823,"['FROM fancy-base-image:1.2.3\nRUN mv docker-entrypoint.sh docker-entrypoint-original.sh\nADD docker-entrypoint.sh\n', '#!/bin/bash\necho Do something.\n./docker-entrypoint-original.sh\necho Do something else\n']"
454,3967,3966,CC BY-SA 3.0,2018-04-26T12:48:03.930,"<p>Download the key once:</p>

<pre><code>gpg --keyserver pgpkeys.mit.edu --recv-key A0E98066
gpg --export A0E98066 &gt; openresty-agentzh-A0E98066.gpg
</code></pre>

<p>Then later you can import the key without having to access the keyserver:</p>

<pre><code>gpg --import openresty-agentzh-A0E98066.gpg
</code></pre>
",2708,2018-04-26T13:00:19.223,"['gpg --keyserver pgpkeys.mit.edu --recv-key A0E98066\ngpg --export A0E98066 > openresty-agentzh-A0E98066.gpg\n', 'gpg --import openresty-agentzh-A0E98066.gpg\n']"
455,3973,3953,CC BY-SA 3.0,2018-04-26T20:22:46.767,"<blockquote>
  <p>Could I have these two different definitions which creates a single
  Ingress with two rules (based on having the same name)?</p>
</blockquote>

<p>Lets investigate whether that would be possible.</p>

<p>According to</p>

<p><a href=""https://kubernetes.io/docs/concepts/services-networking/ingress/"" rel=""nofollow noreferrer"">https://kubernetes.io/docs/concepts/services-networking/ingress/</a></p>

<p>one could update an existing ingress yaml and subsequently run <code>kubectl replace -f</code>. From a microservice perspective, one could store a snippet in every git repo, e.g.:</p>

<pre><code>- host: microservice01.domain.com
  http:
    paths:
    - backend:
        serviceName: ms01
        servicePort: 80
      path: /microservice01
</code></pre>

<p>and deploy it manually or automatically using ssh and merge it with another ingress file that has already been deployed</p>

<pre><code>spec:
  rules:
  &lt;concatenate snippet1&gt;
  &lt;concatenate snippet2&gt;
  and so on and so on
</code></pre>

<p>and run <code>kubectl replace -f</code> once the snippet of a microservice has been deployed.</p>
",210,2018-04-26T20:36:52.340,"['- host: microservice01.domain.com\n  http:\n    paths:\n    - backend:\n        serviceName: ms01\n        servicePort: 80\n      path: /microservice01\n', 'spec:\n  rules:\n  <concatenate snippet1>\n  <concatenate snippet2>\n  and so on and so on\n']"
456,3991,3608,CC BY-SA 3.0,2018-04-27T16:36:16.017,"<p>It is possible to create a secret without passing on the commandline by reading it from file:</p>

<blockquote>
<pre><code>$ kubectl create secret generic ssh-key-secret \
  --from-file=ssh-privatekey=/path/to/.ssh/id_rsa \
  --from-file=ssh-publickey=/path/to/.ssh/id_rsa.pub
</code></pre>
</blockquote>

<p>See <a href=""https://kubernetes.io/docs/concepts/configuration/secret/"" rel=""nofollow noreferrer"">https://kubernetes.io/docs/concepts/configuration/secret/</a> for more information.</p>
",210,2018-04-27T16:36:16.017,['$ kubectl create secret generic ssh-key-secret \\\n  --from-file=ssh-privatekey=/path/to/.ssh/id_rsa \\\n  --from-file=ssh-publickey=/path/to/.ssh/id_rsa.pub\n']
457,3997,3508,CC BY-SA 3.0,2018-04-27T22:09:08.647,"<p>Ok. Maybe you're not gonna like it but there are some things you can do.</p>

<p>One and most simple is to use a volume mount, eventually on a persistent storage but I think an <a href=""https://kubernetes.io/docs/concepts/storage/volumes/#emptydir"" rel=""nofollow noreferrer"">emptyDir</a> can work as well (or even better depending on the nature of the file you want to copy) and use an <a href=""https://kubernetes.io/docs/concepts/workloads/pods/init-containers/"" rel=""nofollow noreferrer"">init container </a> to copy the file to the volume before the app container start. I don't know how you generate that file and I can't speculate about the security implications but the file needs to be in the docker image used for the init container. So, for your init container, you will have a Docker file  like </p>

<pre><code>FROM ubuntu
COPY localfile /container/file
CMD cp /container/file /mnt/kube-volume
</code></pre>

<p>replacing localfile, container/file and /mnt/kube-volume with appropriate values; you build the container image locally -on your machine, so it can contain the file-  and upload it to the (secure) docker repo along with the app container image.</p>

<p>Another method is to upload the file to a (secure) location and have an init container or a bootstrap process that download the file when you start your main application container  in the pod.</p>

<p>The third option is to create a docker image that contains that file and use it for the app container in your pod.</p>
",3009,2018-04-27T22:09:08.647,['FROM ubuntu\nCOPY localfile /container/file\nCMD cp /container/file /mnt/kube-volume\n']
458,4015,3980,CC BY-SA 4.0,2018-04-30T08:42:53.277,"<p>As @Tensibai indicated in one the comments, this could be caused as there is insufficient CPU or memory, but that is not always the case.</p>
<p>For example, a helm chart was just deployed, it failed and the workload in GCP indicated that:</p>
<blockquote>
<p>Pod errors: CrashLoopBackOff</p>
</blockquote>
<p>Based on the comment of @Tensibai the first impression was that there were insufficient resources, but further analysis using <code>kubectl describe pod &lt;pod-name&gt;</code> indicated that in this case the livenessProbe check failed:</p>
<pre><code>Liveness probe failed: Get http://10.16.0.13:80/: dial 
tcp 10.16.0.13:80: getsockopt: connection refused
</code></pre>
<p>In summary, the <code>Does not have minimum availability</code> message is generic. Multiple issues could trigger this and more in dept analysis is required to find the actual error.</p>
",210,2021-03-06T00:13:39.640,['Liveness probe failed: Get http://10.16.0.13:80/: dial \ntcp 10.16.0.13:80: getsockopt: connection refused\n']
459,4016,4013,CC BY-SA 4.0,2018-04-30T09:08:20.787,"<p>Based on <a href=""https://github.com/kubernetes/helm/blob/master/docs/charts_tips_and_tricks.md#creating-image-pull-secrets"" rel=""noreferrer"">this Github documentation</a> it is possible to pull a docker image from a private docker registry:</p>

<p>values.yaml</p>

<pre><code>imageCredentials:
  name: credentials-name
  registry: private-docker-registry
  username: user
  password: pass
</code></pre>

<p>templates/imagePullSecret.yaml</p>

<pre><code>{{- define ""imagePullSecret"" }}
{{- printf ""{\""auths\"": {\""%s\"": {\""auth\"": \""%s\""}}}"" .Values.imageCredentials.registry (printf ""%s:%s"" .Values.imageCredentials.username .Values.imageCredentials.password | b64enc) | b64enc }}
{{- end }}
</code></pre>

<p>templates/secret.yaml</p>

<pre><code>apiVersion: v1
kind: Secret
metadata:
  name: {{ .Values.imageCredentials.name }}
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: {{ template ""imagePullSecret"" . }}
</code></pre>

<p>at the end of the templates/deployment.yaml add the following:</p>

<pre><code>imagePullSecrets:
  - name: {{ .Values.imageCredentials.name }}
</code></pre>
",210,2019-01-22T16:59:19.937,"['imageCredentials:\n  name: credentials-name\n  registry: private-docker-registry\n  username: user\n  password: pass\n', '{{- define ""imagePullSecret"" }}\n{{- printf ""{\\""auths\\"": {\\""%s\\"": {\\""auth\\"": \\""%s\\""}}}"" .Values.imageCredentials.registry (printf ""%s:%s"" .Values.imageCredentials.username .Values.imageCredentials.password | b64enc) | b64enc }}\n{{- end }}\n', 'apiVersion: v1\nkind: Secret\nmetadata:\n  name: {{ .Values.imageCredentials.name }}\ntype: kubernetes.io/dockerconfigjson\ndata:\n  .dockerconfigjson: {{ template ""imagePullSecret"" . }}\n', 'imagePullSecrets:\n  - name: {{ .Values.imageCredentials.name }}\n']"
460,4020,4012,CC BY-SA 3.0,2018-04-30T14:47:14.813,"<p>According to <a href=""https://docs.docker.com/storage/tmpfs/#limitations-of-tmpfs-mounts"" rel=""nofollow noreferrer"">the docs</a> tmpfs is linux only. </p>

<p><strong>RAM disk</strong></p>

<p>If you want ""RAM only storage"", you can literally use a <a href=""https://www.tekrevue.com/tip/how-to-create-a-4gbs-ram-disk-in-mac-os-x/"" rel=""nofollow noreferrer"">RAM disk</a>. ie: </p>

<pre><code>diskutil erasevolume HFS+ 'DockerDisk' `hdiutil attach -nomount ram://2097152 `
</code></pre>

<p>Then you can point volumes at <code>/Volumes/DockerDisk</code>. Drop and recreate at will. </p>

<p>Docker will still store its VM and images on disk. See: Docker > Preferences > Disk.</p>
",7623,2018-04-30T14:47:14.813,"[""diskutil erasevolume HFS+ 'DockerDisk' `hdiutil attach -nomount ram://2097152 `\n""]"
461,4024,4023,CC BY-SA 3.0,2018-04-30T17:09:59.790,"<p>I might be misunderstanding the question.</p>

<p>You tell docker where to put your volume data when you run the container. See <a href=""https://docs.docker.com/engine/reference/run/#volume-shared-filesystems"" rel=""nofollow noreferrer"">the docs</a>. It's not something you need to define in a global config. For example:</p>

<pre><code>docker run -v /Volumes/DockerData/nginx_conf:/etc/nginx/conf.d nginx:latest
</code></pre>

<p>The above would run nginx but pull whatever config files you have in nginx_conf.</p>
",7623,2018-04-30T17:09:59.790,['docker run -v /Volumes/DockerData/nginx_conf:/etc/nginx/conf.d nginx:latest\n']
462,4029,4028,CC BY-SA 3.0,2018-05-01T10:40:13.527,"<p>Neil, it's because the <code>=</code> sign in your <code>/etc/gitlab/gitlab.rb</code> file.</p>

<p>When you'll look on the full comment before the <code>external_url</code> line, you'll see a link to the documentation:</p>

<pre><code>## GitLab URL
##! URL on which GitLab will be reachable.
##! For more details on configuring external_url see:
##! https://docs.gitlab.com/omnibus/settings/configuration.html#configuring-the-external-url-for-gitlab
external_url 'http://gitlab.example.com'
</code></pre>

<p>In the default <code>gitlab.rb</code> file (just after installing the Omnibus GitLab package) and also in the linked documentation you can see, that the <code>external_url</code> value is assigned without the <code>=</code> sign. It's done like that because the <code>external_url</code> is a method, not a variable. So here you're not assigning the value, but calling the method with this value. Ruby allows to call a method without brackets around the arguments, and this is a commonly used pattern when designing a DSLs based on Ruby.</p>

<p>When you try to set the value with:</p>

<pre><code>external_url = 'https://server:actual-fqdn-of-gitlab-server-where-git-repo-is'
</code></pre>

<p>then the <code>external_url</code> method is not receiving any argument and in that case Omnibus GitLab falls back to a default value which is based on host's <code>hostname</code>.</p>

<p>In most cases the hostname of the server where GitLab is installed will be the same as the hostname that the server is accessible with. In some cases - including yours - the <code>external_url</code> needs to be set explicitly.</p>

<p>So the solution seems to be:</p>

<ol>
<li>Change <code>external_url = 'URL_HERE'</code> to <code>external_url 'URL_HERE'</code></li>
<li>Execute <code>sudo gitlab-ctl reconfigure</code></li>
</ol>

<p>This should set the proper values in <code>gitlab.yml</code> file and resolve your problems.</p>
",7642,2018-05-01T10:40:13.527,"[""## GitLab URL\n##! URL on which GitLab will be reachable.\n##! For more details on configuring external_url see:\n##! https://docs.gitlab.com/omnibus/settings/configuration.html#configuring-the-external-url-for-gitlab\nexternal_url 'http://gitlab.example.com'\n"", ""external_url = 'https://server:actual-fqdn-of-gitlab-server-where-git-repo-is'\n""]"
463,4042,4017,CC BY-SA 4.0,2018-05-02T07:25:17.557,"<p>Jenkins itself can be configured in many ways. The same applies for Jenkins jobs.</p>

<p>Probably the most easy way is to configure Jenkins manually and replicate its setup by backing up and restoring. Unfortunately, this means dealing with copying XML files.</p>

<p>But fortunately there are other ways.</p>

<h1><code>init.groovy.d</code> directory</h1>

<p>When Jenkins starts, it checks <code>init.groovy.d</code> directory and executes Groovy scripts there. To enforce locale I'm using a snippet.</p>

<pre><code>// Copied from /var/lib/jenkins/init.groovy.d/set-locale.groovy
def pluginWrapper = jenkins.model.Jenkins.instance.getPluginManager().getPlugin('locale')
def plugin = pluginWrapper.getPlugin()

plugin.setSystemLocale('en_US')
</code></pre>

<p>Another example of setting up Jenkins by Groovy scripts is located on <a href=""https://gist.github.com/hayderimran7/50cb1244cc1e856873a4"" rel=""nofollow noreferrer"">https://gist.github.com/hayderimran7/50cb1244cc1e856873a4</a> - I'm using that snippet to setup local Jenkins users on test machines.</p>

<h1>Generating jobs</h1>

<h2>Jenkins Job builder</h2>

<p>One approach of generating jobs is <a href=""https://docs.openstack.org/infra/jenkins-job-builder/"" rel=""nofollow noreferrer"">Jenkins Job Builder</a>, which creates XML definitions jobs from YAML configurations. I don't like this approach personally as I consider it to be a bit hackish - looks like ""generation of XML files without knowing what it means"". But some big players are using this approach - JJB originates from Openstack.</p>

<h2>Job DSL plugin</h2>

<p>Another approach is <a href=""https://github.com/jenkinsci/job-dsl-plugin"" rel=""nofollow noreferrer"">Job DSL plugin</a> (<a href=""https://plugins.jenkins.io/job-dsl"" rel=""nofollow noreferrer"">plugin page</a>). There is special job type called <em>seed job</em> which creates other jobs from Groovy DSL. The seed job can pull the others job description in from Git, so you can easily version them, reuse them, etc.</p>

<p>I'm using personally this approach, as it was available when I started with Jenkins. I've even found some Jenkins tool to create DSL sources from existing jobs, but I'm not able to find it again.</p>

<p>To provide a seed job, you can still use the <code>init.groovy.d</code> approach.</p>

<h2>Pipelines</h2>

<p>The currently recommended approach is probably related to <a href=""https://jenkins.io/doc/book/pipeline/"" rel=""nofollow noreferrer"">Jenkins Pipelines</a>. You can store your building pipelines in the source VCS repository next to your code.</p>

<p>I haven't explored this very much, but I'm planning to do.</p>
",2479,2018-05-20T06:10:29.370,"[""// Copied from /var/lib/jenkins/init.groovy.d/set-locale.groovy\ndef pluginWrapper = jenkins.model.Jenkins.instance.getPluginManager().getPlugin('locale')\ndef plugin = pluginWrapper.getPlugin()\n\nplugin.setSystemLocale('en_US')\n""]"
464,4046,3859,CC BY-SA 4.0,2018-05-03T02:57:14.020,"<p>If I understand your question correctly you want to pass in a domain to find what could be a physical location or data center. I hope this is helps you!</p>

<p><strong>roles/test/vars/main.yml</strong></p>

<pre><code>---
domains:
  gh4: [127.0.0.1,127.0.0.2,127.0.0.3,127.0.0.4,127.0.0.5]
  gh5: [127.0.0.7,127.0.0.8]
  gh6: [127.0.0.10,127.0.0.11,127.0.0.12]
</code></pre>

<p><strong>roles/test/tasks/main.yml</strong></p>

<pre><code>---
# Make sure we have a domain passed in
- name: Ensure domain is defined
  assert: { that: domain is defined }

# Obtain the IP
- name: Simple A record (IPV4 address) lookup for {{domain}}
  set_fact:
      IP: ""{{ lookup('dig', '+short', '{{domain}}')}}""
  register: output
  tags: test

# Check if the IP belongs to any location
- name: Checking location of IP
  set_fact:
    domain_location: ""{{item}}""
  when:
     - IP in domains[item]
  with_items: ""{{domains}}""

- debug:
    msg: ""domain.com is in gh4.allserevers.com{{domain_location}}""
  when: domain_location is defined
</code></pre>

<p><strong>Example Run</strong>
With domain.com pointing to 127.0.0.12</p>

<pre><code>root@DESKTOP-U4VN2CS:/mnt/c/ansible/roles# ansible-playbook ../playbooks/test.yml  -e domain=domain.com
PLAY [127.0.0.1] ****************************************************************************************************

TASK [Gathering Facts] **********************************************************************************************
ok: [localhost]

TASK [test : Ensure domain is defined] ******************************************************************************
ok: [localhost] =&gt; {
    ""changed"": false,
    ""msg"": ""All assertions passed""
}

TASK [test : Simple A record (IPV4 address) lookup for domain.com] **************************************************
ok: [localhost]

TASK [test : Checking location of IP] *******************************************************************************
skipping: [localhost] =&gt; (item=gh4)
skipping: [localhost] =&gt; (item=gh5)
ok: [localhost] =&gt; (item=gh6)

TASK [test : debug] *************************************************************************************************
ok: [localhost] =&gt; {
    ""msg"": ""domain.com is in gh6.allserevers.com""
}

PLAY RECAP **********************************************************************************************************
localhost                  : ok=5    changed=0    unreachable=0    failed=0
</code></pre>
",7044,2018-05-03T02:57:14.020,"['---\ndomains:\n  gh4: [127.0.0.1,127.0.0.2,127.0.0.3,127.0.0.4,127.0.0.5]\n  gh5: [127.0.0.7,127.0.0.8]\n  gh6: [127.0.0.10,127.0.0.11,127.0.0.12]\n', '---\n# Make sure we have a domain passed in\n- name: Ensure domain is defined\n  assert: { that: domain is defined }\n\n# Obtain the IP\n- name: Simple A record (IPV4 address) lookup for {{domain}}\n  set_fact:\n      IP: ""{{ lookup(\'dig\', \'+short\', \'{{domain}}\')}}""\n  register: output\n  tags: test\n\n# Check if the IP belongs to any location\n- name: Checking location of IP\n  set_fact:\n    domain_location: ""{{item}}""\n  when:\n     - IP in domains[item]\n  with_items: ""{{domains}}""\n\n- debug:\n    msg: ""domain.com is in gh4.allserevers.com{{domain_location}}""\n  when: domain_location is defined\n', 'root@DESKTOP-U4VN2CS:/mnt/c/ansible/roles# ansible-playbook ../playbooks/test.yml  -e domain=domain.com\nPLAY [127.0.0.1] ****************************************************************************************************\n\nTASK [Gathering Facts] **********************************************************************************************\nok: [localhost]\n\nTASK [test : Ensure domain is defined] ******************************************************************************\nok: [localhost] => {\n    ""changed"": false,\n    ""msg"": ""All assertions passed""\n}\n\nTASK [test : Simple A record (IPV4 address) lookup for domain.com] **************************************************\nok: [localhost]\n\nTASK [test : Checking location of IP] *******************************************************************************\nskipping: [localhost] => (item=gh4)\nskipping: [localhost] => (item=gh5)\nok: [localhost] => (item=gh6)\n\nTASK [test : debug] *************************************************************************************************\nok: [localhost] => {\n    ""msg"": ""domain.com is in gh6.allserevers.com""\n}\n\nPLAY RECAP **********************************************************************************************************\nlocalhost                  : ok=5    changed=0    unreachable=0    failed=0\n']"
465,4047,3766,CC BY-SA 4.0,2018-05-03T08:55:10.860,"<p>You can use snippet like</p>

<pre><code>post {
    changed {
        emailext body: '$DEFAULT_CONTENT', recipientProviders: [brokenTestsSuspects(), brokenBuildSuspects(), developers()], subject: '$DEFAULT_SUBJECT'
    }
}
</code></pre>

<p>in declarative pipelines.</p>

<p><a href=""https://jenkins.io/doc/book/pipeline/syntax/#post"" rel=""nofollow noreferrer"" title=""Changed"">Changed</a> post-condition is called when the build result is changed (i.e. of first failure and back to success). There are post-conditions like ""regression"" if you want more control.</p>
",6888,2018-05-03T08:55:10.860,"[""post {\n    changed {\n        emailext body: '$DEFAULT_CONTENT', recipientProviders: [brokenTestsSuspects(), brokenBuildSuspects(), developers()], subject: '$DEFAULT_SUBJECT'\n    }\n}\n""]"
466,4048,863,CC BY-SA 4.0,2018-05-03T11:31:54.773,"<p>We recently open sourced <a href=""https://blog.gruntwork.io/open-sourcing-terratest-a-swiss-army-knife-for-testing-infrastructure-code-5d883336fcd5"" rel=""nofollow noreferrer"">Terratest</a>, our swiss army knife for testing infrastructure code. </p>

<p>Today, you're probably testing all your infrastructure code manually by deploying, validating, and undeploying. Terratest helps you automate this process:</p>

<ol>
<li>Write tests in Go.</li>
<li>Use helpers in Terratest to execute your real IaC tools (e.g., Terraform, Packer, etc.) to deploy real infrastructure (e.g., servers) in a real environment (e.g., AWS).</li>
<li>Use helpers in Terratest to validate that the infrastructure works correctly in that environment by making HTTP requests, API calls, SSH connections, etc.</li>
<li>Use helpers in Terratest to undeploy everything at the end of the test.</li>
</ol>

<p>Here's an example test for some Terraform code:</p>

<pre class=""lang-golang prettyprint-override""><code>terraformOptions := &amp;terraform.Options {
  // The path to where your Terraform code is located
  TerraformDir: ""../examples/terraform-basic-example"",
}

// This will run `terraform init` and `terraform apply` and fail the test if there are any errors
terraform.InitAndApply(t, terraformOptions)

// At the end of the test, run `terraform destroy` to clean up any resources that were created
defer terraform.Destroy(t, terraformOptions)

// Run `terraform output` to get the value of an output variable
instanceUrl := terraform.Output(t, terraformOptions, ""instance_url"")

// Verify that we get back a 200 OK with the expected text
// It can take a minute or so for the Instance to boot up, so retry a few times
expected := ""Hello, World""
maxRetries := 15
timeBetweenRetries := 5 * time.Second
http_helper.HttpGetWithRetry(t, instanceUrl, 200, expected, maxRetries, timeBetweenRetries)
</code></pre>

<p>These are integration tests, and depending on what you're testing, can take 5 - 50 minutes. It's not fast (though using <a href=""https://github.com/gruntwork-io/terratest#iterating-locally-using-docker"" rel=""nofollow noreferrer"">Docker</a> and <a href=""https://github.com/gruntwork-io/terratest#iterating-locally-using-test-stages"" rel=""nofollow noreferrer"">test stages</a>, you can speed <em>some</em> things up), and you'll have to work to make the tests reliable, but it is well worth the time.</p>

<p>Check out the <a href=""https://github.com/gruntwork-io/terratest#iterating-locally-using-test-stages"" rel=""nofollow noreferrer"">Terratest repo</a> for docs and lots of examples of various types of infrastructure code and the corresponding tests for them.</p>
",30,2019-11-09T22:06:31.587,"['terraformOptions := &terraform.Options {\n  // The path to where your Terraform code is located\n  TerraformDir: ""../examples/terraform-basic-example"",\n}\n\n// This will run `terraform init` and `terraform apply` and fail the test if there are any errors\nterraform.InitAndApply(t, terraformOptions)\n\n// At the end of the test, run `terraform destroy` to clean up any resources that were created\ndefer terraform.Destroy(t, terraformOptions)\n\n// Run `terraform output` to get the value of an output variable\ninstanceUrl := terraform.Output(t, terraformOptions, ""instance_url"")\n\n// Verify that we get back a 200 OK with the expected text\n// It can take a minute or so for the Instance to boot up, so retry a few times\nexpected := ""Hello, World""\nmaxRetries := 15\ntimeBetweenRetries := 5 * time.Second\nhttp_helper.HttpGetWithRetry(t, instanceUrl, 200, expected, maxRetries, timeBetweenRetries)\n']"
467,4076,4062,CC BY-SA 4.0,2018-05-09T04:27:19.843,"<p>You can try below /etc/docker/daemon.json </p>

<pre><code>{
    ""experimental"" : true,
    ""storage-driver"" : ""devicemapper"",
    ""storage-opts"" : [""dm.basesize=20G""]
}
</code></pre>

<p>Then try :</p>

<pre><code>systemctl daemon-reload
systemctl restart docker
</code></pre>
",7761,2018-05-09T04:27:19.843,"['{\n    ""experimental"" : true,\n    ""storage-driver"" : ""devicemapper"",\n    ""storage-opts"" : [""dm.basesize=20G""]\n}\n', 'systemctl daemon-reload\nsystemctl restart docker\n']"
468,4080,4079,CC BY-SA 4.0,2018-05-10T07:35:35.397,"<p><a href=""https://docs.docker.com/compose/environment-variables/#the-env-file"" rel=""nofollow noreferrer"">https://docs.docker.com/compose/environment-variables/#the-env-file</a></p>

<p>One could set a variable in an .env file:</p>

<pre><code>TAG=1.2.3
</code></pre>

<p>and call it in a docker-compose file</p>

<p>docker-compose.yml</p>

<pre><code>version: ""3""
services:
  web:
    image: nginx:${TAG}
    ports:
    - 80:80
</code></pre>

<p>docker-compose up</p>

<p>returns:</p>

<pre><code>Pulling web (nginx:1.2.3)...
ERROR: manifest for nginx:1.2.3 not found
</code></pre>

<p>No need to run docker-compose to check the config</p>

<p>According to the documentation one could run:</p>

<pre><code>docker-compose config
</code></pre>

<p>to verify the docker-compose config</p>

<pre><code>networks: {}
services:
  web:
    image: nginx:1.2.3
    ports:
    - 80:80/tcp
version: '3.0'
volumes: {}
</code></pre>
",210,2018-05-10T07:35:35.397,"['TAG=1.2.3\n', 'version: ""3""\nservices:\n  web:\n    image: nginx:${TAG}\n    ports:\n    - 80:80\n', 'Pulling web (nginx:1.2.3)...\nERROR: manifest for nginx:1.2.3 not found\n', 'docker-compose config\n', ""networks: {}\nservices:\n  web:\n    image: nginx:1.2.3\n    ports:\n    - 80:80/tcp\nversion: '3.0'\nvolumes: {}\n""]"
469,4090,4079,CC BY-SA 4.0,2018-05-11T12:49:40.513,"<p>For <code>docker-compose</code>, you can use either the environment or a <code>.env</code> file. For swarm mode, you can only use the environment. So for portability, I like to export variables into the shell or environment of the command being run. </p>

<p>From a bash shell, this would look like:</p>

<pre><code>$ export tomcat_home=/usr/local/tomcat
$ docker-compose up
</code></pre>

<p>Depending on what you use to deploy your containers (shell script, custom code, some other CI/CD tool), exporting your environment variable will vary.</p>
",7730,2018-05-11T12:49:40.513,['$ export tomcat_home=/usr/local/tomcat\n$ docker-compose up\n']
470,4097,4094,CC BY-SA 4.0,2018-05-13T14:41:04.623,"<p>One could also use a docker image from an official docker repository like <a href=""https://hub.docker.com/r/library/redis/"" rel=""nofollow noreferrer"">https://hub.docker.com/r/library/redis/</a></p>

<pre><code>docker run --name some-redis -d redis:alpine
</code></pre>
",210,2018-05-13T14:41:04.623,['docker run --name some-redis -d redis:alpine\n']
471,4103,4101,CC BY-SA 4.0,2018-05-15T09:25:03.180,"<p>First you have to start netcat listening in the background.
$ netcat -l 3440 &amp;</p>

<p>Then build your Dockerfile.</p>

<pre><code>#
# Ubuntu Dockerfile
#
# https://github.com/dockerfile/ubuntu
#

# Pull base image.
FROM ubuntu:14.04

# Install.
RUN \
  sed -i 's/# \(.*multiverse$\)/\1/g' /etc/apt/sources.list &amp;&amp; \
  apt-get update &amp;&amp; \
  apt-get -y upgrade &amp;&amp; \
  apt-get install -y build-essential &amp;&amp; \
  apt-get install -y software-properties-common &amp;&amp; \
  apt-get install -y byobu curl git htop man unzip vim wget &amp;&amp; \
  rm -rf /var/lib/apt/lists/*


# Set environment variables.
ENV HOME /root

# Define working directory.
WORKDIR /root
RUN apt-get install -y netcat
RUN nc localhost 3440 | tar -x -O &gt; ores-$(date +%s.%N).tgz
# Define default command.
CMD [""bash""]
</code></pre>
",7842,2018-05-15T09:25:03.180,"['#\n# Ubuntu Dockerfile\n#\n# https://github.com/dockerfile/ubuntu\n#\n\n# Pull base image.\nFROM ubuntu:14.04\n\n# Install.\nRUN \\\n  sed -i \'s/# \\(.*multiverse$\\)/\\1/g\' /etc/apt/sources.list && \\\n  apt-get update && \\\n  apt-get -y upgrade && \\\n  apt-get install -y build-essential && \\\n  apt-get install -y software-properties-common && \\\n  apt-get install -y byobu curl git htop man unzip vim wget && \\\n  rm -rf /var/lib/apt/lists/*\n\n\n# Set environment variables.\nENV HOME /root\n\n# Define working directory.\nWORKDIR /root\nRUN apt-get install -y netcat\nRUN nc localhost 3440 | tar -x -O > ores-$(date +%s.%N).tgz\n# Define default command.\nCMD [""bash""]\n']"
472,4105,4104,CC BY-SA 4.0,2018-05-15T12:39:45.530,"<p>The scheduler itself is not swappable. However, you can set <a href=""https://docs.docker.com/compose/compose-file/#resources"" rel=""nofollow noreferrer"">memory constraints and reservations on containers in your service</a>:</p>

<pre><code>version: '3'
services:
  redis:
    image: redis:alpine
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 50M
        reservations:
          cpus: '0.25'
          memory: 20M
</code></pre>

<p>The constraint will kill the container if it exceeds the limit even if the host has more memory available. The reservation will ensure that amount of memory on the host is available for the container.</p>
",7730,2018-05-15T12:39:45.530,"[""version: '3'\nservices:\n  redis:\n    image: redis:alpine\n    deploy:\n      resources:\n        limits:\n          cpus: '0.50'\n          memory: 50M\n        reservations:\n          cpus: '0.25'\n          memory: 20M\n""]"
473,4108,4106,CC BY-SA 4.0,2018-05-16T09:17:25.653,"<p>You can simply put a <code>sonar.properties</code> file under <code>/opt/docker-sonar/conf/</code>. This file will be available inside the container under <code>/opt/sonarqube/conf/</code>, because the folder gets mounted as volume.</p>
<p>A full example for a <code>sonar.properties</code> file can be found on <a href=""https://github.com/SonarSource/sonarqube/blob/master/sonar-application/src/main/assembly/conf/sonar.properties"" rel=""nofollow noreferrer"">github</a>. However all you need to enter is:</p>
<pre><code>sonar.ce.javaOpts=-Xmx&lt;XMX_VALUE -Xms&lt;XMS_VALUE&gt; -XX:+HeapDumpOnOutOfMemoryError
</code></pre>
",5252,2021-01-27T11:23:50.210,['sonar.ce.javaOpts=-Xmx<XMX_VALUE -Xms<XMS_VALUE> -XX:+HeapDumpOnOutOfMemoryError\n']
474,4115,2980,CC BY-SA 4.0,2018-05-16T23:44:22.320,"<p>I had a similar problem and this worked for me without it feeling like a hack...</p>

<p><strong>docker-compose.yml</strong>:</p>

<pre><code>version: '3'
services:
   web:
      build .
      environment:
      - GUNICORN_CMD_ARGS=--workers=0 --bind=0.0.0.0:8000 --timeout=10
</code></pre>

<p><em>Note: add env GUNICORN_CMD_ARGS without quotes</em></p>

<p><strong>Dockerfile</strong>:</p>

<pre><code>FROM python:3.6-slim
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt
ENV GUNICORN_CMD_ARGS=""--bind=0.0.0.0:8000 --workers=3""
CMD gunicorn app:app
</code></pre>

<p><em>Note: run CMD gunicorn app:app without passing options via array or quotes</em></p>
",7866,2018-05-16T23:44:22.320,"[""version: '3'\nservices:\n   web:\n      build .\n      environment:\n      - GUNICORN_CMD_ARGS=--workers=0 --bind=0.0.0.0:8000 --timeout=10\n"", 'FROM python:3.6-slim\nCOPY requirements.txt ./\nRUN pip install --no-cache-dir -r requirements.txt\nENV GUNICORN_CMD_ARGS=""--bind=0.0.0.0:8000 --workers=3""\nCMD gunicorn app:app\n']"
475,4117,4035,CC BY-SA 4.0,2018-05-17T07:09:11.287,"<p>The variable <code>GIT_AUTHOR</code> is only visible in the build step where it's defined. You can dump the parameters for the downstream job in a properties file:</p>

<pre>
cd $WORKSPACE/prancer/
GIT_AUTHOR=$(git show --format=""%an"" | head -1)

echo '-------------'
echo 'git_commit is '$GIT_COMMIT
echo 'git_branch is '$GIT_BRANCH
echo 'git_author is '$GIT_AUTHOR
echo '-------------'

cat > alex_test_pipeline.properties &lt&ltEOF
GIT_COMMIT = $GIT_COMMIT
GIT_BRANCH = $GIT_BRANCH
GIT_AUTHOR = $GIT_AUTHOR
EOF
</pre>

<p>In the <code>Trigger parameterized build...</code> step, replace the <code>Predefined parameters</code> with <code>Parameters from properties file</code> (or something like that - I don't remember the exact wording) and select the filename used above. You might also want to check <code>Build only if file exists</code>.</p>
",7855,2018-05-17T07:09:11.287,"['\ncd $WORKSPACE/prancer/\nGIT_AUTHOR=$(git show --format=""%an"" | head -1)\n\necho \'-------------\'\necho \'git_commit is \'$GIT_COMMIT\necho \'git_branch is \'$GIT_BRANCH\necho \'git_author is \'$GIT_AUTHOR\necho \'-------------\'\n\ncat > alex_test_pipeline.properties <&ltEOF;\nGIT_COMMIT = $GIT_COMMIT\nGIT_BRANCH = $GIT_BRANCH\nGIT_AUTHOR = $GIT_AUTHOR\nEOF\n']"
476,4120,4119,CC BY-SA 4.0,2018-05-17T12:09:26.667,"<p>That's what the configuration file is for. Create an <code>ansible.cfg</code> in the directory from where you run <code>ansible</code>, like so:</p>

<pre>
[defaults]
inventory = hosts
ask_vault_pass = True

[privilege_escalation]
become_ask_pass = True
</pre>

<p>See also <a href=""http://docs.ansible.com/ansible/latest/reference_appendices/config.html"" rel=""nofollow noreferrer"">http://docs.ansible.com/ansible/latest/reference_appendices/config.html</a></p>

<p>The <code>ansible.cfg</code> in the working directory precedes <code>/etc/ansible/ansible.cfg</code>. The full search order is described on the page linked above. Command line options you pass on invocation override all configuration files.</p>
",7855,2018-05-17T12:18:07.763,['\n[defaults]\ninventory = hosts\nask_vault_pass = True\n\n[privilege_escalation]\nbecome_ask_pass = True\n']
477,4127,2143,CC BY-SA 4.0,2018-05-18T13:42:24.803,"<p>Just avoid the <code>docker</code> DSL; it is incompatible with Declarative. Also avoid <code>script</code> blocks. Simply</p>

<pre class=""lang-java prettyprint-override""><code>withDockerServer([uri: ""tcp://&lt;my-docker-socket&gt;""]) {
  withDockerRegistry([credentialsId: 'docker-registry-credentials', url: ""https://&lt;my-docker-registry&gt;/""]) {
    sh '''
      docker build -t whatever .
      docker push whatever
      # or better, put all this stuff into a versioned Bash/Python/etc. script
    '''
  }
}
</code></pre>
",7898,2018-05-18T13:42:24.803,"['withDockerServer([uri: ""tcp://<my-docker-socket>""]) {\n  withDockerRegistry([credentialsId: \'docker-registry-credentials\', url: ""https://<my-docker-registry>/""]) {\n    sh \'\'\'\n      docker build -t whatever .\n      docker push whatever\n      # or better, put all this stuff into a versioned Bash/Python/etc. script\n    \'\'\'\n  }\n}\n']"
478,4144,1139,CC BY-SA 4.0,2018-05-22T11:49:03.797,"<p>To add to Philipp's answer, if you are using <code>sudo</code> then you need to make sure to set the <code>DEBIAN_FRONTEND</code> variable afterwards, like so:</p>

<pre><code>apt-get update
sudo DEBIAN_FRONTEND=noninteractive apt-get upgrade -yq
</code></pre>
",7955,2018-05-22T11:49:03.797,['apt-get update\nsudo DEBIAN_FRONTEND=noninteractive apt-get upgrade -yq\n']
479,4151,4138,CC BY-SA 4.0,2018-05-23T00:12:27.937,"<p>The syntax failures are caused by the presence of the <code>{{...}}</code> <a href=""http://jinja.pocoo.org/docs/2.10/templates/#expressions"" rel=""nofollow noreferrer"">expression</a> blocks (normally used for filling the template output with the corresponding content) inside the <code>{%...%}</code> <a href=""http://jinja.pocoo.org/docs/2.10/templates/#list-of-control-structures"" rel=""nofollow noreferrer"">statement</a> blocks.</p>

<p>I only used standalone jinja2 templates, so I'm not 100% certain if this applies to Ansible jinja templates as well, but I suspect so. In the Jinja2 <code>{%...%}</code> statement blocks variables are referenced directly (and variable assignments are done in <code>{% set ...%}</code> statements), so what you're after may be along these lines:</p>

<pre><code>{% set docker_compose_mq = &lt;string-passed from Jenkins&gt; %}
{% set docker_compose_profiles = ""string"" %}

{% if risk_docker_compose_mq == ""string"" %}
  {% set risk_docker_compose_profiles = ""string1"" %}
{% endif %}
</code></pre>
",47,2018-05-23T00:12:27.937,"['{% set docker_compose_mq = <string-passed from Jenkins> %}\n{% set docker_compose_profiles = ""string"" %}\n\n{% if risk_docker_compose_mq == ""string"" %}\n  {% set risk_docker_compose_profiles = ""string1"" %}\n{% endif %}\n']"
480,4154,4153,CC BY-SA 4.0,2018-05-23T06:05:26.057,"<p>My problem resolves down to an issue with group policy, and is likely to be solved with the same answer as this question:</p>

<p><a href=""https://serverfault.com/questions/695839/error-1385-when-executing-runas-on-windows-enterprise-7"">https://serverfault.com/questions/695839/error-1385-when-executing-runas-on-windows-enterprise-7</a></p>

<p>i.e. the required permissions for <code>become</code> to work on Windows, seem to be:</p>

<ul>
<li>Allow Logon as a Service</li>
<li>Allow Logon Locally</li>
</ul>

<h3>Alternate Solution</h3>

<p><a href=""https://docs.ansible.com/ansible/2.5/user_guide/become.html#become-and-windows"" rel=""nofollow noreferrer"">reference</a></p>

<blockquote>
  <p>batch: Runs the process under a batch context that is similar to a
  scheduled task with a password set. This should bypass most WinRM
  restrictions and is useful if the become_user is not allowed to log on
  interactively.</p>
</blockquote>

<p>There is another permission called 'Allow Logon as a Batch Job"". If the domain-user has this permission, the user can run scripts as though they were scheduled tasks.</p>

<p>You can run your scripts using Ansible <code>become</code> and change the logon type to <code>batch</code> as shown below: </p>

<pre><code>win_whoami:
    become: yes
    become_user: ''SOMEDOMAIN\SOMEUSER''
    become_method: runas
    become_flags: logon_type=batch
</code></pre>
",6544,2018-05-24T06:41:30.150,"[""win_whoami:\n    become: yes\n    become_user: ''SOMEDOMAIN\\SOMEUSER''\n    become_method: runas\n    become_flags: logon_type=batch\n""]"
481,4155,3798,CC BY-SA 4.0,2018-05-23T15:40:05.030,"<p>Recently, I used this code snippet (that's part of a regular groovy script located inside the 'vars/' directory) to get the project URL as set in the pipeline project config. Hope this helps.</p>

<pre><code>scm.getUserRemoteConfigs()[0].getUrl()
</code></pre>

<p>FYI, it does not expect to have any SCM operation to have taken place.</p>

<p>For more info, refer to this <a href=""https://stackoverflow.com/questions/38254968/how-do-i-get-the-scm-url-inside-a-jenkins-pipeline-or-multibranch-pipeline"">SO</a> thread. </p>

<p>Hopefully, am not violating the devops stackexchange ground rules with this reference to stack overflow.</p>
",7999,2018-05-23T15:40:05.030,['scm.getUserRemoteConfigs()[0].getUrl()\n']
482,4181,3860,CC BY-SA 4.0,2018-05-27T21:59:43.700,"<p>To answer your question: No, as of now Ansible can't run loops in parallel.</p>
<p>I'd use <a href=""https://linux.die.net/man/8/newusers"" rel=""nofollow noreferrer""><code>newusers</code></a> instead, which is made for bulk user creation. Create a file with all users in it, copy it over to the host, and run <code>newusers /path/to/user/list</code> in a <code>command</code> or <code>shell</code> task.</p>
<p>For example:</p>
<pre><code>- name: Create multiple users
  shell: newusers /path/to/user/list &amp;&amp; touch /path/to/user/ansible-users-added
  args:
    creates: /path/to/user/ansible-users-added

</code></pre>
",7855,2021-04-22T05:17:22.303,['- name: Create multiple users\n  shell: newusers /path/to/user/list && touch /path/to/user/ansible-users-added\n  args:\n    creates: /path/to/user/ansible-users-added\n\n']
483,4188,4185,CC BY-SA 4.0,2018-05-28T15:20:44.950,"<p>Quoting from the cookbook <a href=""https://github.com/poise/application_git/blob/master/README.md#properties"" rel=""nofollow noreferrer"">README</a>:</p>

<blockquote>
  <p>deploy_key – SSH key to use with git. Can be specified either as a
  path to key file already created or as a string value containing the
  key directly.</p>
</blockquote>

<p>And:</p>

<blockquote>
  <p>The application_git resource deploys code from git. It extends the
  core git resource to support deploy keys and disabling strict host key
  verification.</p>
</blockquote>

<p>So checking the core git resource <a href=""https://docs.chef.io/resource_git.html#properties"" rel=""nofollow noreferrer"">documentation</a>:</p>

<blockquote>
  <p>ssh_wrapper Ruby Type: String</p>
  
  <p>The path to the wrapper script used when running SSH with git. The
  GIT_SSH environment variable is set to this.</p>
</blockquote>

<p>so something like this (untested) should do (using the wrapper in the cookbook) :</p>

<pre><code>cookbook_file '/path/to/my/desired/ssh_wrapper.sh' do
  source 'my_ssh_wrapper.sh'
end

application 'accounts' do
  action :deploy
  path &lt;somepath&gt;
  owner 'nobody'
  group 'nogroup'
  git 'name' do
    repository &lt;repopath&gt;
    revision &lt;value&gt;
    ssh_wrapper '/path/to/my/desired/ssh_wrapper.sh'
    deploy_key deploy_key
 end
end 
</code></pre>

<p>You can of course do the same with the deploy_key, but using something like chef_vault or an encrypted databag sounds better to avoid commiting deploy keys within the cookbook.</p>
",13,2018-05-28T15:20:44.950,"[""cookbook_file '/path/to/my/desired/ssh_wrapper.sh' do\n  source 'my_ssh_wrapper.sh'\nend\n\napplication 'accounts' do\n  action :deploy\n  path <somepath>\n  owner 'nobody'\n  group 'nogroup'\n  git 'name' do\n    repository <repopath>\n    revision <value>\n    ssh_wrapper '/path/to/my/desired/ssh_wrapper.sh'\n    deploy_key deploy_key\n end\nend \n""]"
484,4191,4078,CC BY-SA 4.0,2018-05-29T14:45:50.797,"<p>I'm sure it does, otherwise it wouldn't be the module in use in:</p>

<pre><code>https://awslimitchecker.readthedocs.io/en/latest/
</code></pre>

<p>From their setup.py installation script:</p>

<pre><code>requires = [
    'boto3&gt;=1.4.6',
    'botocore&gt;=1.6.0',
    'termcolor&gt;=1.1.0',
    'python-dateutil&gt;=2.4.2',
    'versionfinder&gt;=0.1.1',
    'pytz'
]
</code></pre>

<p>Thing is, maybe what you're trying to build is already built in some way or another. Try searching for libraries that has more or less the description of the tool you're trying to build, before starting.</p>

<p>Happy coding!</p>
",8098,2018-05-30T09:28:18.737,"['https://awslimitchecker.readthedocs.io/en/latest/\n', ""requires = [\n    'boto3>=1.4.6',\n    'botocore>=1.6.0',\n    'termcolor>=1.1.0',\n    'python-dateutil>=2.4.2',\n    'versionfinder>=0.1.1',\n    'pytz'\n]\n""]"
485,4192,4190,CC BY-SA 4.0,2018-05-29T15:17:18.943,"<p>No need to change the Dockerfile. Just define a certain user, e.g. jenkins and a certain uid, e.g. <code>1000</code> and ensure the same uid is used when a folder is mounted.</p>

<blockquote>
<pre><code>ARG user=jenkins
ARG uid=1000

# Jenkins is run with user `jenkins`, uid = 1000
# If you bind mount a volume from the host or a data container,
# ensure you use the same uid
RUN mkdir -p $JENKINS_HOME \
    &amp;&amp; chown ${uid}:${gid} $JENKINS_HOME \
    &amp;&amp; addgroup -g ${gid} ${group} \
&amp;&amp; adduser -h ""$JENKINS_HOME"" -u ${uid} -G ${group} -s /bin/bash -D ${user}

RUN chown -R ${user} ""$JENKINS_HOME"" /usr/share/jenkins/ref
</code></pre>
</blockquote>

<p><a href=""https://github.com/jenkinsci/docker/blob/master/Dockerfile-alpine"" rel=""nofollow noreferrer"">https://github.com/jenkinsci/docker/blob/master/Dockerfile-alpine</a></p>
",210,2018-05-29T15:17:18.943,"['ARG user=jenkins\nARG uid=1000\n\n# Jenkins is run with user `jenkins`, uid = 1000\n# If you bind mount a volume from the host or a data container,\n# ensure you use the same uid\nRUN mkdir -p $JENKINS_HOME \\\n    && chown ${uid}:${gid} $JENKINS_HOME \\\n    && addgroup -g ${gid} ${group} \\\n&& adduser -h ""$JENKINS_HOME"" -u ${uid} -G ${group} -s /bin/bash -D ${user}\n\nRUN chown -R ${user} ""$JENKINS_HOME"" /usr/share/jenkins/ref\n']"
486,4197,3953,CC BY-SA 4.0,2018-05-29T18:47:48.107,"<p>I was able to combine your two example files by first converting them to JSON. </p>

<p><strong>foo.json</strong></p>

<pre><code>{
  ""apiVersion"": ""extensions/v1beta1"",
  ""kind"": ""Ingress"",
  ""metadata"": {
    ""name"": ""nginx-ingress""
  },
  ""spec"": {
    ""tls"": [
      {
        ""hosts"": [
          ""foo.bar.com""
        ],
        ""secretName"": ""tls-secret""
      }
    ],
    ""rules"": [
      {
        ""host"": ""foo.bar.com"",
        ""http"": {
          ""paths"": [
            {
              ""path"": ""/"",
              ""backend"": {
                ""serviceName"": ""foo-web-svc"",
                ""servicePort"": 80
              }
            },
            {
              ""path"": ""/api"",
              ""backend"": {
                ""serviceName"": ""foo-rest-svc"",
                ""servicePort"": 80
              }
            }
          ]
        }
      }
    ]
  }
}
</code></pre>

<p><strong>baz.json</strong></p>

<pre><code>{
  ""apiVersion"": ""extensions/v1beta1"",
  ""kind"": ""Ingress"",
  ""metadata"": {
    ""name"": ""nginx-ingress""
  },
  ""spec"": {
    ""tls"": [
      {
        ""hosts"": [
          ""baz.bar.com""
        ],
        ""secretName"": ""tls-secret""
      }
    ],
    ""rules"": [
      {
        ""host"": ""baz.bar.com"",
        ""http"": {
          ""paths"": [
            {
              ""path"": ""/"",
              ""backend"": {
                ""serviceName"": ""baz-web-svc"",
                ""servicePort"": 80
              }
            },
            {
              ""path"": ""/api"",
              ""backend"": {
                ""serviceName"": ""baz-rest-svc"",
                ""servicePort"": 80
              }
            }
          ]
        }
      }
    ]
  }
}
</code></pre>

<p>You can then combine the rules for each by using <a href=""https://stedolan.github.io/jq/"" rel=""nofollow noreferrer"">jq</a>.</p>

<pre><code>levi@La-Tower:~$ jq 'reduce inputs as $i (.; .spec.rules += $i.spec.rules)' foo.json baz.json
{
  ""apiVersion"": ""extensions/v1beta1"",
  ""kind"": ""Ingress"",
  ""metadata"": {
    ""name"": ""nginx-ingress""
  },
  ""spec"": {
    ""tls"": [
      {
        ""hosts"": [
          ""foo.bar.com""
        ],
        ""secretName"": ""tls-secret""
      }
    ],
    ""rules"": [
      {
        ""host"": ""foo.bar.com"",
        ""http"": {
          ""paths"": [
            {
              ""path"": ""/"",
              ""backend"": {
                ""serviceName"": ""foo-web-svc"",
                ""servicePort"": 80
              }
            },
            {
              ""path"": ""/api"",
              ""backend"": {
                ""serviceName"": ""foo-rest-svc"",
                ""servicePort"": 80
              }
            }
          ]
        }
      },
      {
        ""host"": ""baz.bar.com"",
        ""http"": {
          ""paths"": [
            {
              ""path"": ""/"",
              ""backend"": {
                ""serviceName"": ""baz-web-svc"",
                ""servicePort"": 80
              }
            },
            {
              ""path"": ""/api"",
              ""backend"": {
                ""serviceName"": ""baz-rest-svc"",
                ""servicePort"": 80
              }
            }
          ]
        }
      }
    ]
  }
}
</code></pre>

<p>While yaml is more common JSON is perfectly valid for the Kubernetes API. All credit for the jq logic goes to @Jeff Mercado and his <a href=""https://stackoverflow.com/questions/42011086/merge-arrays-of-json"">answer</a>.</p>
",4427,2018-05-29T18:47:48.107,"['{\n  ""apiVersion"": ""extensions/v1beta1"",\n  ""kind"": ""Ingress"",\n  ""metadata"": {\n    ""name"": ""nginx-ingress""\n  },\n  ""spec"": {\n    ""tls"": [\n      {\n        ""hosts"": [\n          ""foo.bar.com""\n        ],\n        ""secretName"": ""tls-secret""\n      }\n    ],\n    ""rules"": [\n      {\n        ""host"": ""foo.bar.com"",\n        ""http"": {\n          ""paths"": [\n            {\n              ""path"": ""/"",\n              ""backend"": {\n                ""serviceName"": ""foo-web-svc"",\n                ""servicePort"": 80\n              }\n            },\n            {\n              ""path"": ""/api"",\n              ""backend"": {\n                ""serviceName"": ""foo-rest-svc"",\n                ""servicePort"": 80\n              }\n            }\n          ]\n        }\n      }\n    ]\n  }\n}\n', '{\n  ""apiVersion"": ""extensions/v1beta1"",\n  ""kind"": ""Ingress"",\n  ""metadata"": {\n    ""name"": ""nginx-ingress""\n  },\n  ""spec"": {\n    ""tls"": [\n      {\n        ""hosts"": [\n          ""baz.bar.com""\n        ],\n        ""secretName"": ""tls-secret""\n      }\n    ],\n    ""rules"": [\n      {\n        ""host"": ""baz.bar.com"",\n        ""http"": {\n          ""paths"": [\n            {\n              ""path"": ""/"",\n              ""backend"": {\n                ""serviceName"": ""baz-web-svc"",\n                ""servicePort"": 80\n              }\n            },\n            {\n              ""path"": ""/api"",\n              ""backend"": {\n                ""serviceName"": ""baz-rest-svc"",\n                ""servicePort"": 80\n              }\n            }\n          ]\n        }\n      }\n    ]\n  }\n}\n', 'levi@La-Tower:~$ jq \'reduce inputs as $i (.; .spec.rules += $i.spec.rules)\' foo.json baz.json\n{\n  ""apiVersion"": ""extensions/v1beta1"",\n  ""kind"": ""Ingress"",\n  ""metadata"": {\n    ""name"": ""nginx-ingress""\n  },\n  ""spec"": {\n    ""tls"": [\n      {\n        ""hosts"": [\n          ""foo.bar.com""\n        ],\n        ""secretName"": ""tls-secret""\n      }\n    ],\n    ""rules"": [\n      {\n        ""host"": ""foo.bar.com"",\n        ""http"": {\n          ""paths"": [\n            {\n              ""path"": ""/"",\n              ""backend"": {\n                ""serviceName"": ""foo-web-svc"",\n                ""servicePort"": 80\n              }\n            },\n            {\n              ""path"": ""/api"",\n              ""backend"": {\n                ""serviceName"": ""foo-rest-svc"",\n                ""servicePort"": 80\n              }\n            }\n          ]\n        }\n      },\n      {\n        ""host"": ""baz.bar.com"",\n        ""http"": {\n          ""paths"": [\n            {\n              ""path"": ""/"",\n              ""backend"": {\n                ""serviceName"": ""baz-web-svc"",\n                ""servicePort"": 80\n              }\n            },\n            {\n              ""path"": ""/api"",\n              ""backend"": {\n                ""serviceName"": ""baz-rest-svc"",\n                ""servicePort"": 80\n              }\n            }\n          ]\n        }\n      }\n    ]\n  }\n}\n']"
487,4221,4216,CC BY-SA 4.0,2018-06-01T17:22:42.630,"<p>Some thoughts:</p>

<ol>
<li>You do not have to clone the entire project.  <a href=""https://stackoverflow.com/questions/2466735/how-to-checkout-only-one-file-from-git-repository-sparse-checkout?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa"">https://stackoverflow.com/questions/2466735/how-to-checkout-only-one-file-from-git-repository-sparse-checkout?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa</a> discusses how to checkout a single file.  I have also had good results using curl to get single files off github.</li>
<li>You can containerize it.  Like this </li>
</ol>

<blockquote>
<pre><code>FROM docker/compose:1.21.2
RUN mkdir /src
WORKDIR /src
COPY docker-compose.yml /src/docker-compose.yml
ENTRYPOINT [""docker-compose""]
CMD []
</code></pre>
</blockquote>

<p>You can containerize docker-compose just like any other application.</p>
",8142,2018-06-01T17:22:42.630,"['FROM docker/compose:1.21.2\nRUN mkdir /src\nWORKDIR /src\nCOPY docker-compose.yml /src/docker-compose.yml\nENTRYPOINT [""docker-compose""]\nCMD []\n']"
488,4226,4223,CC BY-SA 4.0,2018-06-01T21:27:02.510,"<p>Found the origin of the issue, and unless someone else had run into it they wouldn't have known where to look --</p>
<p>check details of <code>tower-cli --version</code> and <code>ansible --version</code>, as well as <code>which tower-cli</code> <code>which ansible</code>;  in my case were installed in <em>different</em> python environments:</p>
<blockquote>
<p>/usr/lib/python<strong>2.6</strong>/site-packages/ansible</p>
<p>/usr/lib/python<strong>3.4</strong>/site-packages/tower_cli</p>
</blockquote>
<p>If you cannot see the python version using the above for tower-cli, you can run:</p>
<pre><code>$ head -n1 `which tower-cli`
#!/usr/local/opt/python/bin/python3.7
$ 
</code></pre>
<p>The ansible modules couldn't see the tower_cli python modules as they were in a different python environment.</p>
<p>After-the-fact problem origin:  I had installed <strong><code>ansible</code> via <code>yum</code></strong> (package manager), and <strong><code>ansible-tower-cli</code> via <code>pip</code></strong> (python installer).  Being consistent in how you install both to make sure they go to the same environment resolves the issue.</p>
<p><em>Centos/RHEL</em>: <code>yum install ansible ansible-tower-cli</code></p>
<p>-OR-</p>
<p><em>Python</em>:  <code>pip install ansible</code></p>
<p><em>Python</em>:  <code>pip install ansible-tower-cli</code></p>
",8155,2019-05-28T22:59:29.613,['$ head -n1 `which tower-cli`\n#!/usr/local/opt/python/bin/python3.7\n$ \n']
489,4246,3773,CC BY-SA 4.0,2018-06-05T14:29:37.937,"<p>Solution was to put a docker pull into my launch script ... as in</p>

<pre><code>docker-compose -f ${GKE_COMPOSE_YAML} pull
</code></pre>

<p>just before issuing </p>

<pre><code>docker-compose -f ${GKE_COMPOSE_YAML} up -d
</code></pre>

<p>which seems strange since most of the time it works OK without issuing pull ... I am using a local docker registry</p>
",192,2018-06-05T14:29:37.937,"['docker-compose -f ${GKE_COMPOSE_YAML} pull\n', 'docker-compose -f ${GKE_COMPOSE_YAML} up -d\n']"
490,4277,2155,CC BY-SA 4.0,2018-06-10T06:12:10.083,"<p>Try installation instructions from <a href=""https://chocolatey.org/install#completely-offline-install"" rel=""nofollow noreferrer"">https://chocolatey.org/install#completely-offline-install</a> (section ""Installing behind a proxy""):</p>

<pre><code>    @powershell -NoProfile -ExecutionPolicy Bypass -Command ""[System.Net.WebRequest]::DefaultWebProxy.Credentials = [System.Net.CredentialCache]::DefaultCredentials; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))"" &amp;&amp; SET PATH=%PATH%;%ALLUSERSPROFILE%\chocolatey\bin
</code></pre>
",8264,2018-06-10T06:12:10.083,"['    @powershell -NoProfile -ExecutionPolicy Bypass -Command ""[System.Net.WebRequest]::DefaultWebProxy.Credentials = [System.Net.CredentialCache]::DefaultCredentials; iex ((New-Object System.Net.WebClient).DownloadString(\'https://chocolatey.org/install.ps1\'))"" && SET PATH=%PATH%;%ALLUSERSPROFILE%\\chocolatey\\bin\n']"
491,4282,4281,CC BY-SA 4.0,2018-06-12T11:14:47.557,"<p>Note that the suspect filename character may not actually be <code>?</code>, that could be just a filename displaying artifact if your system somehow doesn't properly display that character. BTW, <code>R?glement</code> sounds awfully close to the French <code>Règlement</code>.</p>

<p>One possible approach to accessing those files without worrying too much about typing in those characters or escaping them would be to try to wildcard them instead. In your case try something along these lines (use a more specific pattern if there are other files matching this one besides the 2 files of interest):</p>

<pre><code>aws s3 sync R*glement*pdf s3://bucket_name/raw_files/ --sse
</code></pre>
",47,2018-06-12T11:14:47.557,['aws s3 sync R*glement*pdf s3://bucket_name/raw_files/ --sse\n']
492,4286,292,CC BY-SA 4.0,2018-06-12T16:19:36.657,"<p>In general, there are two ways to automate actions from Jenkins:</p>

<ol>
<li>Install a plugin for Jenkins and use it in steps to automate tasks.</li>
<li>Write a script (shell, python, other) and call it from a step to automate tasks.</li>
</ol>

<p>There are drawbacks / benefits to both approaches. While #1 - the plugin approach - gives you out of the box functionality and does not require you to script, it may be rigid and limited in its abilities. #2 - the scripting approach - requires you to write scripts, as well as maintain them, but may provide much more flexibiity and freedom in automating things.</p>

<p>The scripting approach generally uses a lot of CLIs - aws cli, docker cli, etc. </p>

<p>If #2 - the scripting approach - is viable and you're comfortable with writing shell scripts or other scripts like python to interact with the mainframe, then Brightside can help. </p>

<p>Here's an example of using <a href=""https://www.ca.com/us/trials/ca-brightside.html"" rel=""nofollow noreferrer"">Brightside (free CLI)</a> to interact with PDS on z/OS from a shell script:</p>

<pre><code>    #!/bin/sh
    echo 'bright files create classic ""USER.PUBLIC.SAMPLE.PDS""'
    bright files create classic ""USER.PUBLIC.SAMPLE.PDS""
    echo ''

    echo 'bright files download all-members ""USER.LIB.SAMP"" -d MyPDS'
    bright files download all-members ""USER.LIB.SAMP"" -d MyPDS
    echo ''

    echo 'bright files upload dir-to-pds MyPDS ""USER.PUBLIC.SAMPLE.PDS""'
    bright files upload dir-to-pds MyPDS ""USER.PUBLIC.SAMPLE.PDS""
    echo ''

    echo 'bright files list all-members ""USER.PUBLIC.SAMPLE.PDS""'
    bright files list all-members ""USER.PUBLIC.SAMPLE.PDS""
    echo ''

    echo 'bright files delete data-set ""USER.PUBLIC.SAMPLE.PDS(ALLOCLIB)"" -f'
    bright files delete data-set ""USER.PUBLIC.SAMPLE.PDS(ALLOCLIB)"" -f
    echo ''

    echo 'bright files list all-members ""USER.PUBLIC.SAMPLE.PDS""'
    bright files list all-members ""USER.PUBLIC.SAMPLE.PDS""
    echo ''

    echo 'bright files delete data-set ""USER.PUBLIC.SAMPLE.PDS"" -f'
    bright files delete data-set ""USER.PUBLIC.SAMPLE.PDS"" -f
    echo ''
</code></pre>

<p>Here's the output from that script:</p>

<p><a href=""https://i.stack.imgur.com/ruVTc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ruVTc.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/BwueG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BwueG.png"" alt=""enter image description here""></a></p>

<p>Easy enough to call these scripts from Jenkins and parse the output for whatever purpose.</p>

<p>Full disclosure: I work for CA who created Brightside but we do use this CLI internally for the exact purpose of integrating our mainframe application testing with Jenkins.</p>

<p>
",8291,2018-06-14T15:54:36.577,"['    #!/bin/sh\n    echo \'bright files create classic ""USER.PUBLIC.SAMPLE.PDS""\'\n    bright files create classic ""USER.PUBLIC.SAMPLE.PDS""\n    echo \'\'\n\n    echo \'bright files download all-members ""USER.LIB.SAMP"" -d MyPDS\'\n    bright files download all-members ""USER.LIB.SAMP"" -d MyPDS\n    echo \'\'\n\n    echo \'bright files upload dir-to-pds MyPDS ""USER.PUBLIC.SAMPLE.PDS""\'\n    bright files upload dir-to-pds MyPDS ""USER.PUBLIC.SAMPLE.PDS""\n    echo \'\'\n\n    echo \'bright files list all-members ""USER.PUBLIC.SAMPLE.PDS""\'\n    bright files list all-members ""USER.PUBLIC.SAMPLE.PDS""\n    echo \'\'\n\n    echo \'bright files delete data-set ""USER.PUBLIC.SAMPLE.PDS(ALLOCLIB)"" -f\'\n    bright files delete data-set ""USER.PUBLIC.SAMPLE.PDS(ALLOCLIB)"" -f\n    echo \'\'\n\n    echo \'bright files list all-members ""USER.PUBLIC.SAMPLE.PDS""\'\n    bright files list all-members ""USER.PUBLIC.SAMPLE.PDS""\n    echo \'\'\n\n    echo \'bright files delete data-set ""USER.PUBLIC.SAMPLE.PDS"" -f\'\n    bright files delete data-set ""USER.PUBLIC.SAMPLE.PDS"" -f\n    echo \'\'\n']"
493,4294,4293,CC BY-SA 4.0,2018-06-13T11:41:27.753,"<p>Here is a solution which seems almost like a workaround that I have found which works for declarative pipelines.</p>

<p>First, we need to add some code at the start of our file before we enter into the <code>pipeline{}</code> section. The code we add will run before the pipeline section, and will check if the env/param exists, and if it does will take the value, otherwise we will give it a default and assign that to a variable that we can access during the pipeline. Then we need to change our pipeline code references from the parameter to the variable. </p>

<p>Below is a sample that defines an arbitrary parameter, and also an agent label to be used. As you can see, the variables can be used during stages and also during procedures such as determining the agent.</p>

<pre><code>def MY_VARIABLE = null
if (env.my_parameter) {
  MY_VARIABLE = env.my_parameter
} else {
  MY_VARIABLE = ""my default value""
}
echo ""MY VARIABLE IS SET: ${MY_VARIABLE}""

def MY_AGENT = null
if (env.my_agent) {
  MY_AGENT = env.my_agent
} else {
  MY_AGENT = ""agent_label""
}
echo ""MY AGENT IS SET: ${MY_AGENT}""

pipeline {
    parameters {
        string(defaultValue: ""my default value"", description: 'This is my parameter', name: 'my_parameter') ;
        string(defaultValue: ""agent_label"", description: 'This is my agent label', name: 'my_agent') ;
    }
    agent {
      label ""${MY_AGENT}""
    }
    stages {
        stage('my stage') {
            steps {
                sh 'echo ${MY_VARIABLE}'
            }
        }
    }
}
</code></pre>
",8189,2018-06-13T11:41:27.753,"['def MY_VARIABLE = null\nif (env.my_parameter) {\n  MY_VARIABLE = env.my_parameter\n} else {\n  MY_VARIABLE = ""my default value""\n}\necho ""MY VARIABLE IS SET: ${MY_VARIABLE}""\n\ndef MY_AGENT = null\nif (env.my_agent) {\n  MY_AGENT = env.my_agent\n} else {\n  MY_AGENT = ""agent_label""\n}\necho ""MY AGENT IS SET: ${MY_AGENT}""\n\npipeline {\n    parameters {\n        string(defaultValue: ""my default value"", description: \'This is my parameter\', name: \'my_parameter\') ;\n        string(defaultValue: ""agent_label"", description: \'This is my agent label\', name: \'my_agent\') ;\n    }\n    agent {\n      label ""${MY_AGENT}""\n    }\n    stages {\n        stage(\'my stage\') {\n            steps {\n                sh \'echo ${MY_VARIABLE}\'\n            }\n        }\n    }\n}\n']"
494,4300,4299,CC BY-SA 4.0,2018-06-14T13:42:18.457,"<p>You need to pass that info to your module or also declare it in your module again. For example, for the region, pass it as a variable to the module:</p>

<pre><code>module ""foo"" {
  ...
  current_region = ""${data.aws_region.current.name}""
  ...
}
</code></pre>

<p>Or add it inline in your module, just like you did in your <code>main.tf</code></p>
",8333,2018-06-14T13:42:18.457,"['module ""foo"" {\n  ...\n  current_region = ""${data.aws_region.current.name}""\n  ...\n}\n']"
495,4311,4310,CC BY-SA 4.0,2018-06-17T00:10:05.970,"<p>ChatOps uses <a href=""https://help.github.com/articles/about-required-status-checks/"" rel=""nofollow noreferrer"">GitHub status checks</a>, so it's decidedly GitHub specific and won't work with another provider.</p>

<p>However, if you're just after notifications, what about Heroku's <a href=""https://devcenter.heroku.com/articles/app-webhooks"" rel=""nofollow noreferrer"">App webhooks</a>? They have an 'entity' for new app releases (<code>api:release</code>) which might partially help you... in that you can set up a notification for successful releases, at least.</p>

<p>Alternatively, you could listen to the <code>api:build</code> entity's <code>create</code> event to know when a build starts, and the <code>update</code> event to know when its status changes - which I haven't used but presume would include a field for whether it succeeded or failed.</p>

<p>To subscribe to a webhook, you use the Heroku CLI:</p>

<pre><code>heroku webhooks:add --include api:build --level sync --url https://example.com/hooks
</code></pre>

<p>This is outlined in more detail in the documentation <a href=""https://devcenter.heroku.com/articles/app-webhooks#step-3-subscribe"" rel=""nofollow noreferrer"">here</a>. The payload you receive will look like <a href=""https://devcenter.heroku.com/articles/app-webhooks#receiving-webhooks"" rel=""nofollow noreferrer"">this</a>.</p>

<p>This isn't going to get it straight into Slack for you though, so you'll need a piece of middleware to do that. Here's a <a href=""https://github.com/tdmalone/docker-to-slack"" rel=""nofollow noreferrer"">tiny Sinatra app</a> I forked from a fork. It converts Docker Hub notifications into the format Slack expects for an incoming webhook. It should be pretty easy to edit it to make it convert Heroku webhooks instead. Then, voila, the tiny app itself deploys on Heroku, and that's the URL you stick in the webhook subscription above.</p>

<p>This is probably a lot more steps than you wanted. Someone may have already done it somewhere... but I can say that at least doing it the above way will give you a lot more flexibility to create your own customised workflows where you need them!</p>
",249,2018-06-17T00:10:05.970,['heroku webhooks:add --include api:build --level sync --url https://example.com/hooks\n']
496,4313,3221,CC BY-SA 4.0,2018-06-17T01:11:19.470,"<p>AWS have a CloudWatch agent which will submit a number of useful (configurable) metrics, including <code>inodes_free</code>, <code>inodes_used</code>, and <code>inodes_total</code>. They'll appear, by default, under the <code>CWAgent</code> namespace in CloudWatch metrics from where you can view them, add them to dashboards, create alarms etc.</p>

<p>For the full details, these links will be useful:</p>

<ul>
<li><a href=""https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/install-CloudWatch-Agent-on-first-instance.html"" rel=""nofollow noreferrer"">installing the agent</a></li>
<li><a href=""https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-Configuration-File-Details.html"" rel=""nofollow noreferrer"">configuring the agent</a></li>
<li><a href=""https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/troubleshooting-CloudWatch-Agent.html"" rel=""nofollow noreferrer"">troubleshooting the agent</a></li>
</ul>

<p>Alternatively, the quickest way to get started is to:</p>

<ol>
<li>Download the agent from <a href=""https://s3.amazonaws.com/amazoncloudwatch-agent/linux/amd64/latest/AmazonCloudWatchAgent.zip"" rel=""nofollow noreferrer"">https://s3.amazonaws.com/amazoncloudwatch-agent/linux/amd64/latest/AmazonCloudWatchAgent.zip</a></li>
<li>Unzip and run <code>install.sh</code></li>
<li>Start the agent by running <code>/opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a start</code> (this will create a default config file)</li>
<li>Edit the default config file at <code>/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json</code> and modify the <code>metrics_collected</code> to include the inode metrics under the <code>disk</code> category (see below for sample).</li>
<li>Stop (above command but with <code>-a stop</code> instead) and start the agent for the new config to take effect.</li>
</ol>

<p>You should then see the new metrics appear in CloudWatch within a minute or so. The agent should also automatically start at boot.</p>

<p>Here's a sample of defining the inode metrics (for full details see the <a href=""https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-Agent-Configuration-File-Details.html"" rel=""nofollow noreferrer"">configuration docs</a>):</p>

<pre><code>{
  ""metrics"": {
    ""append_dimensions"": {
      ""InstanceId"": ""${aws:InstanceId}""
    },
    ""metrics_collected"": {
      ""disk"": {
        ""measurement"": [
          ""inodes_free"",
          ""inodes_used"",
          ""inodes_total""
        ],
        ""metrics_collection_interval"": 60,
        ""resources"": [
          ""*""
        ]
      }
    }
  }
}
</code></pre>
",249,2018-06-17T01:11:19.470,"['{\n  ""metrics"": {\n    ""append_dimensions"": {\n      ""InstanceId"": ""${aws:InstanceId}""\n    },\n    ""metrics_collected"": {\n      ""disk"": {\n        ""measurement"": [\n          ""inodes_free"",\n          ""inodes_used"",\n          ""inodes_total""\n        ],\n        ""metrics_collection_interval"": 60,\n        ""resources"": [\n          ""*""\n        ]\n      }\n    }\n  }\n}\n']"
497,4314,4292,CC BY-SA 4.0,2018-06-17T02:45:03.080,"<p>Not really. The standard way to work around this though is to use eg:</p>

<pre><code>terraform apply -target=aws_security_group.my_sg
</code></pre>

<p>but that's only going to apply one security group at a time, so will get tedious if you have a lot of them. You can, however, target multiple resources in one command:</p>

<pre><code>terraform apply -target=aws_security_group.my_sg -target=aws_security_group.my_2nd_sg
</code></pre>

<p>However, there are potentially a couple of workarounds:</p>

<ul>
<li><p><strong>The <code>-target</code> parameter respects dependencies.</strong></p>

<p>This means if you were to eg. <code>-target=aws_instance.my_server</code> and that instance had, say, five security groups attached to it via interpolation, changes to those security groups <em>should</em> be included in the plan (I haven't thoroughly tested this, but I believe this is how it works).</p>

<p>That is a bit messy though, as you probably don't want to touch an instance. A safer alternative might be using something like a <a href=""https://www.terraform.io/docs/provisioners/null_resource.html"" rel=""noreferrer""><code>null_resource</code></a> to provide a target for the security groups, but again I haven't tried this (there might be another 'safe' resource you could rely on, though?).
<br /><br /></p></li>
<li><p><strong>Create a module.</strong></p>

<p>You can target a <a href=""https://www.terraform.io/docs/configuration-0-11/modules.html"" rel=""noreferrer"">module</a> just like you can target a plain resource:</p>

<pre><code>terraform apply -target=module.my_security_groups
</code></pre>

<p>Inside this module, you could define all of your security groups - just like you would have outside of the module. As well as being able to target it directly, this also makes it easier for you to re-use the same set of security groups for other infrastructure, if you ever need to.</p></li>
</ul>
",249,2019-05-22T01:31:56.933,"['terraform apply -target=aws_security_group.my_sg\n', 'terraform apply -target=aws_security_group.my_sg -target=aws_security_group.my_2nd_sg\n', 'terraform apply -target=module.my_security_groups\n']"
498,4319,4312,CC BY-SA 4.0,2018-06-18T02:25:26.930,"<p>So far, I've taken to defining the default <code>builders</code> and <code>provisioners</code> we use, with <a href=""https://www.packer.io/docs/templates/user-variables.html"" rel=""nofollow noreferrer"">user variables</a> interpolated in where required, eg:</p>

<pre><code> ""type"": ""amazon-ebs"",
 ""instance_type"": ""t2.micro"",
 ""ami_name"": ""{{ user `ami-name` }} 
</code></pre>

<p>I've got files called eg. <code>packer-builders.json</code> and <code>packer-provisioners.json</code>, and then all the separate Packer templates in their own directories.</p>

<p>I've then written a quick Bash script that takes the name of the template one wants to build, finds all the <code>packer-*.json</code> files, and uses <code>jq --slurp</code> to merge them in (eg. <code>jq --slurp '.[0] * .[1] * .[2]' $LIST_OF_FILES</code>) with the supplied template at the end. It saves the output and sends that along to <code>packer build</code>.</p>

<p>As a bonus, I'm also using <code>jsmin</code> before hitting <code>jq</code> so that I can include comments in any of the JSON files.</p>

<p>It works well, but I'm not a <em>massive</em> fan of it because it's custom and it adds an additional barrier for entry for others coming across it (much more to consider than just <code>packer build something.json</code>!</p>

<p>So I'm really keen for additional answers here if there's a better way to do this.</p>
",249,2018-06-18T02:25:26.930,"[' ""type"": ""amazon-ebs"",\n ""instance_type"": ""t2.micro"",\n ""ami_name"": ""{{ user `ami-name` }} \n']"
499,4323,4322,CC BY-SA 4.0,2018-06-18T10:17:22.263,"<p>If anyone else has this issue, here's how I got around it.</p>

<p>Specify a variable with the availability zones you want to target</p>

<pre><code>variable ""zones"" {
  default = [""us-east-1b"", ""us-east-1c"", ""us-east-1d""]
}
</code></pre>

<p>When creating your subnets, use this line</p>

<pre><code>availability_zone = ""${var.zones[count.index]}""
</code></pre>
",8332,2018-06-18T10:17:22.263,"['variable ""zones"" {\n  default = [""us-east-1b"", ""us-east-1c"", ""us-east-1d""]\n}\n', 'availability_zone = ""${var.zones[count.index]}""\n']"
500,4329,4320,CC BY-SA 4.0,2018-06-18T14:05:47.187,"<p>So I feel stupid now, but I solved it. I took another look at the error and found <code>Caused by: java.io.IOException: Unable to read /Users/Shared/Jenkins/Home/config-history/nodes/build2/2018-06-13_11-41-13/history.xml
    at hudson.XmlFile.read(XmlFile.java:144)</code></p>

<p>I went to the file and the found that the first row said <code>&lt;?xml version='1.1' encoding='UTF-8'?&gt;</code>. I also noticed that the error message said </p>

<pre><code>Caused by: org.xmlpull.v1.XmlPullParserException: only 1.0 is supported as &lt;?xml version not '1.1' (position: START_DOCUMENT seen &lt;?xml version=\'1.1\'... @1:19) 
    at org.xmlpull.mxp1.MXParser.parseXmlDeclWithVersion(MXParser.java:2608)
</code></pre>

<p>I changed the <code>&lt;?xml version='1.1&gt;</code> to <code>&lt;?xml version='1.0&gt;</code>, saved the file and restarted jenkins using</p>

<pre><code>sudo launchctl stop org.jenkins-ci
sudo launchctl unload /Library/LaunchDaemons/org.jenkins-ci.plist
sudo launchctl load /Library/LaunchDaemons/org.jenkins-ci.plist
</code></pre>
",8374,2018-06-18T14:05:47.187,"[""Caused by: org.xmlpull.v1.XmlPullParserException: only 1.0 is supported as <?xml version not '1.1' (position: START_DOCUMENT seen <?xml version=\\'1.1\\'... @1:19) \n    at org.xmlpull.mxp1.MXParser.parseXmlDeclWithVersion(MXParser.java:2608)\n"", 'sudo launchctl stop org.jenkins-ci\nsudo launchctl unload /Library/LaunchDaemons/org.jenkins-ci.plist\nsudo launchctl load /Library/LaunchDaemons/org.jenkins-ci.plist\n']"
501,4340,4338,CC BY-SA 4.0,2018-06-19T18:44:30.053,"<p>It's deprecated in favor of <em>started</em>.</p>

<pre><code>TASK [Test postfix is running] 
**************************************************************
[DEPRECATION WARNING]: state=running is deprecated. Please use 
state=started. This feature will be removed in version 2.7. 
Deprecation warnings can be disabled by setting 
deprecation_warnings=False in ansible.cfg.
</code></pre>
",7715,2018-06-19T18:44:30.053,['TASK [Test postfix is running] \n**************************************************************\n[DEPRECATION WARNING]: state=running is deprecated. Please use \nstate=started. This feature will be removed in version 2.7. \nDeprecation warnings can be disabled by setting \ndeprecation_warnings=False in ansible.cfg.\n']
502,4346,4341,CC BY-SA 4.0,2018-06-20T17:40:08.930,"<p>You can mix the powerful of <a href=""https://github.com/Miserlou/Zappa"" rel=""nofollow noreferrer"">Zappa</a> and <a href=""https://github.com/timothycrosley/hug"" rel=""nofollow noreferrer"">Hug</a> to convert your code in a serverless <a href=""https://docs.aws.amazon.com/lambda/latest/dg/welcome.html"" rel=""nofollow noreferrer"">AWS Lambda</a> function adding only a decorator to your python process main function</p>

<pre><code>import hug
[...]

@hug.get('/your_endpoint_name')
def your_function_name():
    """"""Here goes your code""""""
    [...]
    return ""Function finished sucesfully""
</code></pre>

<p>After this you can deploy to AWS Lambda with <code>zappa deploy prod</code> and you will only need to call the returned URL twice a month.</p>
",8435,2018-06-20T17:40:08.930,"['import hug\n[...]\n\n@hug.get(\'/your_endpoint_name\')\ndef your_function_name():\n    """"""Here goes your code""""""\n    [...]\n    return ""Function finished sucesfully""\n']"
503,4351,4350,CC BY-SA 4.0,2018-06-21T15:48:58.100,"<p>You should assign a specific port to any containers.<br>
For this configuration you can use <code>docker-compose</code> file such as following example:</p>

<pre><code>version: '3'

services:
  TensorFlow-1:
      image: gcr.io/tensorflow/tensorflow:latest-gpu
      container_name: first-tensor
      ports:
        - ""9001:8888""

  TensorFlow-2:
      image: gcr.io/tensorflow/tensorflow:latest-gpu
      container_name: second-tensor
      ports:
        - ""9002:8888""
</code></pre>

<p>Then in the <code>docker-compose.yml</code> path, on command-line do it:   </p>

<pre><code>sudo docker-compose up
</code></pre>

<p>Or</p>

<pre><code>sudo docker-compose up -d  
</code></pre>

<p><strong>NOTE</strong>: <code>-d</code> option is for run above command in the background.    </p>

<p>Finally you have two tensorflow containers with <code>9001</code> and <code>9002</code> ports.</p>
",7953,2018-06-28T12:06:17.800,"['version: \'3\'\n\nservices:\n  TensorFlow-1:\n      image: gcr.io/tensorflow/tensorflow:latest-gpu\n      container_name: first-tensor\n      ports:\n        - ""9001:8888""\n\n  TensorFlow-2:\n      image: gcr.io/tensorflow/tensorflow:latest-gpu\n      container_name: second-tensor\n      ports:\n        - ""9002:8888""\n', 'sudo docker-compose up\n', 'sudo docker-compose up -d  \n']"
504,4366,4364,CC BY-SA 4.0,2018-06-23T08:21:03.127,"<p>You're not showing how the response example you shown relates to <code>response1</code> (there is no <code>'TagList'</code> in your example). It looks like <code>response1['TagList']</code> is an empty list.</p>

<p>Otherwise you're on the right track (you can always check your exact case directly in the python shell):</p>

<pre><code>$ python
Python 2.7.12 (default, Jul 01 2016, 15:36:53) [GCC] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; response = [{u'Value': '2018-06-21', u'Key': 'Deletion_Date'}]
&gt;&gt;&gt; response[0]
{u'Key': 'Deletion_Date', u'Value': '2018-06-21'}
&gt;&gt;&gt; response[0]['Value']
'2018-06-21'
</code></pre>
",47,2018-06-23T08:21:03.127,"['$ python\nPython 2.7.12 (default, Jul 01 2016, 15:36:53) [GCC] on linux2\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information.\n>>> response = [{u\'Value\': \'2018-06-21\', u\'Key\': \'Deletion_Date\'}]\n>>> response[0]\n{u\'Key\': \'Deletion_Date\', u\'Value\': \'2018-06-21\'}\n>>> response[0][\'Value\']\n\'2018-06-21\'\n']"
505,4396,4393,CC BY-SA 4.0,2018-06-27T13:46:47.543,"<p>Specifically for credentials, CloudBees recommends using the Credentials Plugins, which inject the credentials in the environment available to the invoked scripts. From <a href=""https://support.cloudbees.com/hc/en-us/articles/203802500-Injecting-Secrets-into-Jenkins-Build-Jobs"" rel=""noreferrer"">Injecting Secrets into Jenkins Build Jobs</a>:</p>

<blockquote>
  <ul>
  <li><a href=""https://wiki.jenkins-ci.org/display/JENKINS/Credentials+Plugin"" rel=""noreferrer"">Credentials plugin</a> - provides a centralized way to define credentials that can be used by your Jenkins instance, plugins and
  build jobs.</li>
  <li><a href=""https://wiki.jenkins-ci.org/display/JENKINS/Credentials+Binding+Plugin"" rel=""noreferrer"">Credentials Binding plugin</a> - allows you to configure your build jobs to inject credentials as environment variables.</li>
  <li><a href=""https://wiki.jenkins-ci.org/display/JENKINS/Plain+Credentials+Plugin"" rel=""noreferrer"">Plain Credentials plugin</a> - a plugin dependency required by the Credentials Binding plugin.</li>
  </ul>
</blockquote>

<p>Inside your script you'd pick up the variable from the script's environment:</p>

<pre><code>API_TOKEN = os.getenv('API_TOKEN')
</code></pre>

<p>In a similar way you can pass any arbitrary variables (other than credentials), using the <a href=""https://wiki.jenkins.io/display/JENKINS/EnvInject+Plugin"" rel=""noreferrer"">EnvInject Plugin</a> (watch for the warnings, tho). See related:</p>

<ul>
<li><a href=""https://stackoverflow.com/questions/31203816/jenkins-inject-environment-variable"">Jenkins inject environment variable</a></li>
<li><a href=""https://stackoverflow.com/questions/21130931/environment-variables-in-jenkins"">Environment variables in Jenkins</a></li>
</ul>

<p>Another possible approach is to configure Jenkins to pass the value as an argument to your script. Inside your script you'd pick up the value using your preferred method of processing the script arguments.</p>
",47,2018-06-27T13:46:47.543,"[""API_TOKEN = os.getenv('API_TOKEN')\n""]"
506,4399,4393,CC BY-SA 4.0,2018-06-27T16:08:35.993,"<p>If you are using Pipeline (i.e. Jenkinsfile), use <a href=""https://jenkins.io/doc/pipeline/steps/credentials-binding/"" rel=""nofollow noreferrer""><code>withCredentials</code></a>.  To give a quick and dirty example:</p>

<pre><code>withCredentials([[
  $class: 'UsernamePasswordMultiBinding',
  credentialsId: 'my-credentials',
  usernameVariable: 'user',
  passwordVariable: 'pw',
]]) {
  sh(""./my-python-script.py --user ${user} --password ${pw}"")
}
</code></pre>

<p>Your credentials will be automatically redacted from the console output to help prevent sensitive information from leaking.</p>
",4115,2018-10-03T15:32:40.703,"['withCredentials([[\n  $class: \'UsernamePasswordMultiBinding\',\n  credentialsId: \'my-credentials\',\n  usernameVariable: \'user\',\n  passwordVariable: \'pw\',\n]]) {\n  sh(""./my-python-script.py --user ${user} --password ${pw}"")\n}\n']"
507,4400,986,CC BY-SA 4.0,2018-06-27T16:35:42.250,"<p>I had a similar situation in which I wanted to nest other parallel jobs threads inside another parallel one. This code worked for me:</p>

<pre><code>def performDeploymentStages(String node, String app) {
    stage(""build"") {
        echo ""Building the app [${app}] on node [${node}]""
    }
    stage(""deploy"") {
        echo ""Deploying the app ${app}] on node [${node}]""
    }
    stage(""test"") {
        echo ""Testing the app [${app}] on node [${node}]""
    }
}

pipeline {
    agent {
        label 'master'
    }
    parameters {
        string(name: 'NODES', defaultValue: '1,2,3', description: 'Nodes to build, deploy and test')
        choice(name: 'ENV', choices: 'qa', description: 'Environment')
        string(name: 'APPS', defaultValue: 'app01,app02', description: 'App names')
    }

    stages {
        stage('parallel stage') {
            steps {
                script {
                    def nodes = [:]
                    for (node in params.NODES.tokenize(',')) {
                        def apps = [:]
                        for (app in params.APPS.tokenize(',')) {
                            performDeploymentStages(node, app)
                        }
                        parallel apps
                    }
                    parallel nodes
                }
            }
        }
    }
}
</code></pre>

<p>To fully benefit from parallel run remember to assign enough executors.</p>
",8539,2018-06-27T16:35:42.250,"['def performDeploymentStages(String node, String app) {\n    stage(""build"") {\n        echo ""Building the app [${app}] on node [${node}]""\n    }\n    stage(""deploy"") {\n        echo ""Deploying the app ${app}] on node [${node}]""\n    }\n    stage(""test"") {\n        echo ""Testing the app [${app}] on node [${node}]""\n    }\n}\n\npipeline {\n    agent {\n        label \'master\'\n    }\n    parameters {\n        string(name: \'NODES\', defaultValue: \'1,2,3\', description: \'Nodes to build, deploy and test\')\n        choice(name: \'ENV\', choices: \'qa\', description: \'Environment\')\n        string(name: \'APPS\', defaultValue: \'app01,app02\', description: \'App names\')\n    }\n\n    stages {\n        stage(\'parallel stage\') {\n            steps {\n                script {\n                    def nodes = [:]\n                    for (node in params.NODES.tokenize(\',\')) {\n                        def apps = [:]\n                        for (app in params.APPS.tokenize(\',\')) {\n                            performDeploymentStages(node, app)\n                        }\n                        parallel apps\n                    }\n                    parallel nodes\n                }\n            }\n        }\n    }\n}\n']"
508,4405,4397,CC BY-SA 4.0,2018-06-28T13:22:28.067,"<p>I also could not restore packages after upgrading to 2.1.1. I got multiple errors similar to this:</p>

<pre><code>Detected package version outside of dependency constraint: Microsoft.AspNetCore.App 2.1.0 requires Microsoft.EntityFrameworkCore (= 2.1.0) but version Microsoft.EntityFrameworkCore 2.1.1 was resolved.
</code></pre>

<p>I solved my problem by explicitly <a href=""https://cmatskas.com/working-with-the-latest-net-core-version-in-vsts/"" rel=""nofollow noreferrer"">specifying version 2.1.301</a> in the build definition.</p>
",8555,2018-06-28T13:22:28.067,['Detected package version outside of dependency constraint: Microsoft.AspNetCore.App 2.1.0 requires Microsoft.EntityFrameworkCore (= 2.1.0) but version Microsoft.EntityFrameworkCore 2.1.1 was resolved.\n']
509,4414,4413,CC BY-SA 4.0,2018-06-29T06:13:59.033,"<p>AWS AMIs come with a default username - which username it is depends on the specific AMI that is launched. Amazon Linux AMIs use <code>ec2-user</code>, CentOS uses <code>centos</code>, and there's other combinations too.</p>

<p>If you want to create your own user on instance launch, you can use <a href=""https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html"" rel=""nofollow noreferrer"">EC2 User Data</a> for this, which essentially entails passing a custom script that will be run at launch time.</p>

<p>The <a href=""https://www.terraform.io/docs/providers/aws/r/instance.html#user_data"" rel=""nofollow noreferrer""><code>user_data</code> argument</a> is supported by Terraform's <code>aws_instance</code> resource. You can specify a script inline, but for most cases you'll probably want to use an external file or template.</p>

<p>For example:</p>

<p><strong>create-user.sh</strong>:</p>

<pre><code>#!/usr/bin/env bash

useradd mytestuser

# Anything else you want to do to set up your user account
</code></pre>

<p><strong>main.tf</strong>:</p>

<pre><code>resource ""aws_instance"" ""main"" {
  ...
  user_data = ""${file(""create-user.sh"")}""
}
</code></pre>

<p>Alternatively, there's an example on rendering a template <a href=""http://roshpr.net/blog/2016/10/terraform-using-user-data-in-launch-configuration/"" rel=""nofollow noreferrer"">here</a>, which is useful if you want to pass through custom values rather than just provide a static file.</p>

<p>Or, as an alternative to writing your own shell script, you could try rendering a cloudinit config file using <a href=""https://www.terraform.io/docs/providers/template/d/cloudinit_config.html"" rel=""nofollow noreferrer""><code>template_cloudinit_config</code></a>. Some resources that might be useful for this include <a href=""https://ash.berlintaylor.com/writings/2017/08/reusable-terraform-modules-extending-userdata/"" rel=""nofollow noreferrer"">this blog post</a> and <a href=""http://cloudinit.readthedocs.io/en/latest/topics/examples.html"" rel=""nofollow noreferrer"">this part of the cloudinit documentation</a>.</p>
",249,2018-06-29T06:13:59.033,"['#!/usr/bin/env bash\n\nuseradd mytestuser\n\n# Anything else you want to do to set up your user account\n', 'resource ""aws_instance"" ""main"" {\n  ...\n  user_data = ""${file(""create-user.sh"")}""\n}\n']"
510,4427,4404,CC BY-SA 4.0,2018-07-03T05:36:28.860,"<p>According to <a href=""https://docs.microsoft.com/en-us/vsts/package/overview?view=vsts"" rel=""nofollow noreferrer"">this page</a>, the hosted agent supports NuGet, npm, and Maven.</p>

<p>It looks like it might also support <code>pip</code>.
You could install <code>cget</code> using <code>pip</code> and then use <code>cget</code> to install your package. A bit of a roundabout way, but it might do what you need.</p>

<pre><code>""C:\Program Files\Python36\Scripts\pip"" install cget
cget install nlohmann/json
</code></pre>

<p>I don't have a way to test this right now, but I will try some real examples and edit tomorrow if I have time.</p>

<p>Since it is a CMake/Git project, you could also just clone the repository (or add it as a <a href=""https://git-scm.com/book/en/v2/Git-Tools-Submodules"" rel=""nofollow noreferrer"">submodule</a>) and build it every time. Since I often use libraries that aren't managed, I tend to take this route and leverage the caching that many CI platforms offer to keep my build times low. Sadly, it looks like VSTS hasn't gotten to this <a href=""https://visualstudio.uservoice.com/forums/330519-visual-studio-team-services/suggestions/32044321-improve-hosted-build-agent-performance-with-build"" rel=""nofollow noreferrer"">yet</a>.</p>
",8603,2018-07-03T05:36:28.860,"['""C:\\Program Files\\Python36\\Scripts\\pip"" install cget\ncget install nlohmann/json\n']"
511,4432,4425,CC BY-SA 4.0,2018-07-03T11:04:05.977,"<p>I stumbled across the answer.  From within the profile directory, run this command:</p>

<pre><code>inspec exec .
</code></pre>

<p>Don't forget to set the <code>depends</code> key in <code>inspec.yml</code>.</p>
",8452,2018-07-03T11:04:05.977,['inspec exec .\n']
512,4439,4424,CC BY-SA 4.0,2018-07-04T08:04:35.113,"<p>The problem can be solved by using mount options that force the application of the correct user and group eventhough these attributes can't really be set on the target system its sufficient to get around the docker related problem. </p>

<p>Also a reasonable set of privileges needs to be defined that is used for new files and folders.</p>

<pre><code>mount -t cifs -o username=user,password=pass, \               # provide creds
  uid=www-data,forceuid,gid=root,forcegid, \                  # force gid and uid
  file_mode=744,dir_mode=744 //host/share /local/mountpoint   # set permissions for new files and directories
</code></pre>
",8593,2018-07-04T08:04:35.113,"['mount -t cifs -o username=user,password=pass, \\               # provide creds\n  uid=www-data,forceuid,gid=root,forcegid, \\                  # force gid and uid\n  file_mode=744,dir_mode=744 //host/share /local/mountpoint   # set permissions for new files and directories\n']"
513,4442,4440,CC BY-SA 4.0,2018-07-04T14:16:40.047,"<p>It can be three step process</p>

<ol>
<li><p>Create a playbook with following command -</p>

<pre><code>docker exec mycontainer /bin/sh -c ""cmd1;cmd2;...;cmdn""
</code></pre>

<p>or
Docker file entrypoint option </p>

<pre><code>FROM ubuntu
ENTRYPOINT [""top"", ""-b""]
CMD [""-c""]
</code></pre></li>
<li><p><code>ansible-playbook playbooks/PLAYBOOK_NAME.yml --limit ""mycontainer""</code></p></li>
</ol>
",8627,2018-07-04T15:22:24.840,"['docker exec mycontainer /bin/sh -c ""cmd1;cmd2;...;cmdn""\n', 'FROM ubuntu\nENTRYPOINT [""top"", ""-b""]\nCMD [""-c""]\n']"
514,4444,4440,CC BY-SA 4.0,2018-07-04T19:52:51.877,"<p>With the help of <a href=""https://devops.stackexchange.com/users/4427/levi"">@Levi</a> (refered to <a href=""https://stackoverflow.com/questions/32878795/run-command-inside-of-docker-container-using-ansible/41626257#41626257"">Stackoverflow</a>) I managed to find a way to connect straigt into the docker containers using ansibles docker connection driver and the remote API capability of Docker. </p>

<p>First of all you have to expose the API which is by default not the case. Simply add <code>-H tcp://0.0.0.0:1337</code> to the <code>ExecStart</code> constant of the systemd script. Then reload the start script and restart the docker service. (From <a href=""https://www.ivankrizsan.se/2016/05/18/enabling-docker-remote-api-on-ubuntu-16-04/"" rel=""noreferrer"">this</a> blogpost) </p>

<p>Then you can list the containers in the inventory file like this:</p>

<pre><code>[containers]
container-name ansible_connection=docker ansible_docker_extra_args=""-H tcp://1.2.3.4:1337""
</code></pre>

<p>And execute any playbook like your used to.</p>

<pre><code>ansible-playbook -i docker_inventory playbooks/my_playbook.yml
</code></pre>

<p>The upside of this way of implementing it this way is that you can mix up ""real"" hosts/vms that are maintained through SSH and Docker containers. One negative thing I have to mention is that the docker API is much slower than using SSH as a control tunnel.</p>

<p><strong>This setup is of cause horribly insecure and its only purpose is to explain the concept. Before using it in production you should read into the security features and limit access to the daemon as far as possible.</strong></p>
",8593,2018-07-04T20:03:05.653,"['[containers]\ncontainer-name ansible_connection=docker ansible_docker_extra_args=""-H tcp://1.2.3.4:1337""\n', 'ansible-playbook -i docker_inventory playbooks/my_playbook.yml\n']"
515,4450,4447,CC BY-SA 4.0,2018-07-05T13:35:52.593,"<p>You can build and tag any stage of a multi-stage build. Just use the <a href=""https://docs.docker.com/develop/develop-images/multistage-build/#stop-at-a-specific-build-stage"" rel=""noreferrer""><code>--target</code> option</a> to <code>docker build</code>. E.g.</p>

<pre><code>docker build --target jdk -t myapp-jdk:v1 .
docker build --target jre -t myapp:v1 .
</code></pre>

<p>With the layer caching, the the earlier steps will be reused from the cache and not rerun from scratch each time, so there's little downside to running the build to different targets multiple times.</p>

<p>If you absolutely need to run this from a single build command, you can parse the output of the build, get the image id of the intermediate step, and tag that image id:</p>

<pre><code>docker tag &lt;some_image_id&gt; myapp-jdk:v1
</code></pre>
",7730,2019-02-15T13:12:50.213,"['docker build --target jdk -t myapp-jdk:v1 .\ndocker build --target jre -t myapp:v1 .\n', 'docker tag <some_image_id> myapp-jdk:v1\n']"
516,4486,885,CC BY-SA 4.0,2018-07-10T11:29:46.037,"<p>You can also use error to exit the current stage, then you don't have to consider the current stage hierarchy and similar stuff:</p>

<pre><code>def autoCancelled = false

try {
  stage('checkout') {
    ...
    if (your condition) {
      autoCancelled = true
      error('Aborting the build.')
    }
  }
} catch (e) {
  if (autoCancelled) {
    currentBuild.result = 'SUCCESS'
    // return here instead of throwing error to keep the build ""green""
    return
  }
  // normal error handling
  throw e
}
</code></pre>

<p>But this would lead to a red stage, if the error occurs within a stage.</p>

<p><a href=""https://i.stack.imgur.com/Q9UDp.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Q9UDp.png"" alt=""enter image description here""></a></p>

<p>It depends on your requirements, which way you want to use.</p>
",8714,2018-07-10T11:29:46.037,"['def autoCancelled = false\n\ntry {\n  stage(\'checkout\') {\n    ...\n    if (your condition) {\n      autoCancelled = true\n      error(\'Aborting the build.\')\n    }\n  }\n} catch (e) {\n  if (autoCancelled) {\n    currentBuild.result = \'SUCCESS\'\n    // return here instead of throwing error to keep the build ""green""\n    return\n  }\n  // normal error handling\n  throw e\n}\n']"
517,4497,4034,CC BY-SA 4.0,2018-07-12T05:51:20.030,"<p>you can add role like below </p>

<pre><code>role = ""${aws_iam_role.ec2_role_name.name}""
</code></pre>

<p>Please check - <a href=""https://www.terraform.io/docs/providers/aws/r/iam_instance_profile.html"" rel=""nofollow noreferrer"">https://www.terraform.io/docs/providers/aws/r/iam_instance_profile.html</a></p>
",8744,2018-07-18T04:53:31.757,"['role = ""${aws_iam_role.ec2_role_name.name}""\n']"
518,4505,4503,CC BY-SA 4.0,2018-07-12T18:59:25.010,"<p>The <a href=""https://www.vaultproject.io/docs/commands/read.html"" rel=""nofollow noreferrer"">vault docs</a> mention a <code>-field</code> parameter for the <code>read</code> subcommand.  So you should be able to put this into a shell script:</p>
<pre><code>SECRET=$(vault read -field foo secret/mysecret)
</code></pre>
<p><a href=""https://www.vaultproject.io/intro/getting-started/first-secret.html"" rel=""nofollow noreferrer"">Other vault docs</a> use the <code>vault kv get</code> in the same way so you might try:</p>
<pre><code>SECRET=$(vault kv get -field foo secret/mysecret)
</code></pre>
",739,2021-03-18T13:44:25.500,"['SECRET=$(vault read -field foo secret/mysecret)\n', 'SECRET=$(vault kv get -field foo secret/mysecret)\n']"
519,4518,3999,CC BY-SA 4.0,2018-07-15T19:23:04.923,"<p>Maybe you could use ""count"" attribute for this?</p>

<pre><code>resource ""cloudflare_record"" ""record1"" {
    count = ${aws_instance.instance1.public_ip == """" ? 0 : 1}""
    ...
}
</code></pre>
",8691,2018-07-15T19:23:04.923,"['resource ""cloudflare_record"" ""record1"" {\n    count = ${aws_instance.instance1.public_ip == """" ? 0 : 1}""\n    ...\n}\n']"
520,4519,4516,CC BY-SA 4.0,2018-07-16T08:44:19.543,"<p>Please follow official doc to <a href=""https://docs.saltstack.com/en/2017.7/ref/states/all/salt.states.boto_elb.html"" rel=""nofollow noreferrer"">create LB</a> </p>

<p>Please create a IAM role or mentioned secret and access key as below </p>

<pre><code>elb.keyid: HHTYHLSHDJFJFJFJFJFJFFSVJS
elb.key: basjbsdfbdsfdsjfbkgbsfbdsjfbfdgdfgdfs
</code></pre>

<p>Then Create config for ELB </p>

<pre><code>Ensure myelb ELB exists:
    boto_elb.present:
        - name: myelb
        - region: us-east-1
        - availability_zones:
            - us-east-1a
            - us-east-1c
            - us-east-1d
        - keyid: GKTADJGHEIQSXMKKRBJ08H
        - key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
        - listeners:
            - elb_port: 443
              instance_port: 80
              elb_protocol: HTTPS
              instance_protocol: HTTP
              certificate: 'arn:aws:iam::1111111:server-certificate/mycert'
              policies:
                  - my-ssl-policy
                  - cookie-policy
            - elb_port: 8210
              instance_port: 8210
              elb_protocol: TCP
        - backends:
            - instance_port: 80
              policies:
                  - enable-proxy-protocol
        - health_check:
            target: 'HTTP:80/'
        - attributes:
            cross_zone_load_balancing:
              enabled: true
            access_log:
              enabled: true
              s3_bucket_name: 'mybucket'
              s3_bucket_prefix: 'my-logs'
              emit_interval: 5
            connecting_settings:
              idle_timeout: 60
        - cnames:
            - name: mycname.example.com.
              zone: example.com.
              ttl: 60
            - name: myothercname.example.com.
              zone: example.com.
        - security_groups:
            - my-security-group
        - policies:
            - policy_name: my-ssl-policy
              policy_type: SSLNegotiationPolicyType
              policy:
                Protocol-TLSv1.2: true
                Protocol-SSLv3: false
                Server-Defined-Cipher-Order: true
                ECDHE-ECDSA-AES128-GCM-SHA256: true
            - policy_name: cookie-policy
              policy_type: LBCookieStickinessPolicyType
              policy: {}  # no policy means this is a session cookie
            - policy_name: enable-proxy-protocol
              policy_type: ProxyProtocolPolicyType
              policy:
                ProxyProtocol: true

# Using a profile from pillars
Ensure myelb ELB exists:
    boto_elb.present:
        - name: myelb
        - region: us-east-1
        - profile: myelbprofile

# Passing in a profile
Ensure myelb ELB exists:
    boto_elb.present:
        - name: myelb
        - region: us-east-1
        - profile:
            keyid: GKTADJGHEIQSXMKKRBJ08H
            key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs
</code></pre>

<p>Register instance with ELB. 
<strong>salt.states.boto_elb.register_instances(name, instances, region=None, key=None, keyid=None, profile=None)</strong></p>

<pre><code>add-instances:
  boto_elb.register_instances:
    - name: myloadbalancer
    - instances:
      - instance-id1
      - instance-id2
</code></pre>

<p>You may find <a href=""https://www.opcito.com/improve-your-load-balancer-performance-with-saltstack-and-nginx-2/"" rel=""nofollow noreferrer"">this blog post</a> useful also.</p>
",8744,2018-07-16T09:27:27.527,"['elb.keyid: HHTYHLSHDJFJFJFJFJFJFFSVJS\nelb.key: basjbsdfbdsfdsjfbkgbsfbdsjfbfdgdfgdfs\n', ""Ensure myelb ELB exists:\n    boto_elb.present:\n        - name: myelb\n        - region: us-east-1\n        - availability_zones:\n            - us-east-1a\n            - us-east-1c\n            - us-east-1d\n        - keyid: GKTADJGHEIQSXMKKRBJ08H\n        - key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs\n        - listeners:\n            - elb_port: 443\n              instance_port: 80\n              elb_protocol: HTTPS\n              instance_protocol: HTTP\n              certificate: 'arn:aws:iam::1111111:server-certificate/mycert'\n              policies:\n                  - my-ssl-policy\n                  - cookie-policy\n            - elb_port: 8210\n              instance_port: 8210\n              elb_protocol: TCP\n        - backends:\n            - instance_port: 80\n              policies:\n                  - enable-proxy-protocol\n        - health_check:\n            target: 'HTTP:80/'\n        - attributes:\n            cross_zone_load_balancing:\n              enabled: true\n            access_log:\n              enabled: true\n              s3_bucket_name: 'mybucket'\n              s3_bucket_prefix: 'my-logs'\n              emit_interval: 5\n            connecting_settings:\n              idle_timeout: 60\n        - cnames:\n            - name: mycname.example.com.\n              zone: example.com.\n              ttl: 60\n            - name: myothercname.example.com.\n              zone: example.com.\n        - security_groups:\n            - my-security-group\n        - policies:\n            - policy_name: my-ssl-policy\n              policy_type: SSLNegotiationPolicyType\n              policy:\n                Protocol-TLSv1.2: true\n                Protocol-SSLv3: false\n                Server-Defined-Cipher-Order: true\n                ECDHE-ECDSA-AES128-GCM-SHA256: true\n            - policy_name: cookie-policy\n              policy_type: LBCookieStickinessPolicyType\n              policy: {}  # no policy means this is a session cookie\n            - policy_name: enable-proxy-protocol\n              policy_type: ProxyProtocolPolicyType\n              policy:\n                ProxyProtocol: true\n\n# Using a profile from pillars\nEnsure myelb ELB exists:\n    boto_elb.present:\n        - name: myelb\n        - region: us-east-1\n        - profile: myelbprofile\n\n# Passing in a profile\nEnsure myelb ELB exists:\n    boto_elb.present:\n        - name: myelb\n        - region: us-east-1\n        - profile:\n            keyid: GKTADJGHEIQSXMKKRBJ08H\n            key: askdjghsdfjkghWupUjasdflkdfklgjsdfjajkghs\n"", 'add-instances:\n  boto_elb.register_instances:\n    - name: myloadbalancer\n    - instances:\n      - instance-id1\n      - instance-id2\n']"
521,4522,4514,CC BY-SA 4.0,2018-07-16T13:35:43.713,"<p>Internal Docker networks mean there is no gateway configured to reach the outside internet, you can only reach other containers from that network. In your scenario, none of your networks should have this definition.</p>

<p>Without setting the internal network flag, containers can reach out of the docker host, potentially to the internet if the host has that access. This is one-way access, containers can access the external network, but that external network cannot access the containers.</p>

<p>To access a container from outside of the Docker host, you need to publish the port on the host mapping into the desired container (or service). Publishing ports with the <code>ports</code> section in the <code>docker-compose.yml</code> file is only needed to provide external access, not access between containers. Applications inside containers need to listen on all interfaces (0.0.0.0) for both publishing ports on the host and for container to container communication. However, you can publish ports on a specific interface on the host, e.g.:</p>

<pre><code>ports:
  - '127.0.0.1:8825:8825'
  - '127.0.0.1:8835:8835'
</code></pre>

<p>For container to container communication, it is not necessary to expose or publish the port. All that is needed is a user defined network (which you have) in common between the containers. Then the containers can communicate using Docker's built-in DNS to resolve the service name (e.g. consul and mongo) and the application port inside that container (e.g. consul:8300). To avoid the external network from accessing these containers, do not publish any ports from them.</p>

<p>Side note: from your <code>docker-compose.yml</code>, you should also consider removing <code>container_name</code>, <code>depends_on</code>, and <code>build</code> since they won't work if you try to transition to swarm mode. </p>
",7730,2018-09-16T05:34:22.313,"[""ports:\n  - '127.0.0.1:8825:8825'\n  - '127.0.0.1:8835:8835'\n""]"
522,4524,3757,CC BY-SA 4.0,2018-07-16T19:43:41.930,"<p>Now (July 2018), you should be able to use either</p>

<pre><code>pip install certbot-dns-digitalocean
</code></pre>

<p>or</p>

<pre><code>git clone https://github.com/certbot/certbot.git
cd certbot/certbot-dns-digitalocean/
python setup.py install
</code></pre>

<p>You may need <code>sudo</code> privileges for either.</p>

<p>After installing you may not be able to see the plugin with <code>certbot plugins</code>, but you should be able to <code>certbot certonly --dns-digitalocean</code> just fine.</p>
",8797,2018-07-16T19:43:41.930,"['pip install certbot-dns-digitalocean\n', 'git clone https://github.com/certbot/certbot.git\ncd certbot/certbot-dns-digitalocean/\npython setup.py install\n']"
523,4527,1658,CC BY-SA 4.0,2018-07-17T10:27:55.610,"<p>You can use <a href=""https://docs.ansible.com/ansible/2.5/modules/wait_for_module.html#synopsis"" rel=""nofollow noreferrer"">wait_for</a> module for the same</p>

<p>example quoted from the documentation:</p>

<pre><code>- name: Wait 300 seconds for port 8000 of any IP to close active connections, don't start checking for 10 seconds
  wait_for:
    host: 0.0.0.0
    port: 8000
    delay: 10
    state: drained
</code></pre>
",8806,2018-07-17T11:05:13.383,"[""- name: Wait 300 seconds for port 8000 of any IP to close active connections, don't start checking for 10 seconds\n  wait_for:\n    host: 0.0.0.0\n    port: 8000\n    delay: 10\n    state: drained\n""]"
524,4535,4481,CC BY-SA 4.0,2018-07-18T11:22:45.523,"<p>I managed to fix it. First I disabled and deleted all <code>etcd2</code>-related units. Then I created a new dropin to the <code>etcd-member.service</code> with the following content:</p>

<pre><code>[Service]
Environment=""ETCD_OPTS=--name cluster00 \
  --discovery https://discovery.etcd.io/&lt;MY_ID&gt; \
  --listen-client-urls http://&lt;NODE_IP&gt;:2379,http://127.0.0.1:2379 \
  --listen-peer-urls http://&lt;NODE_IP&gt;:2380 \
  --advertise-client-urls http://&lt;NODE_IP&gt;:2379 \
  --initial-advertise-peer-urls http://&lt;NODE_IP&gt;:2380""
</code></pre>

<p>I generated a new discovery id for the cluster.</p>

<p>Then I teared down the old cluster completely, by deleting all content of <code>/var/lib/etcd/*</code> and the directory <code>/var/lib/etcd2</code> completely and (re-)started the etcd-member service.</p>

<p>Be aware, that I don't have ssl enabled at this point!</p>
",8621,2018-07-18T11:22:45.523,"['[Service]\nEnvironment=""ETCD_OPTS=--name cluster00 \\\n  --discovery https://discovery.etcd.io/<MY_ID> \\\n  --listen-client-urls http://<NODE_IP>:2379,http://127.0.0.1:2379 \\\n  --listen-peer-urls http://<NODE_IP>:2380 \\\n  --advertise-client-urls http://<NODE_IP>:2379 \\\n  --initial-advertise-peer-urls http://<NODE_IP>:2380""\n']"
525,4541,2310,CC BY-SA 4.0,2018-07-19T05:34:05.190,"<p>As I found may be this will helps you. With this you can fetch latest successful build change log file of any project build with Jenkins. </p>

<pre><code>$DirectoryA = ""D:\Jenkins\jobs\projectName\builds""  ####Jenkind directory
$firstfolder = Get-ChildItem -Path $DirectoryA | Where-Object {$_.PSIsContainer} | Sort-Object LastWriteTime -Descending | Select-Object -First 1
$DirectoryB = $DirectoryA + ""\"" + $firstfolder

$sVnLoGfIle = $DirectoryB + ""\"" + ""changelog.xml"" 

write-host $sVnLoGfIle
</code></pre>
",8841,2018-07-19T05:34:05.190,"['$DirectoryA = ""D:\\Jenkins\\jobs\\projectName\\builds""  ####Jenkind directory\n$firstfolder = Get-ChildItem -Path $DirectoryA | Where-Object {$_.PSIsContainer} | Sort-Object LastWriteTime -Descending | Select-Object -First 1\n$DirectoryB = $DirectoryA + ""\\"" + $firstfolder\n\n$sVnLoGfIle = $DirectoryB + ""\\"" + ""changelog.xml"" \n\nwrite-host $sVnLoGfIle\n']"
526,4542,4540,CC BY-SA 4.0,2018-07-19T07:25:55.653,"<p>As stated in the <a href=""https://docs.docker.com/engine/reference/builder/#volume"" rel=""noreferrer"">documentation</a>, VOLUME instruction inherits the directory content and permissions existing in the container, so you can workaround the problem with a dockerfile like this:</p>

<pre><code>FROM ubuntu:xenial
RUN useradd -d /home/ubuntu -ms /bin/bash -g root -G sudo -p ubuntu ubuntu
RUN mkdir /opt/myvolume  &amp;&amp; chown ubuntu /opt/myvolume
WORKDIR /home/ubuntu
VOLUME /opt/myvolume
</code></pre>

<p>The creation of the directory has to be done as root (to be able to write within /opt).</p>
",13,2018-07-19T07:45:26.340,['FROM ubuntu:xenial\nRUN useradd -d /home/ubuntu -ms /bin/bash -g root -G sudo -p ubuntu ubuntu\nRUN mkdir /opt/myvolume  && chown ubuntu /opt/myvolume\nWORKDIR /home/ubuntu\nVOLUME /opt/myvolume\n']
527,4549,4546,CC BY-SA 4.0,2018-07-19T18:46:02.863,"<p>My free tier account uses 30ish GB for in a VM, and I am getting a warning that I am approaching the GB limit (which I am), since day one.</p>

<p>For me, although I'm not a native speaker, the  <a href=""https://aws.amazon.com/free/?awsf.Free%20Tier%20Types=categories%2312monthsfree"" rel=""nofollow noreferrer"">description</a> ...</p>

<pre><code>STORAGE &amp; CONTENT DELIVERY   
Amazon Elastic Block Storage
30 GB

any combination of General Purpose (SSD) or Magnetic

Persistent, durable, low-latency block-level storage volumes for EC2 
instances
</code></pre>

<p>...also seems pretty straightforward: 30 GB for your volumes for your instances. 
Summed up, not ""per"".</p>
",4175,2018-07-19T18:46:02.863,"['STORAGE & CONTENT DELIVERY   \nAmazon Elastic Block Storage\n30 GB\n\nany combination of General Purpose (SSD) or Magnetic\n\nPersistent, durable, low-latency block-level storage volumes for EC2 \ninstances\n']"
528,4563,4557,CC BY-SA 4.0,2018-07-20T18:40:33.387,"<p>Have a look at the documentation presented here:</p>

<p><a href=""https://github.com/jenkinsci/kubernetes-plugin"" rel=""nofollow noreferrer"">https://github.com/jenkinsci/kubernetes-plugin</a></p>

<p>You need to specify a Kubernetes pod in your pipeline. An example of your use case would look similar to this for a single python container. You'll notice that containers: [] expects an array so you can include additional containers.</p>

<pre><code>def label = ""mypod-${UUID.randomUUID().toString()}""

podTemplate(label: label, containers: [
    containerTemplate(name: 'python', image: 'python:3.7-alpine', ttyEnabled: true, command: 'cat'),
]) {
    node(label) {
        stage('Get a Python project') {
            git 'https://github.com/oğuz/project.git'
            container('python') {
                stage('Test a Python project') {
                    sh ""python -m -v py.test TEST_FILE.py ""
                }
            }
        }
    }
}
</code></pre>
",6579,2018-07-20T18:40:33.387,"['def label = ""mypod-${UUID.randomUUID().toString()}""\n\npodTemplate(label: label, containers: [\n    containerTemplate(name: \'python\', image: \'python:3.7-alpine\', ttyEnabled: true, command: \'cat\'),\n]) {\n    node(label) {\n        stage(\'Get a Python project\') {\n            git \'https://github.com/oğuz/project.git\'\n            container(\'python\') {\n                stage(\'Test a Python project\') {\n                    sh ""python -m -v py.test TEST_FILE.py ""\n                }\n            }\n        }\n    }\n}\n']"
529,4592,4590,CC BY-SA 4.0,2018-07-24T14:18:28.630,"<p>You've got a lot of unneeded settings in the compose file, here's a stripped down version that would work just as well:</p>

<pre><code>version: '3.3'
services:
  service-1:
    build: './service-1'
    networks:
      - backend
  service-2:
    build: './service-2'
    ports:
      - '8825:8825'
      - '8835:8835'
    networks:
      - frontend
      - backend
  consul:
    image: 'consul:latest'
    networks:
      - backend
  mongo:
    image: 'mongo:latest'
    networks:
      - backend

networks:
  frontend:
  backend:
    internal: true
</code></pre>

<p>You automatically get the alias of the service name for each container, no need to duplicate that. You also lose the ability to scale a service if you give it a container name. I'd also recommend moving the build step out of the compose file and use an image name for the apps you're building locally.</p>

<hr>

<p>Now for the likely issue, you have a depends_on in your compose file. At best, this will not do what you're looking for. All it checks that the other container has been created and started, but not that the application inside is ready to serve traffic, and a DB may take time to become available. At worst, you'll get an error that it's unsupported if you try to move this into swarm mode.</p>

<p>Instead of depending on docker for this, update your application entrypoint to check for the external dependencies and wait a minute or two for them to become available before failing. A very simple example tool for this is <a href=""https://github.com/vishnubob/wait-for-it"" rel=""nofollow noreferrer"">wait-for-it</a> that is written as a bash shell script.</p>
",7730,2018-07-24T14:18:28.630,"[""version: '3.3'\nservices:\n  service-1:\n    build: './service-1'\n    networks:\n      - backend\n  service-2:\n    build: './service-2'\n    ports:\n      - '8825:8825'\n      - '8835:8835'\n    networks:\n      - frontend\n      - backend\n  consul:\n    image: 'consul:latest'\n    networks:\n      - backend\n  mongo:\n    image: 'mongo:latest'\n    networks:\n      - backend\n\nnetworks:\n  frontend:\n  backend:\n    internal: true\n""]"
530,4614,4609,CC BY-SA 4.0,2018-07-26T14:09:08.313,"<p>This can be done <a href=""https://www.jfrog.com/confluence/display/CLI/CLI+for+JFrog+Artifactory"" rel=""nofollow noreferrer"">through the Jrog CLI</a>. The CLI has a recursive option that looks like it will do what you hope.</p>
<pre><code>jfrog rt upload --recursive artifactory-mirror/* artifact-repo/dir-struct/
</code></pre>
<p>The CLI also has some performance improvements for uploads that doing it through curl or a browser don't seem to get. Also, scriptable!</p>
<p>To include full directory structure you will want to use the flag --flat=false</p>
<pre><code>jfrog rt upload --flat=false --recursive artifactory-mirror/* artifact-repo
</code></pre>
",8983,2020-12-10T17:11:37.440,"['jfrog rt upload --recursive artifactory-mirror/* artifact-repo/dir-struct/\n', 'jfrog rt upload --flat=false --recursive artifactory-mirror/* artifact-repo\n']"
531,4624,4623,CC BY-SA 4.0,2018-07-26T23:15:18.290,"<p>Ok I got the answer after exploring few things and looking at the error more attentively. Here is the way:</p>

<pre><code>aws ec2 authorize-security-group-ingress --group-id sg-07xxxx24d  --protocol tcp --port 22 --source-group sg-d7dyyyy5
</code></pre>
",4883,2018-07-26T23:15:18.290,['aws ec2 authorize-security-group-ingress --group-id sg-07xxxx24d  --protocol tcp --port 22 --source-group sg-d7dyyyy5\n']
532,4625,2115,CC BY-SA 4.0,2018-07-27T03:17:15.333,"<p>Another option is to use the <a href=""https://github.com/cloudposse/terraform-null-label"" rel=""nofollow noreferrer""><code>terraform-null-label</code></a> module. It supports passing a variable called <code>tags</code> as a standard Terraform map. The module then emits an output called <code>tags_as_list_of_maps</code> which contains the tags in the format you want. But an even better reason to use this module is to generate a consistent set of resource names that follow a fixed convention. </p>

<p>For example, you can do this:</p>

<pre><code>module ""example"" {
  source     = ""git::https://github.com/cloudposse/terraform-null-label.git?ref=master""
  namespace  = ""eg""
  stage      = ""prod""
  name       = ""bastion""
  tags       = { 
                 ""BusinessUnit"" = ""XYZ"" 
                 ""Snapshot"" = ""true""
               }
}
</code></pre>

<p>So from your example, we can then write something like this:</p>

<pre><code>resource ""aws_autoscaling_group"" ""instance"" {
  ...
  name = ""${module.example.id}""
  ...
  tags = ""${module.example.tags_as_list_of_maps}""
  ...
}
</code></pre>

<p><strong>NOTE:</strong> I added the <code>name</code> field to show how to generate co</p>
",8995,2018-07-27T03:17:15.333,"['module ""example"" {\n  source     = ""git::https://github.com/cloudposse/terraform-null-label.git?ref=master""\n  namespace  = ""eg""\n  stage      = ""prod""\n  name       = ""bastion""\n  tags       = { \n                 ""BusinessUnit"" = ""XYZ"" \n                 ""Snapshot"" = ""true""\n               }\n}\n', 'resource ""aws_autoscaling_group"" ""instance"" {\n  ...\n  name = ""${module.example.id}""\n  ...\n  tags = ""${module.example.tags_as_list_of_maps}""\n  ...\n}\n']"
533,4627,3408,CC BY-SA 4.0,2018-07-27T04:30:30.983,"<p>The best way to achieve what you're trying to do (generate an openssh public key from an <code>id_rsa</code> private key) is using the <a href=""https://www.terraform.io/docs/providers/tls/d/public_key.html"" rel=""nofollow noreferrer""><code>tls_public_key</code></a> data provider built-in to terraform. Using the <code>external</code> provider should be considered an option of last resort because it introduces dependencies on the local OS which may not be portable. It's like an escape hatch. </p>

<p>You can use it like this:</p>

<pre><code>data ""tls_public_key"" ""example"" {
  private_key_pem = ""${file(""~/.ssh/id_rsa"")}""
}
</code></pre>

<p>Then to get the public key suitable for openssh, you can access</p>

<pre><code>""${data.tls_public_key.example.public_key_openssh}"" 
</code></pre>

<p>Lastly, if you are open to generating a new SSH key pair, you can use the <a href=""https://github.com/cloudposse/terraform-tls-ssh-key-pair"" rel=""nofollow noreferrer""><code>terraform-tls-ssh-key-pair</code></a> module which will write the keys to a new file and exposes a <code>public_key</code> output with the openssh public key.</p>
",8995,2018-07-27T05:06:31.547,"['data ""tls_public_key"" ""example"" {\n  private_key_pem = ""${file(""~/.ssh/id_rsa"")}""\n}\n', '""${data.tls_public_key.example.public_key_openssh}"" \n']"
534,4628,79,CC BY-SA 4.0,2018-07-27T05:03:52.553,"<p>If you're on AWS, then have a look at <a href=""https://aws.amazon.com/blogs/mt/the-right-way-to-store-secrets-using-parameter-store/"" rel=""noreferrer"">""The Right Way to Manage Secrets""</a> by <a href=""https://segment.io"" rel=""noreferrer"">Segment.io</a> on the AWS Blog. We advocate using <a href=""https://github.com/segmentio/chamber"" rel=""noreferrer""><code>chamber</code></a> to all of our customers for managing secrets. It works by leveraging the AWS Systems Manager Parameter Store (SSM) together with KMS keys. This ensures secrets are encrypted at rest (and in transit), secured with IAM, auditable with CloudTrails, and only exposed as environment variables at run-time. </p>

<p>After <a href=""https://docs.cloudposse.com/secrets-management/aws-kms-ssm/"" rel=""noreferrer"">configuring chamber</a> and setting up the KMS key, we write the secrets to the parameter store. </p>

<pre><code>chamber write db TF_VAR_DB_USER foobar
chamber write db TF_VAR_DB_PASS secret
</code></pre>

<p>Then use those secrets when you call terraform.</p>

<pre><code>chamber exec db -- terraform plan
</code></pre>

<p>This assumes you've defined a variable called <code>DB_USER</code> and <code>DB_PASS</code> in your HCL code. </p>

<p>For example, you could add this to <code>variables.tf</code></p>

<pre><code>variable ""DB_USER"" { }
variable ""DB_PASS"" { }
</code></pre>

<p><strong>NOTE:</strong> <code>chamber</code> will always export environment variables in uppercase</p>

<p>We provide a terraform module called <a href=""https://github.com/cloudposse/terraform-aws-kms-key"" rel=""noreferrer""><code>terraform-aws-kms-key</code></a> to make provisioning the KMS key easy. Check out our detailed documentation with examples of how to use <a href=""https://docs.cloudposse.com/tools/chamber/"" rel=""noreferrer""><code>chamber</code></a> with multiple namespaces as well as <a href=""https://docs.cloudposse.com/secrets-management/aws-kms-ssm/"" rel=""noreferrer"">how to use chamber with terraform</a> to manage secrets. See our <a href=""https://github.com/cloudposse/terraform-root-modules/tree/master/aws/chamber"" rel=""noreferrer"">complete reference example</a> for provisioning chamber dependencies. </p>

<p>As for <code>.tfstate</code>, you bring up a really good point about the existence of plain-text secrets in the state file. There's really no way around this. In order for terraform to calculate changes to build a plan, it needs to know the ""before"" and ""after"" state. For this reason, we recommend using an encrypted S3 bucket with mandatory versioning. Use the <a href=""https://github.com/cloudposse/terraform-aws-tfstate-backend"" rel=""noreferrer""><code>terraform-aws-tfstate-backend</code></a> module to provision a bucket and DynamoDB locking table according to best practices. </p>
",8995,2018-07-27T05:03:52.553,"['chamber write db TF_VAR_DB_USER foobar\nchamber write db TF_VAR_DB_PASS secret\n', 'chamber exec db -- terraform plan\n', 'variable ""DB_USER"" { }\nvariable ""DB_PASS"" { }\n']"
535,4646,4644,CC BY-SA 4.0,2018-07-31T16:02:05.033,"<p>The simplest way is to find the icon that scales the application up and click it. In the current UI it's in Project --> Overview --> expand the application info ("">"" icon to the left), --> click ""^"" next to the blue circle to the right. </p>

<p>This gives you a default load-balancing across as many PODs (instances) of the application as your resources and imagination allow.</p>

<p>From the command line, this would scale it to 3 PODs:</p>

<pre><code>oc scale --replicas=3 rc yourapplicationname
</code></pre>

<p>Another way is to deploy the same application with a different name, and then edit the route (Applications --> Routes --> RouteName) that points to it. There should be an option:</p>

<blockquote>
  <p>Alternate Services / Split traffic across multiple services</p>
</blockquote>

<p>This gives you control over how much traffic you want through each version. Good for A/B testing or canary releases.</p>
",8963,2018-07-31T16:02:05.033,['oc scale --replicas=3 rc yourapplicationname\n']
536,4652,4616,CC BY-SA 4.0,2018-08-01T07:00:54.873,"<p>Indeed, this is a pain. I've been fighting with it for the whole day yesterday, but managed to get it working, let's see if our cases are similar enough.</p>

<p>My guess is that the <em>usual</em> <code>aws configure</code> configuration with a MFA ARN + the AWS SDK used to develop <em>kubectl</em> are not entirely compatible: I have two profiles set for this, one that has its <em>mfa_serial_arn</em> and <em>role_arn</em> that works as follows:</p>

<ul>
<li>First <strong>aws</strong> command I type, I get prompted for MFA token </li>
<li>From there onwards, while session is active, I can work without typing in more tokens.</li>
<li><em>kubectl</em> asks for a token EVERY SINGLE TIME.</li>
</ul>

<p>This is bad.</p>

<p>Now, I set a different profile, without any of the above, and I do the following:</p>

<p>```</p>

<pre><code>keys=($(aws sts assume-role --role-arn &lt;ARN_OF_DELEGATED_ROLE&gt; \
   --role-session-name  &lt;RANDOM_UNIQUE_NAME&gt; \
   --serial-number &lt;ARN_OF_MFA_DEVICE&gt;\
   --token-code  \
    --query 'Credentials.[AccessKeyId,SecretAccessKey,SessionToken]' --output text))

# profile used here will be configured in ~/.aws/credentials
export AWS_PROFILE=&lt;PROFILE YOU WANT&gt;

aws configure set aws_access_key_id ${temp_keys[0]}
aws configure set aws_secret_access_key ${temp_keys[1]}
aws configure set aws_session_token ${temp_keys[2]}
</code></pre>

<p>```</p>

<p>This creates a <strong>temporary valid</strong> aws profile, that can be used <strong>BOTH</strong> with the aws cli, and kubectl. </p>
",9045,2018-08-02T06:39:21.657,"[""keys=($(aws sts assume-role --role-arn <ARN_OF_DELEGATED_ROLE> \\\n   --role-session-name  <RANDOM_UNIQUE_NAME> \\\n   --serial-number <ARN_OF_MFA_DEVICE>\\\n   --token-code  \\\n    --query 'Credentials.[AccessKeyId,SecretAccessKey,SessionToken]' --output text))\n\n# profile used here will be configured in ~/.aws/credentials\nexport AWS_PROFILE=<PROFILE YOU WANT>\n\naws configure set aws_access_key_id ${temp_keys[0]}\naws configure set aws_secret_access_key ${temp_keys[1]}\naws configure set aws_session_token ${temp_keys[2]}\n""]"
537,4673,4508,CC BY-SA 4.0,2018-08-02T16:25:32.877,"<p>These are built-in grains, which are collected at minion startup. <a href=""https://github.com/saltstack/salt/tree/develop/salt/grains"" rel=""nofollow noreferrer"">Here's the code</a> responsible for generating them.</p>

<p>You cannot remove them, but you can <a href=""https://docs.saltstack.com/en/latest/topics/grains/index.html"" rel=""nofollow noreferrer"">overwrite them</a>, for example to an empty value in <code>/etc/salt/grains</code>:</p>

<pre><code>osfinger: null
</code></pre>

<p>or with <a href=""https://docs.saltstack.com/en/latest/ref/modules/all/salt.modules.grains.html"" rel=""nofollow noreferrer"">grains execution module</a>: <code>salt minion1 grains.delval osfinger</code>.</p>

<p>Keep in mind that some of the core grains are essential for the correct functioning of salt, e.g. module providers for <code>pkg</code> module rely on them.</p>
",9012,2018-08-02T16:25:32.877,['osfinger: null\n']
538,4677,1937,CC BY-SA 4.0,2018-08-02T23:04:21.397,"<p>I just had a similar issue today, although with another image. </p>

<pre><code>docker {
 image 'node:8'
 args '--tmpfs /.config'
}
</code></pre>

<p>Reference: <a href=""https://docs.docker.com/storage/tmpfs/"" rel=""nofollow noreferrer"">https://docs.docker.com/storage/tmpfs/</a>
This way you shouldn't be worried about any security leaks or files which are present after the container is destroyed inside the jenkins. </p>
",9080,2018-08-02T23:04:21.397,"[""docker {\n image 'node:8'\n args '--tmpfs /.config'\n}\n""]"
539,4679,4678,CC BY-SA 4.0,2018-08-03T06:41:50.907,"<p>It's in the wish list, I think. Quoting from the doc <a href=""https://docs.ansible.com/ansible/latest/plugins/callback/log_plays.html"" rel=""nofollow noreferrer"">log_plays - write playbook output to log file</a></p>

<pre><code>* This callback writes playbook output to a file per host in the /var/log/ansible/hosts directory
* TODO: make this configurable
</code></pre>

<p>IMHO required functionality is not available at the moment. Take a look at the available plugins. ""<a href=""https://docs.ansible.com/ansible/2.6/plugins/callback.html#managing-stdout"" rel=""nofollow noreferrer"">You can only have one plugin</a>"".</p>

<pre><code>ansible-doc -t callback -l
</code></pre>

<p>There is an option to customize a callback. <a href=""https://docs.ansible.com/ansible/2.5/plugins/callback/context_demo.html"" rel=""nofollow noreferrer"">context_demo</a> looks promising.</p>
",7715,2018-08-03T07:57:40.883,"['* This callback writes playbook output to a file per host in the /var/log/ansible/hosts directory\n* TODO: make this configurable\n', 'ansible-doc -t callback -l\n']"
540,4696,4695,CC BY-SA 4.0,2018-08-05T13:57:36.347,"<p>To solve this, you need to include the volume mounts in the containers <a href=""https://cloud.google.com/kubernetes-engine/docs/concepts/volumes#using_volumes"" rel=""nofollow noreferrer"">described here</a>:</p>

<p><strong>Sample Jenkinsfile</strong>:</p>

<pre><code>pipeline {
    agent {
    kubernetes {
      label 'test-pod'
      defaultContainer 'jnlp'
      yaml """"""
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: frontend-test
    image: centos:7
    command:
    - cat
    tty: true
    volumeMounts:
    - mountPath: '/opt/app/shared'
      name: sharedvolume
  - name: backend-test
    image: centos:7
    command:
    - cat
    tty: true   
    volumeMounts:
    - mountPath: '/opt/app/shared'
      name: sharedvolume
  volumes:
  - name: sharedvolume
    emptyDir: {}
""""""
        }
    }
    stages {
        stage('Test Pipeline Configuration') {
            steps {
                container('frontend-test') {
                    sh 'touch /opt/app/shared/test_file'
                }
                container('backend-test') {
                    sh 'ls /opt/app/shared/test_file ; echo $?'
                }
            }
        }
    }
}
</code></pre>

<p><strong>Result</strong>:</p>

<p>This solved the problem.</p>

<pre><code>[Pipeline] podTemplate
[Pipeline] {
[Pipeline] node
Still waiting to schedule task
All nodes of label ‘test-pod’ are offline
Agent test-pod-wv12q-brfxj is provisioned from template Kubernetes Pod Template
Agent specification [Kubernetes Pod Template] (test-pod): 

Running on test-pod-wv12q-brfxj in /home/jenkins/workspace/pipeline-test
[Pipeline] {
[Pipeline] container
[Pipeline] {
[Pipeline] stage
[Pipeline] { (Test Pipeline Configuration)
[Pipeline] container
[Pipeline] {
[Pipeline] sh
[pipeline-test] Running shell script
+ touch /opt/app/shared/test_file
[Pipeline] }
[Pipeline] // container
[Pipeline] container
[Pipeline] {
[Pipeline] sh
[pipeline-test] Running shell script
+ ls /opt/app/shared/test_file
/opt/app/shared/test_file
+ echo 0
0
[Pipeline] }
[Pipeline] // container
[Pipeline] }
[Pipeline] // stage
[Pipeline] }
[Pipeline] // container
[Pipeline] }
[Pipeline] // node
[Pipeline] }
[Pipeline] // podTemplate
[Pipeline] End of Pipeline
Finished: SUCCESS
</code></pre>
",8189,2018-08-05T13:57:36.347,"['pipeline {\n    agent {\n    kubernetes {\n      label \'test-pod\'\n      defaultContainer \'jnlp\'\n      yaml """"""\napiVersion: v1\nkind: Pod\nspec:\n  containers:\n  - name: frontend-test\n    image: centos:7\n    command:\n    - cat\n    tty: true\n    volumeMounts:\n    - mountPath: \'/opt/app/shared\'\n      name: sharedvolume\n  - name: backend-test\n    image: centos:7\n    command:\n    - cat\n    tty: true   \n    volumeMounts:\n    - mountPath: \'/opt/app/shared\'\n      name: sharedvolume\n  volumes:\n  - name: sharedvolume\n    emptyDir: {}\n""""""\n        }\n    }\n    stages {\n        stage(\'Test Pipeline Configuration\') {\n            steps {\n                container(\'frontend-test\') {\n                    sh \'touch /opt/app/shared/test_file\'\n                }\n                container(\'backend-test\') {\n                    sh \'ls /opt/app/shared/test_file ; echo $?\'\n                }\n            }\n        }\n    }\n}\n', '[Pipeline] podTemplate\n[Pipeline] {\n[Pipeline] node\nStill waiting to schedule task\nAll nodes of label ‘test-pod’ are offline\nAgent test-pod-wv12q-brfxj is provisioned from template Kubernetes Pod Template\nAgent specification [Kubernetes Pod Template] (test-pod): \n\nRunning on test-pod-wv12q-brfxj in /home/jenkins/workspace/pipeline-test\n[Pipeline] {\n[Pipeline] container\n[Pipeline] {\n[Pipeline] stage\n[Pipeline] { (Test Pipeline Configuration)\n[Pipeline] container\n[Pipeline] {\n[Pipeline] sh\n[pipeline-test] Running shell script\n+ touch /opt/app/shared/test_file\n[Pipeline] }\n[Pipeline] // container\n[Pipeline] container\n[Pipeline] {\n[Pipeline] sh\n[pipeline-test] Running shell script\n+ ls /opt/app/shared/test_file\n/opt/app/shared/test_file\n+ echo 0\n0\n[Pipeline] }\n[Pipeline] // container\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n[Pipeline] // container\n[Pipeline] }\n[Pipeline] // node\n[Pipeline] }\n[Pipeline] // podTemplate\n[Pipeline] End of Pipeline\nFinished: SUCCESS\n']"
541,4706,4680,CC BY-SA 4.0,2018-08-06T10:43:43.520,"<p>I've just done this and so far it's working well for us. </p>

<p>Basically we use a Jenkinsfile and retrieve the version from the POM  (which is using semantic versioning) and remove the snapshot. </p>

<pre><code>stage('Build Docker Container') {
        steps {
             script {
                pom = readMavenPom file: 'pom.xml'
                pom_version_snapshot = pom.version

                version = pom_version_snapshot.split(""-"")[0]
                echo version

            }
            sh ""docker build -f 'Dockerfile' -t repo/container:${version}-${env.BRANCH_NAME} .""
        }
    }
</code></pre>

<p>We then do a Docker build and use that version to tag the image, which is later deployed to a Kubernetes cluster. </p>
",8332,2018-08-06T10:43:43.520,"['stage(\'Build Docker Container\') {\n        steps {\n             script {\n                pom = readMavenPom file: \'pom.xml\'\n                pom_version_snapshot = pom.version\n\n                version = pom_version_snapshot.split(""-"")[0]\n                echo version\n\n            }\n            sh ""docker build -f \'Dockerfile\' -t repo/container:${version}-${env.BRANCH_NAME} .""\n        }\n    }\n']"
542,4712,4711,CC BY-SA 4.0,2018-08-07T14:43:14.077,"<p>You can use <code>params['IP Address']</code>.</p>

<p>Think of <code>params</code> as a Map containing a key <code>'IP Address'</code>. If the key didn't have a space, then you could use <code>params.IPAddress</code> or <code>params['IPAddress']</code>, but when there's a space, you can only use the latter syntax.</p>

<p>That syntax is also useful when you're computing the key name to look up, and have stored it in a variable:</p>

<pre><code>final String myParam = ""param${i}""
// can't say `params.myParam`
echo ""Value is ${params[myParam]}""
</code></pre>
",8824,2018-08-07T14:43:14.077,"['final String myParam = ""param${i}""\n// can\'t say `params.myParam`\necho ""Value is ${params[myParam]}""\n']"
543,4719,4065,CC BY-SA 4.0,2018-08-08T14:34:50.990,"<p>This blog post covers all of the methods:</p>

<em>excerpt - <a href=""http://toroid.org/ansible-host-patterns"" rel=""nofollow noreferrer"">Host names and patterns in Ansible 2</a></em>

<blockquote>
  <h3>Inventory hostnames</h3>
  
  <p>Ansible 2 requires inventory hostnames to be valid IPv4/IPv6 addresses or hostnames (i.e., x.example.com or x, but not x..example.com or x--). As an extension, it accepts Unicode word characters in hostname labels. Any mistakes result in specific parsing errors, not mysterious failures during execution.</p>
  
  <p>Inventory hostnames may also use alphabetic or numeric ranges to define more than one host. For example, foo[1:3] defines foo1 through foo3, while foo[x:z:2] expands to fox and foz. Addresses may use numeric ranges: 192.0.2.[3:42].</p>
  
  <h3>IPv6 addresses</h3>
  
  <p>A number of problems with the parsing of IPv6 addresses have also been fixed, and their behaviour has been made consistent across the inventory (.ini files) and in playbooks (e.g., in hosts: lines and with add_host).</p>
  
  <p>All of the recommended IPv6 address notations (from spelling out all 128 bits to the various compressed forms) are supported. Addresses with port numbers must be written as [addr]:port. One can also use hexadecimal ranges to define multiple hosts in inventory files, e.g. 9876::[a:f]:2.</p>
  
  <p>A couple of small but necessary bugfixes go hand-in-hand with the parsing changes, and fix problems with passing IPv6 addresses to ssh and to rsync. Taken together, these changes make it possible to use IPv6 in practice with Ansible.</p>
</blockquote>

<p>Therefore patterns such as these IPv6's would be allowed:</p>

<ul>
<li>fully specified 128 bit address</li>
<li>[addr]:port</li>
<li>hexadecimal ranges - 9876::[a:f]:2</li>
<li>various forms of compressing ranges - FF01::[1:6]</li>
</ul>

<p>Simplified examples:</p>

<pre><code># IPv6 Address                                # Simplified Notation
-----------------------------------------     ----------------------------
- FF01:0000:0000:0000:0000:0000:0000:0001     - FF01::1
- 2031:0000:130F:0000:0000:09C0:876A:130B     - 2031:0:130F::9C0:876A:130B
- 0000:0000:0000:0000:0000:0000:0000:0001     - ::1
- FE80:0000:0000:5EFE:0192.0168.0001.0123     - FE80::5EFE:192.168.1.123
- FE80:0000:0000:0000:1585:4868:495F:D521     - FE80::1585:4868:495F:D521
</code></pre>

<h3>References</h3>

<ul>
<li><a href=""https://www.dummies.com/programming/networking/cisco/network-basics-ipv6-address-simplified-notation/"" rel=""nofollow noreferrer"">NETWORK BASICS: IPV6 ADDRESS SIMPLIFIED NOTATION</a></li>
</ul>
",6619,2018-08-09T11:46:54.907,['# IPv6 Address                                # Simplified Notation\n-----------------------------------------     ----------------------------\n- FF01:0000:0000:0000:0000:0000:0000:0001     - FF01::1\n- 2031:0000:130F:0000:0000:09C0:876A:130B     - 2031:0:130F::9C0:876A:130B\n- 0000:0000:0000:0000:0000:0000:0000:0001     - ::1\n- FE80:0000:0000:5EFE:0192.0168.0001.0123     - FE80::5EFE:192.168.1.123\n- FE80:0000:0000:0000:1585:4868:495F:D521     - FE80::1585:4868:495F:D521\n']
544,4726,4723,CC BY-SA 4.0,2018-08-09T07:32:02.987,"<p>Do you need to run it beside a VPN ""OpenVPN service"" ? </p>

<p>I think using below would solve the issue for clearing any unused networks by at least 1 container.</p>

<pre><code>$ docker network prune
</code></pre>
",6223,2018-08-09T07:32:02.987,['$ docker network prune\n']
545,4728,4718,CC BY-SA 4.0,2018-08-09T08:29:02.007,"<p>You can use dns.resolver or dns.rdatatype and update in Python like below: </p>

<pre><code>import dns.resolver
import dns.rdatatype
import dns.update

for i in dns.resolver.query('blah.com', 'TXT').answer.response:
   update.replace(% i , 60, dns.rdatatype.TXT, '"" NEW RECORD""')
</code></pre>
",6223,2018-08-09T08:29:02.007,"['import dns.resolver\nimport dns.rdatatype\nimport dns.update\n\nfor i in dns.resolver.query(\'blah.com\', \'TXT\').answer.response:\n   update.replace(% i , 60, dns.rdatatype.TXT, \'"" NEW RECORD""\')\n']"
546,4740,4739,CC BY-SA 4.0,2018-08-10T06:25:57.073,"<p>Oh! I have search for a while, it's should be like:</p>

<pre><code>docker run -d --name=ak_registry  --restart=always -p 7900:5000   -v /data/.docker:/var/lib/registry    registry
</code></pre>

<p>Used <code>/var/lib/registry</code> instead of <code>/tmp/registry</code></p>
",7146,2018-08-10T06:25:57.073,['docker run -d --name=ak_registry  --restart=always -p 7900:5000   -v /data/.docker:/var/lib/registry    registry\n']
547,4743,4716,CC BY-SA 4.0,2018-08-10T08:46:07.133,"<h3>Firstly</h3>

<p>you should refer to Jinja handling of spaces/newlines. your current template would create new lines, And I think this will confuse <code>sudo</code> and fail syntax validation (IIRC, the right syntax is to add <code>-</code> like: <code>-%}</code> at the for loop, but you should ""play"" and see what happens). To render a template you can do it on your workstation, without running it on actual target machine.</p>

<p>Also, I think creating the template with 1 command at instruction line is more readable:</p>

<pre><code>{% for command in commands %}
%{{group}} ALL=(ALL) NOPASSWD: {{command}}
{% endfor %}
</code></pre>

<h3>Secondly</h3>

<p>I do not recommend to edit existing global files with ansible. Instead create your custom template under <code>/etc/sudoers.d/</code> (like you've mentioned you saw).</p>

<p>This is the right way to do it, because:</p>

<ul>
<li>the system will have all defaults as is.</li>
<li>your template will be far shorter.</li>
<li>if you do mistakes, you would be sure where to look - in your template.</li>
</ul>

<h3>Thirdly</h3>

<p>I think executing <code>which</code> inside <code>sudoers</code> is an original idea, but should not work.</p>
",9207,2019-03-06T17:41:17.493,['{% for command in commands %}\n%{{group}} ALL=(ALL) NOPASSWD: {{command}}\n{% endfor %}\n']
548,4756,4716,CC BY-SA 4.0,2018-08-12T16:54:43.047,"<p><strong>TL;DR:</strong> KISS. Don't use less.</p>

<p>People often make a mistake with ansible by trying to make variable things that don't need to be. Unless there are multiple places where you define the list of commands that support can access, it is perfectly acceptable to just put them in the template create file: </p>

<p><strong>templates/etc/sudoers.d/support1</strong> </p>

<pre><code>Cmnd_Alias LS = /bin/ls
Cmnd_Alias LESS = /bin/cat
Cmnd_Alias DU = /usr/bin/du

%support1 ALL=(ALL) NOPASSWD: LS, LESS, DU
</code></pre>

<p>or even explicitly as you don't reuse the Cmnd_Alias anywhere</p>

<pre><code>%support1 ALL=(ALL) NOPASSWD: /bin/ls
%support1 ALL=(ALL) NOPASSWD: /bin/cat
%support1 ALL=(ALL) NOPASSWD: /usr/bin/du
</code></pre>

<p>And add some task like:</p>

<pre><code>- name: add templates
  template:
    src: {{ item }}
    dest: /{{ item }}
    owner: root
    group: root
    mode: 0640
  with_items:
    - etc/sudoers.d/support1
</code></pre>

<p>You would only use templates instead of files because late on there might be some variable to add to all those or the group name might come from variable if you get another role that creates the groups.</p>

<p>If you need to use variable, the thing you can do is to use a list of hashes like this:</p>

<pre><code>sudoers.support1.commands:
- { alias: ""LS"", path: ""/bin/ls"" }
- { alias: ""DU"", path: ""/usr/bin/du"" }
</code></pre>

<p>Then in the template:</p>

<pre><code>{% for item in sudoers.{{ group }}.commands %}
Cmnd_Alias {{ item.alias }} = {{ item.path }}
{% endfor %}
%{{ group }} ALL=(ALL) NOPASSWD: {{ sudoers.{{ group }}.commands | map(attribute='alias') | join(', ') }}
</code></pre>

<p><strong>It is not safe to use /usr/bin/less</strong></p>

<p>In all this you did not notice much important thing and that is the use of less as viewer. Sadly that is a security hole. You can type '!bash' for invoking bash. And by pressing 'v' you get into editor based on VISUAL, EDITOR or LESSEDIT variables. So you can give them '/bin/cat' and they can always pipe the content into less themselves. Note this is still a security hole as some files in unix are very intentionally restricted for example:</p>

<pre><code>/etc/shadow
/etc/sudoers
/etc/ssh/ssh_host_rsa_key
$HOME/.ssh/id_rsa
</code></pre>
",228,2018-08-13T05:27:06.520,"['Cmnd_Alias LS = /bin/ls\nCmnd_Alias LESS = /bin/cat\nCmnd_Alias DU = /usr/bin/du\n\n%support1 ALL=(ALL) NOPASSWD: LS, LESS, DU\n', '%support1 ALL=(ALL) NOPASSWD: /bin/ls\n%support1 ALL=(ALL) NOPASSWD: /bin/cat\n%support1 ALL=(ALL) NOPASSWD: /usr/bin/du\n', '- name: add templates\n  template:\n    src: {{ item }}\n    dest: /{{ item }}\n    owner: root\n    group: root\n    mode: 0640\n  with_items:\n    - etc/sudoers.d/support1\n', 'sudoers.support1.commands:\n- { alias: ""LS"", path: ""/bin/ls"" }\n- { alias: ""DU"", path: ""/usr/bin/du"" }\n', ""{% for item in sudoers.{{ group }}.commands %}\nCmnd_Alias {{ item.alias }} = {{ item.path }}\n{% endfor %}\n%{{ group }} ALL=(ALL) NOPASSWD: {{ sudoers.{{ group }}.commands | map(attribute='alias') | join(', ') }}\n"", '/etc/shadow\n/etc/sudoers\n/etc/ssh/ssh_host_rsa_key\n$HOME/.ssh/id_rsa\n']"
549,4757,2494,CC BY-SA 4.0,2018-08-13T10:02:16.063,"<p>your token is wrong.</p>

<p>you can get worker token in the manager node:</p>

<pre><code>docker swarm join-token -q worker
</code></pre>

<p>it works for me.</p>

<p><a href=""https://docs.docker.com/engine/reference/commandline/swarm_join/"" rel=""nofollow noreferrer"">https://docs.docker.com/engine/reference/commandline/swarm_join/</a></p>
",9238,2018-08-13T10:02:16.063,['docker swarm join-token -q worker\n']
550,4762,3883,CC BY-SA 4.0,2018-08-14T12:59:59.787,"<p>There are two ways to accomplish this, though one of them was only available recently.</p>

<p>The old-school version, the one you can do as far back as Logstash 1.5, is to pay attention to tags and use conditionals to separate your inputs. Roughly...</p>

<pre><code>input {
  tcp {
    port =&gt; 1525
    codec =&gt; json_lines
    tags =&gt; [ 'tcp' ]
  }
}

input {
  file {
    path =&gt; '/var/log/app.log'
    codec =&gt; 'json'
    tags =&gt; [ 'file' ]
  }
}

output {
  if 'file' in [tags] {
    elasticsearch {
      host =&gt; 'logstash-es'
      index =&gt; 'files'
    }
  }
  if 'tcp' in [tags] {
    elasticsearch {
      host =&gt; 'logstash-es'
      index =&gt; 'tcp'
    }
  }
}
</code></pre>

<p>This results in two inputs that output to two separate outputs. This is all one file, though. Elastic figured out people were muxing pipelines this way, and came up with <a href=""https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html"" rel=""nofollow noreferrer"">a way to do multiple pipelines in separate files</a>.</p>

<pre><code>- pipeline.id: tcp-inputs
  path.config: '/etc/logstash/pipelines/tcp.cfg'
  pipeline.workers: 3
- pipeline.id: file-inputs
  path.config: '/etc/logstash/pipelines/files.cfg'
  pipeline.workers: 2
</code></pre>

<p>This approach is somewhat more maintainable since the pipelines are in separate files, and humans don't have to reason out how the flows work when presented in a single big file. Pipelines are available in Logstash 6.0 and newer.</p>
",8983,2018-08-14T12:59:59.787,"[""input {\n  tcp {\n    port => 1525\n    codec => json_lines\n    tags => [ 'tcp' ]\n  }\n}\n\ninput {\n  file {\n    path => '/var/log/app.log'\n    codec => 'json'\n    tags => [ 'file' ]\n  }\n}\n\noutput {\n  if 'file' in [tags] {\n    elasticsearch {\n      host => 'logstash-es'\n      index => 'files'\n    }\n  }\n  if 'tcp' in [tags] {\n    elasticsearch {\n      host => 'logstash-es'\n      index => 'tcp'\n    }\n  }\n}\n"", ""- pipeline.id: tcp-inputs\n  path.config: '/etc/logstash/pipelines/tcp.cfg'\n  pipeline.workers: 3\n- pipeline.id: file-inputs\n  path.config: '/etc/logstash/pipelines/files.cfg'\n  pipeline.workers: 2\n""]"
551,4781,4322,CC BY-SA 4.0,2018-08-17T17:54:12.353,"<p>You could use AWS ClI for consult availability zones:</p>

<pre><code>aws ec2 describe-availability-zones
</code></pre>

<p>With this result you could prepare a script to take the first result.</p>
",9295,2018-08-18T05:37:21.080,['aws ec2 describe-availability-zones\n']
552,4782,4773,CC BY-SA 4.0,2018-08-17T22:04:18.243,"<p>It will be set after any <code>checkout</code> steps (or derivatives of <code>checkout</code> such as <code>git</code> or <code>svn</code>).</p>

<p>So for instance:</p>

<pre><code>println(currentBuild.changeSets) // should print an empty set

checkout(scm)

println(currentBuild.changeSets) // should print out any changes in the current build
</code></pre>
",4115,2018-08-17T22:04:18.243,['println(currentBuild.changeSets) // should print an empty set\n\ncheckout(scm)\n\nprintln(currentBuild.changeSets) // should print out any changes in the current build\n']
553,4789,1237,CC BY-SA 4.0,2018-08-20T01:15:42.833,"<p>If you want to have a preformatted block within a list, indent by eight spaces:</p>

<ol>
<li><p>generate public/private key</p>

<pre><code>cd vagrant-home
ssh-keygen // just pressed enter
copy ~/.ssh/id_rsa .
copy ~/.ssh/id_rsa.pub .
</code></pre></li>
<li><p>edit Vagrantfile,add follow lines:
        config.vm.provision ""file"", source: ""id_rsa"", destination: ""/home/vagrant/.ssh/id_rsa""</p>

<pre><code>    public_key = File.read(""id_rsa.pub"")
    config.vm.provision ""shell"", inline: &lt;&lt;-SCRIPT
        chmod 600 /home/vagrant/.ssh/is_rsa
        echo 'Copying ansible-vm public SSH Keys to the VM'
        #mkdir -p /home/vagrant/.ssh
        chmod 700 /home/vagrant/.ssh
        echo '#{public_key}' &gt;&gt; /home/vagrant/.ssh/authorized_keys
        chmod -R 600 /home/vagrant/.ssh/authorized_keys
        echo 'Host 192.168.*.*' &gt;&gt; /home/vagrant/.ssh/config
        echo 'StrictHostKeyChecking no' &gt;&gt; /home/vagrant/.ssh/config
        echo 'UserKnownHostsFile /dev/null' &gt;&gt; /home/vagrant/.ssh/config
        chmod -R 600 /home/vagrant/.ssh/config
        SCRIPT
</code></pre></li>
<li><pre><code>        vagrant up // or vagrant reload --provision
</code></pre></li>
</ol>
",9314,2018-08-20T01:32:04.173,"['cd vagrant-home\nssh-keygen // just pressed enter\ncopy ~/.ssh/id_rsa .\ncopy ~/.ssh/id_rsa.pub .\n', '    public_key = File.read(""id_rsa.pub"")\n    config.vm.provision ""shell"", inline: <<-SCRIPT\n        chmod 600 /home/vagrant/.ssh/is_rsa\n        echo \'Copying ansible-vm public SSH Keys to the VM\'\n        #mkdir -p /home/vagrant/.ssh\n        chmod 700 /home/vagrant/.ssh\n        echo \'#{public_key}\' >> /home/vagrant/.ssh/authorized_keys\n        chmod -R 600 /home/vagrant/.ssh/authorized_keys\n        echo \'Host 192.168.*.*\' >> /home/vagrant/.ssh/config\n        echo \'StrictHostKeyChecking no\' >> /home/vagrant/.ssh/config\n        echo \'UserKnownHostsFile /dev/null\' >> /home/vagrant/.ssh/config\n        chmod -R 600 /home/vagrant/.ssh/config\n        SCRIPT\n', '        vagrant up // or vagrant reload --provision\n']"
554,4801,4799,CC BY-SA 4.0,2018-08-21T09:23:58.100,"<p>You can run the history command to see the different layers of your container</p>

<pre><code>docker history samplecontainer
</code></pre>

<p>On the result you can see the image id of each layer</p>
",6775,2018-08-21T09:23:58.100,['docker history samplecontainer\n']
555,4809,4806,CC BY-SA 4.0,2018-08-22T05:23:22.460,"<p>Regarding to <a href=""https://neo4j.com/developer/docker/"" rel=""nofollow noreferrer"">Neo4j with Docker</a> and <a href=""https://neo4j.com/docs/operations-manual/current/installation/docker/"" rel=""nofollow noreferrer"">Insallation: Docker</a></p>

<blockquote>
  <p>/data to allow the database to be persisted outside its container.</p>
  
  <p>/logs to allow access to Neo4j log files.</p>
</blockquote>

<p>I understand that we should mount the <code>/data</code> to the host machine so that the new password is persisted as the following example.</p>

<pre class=""lang-none prettyprint-override""><code>docker run \
    --publish=7474:7474 --publish=7687:7687 \
    --volume=/path/to/neo4j/data:/data \
    --volume=/path/to/neo4j/logs:/logs \
    neo4j:latest
</code></pre>

<p>Note, the <code>/path/to/neo4j</code> is a physical directory on the host machine.</p>

<h3>Edit1</h3>

<p>To set password, the <a href=""https://neo4j.com/docs/operations-manual/current/installation/docker/"" rel=""nofollow noreferrer"">Insallation: Docker</a> mentions as</p>

<blockquote>
  <p>By default Neo4j requires authentication and requires you to login with <code>neo4j/neo4j</code> at the first connection and set a new password. </p>
  
  <p>You can set the password for the Docker container directly by specifying <code>--env NEO4J_AUTH=neo4j/&lt;password&gt;</code> in your run directive. Alternatively, you can disable authentication by specifying <code>--env NEO4J_AUTH=none</code> instead.</p>
</blockquote>

<p>Then the docker run should be</p>

<pre class=""lang-none prettyprint-override""><code>docker run \
    --publish=7474:7474 --publish=7687:7687 \
    --env NEO4J_AUTH=neo4j/&lt;password&gt; \
    --volume=/path/to/neo4j/data:/data \
    --volume=/path/to/neo4j/logs:/logs \
    neo4j:latest
</code></pre>

<p>Anyhow for the <code>/data</code>, I only achieve with mounting it to the host machine.</p>
",9355,2018-08-22T07:21:21.473,"['docker run \\\n    --publish=7474:7474 --publish=7687:7687 \\\n    --volume=/path/to/neo4j/data:/data \\\n    --volume=/path/to/neo4j/logs:/logs \\\n    neo4j:latest\n', 'docker run \\\n    --publish=7474:7474 --publish=7687:7687 \\\n    --env NEO4J_AUTH=neo4j/<password> \\\n    --volume=/path/to/neo4j/data:/data \\\n    --volume=/path/to/neo4j/logs:/logs \\\n    neo4j:latest\n']"
556,4827,4784,CC BY-SA 4.0,2018-08-23T13:50:43.643,"<p>According to this <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html?highlight=hosts%20yml#how-to-differentiate-staging-vs-production"" rel=""nofollow noreferrer"">best practices post</a>, your file will look like this</p>

<p>file: <code>test</code></p>

<pre><code>[webservers]
web1
web2
web3

[mysqlservers]
db1
db2
db3

[lamp]
lamp1
lamp2
lamp3

[misc]
host1
host2

[all:children]
misc
webservers
mysqlservers
lamp

[webservers:children]
lamp

[mysqlservers:children]
lamp
</code></pre>

<p>You can analyse your file by using <code>ansible-inventory</code>:</p>

<pre><code>ansible-inventory --inventory-file=./test --list
</code></pre>

<p><strong>output:</strong></p>

<pre><code>{
    ""_meta"": {
        ""hostvars"": {
            ""db1"": {},
            ""db2"": {},
            ""db3"": {},
            ""host1"": {},
            ""host2"": {},
            ""lamp1"": {},
            ""lamp2"": {},
            ""lamp3"": {},
            ""web1"": {},
            ""web2"": {},
            ""web3"": {}
        }
    },
    ""all"": {
        ""children"": [
            ""lamp"",
            ""misc"",
            ""mysqlservers"",
            ""ungrouped"",
            ""webservers""
        ]
    },
    ""lamp"": {
        ""hosts"": [
            ""lamp1"",
            ""lamp2"",
            ""lamp3""
        ]
    },
    ""misc"": {
        ""hosts"": [
            ""host1"",
            ""host2""
        ]
    },
    ""mysqlservers"": {
        ""children"": [
            ""lamp""
        ],
        ""hosts"": [
            ""db1"",
            ""db2"",
            ""db3""
        ]
    },
    ""ungrouped"": {},
    ""webservers"": {
        ""children"": [
            ""lamp""
        ],
        ""hosts"": [
            ""web1"",
            ""web2"",
            ""web3""
        ]
    }
}
</code></pre>
",4817,2018-08-23T13:50:43.643,"['[webservers]\nweb1\nweb2\nweb3\n\n[mysqlservers]\ndb1\ndb2\ndb3\n\n[lamp]\nlamp1\nlamp2\nlamp3\n\n[misc]\nhost1\nhost2\n\n[all:children]\nmisc\nwebservers\nmysqlservers\nlamp\n\n[webservers:children]\nlamp\n\n[mysqlservers:children]\nlamp\n', 'ansible-inventory --inventory-file=./test --list\n', '{\n    ""_meta"": {\n        ""hostvars"": {\n            ""db1"": {},\n            ""db2"": {},\n            ""db3"": {},\n            ""host1"": {},\n            ""host2"": {},\n            ""lamp1"": {},\n            ""lamp2"": {},\n            ""lamp3"": {},\n            ""web1"": {},\n            ""web2"": {},\n            ""web3"": {}\n        }\n    },\n    ""all"": {\n        ""children"": [\n            ""lamp"",\n            ""misc"",\n            ""mysqlservers"",\n            ""ungrouped"",\n            ""webservers""\n        ]\n    },\n    ""lamp"": {\n        ""hosts"": [\n            ""lamp1"",\n            ""lamp2"",\n            ""lamp3""\n        ]\n    },\n    ""misc"": {\n        ""hosts"": [\n            ""host1"",\n            ""host2""\n        ]\n    },\n    ""mysqlservers"": {\n        ""children"": [\n            ""lamp""\n        ],\n        ""hosts"": [\n            ""db1"",\n            ""db2"",\n            ""db3""\n        ]\n    },\n    ""ungrouped"": {},\n    ""webservers"": {\n        ""children"": [\n            ""lamp""\n        ],\n        ""hosts"": [\n            ""web1"",\n            ""web2"",\n            ""web3""\n        ]\n    }\n}\n']"
557,4829,3715,CC BY-SA 4.0,2018-08-23T14:17:25.577,"<p>This is most likely a problem with the django configuration better fitting to stackoverflow, and not so much a devops problem.</p>

<p>Check the <code>settings.py</code> for the following entries:</p>

<pre><code>INSTALLED_APPS = [
    (...)
    'django.contrib.staticfiles',
]
</code></pre>

<p>At the end of this file</p>

<pre><code>STATIC_ROOT='staticfiles'
STATIC_URL = '/static/'
STATICFILES_DIRS = [
     os.path.join(BASE_DIR, 'static'),
]
</code></pre>

<p>source <strong>Django manual:</strong> <a href=""https://docs.djangoproject.com/en/2.0/howto/static-files/"" rel=""nofollow noreferrer"">How to static-files</a></p>
",4817,2018-08-23T14:17:25.577,"[""INSTALLED_APPS = [\n    (...)\n    'django.contrib.staticfiles',\n]\n"", ""STATIC_ROOT='staticfiles'\nSTATIC_URL = '/static/'\nSTATICFILES_DIRS = [\n     os.path.join(BASE_DIR, 'static'),\n]\n""]"
558,4833,1193,CC BY-SA 4.0,2018-08-24T02:38:48.573,"<p>You need run entrypoint like as:</p>

<pre><code>FROM microsoft/aspnetcore:1.1.1
...

ENTRYPOINT [""dotnet"", ""netcoreApp.dll""]
</code></pre>
",9398,2018-08-24T02:38:48.573,"['FROM microsoft/aspnetcore:1.1.1\n...\n\nENTRYPOINT [""dotnet"", ""netcoreApp.dll""]\n']"
559,4836,4830,CC BY-SA 4.0,2018-08-24T17:21:23.117,"<h2>Orchestration Timers</h2>

<p>Regardless of the internal implementation, there is most likely an orchestrator that starts and stops a timer based on particular signals or events within the Fargate service. Basically, the charges are from when the pull command are executed until an orchestration process issues or receives the termination command/signal for your process. Conceptually, think of it as similar to wrapping a shell script in <code>time { :; }</code>.</p>

<p>Again conceptually, you might think of the way it charges as the following pseudocode:</p>

<pre><code>cpu_charges = $num_cpus * cpu_rate_per_second
mem_charges = $mem_size * mem_rate_per_second
charge_rate = cpu_charges + mem_charges

elapsed_time = time () {
    docker pull foo_image
    docker run --cpus $num_cpus -m $mem_size -it --rm foo_image
}

bill_for elapsed_time * charge_rate
</code></pre>

<p>I am not currently aware of any public documentation that exposes the <em>real</em> mechanics of how this is internally implemented by AWS, but this is likely accurate enough for most practical purposes.</p>
",549,2018-08-24T17:21:23.117,['cpu_charges = $num_cpus * cpu_rate_per_second\nmem_charges = $mem_size * mem_rate_per_second\ncharge_rate = cpu_charges + mem_charges\n\nelapsed_time = time () {\n    docker pull foo_image\n    docker run --cpus $num_cpus -m $mem_size -it --rm foo_image\n}\n\nbill_for elapsed_time * charge_rate\n']
560,4844,457,CC BY-SA 4.0,2018-08-25T14:31:55.210,"<p>If you need to trigger a job from CLI and wait for its completion you can use ""Jenkins CLI"" (see <a href=""https://support.cloudbees.com/hc/en-us/articles/228392127-How-to-wait-for-build-to-finish-when-triggering-from-CLI-"" rel=""nofollow noreferrer"">here</a>).</p>

<p>However jenkins CLI does not support promotions so for them I came up with the following script:</p>

<pre><code>#!/bin/bash
# Trigger a promotion and wait for its completion
#
# For triggering jobs jenkins cli is sufficient: https://support.cloudbees.com/hc/en-us/articles/228392127-How-to-wait-for-build-to-finish-when-triggering-from-CLI-
#
# The script is dependent on the current jenkins implementation of:
# - the promotion web page (links for triggering/re-executing the promotions)
# - the behaviour of the XML of the promotion status
#
# The behaviour of the job run status XML is:
#   - if the the promotion is not yet been triggered than the response is 404 not found
#   - is the the promotion has been triggered
#     - ... but it's still waiting for an executor:  the response is 404 not found or &lt;duration&gt; is empty
#     - ... and has started:                         &lt;duration&gt; is empty or 0
#     - ... and it's finished:                       &lt;duration&gt; is a non-zero number
#
#
#  run syntax:
#    ./trigger_promotion_and_wait_for_completion.sh \
#       &lt;job_name&gt; \
#       &lt;job_run_number_to_promote&gt; \
#       &lt;promotion_name&gt; \
#       &lt;jenkins_user&gt; \
#       &lt;jenkins_pwd&gt; \
#       &lt;jenkins_url&gt; \
#       &lt;script_workspace_folder&gt; \
#       '{""name"": ""prom_param_1"", ""value"": ""stringvalue"" } , {""name"": ""prom_param_2"", ""value"": true }'
#
#   example:
#    ./trigger_promotion_and_wait_for_completion.sh \
#       job1 \
#       22 \
#       promotion1 \
#       admin \
#       password \
#       http://localhost:8080/jenkins/ \
#       . \
#       '{""name"": ""prom_param_1"", ""value"": ""stringvalue"" } , {""name"": ""prom_param_2"", ""value"": true }'



set -uexo pipefail

#other debug options:
#PS4='+\t '
#set -v

JOB_NAME=""${1}""
JOB_RUN_NUMBER=""${2}""
DEPLOY_PROMOTION_NAME=""${3}""
BUILDER_USER=""${4}""
BUILDER_PASSWORD=""${5}""
JENKINS_URL=""${6}""
WORKSPACE_FOLDER=""${7}""
PROMOTION_ARGUMENTS=""${8}""

TIMEOUT=900


echo ""retrieving the promotion nextBuildNumber (so we can poll the promotion status and check if it's finished)...""
PROMOTION_RUN_NUMBER=""$( curl -s  -u${BUILDER_USER}:${BUILDER_PASSWORD} ""${JENKINS_URL}job/${JOB_NAME}/promotion/process/${DEPLOY_PROMOTION_NAME}/api/xml""  | grep -P  '&lt;nextBuildNumber&gt;(.*)&lt;/nextBuildNumber'   | sed -re 's/.*&lt;nextBuildNumber&gt;(.*)&lt;\/nextBuildNumber.*/\1/g' )""




echo ""running the promotion...""
echo 'only the first promotion can be triggered with ""Approve"", while subsequent promotions are triggered with ""Re-execute promotion""'
echo 'so we check in the web page if the approve link is present'

#the link to search in the web page
PROMOTION_APPROVE_STRING=""promotionProcess/${DEPLOY_PROMOTION_NAME}/promotionCondition/hudson.plugins.promoted_builds.conditions.ManualCondition/approve""

PROM_STATUS_URL=""${JENKINS_URL}job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/""

if curl -s -vvv -u${BUILDER_USER}:${BUILDER_PASSWORD}  ""${PROM_STATUS_URL}"" | grep ""${PROMOTION_APPROVE_STRING}"" ; then
    echo ""The job has not yet been promoted, triggering it with 'Approve'""
    WEB_PATH=""job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/promotionProcess/${DEPLOY_PROMOTION_NAME}/promotionCondition/hudson.plugins.promoted_builds.conditions.ManualCondition/approve""
    SUBMIT=""Approve""
else
    echo ""The job has already been promoted, triggering it with 'Re-execute promotion'""
    WEB_PATH=""job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/${DEPLOY_PROMOTION_NAME}/build""
    SUBMIT=""Re-execute+promotion""
fi


#note for the troubleshooting: in case the following curl fails then the error cause can be found near the string ""stack trace""
CURL_OUTPUT=""$(  curl -s -vvv -XPOST -u${BUILDER_USER}:${BUILDER_PASSWORD} ""${JENKINS_URL}${WEB_PATH}""  \
                       --data 'json={
                                 ""parameter"": [
                                                '""${PROMOTION_ARGUMENTS}""'
                                              ]
                                    }&amp;Submit='""${SUBMIT}"" 2&gt;&amp;1 )""

if ( echo ""${CURL_OUTPUT}"" |  grep -P ""&lt; HTTP/1.1 5\d\d"" ) || ( echo ""${CURL_OUTPUT}"" |  grep -P ""&lt; HTTP/1.1 4\d\d"" ) ; then
  echo  'error in triggering the job/promotion! exiting...'
  exit 1
else
  echo  'curl good'
fi



echo ""checking promotion status until promotion is finished""
FINISHED=no


INITIAL_TIME=""$(date +%s)""
while [ ""${FINISHED}"" != ""ok"" ]
do
    sleep 2


    #checking if promotion is finished (we check the value of &lt;duration&gt; XML element in the job run status)
    ERROR="""" ; DURATION=""$(curl -s  -u${BUILDER_USER}:${BUILDER_PASSWORD} ""${JENKINS_URL}job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/${DEPLOY_PROMOTION_NAME}/promotionBuild/${PROMOTION_RUN_NUMBER}/api/xml""    | grep -Po  '&lt;duration&gt;.*&lt;/duration&gt;'   | sed -re  's/&lt;duration&gt;(.*)&lt;\/duration&gt;/\1/g' )""   || ERROR=""yes""
    if [[ $ERROR == ""yes"" ]] ; then
      echo "" the promotion has been queued but not yet started, waiting for it to start...""
      curl -s  -u${BUILDER_USER}:${BUILDER_PASSWORD} ""${JENKINS_URL}job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/${DEPLOY_PROMOTION_NAME}/promotionBuild/${PROMOTION_RUN_NUMBER}/api/xml""
      ERROR=""""
      continue
    fi  ;   ERROR=""""




    #we interrupt the polling of the job/promotion status if the promotion
    #  - is terminated
    #  - is taking too long (there is some problem)
    #(in the XML of the job run status the &lt;duration&gt; XML element value is initially empty, than it is 0, and eventually is the number of seconds of the run duration )

    POLLING_TIME=""$(date +%s)""
    let ""ELAPSED_TIME=POLLING_TIME-INITIAL_TIME""
    echo ""ELAPSED_TIME=${ELAPSED_TIME}""

    if  (( ${ELAPSED_TIME} \&gt; $TIMEOUT ))  ; then
      echo ""error: the promotion has taken too long... exiting""
      exit 1
    fi

    if  [[ ""${DURATION}"" != """" ]] ; then
      re='^[0-9]+$'
      if [[ $DURATION =~ $re ]] ; then
        if (( ""${DURATION}"" \&gt; ""0"" )) ; then
          FINISHED=ok
        else
          : #do nothing (the value of &lt;duration&gt; is 0 , that is the job/promotion has been started in a slave and is still running)
        fi
      else
        echo ""error: the promotion duration is not a number. exiting...""
        exit 1
      fi
    else
      :  # the job/promotion has not yet started
    fi

    echo ""waiting for the promotion to finish...""
done

echo ""Promotion finished""



echo ""Promotion output:""
curl -s  -u${BUILDER_USER}:${BUILDER_PASSWORD} ""${JENKINS_URL}job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/${DEPLOY_PROMOTION_NAME}/promotionBuild/${PROMOTION_RUN_NUMBER}/consoleText"" &gt; ${WORKSPACE_FOLDER}/promotionOutput

cat ${WORKSPACE_FOLDER}/promotionOutput

if [[ ! ""$(tail -n1 ${WORKSPACE_FOLDER}/promotionOutput)"" =~ ""SUCCESS""  ]] ; then
      echo ""Promotion did not successfully terminate""
      exit 1
else
      echo ""Promotion successfully terminated""
fi
</code></pre>
",9423,2018-08-25T14:37:02.980,"['#!/bin/bash\n# Trigger a promotion and wait for its completion\n#\n# For triggering jobs jenkins cli is sufficient: https://support.cloudbees.com/hc/en-us/articles/228392127-How-to-wait-for-build-to-finish-when-triggering-from-CLI-\n#\n# The script is dependent on the current jenkins implementation of:\n# - the promotion web page (links for triggering/re-executing the promotions)\n# - the behaviour of the XML of the promotion status\n#\n# The behaviour of the job run status XML is:\n#   - if the the promotion is not yet been triggered than the response is 404 not found\n#   - is the the promotion has been triggered\n#     - ... but it\'s still waiting for an executor:  the response is 404 not found or <duration> is empty\n#     - ... and has started:                         <duration> is empty or 0\n#     - ... and it\'s finished:                       <duration> is a non-zero number\n#\n#\n#  run syntax:\n#    ./trigger_promotion_and_wait_for_completion.sh \\\n#       <job_name> \\\n#       <job_run_number_to_promote> \\\n#       <promotion_name> \\\n#       <jenkins_user> \\\n#       <jenkins_pwd> \\\n#       <jenkins_url> \\\n#       <script_workspace_folder> \\\n#       \'{""name"": ""prom_param_1"", ""value"": ""stringvalue"" } , {""name"": ""prom_param_2"", ""value"": true }\'\n#\n#   example:\n#    ./trigger_promotion_and_wait_for_completion.sh \\\n#       job1 \\\n#       22 \\\n#       promotion1 \\\n#       admin \\\n#       password \\\n#       http://localhost:8080/jenkins/ \\\n#       . \\\n#       \'{""name"": ""prom_param_1"", ""value"": ""stringvalue"" } , {""name"": ""prom_param_2"", ""value"": true }\'\n\n\n\nset -uexo pipefail\n\n#other debug options:\n#PS4=\'+\\t \'\n#set -v\n\nJOB_NAME=""${1}""\nJOB_RUN_NUMBER=""${2}""\nDEPLOY_PROMOTION_NAME=""${3}""\nBUILDER_USER=""${4}""\nBUILDER_PASSWORD=""${5}""\nJENKINS_URL=""${6}""\nWORKSPACE_FOLDER=""${7}""\nPROMOTION_ARGUMENTS=""${8}""\n\nTIMEOUT=900\n\n\necho ""retrieving the promotion nextBuildNumber (so we can poll the promotion status and check if it\'s finished)...""\nPROMOTION_RUN_NUMBER=""$( curl -s  -u${BUILDER_USER}:${BUILDER_PASSWORD} ""${JENKINS_URL}job/${JOB_NAME}/promotion/process/${DEPLOY_PROMOTION_NAME}/api/xml""  | grep -P  \'<nextBuildNumber>(.*)</nextBuildNumber\'   | sed -re \'s/.*<nextBuildNumber>(.*)<\\/nextBuildNumber.*/\\1/g\' )""\n\n\n\n\necho ""running the promotion...""\necho \'only the first promotion can be triggered with ""Approve"", while subsequent promotions are triggered with ""Re-execute promotion""\'\necho \'so we check in the web page if the approve link is present\'\n\n#the link to search in the web page\nPROMOTION_APPROVE_STRING=""promotionProcess/${DEPLOY_PROMOTION_NAME}/promotionCondition/hudson.plugins.promoted_builds.conditions.ManualCondition/approve""\n\nPROM_STATUS_URL=""${JENKINS_URL}job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/""\n\nif curl -s -vvv -u${BUILDER_USER}:${BUILDER_PASSWORD}  ""${PROM_STATUS_URL}"" | grep ""${PROMOTION_APPROVE_STRING}"" ; then\n    echo ""The job has not yet been promoted, triggering it with \'Approve\'""\n    WEB_PATH=""job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/promotionProcess/${DEPLOY_PROMOTION_NAME}/promotionCondition/hudson.plugins.promoted_builds.conditions.ManualCondition/approve""\n    SUBMIT=""Approve""\nelse\n    echo ""The job has already been promoted, triggering it with \'Re-execute promotion\'""\n    WEB_PATH=""job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/${DEPLOY_PROMOTION_NAME}/build""\n    SUBMIT=""Re-execute+promotion""\nfi\n\n\n#note for the troubleshooting: in case the following curl fails then the error cause can be found near the string ""stack trace""\nCURL_OUTPUT=""$(  curl -s -vvv -XPOST -u${BUILDER_USER}:${BUILDER_PASSWORD} ""${JENKINS_URL}${WEB_PATH}""  \\\n                       --data \'json={\n                                 ""parameter"": [\n                                                \'""${PROMOTION_ARGUMENTS}""\'\n                                              ]\n                                    }&Submit=\'""${SUBMIT}"" 2>&1 )""\n\nif ( echo ""${CURL_OUTPUT}"" |  grep -P ""< HTTP/1.1 5\\d\\d"" ) || ( echo ""${CURL_OUTPUT}"" |  grep -P ""< HTTP/1.1 4\\d\\d"" ) ; then\n  echo  \'error in triggering the job/promotion! exiting...\'\n  exit 1\nelse\n  echo  \'curl good\'\nfi\n\n\n\necho ""checking promotion status until promotion is finished""\nFINISHED=no\n\n\nINITIAL_TIME=""$(date +%s)""\nwhile [ ""${FINISHED}"" != ""ok"" ]\ndo\n    sleep 2\n\n\n    #checking if promotion is finished (we check the value of <duration> XML element in the job run status)\n    ERROR="""" ; DURATION=""$(curl -s  -u${BUILDER_USER}:${BUILDER_PASSWORD} ""${JENKINS_URL}job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/${DEPLOY_PROMOTION_NAME}/promotionBuild/${PROMOTION_RUN_NUMBER}/api/xml""    | grep -Po  \'<duration>.*</duration>\'   | sed -re  \'s/<duration>(.*)<\\/duration>/\\1/g\' )""   || ERROR=""yes""\n    if [[ $ERROR == ""yes"" ]] ; then\n      echo "" the promotion has been queued but not yet started, waiting for it to start...""\n      curl -s  -u${BUILDER_USER}:${BUILDER_PASSWORD} ""${JENKINS_URL}job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/${DEPLOY_PROMOTION_NAME}/promotionBuild/${PROMOTION_RUN_NUMBER}/api/xml""\n      ERROR=""""\n      continue\n    fi  ;   ERROR=""""\n\n\n\n\n    #we interrupt the polling of the job/promotion status if the promotion\n    #  - is terminated\n    #  - is taking too long (there is some problem)\n    #(in the XML of the job run status the <duration> XML element value is initially empty, than it is 0, and eventually is the number of seconds of the run duration )\n\n    POLLING_TIME=""$(date +%s)""\n    let ""ELAPSED_TIME=POLLING_TIME-INITIAL_TIME""\n    echo ""ELAPSED_TIME=${ELAPSED_TIME}""\n\n    if  (( ${ELAPSED_TIME} \\> $TIMEOUT ))  ; then\n      echo ""error: the promotion has taken too long... exiting""\n      exit 1\n    fi\n\n    if  [[ ""${DURATION}"" != """" ]] ; then\n      re=\'^[0-9]+$\'\n      if [[ $DURATION =~ $re ]] ; then\n        if (( ""${DURATION}"" \\> ""0"" )) ; then\n          FINISHED=ok\n        else\n          : #do nothing (the value of <duration> is 0 , that is the job/promotion has been started in a slave and is still running)\n        fi\n      else\n        echo ""error: the promotion duration is not a number. exiting...""\n        exit 1\n      fi\n    else\n      :  # the job/promotion has not yet started\n    fi\n\n    echo ""waiting for the promotion to finish...""\ndone\n\necho ""Promotion finished""\n\n\n\necho ""Promotion output:""\ncurl -s  -u${BUILDER_USER}:${BUILDER_PASSWORD} ""${JENKINS_URL}job/${JOB_NAME}/${JOB_RUN_NUMBER}/promotion/${DEPLOY_PROMOTION_NAME}/promotionBuild/${PROMOTION_RUN_NUMBER}/consoleText"" > ${WORKSPACE_FOLDER}/promotionOutput\n\ncat ${WORKSPACE_FOLDER}/promotionOutput\n\nif [[ ! ""$(tail -n1 ${WORKSPACE_FOLDER}/promotionOutput)"" =~ ""SUCCESS""  ]] ; then\n      echo ""Promotion did not successfully terminate""\n      exit 1\nelse\n      echo ""Promotion successfully terminated""\nfi\n']"
561,4845,3757,CC BY-SA 4.0,2018-08-25T16:02:14.897,"<p>Better method, thanks to the others responses for helping me get to this.</p>

<p>Determine what plugins are installed currently:</p>

<pre><code># certbot-auto plugins
Saving debug log to /var/log/letsencrypt/letsencrypt.log

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
* apache
Description: Apache Web Server plugin - Beta
Interfaces: IAuthenticator, IInstaller, IPlugin
Entry point: apache = certbot_apache.entrypoint:ENTRYPOINT

* nginx
Description: Nginx Web Server plugin
Interfaces: IAuthenticator, IInstaller, IPlugin
Entry point: nginx = certbot_nginx.configurator:NginxConfigurator

* standalone
Description: Spin up a temporary webserver
Interfaces: IAuthenticator, IPlugin
Entry point: standalone = certbot.plugins.standalone:Authenticator

* webroot
Description: Place files in webroot directory
Interfaces: IAuthenticator, IPlugin
Entry point: webroot = certbot.plugins.webroot:Authenticator
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
</code></pre>

<p>Determine where your certbot (in my case certbot-auto) is installed:</p>

<pre><code># find / -name certbot
/opt/eff.org/certbot
...
</code></pre>

<p>Get into the Virtual Env and install plugin</p>

<pre><code>cd /opt/eff.org/certbot/venv
source bin/activate
pip install certbot-dns-google
deactivate
</code></pre>

<p>Verify certbot plugins again</p>

<pre><code># certbot-auto plugins
Saving debug log to /var/log/letsencrypt/letsencrypt.log

- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
* apache
Description: Apache Web Server plugin - Beta
Interfaces: IAuthenticator, IInstaller, IPlugin
Entry point: apache = certbot_apache.entrypoint:ENTRYPOINT

* dns-google
Description: Obtain certificates using a DNS TXT record (if you are using Google
Cloud DNS for DNS).
Interfaces: IAuthenticator, IPlugin
Entry point: dns-google = certbot_dns_google.dns_google:Authenticator

* nginx
Description: Nginx Web Server plugin
Interfaces: IAuthenticator, IInstaller, IPlugin
Entry point: nginx = certbot_nginx.configurator:NginxConfigurator

* standalone
Description: Spin up a temporary webserver
Interfaces: IAuthenticator, IPlugin
Entry point: standalone = certbot.plugins.standalone:Authenticator

* webroot
Description: Place files in webroot directory
Interfaces: IAuthenticator, IPlugin
Entry point: webroot = certbot.plugins.webroot:Authenticator
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
</code></pre>
",9424,2018-08-25T16:02:14.897,"['# certbot-auto plugins\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n* apache\nDescription: Apache Web Server plugin - Beta\nInterfaces: IAuthenticator, IInstaller, IPlugin\nEntry point: apache = certbot_apache.entrypoint:ENTRYPOINT\n\n* nginx\nDescription: Nginx Web Server plugin\nInterfaces: IAuthenticator, IInstaller, IPlugin\nEntry point: nginx = certbot_nginx.configurator:NginxConfigurator\n\n* standalone\nDescription: Spin up a temporary webserver\nInterfaces: IAuthenticator, IPlugin\nEntry point: standalone = certbot.plugins.standalone:Authenticator\n\n* webroot\nDescription: Place files in webroot directory\nInterfaces: IAuthenticator, IPlugin\nEntry point: webroot = certbot.plugins.webroot:Authenticator\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n', '# find / -name certbot\n/opt/eff.org/certbot\n...\n', 'cd /opt/eff.org/certbot/venv\nsource bin/activate\npip install certbot-dns-google\ndeactivate\n', '# certbot-auto plugins\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n* apache\nDescription: Apache Web Server plugin - Beta\nInterfaces: IAuthenticator, IInstaller, IPlugin\nEntry point: apache = certbot_apache.entrypoint:ENTRYPOINT\n\n* dns-google\nDescription: Obtain certificates using a DNS TXT record (if you are using Google\nCloud DNS for DNS).\nInterfaces: IAuthenticator, IPlugin\nEntry point: dns-google = certbot_dns_google.dns_google:Authenticator\n\n* nginx\nDescription: Nginx Web Server plugin\nInterfaces: IAuthenticator, IInstaller, IPlugin\nEntry point: nginx = certbot_nginx.configurator:NginxConfigurator\n\n* standalone\nDescription: Spin up a temporary webserver\nInterfaces: IAuthenticator, IPlugin\nEntry point: standalone = certbot.plugins.standalone:Authenticator\n\n* webroot\nDescription: Place files in webroot directory\nInterfaces: IAuthenticator, IPlugin\nEntry point: webroot = certbot.plugins.webroot:Authenticator\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n']"
562,4855,4835,CC BY-SA 4.0,2018-08-27T17:27:42.090,"<p>You normally would access environment variables using the following syntax:</p>

<pre><code>env.MY_ISSUE_ID
</code></pre>

<p>Typically you'll see the following in practice regarding envvars:</p>

<pre><code>pipeline {
  agent any
  environment {
    MY_ISSUE_ID = 'PROJECT-1234'
  }
  stages {
    stage('Build') {
      steps {
        echo env.MY_ISSUE_ID
      }
    }
  }
}
</code></pre>

<p>or </p>

<pre><code>node{
  stage('Build') {
    withEnv([""MY_ISSUE_ID=PROJECT-1234""]) {
      echo env.MY_ISSUE_ID
    }
  }
}
</code></pre>
",6579,2018-08-27T17:27:42.090,"['env.MY_ISSUE_ID\n', ""pipeline {\n  agent any\n  environment {\n    MY_ISSUE_ID = 'PROJECT-1234'\n  }\n  stages {\n    stage('Build') {\n      steps {\n        echo env.MY_ISSUE_ID\n      }\n    }\n  }\n}\n"", 'node{\n  stage(\'Build\') {\n    withEnv([""MY_ISSUE_ID=PROJECT-1234""]) {\n      echo env.MY_ISSUE_ID\n    }\n  }\n}\n']"
563,4867,4860,CC BY-SA 4.0,2018-08-29T15:48:42.797,"<p>So what you can do is you list all of your containers with command:</p>

<pre><code>docker container ls -a
</code></pre>

<p>And the second field is an image name, you can run this command to get all the read-only layers with their respective directories to search for the file in:</p>

<pre><code>docker image inspect &lt;image_id&gt; | jq '.[0].GraphDriver.Data.LowerDir' -r | tr "":"" ""\n""
</code></pre>

<p>If the file was something written inside the container replace <strong>Lower</strong> with <strong>Upper</strong>. </p>

<p>In case you are on Mac the /var/lib/docker is inside the virtual machine and so you have to first enter that before you can get to those directories described in the command above. You can do it using nsenter like this:</p>

<pre><code>docker run -it --privileged --pid=host debian nsenter -t 1 -m -u -n -i sh
</code></pre>
",228,2018-08-29T15:48:42.797,"['docker container ls -a\n', 'docker image inspect <image_id> | jq \'.[0].GraphDriver.Data.LowerDir\' -r | tr "":"" ""\\n""\n', 'docker run -it --privileged --pid=host debian nsenter -t 1 -m -u -n -i sh\n']"
564,4881,4879,CC BY-SA 4.0,2018-08-31T15:03:38.460,"<p>The problem was a typo in the var-file
I had a double "" in a value:</p>

<pre><code>varname = """"value""
</code></pre>
",9529,2018-08-31T15:03:38.460,"['varname = """"value""\n']"
565,4898,4886,CC BY-SA 4.0,2018-09-04T11:23:46.157,"<p>Okay, I managed to make it work perfectly. But it took a few steps. I am including the manifest here that is required to setup the <a href=""https://cloud.google.com/iap/"" rel=""nofollow noreferrer"">IAP</a> <a href=""https://cloud.google.com/iap/docs/enabling-kubernetes-howto"" rel=""nofollow noreferrer"">using an ingress</a>. It requires a few things which I listed in the manifest below. Hopefully this can help others since I could not find a single source that had all of this put together. Essentially all you need to do is run <code>kubectl apply -f secure-ingress.yaml</code> to make everything work (as long as you have all the depenedencies) and then you just need to configure your <a href=""https://cloud.google.com/iap/"" rel=""nofollow noreferrer"">IAP</a> as you like it.</p>

<hr>

<p><strong><code>secure-ingress.yaml</code></strong></p>

<pre><code># Configure IAP security using ingress automatically
# requirements: kubernetes version at least 1.10.5-gke.3
# requirements: service must respond with 200 at / endpoint (the healthcheck)
# dependencies: need certificate secret my-secret-cert
# dependencies: need oath-client secret my-secret-oath (with my.domain.com configured)
# dependencies: need external IP address my-external-ip
# dependencies: need domain my.domain.com to point to my-external-ip IP
# dependencies: need an app (deployment/statefulset) my-app
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: my-secure-ingress
  namespace: default
  annotations:
    kubernetes.io/ingress.class: ""gce""
    kubernetes.io/ingress.allow-http: ""false""
    kubernetes.io/ingress.global-static-ip-name: my-external-ip
spec:
  tls:
  - secretName: my-secret-cert
  backend:
    serviceName: my-service-be-web
    servicePort: 1234
---
kind: Service
apiVersion: v1
metadata:
  name: my-service-be-web
  namespace: default
  annotations:
    beta.cloud.google.com/backend-config:
      '{""default"": ""my-service-be-conf""}'
spec:
  type: NodePort
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 1234
      targetPort: 1234
      name: my-port-web
---
apiVersion: cloud.google.com/v1beta1
kind: BackendConfig
metadata:
  name: my-service-be-conf
  namespace: default
spec:
  iap:
    enabled: true
    oauthclientCredentials:
      secretName: my-secret-oath
</code></pre>
",8189,2018-09-04T11:23:46.157,"['# Configure IAP security using ingress automatically\n# requirements: kubernetes version at least 1.10.5-gke.3\n# requirements: service must respond with 200 at / endpoint (the healthcheck)\n# dependencies: need certificate secret my-secret-cert\n# dependencies: need oath-client secret my-secret-oath (with my.domain.com configured)\n# dependencies: need external IP address my-external-ip\n# dependencies: need domain my.domain.com to point to my-external-ip IP\n# dependencies: need an app (deployment/statefulset) my-app\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: my-secure-ingress\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: ""gce""\n    kubernetes.io/ingress.allow-http: ""false""\n    kubernetes.io/ingress.global-static-ip-name: my-external-ip\nspec:\n  tls:\n  - secretName: my-secret-cert\n  backend:\n    serviceName: my-service-be-web\n    servicePort: 1234\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: my-service-be-web\n  namespace: default\n  annotations:\n    beta.cloud.google.com/backend-config:\n      \'{""default"": ""my-service-be-conf""}\'\nspec:\n  type: NodePort\n  selector:\n    app: my-app\n  ports:\n    - protocol: TCP\n      port: 1234\n      targetPort: 1234\n      name: my-port-web\n---\napiVersion: cloud.google.com/v1beta1\nkind: BackendConfig\nmetadata:\n  name: my-service-be-conf\n  namespace: default\nspec:\n  iap:\n    enabled: true\n    oauthclientCredentials:\n      secretName: my-secret-oath\n']"
566,4905,3757,CC BY-SA 4.0,2018-09-05T02:02:58.703,"<p>First run</p>

<pre><code># type certbot
certbot is hashed (/usr/bin/certbot)
</code></pre>

<p>To find out where <code>certbot</code> is installed to. Or <code>command -v certbot</code> if you prefer.</p>

<p>Then run <code>head /usr/bin/certbot</code> and note what version of Python it's using:</p>

<pre><code>#!/usr/bin/python3
</code></pre>

<p>In my case, it was using Python 3.</p>

<p>I noticed from my pip output it was trying to install a Python 2.7 package:</p>

<pre><code># pip install certbot-dns-digitalocean
Requirement already satisfied: certbot-dns-digitalocean in /usr/local/lib/python2.7/dist-packages
</code></pre>

<p>So how do we get pip to install Python 3 packages instead? Just copy the instructions from <a href=""https://stackoverflow.com/a/11272201/65387"">here</a>:</p>

<pre><code>cd /tmp
curl -O https://bootstrap.pypa.io/get-pip.py
python3 get-pip.py
rm get-pip.py
</code></pre>

<p>Now you should have the <code>pip3</code> command, so run this instead:</p>

<pre><code>pip3 install certbot-dns-digitalocean
</code></pre>

<p>And now try again:</p>

<pre><code># certbot plugins
Saving debug log to /var/log/letsencrypt/letsencrypt.log

-------------------------------------------------------------------------------
* dns-digitalocean
Description: Obtain certs using a DNS TXT record (if you are using DigitalOcean
for DNS).
Interfaces: IAuthenticator, IPlugin
Entry point: dns-digitalocean =
certbot_dns_digitalocean.dns_digitalocean:Authenticator
</code></pre>
",7142,2018-09-05T02:02:58.703,"['# type certbot\ncertbot is hashed (/usr/bin/certbot)\n', '#!/usr/bin/python3\n', '# pip install certbot-dns-digitalocean\nRequirement already satisfied: certbot-dns-digitalocean in /usr/local/lib/python2.7/dist-packages\n', 'cd /tmp\ncurl -O https://bootstrap.pypa.io/get-pip.py\npython3 get-pip.py\nrm get-pip.py\n', 'pip3 install certbot-dns-digitalocean\n', '# certbot plugins\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\n\n-------------------------------------------------------------------------------\n* dns-digitalocean\nDescription: Obtain certs using a DNS TXT record (if you are using DigitalOcean\nfor DNS).\nInterfaces: IAuthenticator, IPlugin\nEntry point: dns-digitalocean =\ncertbot_dns_digitalocean.dns_digitalocean:Authenticator\n']"
567,4908,4907,CC BY-SA 4.0,2018-09-05T15:18:19.583,"<p>I solved this thanks to Reddit post. It was fairly simple when combined with another part of my testing.</p>

<p>I used the code <code>{PGBINNEW}/initdb --pgdata=""$PGDATANEW"" --encoding=UTF8 --no-locale</code> to reinit the DB AFTER I did the below command:</p>

<pre><code>sudo rm -rf ${PGBASEDIR}/data10
</code></pre>

<p>What happened was I cleared the old DB init config and then put in the config I needed without the localization of the database</p>
",,2018-09-05T15:18:19.583,['sudo rm -rf ${PGBASEDIR}/data10\n']
568,4910,4904,CC BY-SA 4.0,2018-09-05T19:12:18.877,"<p>You don't need cron. Most server OS-es (CoreOS, RedHat, CentOS, Ubuntu, etc.) these days run <a href=""https://freedesktop.org/wiki/Software/systemd/"" rel=""nofollow noreferrer"">systemd</a>, and systemd unit files can run your container to execute the job, for example:</p>

<p>Two unit files. One is mytimedstuff.service and mytimedstuff.timer. The .timer defines when the service should be executed.</p>

<p>In mytimedstuff.service</p>

<pre><code>[Unit]
Description=Executes mystuff
After=default.target docker_network_apps.service
Requires=default.target docker_network_apps.service

[Service]
Type=oneshot
User=root
ExecStartPre=/usr/bin/docker pull mystuff:stable
ExecStartPre=-/bin/bash -c ""/usr/bin/docker rm -f mystuffcontainer 2&gt;/dev/null""
ExecStart=/bin/bash -c ""/usr/bin/docker run --name mystuffcontainer mystuff:stable mystuff""
</code></pre>

<p>In mytimedstuff.timer:</p>

<pre><code>[Unit]
Description=My stuff runs at 00:10 sharp.

[Timer]
OnCalendar=00:10:00

[Install]
WantedBy=multi-user.target
</code></pre>
",9609,2018-09-05T19:12:18.877,"['[Unit]\nDescription=Executes mystuff\nAfter=default.target docker_network_apps.service\nRequires=default.target docker_network_apps.service\n\n[Service]\nType=oneshot\nUser=root\nExecStartPre=/usr/bin/docker pull mystuff:stable\nExecStartPre=-/bin/bash -c ""/usr/bin/docker rm -f mystuffcontainer 2>/dev/null""\nExecStart=/bin/bash -c ""/usr/bin/docker run --name mystuffcontainer mystuff:stable mystuff""\n', '[Unit]\nDescription=My stuff runs at 00:10 sharp.\n\n[Timer]\nOnCalendar=00:10:00\n\n[Install]\nWantedBy=multi-user.target\n']"
569,4915,21,CC BY-SA 4.0,2018-09-06T06:06:33.760,"<p>I'm using scripts from <a href=""https://github.com/sue445/jenkins-backup-script"" rel=""nofollow noreferrer""><code>sue445/jenkins-backup-script</code></a>.</p>

<p>It archives Jenkins settings and plugins such as:</p>

<ul>
<li><code>$JENKINS_HOME/*.xml</code></li>
<li><code>$JENKINS_HOME/jobs/*/*.xml</code></li>
<li><code>$JENKINS_HOME/nodes/*</code></li>
<li><code>$JENKINS_HOME/plugins/*.jpi</code></li>
<li><code>$JENKINS_HOME/secrets/*</code></li>
<li><code>$JENKINS_HOME/users/*</code></li>
</ul>

<h3>Usage</h3>

<pre><code>./jenkins-backup.sh /path/to/jenkins_home archive.tar.gz

# add timestamp suffix
./jenkins-backup.sh /path/to/jenkins_home backup_`date +""%Y%m%d%H%M%S""`.tar.gz
</code></pre>
",9618,2018-09-06T10:28:05.860,"['./jenkins-backup.sh /path/to/jenkins_home archive.tar.gz\n\n# add timestamp suffix\n./jenkins-backup.sh /path/to/jenkins_home backup_`date +""%Y%m%d%H%M%S""`.tar.gz\n']"
570,4920,4912,CC BY-SA 4.0,2018-09-06T08:21:46.777,"<p>There are options you can pass through apt-get to dpkg that will handle the config choices. We usually do something like:</p>

<p><code>apt-get install -y --no_install_recommends -o Dpkg::Options::='--force-confdef' -o Dpkg::Options::='--force-confold' &lt;package_name&gt;</code></p>

<p>When using ansible you can do:</p>

<pre><code>  apt:
    pkg: ""{{ item }}""
    only_upgrade: yes
    install_recommends: no
    force: yes
    dpkg_options: 'force-confdef,force-confold'
    state: latest
  with_items:
    - &lt;package_name&gt;
</code></pre>

<p>For further details on the ansible <strong>apt</strong> module options look <a href=""https://docs.ansible.com/ansible/latest/modules/apt_module.html"" rel=""noreferrer"">here</a></p>
",228,2018-09-06T08:21:46.777,"['  apt:\n    pkg: ""{{ item }}""\n    only_upgrade: yes\n    install_recommends: no\n    force: yes\n    dpkg_options: \'force-confdef,force-confold\'\n    state: latest\n  with_items:\n    - <package_name>\n']"
571,4929,1538,CC BY-SA 4.0,2018-09-07T09:59:02.330,"<p>As of Sep 4 2018 Amazon added support for multiple input sources:</p>

<p><a href=""https://aws.amazon.com/about-aws/whats-new/2018/08/aws-codebuild-adds-ability-to-create-build-projects-with-multiple-input-sources-and-output-artifacts/"" rel=""nofollow noreferrer"">https://aws.amazon.com/about-aws/whats-new/2018/08/aws-codebuild-adds-ability-to-create-build-projects-with-multiple-input-sources-and-output-artifacts/</a></p>

<p>From <a href=""https://docs.aws.amazon.com/codebuild/latest/userguide/sample-multi-in-out.html"" rel=""nofollow noreferrer"">documentation</a>:</p>

<pre><code>{
""name"": ""sample-project"",
""source"": {
  ""type"": ""S3"",
  ""location"": ""bucket/sample.zip""
},
""secondarySources"": [
  {
    ""type"": ""CODECOMMIT"",
    ""location"": ""https://git-codecommit.us-west-2.amazonaws.com/v1/repos/repo""
    ""sourceIdentifier"": ""source1""
  },
  {
    ""type"": ""GITHUB"",
    ""location"": ""https://github.com/awslabs/aws-codebuild-jenkins-plugin""
    ""sourceIdentifier"": ""source2""
  }
],
</code></pre>

<hr>

<pre><code>version: 0.2

phases:
  build:
    commands:
      - cd $CODEBUILD_SRC_DIR_source1
      - touch file1
      - cd $CODEBUILD_SRC_DIR_source2
      - touch file2

artifacts:
  secondary-artifacts:
    artifact1:
      base-directory: $CODEBUILD_SRC_DIR_source1
      files:
        - file1
    artifact2:
      base-directory: $CODEBUILD_SRC_DIR_source2
      files:
        - file2
</code></pre>
",3498,2018-09-07T09:59:02.330,"['{\n""name"": ""sample-project"",\n""source"": {\n  ""type"": ""S3"",\n  ""location"": ""bucket/sample.zip""\n},\n""secondarySources"": [\n  {\n    ""type"": ""CODECOMMIT"",\n    ""location"": ""https://git-codecommit.us-west-2.amazonaws.com/v1/repos/repo""\n    ""sourceIdentifier"": ""source1""\n  },\n  {\n    ""type"": ""GITHUB"",\n    ""location"": ""https://github.com/awslabs/aws-codebuild-jenkins-plugin""\n    ""sourceIdentifier"": ""source2""\n  }\n],\n', 'version: 0.2\n\nphases:\n  build:\n    commands:\n      - cd $CODEBUILD_SRC_DIR_source1\n      - touch file1\n      - cd $CODEBUILD_SRC_DIR_source2\n      - touch file2\n\nartifacts:\n  secondary-artifacts:\n    artifact1:\n      base-directory: $CODEBUILD_SRC_DIR_source1\n      files:\n        - file1\n    artifact2:\n      base-directory: $CODEBUILD_SRC_DIR_source2\n      files:\n        - file2\n']"
572,4934,4253,CC BY-SA 4.0,2018-09-08T14:32:38.633,"<p>If you cordon and drain the nodepool before deleting it, then you can avoid downtime. I use the following script (shamelessly taken from the lazyweb elsewhere and adapted to my needs):</p>

<pre><code>oldpool=pool-1
oldnodes=$(k get no --selector='cloud.google.com/gke-nodepool='$oldpool -o json | jq .items[].metadata.name -r | xargs)

kubectl cordon --selector='cloud.google.com/gke-nodepool='$oldpool

for n in $oldnodes; do
  echo ""draining $n""
  kubectl drain --delete-local-data --ignore-daemonsets $n
  echo ""----------------------------""
done;
</code></pre>
",9666,2018-09-08T14:32:38.633,"['oldpool=pool-1\noldnodes=$(k get no --selector=\'cloud.google.com/gke-nodepool=\'$oldpool -o json | jq .items[].metadata.name -r | xargs)\n\nkubectl cordon --selector=\'cloud.google.com/gke-nodepool=\'$oldpool\n\nfor n in $oldnodes; do\n  echo ""draining $n""\n  kubectl drain --delete-local-data --ignore-daemonsets $n\n  echo ""----------------------------""\ndone;\n']"
573,4935,4932,CC BY-SA 4.0,2018-09-09T10:42:12.853,"<p>Any system would do. You might need to write a wrapper. For example:</p>

<pre><code>&gt; cat get-passwd-01.yml
- hosts: localhost
  gather_facts: no
  tasks:
    - command: ~/bin/get-passwd user9
      register: password
    - debug:
        msg: ""passwd:{{ password.stdout }}""
</code></pre>

<p>.</p>

<pre><code>&gt; ansible-playbook get-passwd-01.yml | grep msg
    ""msg"": ""passwd: T4gpJtZ69R5cZD9zQh""
</code></pre>
",7715,2018-09-09T10:42:12.853,"['> cat get-passwd-01.yml\n- hosts: localhost\n  gather_facts: no\n  tasks:\n    - command: ~/bin/get-passwd user9\n      register: password\n    - debug:\n        msg: ""passwd:{{ password.stdout }}""\n', '> ansible-playbook get-passwd-01.yml | grep msg\n    ""msg"": ""passwd: T4gpJtZ69R5cZD9zQh""\n']"
574,4936,4933,CC BY-SA 4.0,2018-09-09T14:08:13.793,"<p>You need create user define network</p>

<pre><code>docker network create -d transparent --subnet=10.1.1.0/24 --gateway=10.1.1.1 TransparentNet3
</code></pre>

<p>Then you need run container with key --ip</p>

<pre><code>docker run -it --name nano03 --network=TransparentNet3 --ip 10.1.1.1 someimage:sometag
</code></pre>
",9655,2018-09-09T14:08:13.793,"['docker network create -d transparent --subnet=10.1.1.0/24 --gateway=10.1.1.1 TransparentNet3\n', 'docker run -it --name nano03 --network=TransparentNet3 --ip 10.1.1.1 someimage:sometag\n']"
575,4946,4941,CC BY-SA 4.0,2018-09-11T23:37:05.893,"<p>Depend of life cycle of you app, because Node libraries and dependences change or end life to obsolet, so if you app constant change version to deploy, you can use <a href=""https://docs.docker.com/engine/reference/commandline/tag/"" rel=""nofollow noreferrer"">docker tag</a> for describe version or time when it build image, is a good practice, so Dockerfile shall copy package.json, and too look when you need change image source OS, by example change ubuntu linux to alpine , many dependences or how to install ""npm"" and dependences for node, a example:</p>

<pre><code>  FROM alpine:3.8

# Update
RUN apk add --update nodejs nodejs-npm

# Install app dependencies
COPY package.json /src/package.json

RUN cd /src; npm install

# Bundle app source
COPY . /src

EXPOSE 5000
CMD [""node"",""src/index.js""]
</code></pre>

<p>well , hope it help you</p>
",9398,2018-09-11T23:37:05.893,"['  FROM alpine:3.8\n\n# Update\nRUN apk add --update nodejs nodejs-npm\n\n# Install app dependencies\nCOPY package.json /src/package.json\n\nRUN cd /src; npm install\n\n# Bundle app source\nCOPY . /src\n\nEXPOSE 5000\nCMD [""node"",""src/index.js""]\n']"
576,4961,4953,CC BY-SA 4.0,2018-09-13T10:00:47.717,"<p>First things first: let us make clear what we are talking about. We are dwelling on the action of <strong>storing an artifact in an artifact repository</strong>.</p>

<p>I personnaly would rather avoid using <em>deploy</em>, because:</p>

<ul>
<li><strong>publish</strong> implies that you make an artifact available for others to consume. The term seems to do the job. It weakens a bit when you push the artifact to a <em>private</em> repository. You would then do a <em>private publication</em>. It's a lesser evil. It still makes sens.</li>
<li><strong>deploy</strong> is definitely not appropriate. Pushing a single artifact in a single repository is in no way a <em>deployement</em>. Deploy implies some sort of spreading, distributing an artifact on several environments or machines. What we are dealing with, here, is a pre-requisite to deploying; not deploying itself.</li>
</ul>

<p><strong>[Success?] Story</strong></p>

<p>For what it's worth, last time I was faced with naming the job that pushes the artifacts to the artifact repository, I was working in a Kanban context. The team came to an agreement to call the job</p>

<pre><code>version
</code></pre>

<p>because every package that was built following a merge request was a potential release candidate, therefore it was <em>versioned</em> then pushed.</p>

<p><strong>After Thoughts</strong></p>

<p>As of today, I would use the term <strong>publish</strong> (possibly privately) laking of a better term.</p>

<p>Still I don't find this satisfactory. Please feel free to leave your thoughts in the comments below!</p>
",9049,2018-09-13T10:00:47.717,['version\n']
577,4965,1818,CC BY-SA 4.0,2018-09-13T23:17:28.057,"<p>If you want to VPN for a jenkins task you would want to use the OpenConnect plugin as you mentioned.</p>

<p>Here are the steps to do that:</p>

<p>On linux (debian based)</p>

<pre><code>sudo apt-get install openconnect
</code></pre>

<p>Add the following lines to the bottom of /etc/sudoers (ubuntu configuration)</p>

<pre><code>jenkins ALL=NOPASSWD:/usr/sbin/openconnect*
jenkins ALL=NOPASSWD:/bin/kill*
</code></pre>

<p>The you will get an option in the Jenkins run task called:</p>

<pre><code>Connect to Cisco AnyConnect VPN
</code></pre>

<p>Can also be found here:
<a href=""https://stackoverflow.com/questions/35151072/deploy-with-jenkins-to-vpn/43357784#43357784"">https://stackoverflow.com/questions/35151072/deploy-with-jenkins-to-vpn/43357784#43357784</a></p>
",9769,2018-09-13T23:17:28.057,"['sudo apt-get install openconnect\n', 'jenkins ALL=NOPASSWD:/usr/sbin/openconnect*\njenkins ALL=NOPASSWD:/bin/kill*\n', 'Connect to Cisco AnyConnect VPN\n']"
578,4969,4967,CC BY-SA 4.0,2018-09-14T07:35:57.743,"<p>Your second link just use the official cookbook. This official cookbook still uses the LWRP syntax, so you need to check in the provider directory for the <a href=""https://gitlab.com/chef-platform/gitlab-ci-runner/blob/master/providers/default.rb"" rel=""nofollow noreferrer"">resource action code</a> -- which for register is basically just two execute commands (extract from the file linked above):</p>

<pre><code>converge_by(""Register runner #{new_resource.description}"") do
  execute ""#{env} gitlab-runner register --non-interactive #{options}""
  # giving time to gitlab-ci to manage the request
  execute ""sleep #{new_resource.sleep}""
end
</code></pre>

<p>So mostly, your exemple ends up calling the <code>gitlab-runner register</code> command with the options defined in the options hash (with a little transformation of the hash into command parameters).</p>

<p>There's no 'core' chef resource to register gitlab runners out of using an <code>execute</code> resource to run the command.</p>

<p>A basic example of this resource is present in the cookbook <a href=""https://gitlab.com/chef-platform/gitlab-ci-runner/tree/master#default-1"" rel=""nofollow noreferrer"">Readme</a>:</p>

<pre><code>gitlab_ci_runner 'my runner' do
  options({
    registration_token: '1234567890',
    url: 'http://gitlab-ci.myinstance'
  })
end
</code></pre>
",13,2019-06-24T07:36:38.040,"['converge_by(""Register runner #{new_resource.description}"") do\n  execute ""#{env} gitlab-runner register --non-interactive #{options}""\n  # giving time to gitlab-ci to manage the request\n  execute ""sleep #{new_resource.sleep}""\nend\n', ""gitlab_ci_runner 'my runner' do\n  options({\n    registration_token: '1234567890',\n    url: 'http://gitlab-ci.myinstance'\n  })\nend\n""]"
579,4975,1124,CC BY-SA 4.0,2018-09-14T18:59:32.767,"<p>I think your issue is rooted in the <strong>server</strong> variable not being reusable outside the pre-build stage block.</p>

<p>In Jenkins declarative, you can define variables like that using the <code>script { ... }</code> block, but once you leave the stage those variables are inaccessible to other to stages.</p>

<p>With the previous suggestions, I'd recommend this:</p>

<p>House the artifactory deploy code to a shared library.</p>

<pre>
<i>gradle_artifactory.groovy</i>

    def call (Map parameters = [:]) {  //optional parameters mapping

        def server = Artifactory.server 'LocalJfrog'
        def rtGradle = Artifactory.newGradleBuild()
        rtGradle.resolver server: server, repo: 'gradle-dev-local'
        rtGradle.deployer server: server, repo: 'gradle-release-local'
        rtGradle.useWrapper = true
        def buildInfo = rtGradle.run rootDir: ""projectDir/"", buildFile: 
            'build.gradle', tasks: 'clean artifactoryPublish'

    }
</pre>

<p>Then to keep your declarative pipelines <code>D.R.Y</code></p>

<pre><code>@Library('my-shared-lib') 
...
stage('Artifactory Upload') {
    when { &lt;some expression with sonarqube/checkmarx&gt; }
    steps {
        script {
            gradle_artifactory()
        }
    }
}
</code></pre>

<p>refs:</p>

<p><a href=""https://jenkins.io/doc/book/pipeline/syntax/#when"" rel=""nofollow noreferrer"">https://jenkins.io/doc/book/pipeline/syntax/#when</a></p>

<p><a href=""https://jenkins.io/doc/book/pipeline/shared-libraries/"" rel=""nofollow noreferrer"">https://jenkins.io/doc/book/pipeline/shared-libraries/</a></p>
",9790,2018-09-14T18:59:32.767,"['\ngradle_artifactory.groovy\n\n    def call (Map parameters = [:]) {  //optional parameters mapping\n\n        def server = Artifactory.server \'LocalJfrog\'\n        def rtGradle = Artifactory.newGradleBuild()\n        rtGradle.resolver server: server, repo: \'gradle-dev-local\'\n        rtGradle.deployer server: server, repo: \'gradle-release-local\'\n        rtGradle.useWrapper = true\n        def buildInfo = rtGradle.run rootDir: ""projectDir/"", buildFile: \n            \'build.gradle\', tasks: \'clean artifactoryPublish\'\n\n    }\n', ""@Library('my-shared-lib') \n...\nstage('Artifactory Upload') {\n    when { <some expression with sonarqube/checkmarx> }\n    steps {\n        script {\n            gradle_artifactory()\n        }\n    }\n}\n""]"
580,4976,4966,CC BY-SA 4.0,2018-09-14T21:48:14.687,"<p>I implemented this in node.js - I don't know of a unix utility that can dynamically change grep. Here is how it works:</p>

<p><em>before dygrep:</em></p>

<pre><code>many-child-procs &gt; logfile.log                  # in terminal 1
tail -f logfile.log | grep &lt;expression&gt;          # in terminal 2
</code></pre>

<p><em>after dygrep:</em></p>

<pre><code>many-child-procs | dygrep                    # in terminal 1
</code></pre>

<p>then you connect to dygrep with a tcp-client and control which expressions are filtered on.</p>

<p>The following node.js process reads from stdin, and uses a tcp connection to listen for expressions to filter on. For each line of stdin, it only forwards that to stdout if it matches one of the current regular expressions stored in memory.</p>

<pre><code>#!/usr/bin/env node
'use strict';

import * as readline from 'readline';
import * as net from 'net';
import chalk from 'chalk';
import {createParser} from ""./json-parser"";
import log from './logger';

let port = 4900;


const rl = readline.createInterface({
  input: process.stdin.resume()
});

const regex = new Map&lt;string, RegExp&gt;();

rl.on('line', l =&gt; {

  if (regex.size &lt; 1) {
    process.stdout.write(l + '\n');
    return;
  }

  for (let [k, v] of regex) {
    if (v.test(l)) {
      process.stdout.write(chalk.magenta(' (filtered) ') + l + '\n');
      break;
    }
  }

});

interface IncomingTCPMessage {
  command: {
    add: string,
    remove: string,
    list: boolean,
    removeall: boolean
  }
}

const server = net.createServer(s =&gt; {

  const sendMessage = (m: any) =&gt; {
    s.write(JSON.stringify({message: m}) + `\n`);
  };

  s.pipe(createParser()).on('data', (d: IncomingTCPMessage) =&gt; {

    if (!d.command) {
      log.error('No ""command"" field was found:', d);
      return ''
    }

    const c = d.command;

    if (c.list) {
      sendMessage({regexes: Array.from(regex.keys()).map(k =&gt; ({regex: regex.get(k), str: k}))});
      log.info('Listing all regex for the client.');
      return;
    }

    if (c.removeall) {
      regex.clear();
      sendMessage(`Cleared all regex.`);
      log.info('Cleared all regex.');
      return;
    }

    if (c.add) {
      regex.set(c.add, new RegExp(c.add));
      sendMessage(`Added regex: ${c.add}.`);
      log.info('Added regex:', c.add);
      return;
    }

    if (c.remove) {
      regex.delete(c.remove);
      sendMessage(`Deleted regex: ${c.remove}.`);
      log.info('Removed regex:', c.remove);
      return;
    }

    log.error('No matching field was found:', d);
    log.info('Regex:', regex);

  });

});

server.listen(port);
</code></pre>

<p>to see the complete code, see:
<a href=""https://github.com/ORESoftware/dygrep"" rel=""nofollow noreferrer"">https://github.com/ORESoftware/dygrep</a></p>
",7837,2018-09-15T22:44:30.643,"['many-child-procs > logfile.log                  # in terminal 1\ntail -f logfile.log | grep <expression>          # in terminal 2\n', 'many-child-procs | dygrep                    # in terminal 1\n', '#!/usr/bin/env node\n\'use strict\';\n\nimport * as readline from \'readline\';\nimport * as net from \'net\';\nimport chalk from \'chalk\';\nimport {createParser} from ""./json-parser"";\nimport log from \'./logger\';\n\nlet port = 4900;\n\n\nconst rl = readline.createInterface({\n  input: process.stdin.resume()\n});\n\nconst regex = new Map<string, RegExp>();\n\nrl.on(\'line\', l => {\n\n  if (regex.size < 1) {\n    process.stdout.write(l + \'\\n\');\n    return;\n  }\n\n  for (let [k, v] of regex) {\n    if (v.test(l)) {\n      process.stdout.write(chalk.magenta(\' (filtered) \') + l + \'\\n\');\n      break;\n    }\n  }\n\n});\n\ninterface IncomingTCPMessage {\n  command: {\n    add: string,\n    remove: string,\n    list: boolean,\n    removeall: boolean\n  }\n}\n\nconst server = net.createServer(s => {\n\n  const sendMessage = (m: any) => {\n    s.write(JSON.stringify({message: m}) + `\\n`);\n  };\n\n  s.pipe(createParser()).on(\'data\', (d: IncomingTCPMessage) => {\n\n    if (!d.command) {\n      log.error(\'No ""command"" field was found:\', d);\n      return \'\'\n    }\n\n    const c = d.command;\n\n    if (c.list) {\n      sendMessage({regexes: Array.from(regex.keys()).map(k => ({regex: regex.get(k), str: k}))});\n      log.info(\'Listing all regex for the client.\');\n      return;\n    }\n\n    if (c.removeall) {\n      regex.clear();\n      sendMessage(`Cleared all regex.`);\n      log.info(\'Cleared all regex.\');\n      return;\n    }\n\n    if (c.add) {\n      regex.set(c.add, new RegExp(c.add));\n      sendMessage(`Added regex: ${c.add}.`);\n      log.info(\'Added regex:\', c.add);\n      return;\n    }\n\n    if (c.remove) {\n      regex.delete(c.remove);\n      sendMessage(`Deleted regex: ${c.remove}.`);\n      log.info(\'Removed regex:\', c.remove);\n      return;\n    }\n\n    log.error(\'No matching field was found:\', d);\n    log.info(\'Regex:\', regex);\n\n  });\n\n});\n\nserver.listen(port);\n']"
581,4977,4913,CC BY-SA 4.0,2018-09-15T09:48:32.900,"<p>Consider to substitute the version in POM by the <code>git describe</code> upon build without hardcoding the version in your repository, you could do this with e.g. <code>sed</code> from below <code>version_slug</code>.</p>

<pre><code>export git_version=`git describe --tags --always`
export version_slug=""$(sed s/-/\./g &lt;&lt;&lt;$git_version)""
</code></pre>

<p>and then substitute the version_slug in pom.</p>

<p>In that way for each commit and/or tag in gitlab, you'll create a new version, with out actually changing the repository. </p>

<p>this is what i did for a ruby project: <a href=""https://gitlab.com/dgoo2308/jekyll-plantuml-url/blob/master/.gitlab-ci.yml"" rel=""nofollow noreferrer"">jekyll-plantuml-url</a>, where the version is not coded in the source, but is set upon build, and after testing deployed as the git tag.</p>

<pre><code>  script:
   - bundle install
   - rake set_git_tag
   - rake
   - gem build jekyll-plantuml-url.gemspec
</code></pre>

<p>Furthermore don't understand the need of all those branches, with CI/CD we continuously build, test and deploy, that means before accepting a merge to master you have a deployment for QA to do the testing, code review, functional testing ...etc.</p>

<p>Next add QA as approver for a merge to master, thus make it mandatory that QA signs of a merge request to master and integrate quality in the development cycle or have a master that is always ready for release.</p>

<p>One could opt to work from master and for a release tag the master branch with a version tag, as per above example.</p>

<p>OR </p>

<p>like gitlab does it, to create a branch for each release, cherry pick the features from master that are ready or planned and then tag the branch with a version tag.</p>

<p>where as a version tag creates a deployment for a commit, release or a RC.</p>
",2979,2018-09-17T07:24:51.213,"['export git_version=`git describe --tags --always`\nexport version_slug=""$(sed s/-/\\./g <<<$git_version)""\n', '  script:\n   - bundle install\n   - rake set_git_tag\n   - rake\n   - gem build jekyll-plantuml-url.gemspec\n']"
582,4983,3860,CC BY-SA 4.0,2018-09-16T13:44:45.870,"<p>It is possible to achieve this using <code>async</code> mode. Please find some references for how to do this below.</p>

<p>Refs:</p>

<ul>
<li><a href=""http://toroid.org/ansible-parallel-dispatch"" rel=""nofollow noreferrer"">http://toroid.org/ansible-parallel-dispatch</a></li>
<li><a href=""https://blog.crisp.se/2018/01/27/maxwenzin/how-to-run-ansible-tasks-in-parallel"" rel=""nofollow noreferrer"">https://blog.crisp.se/2018/01/27/maxwenzin/how-to-run-ansible-tasks-in-parallel</a></li>
</ul>

<pre><code>---

- name: Run tasks in parallel
  hosts: localhost
  connection: local
  gather_facts: no
  tasks:
    - name: Pretend to create instances
      command: ""sleep {{ item }}""  # Instead of calling a long running operation at a cloud provider, we just sleep.
      with_items:
        - 6
        - 8
        - 7
      register: _create_instances
      async: 600  # Maximum runtime in seconds. Adjust as needed.
      poll: 0  # Fire and continue (never poll)

    - name: Wait for creation to finish
      async_status:
        jid: ""{{ item.ansible_job_id }}""
      register: _jobs
      until: _jobs.finished
      delay: 5  # Check every 5 seconds. Adjust as you like.
      retries: 10  # Retry up to 10 times. Adjust as needed.
      with_items: ""{{ _create_instances.results }}""
</code></pre>
",4540,2019-04-11T15:39:03.580,"['---\n\n- name: Run tasks in parallel\n  hosts: localhost\n  connection: local\n  gather_facts: no\n  tasks:\n    - name: Pretend to create instances\n      command: ""sleep {{ item }}""  # Instead of calling a long running operation at a cloud provider, we just sleep.\n      with_items:\n        - 6\n        - 8\n        - 7\n      register: _create_instances\n      async: 600  # Maximum runtime in seconds. Adjust as needed.\n      poll: 0  # Fire and continue (never poll)\n\n    - name: Wait for creation to finish\n      async_status:\n        jid: ""{{ item.ansible_job_id }}""\n      register: _jobs\n      until: _jobs.finished\n      delay: 5  # Check every 5 seconds. Adjust as you like.\n      retries: 10  # Retry up to 10 times. Adjust as needed.\n      with_items: ""{{ _create_instances.results }}""\n']"
583,4988,4986,CC BY-SA 4.0,2018-09-17T07:39:56.337,"<p>what you're looking at is a resource declaration, mostly a class taking a block as parameter.</p>

<p>In ruby the <code>do code end</code> syntax is the prefered way over the curly braces syntax <code>{ code }</code> which is prefered for inline code.</p>

<p>So mostly, what you have is the same as:</p>

<pre><code>aws_elastic_lb('elb_qa'){ aws_access_key aws[‘aws_access_key_id’]; aws_secret_access_key aws[‘aws_secret_access_key’]; name ‘elb_qa’; action :register }
</code></pre>

<p>In recent version of chef (14.X) the name attribute should be the name of the block (what is just after the resource type (aws_elastic_lb)</p>

<p>More details in <a href=""https://stackoverflow.com/questions/5587264/do-end-vs-curly-braces-for-blocks-in-ruby"">this SO quastion</a> about ruby syntax.</p>

<p>Concerning Chef itself I highly suggest you follow the tutorials at <a href=""https://learn.chef.io"" rel=""nofollow noreferrer"">https://learn.chef.io</a> for a better overview of what is what in cookbooks.</p>
",13,2018-09-17T07:39:56.337,"[""aws_elastic_lb('elb_qa'){ aws_access_key aws[‘aws_access_key_id’]; aws_secret_access_key aws[‘aws_secret_access_key’]; name ‘elb_qa’; action :register }\n""]"
584,4991,4986,CC BY-SA 4.0,2018-09-17T08:52:36.597,"<p>Following Tensiblai's guidance, I found this documentation explaining the parts comprising a resource:</p>

<p>see: <a href=""https://docs.chef.io/resource.html"" rel=""nofollow noreferrer"">https://docs.chef.io/resource.html</a></p>

<blockquote>
  <p>A resource is a Ruby block with four components: a type, a name, one
  (or more) properties (with values), and one (or more) actions. The
  syntax for a resource is like this:</p>
</blockquote>

<pre><code>type 'name' do
   attribute 'value'
   action :type_of_action
end
</code></pre>
",9560,2018-09-17T08:52:36.597,"[""type 'name' do\n   attribute 'value'\n   action :type_of_action\nend\n""]"
585,5006,4987,CC BY-SA 4.0,2018-09-18T09:05:35.237,"<p>Well after some research, it seems the initial issue was caused by the volume mount configuration in the host's docker-compose.yml</p>

<p>Even I put below line on build <code>Dockerfile</code> which copies the files to the given path</p>

<pre><code>ADD . /var/www/html
</code></pre>

<p>Since the host's docker-compose.yml got line like below</p>

<pre><code>volumes:
    - .:/var/www/html  
</code></pre>

<p>The container mounting this directory as a new directory to it's Unix like filesystem. So it masks the underlying files.
So on the file system its a new directory and doesn't represent the underlying files. Basically its empty.
This <a href=""https://github.com/moby/moby/issues/4361"" rel=""nofollow noreferrer"">Github issue</a> confirms this. </p>

<p>Then it runs the <code>wordpress:latest</code>'s <code>docker-entrypoint.sh</code>
Which set <code>/var/www/html</code> as the working directory and if it doesn't contain <code>index.php</code> and <code>wp-includes/version.php</code> (obviously it doesn't due to above matter, directory is new) inside, it downloads and extract WordPress source to this directory. That's why after the mount, my old bundled data wasn't there. </p>

<p>So I was basically tried to do something which was not intended. </p>

<p>As @Jeremy commented,  </p>

<blockquote>
  <p>as /var/www/html? It sounds like your mount is failing - and that the
  ADD Is superfluous</p>
</blockquote>

<hr>

<p><strong>Another try</strong> Was totally wrong. Because I was adding a custom <code>ENTRYPOINT</code> script to my build <code>Dockerfile</code>, so it keeps ignoring the base image <code>wordpress</code>'s <code>ENTRYPOINT</code> and <code>CMD</code> that's why it wasn't copy new source to the directory. </p>
",9818,2018-09-18T09:05:35.237,"['ADD . /var/www/html\n', 'volumes:\n    - .:/var/www/html  \n']"
586,5023,3860,CC BY-SA 4.0,2018-09-20T14:25:34.043,"<p>As @webKnja mentioned this is possible with <code>async</code> mode. I have recently discovered it myself and learned that you can use it in 3 different ways depending on your needs.</p>

<ol>
<li><p><strong>Execute and poll</strong> the results, notice the <code>poll:5</code>, This will poll the results every 5 seconds. You may save some time with this method.</p>

<pre><code>- name: My long runing task
  some_module_name:
    ip: ""{{item.fabric}}""
    username: ""{{user}}""
    password: ""{{password}}""
    secret: ""{{secret}}""
  loop: ""{{zoning_list}}""
  register: _alias_vc_0
  async: 60
  poll: 5
</code></pre></li>
<li><p><strong>Fire and forget</strong> <code>poll: 0</code>, This is very quick option since Ansible it's just shooting out those tasks. The down side is that we don't know what was the outcome of the task i.e. <code>changed: True/False</code>. Of course it's a downside if you care about the feedback ;).</p>

<pre><code>name: My long runing task
some_module_name:
  ip: ""{{item.fabric}}""
  username: ""{{user}}""
  password: ""{{password}}""
  secret: ""{{secret}}""
loop: ""{{zoning_list}}""
register: _alias_vc_0
async: 60
poll: 0
</code></pre></li>
<li><p><strong>Fire and forget with <code>async_status</code></strong>, the syntax for the task is the same as example <strong>2</strong> whowever it will require additional task <code>async_status</code>. This is my favorite since it's relatively fast (faster then normal looping or the <code>execute and poll</code>) and allows you to capture the feedback although will need to deal with new <code>register</code> for your <code>async_task</code>.</p>

<p><code>retries: 20</code> -- how many attempts before failing.</p>

<p><code>delay: 2</code> -- how many second to wait between polls.</p>

<pre><code>- name: My long runing task
  some_module_name:
    ip: ""{{item.fabric}}""
    username: ""{{user}}""
    password: ""{{password}}""
    secret: ""{{secret}}""
  loop: ""{{zoning_list}}""
  register: _alias_vc_0
  async: 60
  poll: 0


- name: Wait for My long running task to finish
  async_status:
    id: ""{{ item.ansible_job_id }}""
  register: _jobs_alias_vc_0
  retries: 20
  delay: 2
  until: _jobs_alias_vc_0.finished
  loop: ""{{_alias_vc_0.results}}""
</code></pre></li>
</ol>

<p><strong>A word of caution</strong>, depending on the task yo may not be able to use the <code>async</code> option. I had examples where I was interacting with system which was not able to handle multiple requests for the same resource. I found <code>async</code> option best working if I have to perform the same task across multiple hosts. That's where I was able to ""save"" the most time.</p>

<p>Since you posted the link to Ansible documentation in the question I'm not going to do that.</p>
",9904,2019-05-10T10:20:29.863,"['- name: My long runing task\n  some_module_name:\n    ip: ""{{item.fabric}}""\n    username: ""{{user}}""\n    password: ""{{password}}""\n    secret: ""{{secret}}""\n  loop: ""{{zoning_list}}""\n  register: _alias_vc_0\n  async: 60\n  poll: 5\n', 'name: My long runing task\nsome_module_name:\n  ip: ""{{item.fabric}}""\n  username: ""{{user}}""\n  password: ""{{password}}""\n  secret: ""{{secret}}""\nloop: ""{{zoning_list}}""\nregister: _alias_vc_0\nasync: 60\npoll: 0\n', '- name: My long runing task\n  some_module_name:\n    ip: ""{{item.fabric}}""\n    username: ""{{user}}""\n    password: ""{{password}}""\n    secret: ""{{secret}}""\n  loop: ""{{zoning_list}}""\n  register: _alias_vc_0\n  async: 60\n  poll: 0\n\n\n- name: Wait for My long running task to finish\n  async_status:\n    id: ""{{ item.ansible_job_id }}""\n  register: _jobs_alias_vc_0\n  retries: 20\n  delay: 2\n  until: _jobs_alias_vc_0.finished\n  loop: ""{{_alias_vc_0.results}}""\n']"
587,5058,5018,CC BY-SA 4.0,2018-09-25T05:17:53.173,"<p>I eventually figured out that Clair server was running inside the container and its service ports - 6060 (API) and 6061 (Health) were available only inside the container context. I confirmed this by running these commands:</p>

<p>Command to see the open ports inside the clair container</p>

<p><code>docker-compose exec clair netstat -anp</code></p>

<p>Command to see the open ports inside the clairctl container</p>

<p><code>docker-compose exec clairctl netstat -anp</code></p>

<p>The clairctl analyze operation was failing inside the container as docker login context was not available inside. I figured out that I will have to expose the ports 6060, 6061 from inside Clair server outside the container context. Only then could it be visible using clairctl binary copied outside the container where the docker login context is available. I did the following three changes post which I could run the clairctl commands successfully.</p>

<ol>
<li>Copied the file <a href=""https://github.com/jgsqware/clairctl/blob/master/clairctl.yml.default"" rel=""nofollow noreferrer"">https://github.com/jgsqware/clairctl/blob/master/clairctl.yml.default</a> as clairctl.yml into $HOME directory from where I had done docker login and was running clairctl commands.</li>
<li>Updated the value of <code>uri</code> parameter in above file from <code>uri: http://clair</code> to <code>uri: http://localhost</code></li>
<li><p>Added the <code>ports</code> clause in section for <code>clair</code> into file /root/go/src/github.com/jgsqware/clairctl/docker-compose.yml as seen below</p>

<pre><code>  clair:
    image: quay.io/coreos/clair:v2.0.0
    restart: unless-stopped
    ports:
      - ""6060:6060""
      - ""6061:6061""
</code></pre></li>
</ol>

<p>This exposed the ports 6060, 6061 inside the clair container to the localhost, after which commands like <code>clairctl health</code> and <code>clairctl analyze &lt;container-image-name&gt;</code> worked successfully.</p>
",9890,2018-09-25T05:17:53.173,"['  clair:\n    image: quay.io/coreos/clair:v2.0.0\n    restart: unless-stopped\n    ports:\n      - ""6060:6060""\n      - ""6061:6061""\n']"
588,5062,5024,CC BY-SA 4.0,2018-09-25T21:53:35.030,"<p>You need apply Continuos integration, so exist many combinations but general you need know your </p>

<p>1.-Programming language.</p>

<p>2.-Operative System and version. </p>

<p>3.-Data type( sql, mongodb,file, etc).</p>

<p>4.-Protocol communication and port.</p>

<p>5.-A script that check o verify outputs.</p>

<p>6.-A file with result/or flag</p>

<p><a href=""https://travis-ci.org"" rel=""nofollow noreferrer"">travis</a> is very well option, because they run test with his machines, and too you can add service git(github option) , with file script called <code>.travis</code> you can run your test, exist other ci services and integrations but general working like it(without docker).   </p>

<pre><code>language: python
cache: pip
python:
  - '3.5'
  - '3.6'

install: pip install -r requirements-dev.txt
script: pytest
deploy:
  provider: pypi
  user: acme-bot
  password:
    secure: ""&lt;something long&gt;""
  distributions: sdist bdist_wheel
  on:
    tags: true

matrix:
  include:
</code></pre>

<p>Well if you network communication require additional service networs you too need a service VPN </p>
",9398,2018-09-25T21:53:35.030,"['language: python\ncache: pip\npython:\n  - \'3.5\'\n  - \'3.6\'\n\ninstall: pip install -r requirements-dev.txt\nscript: pytest\ndeploy:\n  provider: pypi\n  user: acme-bot\n  password:\n    secure: ""<something long>""\n  distributions: sdist bdist_wheel\n  on:\n    tags: true\n\nmatrix:\n  include:\n']"
589,5067,5061,CC BY-SA 4.0,2018-09-26T16:13:03.347,"<p>I'm not aware of any way to do what you want with Declarative, but it certainly is possible with Scripted:</p>

<pre><code>try {
  // your Pipeline code here
} finally {
  if (!DeleteStack) { return }

  [
    CFTBatchStackName,
    CFTVPCStackName,
    CFTSelfDeleteName,
  ].each { stack-&gt;
    withAWS(region:'us-west-2', credentials:'jenkins-deploy') {
      def outputs = cfnDelete(
        stack: stack,
        pollInterval: 1000,
      )
    }
  }
}
</code></pre>
",4115,2018-09-26T16:13:03.347,"[""try {\n  // your Pipeline code here\n} finally {\n  if (!DeleteStack) { return }\n\n  [\n    CFTBatchStackName,\n    CFTVPCStackName,\n    CFTSelfDeleteName,\n  ].each { stack->\n    withAWS(region:'us-west-2', credentials:'jenkins-deploy') {\n      def outputs = cfnDelete(\n        stack: stack,\n        pollInterval: 1000,\n      )\n    }\n  }\n}\n""]"
590,5072,5070,CC BY-SA 4.0,2018-09-27T07:21:56.887,"<p>Remove <em>use_regex: yes</em>. Quoting from the <a href=""https://docs.ansible.com/ansible/latest/modules/find_module.html"" rel=""nofollow noreferrer"">doc</a></p>

<blockquote>
  <p>If false the patterns are file globs (shell) if true they are python regexes.</p>
</blockquote>

<p>If you want to use Python regex then the pattern would be probably something like this</p>

<pre><code>patterns: '[j]{2}.[j]{2}'
</code></pre>

<p>You probably want to append to file <strong>>></strong></p>

<pre><code>echo {{ item.path }} &gt;&gt; /tmp/results.txt
</code></pre>
",7715,2018-09-27T07:42:11.813,"[""patterns: '[j]{2}.[j]{2}'\n"", 'echo {{ item.path }} >> /tmp/results.txt\n']"
591,5078,3264,CC BY-SA 4.0,2018-09-28T08:28:26.247,"<p>Yes, you can do this with AWS Systems manager. AWS Systems Manager Run Command allows you to remotely and securely run set of commands on EC2 as well on-premise server. Below are high-level steps to achieve this.</p>

<p>Attach Instance IAM role:
The ec2 instance must have IAM role with policy AmazonSSMFullAccess. This role enables the instance to communicate with the Systems Manager API.</p>

<p>Install SSM Agent:
The EC2 instance must have SSM agent installed on it. The SSM Agent process the run command requests &amp; configure the instance as per command.</p>

<p>Execute command :
Example usage via AWS CLI:</p>

<p>Execute the following command to retrieve the services running on the instance. Replace Instance-ID with ec2 instance id.</p>

<pre><code>aws ssm send-command --document-name ""AWS-RunShellScript"" --comment ""listing services"" --instance-ids ""Instance-ID"" --parameters commands=""service --status-all"" --region us-west-2 --output text
</code></pre>

<p>More detailed information: <a href=""https://www.justdocloud.com/2018/04/01/run-commands-remotely-ec2-instances/"" rel=""nofollow noreferrer"">here</a></p>
",10071,2018-09-28T17:03:47.560,"['aws ssm send-command --document-name ""AWS-RunShellScript"" --comment ""listing services"" --instance-ids ""Instance-ID"" --parameters commands=""service --status-all"" --region us-west-2 --output text\n']"
592,5090,5089,CC BY-SA 4.0,2018-09-30T21:50:55.490,"<p>You've got a couple of options:</p>

<h3>1. Embed the source code to the CloudFormation template</h3>

<p>I do just that in my <a href=""https://github.com/mludvig/ec2-start-stop"" rel=""nofollow noreferrer"">ec2-start-stop</a> demo. You'll see file <code>ec2-start-stop.template.yml</code> with these lines:</p>

<pre><code>    StartStopLambda:
      Type: AWS::Lambda::Function
      Properties:
        [...]
        Runtime: python3.6
        Code: 
          ZipFile:
            Fn::Join:
            [...]
            -     
              - ""%%{ec2-start-stop.lambda.py}%%""
</code></pre>

<p>Then I've got the actual Python script referred in the <code>%%{ec2-start-stop.lambda.py}%%</code> and a simple <code>import-files.py</code> script that <em>somewhat intelligently</em> embeds the python file into the yaml file and creates a valid standalone CloudFormation template with the lambda code in it.</p>

<p>Note that you're limited to 4096 bytes including new lines for your lambda code.</p>

<hr>

<h3>2. Use <code>aws cloudformation package / deploy</code></h3>

<p>If you've got a more complex Lambda that needs external libraries or doesn't fit in the 4kB limit you can use <code>aws cloudformation package</code> and <code>aws cloudformation deploy</code> to facilitate the deployment to CI/CD.</p>

<p>In this case your <em>Lambda resource</em> in the template points to a local directory, e.g. <code>lambda/</code>. The <code>package</code> command then zips up the contents of the directory, uploads to the provided <em>S3 Bucket</em> with a unique name and generates an updated CFN template with the link to the uploaded file. The <code>aws cloudformation deploy</code> command then takes the template, creates a <em>change set</em> and applies the changes, thus updating the Lambda.</p>

<hr>

<p>I've used both methods in CI/CD pipelines and both work well because the source files are kept in separate files until deployment.</p>

<p>Hope that helps :)</p>
",8800,2018-09-30T21:50:55.490,"['    StartStopLambda:\n      Type: AWS::Lambda::Function\n      Properties:\n        [...]\n        Runtime: python3.6\n        Code: \n          ZipFile:\n            Fn::Join:\n            [...]\n            -     \n              - ""%%{ec2-start-stop.lambda.py}%%""\n']"
593,5098,5095,CC BY-SA 4.0,2018-10-02T13:00:24.103,"<p><strong>Short version</strong>  </p>

<p><code>VOLUME</code> instruction and <code>-v dest</code> are used to create unnamed/anonymous volumes, <code>-v scr:dest</code> option is for mapped volume.</p>

<p><strong>Long Version</strong></p>

<p>Dockerfile's <code>VOLUME</code> does not allow you to specify a host path.<br>
On the host-side, the volumes are created with a very long ID-like name, these volumes are often referred to as unnamed/anonymous volumes.</p>

<p>Given this Dockerfile:</p>

<pre><code>FROM php7:latest
VOLUME /var/www
</code></pre>

<p>Build it:</p>

<pre><code>docker build -t myTest
</code></pre>

<p>Run it :</p>

<pre><code>docker run --rm -it myTest
</code></pre>

<p>Inside the container, run <code>ls</code> and you'll notice the directory exists; <code>/var/www</code> </p>

<p>Running the container also creates a directory on the host-side.</p>

<p>While having the container running, execute <code>docker volume ls</code> on the host machine and you'll see something like this </p>

<pre><code>DRIVER    VOLUME NAME
local     c984..e4fc
</code></pre>

<p>Back in the <em>container</em>, execute <code>touch /var/www/myFile</code></p>

<p>This file is now available on the host machine, in one of the unnamed volumes. </p>

<pre><code>ls /var/lib/docker/volumes/c984..e4fc/_data
</code></pre>

<p>Similarly, you can try to delete this file on the host and it will be deleted in the container as well.</p>

<p>Now run a new container, but specify a volume using <code>-v</code>:</p>

<pre><code>docker run --rm -it -v /myVolume myTest
</code></pre>

<p>This <em>adds</em> a second volume and the whole system ends up having two unnamed volumes.
On the host-side, the new second volume is anonymous and resides together with the other volume in <code>/var/lib/docker/volumes/</code>.</p>

<p>It was stated earlier that the <code>Dockerfile</code> can not map to a host path which sort of pose a problem for us when trying to bring files in from the host to the container during runtime. A different <code>-v</code> syntax solves this problem.</p>

<p>Imagine I have a subfolder in my project directory <code>./src</code> that I wish to sync to <code>/src</code> inside the container. This command does the trick:</p>

<pre><code>docker run -it -v $(pwd)/src:/src myTest
</code></pre>

<p>Both sides of the <code>:</code> character expects an absolute path. Left side being an absolute path on the host machine, right side being an absolute path inside the container.</p>

<p>We run this command:</p>

<pre><code>docker run -v $(pwd)/src:/src myTest
</code></pre>

<p><strong>Is the specification purely informational?</strong></p>

<p>No, it does mount a volume, it's similar to <code>-v /var/www</code> you just don't specify a mount point in the host machine, so docker will take care of it.</p>

<p><strong>What are the (dis)advantages of (not) specifying volumes?</strong><br>
<strong>Why and in which cases should I use VOLUME and when shouldn't I?</strong></p>

<p>It's probably a best practice to never use <code>VOLUME</code>.<br>
The first reason we have already identified: We can not specify the host path.<br>
The second reason is people might forget to use the <code>--rm</code> option when running the container, you will end up with a couple of unused volumes and it might be a daunting task to figure out which of all anonymous volumes are safe to remove </p>

<p><strong>What about files that may optionally be mounted? Do they count as volumes in that case, too?</strong></p>

<p>In this case you don't need volumes; mapping a single file does not make sense, I would use <code>ADD</code> or <code>COPY</code> inside the dockerfile.</p>
",800,2018-10-02T14:25:31.027,"['FROM php7:latest\nVOLUME /var/www\n', 'docker build -t myTest\n', 'docker run --rm -it myTest\n', 'DRIVER    VOLUME NAME\nlocal     c984..e4fc\n', 'ls /var/lib/docker/volumes/c984..e4fc/_data\n', 'docker run --rm -it -v /myVolume myTest\n', 'docker run -it -v $(pwd)/src:/src myTest\n', 'docker run -v $(pwd)/src:/src myTest\n']"
594,5109,4968,CC BY-SA 4.0,2018-10-03T22:04:31.603,"<p>@chupasaurus gave an answer based on a multi-repo solution. </p>

<p>Based on this <a href=""https://stackoverflow.com/a/45507614/3223737"">answer</a>, I came up with the following jenkins pipeline approach. I've decided to build and test the whole solution, but you can use the same approach from ""Push Image"" stage to build and test only the changed services.</p>

<pre><code>pipeline {
agent any
environment {
    CHANGES = getChangeLog()
}
stages {
    stage('Build') {
        steps {
            bat 'dotnet clean solutionFile.sln'
            bat 'dotnet build solutionFile.sln'
        }
    }
    stage('Test') {
        steps {
            bat 'dotnet test solutionFile.sln --no-build --logger:trx;LogFileName=results.trx'
            // parse tests
        }
    }
    stage('Push Image') {
        stage('serviceA') {
            when {
                allOf {
                        expression {
                            hasChanged = powershell(returnStdout: true, script: '""$env:CHANGES"" -like ""*serviceA*"").trim() // check if any file path contains ""serviceA""
                            return  hasChanged == ""True"" 
                        }
                        branch 'master'
                }                        
            }
            steps {   
                // set tag or use latest by default from docker-compose      
                bat 'docker-compose build serviceA.api'
                bat 'docker-compose push registry/serviceA.api'
            }
        }
    }
    stage('Deploy Image') {
        stage('serviceA') {
            // deploy image code
        }
    }
}

def getChangeLog(){
    def changes = """"
    build = currentBuild
    while(build != null &amp;&amp; build.result != 'SUCCESS') {
        changes += ""In ${build.id}:\n""
        for (changeLog in build.changeSets) {
            for(entry in changeLog.items) {
                for(file in entry.affectedFiles) {
                    changes += ""${file.path}\n""
                }
            }
        }
        build = build.previousBuild
    }
    echo changes
    return changes
}
</code></pre>

<p>This code isn't fully tested, I just wanted to give a practical approach.</p>
",9772,2018-10-03T22:04:31.603,"['pipeline {\nagent any\nenvironment {\n    CHANGES = getChangeLog()\n}\nstages {\n    stage(\'Build\') {\n        steps {\n            bat \'dotnet clean solutionFile.sln\'\n            bat \'dotnet build solutionFile.sln\'\n        }\n    }\n    stage(\'Test\') {\n        steps {\n            bat \'dotnet test solutionFile.sln --no-build --logger:trx;LogFileName=results.trx\'\n            // parse tests\n        }\n    }\n    stage(\'Push Image\') {\n        stage(\'serviceA\') {\n            when {\n                allOf {\n                        expression {\n                            hasChanged = powershell(returnStdout: true, script: \'""$env:CHANGES"" -like ""*serviceA*"").trim() // check if any file path contains ""serviceA""\n                            return  hasChanged == ""True"" \n                        }\n                        branch \'master\'\n                }                        \n            }\n            steps {   \n                // set tag or use latest by default from docker-compose      \n                bat \'docker-compose build serviceA.api\'\n                bat \'docker-compose push registry/serviceA.api\'\n            }\n        }\n    }\n    stage(\'Deploy Image\') {\n        stage(\'serviceA\') {\n            // deploy image code\n        }\n    }\n}\n\ndef getChangeLog(){\n    def changes = """"\n    build = currentBuild\n    while(build != null && build.result != \'SUCCESS\') {\n        changes += ""In ${build.id}:\\n""\n        for (changeLog in build.changeSets) {\n            for(entry in changeLog.items) {\n                for(file in entry.affectedFiles) {\n                    changes += ""${file.path}\\n""\n                }\n            }\n        }\n        build = build.previousBuild\n    }\n    echo changes\n    return changes\n}\n']"
595,5116,3852,CC BY-SA 4.0,2018-10-04T14:04:35.853,"<p>I'm a little confused about the exact use case. Are you asking about writing to volumes that are mounted inside the container? </p>

<p>You can change what the process in the docker container runs as by using --user on your run commands.</p>

<pre><code>docker run --user 1000 --ti centos/7 /bin/bash
</code></pre>

<p>This answer may help you: 
<a href=""https://stackoverflow.com/questions/41100333/difference-between-docker-run-user-and-group-add-parameters"">https://stackoverflow.com/questions/41100333/difference-between-docker-run-user-and-group-add-parameters</a></p>

<p>The manual explains this as well: <a href=""https://docs.docker.com/engine/reference/run/#user"" rel=""nofollow noreferrer"">https://docs.docker.com/engine/reference/run/#user</a></p>
",7044,2018-10-04T14:04:35.853,['docker run --user 1000 --ti centos/7 /bin/bash\n']
596,5136,5087,CC BY-SA 4.0,2018-10-07T11:19:15.857,"<p>how we can extract the certificates from the kubeconfig file:</p>

<ol>
<li>Locate your kubeconfig or config file which you use to run kubectl commands. If you have used my Vagrant file above, you can find it on /etc/kubernetes/admin.conf</li>
<li><p>You need to export a single file (.p12) with the following two certificates: the client-certificate-data, and the client-key-data. My example runs the command on /home/vagrant. If you run this command on macOS, be sure to change the base64 -d to base64 -D</p>

<pre><code>$ grep 'client-certificate-data' ~/.kube/config | head -n 1 | awk '{print $2}' | base64 -d &gt;&gt; kubecfg.crt


$ grep 'client-key-data' ~/.kube/config | head -n 1 | awk '{print $2}' | base64 -d &gt;&gt; kubecfg.key


$ openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12
</code></pre></li>
<li><p>Import the kubecfg.p12 certificate, reopen your browser, and visit the Kubernetes Dashboard URL. Accept any warning and you should see the authentication page. You can skip the login and check you are not able to perform any task.</p></li>
<li><p>The following steps have been copied from the Kubernetes Dashboard wiki page (Creating-sample-user)</p>

<pre><code>    1- Create service account

        cat &lt;&lt;EOF | kubectl create -f -
        apiVersion: v1
        kind: ServiceAccount
        metadata:
          name: admin-user
          namespace: kube-system
        EOF
        &gt;&gt;

    2- Create ClusterRoleBinding

        cat &lt;&lt;EOF | kubectl create -f -
        apiVersion: rbac.authorization.k8s.io/v1
        kind: ClusterRoleBinding
        metadata:
          name: admin-user
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: cluster-admin
        subjects:
        - kind: ServiceAccount
          name: admin-user
          namespace: kube-system
        EOF
        &gt;&gt;

    3- Get the Bearer Token. Once you run the following command, copy the token value which you will use on the following step.

        $ kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')


    4- Come back to your browser and choose token on the login page. You will need to paste the token value you have copied on the previous step.
5- Click “SIGN IN” and you should be able to see your Kubernetes Dashboard fully operational.
</code></pre></li>
</ol>
",10216,2018-10-07T11:19:15.857,"[""$ grep 'client-certificate-data' ~/.kube/config | head -n 1 | awk '{print $2}' | base64 -d >> kubecfg.crt\n\n\n$ grep 'client-key-data' ~/.kube/config | head -n 1 | awk '{print $2}' | base64 -d >> kubecfg.key\n\n\n$ openssl pkcs12 -export -clcerts -inkey kubecfg.key -in kubecfg.crt -out kubecfg.p12\n"", ""    1- Create service account\n\n        cat <<EOF | kubectl create -f -\n        apiVersion: v1\n        kind: ServiceAccount\n        metadata:\n          name: admin-user\n          namespace: kube-system\n        EOF\n        >>\n\n    2- Create ClusterRoleBinding\n\n        cat <<EOF | kubectl create -f -\n        apiVersion: rbac.authorization.k8s.io/v1\n        kind: ClusterRoleBinding\n        metadata:\n          name: admin-user\n        roleRef:\n          apiGroup: rbac.authorization.k8s.io\n          kind: ClusterRole\n          name: cluster-admin\n        subjects:\n        - kind: ServiceAccount\n          name: admin-user\n          namespace: kube-system\n        EOF\n        >>\n\n    3- Get the Bearer Token. Once you run the following command, copy the token value which you will use on the following step.\n\n        $ kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '{print $1}')\n\n\n    4- Come back to your browser and choose token on the login page. You will need to paste the token value you have copied on the previous step.\n5- Click “SIGN IN” and you should be able to see your Kubernetes Dashboard fully operational.\n""]"
597,5145,3866,CC BY-SA 4.0,2018-10-09T09:08:56.510,"<p>There's a <a href=""https://www.jenkins.io/doc/pipeline/steps/workflow-multibranch/#resolvescm-resolves-an-scm-from-an-scm-source-and-a-list-of-candidate-target-branch-names"" rel=""nofollow noreferrer""><code>resolveScm</code> step</a> implemented by the <a href=""https://www.jenkins.io/doc/pipeline/steps/workflow-multibranch/"" rel=""nofollow noreferrer"">Pipeline: Multibranch plugin</a>:</p>
<pre><code>checkout resolveScm(source: [$class: 'GitSCMSource',
                             credentialsId: '&lt;credentialsId&gt;',
                             id: '_',
                             remote: 'https://your.git.remote/repository.git',
                             traits: [[$class: 'jenkins.plugins.git.traits.BranchDiscoveryTrait']]],
                    targets: [BRANCH_NAME, 'master'])
</code></pre>
<p>Above procedure will look whether <code>$BRANCH_NAME</code> exists, check it out if yes and check out <code>master</code> otherwise.</p>
",10243,2020-09-14T11:53:54.260,"[""checkout resolveScm(source: [$class: 'GitSCMSource',\n                             credentialsId: '<credentialsId>',\n                             id: '_',\n                             remote: 'https://your.git.remote/repository.git',\n                             traits: [[$class: 'jenkins.plugins.git.traits.BranchDiscoveryTrait']]],\n                    targets: [BRANCH_NAME, 'master'])\n""]"
598,5168,5106,CC BY-SA 4.0,2018-10-12T06:02:12.943,"<p>Did you try the variable <code>ServerlessRestApi</code>? It works for us like this:</p>

<pre><code>Outputs:    
    EncryptURL:
      Description: ""Encrypt endpoint URL for Stage environment""
      Value: !Sub ""https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Stage/encrypt""
</code></pre>
",7772,2018-10-12T06:02:12.943,"['Outputs:    \n    EncryptURL:\n      Description: ""Encrypt endpoint URL for Stage environment""\n      Value: !Sub ""https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Stage/encrypt""\n']"
599,5179,5174,CC BY-SA 4.0,2018-10-13T04:39:05.987,"<p>Use this command: </p>

<pre><code>docker-compose up --build
</code></pre>
",10285,2019-11-26T05:11:08.413,['docker-compose up --build\n']
600,5186,1390,CC BY-SA 4.0,2018-10-15T17:30:50.243,"<p>The args elements themselves need to be a string</p>

<pre><code>  args:
    - 'MAVEN_USER=$MAVEN_USER'
    - 'MAVEN_PASSWORD=$MAVEN_PASSWORD'
</code></pre>
",10348,2018-10-15T17:30:50.243,"[""  args:\n    - 'MAVEN_USER=$MAVEN_USER'\n    - 'MAVEN_PASSWORD=$MAVEN_PASSWORD'\n""]"
601,5189,3866,CC BY-SA 4.0,2018-10-16T06:59:59.200,"<pre><code>pipeline {
  agent any 
  stages { 
    stage('Tests') {
      when {
        branch 'master'
      }
      steps {
        echo 'foo'
      } 
   }
}
</code></pre>
",7370,2019-10-23T17:15:03.623,"[""pipeline {\n  agent any \n  stages { \n    stage('Tests') {\n      when {\n        branch 'master'\n      }\n      steps {\n        echo 'foo'\n      } \n   }\n}\n""]"
602,5201,5197,CC BY-SA 4.0,2018-10-17T21:48:15.480,"<p>It could be disk space, or hot deploy. For hot deploy, you can put the following parameters:</p>

<pre><code>...
&lt;target name=""tomcat-stop""&gt;
    &lt;exec executable=""${server.home}/bin/catalina.bat""&gt;
        &lt;arg value=""stop""/&gt;
    &lt;/exec&gt;
&lt;/target&gt;

&lt;target name=""tomcat-start""&gt;
    &lt;exec executable=""${server.home}/bin/startup.bat""&gt;
        &lt;arg value=""start""/&gt;
    &lt;/exec&gt;
&lt;/target&gt;
...
&lt;target name=""all"" depends=""tomcat-stop,clean,init,compile,junit-slow,make_war,deploy,tomcat-start""&gt;&lt;/target&gt;
</code></pre>

<p>The answer is at this link: <a href=""https://stackoverflow.com/a/32482795/8442153"">https://stackoverflow.com/a/32482795/8442153</a></p>
",9838,2018-10-17T21:48:15.480,"['...\n<target name=""tomcat-stop"">\n    <exec executable=""${server.home}/bin/catalina.bat"">\n        <arg value=""stop""/>\n    </exec>\n</target>\n\n<target name=""tomcat-start"">\n    <exec executable=""${server.home}/bin/startup.bat"">\n        <arg value=""start""/>\n    </exec>\n</target>\n...\n<target name=""all"" depends=""tomcat-stop,clean,init,compile,junit-slow,make_war,deploy,tomcat-start""></target>\n']"
603,5211,5196,CC BY-SA 4.0,2018-10-18T10:45:00.427,"<p>Most Dockerfiles start from a parent image. If you need to completely control the contents of your image, you might need to create a base image instead.
A base image either has no <code>FROM</code> line in its <code>Dockerfile</code>, or has <code>FROM</code> scratch.</p>

<h3>Create a full image using tar</h3>

<p>In general, start with a working machine that is running the distribution you’d like to package as a parent image, though that is not required for some tools like Debian’s Debootstrap, which you can also use to build Ubuntu images.</p>

<p>There are more example scripts for creating parent images in the Docker GitHub Repo:</p>

<pre><code>BusyBox
CentOS / Scientific Linux CERN (SLC) on Debian/Ubuntu or on CentOS/RHEL/SLC/etc.
Debian / Ubuntu
</code></pre>

<h3><a href=""https://docs.docker.com/develop/develop-images/baseimages/"" rel=""nofollow noreferrer"">Create a base image</a></h3>

<p>I guess after creating you can export this on docker hub with <code>Dockerfile</code>.</p>
",9404,2018-11-06T12:14:16.863,['BusyBox\nCentOS / Scientific Linux CERN (SLC) on Debian/Ubuntu or on CentOS/RHEL/SLC/etc.\nDebian / Ubuntu\n']
604,5217,5086,CC BY-SA 4.0,2018-10-19T14:05:36.757,"<p>I modified your Jenkins file as shown below. </p>

<pre><code>pipeline {
agent { label 'agent01'}
stages {
    stage('build') {
        steps {
            echo ""build""
            sh ""ls -lrt &amp;&amp; touch build.txt""
        }
    }
    stage('test') {
        parallel {
            stage('unit tests') {
                steps {
                    echo ""unit tests""
                    sh ""ls -lrt &amp;&amp; touch ut.txt""
                    sleep(time:10,unit:""SECONDS"")
                }
            }
            stage('integration tests') {
                steps {
                    echo ""integration tests""
                    sh ""ls -lrt &amp;&amp; touch it.txt""
                    sleep(time:10,unit:""SECONDS"")
                }
            }
        }
    }
    stage('deploy staging') {
        agent { label 'master' }
        steps {
            echo ""deploy staging""
            sh ""ls -lrt &amp;&amp; touch dep.txt""
        }
    }
    stage('confirm release') {
        agent { label 'master' }
        steps {
            echo ""RELEASE?""
            sh ""ls -lrt &amp;&amp; touch release.txt""
        }
    }
    stage('deploy production') {
        steps {
            echo ""deploy production""
            sh ""ls -lrt &amp;&amp; touch produ.txt""
        }
    }
}
}
</code></pre>

<ol>
<li>You need not stash and unstash files since it runs on same node and
    workspace. </li>
<li>Use a general node for all the stages except for the one that needs a user input.</li>
</ol>

<p>The output is </p>

<pre><code>    Running in Durability level: MAX_SURVIVABILITY
[Pipeline] node
Running on agent01 in /var/jenkins_home/workspace/sandbox-pipeline
[Pipeline] {
[Pipeline] stage
[Pipeline] { (build)
[Pipeline] echo
build
[Pipeline] sh
[sandbox-pipeline] Running shell script
+ ls -lrt
total 0
+ touch build.txt
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (test)
[Pipeline] parallel
[Pipeline]     [unit tests] { (Branch: unit tests)
[Pipeline]     [integration tests] { (Branch: integration tests)
[Pipeline]     [unit tests] stage
[Pipeline]     [unit tests] { (unit tests)
[Pipeline]     [integration tests] stage
[Pipeline]     [integration tests] { (integration tests)
[Pipeline]     [unit tests] echo
[unit tests] unit tests
[Pipeline]     [unit tests] sh
[unit tests]     [sandbox-pipeline] Running shell script
[Pipeline]     [integration tests] echo
[integration tests] integration tests
[Pipeline]     [integration tests] sh
[unit tests] + ls -lrt
[unit tests] total 0
[unit tests] -rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 build.txt
[unit tests] + touch ut.txt
[integration tests]     [sandbox-pipeline] Running shell script
[Pipeline]     [unit tests] sleep
[integration tests] + ls -lrt
[integration tests] total 0
[integration tests] -rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 build.txt
[integration tests] -rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 ut.txt
[integration tests] + touch it.txt
[unit tests] Sleeping for 10 sec
[Pipeline]     [integration tests] sleep
[integration tests] Sleeping for 10 sec
[Pipeline]     [unit tests] }
[Pipeline]     [unit tests] // stage
[Pipeline]     [unit tests] }
[Pipeline]     [integration tests] }
[Pipeline]     [integration tests] // stage
[Pipeline]     [integration tests] }
[Pipeline] // parallel
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (deploy staging)
[Pipeline] node
Running on Jenkins in /var/jenkins_home/workspace/sandbox-pipeline
[Pipeline] {
[Pipeline] echo
deploy staging
[Pipeline] sh
[sandbox-pipeline] Running shell script
+ ls -lrt
total 0
+ touch dep.txt
[Pipeline] }
[Pipeline] // node
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (confirm release)
[Pipeline] node
Running on Jenkins in /var/jenkins_home/workspace/sandbox-pipeline
[Pipeline] {
[Pipeline] echo
RELEASE?
[Pipeline] sh
[sandbox-pipeline] Running shell script
+ ls -lrt
total 0
-rw-r--r-- 1 jenkins 115 0 Oct 19 13:58 dep.txt
+ touch release.txt
[Pipeline] }
[Pipeline] // node
[Pipeline] }
[Pipeline] // stage
[Pipeline] stage
[Pipeline] { (deploy production)
[Pipeline] echo
deploy production
[Pipeline] sh
[sandbox-pipeline] Running shell script
+ ls -lrt
total 0
-rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 build.txt
-rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 ut.txt
-rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 it.txt
+ touch produ.txt
[Pipeline] }
[Pipeline] // stage
[Pipeline] }
[Pipeline] // node
[Pipeline] End of Pipeline
Finished: SUCCESS
</code></pre>
",7370,2018-10-19T14:05:36.757,"['pipeline {\nagent { label \'agent01\'}\nstages {\n    stage(\'build\') {\n        steps {\n            echo ""build""\n            sh ""ls -lrt && touch build.txt""\n        }\n    }\n    stage(\'test\') {\n        parallel {\n            stage(\'unit tests\') {\n                steps {\n                    echo ""unit tests""\n                    sh ""ls -lrt && touch ut.txt""\n                    sleep(time:10,unit:""SECONDS"")\n                }\n            }\n            stage(\'integration tests\') {\n                steps {\n                    echo ""integration tests""\n                    sh ""ls -lrt && touch it.txt""\n                    sleep(time:10,unit:""SECONDS"")\n                }\n            }\n        }\n    }\n    stage(\'deploy staging\') {\n        agent { label \'master\' }\n        steps {\n            echo ""deploy staging""\n            sh ""ls -lrt && touch dep.txt""\n        }\n    }\n    stage(\'confirm release\') {\n        agent { label \'master\' }\n        steps {\n            echo ""RELEASE?""\n            sh ""ls -lrt && touch release.txt""\n        }\n    }\n    stage(\'deploy production\') {\n        steps {\n            echo ""deploy production""\n            sh ""ls -lrt && touch produ.txt""\n        }\n    }\n}\n}\n', '    Running in Durability level: MAX_SURVIVABILITY\n[Pipeline] node\nRunning on agent01 in /var/jenkins_home/workspace/sandbox-pipeline\n[Pipeline] {\n[Pipeline] stage\n[Pipeline] { (build)\n[Pipeline] echo\nbuild\n[Pipeline] sh\n[sandbox-pipeline] Running shell script\n+ ls -lrt\ntotal 0\n+ touch build.txt\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (test)\n[Pipeline] parallel\n[Pipeline]     [unit tests] { (Branch: unit tests)\n[Pipeline]     [integration tests] { (Branch: integration tests)\n[Pipeline]     [unit tests] stage\n[Pipeline]     [unit tests] { (unit tests)\n[Pipeline]     [integration tests] stage\n[Pipeline]     [integration tests] { (integration tests)\n[Pipeline]     [unit tests] echo\n[unit tests] unit tests\n[Pipeline]     [unit tests] sh\n[unit tests]     [sandbox-pipeline] Running shell script\n[Pipeline]     [integration tests] echo\n[integration tests] integration tests\n[Pipeline]     [integration tests] sh\n[unit tests] + ls -lrt\n[unit tests] total 0\n[unit tests] -rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 build.txt\n[unit tests] + touch ut.txt\n[integration tests]     [sandbox-pipeline] Running shell script\n[Pipeline]     [unit tests] sleep\n[integration tests] + ls -lrt\n[integration tests] total 0\n[integration tests] -rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 build.txt\n[integration tests] -rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 ut.txt\n[integration tests] + touch it.txt\n[unit tests] Sleeping for 10 sec\n[Pipeline]     [integration tests] sleep\n[integration tests] Sleeping for 10 sec\n[Pipeline]     [unit tests] }\n[Pipeline]     [unit tests] // stage\n[Pipeline]     [unit tests] }\n[Pipeline]     [integration tests] }\n[Pipeline]     [integration tests] // stage\n[Pipeline]     [integration tests] }\n[Pipeline] // parallel\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (deploy staging)\n[Pipeline] node\nRunning on Jenkins in /var/jenkins_home/workspace/sandbox-pipeline\n[Pipeline] {\n[Pipeline] echo\ndeploy staging\n[Pipeline] sh\n[sandbox-pipeline] Running shell script\n+ ls -lrt\ntotal 0\n+ touch dep.txt\n[Pipeline] }\n[Pipeline] // node\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (confirm release)\n[Pipeline] node\nRunning on Jenkins in /var/jenkins_home/workspace/sandbox-pipeline\n[Pipeline] {\n[Pipeline] echo\nRELEASE?\n[Pipeline] sh\n[sandbox-pipeline] Running shell script\n+ ls -lrt\ntotal 0\n-rw-r--r-- 1 jenkins 115 0 Oct 19 13:58 dep.txt\n+ touch release.txt\n[Pipeline] }\n[Pipeline] // node\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] stage\n[Pipeline] { (deploy production)\n[Pipeline] echo\ndeploy production\n[Pipeline] sh\n[sandbox-pipeline] Running shell script\n+ ls -lrt\ntotal 0\n-rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 build.txt\n-rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 ut.txt\n-rw-r--r-- 1 jenkins docker 0 Oct 19 13:53 it.txt\n+ touch produ.txt\n[Pipeline] }\n[Pipeline] // stage\n[Pipeline] }\n[Pipeline] // node\n[Pipeline] End of Pipeline\nFinished: SUCCESS\n']"
605,5227,5225,CC BY-SA 4.0,2018-10-21T01:52:50.543,"<p>If run you <code>docker pull &lt;image&gt;</code>, you are implicitly asking for a tag named <code>latest</code>.  There is no such tag available from the Ansible repository.  You can see a list of available tags at <a href=""https://hub.docker.com/r/ansible/ansible/tags/"" rel=""nofollow noreferrer"">https://hub.docker.com/r/ansible/ansible/tags/</a>.</p>

<p>For example, if you wanted the <code>fedora27py3</code> version of the image, you would run:</p>

<pre><code>docker pull ansible/ansible:fedora27py3
</code></pre>

<p>I note that the most recent of thoses images is 7 months old. If you're experimenting iwth Ansible you might want to just install it into a Python virtual environment.</p>
",4011,2018-10-21T01:52:50.543,['docker pull ansible/ansible:fedora27py3\n']
606,5242,2526,CC BY-SA 4.0,2018-10-23T15:39:30.067,"<p>The <a href=""https://github.com/ncopa/su-exec"" rel=""nofollow noreferrer"">su-exec</a> program in this script is actually the Alpine version created by Natanael Copa.</p>

<p>It is installed from the OP's <a href=""https://github.com/31z4/zookeeper-docker/blob/d5d320f94212691bd6e60326e45c152ac6784210/3.4.10/Dockerfile"" rel=""nofollow noreferrer"">Dockerfile</a> on line 6.</p>

<p>The Alpine su-exec program is a substitute for <a href=""https://github.com/tianon/gosu"" rel=""nofollow noreferrer"">gosu</a>. Both programs are used to enable execution of a command as a specific user with the same environment variables and permissions as would normally be available to the user. </p>

<p>Thus you can effectively ""step down"" from root inside the container to run a specific command as a user and not as root.</p>

<p>So the alternative solution in Ubuntu would be to install gosu itself, which has no dependencies, and in the <code>docker-entrypoint.sh</code> script use:</p>

<pre><code>gosu ""$ZOO_USER"" ""$@""
</code></pre>

<p>(as per @alexey-shrub's comment below)</p>
",10469,2020-03-18T00:14:47.710,"['gosu ""$ZOO_USER"" ""$@""\n']"
607,5243,5240,CC BY-SA 4.0,2018-10-23T22:25:53.533,"<p>Sure, you can do this with Scripted Pipelines.  I've never tried to do it with Declarative so I'm not sure whether it's possible to do with Declarative or, if it is, if it's easy or straightforward.</p>

<p>Here's an example of what this might look like with a Scripted Pipeline.  I haven't tested it so there may be syntax errors or other problems.</p>

<pre><code>def parallelTopLevelSteps = [:]

parallelTopLevelSteps['A and B'] = {
  def parallelNestedSteps = [:]

  parallelNestedSteps['step A'] = { echo('A') }
  parallelNestedSteps['step B'] = { echo('B') }

  parallel(parallelNestedSteps)
}

parallelTopLevelSteps['C and D'] = {
  def parallelNestedSteps = [:]

  parallelNestedSteps['step C'] = { echo('C') }
  parallelNestedSteps['step D'] = { echo('D') }

  parallel(parallelNestedSteps)
}

parallel(parallelTopLevelSteps)
</code></pre>
",4115,2018-10-23T22:25:53.533,"[""def parallelTopLevelSteps = [:]\n\nparallelTopLevelSteps['A and B'] = {\n  def parallelNestedSteps = [:]\n\n  parallelNestedSteps['step A'] = { echo('A') }\n  parallelNestedSteps['step B'] = { echo('B') }\n\n  parallel(parallelNestedSteps)\n}\n\nparallelTopLevelSteps['C and D'] = {\n  def parallelNestedSteps = [:]\n\n  parallelNestedSteps['step C'] = { echo('C') }\n  parallelNestedSteps['step D'] = { echo('D') }\n\n  parallel(parallelNestedSteps)\n}\n\nparallel(parallelTopLevelSteps)\n""]"
608,5244,5173,CC BY-SA 4.0,2018-10-23T22:34:00.000,"<p>The other answer is incorrect.  There is indeed a builtin to retry arbitrary sections of your job called <a href=""https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#retry-retry-the-body-up-to-n-times"" rel=""noreferrer""><code>retry</code></a>.</p>

<p>If you want to retry the whole job three times, you can wrap your entire job in a <code>retry</code> block:</p>

<pre><code>retry(count: 3) {
  // your job definition here
}
</code></pre>

<p>However, if it's safe to do so, I would recommend wrapping individual steps or stages instead:</p>

<pre><code>stage('my first stage') {
  retry(count: 3) {
    sh('some-command')
    sh('some-other-command')
  }
}
</code></pre>
",4115,2018-10-23T22:34:00.000,"['retry(count: 3) {\n  // your job definition here\n}\n', ""stage('my first stage') {\n  retry(count: 3) {\n    sh('some-command')\n    sh('some-other-command')\n  }\n}\n""]"
609,5245,5203,CC BY-SA 4.0,2018-10-23T23:18:08.300,"<p>For Declarative Pipeline:</p>

<p>This question already has a <a href=""https://stackoverflow.com/a/44101004/1824868"">highly-upvoted answer on StackOverflow</a>:</p>

<blockquote>
  <p>If you want to use a file (since a script is the thing generating the value you need):</p>

<pre><code>pipeline {
  agent { label 'docker' }
  stages {
    stage('one') {
      steps {
        sh 'echo hotness &gt; myfile.txt'
        script {
          // trim removes leading and trailing whitespace from the string
          myVar = readFile('myfile.txt').trim()
        }
        echo ""${myVar}"" // prints 'hotness'
      }
    }
    stage('two') {
      steps {
        echo ""${myVar}"" // prints 'hotness'
      }
    }
    // this stage is skipped due to the when expression, so nothing is printed
    stage('three') {
      when {
        expression { myVar != 'hotness' }
      }
      steps {
        echo ""three: ${myVar}""
      }
    }
  }
}
</code></pre>
</blockquote>

<p>A second solution would be to write out output from your script directly or with <a href=""https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#writefile-write-file-to-workspace"" rel=""noreferrer""><code>writeFile</code></a> and then later read it back in with <a href=""https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#readfile-read-file-from-workspace"" rel=""noreferrer""><code>readFile</code></a>.  However, this comes with the significant caveat that both the reading and writing must take place on the same node, so you can't use this to send data across nodes.</p>

<p>You can also can archive files centrally with <a href=""https://jenkins.io/doc/pipeline/steps/core/#archiveartifacts-archive-the-artifacts"" rel=""noreferrer""><code>archiveArtifact</code></a> and retrieve them with <a href=""https://jenkins.io/doc/pipeline/steps/copyartifact/#copyartifacts-copy-artifacts-from-another-project"" rel=""noreferrer""><code>copyArtifact</code></a> (and then read in the file with <code>readFile</code>).</p>

<p>Finally, there are some answers to a <a href=""https://stackoverflow.com/q/47462500/1824868"">near-identical question on StackOverflow</a> that offer alternative solutions.</p>

<hr>

<p>However, if you can, I would suggest using Scripted Pipeline instead, which allows a much simpler solution:</p>

<pre><code>def String myVar

stage('my-first-stage') {
  myVar = sh(script: 'my-command', returnStdout: true)
}

stage('my-second-stage') {
  sh(""my-other-command --var='${myVar}'"")
}
</code></pre>

<p>(I also already answered this question for Scripted Pipeline over on <a href=""https://serverfault.com/a/884798/213070"">ServerFault</a>.)</p>

<hr>

<p>It looks like some of these solutions have already been proposed in the comments, but you are concerned that they are not elegant enough.  I'm not really sure what kind of elegance you're looking for, because I can't think of any way to simplify these answers in Jenkins-Pipeline-land.</p>
",4115,2018-11-26T04:24:55.493,"['pipeline {\n  agent { label \'docker\' }\n  stages {\n    stage(\'one\') {\n      steps {\n        sh \'echo hotness > myfile.txt\'\n        script {\n          // trim removes leading and trailing whitespace from the string\n          myVar = readFile(\'myfile.txt\').trim()\n        }\n        echo ""${myVar}"" // prints \'hotness\'\n      }\n    }\n    stage(\'two\') {\n      steps {\n        echo ""${myVar}"" // prints \'hotness\'\n      }\n    }\n    // this stage is skipped due to the when expression, so nothing is printed\n    stage(\'three\') {\n      when {\n        expression { myVar != \'hotness\' }\n      }\n      steps {\n        echo ""three: ${myVar}""\n      }\n    }\n  }\n}\n', 'def String myVar\n\nstage(\'my-first-stage\') {\n  myVar = sh(script: \'my-command\', returnStdout: true)\n}\n\nstage(\'my-second-stage\') {\n  sh(""my-other-command --var=\'${myVar}\'"")\n}\n']"
610,5253,5251,CC BY-SA 4.0,2018-10-25T01:59:38.453,"<p>Those images are the docker build cache. You need this to be able to quickly rebuild similar images, and to avoid rebuilding unchanged layers which would result in resending those to remote registry servers and forcing servers to download those unchanged layers again. One important point on these layers:</p>

<h1>They do not consume any significant disk space</h1>

<p>You can view the layers of an image by running the <code>docker image history</code> command on an image. Here's an example of a rather large image built on my machine:</p>

<pre><code>$ docker image history 25f90c8ba1ca
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
25f90c8ba1ca        11 days ago         /bin/sh -c #(nop)  CMD [""/bin/sh"" ""-c"" ""echo…   0B
8a190467427e        11 days ago         /bin/sh -c #(nop) COPY dir:36bb9e67a0f2844c2…   298MB
1f6f5474071d        11 days ago         /bin/sh -c #(nop) COPY dir:7c364877951bb2312…   249MB
007510a95d17        11 days ago         /bin/sh -c #(nop) COPY dir:9817b6e3d212385d0…   231MB
ee23b7a42488        11 days ago         /bin/sh -c #(nop) COPY dir:57e817f3d9d977f66…   277MB
e190d1bb3f66        11 days ago         /bin/sh -c #(nop) COPY dir:9ba997e629e74ca64…   205MB
abe0ec5c0ef9        11 days ago         /bin/sh -c #(nop) COPY dir:4dbbd5b2010590e28…   213MB
544af937d8a3        11 days ago         /bin/sh -c #(nop) COPY dir:0ac40edba2c7e1317…   178MB
b78085aba431        11 days ago         /bin/sh -c #(nop) COPY dir:2137a075c552d6783…   135MB
3ff8488b067b        11 days ago         /bin/sh -c #(nop) COPY dir:45da2005488e81e9c…   112MB
19b7cdd9d682        11 days ago         /bin/sh -c #(nop) COPY dir:2b745a4311740ddf7…   65.5MB
eb2cf84859fb        11 days ago         /bin/sh -c #(nop) COPY dir:cd7b639f2eee0e9da…   50.1MB
1ba1c21bb0a3        11 days ago         /bin/sh -c #(nop) COPY dir:594739607d1f2d593…   51.9MB
1da5d6bf03e9        11 days ago         /bin/sh -c #(nop) COPY dir:757daf68a395cfaae…   30MB
f6df8b695822        11 days ago         /bin/sh -c #(nop) COPY dir:449b6c2ff93606741…   18.5MB
72895d213dac        11 days ago         /bin/sh -c #(nop) COPY dir:2290eb8d11f15dbe6…   13.8MB
3b6ceadce77b        11 days ago         /bin/sh -c #(nop) COPY file:fcd71a6bfc87e9dd…   167B
52dd0e701be3        11 days ago         /bin/sh -c #(nop)  ENV TARGET=/usr/share/ngi…   0B
aae476eee77d        3 weeks ago         /bin/sh -c #(nop)  CMD [""nginx"" ""-g"" ""daemon…   0B
&lt;missing&gt;           3 weeks ago         /bin/sh -c #(nop)  STOPSIGNAL [SIGTERM]         0B
&lt;missing&gt;           3 weeks ago         /bin/sh -c #(nop)  EXPOSE 80/tcp                0B
&lt;missing&gt;           3 weeks ago         /bin/sh -c #(nop) COPY file:1d1ac3b9a14c94a7…   1.09kB
&lt;missing&gt;           3 weeks ago         /bin/sh -c #(nop) COPY file:af94db45bb7e4b8f…   643B
&lt;missing&gt;           3 weeks ago         /bin/sh -c GPG_KEYS=B0F4253373F8F6F510D42178…   13.3MB
&lt;missing&gt;           3 weeks ago         /bin/sh -c #(nop)  ENV NGINX_VERSION=1.15.5     0B
&lt;missing&gt;           4 weeks ago         /bin/sh -c #(nop)  LABEL maintainer=NGINX Do…   0B
&lt;missing&gt;           6 weeks ago         /bin/sh -c #(nop)  CMD [""/bin/sh""]              0B
&lt;missing&gt;           6 weeks ago         /bin/sh -c #(nop) ADD file:25c10b1d1b41d46a1…   4.41MB

$ docker image inspect --format '{{json .RootFS.Layers}}' 25f90c8ba1ca | jq
.
[
  ""sha256:df64d3292fd6194b7865d7326af5255db6d81e9df29f48adde61a918fbd8c332"",
  ""sha256:39e8483b9882aa8e95fb00c14e1c5dbdf32e836af4aff4bf862608e0a35bc914"",
  ""sha256:431a5c7929dd5848b9734d84d5cc5be237dd84e9e5ab1cb84ad6975bdc171c0c"",
  ""sha256:a83dbde6ba05e8112bd2732375ffbd350d9872d9c9e7e088ba5127118cd6d99e"",
  ""sha256:65ec7af97662fd3f933dc8b0aefb9f2d9d25c0d78530142bcdab1323c6aee223"",
  ""sha256:25212046c4c3a7589e45b426085da35d7e5e5a7a834180977a43df533672c360"",
  ""sha256:508c1d799f8da8accdd8b4e92964c73d6f9b8c4e7381fd0e1241e894d01418d3"",
  ""sha256:a197e87da4cd4587c8965d81878fbb1d898c8ba7d2a05ff0e9862eb700d26053"",
  ""sha256:f66588501183b7000c7683808ec4653bb83dc3c07f77d67fc34c78e9d9e5cb33"",
  ""sha256:de2288e4aa944daa6059184813c549d994f5c2407bfae61c7f8b4e0f950e73b1"",
  ""sha256:77ae40a90a8d41d53751ee800d4008d7a3706ecae6364560b4606ba0167c2674"",
  ""sha256:1a4bae64e86919b1f40e61a6022e8f910748566b88c2628893c4e424a60c74a2"",
  ""sha256:ca61f354107fc14de3c01f5bb192ff8b673b6f84c7089a23d754b23a65751310"",
  ""sha256:d0da652f2c59d6fb6380c0b6940aaa9f5e5a4fc28ae0b82f1acb5ccf9a1884e1"",
  ""sha256:5f3a91149be048f4f0a4d2450eab6ff8e630bb416b5c508633014e645f57df06"",
  ""sha256:0c0762559bcfec46462749615ee06b0998e61673e8118cd1a43e20b38e27825a"",
  ""sha256:581ad1603f59463febb540052046bbdec82bdfc7c75fd4a94578bdca88b91fec"",
  ""sha256:ff599edf8583ba1dfd7d9c79c1b718f94641e1fb644a0be29ca5b45dcc1768b4"",
  ""sha256:6ce4a45f89645a2020cfdae51c83470d9f24424ea16f4bddaf1244aa08f2945e"",
  ""sha256:5fcfba1ba609a8fbfc3eccbc805eb18a78041897ec3f6dc168c9ed871baed950""
]

$ docker image inspect --format '{{json .RootFS.Layers}}' 8a190467427e | jq .
[
  ""sha256:df64d3292fd6194b7865d7326af5255db6d81e9df29f48adde61a918fbd8c332"",
  ""sha256:39e8483b9882aa8e95fb00c14e1c5dbdf32e836af4aff4bf862608e0a35bc914"",
  ""sha256:431a5c7929dd5848b9734d84d5cc5be237dd84e9e5ab1cb84ad6975bdc171c0c"",
  ""sha256:a83dbde6ba05e8112bd2732375ffbd350d9872d9c9e7e088ba5127118cd6d99e"",
  ""sha256:65ec7af97662fd3f933dc8b0aefb9f2d9d25c0d78530142bcdab1323c6aee223"",
  ""sha256:25212046c4c3a7589e45b426085da35d7e5e5a7a834180977a43df533672c360"",
  ""sha256:508c1d799f8da8accdd8b4e92964c73d6f9b8c4e7381fd0e1241e894d01418d3"",
  ""sha256:a197e87da4cd4587c8965d81878fbb1d898c8ba7d2a05ff0e9862eb700d26053"",
  ""sha256:f66588501183b7000c7683808ec4653bb83dc3c07f77d67fc34c78e9d9e5cb33"",
  ""sha256:de2288e4aa944daa6059184813c549d994f5c2407bfae61c7f8b4e0f950e73b1"",
  ""sha256:77ae40a90a8d41d53751ee800d4008d7a3706ecae6364560b4606ba0167c2674"",
  ""sha256:1a4bae64e86919b1f40e61a6022e8f910748566b88c2628893c4e424a60c74a2"",
  ""sha256:ca61f354107fc14de3c01f5bb192ff8b673b6f84c7089a23d754b23a65751310"",
  ""sha256:d0da652f2c59d6fb6380c0b6940aaa9f5e5a4fc28ae0b82f1acb5ccf9a1884e1"",
  ""sha256:5f3a91149be048f4f0a4d2450eab6ff8e630bb416b5c508633014e645f57df06"",
  ""sha256:0c0762559bcfec46462749615ee06b0998e61673e8118cd1a43e20b38e27825a"",
  ""sha256:581ad1603f59463febb540052046bbdec82bdfc7c75fd4a94578bdca88b91fec"",
  ""sha256:ff599edf8583ba1dfd7d9c79c1b718f94641e1fb644a0be29ca5b45dcc1768b4"",
  ""sha256:6ce4a45f89645a2020cfdae51c83470d9f24424ea16f4bddaf1244aa08f2945e"",
  ""sha256:5fcfba1ba609a8fbfc3eccbc805eb18a78041897ec3f6dc168c9ed871baed950""
]

$ docker image inspect --format '{{json .RootFS.Layers}}' 1f6f5474071d | jq .
[
  ""sha256:df64d3292fd6194b7865d7326af5255db6d81e9df29f48adde61a918fbd8c332"",
  ""sha256:39e8483b9882aa8e95fb00c14e1c5dbdf32e836af4aff4bf862608e0a35bc914"",
  ""sha256:431a5c7929dd5848b9734d84d5cc5be237dd84e9e5ab1cb84ad6975bdc171c0c"",
  ""sha256:a83dbde6ba05e8112bd2732375ffbd350d9872d9c9e7e088ba5127118cd6d99e"",
  ""sha256:65ec7af97662fd3f933dc8b0aefb9f2d9d25c0d78530142bcdab1323c6aee223"",
  ""sha256:25212046c4c3a7589e45b426085da35d7e5e5a7a834180977a43df533672c360"",
  ""sha256:508c1d799f8da8accdd8b4e92964c73d6f9b8c4e7381fd0e1241e894d01418d3"",
  ""sha256:a197e87da4cd4587c8965d81878fbb1d898c8ba7d2a05ff0e9862eb700d26053"",
  ""sha256:f66588501183b7000c7683808ec4653bb83dc3c07f77d67fc34c78e9d9e5cb33"",
  ""sha256:de2288e4aa944daa6059184813c549d994f5c2407bfae61c7f8b4e0f950e73b1"",
  ""sha256:77ae40a90a8d41d53751ee800d4008d7a3706ecae6364560b4606ba0167c2674"",
  ""sha256:1a4bae64e86919b1f40e61a6022e8f910748566b88c2628893c4e424a60c74a2"",
  ""sha256:ca61f354107fc14de3c01f5bb192ff8b673b6f84c7089a23d754b23a65751310"",
  ""sha256:d0da652f2c59d6fb6380c0b6940aaa9f5e5a4fc28ae0b82f1acb5ccf9a1884e1"",
  ""sha256:5f3a91149be048f4f0a4d2450eab6ff8e630bb416b5c508633014e645f57df06"",
  ""sha256:0c0762559bcfec46462749615ee06b0998e61673e8118cd1a43e20b38e27825a"",
  ""sha256:581ad1603f59463febb540052046bbdec82bdfc7c75fd4a94578bdca88b91fec"",
  ""sha256:ff599edf8583ba1dfd7d9c79c1b718f94641e1fb644a0be29ca5b45dcc1768b4"",
  ""sha256:6ce4a45f89645a2020cfdae51c83470d9f24424ea16f4bddaf1244aa08f2945e""
]
</code></pre>

<p>In each of those inspect commands you should see that each new image is just adding on an extra layer until you reach the final image. These layers are the same sha256 checksums, pointing to the same files on the disk. Docker does not copy these files per image, it doesn't even copy them when creating containers (excluding initializing named volumes), the layers are read-only and reused by every descendant image and container via a union filesystem. The disk usage that docker displays is the sum of all of the layers even when other images may share layers, while your actual disk usage is only of the unique layers.</p>

<p>If you rebuild images often on the server with the same build tag, you can prune dangling images with <code>docker image prune</code>. Otherwise, simply avoid displaying these build artifacts by running <code>docker image ls</code> without the <code>-a</code> option.</p>
",7730,2018-10-25T01:59:38.453,"['$ docker image history 25f90c8ba1ca\nIMAGE               CREATED             CREATED BY                                      SIZE                COMMENT\n25f90c8ba1ca        11 days ago         /bin/sh -c #(nop)  CMD [""/bin/sh"" ""-c"" ""echo…   0B\n8a190467427e        11 days ago         /bin/sh -c #(nop) COPY dir:36bb9e67a0f2844c2…   298MB\n1f6f5474071d        11 days ago         /bin/sh -c #(nop) COPY dir:7c364877951bb2312…   249MB\n007510a95d17        11 days ago         /bin/sh -c #(nop) COPY dir:9817b6e3d212385d0…   231MB\nee23b7a42488        11 days ago         /bin/sh -c #(nop) COPY dir:57e817f3d9d977f66…   277MB\ne190d1bb3f66        11 days ago         /bin/sh -c #(nop) COPY dir:9ba997e629e74ca64…   205MB\nabe0ec5c0ef9        11 days ago         /bin/sh -c #(nop) COPY dir:4dbbd5b2010590e28…   213MB\n544af937d8a3        11 days ago         /bin/sh -c #(nop) COPY dir:0ac40edba2c7e1317…   178MB\nb78085aba431        11 days ago         /bin/sh -c #(nop) COPY dir:2137a075c552d6783…   135MB\n3ff8488b067b        11 days ago         /bin/sh -c #(nop) COPY dir:45da2005488e81e9c…   112MB\n19b7cdd9d682        11 days ago         /bin/sh -c #(nop) COPY dir:2b745a4311740ddf7…   65.5MB\neb2cf84859fb        11 days ago         /bin/sh -c #(nop) COPY dir:cd7b639f2eee0e9da…   50.1MB\n1ba1c21bb0a3        11 days ago         /bin/sh -c #(nop) COPY dir:594739607d1f2d593…   51.9MB\n1da5d6bf03e9        11 days ago         /bin/sh -c #(nop) COPY dir:757daf68a395cfaae…   30MB\nf6df8b695822        11 days ago         /bin/sh -c #(nop) COPY dir:449b6c2ff93606741…   18.5MB\n72895d213dac        11 days ago         /bin/sh -c #(nop) COPY dir:2290eb8d11f15dbe6…   13.8MB\n3b6ceadce77b        11 days ago         /bin/sh -c #(nop) COPY file:fcd71a6bfc87e9dd…   167B\n52dd0e701be3        11 days ago         /bin/sh -c #(nop)  ENV TARGET=/usr/share/ngi…   0B\naae476eee77d        3 weeks ago         /bin/sh -c #(nop)  CMD [""nginx"" ""-g"" ""daemon…   0B\n<missing>           3 weeks ago         /bin/sh -c #(nop)  STOPSIGNAL [SIGTERM]         0B\n<missing>           3 weeks ago         /bin/sh -c #(nop)  EXPOSE 80/tcp                0B\n<missing>           3 weeks ago         /bin/sh -c #(nop) COPY file:1d1ac3b9a14c94a7…   1.09kB\n<missing>           3 weeks ago         /bin/sh -c #(nop) COPY file:af94db45bb7e4b8f…   643B\n<missing>           3 weeks ago         /bin/sh -c GPG_KEYS=B0F4253373F8F6F510D42178…   13.3MB\n<missing>           3 weeks ago         /bin/sh -c #(nop)  ENV NGINX_VERSION=1.15.5     0B\n<missing>           4 weeks ago         /bin/sh -c #(nop)  LABEL maintainer=NGINX Do…   0B\n<missing>           6 weeks ago         /bin/sh -c #(nop)  CMD [""/bin/sh""]              0B\n<missing>           6 weeks ago         /bin/sh -c #(nop) ADD file:25c10b1d1b41d46a1…   4.41MB\n\n$ docker image inspect --format \'{{json .RootFS.Layers}}\' 25f90c8ba1ca | jq\n.\n[\n  ""sha256:df64d3292fd6194b7865d7326af5255db6d81e9df29f48adde61a918fbd8c332"",\n  ""sha256:39e8483b9882aa8e95fb00c14e1c5dbdf32e836af4aff4bf862608e0a35bc914"",\n  ""sha256:431a5c7929dd5848b9734d84d5cc5be237dd84e9e5ab1cb84ad6975bdc171c0c"",\n  ""sha256:a83dbde6ba05e8112bd2732375ffbd350d9872d9c9e7e088ba5127118cd6d99e"",\n  ""sha256:65ec7af97662fd3f933dc8b0aefb9f2d9d25c0d78530142bcdab1323c6aee223"",\n  ""sha256:25212046c4c3a7589e45b426085da35d7e5e5a7a834180977a43df533672c360"",\n  ""sha256:508c1d799f8da8accdd8b4e92964c73d6f9b8c4e7381fd0e1241e894d01418d3"",\n  ""sha256:a197e87da4cd4587c8965d81878fbb1d898c8ba7d2a05ff0e9862eb700d26053"",\n  ""sha256:f66588501183b7000c7683808ec4653bb83dc3c07f77d67fc34c78e9d9e5cb33"",\n  ""sha256:de2288e4aa944daa6059184813c549d994f5c2407bfae61c7f8b4e0f950e73b1"",\n  ""sha256:77ae40a90a8d41d53751ee800d4008d7a3706ecae6364560b4606ba0167c2674"",\n  ""sha256:1a4bae64e86919b1f40e61a6022e8f910748566b88c2628893c4e424a60c74a2"",\n  ""sha256:ca61f354107fc14de3c01f5bb192ff8b673b6f84c7089a23d754b23a65751310"",\n  ""sha256:d0da652f2c59d6fb6380c0b6940aaa9f5e5a4fc28ae0b82f1acb5ccf9a1884e1"",\n  ""sha256:5f3a91149be048f4f0a4d2450eab6ff8e630bb416b5c508633014e645f57df06"",\n  ""sha256:0c0762559bcfec46462749615ee06b0998e61673e8118cd1a43e20b38e27825a"",\n  ""sha256:581ad1603f59463febb540052046bbdec82bdfc7c75fd4a94578bdca88b91fec"",\n  ""sha256:ff599edf8583ba1dfd7d9c79c1b718f94641e1fb644a0be29ca5b45dcc1768b4"",\n  ""sha256:6ce4a45f89645a2020cfdae51c83470d9f24424ea16f4bddaf1244aa08f2945e"",\n  ""sha256:5fcfba1ba609a8fbfc3eccbc805eb18a78041897ec3f6dc168c9ed871baed950""\n]\n\n$ docker image inspect --format \'{{json .RootFS.Layers}}\' 8a190467427e | jq .\n[\n  ""sha256:df64d3292fd6194b7865d7326af5255db6d81e9df29f48adde61a918fbd8c332"",\n  ""sha256:39e8483b9882aa8e95fb00c14e1c5dbdf32e836af4aff4bf862608e0a35bc914"",\n  ""sha256:431a5c7929dd5848b9734d84d5cc5be237dd84e9e5ab1cb84ad6975bdc171c0c"",\n  ""sha256:a83dbde6ba05e8112bd2732375ffbd350d9872d9c9e7e088ba5127118cd6d99e"",\n  ""sha256:65ec7af97662fd3f933dc8b0aefb9f2d9d25c0d78530142bcdab1323c6aee223"",\n  ""sha256:25212046c4c3a7589e45b426085da35d7e5e5a7a834180977a43df533672c360"",\n  ""sha256:508c1d799f8da8accdd8b4e92964c73d6f9b8c4e7381fd0e1241e894d01418d3"",\n  ""sha256:a197e87da4cd4587c8965d81878fbb1d898c8ba7d2a05ff0e9862eb700d26053"",\n  ""sha256:f66588501183b7000c7683808ec4653bb83dc3c07f77d67fc34c78e9d9e5cb33"",\n  ""sha256:de2288e4aa944daa6059184813c549d994f5c2407bfae61c7f8b4e0f950e73b1"",\n  ""sha256:77ae40a90a8d41d53751ee800d4008d7a3706ecae6364560b4606ba0167c2674"",\n  ""sha256:1a4bae64e86919b1f40e61a6022e8f910748566b88c2628893c4e424a60c74a2"",\n  ""sha256:ca61f354107fc14de3c01f5bb192ff8b673b6f84c7089a23d754b23a65751310"",\n  ""sha256:d0da652f2c59d6fb6380c0b6940aaa9f5e5a4fc28ae0b82f1acb5ccf9a1884e1"",\n  ""sha256:5f3a91149be048f4f0a4d2450eab6ff8e630bb416b5c508633014e645f57df06"",\n  ""sha256:0c0762559bcfec46462749615ee06b0998e61673e8118cd1a43e20b38e27825a"",\n  ""sha256:581ad1603f59463febb540052046bbdec82bdfc7c75fd4a94578bdca88b91fec"",\n  ""sha256:ff599edf8583ba1dfd7d9c79c1b718f94641e1fb644a0be29ca5b45dcc1768b4"",\n  ""sha256:6ce4a45f89645a2020cfdae51c83470d9f24424ea16f4bddaf1244aa08f2945e"",\n  ""sha256:5fcfba1ba609a8fbfc3eccbc805eb18a78041897ec3f6dc168c9ed871baed950""\n]\n\n$ docker image inspect --format \'{{json .RootFS.Layers}}\' 1f6f5474071d | jq .\n[\n  ""sha256:df64d3292fd6194b7865d7326af5255db6d81e9df29f48adde61a918fbd8c332"",\n  ""sha256:39e8483b9882aa8e95fb00c14e1c5dbdf32e836af4aff4bf862608e0a35bc914"",\n  ""sha256:431a5c7929dd5848b9734d84d5cc5be237dd84e9e5ab1cb84ad6975bdc171c0c"",\n  ""sha256:a83dbde6ba05e8112bd2732375ffbd350d9872d9c9e7e088ba5127118cd6d99e"",\n  ""sha256:65ec7af97662fd3f933dc8b0aefb9f2d9d25c0d78530142bcdab1323c6aee223"",\n  ""sha256:25212046c4c3a7589e45b426085da35d7e5e5a7a834180977a43df533672c360"",\n  ""sha256:508c1d799f8da8accdd8b4e92964c73d6f9b8c4e7381fd0e1241e894d01418d3"",\n  ""sha256:a197e87da4cd4587c8965d81878fbb1d898c8ba7d2a05ff0e9862eb700d26053"",\n  ""sha256:f66588501183b7000c7683808ec4653bb83dc3c07f77d67fc34c78e9d9e5cb33"",\n  ""sha256:de2288e4aa944daa6059184813c549d994f5c2407bfae61c7f8b4e0f950e73b1"",\n  ""sha256:77ae40a90a8d41d53751ee800d4008d7a3706ecae6364560b4606ba0167c2674"",\n  ""sha256:1a4bae64e86919b1f40e61a6022e8f910748566b88c2628893c4e424a60c74a2"",\n  ""sha256:ca61f354107fc14de3c01f5bb192ff8b673b6f84c7089a23d754b23a65751310"",\n  ""sha256:d0da652f2c59d6fb6380c0b6940aaa9f5e5a4fc28ae0b82f1acb5ccf9a1884e1"",\n  ""sha256:5f3a91149be048f4f0a4d2450eab6ff8e630bb416b5c508633014e645f57df06"",\n  ""sha256:0c0762559bcfec46462749615ee06b0998e61673e8118cd1a43e20b38e27825a"",\n  ""sha256:581ad1603f59463febb540052046bbdec82bdfc7c75fd4a94578bdca88b91fec"",\n  ""sha256:ff599edf8583ba1dfd7d9c79c1b718f94641e1fb644a0be29ca5b45dcc1768b4"",\n  ""sha256:6ce4a45f89645a2020cfdae51c83470d9f24424ea16f4bddaf1244aa08f2945e""\n]\n']"
611,5268,5214,CC BY-SA 4.0,2018-10-27T13:55:25.030,"<p>It can be done by modifying the <a href=""https://amazon-eks.s3-us-west-2.amazonaws.com/cloudformation/2018-08-30/amazon-eks-nodegroup.yaml"" rel=""nofollow noreferrer"">Cloudformation Template</a> (which is mentioned in this <a href=""https://docs.aws.amazon.com/eks/latest/userguide/launch-workers.html"" rel=""nofollow noreferrer"">document</a>) in the <code>LaunchConfiguration</code> section to specify a spot price.</p>

<pre><code>NodeLaunchConfig:
  Type: AWS::AutoScaling::LaunchConfiguration
  Properties:
    SpotPrice: ""20"" # &lt;=== Here
    AssociatePublicIpAddress: 'true'
    IamInstanceProfile: !Ref NodeInstanceProfile
    ImageId: !Ref NodeImageId
    InstanceType: !Ref NodeInstanceType
    KeyName: !Ref KeyName
    SecurityGroups:
    - !Ref NodeSecurityGroup
    BlockDeviceMappings:
      - DeviceName: /dev/xvda
        Ebs:
          VolumeSize: !Ref NodeVolumeSize
          VolumeType: gp2
          DeleteOnTermination: true
    UserData:
      Fn::Base64:
        !Sub |
          #!/bin/bash
          set -o xtrace
          /etc/eks/bootstrap.sh ${ClusterName} ${BootstrapArguments}
          /opt/aws/bin/cfn-signal --exit-code $? \
                   --stack  ${AWS::StackName} \
                   --resource NodeGroup  \
                   --region ${AWS::Region}
</code></pre>
",8675,2018-10-27T13:55:25.030,"['NodeLaunchConfig:\n  Type: AWS::AutoScaling::LaunchConfiguration\n  Properties:\n    SpotPrice: ""20"" # <=== Here\n    AssociatePublicIpAddress: \'true\'\n    IamInstanceProfile: !Ref NodeInstanceProfile\n    ImageId: !Ref NodeImageId\n    InstanceType: !Ref NodeInstanceType\n    KeyName: !Ref KeyName\n    SecurityGroups:\n    - !Ref NodeSecurityGroup\n    BlockDeviceMappings:\n      - DeviceName: /dev/xvda\n        Ebs:\n          VolumeSize: !Ref NodeVolumeSize\n          VolumeType: gp2\n          DeleteOnTermination: true\n    UserData:\n      Fn::Base64:\n        !Sub |\n          #!/bin/bash\n          set -o xtrace\n          /etc/eks/bootstrap.sh ${ClusterName} ${BootstrapArguments}\n          /opt/aws/bin/cfn-signal --exit-code $? \\\n                   --stack  ${AWS::StackName} \\\n                   --resource NodeGroup  \\\n                   --region ${AWS::Region}\n']"
612,5285,5275,CC BY-SA 4.0,2018-10-31T00:25:47.523,"<p>This can be done with <a href=""https://www.terraform.io/docs/providers/docker/d/registry_image.html"" rel=""nofollow noreferrer"">docker_registry_image</a>:</p>

<pre><code>data ""docker_registry_image"" ""ubuntu"" {
  name = ""ubuntu:latest""
}

resource ""docker_image"" ""ubuntu"" {
  name          = ""${data.docker_registry_image.ubuntu.name}""
  pull_triggers = [""${data.docker_registry_image.ubuntu.sha256_digest}""]
}
</code></pre>
",10262,2018-10-31T00:25:47.523,"['data ""docker_registry_image"" ""ubuntu"" {\n  name = ""ubuntu:latest""\n}\n\nresource ""docker_image"" ""ubuntu"" {\n  name          = ""${data.docker_registry_image.ubuntu.name}""\n  pull_triggers = [""${data.docker_registry_image.ubuntu.sha256_digest}""]\n}\n']"
613,5294,5291,CC BY-SA 4.0,2018-10-31T13:56:36.360,"<p>Given that this is symptomatic of rate limiting in Nginx in this case, the solution is to configure the <a href=""https://www.nginx.com/blog/rate-limiting-nginx/"" rel=""nofollow noreferrer"">rate limiting feature of Nginx to allow this</a></p>

<p>A whitelist could  be created in the configuration to remove ratelimiting from the url generating the traffic.</p>

<p>To follow the <a href=""https://docs.nginx.com/nginx/admin-guide/security-controls/controlling-access-proxied-http/#limiting-the-request-rate"" rel=""nofollow noreferrer"">Nginx documentation</a>, this could be specified as whitelisting an IP.</p>

<p>The current server setup is : </p>

<pre><code>limit_req_zone $binary_remote_addr zone=flood:10m rate=12r/s;
limit_req_zone $binary_remote_addr zone=bot:10m rate=200r/m;
limit_req_status 429;
limit_conn_zone $binary_remote_addr zone=connperip:10m;
limit_conn_status 429;
</code></pre>

<p>This sets up the rate limit on connections. A whitelist can be created as suggested above, by simulating a boolean condition with a key value map:</p>

<pre><code>geo $limit {
    default 1;
    10.0.0.0/8 0;
    192.168.0.0/24 0;
}

map $limit $limit_key {
    0 """";
    1 $binary_remote_addr;
}
</code></pre>

<p>This removes the rate limit (sets it to 0) if the remote address falls into the whitelist:</p>

<pre><code>limit_req_zone $limit_key zone=req_zone:10m rate=5r/s;

server {
    location / {
        limit_req zone=req_zone burst=10 nodelay;
</code></pre>
",354,2018-11-03T17:59:27.977,"['limit_req_zone $binary_remote_addr zone=flood:10m rate=12r/s;\nlimit_req_zone $binary_remote_addr zone=bot:10m rate=200r/m;\nlimit_req_status 429;\nlimit_conn_zone $binary_remote_addr zone=connperip:10m;\nlimit_conn_status 429;\n', 'geo $limit {\n    default 1;\n    10.0.0.0/8 0;\n    192.168.0.0/24 0;\n}\n\nmap $limit $limit_key {\n    0 """";\n    1 $binary_remote_addr;\n}\n', 'limit_req_zone $limit_key zone=req_zone:10m rate=5r/s;\n\nserver {\n    location / {\n        limit_req zone=req_zone burst=10 nodelay;\n']"
614,5298,2149,CC BY-SA 4.0,2018-10-31T21:34:12.483,"<p>Not sure if you sorted this out, but I had to do something similar to get who started the instance so I can badger them into stopping the instance if they are not using it. I put together a Logging query:</p>

<p><code>resource.type = gce_instance AND (jsonPayload.event_subtype = compute.instances.start OR jsonPayload.event_subtype = compute.instances.insert ) AND jsonPayload.event_type = GCE_OPERATION_DONE AND timestamp &gt;= ""2018-10-29T14:28:34-07:00"" AND jsonPayload.actor.user!="""" AND jsonPayload.resource.name=my-sweet-instance-name</code></p>

<p>And here is the nodejs function I put together to get it:</p>

<pre><code>const Logging   = require( '@google-cloud/logging' );
const moment    = require( 'moment' );

const logging   = new Logging( );




var getStartInfo = function( instanceName, querySince, cb ) {

    var tstart = ( querySince ? querySince : moment( ).subtract( 48, 'hours' ).format( ) ); // 

    var theLogFilter = 'resource.type = gce_instance AND ' +
        '(jsonPayload.event_subtype = compute.instances.start OR jsonPayload.event_subtype = compute.instances.insert ) AND ' +
        'jsonPayload.event_type = GCE_OPERATION_DONE AND ' +
        'timestamp &gt;= ""' + tstart + '"" AND ' +
        'jsonPayload.actor.user!="""" AND ' +
        'jsonPayload.resource.name=' + instanceName;

    logging.getEntries( {
        filter: theLogFilter,
        autoPaginate: false
    }, ( err, entries, nextQuery, apiResponse ) =&gt; {


        if ( err ) {
            console.log( ""ERROR: "" + err );
            cb( err );
            return;
        }

        var item, startedBy, startTime, runningTime, mostRecentStart;

        //console.log( 'Entries: ' + JSON.stringify( entries ) );
        // Mabye if none found, we try again with a longer querySince?
        if ( entries.length == 0 ) {

            console.log( ""\nNo log entries found for instance '"" + instanceName + ""'. Filter:"" );
            console.log( theLogFilter );
            cb( ""No entries found"" );
            return;
        }


        // Are these sorted by time?
        for ( var i = 0; i &lt; entries.length; i++ ) {


            startedBy = entries[ i ].metadata.jsonPayload.fields.actor.structValue.fields.user.stringValue;
            startTime = entries[ i ].metadata.jsonPayload.fields.event_timestamp_us.stringValue / 1000; // This is nano seconds since epoch

        }

        if ( cb )
            cb( null, { ""startedBy"": startedBy, ""startTime"": moment( startTime ).format() } );

    } );

}
</code></pre>

<p>Hopefully that helps someone because it was a good bit of work to put together.</p>
",10608,2018-10-31T21:34:12.483,"['const Logging   = require( \'@google-cloud/logging\' );\nconst moment    = require( \'moment\' );\n\nconst logging   = new Logging( );\n\n\n\n\nvar getStartInfo = function( instanceName, querySince, cb ) {\n\n    var tstart = ( querySince ? querySince : moment( ).subtract( 48, \'hours\' ).format( ) ); // \n\n    var theLogFilter = \'resource.type = gce_instance AND \' +\n        \'(jsonPayload.event_subtype = compute.instances.start OR jsonPayload.event_subtype = compute.instances.insert ) AND \' +\n        \'jsonPayload.event_type = GCE_OPERATION_DONE AND \' +\n        \'timestamp >= ""\' + tstart + \'"" AND \' +\n        \'jsonPayload.actor.user!="""" AND \' +\n        \'jsonPayload.resource.name=\' + instanceName;\n\n    logging.getEntries( {\n        filter: theLogFilter,\n        autoPaginate: false\n    }, ( err, entries, nextQuery, apiResponse ) => {\n\n\n        if ( err ) {\n            console.log( ""ERROR: "" + err );\n            cb( err );\n            return;\n        }\n\n        var item, startedBy, startTime, runningTime, mostRecentStart;\n\n        //console.log( \'Entries: \' + JSON.stringify( entries ) );\n        // Mabye if none found, we try again with a longer querySince?\n        if ( entries.length == 0 ) {\n\n            console.log( ""\\nNo log entries found for instance \'"" + instanceName + ""\'. Filter:"" );\n            console.log( theLogFilter );\n            cb( ""No entries found"" );\n            return;\n        }\n\n\n        // Are these sorted by time?\n        for ( var i = 0; i < entries.length; i++ ) {\n\n\n            startedBy = entries[ i ].metadata.jsonPayload.fields.actor.structValue.fields.user.stringValue;\n            startTime = entries[ i ].metadata.jsonPayload.fields.event_timestamp_us.stringValue / 1000; // This is nano seconds since epoch\n\n        }\n\n        if ( cb )\n            cb( null, { ""startedBy"": startedBy, ""startTime"": moment( startTime ).format() } );\n\n    } );\n\n}\n']"
615,5311,4503,CC BY-SA 4.0,2018-11-02T10:03:58.563,"<p>This mighty be a lengthy procedure but worth implementing, <strong>creating child tokens to fetch information from Vault Server</strong>.</p>
<p>Execute following procedure at Vault Server.</p>
<blockquote>
<ol>
<li>Create policy to restrict the access for clients.</li>
</ol>
</blockquote>
<pre><code>cat auth-policy.hcl 
path &quot;secret/*&quot; {
  capabilities = [&quot;read&quot;]
}
</code></pre>
<blockquote>
<ol start=""2"">
<li>Write the policy</li>
</ol>
</blockquote>
<pre><code>vault policy write client-access auth-policy.hcl                         
Success! Uploaded policy: client-access 
</code></pre>
<blockquote>
<ol start=""3"">
<li>Create token</li>
</ol>
</blockquote>
<pre><code>vault token create -policy=client-access -period=768h                                    
                                                                                
Key                Value                                                        
---                -----                                                        
token              *********************                         
token_accessor     *********************                         
token_duration     768h                                                         
token_renewable    true                                                         
token_policies     [client-access default]  
-----------------------------------------------
vault policy write client-access auth-policy.hcl                         
Success! Uploaded policy: client-access 
</code></pre>
<p>Configure <code>-period</code> in hours. Token should be renewed after configured period of time. Configure expiry period accordingly by considering <code>max_lease_ttl</code> and <code>default_lease_ttl</code> in <code>config.hcl</code>.</p>
<p>Configure these parameters in <code>config.hcl</code> during Vault startup.</p>
<pre><code>max_lease_ttl = &quot;1000h&quot;
default_lease_ttl = &quot;1000h&quot;
</code></pre>
<p>Now using this child token, from your laptop/machine, you will be able to fetch the information from Vault server, using APIs.</p>
<pre><code>$ curl -sH &quot;X-Vault-Token: CHILD-TOKEN&quot; -X GET VAULT-URL/v1/secret/SECRET | jq
{
  &quot;request_id&quot;: &quot;e53887a2-fe5a-2f27-2121-c716a697f0e8&quot;,
  &quot;lease_id&quot;: &quot;&quot;,
  &quot;renewable&quot;: false,
  &quot;lease_duration&quot;: 25920000,
  &quot;data&quot;: {
    **************
    **************
  },
  &quot;wrap_info&quot;: null,
  &quot;warnings&quot;: null,
  &quot;auth&quot;: null
}
</code></pre>
<p>With this child token, <strong>users can only read the data but neither write or delete data as configured in <code>auth-policy</code></strong>.</p>
<p>If you still want to secure child token you can save it in Jenkins credentials and will be fetched into bash script when build triggered.</p>
",2412,2021-03-20T12:39:03.067,"['cat auth-policy.hcl \npath ""secret/*"" {\n  capabilities = [""read""]\n}\n', 'vault policy write client-access auth-policy.hcl                         \nSuccess! Uploaded policy: client-access \n', 'vault token create -policy=client-access -period=768h                                    \n                                                                                \nKey                Value                                                        \n---                -----                                                        \ntoken              *********************                         \ntoken_accessor     *********************                         \ntoken_duration     768h                                                         \ntoken_renewable    true                                                         \ntoken_policies     [client-access default]  \n-----------------------------------------------\nvault policy write client-access auth-policy.hcl                         \nSuccess! Uploaded policy: client-access \n', 'max_lease_ttl = ""1000h""\ndefault_lease_ttl = ""1000h""\n', '$ curl -sH ""X-Vault-Token: CHILD-TOKEN"" -X GET VAULT-URL/v1/secret/SECRET | jq\n{\n  ""request_id"": ""e53887a2-fe5a-2f27-2121-c716a697f0e8"",\n  ""lease_id"": """",\n  ""renewable"": false,\n  ""lease_duration"": 25920000,\n  ""data"": {\n    **************\n    **************\n  },\n  ""wrap_info"": null,\n  ""warnings"": null,\n  ""auth"": null\n}\n']"
616,5312,4453,CC BY-SA 4.0,2018-11-02T10:29:59.147,"<p>The set of errors are same that we have observed <strong>during TLS integration in Vault</strong>.</p>

<p>As stated by @Colin, <strong>change VAULT_ADDR to HTTPS</strong>, VAULT_ADDR=<a href=""https://mydomain.com"" rel=""nofollow noreferrer"">https://mydomain.com</a> </p>

<p>Along with that <strong>change listener tcp address in vault.hcl</strong> as follows:</p>

<pre><code>listener ""tcp"" {
  address = ""0.0.0.0:8200""
  tls_disable = 0
  tls_cert_file = ""***""
  tls_key_file = ""***""
}
</code></pre>

<p>Hope this works for you as well!</p>
",2412,2018-11-02T10:29:59.147,"['listener ""tcp"" {\n  address = ""0.0.0.0:8200""\n  tls_disable = 0\n  tls_cert_file = ""***""\n  tls_key_file = ""***""\n}\n']"
617,5313,3442,CC BY-SA 4.0,2018-11-02T11:39:51.297,"<p>Here's the way I do it: no plugin required, just triggering Jenkins <code>api</code> from gitlab-ci.</p>

<h2>Gitlab-CI</h2>

<p>I will assume you have a gitlab-ci runner installed and configured.</p>

<p>First, you need to have a <code>.gitlab-ci.yml</code> file in your project having a basic structure such as:</p>

<pre><code>stages:
- my-jenkins-trigger
variables:
 MY_VARIABLE: ""EVERYTHING_IS_AWESOME""

my-jenkins-trigger-job:
 stage: my-jenkins-trigger
 script: curl -i -X POST --user JENKINS_USER:JENKINS_TOKEN JENKINS_JOB_URL/buildWithParameters?MY_JENK_PARAM=${MY_VARIABLE}
</code></pre>

<p>In the above, I also assume </p>

<ul>
<li>You have a Jenkins job somewhere at URL <code>JENKINS_JOB_URL</code></li>
<li>this Jenkins job has a build parameter called <code>MY_VARIABLE</code></li>
<li><code>JENKINS_USER</code>, <code>JENKINS_TOKEN</code> are defined [*]</li>
</ul>

<h2>That simple?</h2>

<p>Well yes, but no...</p>

<p>That is the rough structure. That script will merely trigger a Jenkins job and forget about it. You need to work a little more to monitor the job and feed its status back in Gitlab-CI, manage security and possibly get some commit info from gitlab to inject into your job.</p>

<h2>Monitoring</h2>

<p>In order to have a proper monitoring, I recommand to write a full <em>trigger + monitor + return value</em> script [** ] (in whatever language available or you're familiar with).</p>

<p>Just start by triggering the job as I stated above.</p>

<p>Then, run a <code>while</code> loop (don't forget to put it to <code>sleep</code> [***]) on</p>

<pre><code>curl --silent --user JENKINS_USER:JENKINS_TOKEN JENKINS_JOB_URL/lastBuild/api/json | grep result\"":null &gt; /dev/null
</code></pre>

<p>until the result of this command is not <code>0</code>.</p>

<p>Once the Jenkins job is finished, you would probably want to fetch the job's console in Gitlab</p>

<pre><code>curl -i -X POST --user JENKINS_USER:JENKINS_TOKEN JENKINS_JOB_URL/lastBuild/consoleText
</code></pre>

<p>Finally you may <code>curl</code> once more on <code>JENKINS_JOB_URL/lastBuild/api/json</code> but this time you <code>grep</code> it on <code>UNSTABLE</code>, <code>SUCCESS</code> or <code>FAILURE</code>.</p>

<h2>Discussion</h2>

<p>By following the guidelines above, you can fully orchestrate Jenkins jobs from Gitlab-CI. I've posted a <a href=""https://stackoverflow.com/questions/37429453/gitlab-ci-vs-jenkins/52855927#52855927"">long discussion</a> on why and when should you do this.</p>

<p>I hope this will help you.</p>

<hr>

<p>[*] Your Gitlab project Settings > CI/CD > Secret vaiables<br>
[** ] Of course I mean by that to <strong>craft</strong> a script nicely with params, functions, nice variable names, meaningful logs... You name it.<br>
[***] I found a <code>sleep</code> of 20 seconds worked for me</p>
",9049,2018-11-02T11:39:51.297,"['stages:\n- my-jenkins-trigger\nvariables:\n MY_VARIABLE: ""EVERYTHING_IS_AWESOME""\n\nmy-jenkins-trigger-job:\n stage: my-jenkins-trigger\n script: curl -i -X POST --user JENKINS_USER:JENKINS_TOKEN JENKINS_JOB_URL/buildWithParameters?MY_JENK_PARAM=${MY_VARIABLE}\n', 'curl --silent --user JENKINS_USER:JENKINS_TOKEN JENKINS_JOB_URL/lastBuild/api/json | grep result\\"":null > /dev/null\n', 'curl -i -X POST --user JENKINS_USER:JENKINS_TOKEN JENKINS_JOB_URL/lastBuild/consoleText\n']"
618,5316,2429,CC BY-SA 4.0,2018-11-02T16:40:45.730,"<p>Try <a href=""https://dev.to/melezhik/sparky---powerful-pocket-size-task-runner-server-in-crontab-style-2ed5"" rel=""nofollow noreferrer"">Sparky</a>. This is a lightweight but powerful alternative to linux crontab. It comes with nice UI to see cronjob reports and statues. You can also run tasks remotely over ssh or through docker. The typical tasks you've mentioned are covered by existing <a href=""https://github.com/melezhik/sparrowdo/blob/master/core-dsl.md"" rel=""nofollow noreferrer"">DSL</a> ( written on Perl6 ), for example:</p>

<p>""Does a file, with a maximum age, exist on some network share?""</p>

<pre><code>bash ""find file.txt -mmin -10"", %( expect_stdout =&gt; ""file.txt"" );
</code></pre>

<p>""Does the response-body of a HTTP-request match a specific regex?""</p>

<pre><code>http-ok 'http://sparrowhub.org', %( has-content =&gt; 'SparrowHub' );
</code></pre>

<p>And yet if it's not enough it's easy to create extensions.</p>

<p>PS Sparky only supports linux for now ...</p>
",497,2018-11-05T18:22:26.230,"['bash ""find file.txt -mmin -10"", %( expect_stdout => ""file.txt"" );\n', ""http-ok 'http://sparrowhub.org', %( has-content => 'SparrowHub' );\n""]"
619,5350,4253,CC BY-SA 4.0,2018-11-06T15:53:03.680,"<p>1). Inside the node pool(lets call it <strong><em>old_node_pool</em></strong> ) that you want to delete, First Cordon all the nodes one after the other. </p>

<pre><code> kubectl cordon &lt;name_of_node_1&gt;
 kubectl cordon &lt;name_of_node_2&gt;
           ........ 
</code></pre>

<p>2). Drain all the nodes of the <strong><em>old_node_pool</em></strong>.</p>

<pre><code> kubectl drain &lt;name_of_node_1&gt;
 kubectl drain &lt;name_of_node_2&gt;
           ........ 
</code></pre>

<p>3). Wait to see all the pods are up and running on the new node pool.</p>

<p>4). Delete the old node pool.</p>
",3356,2018-11-06T15:53:03.680,"[' kubectl cordon <name_of_node_1>\n kubectl cordon <name_of_node_2>\n           ........ \n', ' kubectl drain <name_of_node_1>\n kubectl drain <name_of_node_2>\n           ........ \n']"
620,5361,4540,CC BY-SA 4.0,2018-11-07T07:46:40.373,"<p>I had a similar problem, this worked for me:</p>

<ol>
<li><p>Write Docker file with:</p>

<pre><code># Create app layer:
FROM python:3.4
# Create app user &amp; group ""testuser"" with IDs:
RUN groupadd -r testuser --gid 1234 &amp;&amp; useradd -d /home/testuser -ms /bin/bash -r -g testuser testuser --uid 1234
# Create ""testuser"" working dir:
WORKDIR /home/testuser
# Make working dir known to Python    
ENV PYTHONPATH ""${PYTHONPATH}:/home/testuser""
# Create &amp; mount shared storage:
RUN mkdir /var/run/testuser-storage
VOLUME [""/var/run/testuser-storage""]
# Start container as ""testuser"":
ENV NAME testuser
ENV HOME /home/testuser
USER testuser
</code></pre></li>
<li><p>Run these bash commands:</p>

<pre><code># Create the same user &amp; group ""testuser"" with IDs on host:
getent group testuser &gt; /dev/null || /usr/sbin/groupadd -r testuser --gid 1234
getent passwd testuser &gt; /dev/null || /usr/sbin/useradd -r -g testuser -d /var/lib/testuser -s /bin/nologin testuser --uid 1234
# Create shared storage dirs on host:
mkdir /var/run/testuser-storage
chown -R testuser.testuser /var/run/testuser-storage
# Build and run ""testuser"" Docker image:
docker build . -t testuser
docker run --net host --name testuser -v /var/run/testuser-storage:/var/run/testuser-storage -d testuser
# Change ownership of shared volume dir to the be the GID of ""testuser""
chown -R 1234:1234 /var/run/testuser-storage
</code></pre></li>
</ol>

<p>Note the names, UID's ,GID's must be the same for the Docker user and the host user. The last bash command tells the Docker image that that host user is the same as the Docker shared volume dir user, so that file dir then becomes owned by the ""testuser"" in the Docker container.</p>
",10707,2018-11-07T07:46:40.373,"['# Create app layer:\nFROM python:3.4\n# Create app user & group ""testuser"" with IDs:\nRUN groupadd -r testuser --gid 1234 && useradd -d /home/testuser -ms /bin/bash -r -g testuser testuser --uid 1234\n# Create ""testuser"" working dir:\nWORKDIR /home/testuser\n# Make working dir known to Python    \nENV PYTHONPATH ""${PYTHONPATH}:/home/testuser""\n# Create & mount shared storage:\nRUN mkdir /var/run/testuser-storage\nVOLUME [""/var/run/testuser-storage""]\n# Start container as ""testuser"":\nENV NAME testuser\nENV HOME /home/testuser\nUSER testuser\n', '# Create the same user & group ""testuser"" with IDs on host:\ngetent group testuser > /dev/null || /usr/sbin/groupadd -r testuser --gid 1234\ngetent passwd testuser > /dev/null || /usr/sbin/useradd -r -g testuser -d /var/lib/testuser -s /bin/nologin testuser --uid 1234\n# Create shared storage dirs on host:\nmkdir /var/run/testuser-storage\nchown -R testuser.testuser /var/run/testuser-storage\n# Build and run ""testuser"" Docker image:\ndocker build . -t testuser\ndocker run --net host --name testuser -v /var/run/testuser-storage:/var/run/testuser-storage -d testuser\n# Change ownership of shared volume dir to the be the GID of ""testuser""\nchown -R 1234:1234 /var/run/testuser-storage\n']"
621,5365,5363,CC BY-SA 4.0,2018-11-07T11:33:33.440,"<p>This question seems similar to <a href=""https://stackoverflow.com/questions/36188512/search-through-console-output-of-a-jenkins-job#36190644"">another on StackOverflow</a>, but seems to be a close, but not exact duplicate of 
<a href=""https://stackoverflow.com/questions/37018509/jenkinsfile-build-log"">https://stackoverflow.com/questions/37018509/jenkinsfile-build-log</a></p>

<p>To quote those : </p>

<blockquote>
  <p>if you just want to check, that your log contains string myTestString you can just call manager.logContains('.<em>myTestString.</em>')</p>
  
  <p>If you want to get some information from the first matching line you can use manager.getLogMatcher(regexp)</p>
</blockquote>

<p>You could use the <a href=""https://jenkins.io/doc/book/pipeline/syntax/#flow-control"" rel=""nofollow noreferrer"">Groovy flow control</a> to break the build - you just need a step to execute the test:</p>

<p>Following the example on the link : </p>

<pre><code>node {
    stage('CheckLog') {
      steps {
        if (manager.logContains('.*myTestString.*')) {
          error(""Build failed because of this and that.."")    
        }
      }
    }
</code></pre>
",354,2018-11-07T12:59:00.503,"['node {\n    stage(\'CheckLog\') {\n      steps {\n        if (manager.logContains(\'.*myTestString.*\')) {\n          error(""Build failed because of this and that.."")    \n        }\n      }\n    }\n']"
622,5380,5371,CC BY-SA 4.0,2018-11-08T18:46:51.777,"<p>The <code>.gitmodules</code> file just records the path and remote URL to the submodule repository. The commit itself is stored in the tree object. You can query it like this:</p>

<pre><code>git ls-tree &lt;ref&gt; &lt;path&gt;
</code></pre>

<p>where <code>&lt;ref&gt;</code> is a reference to some commit (e.g. <code>HEAD</code>, <code>master</code>, a commit SHA sum) and <code>&lt;path&gt;</code> is a path to a submodule.</p>

<p>The output looks something like this:</p>

<pre><code>160000 commit &lt;sha&gt; &lt;path&gt;
</code></pre>

<p>where <code>&lt;sha&gt;</code> is the commit in the submodule. The number in front has the following meaning, according to <a href=""https://git-scm.com/book/en/v2/Git-Tools-Submodules"" rel=""noreferrer"">the Git book</a>:</p>

<blockquote>
  <p>Notice the <code>160000</code> mode for the <code>DbConnector</code> <em>(submodule path of the example used in the book)</em> entry. That is a special mode in Git that basically means you’re recording a commit as a directory entry rather than a subdirectory or a file.</p>
</blockquote>

<p>See also <a href=""https://stackoverflow.com/q/5033441/1347968"">this question on StackOverflow</a>.</p>
",2855,2018-11-08T18:46:51.777,"['git ls-tree <ref> <path>\n', '160000 commit <sha> <path>\n']"
623,5390,4823,CC BY-SA 4.0,2018-11-09T09:53:42.590,"<p>Although the comments have highlighted the fact that this playbook is fine, as long as it is designed to do what it needs to do:</p>

<blockquote>
  <p>The reason behind this is that, the first play will create ansible user with sudo access. Here, I have used root user to run the play. Then I have to run another play as ansible user.</p>
</blockquote>

<p>In the first play, you have only one role: <code>role1</code>. If in <code>role1</code> you have a task that creates the ansible user, then you can use that user to connect the next time. This is actually something many people do, including myself, to put a known baseline on a service:</p>

<pre><code>- name: Ensure Ansible user is present (RedHat)
  user:
   name: ansible
   comment: ""ansible user created by bootstrap playbook""
   generate_ssh_key: yes
   groups: wheel
 tags:
 - bootstrap
 when: ansible_os_family==""RedHat""

- name: Ensure Ansible user is present (Debian)
  user:
   name: ansible
   comment: ""ansible user created by bootstrap playbook""
   generate_ssh_key: yes
   groups: sudo
  tags:
  - bootstrap
  when: ansible_os_family==""Debian""

- name: update sudoers to ensure ansible user can sudo
  lineinfile:
    dest: /etc/sudoers
    state: present
    regexp: '^ansible'
    line: 'ansible ALL=(ALL) NOPASSWD: ALL'
  tags:
  - bootstrap
</code></pre>

<p>This will ensure that the user is added, and included in the right groups, with sudo rights -- it is just an example of how you could achieve this, there are other strategies of course.</p>

<blockquote>
  <p>My question is how to run these play one after another? I first want to run first one then after that second one.</p>
</blockquote>

<p>That's exactly how playbooks work.</p>

<blockquote>
  <p>If I run the playbook then it will get stuck because it will first run first play and tries to run second play where it gets stuck.</p>
</blockquote>

<p>If you do not have a task to configure the user required in the next play, then yes, it will fail (not get stuck). 
The point is that since Ansible is idempotent, you don't have to worry about skipping the play because if the user is properly configured, the first play will simply have no effect.</p>

<p>However, to answer the actual question </p>

<blockquote>
  <p>How do I skip a play in an Ansible playbook ? </p>
</blockquote>

<p>This is done using the conditional execution using <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html#the-when-statement"" rel=""nofollow noreferrer""><code>when</code></a></p>
",354,2018-11-09T09:53:42.590,"['- name: Ensure Ansible user is present (RedHat)\n  user:\n   name: ansible\n   comment: ""ansible user created by bootstrap playbook""\n   generate_ssh_key: yes\n   groups: wheel\n tags:\n - bootstrap\n when: ansible_os_family==""RedHat""\n\n- name: Ensure Ansible user is present (Debian)\n  user:\n   name: ansible\n   comment: ""ansible user created by bootstrap playbook""\n   generate_ssh_key: yes\n   groups: sudo\n  tags:\n  - bootstrap\n  when: ansible_os_family==""Debian""\n\n- name: update sudoers to ensure ansible user can sudo\n  lineinfile:\n    dest: /etc/sudoers\n    state: present\n    regexp: \'^ansible\'\n    line: \'ansible ALL=(ALL) NOPASSWD: ALL\'\n  tags:\n  - bootstrap\n']"
624,5393,4225,CC BY-SA 4.0,2018-11-09T13:17:21.640,"<p>use try/catch</p>

<pre><code>def safeBuildUser = ""unknown""
wrap([$class: 'BuildUser']) {
  try {
     safeBuildUser = BUILD_USER
  } catch (e) {
     echo ""User not in scope, probably triggered from another job""
  }
}
echo ""Builduser is: ${safeBuildUser}""
</code></pre>
",10762,2018-11-09T13:17:21.640,"['def safeBuildUser = ""unknown""\nwrap([$class: \'BuildUser\']) {\n  try {\n     safeBuildUser = BUILD_USER\n  } catch (e) {\n     echo ""User not in scope, probably triggered from another job""\n  }\n}\necho ""Builduser is: ${safeBuildUser}""\n']"
625,5396,5391,CC BY-SA 4.0,2018-11-09T18:57:34.577,"<p>You have to execute <code>ssh-keyscan</code>. For example to ssh to a host (github.com here ) you have to run below script </p>

<pre><code># Add ssh key to help cloning private github repo

ssh-keygen -t rsa -N """" -f secrets/ssh/github_rsa
PUB_KEY=$(cat secrets/ssh/github_rsa.pub)
PRV_KEY=$(cat secrets/ssh/github_rsa)

echo ""${PRV_KEY}"" &gt;&gt; ~/.ssh/github_rsa
chmod 600 ~/.ssh/github_rsa
eval $(ssh-agent)
ssh-add ~/.ssh/github_rsa

ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts
echo IdentityFile ~/.ssh/github_rsa &gt;&gt; ~/.ssh/config

echo ""Paste the following public key to your host machine "".${PUB_KEY}
</code></pre>
",10766,2018-11-11T07:36:18.637,"['# Add ssh key to help cloning private github repo\n\nssh-keygen -t rsa -N """" -f secrets/ssh/github_rsa\nPUB_KEY=$(cat secrets/ssh/github_rsa.pub)\nPRV_KEY=$(cat secrets/ssh/github_rsa)\n\necho ""${PRV_KEY}"" >> ~/.ssh/github_rsa\nchmod 600 ~/.ssh/github_rsa\neval $(ssh-agent)\nssh-add ~/.ssh/github_rsa\n\nssh-keyscan github.com >> ~/.ssh/known_hosts\necho IdentityFile ~/.ssh/github_rsa >> ~/.ssh/config\n\necho ""Paste the following public key to your host machine "".${PUB_KEY}\n']"
626,5411,5397,CC BY-SA 4.0,2018-11-11T14:42:32.477,"<p>According to <a href=""https://yamllint.readthedocs.io/en/stable/disable_with_comments.html#disabling-checks-for-a-specific-line"" rel=""nofollow noreferrer"">the yamllint documentation</a> you need to add a special comment to the line -- <code>&lt;string-to-be-excluded&gt;  # yamllint disable-line rule:line-length</code></p>

<pre><code>---
#defaults/main
firefox_checksum: sha512:49d776cfb5f42c6e5ea1a55a80d9f6bad223080b16baa0d39de63534c25e68340091b4e16be5355d565f81291cb94fb996f03ae7e3e4c7a28021b0a0929daf58 #yamllint disable-line rule:line-length
</code></pre>
",354,2018-11-16T16:51:26.693,['---\n#defaults/main\nfirefox_checksum: sha512:49d776cfb5f42c6e5ea1a55a80d9f6bad223080b16baa0d39de63534c25e68340091b4e16be5355d565f81291cb94fb996f03ae7e3e4c7a28021b0a0929daf58 #yamllint disable-line rule:line-length\n']
627,5421,5418,CC BY-SA 4.0,2018-11-12T14:57:25.143,"<p>Correct script below:</p>

<pre><code>build:
  stage: build
  script:
    - apt-get install zip unzip
    - yarn install
    - ./node_modules/@angular/cli/bin/ng build --prod
    - cd dist/AngularTemplate; zip -r ../../dist.zip *; cd ..; cd..
  artifacts:
    paths:
      - dist.zip
</code></pre>

<p>Was installing the wrong Zip package and then puttin my archive in the wrong folder.</p>
",10803,2018-11-12T14:57:25.143,['build:\n  stage: build\n  script:\n    - apt-get install zip unzip\n    - yarn install\n    - ./node_modules/@angular/cli/bin/ng build --prod\n    - cd dist/AngularTemplate; zip -r ../../dist.zip *; cd ..; cd..\n  artifacts:\n    paths:\n      - dist.zip\n']
628,5432,2640,CC BY-SA 4.0,2018-11-13T15:38:38.210,"<p>The apiserver runs on master nodes. To get a list of all the master node IP's, this should help-</p>

<pre><code>kubectl -n kube-system get po | grep -i apiserver | cut -f1 -d"" "" | xargs kubectl -n kube-system get po $1 -o=jsonpath=""{.items[*].status.hostIP}""
</code></pre>

<p>Based on the version of Kubernetes you are running, you might need to update the location of the <code>hostIP</code> in the <code>jsonPath</code> parameter.</p>
",4394,2018-11-13T15:38:38.210,"['kubectl -n kube-system get po | grep -i apiserver | cut -f1 -d"" "" | xargs kubectl -n kube-system get po $1 -o=jsonpath=""{.items[*].status.hostIP}""\n']"
629,5434,5430,CC BY-SA 4.0,2018-11-13T17:57:31.937,"<p>Remove the quotes around <code>env.BUILD_NUMBER</code>.</p>

<p>Instead of:</p>

<pre><code>value: 'env.BUILD_NUMBER'
</code></pre>

<p>Try:</p>

<pre><code>value: env.BUILD_NUMBER
</code></pre>
",4115,2018-11-13T17:57:31.937,"[""value: 'env.BUILD_NUMBER'\n"", 'value: env.BUILD_NUMBER\n']"
630,5438,3264,CC BY-SA 4.0,2018-11-14T02:13:11.023,"<p>Here is something super cool I do with AWS SSM Send-Command!</p>

<p>Using Apache Airflow I create a brand new EC2-Instance using a Cloud Formation Template (or CFT for short) that's just a JSON file with all the configuration values for my EC2-Instance that I want; also note that in this CFT I also have a bootstrap command that copies a Python script from an S3 location to the new EC2-Instance so that I can execute it later on using an SSM Send-Command! I do this using Python3 and the AWS SDK for Python3 called the Boto3 library. Here's part of the command for creating the new CFT Stack that in turn creates my new EC2-Instance:</p>

<pre><code>import boto3

cft = boto3.client(""cloudformation"", ""us-east-1"")

response = cft.create_stack(
    StackName='foobarStackName',
    TemplateBody=json.dumps(json_data))
</code></pre>

<p>Then I can get the Instance-ID of the new EC2-Instance (required to use SSM Send-Command) using something like this:</p>

<pre><code>response = cft.describe_stacks(
    StackName='foobarStackName',
)
</code></pre>

<p>Then I can get the Instance-ID of the current Airflow Worker's server's EC2-Instance by running this command <code>wget -q -O - http://169.254.169.254/latest/meta-data/instance-id</code> through Python:</p>

<pre><code>output = subprocess.Popen(['wget', '-q', '-O', '-', 'http://169.254.169.254/latest/meta-data/instance-id'],
                          stdout=subprocess.PIPE)

# Do some weird stuff to get the value (I'm a Java developer so excuse my bad Python skilz)
instanceId = output.communicate()    
instanceId = str(instanceId).split(""'"")[1]
</code></pre>

<p><strong>NOW!!!! FOR THE GRAND FINALE</strong></p>

<p>I can then execute a script on the new EC2-Instance I created and send that script whatever parameters/arguments I want... including the Instance-ID of the server that sent the SSM Send-Command so that way when my script is done running on the new EC2-Instance it can send another SSM Send-Command back to my Airflow server to tell it that the script is finished. This is at a very high level without details but it's just to demonstrate an idea :)</p>

<pre><code>subprocess.run(shlex.split('sudo aws ssm send-command --document-name ""AWS-RunShellScript"" --parameters commands=[""sudo python3 /home/ec2-user/ec2_file_sensor.py ' + filepath + ' ' + batchIdValue + ' ' + source + ' ' + fileType + ' ' + airflowWorkerInstanceId + '""] --instance-ids ' + ec2ResourceInstanceId + ' --region us-east-1'))
</code></pre>

<p><em>Not sure if this helped anyone but it's a cool and FUN example of doing something with the AWS SSM Send-Command! Albeit, probably a code smell xD</em></p>
",10844,2018-11-14T19:01:25.560,"['import boto3\n\ncft = boto3.client(""cloudformation"", ""us-east-1"")\n\nresponse = cft.create_stack(\n    StackName=\'foobarStackName\',\n    TemplateBody=json.dumps(json_data))\n', ""response = cft.describe_stacks(\n    StackName='foobarStackName',\n)\n"", 'output = subprocess.Popen([\'wget\', \'-q\', \'-O\', \'-\', \'http://169.254.169.254/latest/meta-data/instance-id\'],\n                          stdout=subprocess.PIPE)\n\n# Do some weird stuff to get the value (I\'m a Java developer so excuse my bad Python skilz)\ninstanceId = output.communicate()    \ninstanceId = str(instanceId).split(""\'"")[1]\n', 'subprocess.run(shlex.split(\'sudo aws ssm send-command --document-name ""AWS-RunShellScript"" --parameters commands=[""sudo python3 /home/ec2-user/ec2_file_sensor.py \' + filepath + \' \' + batchIdValue + \' \' + source + \' \' + fileType + \' \' + airflowWorkerInstanceId + \'""] --instance-ids \' + ec2ResourceInstanceId + \' --region us-east-1\'))\n']"
631,5443,1325,CC BY-SA 4.0,2018-11-14T13:23:04.627,"<p>In my automatic jenkins job, launched daily, if there are no changes the git commit command returns 1. That will mark the build as failed. To solve this problem I use these two commands in my shell build step: </p>

<pre><code>git add -A
git diff-index --quiet HEAD || git commit -m ""Jenkins automatic update commit""
</code></pre>

<ul>
<li>the first will eventually add all unstaged files in the whole working tree (equivalent to <code>git add --all</code>);</li>
<li>the second will perform the commit if and only if there are differences against the HEAD version of the working directory. If the <code>git diff</code> command has exit code zero then the <code>git commit</code> command is executed.</li>
</ul>
",10858,2018-11-16T16:03:13.923,"['git add -A\ngit diff-index --quiet HEAD || git commit -m ""Jenkins automatic update commit""\n']"
632,5446,5115,CC BY-SA 4.0,2018-11-14T20:10:08.953,"<p>Still no answers, and still no CRR monitoring in place on AWS, here's minimalistic solution, any feedback and suggestions are welcome. This monitor will only show which S3 objects are missing from destination, it will not provide visibility on versions of replicated objects.</p>

<p>Prerequisites</p>

<hr>

<ol>
<li><a href=""https://docs.aws.amazon.com/AmazonS3/latest/user-guide/configure-inventory.html"" rel=""nofollow noreferrer"">Enable inventory reports</a> on <code>src</code> (Source) and <code>dst</code>
(Destination) buckets</li>
<li><a href=""https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-inventory.html#storage-inventory-athena-query"" rel=""nofollow noreferrer"">Create Athena tables</a> (<code>src_inventory</code>, <code>dst_inventory</code>) based on inventory reports for each bucket</li>
</ol>

<p>Monitor</p>

<hr>

<p>Run Athena query after both inventory reports generated e.g. on daily basis, can be executed from <a href=""https://docs.aws.amazon.com/athena/latest/APIReference/API_StartQueryExecution.html"" rel=""nofollow noreferrer"">Lambda</a>, <a href=""https://github.com/anselmo/step_function_activity_patterns/blob/master/athena_query_pull_mode/fns/athena.js"" rel=""nofollow noreferrer"">Step Function</a>, build server or any type of cron job.</p>

<p>Example of Athena query which should show number of missing objects on destination bucket at the time of generation of inventory reports:</p>

<pre><code>FROM src_inventory src 
LEFT JOIN dst_inventory dst 
ON src.key = dst.key 
WHERE dst.key is NULL
AND src.dt = '2018-11-11-08-00';
</code></pre>

<p>The result can be reported as CloudWatch metric and monitored with CloudWatch alarm. </p>
",743,2019-05-31T14:57:46.150,"[""FROM src_inventory src \nLEFT JOIN dst_inventory dst \nON src.key = dst.key \nWHERE dst.key is NULL\nAND src.dt = '2018-11-11-08-00';\n""]"
633,5447,5444,CC BY-SA 4.0,2018-11-14T21:04:00.843,"<p>I just played with it locally on a ""safe network"", but it may give you an idea.</p>

<p>I put in <code>.git/hooks/post-commit</code> something like:</p>

<pre><code>wget --auth-no-challenge --http-user=$USER --http-password=$APITOKEN --secure-protocol=TLSv1 $JENKINS/job/$JOB/build?token=$JOBTOKEN -O /dev/null -o /dev/null
</code></pre>

<p>You need to create API token in jenkins and grab the webhook url for a given job. </p>
",3525,2018-11-14T21:04:00.843,['wget --auth-no-challenge --http-user=$USER --http-password=$APITOKEN --secure-protocol=TLSv1 $JENKINS/job/$JOB/build?token=$JOBTOKEN -O /dev/null -o /dev/null\n']
634,5448,3073,CC BY-SA 4.0,2018-11-15T01:24:34.300,"<p>This also works, if you want to stay within the <code>Declarative Pipeline</code> space</p>

<pre><code>// declare our vars outside the pipeline
def tests = [:]
def files

pipeline {
    agent any
    stages {
        stage('1') {
            steps {
                script {
                    // we've declared the variable, now we give it the values
                    files = findFiles(glob: '**/html/*.html')
                    // Loop through them
                    files.each { f -&gt;
                        // add each object from the 'files' loop to the 'tests' array
                        tests[f] = {
                            // we're already in the script{} block, so do our advanced stuff here
                            echo f.toString()
                        }
                    }
                    // Still within the 'Script' block, run the parallel array object
                    parallel tests
                }
            }
        }       
    }
}
</code></pre>
",10868,2018-12-19T21:45:09.707,"[""// declare our vars outside the pipeline\ndef tests = [:]\ndef files\n\npipeline {\n    agent any\n    stages {\n        stage('1') {\n            steps {\n                script {\n                    // we've declared the variable, now we give it the values\n                    files = findFiles(glob: '**/html/*.html')\n                    // Loop through them\n                    files.each { f ->\n                        // add each object from the 'files' loop to the 'tests' array\n                        tests[f] = {\n                            // we're already in the script{} block, so do our advanced stuff here\n                            echo f.toString()\n                        }\n                    }\n                    // Still within the 'Script' block, run the parallel array object\n                    parallel tests\n                }\n            }\n        }       \n    }\n}\n""]"
635,5451,5430,CC BY-SA 4.0,2018-11-15T04:18:33.723,"<p>Looks like you're missing a plugin. Remove the <code>[$class: 'ScannerJobProperty', doNotScan: false]</code> portion. This works:</p>

<p><em>Upstream Job</em></p>

<pre><code>node {
    stage('Build parameters') {
        properties(
            [parameters(
                [string(
                    defaultValue: '***', 
                    description: '', 
                    name: 'version', 
                    trim: false)
                ])
            ])
    }
    echo env.BUILD_NUMBER
    def Latest_Build_Number = env.BUILD_NUMBER
    build(
        job: 'Downstream', 
        parameters: [
            [$class: 'StringParameterValue', 
             name: 'Latest_Build_Number', 
             value: env.BUILD_NUMBER, 
             propagate: false]
        ]
    )
}
</code></pre>

<p><em>Downstream Job</em></p>

<pre><code>node {
    stage('Downstream') {
        properties([
            parameters([string(
                defaultValue: '', 
                description: '', 
                name: 'Latest_Build_Number', 
                trim: false)
            ])
        ])
        echo Latest_Build_Number
    }
}
</code></pre>
",10868,2018-11-15T04:18:33.723,"[""node {\n    stage('Build parameters') {\n        properties(\n            [parameters(\n                [string(\n                    defaultValue: '***', \n                    description: '', \n                    name: 'version', \n                    trim: false)\n                ])\n            ])\n    }\n    echo env.BUILD_NUMBER\n    def Latest_Build_Number = env.BUILD_NUMBER\n    build(\n        job: 'Downstream', \n        parameters: [\n            [$class: 'StringParameterValue', \n             name: 'Latest_Build_Number', \n             value: env.BUILD_NUMBER, \n             propagate: false]\n        ]\n    )\n}\n"", ""node {\n    stage('Downstream') {\n        properties([\n            parameters([string(\n                defaultValue: '', \n                description: '', \n                name: 'Latest_Build_Number', \n                trim: false)\n            ])\n        ])\n        echo Latest_Build_Number\n    }\n}\n""]"
636,5463,764,CC BY-SA 4.0,2018-11-16T14:39:52.827,"<p>It's actually a bad idea to run Docker as root. What you should do instead is add the Jenkins user to the Docker group. <code>sudo usermod -aG docker jenkins</code>. That will avoid opening needless security holes and allow Jenkins to do all that it needs to do with Docker, including running as root inside the containers. I do this regularly with my builds, using this as a sample:</p>

<pre><code>stage ('Build Docker Image') {
  steps {
    script {
      // Build the Docker image for compiling
      dockerImage = docker.build(""myapp:v1"")
    }
  }
}
stage ('Run UnitTests') {
  steps {
    script {
      dockerImage.inside(""-itu root"") {
        sh(script: ""nosetests app-test.py --verbose"")
      }
    }
  }
}
</code></pre>
",10868,2018-12-12T14:59:00.357,"['stage (\'Build Docker Image\') {\n  steps {\n    script {\n      // Build the Docker image for compiling\n      dockerImage = docker.build(""myapp:v1"")\n    }\n  }\n}\nstage (\'Run UnitTests\') {\n  steps {\n    script {\n      dockerImage.inside(""-itu root"") {\n        sh(script: ""nosetests app-test.py --verbose"")\n      }\n    }\n  }\n}\n']"
637,5468,5460,CC BY-SA 4.0,2018-11-16T17:17:58.387,"<p>Quickly going through this it looks like you have added wrong credentials to Jenkins. Can you please check the added credentials first. </p>

<pre><code>aused by: org.codehaus.cargo.container.tomcat.internal.TomcatManagerException: The username and password you provided are not correct (error 401)
</code></pre>
",10902,2018-11-16T17:17:58.387,['aused by: org.codehaus.cargo.container.tomcat.internal.TomcatManagerException: The username and password you provided are not correct (error 401)\n']
638,5471,2491,CC BY-SA 4.0,2018-11-16T23:01:59.273,"<p>If you don't care about web UI, you can distribute your powershell scripts as console tasks using <a href=""https://dev.to/melezhik/sparrow-as-a-reasonable-alternative-to-dotfiles-a1n"" rel=""nofollow noreferrer"">Sparrow</a>, you basically just save your Powershell scripts as tasks to a git repository so that users can use it.</p>

<p>Say, you have task, task2, task3 and so on Powershell scripts ( aka tasks ) scattered across different projects ( aka groups ):</p>

<h1>on your machine</h1>

<pre><code># 1. convert powershell scripts into sparrow plugins
# and place them to local git repository 
# /path/local/repo/plugins directory

# 2. create configurations for your plugins
# as sparrow tasks

sparrow task $project/$task ini 

# 3. save tasks to a local git repository
# /path/local/repo/

sparrow task save /path/local/repo/
cd  /path/local/repo/ &amp;&amp; git commit -a -m ""my tasks"" &amp;&amp; git push
</code></pre>

<h1>on target machine</h1>

<pre><code># load tasks from a git repository

git clone $repo/powershell-tasks.git powershell-tasks

# install plugins to a local system:

cd powershell-tasks &amp;&amp; sparrow plg install $PWD/plugins --recursive --local

# install tasks into a local system:

cd powershell-tasks
sparrow task restore $PWD

# setup and run tasks

sparrow task ini project1/task1 # override default settings

 foo: 1
 bar: 2

sparrow task run project1/task1 # run script as a task

sparrow task ini project2/task2 # override default settings

 foo: 11
 bar: 22

sparrow task run project2/task2 # run script as a task
</code></pre>
",497,2018-11-20T00:28:23.390,"['# 1. convert powershell scripts into sparrow plugins\n# and place them to local git repository \n# /path/local/repo/plugins directory\n\n# 2. create configurations for your plugins\n# as sparrow tasks\n\nsparrow task $project/$task ini \n\n# 3. save tasks to a local git repository\n# /path/local/repo/\n\nsparrow task save /path/local/repo/\ncd  /path/local/repo/ && git commit -a -m ""my tasks"" && git push\n', '# load tasks from a git repository\n\ngit clone $repo/powershell-tasks.git powershell-tasks\n\n# install plugins to a local system:\n\ncd powershell-tasks && sparrow plg install $PWD/plugins --recursive --local\n\n# install tasks into a local system:\n\ncd powershell-tasks\nsparrow task restore $PWD\n\n# setup and run tasks\n\nsparrow task ini project1/task1 # override default settings\n\n foo: 1\n bar: 2\n\nsparrow task run project1/task1 # run script as a task\n\nsparrow task ini project2/task2 # override default settings\n\n foo: 11\n bar: 22\n\nsparrow task run project2/task2 # run script as a task\n']"
639,5493,5037,CC BY-SA 4.0,2018-11-20T22:49:51.573,"<p>What I would suggest, like comments under your post, is to take this to the #inspec channel on the Chef Community Slack to ask there. That said, here's how I might attack this:</p>

<pre><code>control 'some-control-slug' do
  title 'My control'
  impact 1.0
  desc 'Example code for Stack Exchange'

  if os.windows? &amp;&amp; ::Gem::Version.new(os.release) &lt; ::Gem::Version.new('6.1')
    # Only executed on Windows machines older than 2008r2
    describe directory('C:/Users') do
      it { should exist }
    end

  elsif os.windows? &amp;&amp; ::Gem::Version.new(os.release) &gt;= ::Gem::Version.new('10')
    # Only executed on Windows Server 2016 or newer
    describe directory('D:/MyFolder') do
      it { should_not exist }
    end

  end

  # Executed on all host types
  describe sys_info do
    its('hostname') { should match(/SomeAwesomeHost/i) }
  end
end
</code></pre>

<p>Additionally, you can limit the entire inspec control with Chef-like hooks, such as <code>only_if</code>. The above example code, as written, may execute on a Linux target. We could limit all of them by placing the following up near the <code>desc</code> or <code>title</code>:</p>

<pre><code>only_if { os.windows? }
</code></pre>
",10969,2018-11-20T22:49:51.573,"[""control 'some-control-slug' do\n  title 'My control'\n  impact 1.0\n  desc 'Example code for Stack Exchange'\n\n  if os.windows? && ::Gem::Version.new(os.release) < ::Gem::Version.new('6.1')\n    # Only executed on Windows machines older than 2008r2\n    describe directory('C:/Users') do\n      it { should exist }\n    end\n\n  elsif os.windows? && ::Gem::Version.new(os.release) >= ::Gem::Version.new('10')\n    # Only executed on Windows Server 2016 or newer\n    describe directory('D:/MyFolder') do\n      it { should_not exist }\n    end\n\n  end\n\n  # Executed on all host types\n  describe sys_info do\n    its('hostname') { should match(/SomeAwesomeHost/i) }\n  end\nend\n"", 'only_if { os.windows? }\n']"
640,5530,5487,CC BY-SA 4.0,2018-11-23T18:09:03.063,"<p>You can use regex and after that change, you need to restart the webserver:</p>

<pre><code>sed -i 's/upload_max_filesize\s*=.*/upload_max_filesize=100M/g' path/to/php.ini
sed -i 's/post_max_size\s*=.*/post_max_size=100M/g' path/to/php.ini
sed -i 's/memory_limit\s*=.*/memory_limit=512M/g' path/to/php.ini
</code></pre>

<p>But it is preferable to use <strong>Configuration Management Tools</strong></p>
",11029,2018-11-24T07:48:53.647,"[""sed -i 's/upload_max_filesize\\s*=.*/upload_max_filesize=100M/g' path/to/php.ini\nsed -i 's/post_max_size\\s*=.*/post_max_size=100M/g' path/to/php.ini\nsed -i 's/memory_limit\\s*=.*/memory_limit=512M/g' path/to/php.ini\n""]"
641,5531,5241,CC BY-SA 4.0,2018-11-23T20:55:37.710,"<p>As @Harith mentioned, the use of secrets simplifies deployments in various environments using environmental variables. To load in a secret directly use:</p>

<blockquote>
  <p>$ kubectl create secret generic &lt; NAME OF SECRET > --from-literal=&lt; KEY >=abc123!:?  </p>
</blockquote>

<p>NOTE! This will put the secret in the Default namespace, add a namespace flag for specific resources e.g.:</p>

<blockquote>
  <p>$ kubectl create secret generic mongodbsecret --from-literal=mongoUser=abc123!:? -n mongoNamespace</p>
</blockquote>

<p>You can then reference this secret in the deployment.yml or pod.yml or wherever you put your image for deployment on the kubernetes cluster.</p>

<pre><code>env:
- name: MONGO_INITDB_ROOT_USERNAME &lt;name of the env var in the code&gt;
   valueFrom:
     secretKeyRef:
       name: mongodbSecret &lt;NAME OF SECRET&gt; 
       key: mongoUser &lt;KEY&gt;
</code></pre>

<p>However, if all you need is to change 'development' to 'production' you could put an environment var directly in the (deployment).yaml.</p>

<pre><code>env:
- name: NODE_ENV
  value: production
</code></pre>

<p>You can also update the Jenkinsfile to send in the environment by for instance:</p>

<pre><code>def resource_env = BRANCH_NAME == 'master' ? 'production' : 'development'

sh ""kubectl set env ${kubeImageName} NODE_ENV=${resource_env} --namespace ${kubeNamespace}""
</code></pre>

<p>On your current pipeline idea: The safest place for sensitive env vars would be putting it in kubernetes in a secret in your situation. However, for simple selection of deployment environments then using a Jenkinsfile simplifies things a bit like 'prod' vs 'dev'. Putting sensitive, variable or private things on git is a bad idea. Keep your docker images precise and task-orientated. </p>

<p>Hope that helps</p>
",10008,2018-11-23T20:55:37.710,"['env:\n- name: MONGO_INITDB_ROOT_USERNAME <name of the env var in the code>\n   valueFrom:\n     secretKeyRef:\n       name: mongodbSecret <NAME OF SECRET> \n       key: mongoUser <KEY>\n', 'env:\n- name: NODE_ENV\n  value: production\n', 'def resource_env = BRANCH_NAME == \'master\' ? \'production\' : \'development\'\n\nsh ""kubectl set env ${kubeImageName} NODE_ENV=${resource_env} --namespace ${kubeNamespace}""\n']"
642,5542,5541,CC BY-SA 4.0,2018-11-26T14:44:44.137,"<p>Prometheus use a timeseries databases with vacuum, the <a href=""https://prometheus.io/docs/prometheus/latest/storage/#operational-aspects"" rel=""noreferrer"">documentation</a> gives some maths to plan your disk consumption:</p>

<blockquote>
  <p>On average, Prometheus uses only around 1-2 bytes per sample. Thus, to
  plan the capacity of a Prometheus server, you can use the rough
  formula:</p>

<pre><code>needed_disk_space = retention_time_seconds * ingested_samples_per_second * bytes_per_sample
</code></pre>
</blockquote>

<p>So depending on your retention configuration, 1TB could never be reach or you can keep a very long time. That said it's using prometheus local storage, using another storage system will change the maths depending on the system concerned, influxdb is one of them and has its own documentation about storage.</p>
",13,2018-11-26T14:44:44.137,['needed_disk_space = retention_time_seconds * ingested_samples_per_second * bytes_per_sample\n']
643,5544,5543,CC BY-SA 4.0,2018-11-26T19:31:42.217,"<p>You could set a fact to be the list of services you need restarted by the handlers: </p>

<pre><code>- name: Tag services to restart
  set_fact:
    services_to_restart:
     - ntp
     - nginx
     - grafana
</code></pre>

<p>then your handler becomes:</p>

<pre><code>- name: Restart tagged services
  service:
    name: ""{{ item }}""
    state: restarted
  loop: ""{{ services_to_restart }} | default('nginx')""
</code></pre>

<p>I suggest using a sane default there in case you send an empty list to the service module.</p>
",354,2018-11-26T19:31:42.217,"['- name: Tag services to restart\n  set_fact:\n    services_to_restart:\n     - ntp\n     - nginx\n     - grafana\n', '- name: Restart tagged services\n  service:\n    name: ""{{ item }}""\n    state: restarted\n  loop: ""{{ services_to_restart }} | default(\'nginx\')""\n']"
644,5558,5540,CC BY-SA 4.0,2018-11-28T08:12:15.637,"<p>If you use python and GitLab like I do, you can include a test coverage report in your CI/CD pipeline. You <code>pip install coverage</code> and then just run <code>coverage</code> in your pipeline. The following is an excerpt from an AWS lambda pipeline, but you should be able to find something similar for your environment:</p>

<pre><code> script:
    - pip install -r ./awslambda/requirements.txt
    - coverage run -m unittest discover -v -s ""./awslambda"" -p ""*_test.py""
    - coverage report
</code></pre>

<p>The above generates a nice code coverage report and it is free of charge, for Python, AWS and GitLab. </p>
",7772,2018-11-28T08:12:15.637,"[' script:\n    - pip install -r ./awslambda/requirements.txt\n    - coverage run -m unittest discover -v -s ""./awslambda"" -p ""*_test.py""\n    - coverage report\n']"
645,5560,5555,CC BY-SA 4.0,2018-11-28T10:47:00.523,"<p>If organizations which manage firewall host and infra around can create a user for you on their equipment - you can use the advantage of ""jump host"".
Imagine you have access to host A and host A has connectivity with host B. Then you can do it with the following ssh config.</p>

<pre><code>Host A
  Username username
  Hostname bloody.enterprise.example
Host B
   ProxyJump A
</code></pre>

<p>If it's not an option.Well, you can consider setting up VPN.</p>
",11080,2018-11-28T10:47:00.523,['Host A\n  Username username\n  Hostname bloody.enterprise.example\nHost B\n   ProxyJump A\n']
646,5563,5561,CC BY-SA 4.0,2018-11-28T12:20:16.980,"<p>You can loop with dictionaries using <code>loop</code>. It doesn't look like the <code>easy_install</code> module handles versions with a module attribute, so you might have t pass the version on the <code>name</code> attribute.</p>

<pre><code>- name: install things with easy_install
  easy_install:
    name: ""{{ item.name }}=={{item.version}}""
    state: present
  loop:
    - { name: 'pip', version: '18.1' }
</code></pre>
",354,2018-11-28T12:20:16.980,"['- name: install things with easy_install\n  easy_install:\n    name: ""{{ item.name }}=={{item.version}}""\n    state: present\n  loop:\n    - { name: \'pip\', version: \'18.1\' }\n']"
647,5564,5561,CC BY-SA 4.0,2018-11-28T12:27:12.630,"<p>You can loop over file content:</p>

<pre><code>- name: Installs Python libraries from requirements.txt
  easy_install:
    name: {{ item }}
    state: present
  with_lines: cat ""/my_app/requirements.txt""
</code></pre>
",800,2018-11-28T12:27:12.630,"['- name: Installs Python libraries from requirements.txt\n  easy_install:\n    name: {{ item }}\n    state: present\n  with_lines: cat ""/my_app/requirements.txt""\n']"
648,5569,5482,CC BY-SA 4.0,2018-11-29T05:12:06.830,"<p>You can use the Jenkins pipeline syntax to get the groovy script.  For example below code will generate radio buttons for active choice parameter. you can generate scripts like this from your jenkins instance at  <a href=""http://localhost:8080/pipeline-syntax/"" rel=""nofollow noreferrer"">http://localhost:8080/pipeline-syntax/</a>. More info is here <a href=""https://jenkins.io/doc/book/pipeline/getting-started/#snippet-generator"" rel=""nofollow noreferrer"">https://jenkins.io/doc/book/pipeline/getting-started/#snippet-generator</a></p>

<pre><code>def createInputParameters(){
([[$class: 'RebuildSettings', autoRebuild: false, rebuildDisabled: false],
 parameters([[$class: 'ChoiceParameter', choiceType: 'PT_RADIO', description: '',
 filterLength: 1, filterable: false, name: 'Select_snapshot_or_release',
  randomName: 'choice-parameter-1683871426502398',
   script: [$class: 'GroovyScript', fallbackScript: [classpath: [], sandbox: true, 
    script: 'return ""Error""'],
     script: [classpath: [], sandbox: true,
      script: '''return[
            \'snapshots\',\'release\']''']]]]),
             [$class: 'ThrottleJobProperty', categories: [],
              limitOneJobWithMatchingParams: false, maxConcurrentPerNode: 0, 
               maxConcurrentTotal: 0,
               paramsToUseForLimit: '', throttleEnabled: false, throttleOption: 
               'project']])
      }
</code></pre>
",8469,2018-11-29T05:12:06.830,"['def createInputParameters(){\n([[$class: \'RebuildSettings\', autoRebuild: false, rebuildDisabled: false],\n parameters([[$class: \'ChoiceParameter\', choiceType: \'PT_RADIO\', description: \'\',\n filterLength: 1, filterable: false, name: \'Select_snapshot_or_release\',\n  randomName: \'choice-parameter-1683871426502398\',\n   script: [$class: \'GroovyScript\', fallbackScript: [classpath: [], sandbox: true, \n    script: \'return ""Error""\'],\n     script: [classpath: [], sandbox: true,\n      script: \'\'\'return[\n            \\\'snapshots\\\',\\\'release\\\']\'\'\']]]]),\n             [$class: \'ThrottleJobProperty\', categories: [],\n              limitOneJobWithMatchingParams: false, maxConcurrentPerNode: 0, \n               maxConcurrentTotal: 0,\n               paramsToUseForLimit: \'\', throttleEnabled: false, throttleOption: \n               \'project\']])\n      }\n']"
649,5570,5556,CC BY-SA 4.0,2018-11-29T10:01:39.700,"<p>Since the result is JSON, pipe the result to <a href=""https://stedolan.github.io/jq/"" rel=""nofollow noreferrer""><strong>jq</strong></a> and go from there.</p>
<pre><code>kubectl get | jq '.items[0].metadata.name'
</code></pre>
<p>yields</p>
<pre><code>➜ cat abc.json | jq '.items[0].metadata.name'
&quot;kubernetes-bootcamp-5c69669756-cxhwf&quot;
</code></pre>
",3164,2021-05-11T23:22:44.343,"[""kubectl get | jq '.items[0].metadata.name'\n"", '➜ cat abc.json | jq \'.items[0].metadata.name\'\n""kubernetes-bootcamp-5c69669756-cxhwf""\n']"
650,5618,5612,CC BY-SA 4.0,2018-12-05T00:37:28.503,"<p>You should use <a href=""https://docs.saltstack.com/en/latest/topics/jinja/index.html"" rel=""nofollow noreferrer"">Jinja</a> to <a href=""http://jinja.pocoo.org/docs/2.10/templates/#for"" rel=""nofollow noreferrer"">loop</a> over a list of files and pattern/replacement pairs.</p>

<pre><code>{% set files = ['/a/foo.sh', '/b/bar.sh', '/b/baz.sh'] %}

{% for file in files %}
{% for p, r in [('/aaa/bbb', '/aaa/ccc'), ('/xxx/yyy', '/xxx/zzz')] %}
replace {{ p }} in {{ file }}:
   file.replace:
      - name: {{ file }}
      - pattern: {{ p }}
      - repl: {{ r }}
{% endfor %}
{% endfor %}
</code></pre>

<p>Keep in mind the identifiers need to be unique, that's why variables in <code>replace {{ p }} in {{ file }}:</code> are used.</p>
",9012,2018-12-05T00:37:28.503,"[""{% set files = ['/a/foo.sh', '/b/bar.sh', '/b/baz.sh'] %}\n\n{% for file in files %}\n{% for p, r in [('/aaa/bbb', '/aaa/ccc'), ('/xxx/yyy', '/xxx/zzz')] %}\nreplace {{ p }} in {{ file }}:\n   file.replace:\n      - name: {{ file }}\n      - pattern: {{ p }}\n      - repl: {{ r }}\n{% endfor %}\n{% endfor %}\n""]"
651,5628,284,CC BY-SA 4.0,2018-12-06T08:31:48.553,"<p>I was able to get around this issue in a bit of a dodgy way by changing the command to:</p>

<pre><code>/bin/bash -c ""your-command-here | { ! grep '^'; }""
</code></pre>

<p>This pipes the output through <code>grep</code> and fails if there is any output at all, but <code>grep</code> still passes it through so you still get to see the output in Rundeck upon failure.</p>

<p>One drawback is that I believe you lose any blank lines but we don't output any so no big deal for us, and it will tide us over until we can update the app to terminate with a proper exit code.</p>
",11219,2018-12-06T08:31:48.553,"['/bin/bash -c ""your-command-here | { ! grep \'^\'; }""\n']"
652,5643,4725,CC BY-SA 4.0,2018-12-08T10:04:36.440,"<p>It is a convenience that Jenkins will pull from git for you. With such a complex setup as needing to pull from two repos you can simply use a pipeline job that runs ""sh"" to explicitly git checkout the code and pull the submodules:</p>

<pre><code>sh ""git checkout ${custom_env_var} ${custom_parameter}
</code></pre>

<p>The good news with this slightly manual approach is that you can debug the sh commands to run on a dev server and cut paste them straight into a pipeline. Just start a “sh” session (usually it runs bash) and test the commands. </p>
",10599,2018-12-09T08:12:35.383,"['sh ""git checkout ${custom_env_var} ${custom_parameter}\n']"
653,5684,5658,CC BY-SA 4.0,2018-12-11T15:10:39.280,"<blockquote>
  <p>TL;DR: Ansible modules like <code>apt</code> can be mostly implemented with
  <code>command</code> module, but you lose error checking. Using command is usually sign of a lack of experience with ansible.</p>
</blockquote>

<p>To answer this question it is best to look at the <a href=""https://github.com/ansible/ansible-modules-core/blob/devel/packaging/os/apt.py"" rel=""nofollow noreferrer"">code implementing the apt module</a> in ansible. What you can see is that most of the features of the module are implemented by constructing an appropriate <code>apt-get</code> command and executing it, then handling error conditions and presenting them in ansible data structures. Sometimes depending on options the command can be quite complex. In two exceptions for upgrade, in case it is <em>full-upgrade</em> or <em>safe-upgrade</em> it would use <code>aptitude</code> command instead of <code>apt-get</code>. </p>

<p>Of course, the implementation of the module can change going forward, but you should be able to rely on it doing essentially the same thing. On the other hand, if <code>apt-get</code> changes in some way or returns new unhandled type of errors, you will need to change your ansible code in case you use <code>command</code> module directly. While if you use <code>apt</code> module, it is likely the maintainer of the module will implement the new error checking for you.</p>

<p>So in general it is better to use <code>apt</code> to <code>command: apt-get</code> unless the module won't do something that you absolutely need to do and there is no other way around it.</p>

<p>To do the 2nd task in ansible using apt module do:</p>

<pre><code>- name: Ensure some basics
  apt:
    name: aptitude
</code></pre>
",228,2018-12-19T18:30:01.853,['- name: Ensure some basics\n  apt:\n    name: aptitude\n']
654,5694,5662,CC BY-SA 4.0,2018-12-12T03:28:29.643,"<p>I would discourage you from using Ansible to run Ansible (though this can be done) as you will run the risk of breaking idempotent rule of Ansible. Instead, choose a singular starting point for running your playbooks; either command line, cron or some other program.</p>

<p>With that said, I would use cron to run an Ansible playbook, however I would also setup your <code>ansible.cfg</code> file for logging and check the log periodically if there is breakage in your playbook.</p>

<p>Ansible by default doesn't do logging so I would set this up in <code>ansible.cfg</code>, just in case:</p>

<pre><code>[defaults]
log_path = ./ansible.log
</code></pre>

<p>Also, make sure to check your email regularly to make sure your cron/Ansible job ran without any problem.</p>
",11309,2018-12-13T17:15:29.217,['[defaults]\nlog_path = ./ansible.log\n']
655,5702,1960,CC BY-SA 4.0,2018-12-12T12:57:31.657,"<p>If you use CentOS 7 (as I have ). You may have SELinux turned on by default.check <a href=""https://www.rootusers.com/how-to-enable-or-disable-selinux-in-centos-rhel-7/"" rel=""noreferrer"">https://www.rootusers.com/how-to-enable-or-disable-selinux-in-centos-rhel-7/</a>
or mount like this: </p>

<pre><code>  volumes:
   - ./database:/var/lib/mysql:Z
   - ./_conf/mariadb.cnf:/etc/mysql/my.cnf:Z
   - ./logs:/var/log/mysql:Z
</code></pre>
",11324,2018-12-12T12:57:31.657,['  volumes:\n   - ./database:/var/lib/mysql:Z\n   - ./_conf/mariadb.cnf:/etc/mysql/my.cnf:Z\n   - ./logs:/var/log/mysql:Z\n']
656,5704,5620,CC BY-SA 4.0,2018-12-12T15:47:03.650,"<p>Look this: </p>

<pre><code>#!/bin/bash
#Get servers list
set -f
string=$DEPLOY_SERVER
array=(${string//,/ })
for i in ""${!array[@]}""do    
      echo ""Deploy project on server ${array[i]}""    
done
</code></pre>

<p>I found this <a href=""https://medium.com/@lucabecchetti/autodeploy-from-gitlab-to-multiple-aws-ec2-instances-a43448727c5a"" rel=""nofollow noreferrer"">link</a></p>
",9838,2018-12-12T15:47:03.650,"['#!/bin/bash\n#Get servers list\nset -f\nstring=$DEPLOY_SERVER\narray=(${string//,/ })\nfor i in ""${!array[@]}""do    \n      echo ""Deploy project on server ${array[i]}""    \ndone\n']"
657,5714,5713,CC BY-SA 4.0,2018-12-13T15:14:23.017,"<p>Hi and welcome to DevOps SE and Docker!</p>

<p>Now the concept of Docker is to create isolated virtual  environments, actually it's just a process or more but wrapped in its own environment.</p>

<p>So at first hand you could take any Docker image and the scripts inside would be there where the creators of the image placed them.</p>

<p>If you decide to create your own Docker images, and I believe you will sooner or later, then it is up to you how layout the system.</p>

<p>Additionally, you could link - proper term is here <em>mount</em> - your system's folders with those of the container but still the execution will take place inside the container.</p>

<p>For example to install the RStudio package in an Anaconda3 environment, I have tried the following.</p>

<pre><code>$ docker run -it continuumio/anaconda3 bash
(base) root@7162c3acc9e3:/# conda install -y -c r rstudio
(base) root@7162c3acc9e3:/# which rstudio
(base) root@7162c3acc9e3:/# /opt/conda/bin/rstudio
</code></pre>

<p>As you can see, if installed as root user which is default, the path is <code>/opt/conda/bin/rstudio</code>. Most packages not using special system capabilities would considerably not ""know"" whether they are in a Docker environment or not, so in many cases you could consider a Docker container to be just a (fluid) environment you have the root access too.</p>

<p>Additional note on the terms:</p>

<ul>
<li><em>image</em> is a blueprint for a container defined by a Dockerfile. ""Installing"" something in an image means you add instructions to its Dockerfile. Own images can be derived from others by the statment FROM.</li>
<li><em>container</em> is basically process isolation in its own OS environment. If you install something in the container during its uptime, this change will be gone with the container.</li>
</ul>
",707,2018-12-14T08:55:16.103,['$ docker run -it continuumio/anaconda3 bash\n(base) root@7162c3acc9e3:/# conda install -y -c r rstudio\n(base) root@7162c3acc9e3:/# which rstudio\n(base) root@7162c3acc9e3:/# /opt/conda/bin/rstudio\n']
658,5723,5651,CC BY-SA 4.0,2018-12-13T23:18:15.993,"<p>The short answer is ""you don't have to"".</p>

<p>The long answer is I was doing it wrong. Here's what was wrong and what I learned.</p>

<p>After working through <a href=""https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs-cli-tutorial-fargate.html"" rel=""nofollow noreferrer"">tutorials</a>, RTFMing and re-building my ECS configuration I found that I actually <strong>wasn't launching via Fargate</strong>. I had made a mistake during the initial <code>configure</code> command, so the default config was using EC2 launch type. When making the cluster it created an Autoscaling Group template with t2.micro in it, and then it was using this to launch the initial instance. I didn't think this was unusual, as I read that Fargate managed your EC2's for you, which I presumed was what was happening. No, this was ""traditional"" EC2 creation via a scaling template.</p>

<p>I figured out the mistake by viewing the config file. I noticed <code>ecs-cli</code> doesn't have any ""view config"" commands - they only write to the config, so it feels a bit mysterious when you are issuing later commands, especially as <a href=""https://github.com/aws/amazon-ecs-cli#configuring-defaults"" rel=""nofollow noreferrer"">you are encouraged to set lots of defaults</a> (presumably to simplify the CLI commands which get long and cumbersome).</p>

<pre><code>less ~/.ecs/config 

version: v1
default: MY-TRIAL-CONFIG
clusters:
  MY-TRIAL-CONFIG:
    cluster: MY-TRIAL-CLUSTER
    region: ap-southeast-2
    default_launch_type: """"      &lt;= this was the problem
  tutorial:
    cluster: tutorial
    region: ap-southeast-2
    default_launch_type: FARGATE
</code></pre>

<p>So I then tried the EC2-only parameter:</p>

<pre><code>ecs-cli up --instance-type ""t2.small"" --capability-iam
</code></pre>

<p>and this changed the Autoscaling Group and indeed launched a t2.small. So I now know how to do it the EC2 way.</p>

<p>To do it properly as I had originally intended with Fargate, I needed <code>default-launch-type FARGATE</code>:</p>

<pre><code>ecs-cli configure --cluster MY-TRIAL-CLUSTER --region ap-southeast-2 --default-launch-type FARGATE --config-name MY-TRIAL-CONFIG
</code></pre>

<p>Now the config looks like this:</p>

<pre><code>less ~/.ecs/config 

version: v1
default: MY-TRIAL-CONFIG
clusters:
  MY-TRIAL-CONFIG:
    cluster: MY-TRIAL-CLUSTER
    region: ap-southeast-2
    default_launch_type: FARGATE
  tutorial:
    cluster: tutorial
    region: ap-southeast-2
    default_launch_type: FARGATE
</code></pre>

<p>After doing this, <code>ecs-cli compose service up</code> works very differently from the observed ECS launch flow.</p>

<ol>
<li>it doesn't create any Autoscaling stuff</li>
<li>it doesn't launch any EC2 instances (I thought Fargate did, but managed it for you, but you don't get to see the container hosts)</li>
<li>It created a Cloudformation Stack instead (interestingly with a t2.micro EcsInstanceType parameter)</li>
<li>It's very clearly labelled on the Cluster home page: there's a row for EC2 launch types below the FARGATE row. </li>
</ol>

<p>e.g.</p>

<pre><code>MY-TRIAL-CLUSTER &gt;
FARGATE
1          0             1
Services   Running tasks Pending tasks

EC2
0        0             0                                              0
Services Running tasks Pending tasks CPUUtilization MemoryUtilization Container instances
</code></pre>

<p>It's very clear now I see it. There are no instances for Fargate services.</p>

<p>You can also watch Fargate re-start the task-containers if they fail, either in the control panel, or with <code>ecs-cli compose service ps</code> and <code>ecs-cli logs --task-id XXX --follow</code>, to get a feel for the magic and how the Docker Compose features are being performed.</p>
",1218,2018-12-13T23:18:15.993,"['less ~/.ecs/config \n\nversion: v1\ndefault: MY-TRIAL-CONFIG\nclusters:\n  MY-TRIAL-CONFIG:\n    cluster: MY-TRIAL-CLUSTER\n    region: ap-southeast-2\n    default_launch_type: """"      <= this was the problem\n  tutorial:\n    cluster: tutorial\n    region: ap-southeast-2\n    default_launch_type: FARGATE\n', 'ecs-cli up --instance-type ""t2.small"" --capability-iam\n', 'ecs-cli configure --cluster MY-TRIAL-CLUSTER --region ap-southeast-2 --default-launch-type FARGATE --config-name MY-TRIAL-CONFIG\n', 'less ~/.ecs/config \n\nversion: v1\ndefault: MY-TRIAL-CONFIG\nclusters:\n  MY-TRIAL-CONFIG:\n    cluster: MY-TRIAL-CLUSTER\n    region: ap-southeast-2\n    default_launch_type: FARGATE\n  tutorial:\n    cluster: tutorial\n    region: ap-southeast-2\n    default_launch_type: FARGATE\n', 'MY-TRIAL-CLUSTER >\nFARGATE\n1          0             1\nServices   Running tasks Pending tasks\n\nEC2\n0        0             0                                              0\nServices Running tasks Pending tasks CPUUtilization MemoryUtilization Container instances\n']"
659,5753,5385,CC BY-SA 4.0,2018-12-16T06:30:45.370,"<p>Answers to some parts of your question are:</p>

<ul>
<li><p>""I want to find a softlink (to another file) in the $PATH environment variable on Linux managed nodes""</p>

<p>Use ""shell"" module instead of lookup. </p>

<blockquote>
  <p><a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_lookups.html#lookups-and-variables"" rel=""nofollow noreferrer"">Lookup</a> occur on the local computer, not on the remote computer.</p>
</blockquote></li>
<li><p>""I want to extract the path of the file name for the file that is found. How do I do this?""</p>

<p>Use ""files_found.files"" to see the complete path. Checkout the return values section in <a href=""https://docs.ansible.com/ansible/latest/modules/find_module.html#return-values"" rel=""nofollow noreferrer"">find</a> module documentation.</p></li>
<li><p>As far as i understood, you want to do something like this</p></li>
</ul>

<p>Try out the following:</p>

<pre><code>- name: finding files matching ""goodfile"" pattern
  find:
     paths: ""{{ some_path }}""
     patterns: ""goodfile""
     file_type: link
  register: files_found

- name : get the complete path
  set_fact:
    files_found_path: ""{{ files_found.files }}""

 - debug:
     var: files_found_path
</code></pre>
",10912,2018-12-16T06:46:32.877,"['- name: finding files matching ""goodfile"" pattern\n  find:\n     paths: ""{{ some_path }}""\n     patterns: ""goodfile""\n     file_type: link\n  register: files_found\n\n- name : get the complete path\n  set_fact:\n    files_found_path: ""{{ files_found.files }}""\n\n - debug:\n     var: files_found_path\n']"
660,5772,5761,CC BY-SA 4.0,2018-12-18T12:33:38.073,"<p>You do not specify a volume source when you define a volume in an image. Doing so would be a potential security exploit where an image could mount a private volume with a common name and send the contents of that volume over the network. To create your volumes with known names, and have that defined in a file, you would do that at runtime with a docker-compose.yml file when the container is created. E.g.</p>

<pre><code>version: '3'
volumes:
  - app_data
services:
  app:
    image: your_image:1.0
    volumes:
      - app_data:/data
</code></pre>
",7730,2018-12-18T12:33:38.073,"[""version: '3'\nvolumes:\n  - app_data\nservices:\n  app:\n    image: your_image:1.0\n    volumes:\n      - app_data:/data\n""]"
661,5776,1343,CC BY-SA 4.0,2018-12-18T16:11:45.120,"<p>Yes, it's possible. You can use <code>--parallel</code> option since docker-composer 1.23.2 version.</p>

<p>Version 1.23.2 also correct 1.23.0 bug: </p>

<blockquote>
  <p>Reverted a 1.23.0 change that appended random strings to container
  names created by docker-compose up, causing addressability issues.
  Note: Containers created by docker-compose run will continue to use
  randomly generated names to avoid collisions during parallel runs.</p>
</blockquote>

<p><a href=""https://github.com/docker/compose/releases/tag/1.23.2"" rel=""noreferrer"">https://github.com/docker/compose/releases/tag/1.23.2</a></p>

<p>You can use it simply doing:</p>

<pre><code>docker-compose build --parallel
</code></pre>
",7478,2019-08-25T09:36:47.740,['docker-compose build --parallel\n']
662,5788,5785,CC BY-SA 4.0,2018-12-19T04:58:21.227,"<p>YAML is a very simple, text/human-readable annotation format that can be used to store data.
YAML keeps data stored as a map containing keys and values associated to those keys. This map is in no particular order, so you can reorder it at will. Each pair is in the format KEY: VALUE
When the value is a text string enclose the value with quotes. Some examples below:</p>

<pre><code>KEY1: 'HELLO'
HOST_NUMBER: 1
</code></pre>
",10690,2018-12-19T04:58:21.227,"[""KEY1: 'HELLO'\nHOST_NUMBER: 1\n""]"
663,5798,3050,CC BY-SA 4.0,2018-12-20T13:55:22.537,"<p>From your comment</p>

<blockquote>
  <p>I was hoping for unit tests of target code, some analysis à la valgrind all the way to CD</p>
</blockquote>

<p>I had <a href=""https://arduino.stackexchange.com/a/50534/42393"">an answer to the Arduino StackExchange question that was mentioned</a>, which addresses some of this.  But since writing that answer I've added some memory-checking features to <a href=""https://github.com/ianfixes/arduino_ci"" rel=""nofollow noreferrer""><code>arduino_ci</code></a> [of which, full disclosure, I am the author].</p>

<p>Although it doesn't do static analysis, it can <a href=""https://travis-ci.org/ianfixes/AcceleratedLED/builds/428427957#L185"" rel=""nofollow noreferrer"">detect certain kinds of memory problems while running unit tests</a>:</p>

<pre><code>==2284==ERROR: AddressSanitizer: heap-use-after-free on address 0x603000000280 at pc 
0x0001032b987e bp 0x7ffeec94c0b0 sp 0x7ffeec94c0a8
READ of size 1 at 0x603000000280 thread T0
    #0 0x1032b987d in Adafruit_WS2801::show() Adafruit_WS2801.cpp:203
    #1 0x1032b84b1 in Strip::init(unsigned char, unsigned char) Strip.cpp:10
    #2 0x1032baaff in test_set_strip_values::task() strip.cpp:10
    #3 0x1032bd900 in Test::test() ArduinoUnitTests.h:165
    #4 0x1032bcfd4 in Test::run(Test::ReporterTAP*) ArduinoUnitTests.h:137
    #5 0x1032bcb79 in Test::run_and_report(int, char**) ArduinoUnitTests.h:155
    #6 0x1032bcab8 in main strip.cpp:43
    #7 0x7fff769d0114 in start (libdyld.dylib:x86_64+0x1114)
</code></pre>

<p>More context in <a href=""https://github.com/adafruit/Adafruit-WS2801-Library/pull/20"" rel=""nofollow noreferrer"">the pull request that fixes this problem</a></p>
",11471,2018-12-20T13:55:22.537,"['==2284==ERROR: AddressSanitizer: heap-use-after-free on address 0x603000000280 at pc \n0x0001032b987e bp 0x7ffeec94c0b0 sp 0x7ffeec94c0a8\nREAD of size 1 at 0x603000000280 thread T0\n    #0 0x1032b987d in Adafruit_WS2801::show() Adafruit_WS2801.cpp:203\n    #1 0x1032b84b1 in Strip::init(unsigned char, unsigned char) Strip.cpp:10\n    #2 0x1032baaff in test_set_strip_values::task() strip.cpp:10\n    #3 0x1032bd900 in Test::test() ArduinoUnitTests.h:165\n    #4 0x1032bcfd4 in Test::run(Test::ReporterTAP*) ArduinoUnitTests.h:137\n    #5 0x1032bcb79 in Test::run_and_report(int, char**) ArduinoUnitTests.h:155\n    #6 0x1032bcab8 in main strip.cpp:43\n    #7 0x7fff769d0114 in start (libdyld.dylib:x86_64+0x1114)\n']"
664,5819,5735,CC BY-SA 4.0,2018-12-24T11:50:23.470,"<p>First, use alpine images if possible.</p>

<p>Second, use ENV variables for prepare database configuration. <a href=""https://hub.docker.com/_/postgres/#environment-variables"" rel=""noreferrer"">More info</a>.</p>

<p>Third, use <code>/docker-entrypoint-initdb.d</code> directory for extend image. <a href=""https://hub.docker.com/_/postgres/#how-to-extend-this-image"" rel=""noreferrer"">More info</a>.</p>

<p>Example stack with devlopment environment.</p>

<pre><code>version: '3.2'
services:
  example:
    image: ""${EXAMPLE_SERVICE}:${EXAMPLE_SERVICE__VERSION}-development""
    build:
      context: .
      dockerfile: Dockerfile.development
    networks:
      - net
    ports:
      - 5000:5000
    depends_on:
      - example__migrator
    stdin_open: true
    tty: true
    environment:
      POSTGRES_PASSWORD: example
      POSTGRES_DB: example
      POSTGRES_USER: example
      POSTGRES_HOST: pg.example_net
      POSTGRES_PORT: 5432
      FLASK_APP: app.py
      FLASK_DEBUG: 1
    volumes:
      - .:/home/example
  example__migrator:
    image: ""${EXAMPLE_SERVICE}:${EXAMPLE_SERVICE__VERSION}-development""
    build:
      context: .
    command: sh -c './wait-for pg.example_net:5432 -- python manage.py db upgrade'
    networks:
      - net
    depends_on:
      - pg
    environment:
      POSTGRES_PASSWORD: example
      POSTGRES_DB: example
      POSTGRES_USER: example
      POSTGRES_HOST: pg.example_net
      POSTGRES_PORT: 5432
  pg:
    image: postgres:10.0-alpine
    networks:
      - net
    ports:
      - 5432:5432
    volumes:
      - pg_data:/var/lib/postgresql/data/pg_data
    environment:
      POSTGRES_PASSWORD: example
      POSTGRES_DB: example
      POSTGRES_USER: example
      POSTGRES_HOST: pg.example_net
      POSTGRES_PORT: 5432
      PGDATA: /var/lib/postgresql/data/pg_data
networks:
  net:
volumes:
  pg_data:
</code></pre>
",9884,2018-12-24T11:50:23.470,"['version: \'3.2\'\nservices:\n  example:\n    image: ""${EXAMPLE_SERVICE}:${EXAMPLE_SERVICE__VERSION}-development""\n    build:\n      context: .\n      dockerfile: Dockerfile.development\n    networks:\n      - net\n    ports:\n      - 5000:5000\n    depends_on:\n      - example__migrator\n    stdin_open: true\n    tty: true\n    environment:\n      POSTGRES_PASSWORD: example\n      POSTGRES_DB: example\n      POSTGRES_USER: example\n      POSTGRES_HOST: pg.example_net\n      POSTGRES_PORT: 5432\n      FLASK_APP: app.py\n      FLASK_DEBUG: 1\n    volumes:\n      - .:/home/example\n  example__migrator:\n    image: ""${EXAMPLE_SERVICE}:${EXAMPLE_SERVICE__VERSION}-development""\n    build:\n      context: .\n    command: sh -c \'./wait-for pg.example_net:5432 -- python manage.py db upgrade\'\n    networks:\n      - net\n    depends_on:\n      - pg\n    environment:\n      POSTGRES_PASSWORD: example\n      POSTGRES_DB: example\n      POSTGRES_USER: example\n      POSTGRES_HOST: pg.example_net\n      POSTGRES_PORT: 5432\n  pg:\n    image: postgres:10.0-alpine\n    networks:\n      - net\n    ports:\n      - 5432:5432\n    volumes:\n      - pg_data:/var/lib/postgresql/data/pg_data\n    environment:\n      POSTGRES_PASSWORD: example\n      POSTGRES_DB: example\n      POSTGRES_USER: example\n      POSTGRES_HOST: pg.example_net\n      POSTGRES_PORT: 5432\n      PGDATA: /var/lib/postgresql/data/pg_data\nnetworks:\n  net:\nvolumes:\n  pg_data:\n']"
665,5833,4189,CC BY-SA 4.0,2018-12-26T23:09:54.590,"<p>The typical approach is to use a folder per environment that contains identically named files: </p>

<pre><code>conf/dev/application.properties
conf/test/application.properties
conf/uat/application.properties
conf/prod/application.properties
</code></pre>

<p>Then parameterize the @PropertySource to use an  environment variable such as ""env"": </p>

<pre><code>@PropertySource(""file:${catalina.base}/conf/${env}/application.properties"") 
</code></pre>

<p>Now you simply need to ensure that in each environment there is an operating system environment variable defined called ""env"" that is set correctly (i.e, dev, test, uat or prod). You haven't stated how your launch your application (j2ee server launch script on linux? springboot docker container?) but it shouldn't be a problem to set the environment variable in each environment. </p>

<p>Rather than load files from ""${catalina.base}"" you can load files from the classpath with something like: </p>

<pre><code>// see https://stackoverflow.com/a/26387933/329496
@PropertySource(""classpath:${env}/application.properties"")
</code></pre>

<p>If you are building with maven you can create the folders under <code>src/main/resources</code> and they will be <a href=""https://stackoverflow.com/a/9063515/329496"">copied into the classpath</a>: </p>

<pre><code>src/main/resources/dev/application.properties
src/main/resources/test/application.properties
src/main/resources/uat/application.properties
src/main/resources/prod/application.properties
</code></pre>

<p>That simplified things quite a lot. Jenkins doesn't need to do anything at all as the same build/release artefact can be run in any and every environment. It is usually an anti-pattern to have Jenkins have to do extra work to reconfigure an application to work in a particular environment. Rather you should aim to have a single Jenkins release job build an artefact that can be simply copied between environments.   </p>

<p>There is one downside to such an approach. If you want to create a new environment you have to add a new file into source control and create a new release artefact. With legacy technologies setting up new environments is a lot of work (e.g., commissioning VMs and databases) such that this ""extra step"" of adding a file to the code doesn't seem like a problem. </p>

<p>With more modern cloud-native technologies like Kubernetes, you can set up environments in seconds, and ""on-demand"". In which case you don't want to be pre-specifying your environments within your codebase. Rather you should follow a <a href=""http://12factor.net"" rel=""nofollow noreferrer"">12factor.net</a> approach and define every single property as an environment variable and have spring just use them directly. If you look at the current <a href=""https://docs.spring.io/spring-boot/docs/current/reference/html/boot-features-external-config.html"" rel=""nofollow noreferrer"">springboot documentation</a> it uses environment variables by default. This means if you haven't defined a <code>@PropertySource</code> but you are using things like: </p>

<pre><code>@Value(""${name}"")
private String name;
</code></pre>

<p>they will bbe set from the environment variable of the <a href=""http://mrhaki.blogspot.com/2015/09/spring-sweets-setting-configuration.html"" rel=""nofollow noreferrer"">same name but using all caps</a>. This then moves the problem to ""how do we make sure that the environment variables are correctly set up in each environment"". Technologies that make it easy to spin up environments in seconds (kubernetes, cloudfoundry, swarm) also typically make it easy to manage environment variables. With kubernetes you create a ""ConfigMap"" (e.g. ""my-app-properties"") and have <a href=""https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables"" rel=""nofollow noreferrer"">it mounted as the environment variables</a> where every key+value defines a unique environment variable for the application. Each logical environment can then be a separate Kubernetes namespace (possibly on a shared cluster for dev/test but a dedicated cluster for prod) that has its own ""my-app-properties"" configuration object that defines the environment variables for that logical environment . </p>

<p>You can put these settings under source control but not in the application source repo. Rather you can take an ""infrastructure as code"" approach where everything that runs the application (e.g., all scripts and yaml to set up the environments) is in it's own separate git repo. You can then set up a configuration deploy job that is triggered by a git webhook on the configuration repo. This can push out the new environment variables. That allows you to have continuous deployment of configuration changes that are independent of the continuous deployment of application code. </p>

<p>If you are using Kubernetes then Helmfile is an excellent choice for that is it won't update anything in kubernetes that hasn't changed within git. This means it is safe to reapply all the configuration in the git repo on every push to a protected master branch; helmfile will double check what is already deployed and only update Kubernetes configuration objects that need to be updated. </p>
",10599,2018-12-27T12:50:45.667,"['conf/dev/application.properties\nconf/test/application.properties\nconf/uat/application.properties\nconf/prod/application.properties\n', '@PropertySource(""file:${catalina.base}/conf/${env}/application.properties"") \n', '// see https://stackoverflow.com/a/26387933/329496\n@PropertySource(""classpath:${env}/application.properties"")\n', 'src/main/resources/dev/application.properties\nsrc/main/resources/test/application.properties\nsrc/main/resources/uat/application.properties\nsrc/main/resources/prod/application.properties\n', '@Value(""${name}"")\nprivate String name;\n']"
666,5836,4572,CC BY-SA 4.0,2018-12-27T14:54:13.853,"<p>Docker was built for linux, it runs on Mac through HyperkIT, which is a lightweight hypervisor. This means Docker only sees devices connected to the hyperkit hypervisor, rather than the devices connected to the Mac.</p>

<p>Unfortunately, Hyperkit has issues with USB device passthrough from your MacOS to the hypervisor (read more <a href=""https://github.com/moby/hyperkit/issues/149"" rel=""nofollow noreferrer"">here</a>) so the --device command won't be much use to you here. You have three options,</p>

<p>Option 1: Mount the ext4 drive to your Mac (not recommended)</p>

<p>Whilst your Mac doesn't natively support ext4, there are ways around this. I have installed ext4fuse on your Mac by following <a href=""https://apple.stackexchange.com/questions/210198/mount-ext4-on-el-capitan"">this</a> tutorial. When you have mounted your device, add it to your ubuntu container with the -v flag,</p>

<pre><code>docker run -v &lt;Your_volume&gt;:&lt;dest_volume&gt; -it ubuntu bash
</code></pre>

<p>Making sure that the directory of your volume has been added to the file sharing folders in Docker.</p>

<p>Option 2: create a docker-machine using the virtualbox driver and add the device to the virtualbox vm (still not recommended)</p>

<p>Follow this great tutorial <a href=""https://milad.ai/docker/2018/05/06/access-usb-devices-in-container-in-mac.html"" rel=""nofollow noreferrer"">here</a> which goes through installing a docker machine with a virtualbox driver and mounting the USB stick.</p>

<p>Option 3: Run Docker on linux (recommended!)</p>

<p>I wouldn't recommend using Docker for Mac. It was built for linux and if you don't switch to linux you'll waste your time troubleshooting issues like these for no real reason.</p>

<p>I've got a mac, but run a few ubuntu cores in virtualbox and then install docker on top of them, that way I can play around with docker starm too (which you can't with docker Mac unless you use docker-machine!</p>
",11545,2018-12-27T14:54:13.853,['docker run -v <Your_volume>:<dest_volume> -it ubuntu bash\n']
667,5837,5829,CC BY-SA 4.0,2018-12-27T15:13:55.397,"<p><code>ansible-lint</code> warning <code>405</code> can be quite irritating as in certain cases, i.e. when running locally retrying is very unlikely to make any difference.  Actually resolving it is normally simply a case of adding the following:</p>

<pre><code>register: task_result
until: task_result is success
retries: 10
delay: 2
</code></pre>

<p>When this is added to task Ansible will retry ten times with a delay of two seconds between each retry until the <code>returncode</code> is <code>0</code>.</p>
",397,2018-12-28T14:44:21.980,['register: task_result\nuntil: task_result is success\nretries: 10\ndelay: 2\n']
668,5859,1626,CC BY-SA 4.0,2018-12-31T19:26:38.363,"<p>Attach below policy to that user:</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                        ""s3:GetBucketLocation"",
                        ""s3:ListAllMyBuckets""
                      ],
            ""Resource"": ""arn:aws:s3:::*""
        },
        {
            ""Effect"": ""Allow"",
            ""Action"": ""s3:*"",
            ""Resource"": [
                ""arn:aws:s3:::YOUR-BUCKET"",
                ""arn:aws:s3:::YOUR-BUCKET/*""
            ]
        }
    ]
}
</code></pre>

<p><a href=""https://www.serverkaka.com/2018/05/grant-access-to-only-one-s3-bucket-to-aws-user.html"" rel=""nofollow noreferrer"">https://www.serverkaka.com/2018/05/grant-access-to-only-one-s3-bucket-to-aws-user.html</a></p>
",11598,2018-12-31T19:26:38.363,"['{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                        ""s3:GetBucketLocation"",\n                        ""s3:ListAllMyBuckets""\n                      ],\n            ""Resource"": ""arn:aws:s3:::*""\n        },\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": ""s3:*"",\n            ""Resource"": [\n                ""arn:aws:s3:::YOUR-BUCKET"",\n                ""arn:aws:s3:::YOUR-BUCKET/*""\n            ]\n        }\n    ]\n}\n']"
669,5862,5846,CC BY-SA 4.0,2019-01-01T19:52:17.997,"<p>In lack of a better idea I chose this rather long approach:</p>

<p><strong>myid.j2</strong></p>

<pre><code>{% for host in groups['zookeeper'] %}
{% if host == inventory_hostname %}
{{ loop.index }}
{% endif %}
{% endfor %}
</code></pre>

<p>The idea is to iterate over all hosts and check if the current host being processed matches the host in the list of hosts. If it matches I write the iteration counter to the file.</p>

<p>When I ssh into the boxes I can see their myid files were created according to my need:</p>

<pre><code>[root@quorumandmonitoring data]# cat myid
5
</code></pre>
",11581,2019-01-01T19:52:17.997,"[""{% for host in groups['zookeeper'] %}\n{% if host == inventory_hostname %}\n{{ loop.index }}\n{% endif %}\n{% endfor %}\n"", '[root@quorumandmonitoring data]# cat myid\n5\n']"
670,5868,5864,CC BY-SA 4.0,2019-01-02T21:03:05.813,"<p>Perhaps a macro might be what you are looking for.</p>

<p><a href=""https://docs.saltstack.com/en/latest/topics/jinja/index.html#macros"" rel=""nofollow noreferrer"">Understanding Jinja:Macros</a></p>

<p>In the lib.sls example in the link (pasted below), it sets a value contingent on the value of the if statement.  I think a similar approach could work for you.</p>

<pre><code>{% macro pythonpkg(pkg) -%}
  {%- if grains['os'] == 'FreeBSD' -%}
    py27-{{ pkg }}
  {%- elif grains['os'] == 'Debian' -%}
    python-{{ pkg }}
  {%- endif -%}
{%- endmacro %}
</code></pre>
",11627,2019-01-02T21:03:05.813,"[""{% macro pythonpkg(pkg) -%}\n  {%- if grains['os'] == 'FreeBSD' -%}\n    py27-{{ pkg }}\n  {%- elif grains['os'] == 'Debian' -%}\n    python-{{ pkg }}\n  {%- endif -%}\n{%- endmacro %}\n""]"
671,5870,5863,CC BY-SA 4.0,2019-01-03T01:32:49.017,"<p>You want a <a href=""https://en.wikipedia.org/wiki/Revision_Control_System"" rel=""nofollow noreferrer"">RCS/VCS</a> that handles the version incrementally for you. I'm not sure how this relates to CI as the idea is to <a href=""https://stackify.com/continuous-delivery-git-jenkins/"" rel=""nofollow noreferrer"">Continuously Integrate</a> instead of spawning more branches. I'm not sure what you're using for your PR's, so I'll use Atlassian Bitbucket as an example. In the response to pushing up a new branch you get back the url for creating a PR which has an <a href=""https://developer.atlassian.com/cloud/bitbucket/"" rel=""nofollow noreferrer"">API which you can call to create your PR</a>.
Git commands will do the branching for you: </p>

<pre><code># Get the latest description, usually based on tags : https://git-scm.com/book/en/v2/Git-Basics-Tagging
$branchName = git describe
# Checkout the new branch 
git checkout -b $branchName
# Push up the branch to origin
git push --set-upstream origin feature/$branchName
</code></pre>

<p>It's best to have a firm grasp of git when dealing with VCS. 
* <a href=""https://try.github.io/"" rel=""nofollow noreferrer"">https://try.github.io/</a> 
* <a href=""https://git-scm.com/book/en/v2/Getting-Started-Git-Basics"" rel=""nofollow noreferrer"">https://git-scm.com/book/en/v2/Getting-Started-Git-Basics</a></p>
",9030,2019-01-03T01:32:49.017,"['# Get the latest description, usually based on tags : https://git-scm.com/book/en/v2/Git-Basics-Tagging\n$branchName = git describe\n# Checkout the new branch \ngit checkout -b $branchName\n# Push up the branch to origin\ngit push --set-upstream origin feature/$branchName\n']"
672,5871,5842,CC BY-SA 4.0,2019-01-03T12:40:49.613,"<p>I could see some spelling mistakes in the below mentioned line, rest all are fine i think.</p>

<pre><code>delete_on_termination = ""${var.delete_on_termincation}""
</code></pre>

<p>Better you could avoid this line, This might be deleting the EBS when u terminating the ec2 instance. Skip this option and check.</p>
",11635,2019-01-03T12:40:49.613,"['delete_on_termination = ""${var.delete_on_termincation}""\n']"
673,5883,5292,CC BY-SA 4.0,2019-01-04T12:33:11.747,"<p>This is the way to go:</p>

<pre><code>stage('Deploy'){
  when {
    expression {env.GIT_BRANCH == 'origin/master'}
  }
  steps {
    ....
   }
}
</code></pre>

<p>Take care, this is only working with the declarative syntax.</p>

<p>The environment step is used to ""set up the environment"" meaning this is the place to declare environmental variables. </p>

<p>Also, in my case I did not declare the GIT_BRANCH var myself. But jenkins provides it as an environmental (therefore ""env.GIT_BRANCH"") variable if you did ""checkout scm"" to checkout your repository. If you want to check all the available env vars, do this as a step: <code>sh 'printenv'</code></p>

<p>check out this article for more info: <a href=""https://jenkins.io/blog/2017/01/19/converting-conditional-to-pipeline/"" rel=""nofollow noreferrer"">https://jenkins.io/blog/2017/01/19/converting-conditional-to-pipeline/</a></p>
",11654,2019-01-04T12:41:04.920,"[""stage('Deploy'){\n  when {\n    expression {env.GIT_BRANCH == 'origin/master'}\n  }\n  steps {\n    ....\n   }\n}\n""]"
674,5888,5882,CC BY-SA 4.0,2019-01-04T19:29:27.810,"<p>Try this: </p>

<pre><code># Get status
curl http://localhost:8081/nexus/service/local/status 
# List of repositories
curl http://localhost:8081/nexus/service/local/repositories
</code></pre>

<p>For the json parameter: </p>

<pre><code>curl -i -H ""Accept: application/json"" &lt;url&gt;
</code></pre>

<p>More information, see this <a href=""http://www.sonatype.com/people/2012/07/learning-the-nexus-rest-api-read-the-docs-or-fire-up-a-browser/"" rel=""nofollow noreferrer"">link</a></p>
",9838,2019-01-04T19:29:27.810,"['# Get status\ncurl http://localhost:8081/nexus/service/local/status \n# List of repositories\ncurl http://localhost:8081/nexus/service/local/repositories\n', 'curl -i -H ""Accept: application/json"" <url>\n']"
675,5908,5907,CC BY-SA 4.0,2019-01-08T03:12:15.700,"<p>I'll go out on a limb here and assume that the issue is actually in your ""aws_instance"" block and is likely the result of how you are assigning the security groups in the ""aws_instance"".</p>

<p>Copied from the first linked article, in the resolution: </p>

<pre><code>change 

security_groups = [""cloud9Test""]

to

vpc_security_group_ids = [""${aws_security_group.cloud9Test.id}""]
</code></pre>

<p>Two related articles:</p>

<p><a href=""https://github.com/KainosSoftwareLtd/aws-api-gateway-demo/issues/3"" rel=""nofollow noreferrer"">https://github.com/KainosSoftwareLtd/aws-api-gateway-demo/issues/3</a></p>

<p><a href=""https://stackoverflow.com/questions/31569910/terraform-throws-groupname-cannot-be-used-with-the-parameter-subnet-or-vpc-se/34586893#34586893"">https://stackoverflow.com/questions/31569910/terraform-throws-groupname-cannot-be-used-with-the-parameter-subnet-or-vpc-se/34586893#34586893</a></p>

<p>If this is not on track, please post the ""aws_instance"" declaration. </p>

<p>For your own sanity I'd also recommend giving the resources names that are more specific to their role, and not identical, for example ""cloud9Test_vpc"". </p>
",9839,2019-01-08T03:12:15.700,"['change \n\nsecurity_groups = [""cloud9Test""]\n\nto\n\nvpc_security_group_ids = [""${aws_security_group.cloud9Test.id}""]\n']"
676,5912,3155,CC BY-SA 4.0,2019-01-08T13:27:24.683,"<p>This is how I do it:</p>

<pre><code>- name: Add certbot repository
  apt_repository:
    repo: 'ppa:certbot/certbot'

- name: Install Certbot's Apache package
  apt:
    name: python-certbot-apache
    state: present
</code></pre>
",11714,2019-01-08T13:27:24.683,"[""- name: Add certbot repository\n  apt_repository:\n    repo: 'ppa:certbot/certbot'\n\n- name: Install Certbot's Apache package\n  apt:\n    name: python-certbot-apache\n    state: present\n""]"
677,5925,5921,CC BY-SA 4.0,2019-01-09T09:23:26.180,"<p>if you do something like:</p>

<pre><code>- name: Launch instance
  ec2:
  register: data_struct
</code></pre>

<p>You can then output all the values returned by doing this below the above code:</p>

<pre><code>- name: print all returned values
  debug:
    msg: ""{{ data_struct }}""
</code></pre>
",8858,2019-01-09T09:23:26.180,"['- name: Launch instance\n  ec2:\n  register: data_struct\n', '- name: print all returned values\n  debug:\n    msg: ""{{ data_struct }}""\n']"
678,5951,5949,CC BY-SA 4.0,2019-01-11T09:41:25.577,"<p>You can use '<strong>Publish Over SSH plugin</strong>'. Using this plugin you can send files and execute the command on the remote server.</p>
<p><a href=""https://wiki.jenkins.io/display/JENKINS/Publish+Over+SSH+Plugin"" rel=""nofollow noreferrer"">Click Here For install plugin.</a></p>
<h1>Configure</h1>
<ol>
<li>Click “Manage Jenkins”</li>
<li>Click “Configure System”</li>
<li>Go to “Publish over SSH” section</li>
<li>Enter “/Users/Shared/Jenkins/.ssh/id_rsa” to “Path to Key”</li>
<li>Click “Add” at “SSH Servers”</li>
<li>Enter any logical name to “Name”</li>
<li>Enter IP Address or Hostname of the server to “Hostname”</li>
<li>Enter the user name to log in to “Username”</li>
<li>Enter any directory to “Remote Directory”</li>
<li>Click “Test Configuration”</li>
<li>Click “Save” at bottom of the page</li>
</ol>
<p><a href=""https://i.stack.imgur.com/mHsAV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mHsAV.png"" alt=""enter image description here"" /></a></p>
<h1>Create a job</h1>
<ol>
<li>Create or copy a job that can build the WAR correctly.</li>
<li>As I wrote in How to specify a Git tag to be processed, make a job to can specify a
tag to be processed.</li>
<li>Click “Add post-build action”</li>
<li>Click “Send build artifacts over SSH”</li>
<li>Enter “Source files”</li>
<li>Enter “Remove prefix”</li>
<li>Enter “Exec command”</li>
</ol>
<p><a href=""https://i.stack.imgur.com/rlpr2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rlpr2.png"" alt=""enter image description here"" /></a></p>
<p>For More reference:</p>
<ol>
<li><a href=""https://nozaki.me/roller/kyle/entry/articles-jenkins-sshdeploy"" rel=""nofollow noreferrer"">https://nozaki.me/roller/kyle/entry/articles-jenkins-sshdeploy</a></li>
<li><a href=""https://medium.com/@weblab_tech/how-to-publish-artifacts-in-jenkins-f021b17fde71"" rel=""nofollow noreferrer"">https://medium.com/@weblab_tech/how-to-publish-artifacts-in-jenkins-f021b17fde71</a></li>
<li><a href=""https://wiki.jenkins.io/display/JENKINS/Publish+Over+SSH+Plugin"" rel=""nofollow noreferrer"">https://wiki.jenkins.io/display/JENKINS/Publish+Over+SSH+Plugin</a></li>
</ol>
<p>you can also do the same thing in pipeline script, see below images:
<a href=""https://i.stack.imgur.com/XdynF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XdynF.png"" alt=""enter image description here"" /></a></p>
<pre><code>node(master)
{
  stage(Deploy)
  {
     sshPublisher(publishers: [sshPublisherDesc(configName: 'LAB-35', transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: 'apt-get update', execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '', remoteDirectorySDF: false, removePrefix: '', sourceFiles: '*.war')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)])
  }
}
</code></pre>
<p>Here configName: 'LAB-35' is your remote ssh server.</p>
",11598,2019-01-11T11:19:47.920,"[""node(master)\n{\n  stage(Deploy)\n  {\n     sshPublisher(publishers: [sshPublisherDesc(configName: 'LAB-35', transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: 'apt-get update', execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '', remoteDirectorySDF: false, removePrefix: '', sourceFiles: '*.war')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)])\n  }\n}\n""]"
679,5958,5949,CC BY-SA 4.0,2019-01-12T10:22:18.837,"<p>Below is sample groovy code for sending file or execute command over SSH in jenkins: </p>

<pre><code>node(master)
{
  stage(Deploy)
  {
     sshPublisher(publishers: [sshPublisherDesc(configName: 'SERVER_NAME', transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: 'apt-get update', execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '', remoteDirectorySDF: false, removePrefix: '', sourceFiles: '*.war')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)])
  }
}
</code></pre>
",11797,2019-01-12T10:22:18.837,"[""node(master)\n{\n  stage(Deploy)\n  {\n     sshPublisher(publishers: [sshPublisherDesc(configName: 'SERVER_NAME', transfers: [sshTransfer(cleanRemote: false, excludes: '', execCommand: 'apt-get update', execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false, patternSeparator: '[, ]+', remoteDirectory: '', remoteDirectorySDF: false, removePrefix: '', sourceFiles: '*.war')], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)])\n  }\n}\n""]"
680,5972,5950,CC BY-SA 4.0,2019-01-12T22:34:46.210,"<p>Use a docker image within your pipeline that has <code>helm</code> and other tools installed.</p>

<p>To <a href=""https://jenkins.io/doc/book/pipeline/docker/"" rel=""nofollow noreferrer"">quote the docs</a>:</p>

<blockquote>
  <p>Pipeline is designed to easily use Docker images as the execution
  environment for a single Stage or the entire Pipeline. Meaning that a
  user can define the tools required for their Pipeline, without having
  to manually configure agents. Practically any tool which can be
  packaged in a Docker container. can be used with ease by making only
  minor edits to a Jenkinsfile.</p>
</blockquote>

<p>It then gives an example that we can modify to show running helm:</p>

<pre><code>pipeline {
    agent {
        docker { image 'your_image:1.0' }
    }
    stages {
        stage('Deploy') {
            steps {
                sh 'helm list'
            }
        }
    }
}
</code></pre>

<p>This is a total game changer. Docker is the plugin to end all plugins. Before Docker you had to find a plug-in written in Java that to exposes a DSL to be scriptable in a Groovy sandbox. That was because it was not secure or scalable to let you simply run your own tools and scripts on a shared Jenkins. You were not even allowed use the full power of Groovy or Java. With Docker it is safe run any script or tools. So you no longer have the indirection of Java plugins and you can use the full power of any Linux tool on any Linux distro.</p>

<p>This approach is exactly how new cloud based build engines work. With bitbucket.com pipelines and cricleci.com you don’t need any plugins. You simply say which containers to use and what commands to run within them just like the example above. The build engine simply checks out the code where the docker container can see it.</p>

<p>Once you have used Docker based builds for a while doing it the old way feels very restricted and limiting. For example consider having to move files around in the build. In a pipeline with Groovy if you are new to Jenkins you have to look at a huge amount of (very ugly) documentation to just to basic things. If you use docker you can simply use standard bash and Linux commands.  </p>
",10599,2019-01-12T22:52:11.420,"[""pipeline {\n    agent {\n        docker { image 'your_image:1.0' }\n    }\n    stages {\n        stage('Deploy') {\n            steps {\n                sh 'helm list'\n            }\n        }\n    }\n}\n""]"
681,5982,5928,CC BY-SA 4.0,2019-01-14T13:35:55.083,"<p>I've not tested it, but as the doc says, you can configure the plugin via two ways : ini entries or env.</p>

<p>Add below your snippet the following and it should work : </p>

<pre><code>[defaults]
callback_whitelist = profile_tasks

[callback_profile_tasks]
sort_order = descending
</code></pre>
",11823,2019-01-14T13:35:55.083,['[defaults]\ncallback_whitelist = profile_tasks\n\n[callback_profile_tasks]\nsort_order = descending\n']
682,5984,5980,CC BY-SA 4.0,2019-01-14T14:50:04.837,"<p>Containers are designed to be disposable. Delete the ""A"" container and recreate it with the new volume mount and port number. Note that deleting the container will delete any changes made within the container specific RW filesystem layers. If you have changes in there that you need to preserve, then you really want to make those volume mounts. In the end, the workflow looks like:</p>

<pre><code>docker container rm ${old_container_id}
docker container run -v ${new_volume} -p ${new_port} ...
</code></pre>

<p>As for changing an existing container, there is:</p>

<pre><code>docker container update ...
</code></pre>

<p>however, changing volumes and port bindings are not part of the settings designed to be changed from this. Going under the hood of the docker engine to try to change these settings manually is unsupported and may result in unexpected behavior or a broken engine.</p>
",7730,2019-01-14T14:50:04.837,"['docker container rm ${old_container_id}\ndocker container run -v ${new_volume} -p ${new_port} ...\n', 'docker container update ...\n']"
683,5987,5960,CC BY-SA 4.0,2019-01-14T19:59:44.877,"<p>While I don't know of any operator that allows for this directly, it can be done with a bash one liner with <code>awk</code>, <code>xargs</code>, <code>sed</code>, and gnu <code>date</code>. I've taken it from <a href=""https://stackoverflow.com/questions/48934491/kubernetes-how-to-delete-pods-based-on-age-creation-time"">this  post</a> and modified it to do namespaces, and to not delete the <code>default</code> or <code>kube-*</code> namespaces.</p>

<pre><code>kubectl get namespaces -o go-template --template '{{range .items}}{{.metadata.name}} {{.metadata.creationTimestamp}}{{""\n""}}{{end}}' | awk '$2 &lt;= ""'$(date -d '1 week ago' -Ins --utc | sed 's/+0000/Z/')'"" &amp;&amp; $1 !~ /(default|kube.*)/ { print $1 }' | xargs --no-run-if-empty kubectl delete namespace
</code></pre>

<p>Be careful using this though, it's worth running it without the final xargs call to verify that it is selecting the namespaces you are interested in.</p>
",11568,2019-01-14T19:59:44.877,"['kubectl get namespaces -o go-template --template \'{{range .items}}{{.metadata.name}} {{.metadata.creationTimestamp}}{{""\\n""}}{{end}}\' | awk \'$2 <= ""\'$(date -d \'1 week ago\' -Ins --utc | sed \'s/+0000/Z/\')\'"" && $1 !~ /(default|kube.*)/ { print $1 }\' | xargs --no-run-if-empty kubectl delete namespace\n']"
684,5993,5990,CC BY-SA 4.0,2019-01-15T07:19:33.470,"<p>I cannot say this is a the best answer so I do hope someone can provide a better clarification.  </p>

<p>It seems the default shell for <code>sh()</code> in Jenkins is Bourne.  By updating the <code>sh()</code> with the correct shell this allows the below usage:</p>

<pre><code>sh'''#!/bin/bash
    IFS='/'
    branch=($1)
    # Use it.
'''
</code></pre>

<p>This doesn't resolve the the redirection error.  Also I would think by updating the default shell in the image with <code>chsh -s /bin/bash</code> I wouldn't need to set it but I still do.</p>
",9662,2019-01-15T07:33:59.940,"[""sh'''#!/bin/bash\n    IFS='/'\n    branch=($1)\n    # Use it.\n'''\n""]"
685,5998,5997,CC BY-SA 4.0,2019-01-15T22:15:19.380,"<p>Simply keep pushing stuff between the repositories. Git pushes are designed for exactly that. </p>

<p>So, if <code>origin</code> is the old repository, and <code>new</code>is the new one, and you want to move new stuff in the <code>master</code> branch from <code>origin</code> to <code>new</code>, then, locally:</p>

<pre><code>git checkout master &amp;&amp; git reset --hard    # to clean up any local changes, optional
git pull origin 
git push new
</code></pre>

<p>That's it. <code>master</code> is a branch like any other, so if you have multiple branches, rinse and repeat.</p>
",4175,2019-01-15T22:15:19.380,"['git checkout master && git reset --hard    # to clean up any local changes, optional\ngit pull origin \ngit push new\n']"
686,6008,5980,CC BY-SA 4.0,2019-01-16T12:33:39.860,"<p>First thing first - two containers cannot run on the same host port, while one container is running or stopped, the port is still attached to it, so that same host port scenario won't come in your case. </p>

<p>Regarding changing the volume mount and to run under another port, you can remove the container A and then start another container with either same name or different name and mount point and ports(free ports) as you want them too.</p>

<pre><code>docker stop A;docker rm A;
docker run --ti \
           --name A \
           -p &lt;desrired host port:desired container port&gt; \
           -v &lt;desired mount point:container mount point&gt; \
           -d your_image:tag

</code></pre>
",11832,2019-01-16T12:50:18.740,['docker stop A;docker rm A;\ndocker run --ti \\\n           --name A \\\n           -p <desrired host port:desired container port> \\\n           -v <desired mount point:container mount point> \\\n           -d your_image:tag\n\n']
687,6010,5904,CC BY-SA 4.0,2019-01-16T13:15:29.077,"<p>If I understand you question clearly, you're trying to mount <code>/jaeger-data</code> inside the elastic-search container or pod. To achieve this, what you can do is put this mount details inside the statefulset yaml of the Kubernetes pod for elastic-search. Using the volumeMounts inside the statefulset, you will not need to ssh or exec inside the container or bother about the change or container ID for each pod restart/recreation. You can use the below example as a reference for your <strong>PVC</strong> and <strong>volumeMounts</strong>, just edit your statefulset using <code>kubectl edit sts elasticsearch-0 -n default</code>, this will open an editor and you can replace you PVC details in the below yaml and append and save and exit will recreate your pod and attach the mountpoint:</p>

<pre><code>          volumeMounts:
            - mountPath: /es-storage
              name: jaeger-data
  volumeClaimTemplates:
  - metadata:
      name: es-storage
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 100Gi
</code></pre>

<ul>
<li>Container ID will change with each recreation of containers;</li>
<li>If in case you need to exec into the container, the better way is to use <code>kubectl exec -ti &lt;pod-name&gt; -n &lt;namespace&gt; bash</code> to exec into the container from any of the master node(similar command as docker exec, just replace pod-name and namespace) or from your local laptop if you have kubeconfig configured.</li>
<li>Using <strong>Service</strong>, you can expose this application on a particular port, Kubernetes creates an abstraction and itself takes care of the change of pod IP</li>
</ul>
",11832,2019-01-16T13:15:29.077,['          volumeMounts:\n            - mountPath: /es-storage\n              name: jaeger-data\n  volumeClaimTemplates:\n  - metadata:\n      name: es-storage\n    spec:\n      accessModes:\n      - ReadWriteOnce\n      resources:\n        requests:\n          storage: 100Gi\n']
688,6011,6003,CC BY-SA 4.0,2019-01-16T13:38:30.553,"<p>AFAIK, <strong><em>environment variables</em></strong> are not folder/directory specific, but user specific, that means, for any user its loaded when the user logins into the shell or source the profile which contains the added environment variables (like ~/.bash_profile). So, if your environment variables are present at root directory, it should be present at the folder/job level as well unless your new bash where this job is running, doesn't loads the environment variable, for which you can test them using the below commands in the job to see if those variables are present or not:</p>

<pre><code>pwd
echo $PATH
env
</code></pre>

<p>if not present, you can source your profile in the job using <code>. .bash_profile</code> and check if all variables are present or not</p>
",11832,2019-01-16T13:38:30.553,['pwd\necho $PATH\nenv\n']
689,6012,5827,CC BY-SA 4.0,2019-01-16T13:50:19.093,"<p>Instead of writing your own Dockerfile, you can simply pass auth through environment variables to official images, I use compose file something like this:</p>

<pre><code>version: '3.1'

services:
  mongo:
    image: mongo
    restart: always
    container_name: mongo
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: abcd
    ports:
      - ""27017:27017""
    volumes: 
      - ./databases:/data/db

  mongo-express:
    image: mongo-express
    restart: always
    container_name: mongo-express
    ports:
      - 8081:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: abcd
</code></pre>

<p>you can have your database persisted in ./databases folder and nice in browser ui at port :8081</p>
",11863,2019-01-16T13:50:19.093,"['version: \'3.1\'\n\nservices:\n  mongo:\n    image: mongo\n    restart: always\n    container_name: mongo\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: root\n      MONGO_INITDB_ROOT_PASSWORD: abcd\n    ports:\n      - ""27017:27017""\n    volumes: \n      - ./databases:/data/db\n\n  mongo-express:\n    image: mongo-express\n    restart: always\n    container_name: mongo-express\n    ports:\n      - 8081:8081\n    environment:\n      ME_CONFIG_MONGODB_ADMINUSERNAME: root\n      ME_CONFIG_MONGODB_ADMINPASSWORD: abcd\n']"
690,6013,2458,CC BY-SA 4.0,2019-01-16T14:53:02.383,"<p>I agree with @alitheg answer, and to add two my cents, sequence of commands to be executed by you or any 3 colleagues of yours who has possession of the vault unseal token</p>

<pre><code>export VAULT_ADDR=https://vault.yourcompany.com  # Address of your Vault
export VAULT_SKIP_VERIFY=true                    # this can be skipped, if you use a proper certificate and not self-signed certificate
vault status                                     # to check the vault status
vault unseal                                     # this will ask for the vault unseal token
</code></pre>
",11832,2019-01-16T14:53:02.383,"['export VAULT_ADDR=https://vault.yourcompany.com  # Address of your Vault\nexport VAULT_SKIP_VERIFY=true                    # this can be skipped, if you use a proper certificate and not self-signed certificate\nvault status                                     # to check the vault status\nvault unseal                                     # this will ask for the vault unseal token\n']"
691,6014,5014,CC BY-SA 4.0,2019-01-16T15:54:15.190,"<p>In your job, I noticed the below curl command, where two things need to be corrected:</p>

<ul>
<li><p><code>token=$CI_JOB_TOKEN</code> - this TOKEN should be generated in project B under Settings -> CI/CD -> Pipeline triggers (Add triggers)</p></li>
<li><p><code>""ref=$CI_COMMIT_REF_NAME""</code> - this is pointing to a branch with name $CI_COMMIT_REF_NAME on project B and this will only execute if it find a project with that branch name, so if you are trying to trigger it on master branch or any specific branch, you should replace it with something like <code>-F ""ref=master""</code> in your curl command</p></li>
</ul>

<pre><code> - curl -X POST -F ""token=$CI_JOB_TOKEN"" -F ""ref=$CI_COMMIT_REF_NAME"" https://gitlab.com/api/v4/projects/1234/trigger/pipeline
</code></pre>

<p>I use the same trigger with few variables to execute one of my job in another project</p>

<pre><code>- ""curl -k -X POST -F token=$PROJECT_B_TOKEN -F ref=master -F variables[PROJECT_NAME]=$CI_PROJECT_NAME -F variables[TAG]=$CI_BUILD_REF_NAME -F variables[SOME_VARIABLE_IDENTIFIER]=DevOps -F variables[USER]=$GITLAB_USER_LOGIN https://gitlab.mycompany.com/api/v4/projects/1234/trigger/pipeline""
</code></pre>

<p>The person who created in token in project B, needs to be owner in project A to execute this trigger, else it fails with a 404 message.</p>
",11832,2019-01-16T15:54:15.190,"[' - curl -X POST -F ""token=$CI_JOB_TOKEN"" -F ""ref=$CI_COMMIT_REF_NAME"" https://gitlab.com/api/v4/projects/1234/trigger/pipeline\n', '- ""curl -k -X POST -F token=$PROJECT_B_TOKEN -F ref=master -F variables[PROJECT_NAME]=$CI_PROJECT_NAME -F variables[TAG]=$CI_BUILD_REF_NAME -F variables[SOME_VARIABLE_IDENTIFIER]=DevOps -F variables[USER]=$GITLAB_USER_LOGIN https://gitlab.mycompany.com/api/v4/projects/1234/trigger/pipeline""\n']"
692,6017,6003,CC BY-SA 4.0,2019-01-17T07:56:00.783,"<p>I recommend that you use the <strong>printenv</strong> command for list system Variable:</p>

<pre><code>printenv
</code></pre>

<p>and also An easy way to obtain the Jenkins environment variables list from your local installation is to append env-vars.html to the server's URL. the URL would be </p>

<p><code>http://{jenkins_url}/env-vars.html</code></p>
",11598,2019-01-17T07:56:00.783,['printenv\n']
693,6025,6023,CC BY-SA 4.0,2019-01-17T17:29:08.053,"<p>AFAIK there are only 2 ways of deploying GAE apps:</p>

<ul>
<li>using the <a href=""https://cloud.google.com/sdk/gcloud/reference/app/deploy"" rel=""nofollow noreferrer""><code>gcloud app deploy</code></a> command:</li>
</ul>

<blockquote>
  <p>gcloud app deploy - deploy the local code and/or configuration of your
  app to App Engine</p>
</blockquote>

<ul>
<li>using the Admin API. From <a href=""https://cloud.google.com/appengine/docs/admin-api/deploying-overview"" rel=""nofollow noreferrer"">Deploying Your Apps with the Admin API</a>:</li>
</ul>

<blockquote>
  <p>To deploy a version of your app with the Admin API:</p>
  
  <ol>
  <li><a href=""https://cloud.google.com/appengine/docs/admin-api/uploading-resources"" rel=""nofollow noreferrer"">Upload your app's resources to Cloud Storage</a>.</li>
  <li><a href=""https://cloud.google.com/appengine/docs/admin-api/creating-config-files"" rel=""nofollow noreferrer"">Create a configuration file that defines your deployment</a>.</li>
  <li><a href=""https://cloud.google.com/appengine/docs/admin-api/deploying-apps"" rel=""nofollow noreferrer"">Create and send the HTTP request for deploying your app</a>.</li>
  </ol>
</blockquote>

<p>Both <code>gcloud</code> (used in the 1st method) as well as <code>gsutil</code> (used in the 1st step of the 2nd method) are part of the <a href=""https://cloud.google.com/sdk/docs/"" rel=""nofollow noreferrer"">Google Cloud SDK</a>, so you'll need to have the SDK installed on your runner.</p>

<p>Summarizing the required steps from a GAE deployment example using the 1st approach that I found in <a href=""https://revs.runtime-revolution.com/getting-started-with-angular-6-gitlab-ci-cd-and-google-app-engine-b1118efcdf69"" rel=""nofollow noreferrer"">Getting started with Angular 6, GitLab CI/CD and Google App Engine</a> (probably a good read for details):</p>

<ul>
<li>in gitlab set env vars with your GAE service account and project ID info</li>
<li>in your <code>.gitlab-ci.yml</code> file's deployment section add a <code>before_script</code> section for installing the SDK (update for current SDK version)</li>
</ul>

<blockquote>
<pre><code>        before_script:
          - wget https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-218.0.0-linux-x86.tar.gz
          - tar -xzf  google-cloud-sdk-218.0.0-linux-x86.tar.gz
          - ./google-cloud-sdk/install.sh
</code></pre>
</blockquote>

<p>and a <code>script</code> section for the actual deployment, referencing those env vars:</p>

<blockquote>
<pre><code>        script:
          - echo $GAE_KEY_FILE &gt; gae_auth.json
          - ./google-cloud-sdk/bin/gcloud auth activate-service-account --key-file gae_auth.json
          - ./google-cloud-sdk/bin/gcloud app deploy --project=$GAE_PROJECT_ID
</code></pre>
</blockquote>
",47,2019-01-17T17:29:08.053,"['        before_script:\n          - wget https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-218.0.0-linux-x86.tar.gz\n          - tar -xzf  google-cloud-sdk-218.0.0-linux-x86.tar.gz\n          - ./google-cloud-sdk/install.sh\n', '        script:\n          - echo $GAE_KEY_FILE > gae_auth.json\n          - ./google-cloud-sdk/bin/gcloud auth activate-service-account --key-file gae_auth.json\n          - ./google-cloud-sdk/bin/gcloud app deploy --project=$GAE_PROJECT_ID\n']"
694,6031,4709,CC BY-SA 4.0,2019-01-18T09:32:09.130,"<p>You mentioned that the auth key is stored in Jenkins credentials and are available as environment variables, if so, then your half task is already done; what you can probably do from here is, use those environment variables to perform docker login (assuming USERNAME and PASSWORD are the Jenkins credentials variable), use the below command to login</p>

<pre><code>docker login your.docker-registry.com -u $USERNAME -p $PASSWORD
</code></pre>

<p>This assumes, that your registry has SSL enabled, if so, don't forget to place the registry certificates under the below name on your Jenkin host</p>

<pre><code>/etc/docker/certs.d/your.docker-registry/ca.crt
</code></pre>

<p>Post this, you would be able to push image to the registry</p>
",11832,2019-01-18T09:32:09.130,"['docker login your.docker-registry.com -u $USERNAME -p $PASSWORD\n', '/etc/docker/certs.d/your.docker-registry/ca.crt\n']"
695,6037,5957,CC BY-SA 4.0,2019-01-18T18:09:05.987,"<p>Found out that the remote_file resource couldn't handle redirects. Hence I had to write a ruby_block resource that makes use of 'Down' gem.</p>

<pre><code>ruby_block 'download_openvpn_zip' do
    block do 
        attempt = 2
        begin
            retries ||= 0
            tempfile = Down::NetHttp.download(""http://www.someurl.com/#{zip},max_redirects: 0)
            FileUtils.mv tempfile.path, ""#{node['openvpn-conf-path']}/#{tempfile.original_filename}""
        rescue Down::TooManyRedirects =&gt; e
            puts ""\n \t ERROR: #{e.message}""
            retry if (retries += 1) &lt; 1
        end 
    end
    action :run
    notifies :run, 'execute[unzip_file]', :delayed
end
</code></pre>
",11793,2019-01-18T18:09:05.987,"['ruby_block \'download_openvpn_zip\' do\n    block do \n        attempt = 2\n        begin\n            retries ||= 0\n            tempfile = Down::NetHttp.download(""http://www.someurl.com/#{zip},max_redirects: 0)\n            FileUtils.mv tempfile.path, ""#{node[\'openvpn-conf-path\']}/#{tempfile.original_filename}""\n        rescue Down::TooManyRedirects => e\n            puts ""\\n \\t ERROR: #{e.message}""\n            retry if (retries += 1) < 1\n        end \n    end\n    action :run\n    notifies :run, \'execute[unzip_file]\', :delayed\nend\n']"
696,6052,4441,CC BY-SA 4.0,2019-01-21T15:47:29.297,"<p>I think your ingress rule is fine but I think your Traefik service needs to be changed. Check out this article <a href=""https://kubernetes.io/docs/tutorials/services/source-ip/"" rel=""nofollow noreferrer"">https://kubernetes.io/docs/tutorials/services/source-ip/</a></p>

<p>I think what you are looking for is <code>nodePort</code> with <code>externalTrafficPolicy</code> set to <code>local</code>.</p>

<p>This should allow Traefik to enforce <code>whitelist-source-range</code> annotation on the ingress. </p>

<p>EDIT:</p>

<p>I was going to go into more detail but it was so old I thought you might have already found a solution. Ingress controllers are not allowed to bind to 80 and 443 but most organizations are using the load balancer service to load balance traffic to the Ingress controller and then out to the kubernetes services and then to the pods. </p>

<pre><code>DNS    HostName Routing       Port routing
LB --&gt; Ingress nodePort --&gt; Service ClusterIP --&gt; Pod
</code></pre>

<p>I don't usually use the cloud providers LB. So usually I will wildcard my dns <code>*.mycluster.com</code> and point that to nginx. In nginx I will then have a couple of configs to redirect that traffic to either the ingress controller or some of my services that are running nodePort because they are fragile. </p>

<p>Hope this helps</p>
",4427,2019-01-22T22:19:21.470,['DNS    HostName Routing       Port routing\nLB --> Ingress nodePort --> Service ClusterIP --> Pod\n']
697,6059,6058,CC BY-SA 4.0,2019-01-22T06:36:52.647,"<p>To solve this, I printed <code>vars</code> and <code>ansible_facts</code>, and eventually stumbled on the <code>ansible_play_batch</code> variable, which is a list of hostnames in the current batch. <code>ansible_play_hosts_all</code> gives the full list of hostnames. (Do not use <code>ansible_play_hosts</code> for this purpose, because as of Ansible 2.7, it works but <a href=""https://docs.ansible.com/ansible/2.7/reference_appendices/special_variables.html"" rel=""nofollow noreferrer"">the docs</a> say it gives something completely different.)</p>

<p>The question: Is this the final batch?<br>
Rephrasing based on the data: Is this batch == the last part of the host list?<br>
Or to make it simpler: Is the end of this batch == the end of the host list?</p>

<p>In Ansible, the check for that is:</p>

<pre><code>tasks:
  - pause:
      seconds: ""{{ health_check_healthy_threshold * health_check_interval }}""
      prompt: Waiting to allow AWS health checks to pass
    when: ansible_play_batch[-1] != ansible_play_hosts_all[-1]

  - debug: msg=""This is the last batch.""
    when: ansible_play_batch[-1] == ansible_play_hosts_all[-1]
</code></pre>

<hr>

<p>Side note: I used the following playbook for testing, to simulate having many/few hosts without bothering to set them up. I couldn't see how to specify the hosts as a list in the playbook, so I added them to a group, then executed the group:</p>

<pre><code>---
- hosts: localhost
  connection: local
  tasks:
    - add_host: { name: host1, groups: test_hosts }
    - add_host: { name: host2, groups: test_hosts }
- hosts: test_hosts
  connection: local
  serial: ""25%""
  tasks:
    - debug: var=ansible_play_batch
</code></pre>
",11958,2019-06-22T16:06:33.377,"['tasks:\n  - pause:\n      seconds: ""{{ health_check_healthy_threshold * health_check_interval }}""\n      prompt: Waiting to allow AWS health checks to pass\n    when: ansible_play_batch[-1] != ansible_play_hosts_all[-1]\n\n  - debug: msg=""This is the last batch.""\n    when: ansible_play_batch[-1] == ansible_play_hosts_all[-1]\n', '---\n- hosts: localhost\n  connection: local\n  tasks:\n    - add_host: { name: host1, groups: test_hosts }\n    - add_host: { name: host2, groups: test_hosts }\n- hosts: test_hosts\n  connection: local\n  serial: ""25%""\n  tasks:\n    - debug: var=ansible_play_batch\n']"
698,6064,5237,CC BY-SA 4.0,2019-01-22T10:48:27.743,"<p>I posted the <a href=""https://stackoverflow.com/questions/52942359/how-to-pull-all-alternative-tags-of-a-docker-image"">same question at stackoverflow</a>. The question is answered there and I have posted my script. For the sake of completeness, I will post it here as well.</p>

<pre><code>#!/bin/sh

TOKEN=`curl -s ""https://auth.docker.io/token?service=registry.docker.io&amp;scope=repository:gitlab/gitlab-runner-helper:pull"" | jq '.token' | sed 's/""//g'`
TAGS=`curl -s https://registry.hub.docker.com/v2/gitlab/gitlab-runner-helper/tags/list -H ""Authorization: Bearer $TOKEN"" | jq "".tags[]"" | sed 's/""//g' | grep x86_64`

for tag in $TAGS;
do
  # is $tag an old entry?
  if grep -Fxq $tag tags.list
  then
    # already processed
    continue
  else
    echo ""new tag found: $tag""
    newSHA=`curl -s https://registry.hub.docker.com/v2/gitlab/gitlab-runner-helper/manifests/$tag -H ""Authorization: Bearer $TOKEN"" | jq "".fsLayers[] .blobSum"" | sed 's/""//g'`
    latestSHA=`curl -s https://registry.hub.docker.com/v2/gitlab/gitlab-runner-helper/manifests/x86_64-latest -H ""Authorization: Bearer $TOKEN"" | jq "".fsLayers[] .blobSum"" | sed 's/""//g'`
    if [ ""$newSHA"" = ""$latestSHA"" ]
    then
      echo ""$tag is new latest version""
      docker pull gitlab/gitlab-runner-helper:$tag
      echo $tag &gt;&gt; tags.list
    fi
  fi
done
</code></pre>

<p>The above script utilizes a file named <code>tags.list</code>, that is placed next to it. This file contains the older tags, to prevent issuing 500+ HTTP requests. If a tag from the <code>TAGS</code> is not yet present in the file, it does not mean, it is the latest. Sometimes tags appear, that eventually will become the latest version. Those tags are probed, but will not be inserted into the file. This might become an issue in the future, if those versions will be skipped as latest.</p>

<p><strong>Note:</strong> The script above only focuses on a specific subset of tags <code>(x86_64)</code>.</p>
",3427,2019-01-22T10:48:27.743,"['#!/bin/sh\n\nTOKEN=`curl -s ""https://auth.docker.io/token?service=registry.docker.io&scope=repository:gitlab/gitlab-runner-helper:pull"" | jq \'.token\' | sed \'s/""//g\'`\nTAGS=`curl -s https://registry.hub.docker.com/v2/gitlab/gitlab-runner-helper/tags/list -H ""Authorization: Bearer $TOKEN"" | jq "".tags[]"" | sed \'s/""//g\' | grep x86_64`\n\nfor tag in $TAGS;\ndo\n  # is $tag an old entry?\n  if grep -Fxq $tag tags.list\n  then\n    # already processed\n    continue\n  else\n    echo ""new tag found: $tag""\n    newSHA=`curl -s https://registry.hub.docker.com/v2/gitlab/gitlab-runner-helper/manifests/$tag -H ""Authorization: Bearer $TOKEN"" | jq "".fsLayers[] .blobSum"" | sed \'s/""//g\'`\n    latestSHA=`curl -s https://registry.hub.docker.com/v2/gitlab/gitlab-runner-helper/manifests/x86_64-latest -H ""Authorization: Bearer $TOKEN"" | jq "".fsLayers[] .blobSum"" | sed \'s/""//g\'`\n    if [ ""$newSHA"" = ""$latestSHA"" ]\n    then\n      echo ""$tag is new latest version""\n      docker pull gitlab/gitlab-runner-helper:$tag\n      echo $tag >> tags.list\n    fi\n  fi\ndone\n']"
699,6074,6071,CC BY-SA 4.0,2019-01-23T08:47:46.270,"<p>If your local network is faster than your internet connexion you can do the following: </p>

<ol>
<li>Download the tarball in your ansible host using run_once option.</li>
<li>Copy it to each target. </li>
<li>Install it locally from a file ; most of package managers support local install.</li>
</ol>

<p><strong>Yum rpm example</strong></p>

<pre><code>- name: Download RPM locally
  get_url:
    url: http://example.com/path/file.rpm
    dest: /local_path/file.rpm
  delegate_to: localhost
  run_once: yes

- name: Copying file.rpm 
  copy:
    src: /local_path/file.rpm
    dest: /remote_path/file.rpm

- name: Install rpm from a local file
  yum:
    name: /remote_path/file.rpm
    state: present
</code></pre>

<p><strong>Local install example with pip</strong>  </p>

<pre><code>- pip:
  name: file:///remote_path/file.gz
</code></pre>

<p><strong>Local install example with apt</strong></p>

<pre><code>- name: Install a .deb package
  apt:
    deb: /remote_path/file.deb
</code></pre>

<p>The problem with this method, is when you have many dependencies ; you have to download and install them all before your package (Optionally with a requirements.txt or so depending on the package manager you use..)</p>
",800,2019-01-23T09:12:31.290,"['- name: Download RPM locally\n  get_url:\n    url: http://example.com/path/file.rpm\n    dest: /local_path/file.rpm\n  delegate_to: localhost\n  run_once: yes\n\n- name: Copying file.rpm \n  copy:\n    src: /local_path/file.rpm\n    dest: /remote_path/file.rpm\n\n- name: Install rpm from a local file\n  yum:\n    name: /remote_path/file.rpm\n    state: present\n', '- pip:\n  name: file:///remote_path/file.gz\n', '- name: Install a .deb package\n  apt:\n    deb: /remote_path/file.deb\n']"
700,6081,6071,CC BY-SA 4.0,2019-01-24T07:29:45.490,"<blockquote>
  <p>Can Ansible use a local repository?</p>
</blockquote>

<p>I just take the title because the answer lies in it. </p>

<blockquote>
  <p>What is the best practice when there are lots of hosts and lots of packages?</p>
</blockquote>

<p>You have a many hosts, hopefully from the same distribution. So it would make sense to create a local mirror (repository), which can be on your Ansible machine by the way, and to configure, for either <a href=""https://packaging.python.org/guides/index-mirrors-and-caches/"" rel=""nofollow noreferrer"">pip</a> or <a href=""https://help.ubuntu.com/community/Rsyncmirror"" rel=""nofollow noreferrer"">apt</a>. </p>

<p>This takes space, but will save you a lot of time downloading updates and packages. </p>

<p>You have to calculate if it is worth it, as it takes a fair amount of storage, but setting this up isn't very complicated.</p>

<p>Then just update the <code>apt</code> configuration of each hosts to point to your local mirror with <em>Ansible</em>. </p>

<blockquote>
  <p>Can ansible download these deb or pip packages to its local (or anywhere) and install to each host to decrease time.</p>
</blockquote>

<p>For that part, I believe @storm gave a very good answer:</p>

<pre><code>delegate_to: localhost
run_once: yes
</code></pre>
",11905,2019-01-24T07:29:45.490,['delegate_to: localhost\nrun_once: yes\n']
701,6082,6078,CC BY-SA 4.0,2019-01-24T08:26:37.230,"<blockquote>
  <p>But is there a way to achieve the same result without copying first the (potentially large) dump into the container?</p>
</blockquote>

<p>The only way that ables you to do that (which I know), is :</p>

<pre><code>RUN gunzip &lt; $(curl -SL http://docker-localhost/db-dump.gz) \
        | mysql
</code></pre>

<p>For this you need to have your dump available on a website, which isn't ideal (probably not as fast as what you are doing)
If you look at the good Dockerfiles (public ones), they mostly get archive files from the web, then remove the archives.</p>

<p>Your commands in <code>Dockerfile</code> seem very good. You could just add a <code>&amp;&amp; rm /tmp/db-dump.gz</code> after <code>mysql</code>.</p>
",11905,2019-01-24T08:26:37.230,['RUN gunzip < $(curl -SL http://docker-localhost/db-dump.gz) \\\n        | mysql\n']
702,6083,1683,CC BY-SA 4.0,2019-01-24T08:47:05.590,"<p>You can also as an alternative set the option to <code>false</code> for the stage where you want to check out the git:</p>

<pre><code>pipeline {
  agent none
  options { skipDefaultCheckout(true) }
  stages {
    stage('Build') {
      agent { node { label 'builder' } }
      options { skipDefaultCheckout(false) }
      steps {
        echo 'build-the-app'
        stash(name: 'app', includes: 'outputs')
      }
    }
    stage('Test') {
      agent { node { label 'tester' } }
      steps {
        unstash 'app'
        echo 'test-the-app'
      }
    }
  }
}
</code></pre>
",12011,2019-01-24T08:47:05.590,"[""pipeline {\n  agent none\n  options { skipDefaultCheckout(true) }\n  stages {\n    stage('Build') {\n      agent { node { label 'builder' } }\n      options { skipDefaultCheckout(false) }\n      steps {\n        echo 'build-the-app'\n        stash(name: 'app', includes: 'outputs')\n      }\n    }\n    stage('Test') {\n      agent { node { label 'tester' } }\n      steps {\n        unstash 'app'\n        echo 'test-the-app'\n      }\n    }\n  }\n}\n""]"
703,6087,6085,CC BY-SA 4.0,2019-01-24T13:23:38.720,"<p>if you want just access the log and download it as a txt file to your workspace from the job's URL:</p>

<pre><code>${BUILD_URL}/consoleText
</code></pre>

<p>On Linux, you can use <code>wget</code> to download it to your workspace</p>

<pre><code>wget ${BUILD_URL}/consoleText
</code></pre>

<p>The actual log file on the file system is in the Master machine. You can find it under:</p>

<p><code>$JENKINS_HOME/jobs/$JOB_NAME/builds/lastSuccessfulBuild/log</code></p>
",11598,2019-01-24T13:23:38.720,"['${BUILD_URL}/consoleText\n', 'wget ${BUILD_URL}/consoleText\n']"
704,6089,6078,CC BY-SA 4.0,2019-01-24T13:43:23.013,"<p>You can do this with BuildKit and the experimental frontend. As of 18.09, BuildKit can be enabled with either:</p>

<pre><code>export DOCKER_BUILDKIT=1
</code></pre>

<p>for a single shell, or to change the default for the host, you can add to /etc/docker/daemon.json:</p>

<pre><code>{
  ""features"": {""buildkit"": true}
}
</code></pre>

<p>You'll need to reload the docker engine after changing the above.</p>

<hr>

<p>With BuildKit enabled, your Dockerfile would look like:</p>

<pre><code># syntax=docker/dockerfile:experimental

RUN --mount=type=bind,source=db-dump.gz,target=/tmp/db-dump.gz \
    zcat /tmp/db-dump.gz | mysql
</code></pre>

<p>You then build with a <code>docker build .</code> command as before, but with BuildKit enabled.</p>

<p>To see more about BuildKit's experimental features, see <a href=""https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/experimental.md"" rel=""nofollow noreferrer"">https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/experimental.md</a></p>
",7730,2019-01-24T13:43:23.013,"['export DOCKER_BUILDKIT=1\n', '{\n  ""features"": {""buildkit"": true}\n}\n', '# syntax=docker/dockerfile:experimental\n\nRUN --mount=type=bind,source=db-dump.gz,target=/tmp/db-dump.gz \\\n    zcat /tmp/db-dump.gz | mysql\n']"
705,6098,6092,CC BY-SA 4.0,2019-01-25T05:12:32.620,"<p>please attach below policy to your AWS S3 Bucket.</p>

<blockquote>
  <p><strong>Allow Access to Specific IP Addresses</strong></p>
</blockquote>

<pre><code> &lt;div class=""code""&gt;  
 {  
   ""Id"": ""S3PolicyId1"",  
   ""Statement"": [  
     {  
       ""Sid"": ""IPDeny"",  
       ""Effect"": ""Deny"",  
       ""Principal"": {  
         ""AWS"": ""*""  
       },  
       ""Action"": ""s3:*"",  
       ""Resource"": ""arn:aws:s3:::bucket/*"",  
       ""Condition"": {  
         ""IpAddress"": {  
           ""aws:SourceIp"": ""54.240.143.188/32""  
         }  
       }  
     }  
   ]  
 }  
 &lt;/div&gt;
</code></pre>

<blockquote>
  <p><strong>Deny Access to Specific IP Addresses</strong></p>
</blockquote>

<pre><code>{  
  ""Version"": ""2012-10-17"",  
  ""Id"": ""S3PolicyId1"",  
  ""Statement"": [  
   {  
    ""Sid"": ""IPAllow"",  
    ""Effect"": ""Allow"",  
    ""Principal"": ""*"",  
    ""Action"": ""s3:*"",  
    ""Resource"": ""arn:aws:s3:::bucket/*"",  
    ""Condition"": {  
      ""NotIpAddress"": {""aws:SourceIp"": ""54.240.143.188/32""}   
    }   
   }   
  ]  
 }
</code></pre>
",11598,2019-01-25T05:17:53.623,"[' <div class=""code"">  \n {  \n   ""Id"": ""S3PolicyId1"",  \n   ""Statement"": [  \n     {  \n       ""Sid"": ""IPDeny"",  \n       ""Effect"": ""Deny"",  \n       ""Principal"": {  \n         ""AWS"": ""*""  \n       },  \n       ""Action"": ""s3:*"",  \n       ""Resource"": ""arn:aws:s3:::bucket/*"",  \n       ""Condition"": {  \n         ""IpAddress"": {  \n           ""aws:SourceIp"": ""54.240.143.188/32""  \n         }  \n       }  \n     }  \n   ]  \n }  \n </div>\n', '{  \n  ""Version"": ""2012-10-17"",  \n  ""Id"": ""S3PolicyId1"",  \n  ""Statement"": [  \n   {  \n    ""Sid"": ""IPAllow"",  \n    ""Effect"": ""Allow"",  \n    ""Principal"": ""*"",  \n    ""Action"": ""s3:*"",  \n    ""Resource"": ""arn:aws:s3:::bucket/*"",  \n    ""Condition"": {  \n      ""NotIpAddress"": {""aws:SourceIp"": ""54.240.143.188/32""}   \n    }   \n   }   \n  ]  \n }\n']"
706,6102,6100,CC BY-SA 4.0,2019-01-25T10:21:35.907,"<p>Yes, we can block traffic from single IP or IP range. Please follow below steps to do this</p>
<blockquote>
<p>Open <strong>VPC</strong> dashboard</p>
</blockquote>
<p><a href=""https://i.stack.imgur.com/4FQ46.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/4FQ46.png"" alt=""enter image description here"" /></a></p>
<blockquote>
<p>Open the <strong>Network ACLs</strong> view</p>
</blockquote>
<p><a href=""https://i.stack.imgur.com/AIfeO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AIfeO.png"" alt=""enter image description here"" /></a></p>
<blockquote>
<p>Open the ACL editor</p>
</blockquote>
<ol>
<li><p>Select the subnet to which your EC2 instances or load balancers are connected.</p>
</li>
<li><p>Click <strong>Inbound Rules</strong></p>
</li>
<li><p>Click <strong>Edit</strong></p>
</li>
</ol>
<p><a href=""https://i.stack.imgur.com/n81I6.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/n81I6.png"" alt=""enter image description here"" /></a></p>
<blockquote>
<p>Add a rule to block the traffic/IP</p>
</blockquote>
<p>You will now see the ACL editor. On the last row, you can add a new rule.</p>
<p><a href=""https://i.stack.imgur.com/kF4qy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kF4qy.png"" alt=""enter image description here"" /></a></p>
<p>Here is how you should fill out the fields:</p>
<h1>Rule</h1>
<p>Use any number less than 100, which is the number of the default accept-all rule. This is important because rules are evaluated in order, and your rule needs to come before the default.</p>
<h1>Type</h1>
<p>Select “All traffic” or Particular Protocol which you want to Block</p>
<h1>Source</h1>
<p>The CIDR you want to block. To match a single IP address, enter it here and append /32. For example, I blocked <code>22.87.45.187/32</code></p>
<h1>Allow/Deny</h1>
<p>Select “DENY”</p>
<p>Now <strong>click Save</strong> and you should see the updated rules table.</p>
<p>Fore more details visit <a href=""https://www.serverkaka.com/2018/05/block-traffic-from-single-ip-in-aws.html"" rel=""nofollow noreferrer"">https://www.serverkaka.com/2018/05/block-traffic-from-single-ip-in-aws.html</a></p>
<hr />
<h3>UPDATE: How to do it in CLI</h3>
<blockquote>
<p>NOTE: This example command includes <code>--dry-run</code> option, so it is safe to run. It will not create <em>NACL</em> rule. Run it without this option, if you want to apply it.</p>
</blockquote>
<pre><code>aws ec2 create-network-acl-entry --dry-run --network-acl-id acl-146adb6f --ingress --rule-number 20 --protocol tcp --port-range From=80,To=80 --cidr-block 22.87.45.187/32 --rule-action deny
</code></pre>
<p>More examples:
<a href=""https://docs.aws.amazon.com/cli/latest/reference/ec2/create-network-acl-entry.html#examples"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/cli/latest/reference/ec2/create-network-acl-entry.html#examples</a></p>
",11598,2019-08-14T09:35:40.757,"['aws ec2 create-network-acl-entry --dry-run --network-acl-id acl-146adb6f --ingress --rule-number 20 --protocol tcp --port-range From=80,To=80 --cidr-block 22.87.45.187/32 --rule-action deny\n']"
707,6127,6126,CC BY-SA 4.0,2019-01-28T06:54:43.757,"<p>You need to define variables before the pipeline block starts. Then it should be work.</p>

<pre><code>def foo = ""foo""

pipeline {
    agent none
    stages {
        stage(""first"") {
            sh ""echo ${foo}""
        }
    }
}
</code></pre>
",11598,2019-03-06T04:45:24.520,"['def foo = ""foo""\n\npipeline {\n    agent none\n    stages {\n        stage(""first"") {\n            sh ""echo ${foo}""\n        }\n    }\n}\n']"
708,6132,6130,CC BY-SA 4.0,2019-01-28T16:23:02.187,"<p>As I understand you want to add a variable to the docker image tag, </p>

<p>in this case, you have to get an environment variable from Jenkins and use it in your image label.</p>

<pre><code>    pipeline {
  environment {
    registry = ""docker_hub_account/repository_name""
    registryCredential = 'dockerhub'
  }
  agent any
  stages {
    stage('Building image') {
      steps{
        script {
          docker.build registry + "":$BUILD_NUMBER""
        }
      }
    }
  }
}
</code></pre>

<p>pleae use this <a href=""https://medium.com/@gustavo.guss/jenkins-building-docker-image-and-sending-to-registry-64b84ea45ee9"" rel=""nofollow noreferrer"">URL</a> for more info</p>
",10533,2019-01-29T08:48:24.943,"['    pipeline {\n  environment {\n    registry = ""docker_hub_account/repository_name""\n    registryCredential = \'dockerhub\'\n  }\n  agent any\n  stages {\n    stage(\'Building image\') {\n      steps{\n        script {\n          docker.build registry + "":$BUILD_NUMBER""\n        }\n      }\n    }\n  }\n}\n']"
709,6134,6129,CC BY-SA 4.0,2019-01-28T16:35:12.390,"<p>try this one</p>

<pre><code>static void main(String[] args) { 
      // Initializing 2 variables 
      def x = 5; 
      def y = 10;

      //Performing addition of 2 operands 
      println(x+y);
 }
</code></pre>

<p>}</p>

<p>check this <a href=""https://www.tutorialspoint.com/groovy/groovy_arithmetic_operators.htm"" rel=""nofollow noreferrer"">URL</a> </p>
",10533,2019-01-28T16:35:12.390,['static void main(String[] args) { \n      // Initializing 2 variables \n      def x = 5; \n      def y = 10;\n\n      //Performing addition of 2 operands \n      println(x+y);\n }\n']
710,6150,6149,CC BY-SA 4.0,2019-01-29T17:24:22.493,"<p>This will do want I want: killing all containers <em>directly</em> based on <code>mariadb</code> regardless of their tag--and without killing containers having <code>mariadb</code> somewhere higher in their ancestor list.</p>

<pre><code>sudo docker kill $(
  sudo docker ps --format '{{.ID}} {{.Image}}' | awk '$2 ~ /^mariadb:/ { print $1}'
)
</code></pre>
",11179,2019-01-29T22:28:16.733,"[""sudo docker kill $(\n  sudo docker ps --format '{{.ID}} {{.Image}}' | awk '$2 ~ /^mariadb:/ { print $1}'\n)\n""]"
711,6152,6144,CC BY-SA 4.0,2019-01-29T17:29:57.740,"<p>The easiest approach does appear to be to use <code>gcloud</code>, as trying to get a kubeconfig without it proved tricky.</p>

<p>Fortunately, <code>gcloud</code>, <code>kubectl</code> and <code>helm</code> are available as a single docker image <code>kiwigrid/gcloud-kubectl-helm</code>. For example:</p>

<pre><code>docker run -it --rm --volume ./gcp-key-file.json:/data/gcp-key-file.json:ro kiwigrid/gcloud-kubectl-helm:2.11.0-224.0.0 bash
gcloud auth activate-service-account --key-file=/data/gcp-key-file.json
gcloud container clusters get-credentials dev-cluster --project &lt;project name&gt; --zone &lt;zone&gt;
</code></pre>
",12104,2019-01-29T17:29:57.740,['docker run -it --rm --volume ./gcp-key-file.json:/data/gcp-key-file.json:ro kiwigrid/gcloud-kubectl-helm:2.11.0-224.0.0 bash\ngcloud auth activate-service-account --key-file=/data/gcp-key-file.json\ngcloud container clusters get-credentials dev-cluster --project <project name> --zone <zone>\n']
712,6153,1930,CC BY-SA 4.0,2019-01-29T19:01:24.393,"<p>So, assuming Docker and Jenkins are set as stated, I would say your approach covers it: Build Jar in one container, grab the Jar and build an image with it, then build containers from that image for your environments.</p>

<p>For some thoughts on how to set it up:</p>

<p>Have a Docker Host (or swarm) running and start a Jenkins service on it. This is a compose file that I have running:</p>

<pre><code>version: '3.7'

services:
  jenkins-local:
    user: root
    image: jenkinsci/blueocean
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ../../..:/var/projects
      - ./jenkins_home:/var/jenkins_home
    ports:
      - ""9000:8080""

volumes:
  jenkins-home:
</code></pre>

<p>The important part is the volume where /var/run/docker.sock of the host is mounted to /var/run/docker.sock of the container. This allows Jenkins to access the host's Docker daemon via the Docker socket (make sure ""user"" is ""root""). Find some reading about this here: <a href=""https://getintodevops.com/blog/the-simple-way-to-run-docker-in-docker-for-ci"" rel=""nofollow noreferrer"">https://getintodevops.com/blog/the-simple-way-to-run-docker-in-docker-for-ci</a></p>

<p>The reason why I'd choose the jenkinsci/""blueocean"" image is because it allows for usage of blueocean pipelines. <a href=""https://jenkins.io/projects/blueocean/"" rel=""nofollow noreferrer"">https://jenkins.io/projects/blueocean/</a></p>

<p>Within pipelines you write Jenkinsfiles to define your build pipelines:</p>

<pre><code>node {
    stage('checkout scm') {
        checkout scm
    }
    stage('Build artifact') {
        // Connect to our Nexus Docker repository with the nexus_jenkins_user user credentials managed in Jenkins
        docker.withRegistry('https://registry.swarm', 'nexus_jenkins_user') {
            // Run a Maven builder image and attach it to the nexus network
            // Add a volume to cache the maven-repo in for consecutive runs
            docker.image('registry.swarm/builder/maven:maven-3.3.9').inside('-v maven-repo:/root/.m2 --network=nexus_nexus') {
                sh 'mvn clean package -Dmaven.test.failure.ignore=true'
            }
        }
    }
    stage('archive artifacts and save test results') {
        archiveArtifacts artifacts: ""target/*.jar"", fingerprint: true
        junit 'target/surefire-reports/*.xml'
    }
    stage('Build run container image, push Docker image to nexus') {
        docker.withRegistry('https://registry.swarm', 'nexus_jenkins_user') {
            docker.build(""app/my-service:current"").push()
        }
    }
}
</code></pre>

<p>Since everything happens in Jenkins Workspace, the only important line for the Dockerfile is this one:</p>

<pre><code>COPY ./target/my-service-*.jar ./my-service.jar

CMD [ ""java"", ""-Duser.timezone=UTC"", ""-jar"", ""my-service.jar""]
</code></pre>

<p>This will grab the jar, copy it over and use it for the run command in the image.</p>
",7646,2019-01-29T19:01:24.393,"['version: \'3.7\'\n\nservices:\n  jenkins-local:\n    user: root\n    image: jenkinsci/blueocean\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - ../../..:/var/projects\n      - ./jenkins_home:/var/jenkins_home\n    ports:\n      - ""9000:8080""\n\nvolumes:\n  jenkins-home:\n', 'node {\n    stage(\'checkout scm\') {\n        checkout scm\n    }\n    stage(\'Build artifact\') {\n        // Connect to our Nexus Docker repository with the nexus_jenkins_user user credentials managed in Jenkins\n        docker.withRegistry(\'https://registry.swarm\', \'nexus_jenkins_user\') {\n            // Run a Maven builder image and attach it to the nexus network\n            // Add a volume to cache the maven-repo in for consecutive runs\n            docker.image(\'registry.swarm/builder/maven:maven-3.3.9\').inside(\'-v maven-repo:/root/.m2 --network=nexus_nexus\') {\n                sh \'mvn clean package -Dmaven.test.failure.ignore=true\'\n            }\n        }\n    }\n    stage(\'archive artifacts and save test results\') {\n        archiveArtifacts artifacts: ""target/*.jar"", fingerprint: true\n        junit \'target/surefire-reports/*.xml\'\n    }\n    stage(\'Build run container image, push Docker image to nexus\') {\n        docker.withRegistry(\'https://registry.swarm\', \'nexus_jenkins_user\') {\n            docker.build(""app/my-service:current"").push()\n        }\n    }\n}\n', 'COPY ./target/my-service-*.jar ./my-service.jar\n\nCMD [ ""java"", ""-Duser.timezone=UTC"", ""-jar"", ""my-service.jar""]\n']"
713,6155,6148,CC BY-SA 4.0,2019-01-29T23:06:50.810,"<p>In the official MariaDB image, <code>my.cnf</code> is configured to read additional configuration files from the <code>/etc/mysql/conf.d/</code> and <code>/etc/mysql/maria.conf.d/</code> directories:</p>

<pre><code>root@bbd24e22be98:/# tail /etc/mysql/my.cnf 

#
# * IMPORTANT: Additional settings that can override those from this file!
#   The files must end with '.cnf', otherwise they'll be ignored.
#
!include /etc/mysql/mariadb.cnf
!includedir /etc/mysql/conf.d/

root@bbd24e22be98:/# tail /etc/mysql/mariadb.cnf 
# * Character sets
# 
# Default is Latin1, if you need UTF-8 set all this (also in client section)
#
#character_set_server   = utf8 
#collation_server       = utf8_general_ci 
# Import all .cnf files from configuration directory
!includedir /etc/mysql/mariadb.conf.d/
</code></pre>

<p>Based on that, it is quite easy to setup utf8 everywhere by writing a configuration file to override the relevant settings, copying it at the right place from your Dockerfile:</p>

<pre><code>$ cat db/utf8.cnf 
[client]
default-character-set=utf8

[mysql]
default-character-set=utf8

[mysqld]
init_connect='SET collation_connection = utf8_unicode_ci'
init_connect='SET NAMES utf8'
character-set-server=utf8
collation-server=utf8_unicode_ci 
skip-character-set-client-handshake
</code></pre>



<pre><code>$ cat db/Dockerfile 
# Base image
FROM mariadb:10.4

# utf8 everywhere
COPY utf8.cnf /etc/mysql/mariadb.conf.d/
ENV MYSQL_RANDOM_ROOT_PASSWORD=yes
</code></pre>

<p>I let you compare the output of <code>show variables</code> after those changes with the one provided in the question:</p>

<pre><code>MariaDB [(none)]&gt; show variables like 'char%'
    -&gt; ;
+--------------------------+----------------------------+
| Variable_name            | Value                      |
+--------------------------+----------------------------+
| character_set_client     | utf8                       |
| character_set_connection | utf8                       |
| character_set_database   | utf8                       |
| character_set_filesystem | binary                     |
| character_set_results    | utf8                       |
| character_set_server     | utf8                       |
| character_set_system     | utf8                       |
| character_sets_dir       | /usr/share/mysql/charsets/ |
+--------------------------+----------------------------+
</code></pre>
",11179,2019-01-29T23:06:50.810,"[""root@bbd24e22be98:/# tail /etc/mysql/my.cnf \n\n#\n# * IMPORTANT: Additional settings that can override those from this file!\n#   The files must end with '.cnf', otherwise they'll be ignored.\n#\n!include /etc/mysql/mariadb.cnf\n!includedir /etc/mysql/conf.d/\n\nroot@bbd24e22be98:/# tail /etc/mysql/mariadb.cnf \n# * Character sets\n# \n# Default is Latin1, if you need UTF-8 set all this (also in client section)\n#\n#character_set_server   = utf8 \n#collation_server       = utf8_general_ci \n# Import all .cnf files from configuration directory\n!includedir /etc/mysql/mariadb.conf.d/\n"", ""$ cat db/utf8.cnf \n[client]\ndefault-character-set=utf8\n\n[mysql]\ndefault-character-set=utf8\n\n[mysqld]\ninit_connect='SET collation_connection = utf8_unicode_ci'\ninit_connect='SET NAMES utf8'\ncharacter-set-server=utf8\ncollation-server=utf8_unicode_ci \nskip-character-set-client-handshake\n"", '$ cat db/Dockerfile \n# Base image\nFROM mariadb:10.4\n\n# utf8 everywhere\nCOPY utf8.cnf /etc/mysql/mariadb.conf.d/\nENV MYSQL_RANDOM_ROOT_PASSWORD=yes\n', ""MariaDB [(none)]> show variables like 'char%'\n    -> ;\n+--------------------------+----------------------------+\n| Variable_name            | Value                      |\n+--------------------------+----------------------------+\n| character_set_client     | utf8                       |\n| character_set_connection | utf8                       |\n| character_set_database   | utf8                       |\n| character_set_filesystem | binary                     |\n| character_set_results    | utf8                       |\n| character_set_server     | utf8                       |\n| character_set_system     | utf8                       |\n| character_sets_dir       | /usr/share/mysql/charsets/ |\n+--------------------------+----------------------------+\n""]"
714,6161,6108,CC BY-SA 4.0,2019-01-30T16:39:39.827,"<p>The ""saltey"" way of doing this is typically in a map.jinja file. <a href=""https://github.com/jdshewey/salt-formula-freeipa/blob/master/freeipa/map.jinja"" rel=""nofollow noreferrer"">This one</a> for example...</p>

<p>In that, you would:</p>

<pre><code>{%- load_yaml as serverlist %}
#Note that a default list could be provided here
{%- endload %}

{%- set serverlist2 = salt['grains.filter_by'](serverlist, merge=salt['pillar.get']('pillarname:server_list_de')) %}
{%- set servers = salt['grains.filter_by'](serverlist2, merge=salt['pillar.get']('pillarname:server_list_uk')) %}
</code></pre>

<p>Then in your sls file you would then put at the top:</p>

<pre><code>{%- from ""formulaname/map.jinja"" import servers with context %}
</code></pre>

<p>Servers should then be available to you. I've never tried merging twice though, so give it a try. At a minimum this may give you some direction as the syntax for doing a pillar merge like this may get you what you are looking for.</p>
",2845,2019-01-30T16:39:39.827,"[""{%- load_yaml as serverlist %}\n#Note that a default list could be provided here\n{%- endload %}\n\n{%- set serverlist2 = salt['grains.filter_by'](serverlist, merge=salt['pillar.get']('pillarname:server_list_de')) %}\n{%- set servers = salt['grains.filter_by'](serverlist2, merge=salt['pillar.get']('pillarname:server_list_uk')) %}\n"", '{%- from ""formulaname/map.jinja"" import servers with context %}\n']"
715,6165,6146,CC BY-SA 4.0,2019-01-30T19:42:38.853,"<p>This compatibility issue was solved for chef14 with the new load format of a provider in a recipe.</p>

<pre><code>deploy_key deploy_key_name do
      provider Chef::ProviderResolver.new(node, find_resource!(""deploy_key[github]""), :nothing).resolve
      path ""/home/#{current_user}/.ssh""
      credentials({
          :token =&gt; File.read('/root/someid').strip
      })
      repo 'test/test_config'
      owner 'root'
      group 'root'
      mode '0400'
      action :add
  end
</code></pre>
",11070,2019-01-30T19:42:38.853,"['deploy_key deploy_key_name do\n      provider Chef::ProviderResolver.new(node, find_resource!(""deploy_key[github]""), :nothing).resolve\n      path ""/home/#{current_user}/.ssh""\n      credentials({\n          :token => File.read(\'/root/someid\').strip\n      })\n      repo \'test/test_config\'\n      owner \'root\'\n      group \'root\'\n      mode \'0400\'\n      action :add\n  end\n']"
716,6168,6154,CC BY-SA 4.0,2019-01-31T08:56:56.727,"<p>You have a problem of compile vs converge times as you guessed.</p>

<p>You code between the execute resource and the ruby_block resource is executed before the execute resource is converged.</p>

<p>The easiest way to circumvent that is to put that code within a ruby_block, and to avoid scoping problem use node.run_state hash to store the value to be checked.</p>

<p>A rewrite of your recipe which should work would be:</p>

<pre><code>#
# Cookbook:: test_cookbook
# Recipe:: check-vpn-ip
#
# Copyright:: 2019, The Authors, All Rights Reserved.

#Getting the IP address using the ruby's Socket class.

ip_list = Socket.ip_address_list
vpn_ip_list = ip_list.select{ |ip| ip.ip_address.match(/^10.12/) }
!vpn_ip_list.empty? ? ip_addr = vpn_ip_list.first.ip_address : ip_addr = """"

execute 'manually_start_open_vpn' do
  command ""sudo openvpn #{node['openvpn-conf-path']}/#{host}.conf &amp;""
  action :nothing
  only_if {ip_addr.length.eql?(0)}
end

ruby_block 'check_vpn_ip_list' do
  block do
    new_ip_list = Socket.ip_address_list
    new_vpn_ip_list = new_ip_list.select{ |ip| ip.ip_address.match(/^10.12/) }
    node.run_state['newvpn_ip_addr'] = !new_vpn_ip_list.empty? ?  new_vpn_ip_list.first.ip_address : """"
  end
end

ruby_block 'chat-bot' do
  block do
    machine_data = {text: ""OpenVPN IP not assigned to #{host} 
        software_version: 18.4.4 \n This is a test message please 
        ignore @all""}.to_json 
    header = {'Content-Type': 'text/json'}
    http = Net::HTTP.new(google_chat_uri.host,                       google_chat_uri.port)
    http.use_ssl = true
    request = Net::HTTP::Post.new(google_chat_uri.request_uri, header)
    request.body = machine_data
    response = http.request(request)
  end
  only_if {node.run_state['newvpn_ip_addr'].length.eql?(0)}
  action :nothing
end 
</code></pre>

<p>There's no real use of response = in the last line as you don't use it later, but I let it as is in case you wish to log in the ruby block the response.</p>
",13,2019-01-31T08:56:56.727,"['#\n# Cookbook:: test_cookbook\n# Recipe:: check-vpn-ip\n#\n# Copyright:: 2019, The Authors, All Rights Reserved.\n\n#Getting the IP address using the ruby\'s Socket class.\n\nip_list = Socket.ip_address_list\nvpn_ip_list = ip_list.select{ |ip| ip.ip_address.match(/^10.12/) }\n!vpn_ip_list.empty? ? ip_addr = vpn_ip_list.first.ip_address : ip_addr = """"\n\nexecute \'manually_start_open_vpn\' do\n  command ""sudo openvpn #{node[\'openvpn-conf-path\']}/#{host}.conf &""\n  action :nothing\n  only_if {ip_addr.length.eql?(0)}\nend\n\nruby_block \'check_vpn_ip_list\' do\n  block do\n    new_ip_list = Socket.ip_address_list\n    new_vpn_ip_list = new_ip_list.select{ |ip| ip.ip_address.match(/^10.12/) }\n    node.run_state[\'newvpn_ip_addr\'] = !new_vpn_ip_list.empty? ?  new_vpn_ip_list.first.ip_address : """"\n  end\nend\n\nruby_block \'chat-bot\' do\n  block do\n    machine_data = {text: ""OpenVPN IP not assigned to #{host} \n        software_version: 18.4.4 \\n This is a test message please \n        ignore @all""}.to_json \n    header = {\'Content-Type\': \'text/json\'}\n    http = Net::HTTP.new(google_chat_uri.host,                       google_chat_uri.port)\n    http.use_ssl = true\n    request = Net::HTTP::Post.new(google_chat_uri.request_uri, header)\n    request.body = machine_data\n    response = http.request(request)\n  end\n  only_if {node.run_state[\'newvpn_ip_addr\'].length.eql?(0)}\n  action :nothing\nend \n']"
717,6177,6174,CC BY-SA 4.0,2019-01-31T16:28:48.547,"<p>Either <code>request_timestamp</code> needs to be converted from the ISO 8601 formatted string into a timestamp with time zone, or <code>current_timestamp</code> needs to be converted into the string.</p>

<p>One method is to convert <code>request_timestamp</code> into a string in format <code>%Y-%m-%d</code>, e.g.</p>

<ul>
<li><code>split_part(request_timestamp, 'T', 1)</code></li>
<li><code>substr(request_timestamp, 1, 10)</code></li>
</ul>

<p>then compare it with <code>current_timestamp</code> which can be converted to the ISO 8601 formatted string.</p>

<p>Here is the final query:</p>

<pre><code>SELECT *
FROM elb_logs
WHERE split_part(request_timestamp, 'T', 1) = split_part(to_iso8601(current_timestamp), 'T', 1)
LIMIT 10
</code></pre>
",3,2019-01-31T16:28:48.547,"[""SELECT *\nFROM elb_logs\nWHERE split_part(request_timestamp, 'T', 1) = split_part(to_iso8601(current_timestamp), 'T', 1)\nLIMIT 10\n""]"
718,6179,6178,CC BY-SA 4.0,2019-01-31T17:17:07.103,"<p>The <code>docker network inspect</code> command produces a JSON output that can be parsed using <a href=""https://stedolan.github.io/jq/"" rel=""nofollow noreferrer""><code>jq</code></a> to extract the relevant piece of information:</p>

<pre><code>sudo docker network inspect app-bridge | jq '.[].Containers[].Name'

""app2""
""app3""
""app1""
""laughing_easley""
""database""
""thirsty_wing""
</code></pre>

<p>If you are already familiar with JSON processing with <code>jq</code>, the advantage is you can reinvest your knowledge without having to bother with <a href=""https://golang.org/pkg/text/template/"" rel=""nofollow noreferrer"">Go templates</a>. On the other hand, it relies on an external tool which may or may be not available at your site.</p>
",11179,2019-02-01T10:00:21.907,"['sudo docker network inspect app-bridge | jq \'.[].Containers[].Name\'\n\n""app2""\n""app3""\n""app1""\n""laughing_easley""\n""database""\n""thirsty_wing""\n']"
719,6193,6163,CC BY-SA 4.0,2019-02-01T08:49:57.990,"<p>There is a hacky workaround for getting Terraform to do module dependencies. You can force the module to be aware of the Terraform calling it like this:</p>

<pre><code># ROOT level main.tf
# -------------------------------------------------------------------
# Create NAT Gateway - Associates EIP as well
# -------------------------------------------------------------------
module ""vpc_nat_gateway"" {
  source            = ""./vpc_nat_gateway""
  vpc_id            = ""${ module.vpc.id }""
  public_subnet_ids = ""${ module.vpc_subnets.public_subnet_ids }""
  private_cidr      = ""${ var.private_cidr }""
  common_tags       = ""${ local.common_tags }""
}

# -------------------------------------------------------------------
# Create Private Routes
# -------------------------------------------------------------------
module ""vpc_private_route"" {
  source         = ""./vpc_private_route""
  vpc_id.        = ""${ module.vpc.id }""
  nat_gateway_id = ""${ module.vpc_nat_gateway.nat_gateway_id }""
  common_tags    = ""${ local.common_tags }""

  depends_on = [""${module.vpc_nat_gateway.nat_gateway_id}""]
}
</code></pre>

<pre><code># vpc_private_route module - main.tf
variable ""depends_on"" {
  default = []
}

resource ""null_resource"" ""depends_on"" {
  triggers {
    depends_on = ""${join("""", var.depends_on)}""
  }
}

data ""aws_nat_gateway"" ""az1"" {
  vpc_id = ""${ var.vpc_id }""

  tags {
    Name = ""*NAT GW AZ 1""
  }

  depends_on = [
    ""null_resource.depends_on""
  ]
}

data ""aws_nat_gateway"" ""az2"" {
  vpc_id = ""${ var.vpc_id }""

  tags {
    Name = ""*NAT GW AZ 2""
  }

  depends_on = [
    ""null_resource.depends_on""
  ]
}
</code></pre>

<p>It adds a lot of boilerplate but you will get the desired effect.</p>
",503,2019-02-01T08:49:57.990,"['# ROOT level main.tf\n# -------------------------------------------------------------------\n# Create NAT Gateway - Associates EIP as well\n# -------------------------------------------------------------------\nmodule ""vpc_nat_gateway"" {\n  source            = ""./vpc_nat_gateway""\n  vpc_id            = ""${ module.vpc.id }""\n  public_subnet_ids = ""${ module.vpc_subnets.public_subnet_ids }""\n  private_cidr      = ""${ var.private_cidr }""\n  common_tags       = ""${ local.common_tags }""\n}\n\n# -------------------------------------------------------------------\n# Create Private Routes\n# -------------------------------------------------------------------\nmodule ""vpc_private_route"" {\n  source         = ""./vpc_private_route""\n  vpc_id.        = ""${ module.vpc.id }""\n  nat_gateway_id = ""${ module.vpc_nat_gateway.nat_gateway_id }""\n  common_tags    = ""${ local.common_tags }""\n\n  depends_on = [""${module.vpc_nat_gateway.nat_gateway_id}""]\n}\n', '# vpc_private_route module - main.tf\nvariable ""depends_on"" {\n  default = []\n}\n\nresource ""null_resource"" ""depends_on"" {\n  triggers {\n    depends_on = ""${join("""", var.depends_on)}""\n  }\n}\n\ndata ""aws_nat_gateway"" ""az1"" {\n  vpc_id = ""${ var.vpc_id }""\n\n  tags {\n    Name = ""*NAT GW AZ 1""\n  }\n\n  depends_on = [\n    ""null_resource.depends_on""\n  ]\n}\n\ndata ""aws_nat_gateway"" ""az2"" {\n  vpc_id = ""${ var.vpc_id }""\n\n  tags {\n    Name = ""*NAT GW AZ 2""\n  }\n\n  depends_on = [\n    ""null_resource.depends_on""\n  ]\n}\n']"
720,6207,6203,CC BY-SA 4.0,2019-02-02T23:53:01.010,"<p>From my understanding of <a href=""https://developer.github.com/enterprise/2.13/v3/issues/labels/#add-labels-to-an-issue"" rel=""nofollow noreferrer"">the docs</a>, you should directly send an array (which is valid JSON), without wrapping it in an object. That is <code>[""bug""]</code> instead of <code>{""labels"": [""bug""]}</code>.</p>

<p>So, the proper request should be:</p>

<pre><code>curl -X POST -u githuser:gittoken \
    https://api.github.mycompany.com/repos/team/repo/issues/560/labels \
    -H ""Content-type: application/json"" -k \
    -d '[""bug""]' \
    -H ""Accept: application/json""
</code></pre>
",11179,2019-02-02T23:53:01.010,"['curl -X POST -u githuser:gittoken \\\n    https://api.github.mycompany.com/repos/team/repo/issues/560/labels \\\n    -H ""Content-type: application/json"" -k \\\n    -d \'[""bug""]\' \\\n    -H ""Accept: application/json""\n']"
721,6211,6197,CC BY-SA 4.0,2019-02-03T11:31:13.717,"<h2>Do that:</h2>

<p>You cannot attach several networks using the <code>--network</code> option. You have to rely on the <a href=""https://docs.docker.com/engine/reference/commandline/network_connect/"" rel=""nofollow noreferrer""><code>docker network connect</code></a> command. So if you want the multiple network interfaces to be available at container startup, you have to do it in three steps:</p>

<ol>
<li><em>create</em> the container,</li>
<li><em>connect</em> the extra network needed,</li>
<li>and finally <em>run</em> the container.</li>
</ol>



<pre><code># create a container, attaching it to one user-defined bridge:
docker create --name app3 \
              --network back-end \
              ${IMAGE}

# connect the other bridge networks:
docker network connect front-end app3

# start the container
docker start app3
</code></pre>



<pre><code>docker exec -it app3 ip addr show
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
465: eth1@if466: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:ac:13:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.19.0.3/16 brd 172.19.255.255 scope global eth1
       valid_lft forever preferred_lft forever
467: eth0@if468: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:ac:14:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.20.0.3/16 brd 172.20.255.255 scope global eth0
       valid_lft forever preferred_lft forever
</code></pre>

<p><br></p>

<h2>Dont' do that:</h2>

<p>It is tempting to do that instead:</p>

<pre><code># You probably DON'T want this:
# create a container with the default network settings
docker create --name app3 \
              ${IMAGE}

# connect the user-defined bridge networks:
docker network connect back-end app3
docker network connect front-end app3

# start the container
docker start app3
</code></pre>

<p>However, there is a pitfall here: when creating the container without an explicit <code>--network</code> option, Docker attaches it to the default bridge. Then the two <code>network connect</code> commands will add two <em>more</em> networks. And the container end-up bein attached to the <em>front_end</em> and <em>back_end</em> networks as expected. But also to the <em>default bridge</em>, something you probably don't want when using user-defined networks. </p>
",11179,2019-02-03T12:26:01.243,"['# create a container, attaching it to one user-defined bridge:\ndocker create --name app3 \\\n              --network back-end \\\n              ${IMAGE}\n\n# connect the other bridge networks:\ndocker network connect front-end app3\n\n# start the container\ndocker start app3\n', 'docker exec -it app3 ip addr show\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n465: eth1@if466: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:ac:13:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.19.0.3/16 brd 172.19.255.255 scope global eth1\n       valid_lft forever preferred_lft forever\n467: eth0@if468: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:ac:14:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.20.0.3/16 brd 172.20.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n', ""# You probably DON'T want this:\n# create a container with the default network settings\ndocker create --name app3 \\\n              ${IMAGE}\n\n# connect the user-defined bridge networks:\ndocker network connect back-end app3\ndocker network connect front-end app3\n\n# start the container\ndocker start app3\n""]"
722,6237,6236,CC BY-SA 4.0,2019-02-05T12:45:31.247,"<p>I assume you have a copy-paste issue. The right package name is <code>build-essential</code>. And if you want to split a RUN statement over several lines, you will have to use backslash for line continuation.</p>

<p>All that leading to something along the lines of:</p>

<pre><code>RUN apt-get update -yqq; apt-get -yqq install ruby ruby-dev \
          build-essential redis-tools
</code></pre>

<p>As a personal suggestion, when you have several commands to run, it is usually better to join them using <code>&amp;&amp;</code> rather than <code>;</code> since you want the build to fail if <em>either</em> command is failing.</p>

<pre><code>RUN apt-get update -yqq &amp;&amp; apt-get -yqq install ruby ruby-dev \
          build-essential redis-tools
</code></pre>
",11179,2019-02-05T12:45:31.247,"['RUN apt-get update -yqq; apt-get -yqq install ruby ruby-dev \\\n          build-essential redis-tools\n', 'RUN apt-get update -yqq && apt-get -yqq install ruby ruby-dev \\\n          build-essential redis-tools\n']"
723,6242,6241,CC BY-SA 4.0,2019-02-05T17:08:41.060,"<p>I take the risk of being downvoted here, but I find Go templates a nightmare to use beyond the most basic use cases. Don't take me wrong: they are extremely powerful as you can guess it by <a href=""https://golang.org/pkg/text/template/"" rel=""noreferrer"">reading the docs</a>, but I find the syntax unfriendly, and for the most complex cases, I prefer parsing the JSON output with <a href=""https://stedolan.github.io/jq/"" rel=""noreferrer""><code>jq</code></a>. Anyway:</p>

<h1>Formatting <code>expect</code> commands</h1>

<pre><code>sho$ CID=$(sudo docker run --rm -d busybox sleep 3000)                                                                                         
sh$ sudo docker inspect $CID
[
    {
        ""Id"": ""0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967"",
        ""Created"": ""2019-02-05T16:41:40.040349047Z"",
        ""Path"": ""sleep"",
        ""Args"": [
            ""3000""
        ],
        ""State"": {
            ""Status"": ""running"",
            ""Running"": true,
            ""Paused"": false,
            ""Restarting"": false,
            ""OOMKilled"": false,
            ""Dead"": false,
            ""Pid"": 26467,
            ""ExitCode"": 0,
            ""Error"": """",
            ""StartedAt"": ""2019-02-05T16:41:40.659056612Z"",
            ""FinishedAt"": ""0001-01-01T00:00:00Z""
        },
        ""Image"": ""sha256:3a093384ac306cbac30b67f1585e12b30ab1a899374dabc3170b9bca246f1444"",
        ""ResolvConfPath"": ""/var/lib/docker/containers/0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967/resolv.conf"",
        ""HostnamePath"": ""/var/lib/docker/containers/0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967/hostname"",
        ""HostsPath"": ""/var/lib/docker/containers/0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967/hosts"",
        ""LogPath"": ""/var/lib/docker/containers/0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967/0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967-json.log"",
        ""Name"": ""/vibrant_shaw"",
        ""RestartCount"": 0,
        ""Driver"": ""aufs"",
        ""Platform"": ""linux"",
        ""MountLabel"": """",
        ""ProcessLabel"": """",
        ""AppArmorProfile"": ""docker-default"",
        ""ExecIDs"": null,
        ""HostConfig"": {
            ""Binds"": null,
            ""ContainerIDFile"": """",
           ""LogConfig"": {
                ""Type"": ""json-file"",
                ""Config"": {}
            },
            ""NetworkMode"": ""default"",
            ""PortBindings"": {},
            ""RestartPolicy"": {
                ""Name"": ""no"",
                ""MaximumRetryCount"": 0
            },
            ""AutoRemove"": true,
            ""VolumeDriver"": """",
            ""VolumesFrom"": null,
            ""CapAdd"": null,
            ""CapDrop"": null,
            ""Dns"": [],
            ""DnsOptions"": [],
            ""DnsSearch"": [],
            ""ExtraHosts"": null,
            ""GroupAdd"": null,
            ""IpcMode"": ""shareable"",
            ""Cgroup"": """",
            ""Links"": null,
            ""OomScoreAdj"": 0,
            ""PidMode"": """",
            ""Privileged"": false,
            ""PublishAllPorts"": false,
            ""ReadonlyRootfs"": false,
            ""SecurityOpt"": null,
            ""UTSMode"": """",
            ""UsernsMode"": """",
            ""ShmSize"": 67108864,
            ""Runtime"": ""runc"",
            ""ConsoleSize"": [
                0,
                0
            ],
            ""Isolation"": """",
            ""CpuShares"": 0,
            ""Memory"": 0,
            ""NanoCpus"": 0,
            ""CgroupParent"": """",
            ""BlkioWeight"": 0,
            ""BlkioWeightDevice"": [],
            ""BlkioDeviceReadBps"": null,
            ""BlkioDeviceWriteBps"": null,
            ""BlkioDeviceReadIOps"": null,
            ""BlkioDeviceWriteIOps"": null,
            ""CpuPeriod"": 0,
            ""CpuQuota"": 0,
            ""CpuRealtimePeriod"": 0,
            ""CpuRealtimeRuntime"": 0,
            ""CpusetCpus"": """",
            ""CpusetMems"": """",
            ""Devices"": [],
            ""DeviceCgroupRules"": null,
            ""DiskQuota"": 0,
            ""KernelMemory"": 0,
            ""MemoryReservation"": 0,
            ""MemorySwap"": 0,
            ""MemorySwappiness"": null,
            ""OomKillDisable"": false,
            ""PidsLimit"": 0,
            ""Ulimits"": null,
            ""CpuCount"": 0,
            ""CpuPercent"": 0,
            ""IOMaximumIOps"": 0,
            ""IOMaximumBandwidth"": 0,
            ""MaskedPaths"": [
                ""/proc/acpi"",
                ""/proc/kcore"",
                ""/proc/keys"",
                ""/proc/latency_stats"",
                ""/proc/timer_list"",
                ""/proc/timer_stats"",
                ""/proc/sched_debug"",
                ""/proc/scsi"",
                ""/sys/firmware""
            ],
            ""ReadonlyPaths"": [
                ""/proc/asound"",
                ""/proc/bus"",
                ""/proc/fs"",
                ""/proc/irq"",
                ""/proc/sys"",
                ""/proc/sysrq-trigger""
            ]
        },
        ""GraphDriver"": {
            ""Data"": null,
            ""Name"": ""aufs""
        },
        ""Mounts"": [],
        ""Config"": {
            ""Hostname"": ""0470a3549d2f"",
            ""Domainname"": """",
            ""User"": """",
            ""AttachStdin"": false,
            ""AttachStdout"": false,
            ""AttachStderr"": false,
            ""Tty"": false,
            ""OpenStdin"": false,
            ""StdinOnce"": false,
            ""Env"": [
                ""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin""
            ],
            ""Cmd"": [
                ""sleep"",
                ""3000""
            ],
            ""Image"": ""busybox"",
            ""Volumes"": null,
            ""WorkingDir"": """",
            ""Entrypoint"": null,
            ""OnBuild"": null,
            ""Labels"": {}
        },
        ""NetworkSettings"": {
            ""Bridge"": """",
            ""SandboxID"": ""654da638965d9bb26e394ba61036ea713bdccb6304eb09bee86f3c0611a26ca5"",
            ""HairpinMode"": false,
            ""LinkLocalIPv6Address"": """",
            ""LinkLocalIPv6PrefixLen"": 0,
            ""Ports"": {},
            ""SandboxKey"": ""/var/run/docker/netns/654da638965d"",
            ""SecondaryIPAddresses"": null,
            ""SecondaryIPv6Addresses"": null,
            ""EndpointID"": ""c69ef9cb870a3c477105c7bc19e370683886e4e3c62fac8444d3e1e097551250"",
            ""Gateway"": ""172.17.0.1"",
            ""GlobalIPv6Address"": """",
            ""GlobalIPv6PrefixLen"": 0,
            ""IPAddress"": ""172.17.0.3"",
            ""IPPrefixLen"": 16,
            ""IPv6Gateway"": """",
            ""MacAddress"": ""02:42:ac:11:00:03"",
            ""Networks"": {
                ""bridge"": {
                    ""IPAMConfig"": null,
                    ""Links"": null,
                    ""Aliases"": null,
                    ""NetworkID"": ""5ec8728b05efd5ce6bfde5cbe6e42f247348345e0fdfb305fda76566327fc151"",
                    ""EndpointID"": ""c69ef9cb870a3c477105c7bc19e370683886e4e3c62fac8444d3e1e097551250"",
                    ""Gateway"": ""172.17.0.1"",
                    ""IPAddress"": ""172.17.0.3"",
                    ""IPPrefixLen"": 16,
                    ""IPv6Gateway"": """",
                    ""GlobalIPv6Address"": """",
                    ""GlobalIPv6PrefixLen"": 0,
                    ""MacAddress"": ""02:42:ac:11:00:03"",
                    ""DriverOpts"": null
                }
            }
        }
    }
]
</code></pre>

<h2>Returning scalar properties</h2>

<p>You can query any scalar attribute by its name, prefixed by a dot:</p>

<pre><code>sh$ sudo docker inspect $CID --format '{{.Id}}
0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967
sh$ sudo docker inspect $CID --format '{{.Name}} {{.Driver}}'
/vibrant_shaw aufs

# jq notation
sh$ sudo docker inspect $CID | jq '.[].Id'
""0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967""

sh$ sudo docker inspect $CID | jq '.[]|(.Name,.Driver)'
""/vibrant_shaw""
""aufs""
</code></pre>

<p>You can also query nested fields:</p>

<pre><code>sh$ sudo docker inspect $CID --format '{{.State.Running}}'
true

# jq notation
sudo docker inspect $CID | jq '.[].State.Running'
true
</code></pre>

<h2>Returning entire objects and arrays</h2>

<p>But it does not work as expected for nested structures:</p>

<pre><code>sh$ sudo docker inspect $CID --format '{{.State}}'
{running true false false false false 26467 0  2019-02-05T16:41:40.659056612Z 0001-01-01T00:00:00Z &lt;nil&gt;}
</code></pre>

<p>You end up having the data, but without the field names, it is pretty useless--unless you are assuming some predefined field order (something that is probably not safe).</p>

<p>When accessing entire objects, there are chances you want an <a href=""https://docs.docker.com/config/formatting/"" rel=""noreferrer"">explicit formatter</a>:</p>

<pre><code>sh$ sudo docker inspect $CID --format '{{json .State}}'
{""Status"":""running"",""Running"":true,""Paused"":false,""Restarting"":false,""OOMKilled"":false,""Dead"":false,""Pid"":26467,""ExitCode"":0,""Error"":"""",""StartedAt"":""2019-02-05T16:41:40.659056612Z"",""FinishedAt"":""0001-01-01T00:00:00Z""}

# jq notation
sh$ sudo docker inspect $CID | jq '.[].State'
{
  ""Status"": ""running"",
  ""Running"": true,
  ""Paused"": false,
  ""Restarting"": false,
  ""OOMKilled"": false,
  ""Dead"": false,
  ""Pid"": 26467,
  ""ExitCode"": 0,
  ""Error"": """",
  ""StartedAt"": ""2019-02-05T16:41:40.659056612Z"",
  ""FinishedAt"": ""0001-01-01T00:00:00Z""
}
</code></pre>

<p>Same thing for arrays:</p>

<pre><code>sh$ sudo docker inspect $CID --format '{{.HostConfig.ReadonlyPaths}}'
[/proc/asound /proc/bus /proc/fs /proc/irq /proc/sys /proc/sysrq-trigger]

sh$ sudo docker inspect $CID --format '{{json .HostConfig.ReadonlyPaths}}'
[""/proc/asound"",""/proc/bus"",""/proc/fs"",""/proc/irq"",""/proc/sys"",""/proc/sysrq-trigger""]

sh$ sudo docker inspect $CID --format '{{join .HostConfig.ReadonlyPaths "":""}}'
/proc/asound:/proc/bus:/proc/fs:/proc/irq:/proc/sys:/proc/sysrq-trigger

# jq notation
sh$ sudo docker inspect $CID | jq '.[].HostConfig.ReadonlyPaths'
[
  ""/proc/asound"",
  ""/proc/bus"",
  ""/proc/fs"",
  ""/proc/irq"",
  ""/proc/sys"",
  ""/proc/sysrq-trigger""
]
sh$ sudo docker inspect $CID | jq '.[].HostConfig.ReadonlyPaths | join("":"")'
""/proc/asound:/proc/bus:/proc/fs:/proc/irq:/proc/sys:/proc/sysrq-trigger""
</code></pre>

<h2>Arrays of objects</h2>

<p>More complicated (according to my limited Go Template skills) is accessing fields nested in an array of objects:</p>

<pre><code># This works as expected
sh$ sudo docker network inspect bridge --format '{{json .IPAM.Config}}'
[{""Subnet"":""172.17.0.0/16"",""Gateway"":""172.17.0.1""}]

# But not that
sudo docker network inspect bridge --format '{{.IPAM.Config.Gateway}}'

Template parsing error: template: :1:7: executing """" at &lt;.IPAM.Config.Gateway&gt;: can't evaluate field Gateway in type interface {}
</code></pre>

<p>When I want to extract such nested value, I resort on an explicit range loop:</p>

<pre><code>sh$ sudo docker network inspect bridge --format '{{range .IPAM.Config}}{{.Gateway}}{{end}}'
172.17.0.1

# jq notation
sh$ sudo docker network inspect bridge | jq '.[].IPAM.Config[].Gateway'
""172.17.0.1""

sh$ sudo docker network inspect bridge | jq -r '.[].IPAM.Config[].Gateway'
172.17.0.1
</code></pre>

<h1>Formatting <code>ls</code> commands</h1>

<p>With the <code>json</code> formatter, we can obtain (some? all?) the possible selectors you can later use with <code>--format</code>:</p>

<pre><code>sh$ sudo docker network ls --format '{{json .}}'
{""CreatedAt"":""2019-01-07 14:28:55.63238018 +0100 CET"",""Driver"":""bridge"",""ID"":""5ec8728b05ef"",""IPv6"":""false"",""Internal"":""false"",""Labels"":"""",""Name"":""bridge"",""Scope"":""local""}
{""CreatedAt"":""2019-02-05 15:36:57.701603791 +0100 CET"",""Driver"":""bridge"",""ID"":""45d6f09ca923"",""IPv6"":""false"",""Internal"":""false"",""Labels"":""com.docker.compose.network=default,com.docker.compose.project=compose-demo,com.docker.compose.version=1.23.2"",""Name"":""compose-demo_default"",""Scope"":""local""}
{""CreatedAt"":""2019-02-05 17:30:47.98883918 +0100 CET"",""Driver"":""bridge"",""ID"":""aaff418d1c56"",""IPv6"":""false"",""Internal"":""false"",""Labels"":""com.docker.compose.network=net,com.docker.compose.project=compose-demo,com.docker.compose.version=1.23.2"",""Name"":""compose-demo_net"",""Scope"":""local""}
{""CreatedAt"":""2018-05-26 10:31:48.149819089 +0200 CEST"",""Driver"":""host"",""ID"":""988954899b53"",""IPv6"":""false"",""Internal"":""false"",""Labels"":"""",""Name"":""host"",""Scope"":""local""}
{""CreatedAt"":""2018-05-26 10:31:48.118573602 +0200 CEST"",""Driver"":""null"",""ID"":""ce1680ed377f"",""IPv6"":""false"",""Internal"":""false"",""Labels"":"""",""Name"":""none"",""Scope"":""local""}
{""CreatedAt"":""2019-02-05 19:44:21.286955573 +0100 CET"",""Driver"":""bridge"",""ID"":""41c62c023d16"",""IPv6"":""false"",""Internal"":""false"",""Labels"":""com.docker.compose.version=1.23.2,com.docker.compose.network=default,com.docker.compose.project=test"",""Name"":""test_default"",""Scope"":""local""}
</code></pre>

<p>Here, you can see <code>docker network ls</code> exposes, among others, the ""ID"", ""Driver"" and ""Scope"" fields. You can use them in your format:</p>

<pre><code>sh$ $ sudo docker network ls --format '{{.ID}}: {{.Driver}} ({{.Scope}})'
5ec8728b05ef: bridge (local)
45d6f09ca923: bridge (local)
aaff418d1c56: bridge (local)
988954899b53: host (local)
ce1680ed377f: null (local)
41c62c023d16: bridge (local)
</code></pre>

<h1>The best of both worlds</h1>

<p>The <code>docker ... ls</code> commands only exports a small subset of the docker object's properties. Depending your needs, you may prefer something along the lines of <code>docker ... inspect $(docker ... ls -q)</code>.</p>

<p>For example, <code>docker image ls</code> does not export the image architecture. but you can obtain it with <code>docker image inspect</code>. If you want that information, you could use something like that:</p>

<pre><code>sh$ sudo docker image inspect \
         --format '{{.Id}}: {{.RepoTags}} ({{.Architecture}})' \
         $(sudo docker image ls -q)
sha256:fc37804350a8adea0b41dba0c413a6c967140ca2ed6dfeefdbe88d7868902406: [compose-demo_monitor:latest] (amd64)
sha256:a6f30c0890bca94e3cf5930ad5c3358b06cb38450e92d4ddabeb208ee34383f8: [compose-demo_app:latest] (amd64)
sha256:a79892b33e0bb51598e9311cc1d23ca8d0e3013a5a15fd67d202d22ffd08a6af: [] (amd64)
sha256:394c82635f220db389b8532e316001674965b51679dbc8dff747d5f224e6d568: [] (amd64)
sha256:95f0c755feb65af441c0cb8727bb13b35517977a3bed06e4a3456c95d6a69dd4: [redis:5.0-alpine] (amd64)
sha256:1f6c34f7921c7b50ef4452737399b5cff0eb834fc183d188d82886fd23b7fc34: [node:8] (amd64)
sha256:3a093384ac306cbac30b67f1585e12b30ab1a899374dabc3170b9bca246f1444: [busybox:latest] (amd64)
</code></pre>
",11179,2019-02-05T20:09:12.710,"['sho$ CID=$(sudo docker run --rm -d busybox sleep 3000)                                                                                         \nsh$ sudo docker inspect $CID\n[\n    {\n        ""Id"": ""0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967"",\n        ""Created"": ""2019-02-05T16:41:40.040349047Z"",\n        ""Path"": ""sleep"",\n        ""Args"": [\n            ""3000""\n        ],\n        ""State"": {\n            ""Status"": ""running"",\n            ""Running"": true,\n            ""Paused"": false,\n            ""Restarting"": false,\n            ""OOMKilled"": false,\n            ""Dead"": false,\n            ""Pid"": 26467,\n            ""ExitCode"": 0,\n            ""Error"": """",\n            ""StartedAt"": ""2019-02-05T16:41:40.659056612Z"",\n            ""FinishedAt"": ""0001-01-01T00:00:00Z""\n        },\n        ""Image"": ""sha256:3a093384ac306cbac30b67f1585e12b30ab1a899374dabc3170b9bca246f1444"",\n        ""ResolvConfPath"": ""/var/lib/docker/containers/0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967/resolv.conf"",\n        ""HostnamePath"": ""/var/lib/docker/containers/0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967/hostname"",\n        ""HostsPath"": ""/var/lib/docker/containers/0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967/hosts"",\n        ""LogPath"": ""/var/lib/docker/containers/0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967/0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967-json.log"",\n        ""Name"": ""/vibrant_shaw"",\n        ""RestartCount"": 0,\n        ""Driver"": ""aufs"",\n        ""Platform"": ""linux"",\n        ""MountLabel"": """",\n        ""ProcessLabel"": """",\n        ""AppArmorProfile"": ""docker-default"",\n        ""ExecIDs"": null,\n        ""HostConfig"": {\n            ""Binds"": null,\n            ""ContainerIDFile"": """",\n           ""LogConfig"": {\n                ""Type"": ""json-file"",\n                ""Config"": {}\n            },\n            ""NetworkMode"": ""default"",\n            ""PortBindings"": {},\n            ""RestartPolicy"": {\n                ""Name"": ""no"",\n                ""MaximumRetryCount"": 0\n            },\n            ""AutoRemove"": true,\n            ""VolumeDriver"": """",\n            ""VolumesFrom"": null,\n            ""CapAdd"": null,\n            ""CapDrop"": null,\n            ""Dns"": [],\n            ""DnsOptions"": [],\n            ""DnsSearch"": [],\n            ""ExtraHosts"": null,\n            ""GroupAdd"": null,\n            ""IpcMode"": ""shareable"",\n            ""Cgroup"": """",\n            ""Links"": null,\n            ""OomScoreAdj"": 0,\n            ""PidMode"": """",\n            ""Privileged"": false,\n            ""PublishAllPorts"": false,\n            ""ReadonlyRootfs"": false,\n            ""SecurityOpt"": null,\n            ""UTSMode"": """",\n            ""UsernsMode"": """",\n            ""ShmSize"": 67108864,\n            ""Runtime"": ""runc"",\n            ""ConsoleSize"": [\n                0,\n                0\n            ],\n            ""Isolation"": """",\n            ""CpuShares"": 0,\n            ""Memory"": 0,\n            ""NanoCpus"": 0,\n            ""CgroupParent"": """",\n            ""BlkioWeight"": 0,\n            ""BlkioWeightDevice"": [],\n            ""BlkioDeviceReadBps"": null,\n            ""BlkioDeviceWriteBps"": null,\n            ""BlkioDeviceReadIOps"": null,\n            ""BlkioDeviceWriteIOps"": null,\n            ""CpuPeriod"": 0,\n            ""CpuQuota"": 0,\n            ""CpuRealtimePeriod"": 0,\n            ""CpuRealtimeRuntime"": 0,\n            ""CpusetCpus"": """",\n            ""CpusetMems"": """",\n            ""Devices"": [],\n            ""DeviceCgroupRules"": null,\n            ""DiskQuota"": 0,\n            ""KernelMemory"": 0,\n            ""MemoryReservation"": 0,\n            ""MemorySwap"": 0,\n            ""MemorySwappiness"": null,\n            ""OomKillDisable"": false,\n            ""PidsLimit"": 0,\n            ""Ulimits"": null,\n            ""CpuCount"": 0,\n            ""CpuPercent"": 0,\n            ""IOMaximumIOps"": 0,\n            ""IOMaximumBandwidth"": 0,\n            ""MaskedPaths"": [\n                ""/proc/acpi"",\n                ""/proc/kcore"",\n                ""/proc/keys"",\n                ""/proc/latency_stats"",\n                ""/proc/timer_list"",\n                ""/proc/timer_stats"",\n                ""/proc/sched_debug"",\n                ""/proc/scsi"",\n                ""/sys/firmware""\n            ],\n            ""ReadonlyPaths"": [\n                ""/proc/asound"",\n                ""/proc/bus"",\n                ""/proc/fs"",\n                ""/proc/irq"",\n                ""/proc/sys"",\n                ""/proc/sysrq-trigger""\n            ]\n        },\n        ""GraphDriver"": {\n            ""Data"": null,\n            ""Name"": ""aufs""\n        },\n        ""Mounts"": [],\n        ""Config"": {\n            ""Hostname"": ""0470a3549d2f"",\n            ""Domainname"": """",\n            ""User"": """",\n            ""AttachStdin"": false,\n            ""AttachStdout"": false,\n            ""AttachStderr"": false,\n            ""Tty"": false,\n            ""OpenStdin"": false,\n            ""StdinOnce"": false,\n            ""Env"": [\n                ""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin""\n            ],\n            ""Cmd"": [\n                ""sleep"",\n                ""3000""\n            ],\n            ""Image"": ""busybox"",\n            ""Volumes"": null,\n            ""WorkingDir"": """",\n            ""Entrypoint"": null,\n            ""OnBuild"": null,\n            ""Labels"": {}\n        },\n        ""NetworkSettings"": {\n            ""Bridge"": """",\n            ""SandboxID"": ""654da638965d9bb26e394ba61036ea713bdccb6304eb09bee86f3c0611a26ca5"",\n            ""HairpinMode"": false,\n            ""LinkLocalIPv6Address"": """",\n            ""LinkLocalIPv6PrefixLen"": 0,\n            ""Ports"": {},\n            ""SandboxKey"": ""/var/run/docker/netns/654da638965d"",\n            ""SecondaryIPAddresses"": null,\n            ""SecondaryIPv6Addresses"": null,\n            ""EndpointID"": ""c69ef9cb870a3c477105c7bc19e370683886e4e3c62fac8444d3e1e097551250"",\n            ""Gateway"": ""172.17.0.1"",\n            ""GlobalIPv6Address"": """",\n            ""GlobalIPv6PrefixLen"": 0,\n            ""IPAddress"": ""172.17.0.3"",\n            ""IPPrefixLen"": 16,\n            ""IPv6Gateway"": """",\n            ""MacAddress"": ""02:42:ac:11:00:03"",\n            ""Networks"": {\n                ""bridge"": {\n                    ""IPAMConfig"": null,\n                    ""Links"": null,\n                    ""Aliases"": null,\n                    ""NetworkID"": ""5ec8728b05efd5ce6bfde5cbe6e42f247348345e0fdfb305fda76566327fc151"",\n                    ""EndpointID"": ""c69ef9cb870a3c477105c7bc19e370683886e4e3c62fac8444d3e1e097551250"",\n                    ""Gateway"": ""172.17.0.1"",\n                    ""IPAddress"": ""172.17.0.3"",\n                    ""IPPrefixLen"": 16,\n                    ""IPv6Gateway"": """",\n                    ""GlobalIPv6Address"": """",\n                    ""GlobalIPv6PrefixLen"": 0,\n                    ""MacAddress"": ""02:42:ac:11:00:03"",\n                    ""DriverOpts"": null\n                }\n            }\n        }\n    }\n]\n', 'sh$ sudo docker inspect $CID --format \'{{.Id}}\n0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967\nsh$ sudo docker inspect $CID --format \'{{.Name}} {{.Driver}}\'\n/vibrant_shaw aufs\n\n# jq notation\nsh$ sudo docker inspect $CID | jq \'.[].Id\'\n""0470a3549d2f41efd0477cf8fc4eb3a27aca592f089c018ad24704031bbef967""\n\nsh$ sudo docker inspect $CID | jq \'.[]|(.Name,.Driver)\'\n""/vibrant_shaw""\n""aufs""\n', ""sh$ sudo docker inspect $CID --format '{{.State.Running}}'\ntrue\n\n# jq notation\nsudo docker inspect $CID | jq '.[].State.Running'\ntrue\n"", ""sh$ sudo docker inspect $CID --format '{{.State}}'\n{running true false false false false 26467 0  2019-02-05T16:41:40.659056612Z 0001-01-01T00:00:00Z <nil>}\n"", 'sh$ sudo docker inspect $CID --format \'{{json .State}}\'\n{""Status"":""running"",""Running"":true,""Paused"":false,""Restarting"":false,""OOMKilled"":false,""Dead"":false,""Pid"":26467,""ExitCode"":0,""Error"":"""",""StartedAt"":""2019-02-05T16:41:40.659056612Z"",""FinishedAt"":""0001-01-01T00:00:00Z""}\n\n# jq notation\nsh$ sudo docker inspect $CID | jq \'.[].State\'\n{\n  ""Status"": ""running"",\n  ""Running"": true,\n  ""Paused"": false,\n  ""Restarting"": false,\n  ""OOMKilled"": false,\n  ""Dead"": false,\n  ""Pid"": 26467,\n  ""ExitCode"": 0,\n  ""Error"": """",\n  ""StartedAt"": ""2019-02-05T16:41:40.659056612Z"",\n  ""FinishedAt"": ""0001-01-01T00:00:00Z""\n}\n', 'sh$ sudo docker inspect $CID --format \'{{.HostConfig.ReadonlyPaths}}\'\n[/proc/asound /proc/bus /proc/fs /proc/irq /proc/sys /proc/sysrq-trigger]\n\nsh$ sudo docker inspect $CID --format \'{{json .HostConfig.ReadonlyPaths}}\'\n[""/proc/asound"",""/proc/bus"",""/proc/fs"",""/proc/irq"",""/proc/sys"",""/proc/sysrq-trigger""]\n\nsh$ sudo docker inspect $CID --format \'{{join .HostConfig.ReadonlyPaths "":""}}\'\n/proc/asound:/proc/bus:/proc/fs:/proc/irq:/proc/sys:/proc/sysrq-trigger\n\n# jq notation\nsh$ sudo docker inspect $CID | jq \'.[].HostConfig.ReadonlyPaths\'\n[\n  ""/proc/asound"",\n  ""/proc/bus"",\n  ""/proc/fs"",\n  ""/proc/irq"",\n  ""/proc/sys"",\n  ""/proc/sysrq-trigger""\n]\nsh$ sudo docker inspect $CID | jq \'.[].HostConfig.ReadonlyPaths | join("":"")\'\n""/proc/asound:/proc/bus:/proc/fs:/proc/irq:/proc/sys:/proc/sysrq-trigger""\n', '# This works as expected\nsh$ sudo docker network inspect bridge --format \'{{json .IPAM.Config}}\'\n[{""Subnet"":""172.17.0.0/16"",""Gateway"":""172.17.0.1""}]\n\n# But not that\nsudo docker network inspect bridge --format \'{{.IPAM.Config.Gateway}}\'\n\nTemplate parsing error: template: :1:7: executing """" at <.IPAM.Config.Gateway>: can\'t evaluate field Gateway in type interface {}\n', 'sh$ sudo docker network inspect bridge --format \'{{range .IPAM.Config}}{{.Gateway}}{{end}}\'\n172.17.0.1\n\n# jq notation\nsh$ sudo docker network inspect bridge | jq \'.[].IPAM.Config[].Gateway\'\n""172.17.0.1""\n\nsh$ sudo docker network inspect bridge | jq -r \'.[].IPAM.Config[].Gateway\'\n172.17.0.1\n', 'sh$ sudo docker network ls --format \'{{json .}}\'\n{""CreatedAt"":""2019-01-07 14:28:55.63238018 +0100 CET"",""Driver"":""bridge"",""ID"":""5ec8728b05ef"",""IPv6"":""false"",""Internal"":""false"",""Labels"":"""",""Name"":""bridge"",""Scope"":""local""}\n{""CreatedAt"":""2019-02-05 15:36:57.701603791 +0100 CET"",""Driver"":""bridge"",""ID"":""45d6f09ca923"",""IPv6"":""false"",""Internal"":""false"",""Labels"":""com.docker.compose.network=default,com.docker.compose.project=compose-demo,com.docker.compose.version=1.23.2"",""Name"":""compose-demo_default"",""Scope"":""local""}\n{""CreatedAt"":""2019-02-05 17:30:47.98883918 +0100 CET"",""Driver"":""bridge"",""ID"":""aaff418d1c56"",""IPv6"":""false"",""Internal"":""false"",""Labels"":""com.docker.compose.network=net,com.docker.compose.project=compose-demo,com.docker.compose.version=1.23.2"",""Name"":""compose-demo_net"",""Scope"":""local""}\n{""CreatedAt"":""2018-05-26 10:31:48.149819089 +0200 CEST"",""Driver"":""host"",""ID"":""988954899b53"",""IPv6"":""false"",""Internal"":""false"",""Labels"":"""",""Name"":""host"",""Scope"":""local""}\n{""CreatedAt"":""2018-05-26 10:31:48.118573602 +0200 CEST"",""Driver"":""null"",""ID"":""ce1680ed377f"",""IPv6"":""false"",""Internal"":""false"",""Labels"":"""",""Name"":""none"",""Scope"":""local""}\n{""CreatedAt"":""2019-02-05 19:44:21.286955573 +0100 CET"",""Driver"":""bridge"",""ID"":""41c62c023d16"",""IPv6"":""false"",""Internal"":""false"",""Labels"":""com.docker.compose.version=1.23.2,com.docker.compose.network=default,com.docker.compose.project=test"",""Name"":""test_default"",""Scope"":""local""}\n', ""sh$ $ sudo docker network ls --format '{{.ID}}: {{.Driver}} ({{.Scope}})'\n5ec8728b05ef: bridge (local)\n45d6f09ca923: bridge (local)\naaff418d1c56: bridge (local)\n988954899b53: host (local)\nce1680ed377f: null (local)\n41c62c023d16: bridge (local)\n"", ""sh$ sudo docker image inspect \\\n         --format '{{.Id}}: {{.RepoTags}} ({{.Architecture}})' \\\n         $(sudo docker image ls -q)\nsha256:fc37804350a8adea0b41dba0c413a6c967140ca2ed6dfeefdbe88d7868902406: [compose-demo_monitor:latest] (amd64)\nsha256:a6f30c0890bca94e3cf5930ad5c3358b06cb38450e92d4ddabeb208ee34383f8: [compose-demo_app:latest] (amd64)\nsha256:a79892b33e0bb51598e9311cc1d23ca8d0e3013a5a15fd67d202d22ffd08a6af: [] (amd64)\nsha256:394c82635f220db389b8532e316001674965b51679dbc8dff747d5f224e6d568: [] (amd64)\nsha256:95f0c755feb65af441c0cb8727bb13b35517977a3bed06e4a3456c95d6a69dd4: [redis:5.0-alpine] (amd64)\nsha256:1f6c34f7921c7b50ef4452737399b5cff0eb834fc183d188d82886fd23b7fc34: [node:8] (amd64)\nsha256:3a093384ac306cbac30b67f1585e12b30ab1a899374dabc3170b9bca246f1444: [busybox:latest] (amd64)\n""]"
724,6286,6265,CC BY-SA 4.0,2019-02-07T10:01:59.190,"<p>No, Jenkins file is not created at execution. 
Actually Jenkins file is a suite of all steps or activity which you want to build as a job or a groovy code.</p>

<p>Jenkins file come from code repository, if you added file in your project.</p>

<p><strong>Below is a Jenkins file example:</strong></p>

<pre><code>pipeline {
    agent any

    stages {
        stage('Build') {
            steps {
                echo 'Building..'
            }
        }
        stage('Test') {
            steps {
                echo 'Testing..'
            }
        }
        stage('Deploy') {
            steps {
                echo 'Deploying....'
            }
        }
    }
}
</code></pre>

<p>for more reference watch this video: <a href=""https://www.youtube.com/watch?v=KZY4Rwsewro"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=KZY4Rwsewro</a></p>
",11598,2019-02-07T10:08:35.847,"[""pipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                echo 'Building..'\n            }\n        }\n        stage('Test') {\n            steps {\n                echo 'Testing..'\n            }\n        }\n        stage('Deploy') {\n            steps {\n                echo 'Deploying....'\n            }\n        }\n    }\n}\n""]"
725,6288,6266,CC BY-SA 4.0,2019-02-07T10:22:31.280,"<p>docker inspect the container running jenkins</p>

<pre><code>docker inspect  eaddfb02c83c|grep _50000
</code></pre>

<p>this gives some variables which are set with the correct address</p>

<pre><code>$ docker inspect  eaddfb02c83c|grep _50000
            ""MY_RELEASE_JENKINS_AGENT_PORT_50000_TCP_PORT=50000"",
            ""MY_RELEASE_JENKINS_AGENT_PORT_50000_TCP_ADDR=10.102.9.168"",
            ""MY_RELEASE_JENKINS_AGENT_PORT_50000_TCP_PROTO=tcp"",
            ""MY_RELEASE_JENKINS_AGENT_PORT_50000_TCP=tcp://10.102.9.168:50000"",
</code></pre>

<p>use this information to set the ""Jenkins tunnel"" argument in the Cloud Kubernetes, using the values above for example the setting is 10.102.9.168:50000</p>
",4954,2019-02-07T10:22:31.280,"['docker inspect  eaddfb02c83c|grep _50000\n', '$ docker inspect  eaddfb02c83c|grep _50000\n            ""MY_RELEASE_JENKINS_AGENT_PORT_50000_TCP_PORT=50000"",\n            ""MY_RELEASE_JENKINS_AGENT_PORT_50000_TCP_ADDR=10.102.9.168"",\n            ""MY_RELEASE_JENKINS_AGENT_PORT_50000_TCP_PROTO=tcp"",\n            ""MY_RELEASE_JENKINS_AGENT_PORT_50000_TCP=tcp://10.102.9.168:50000"",\n']"
726,6309,6303,CC BY-SA 4.0,2019-02-08T16:46:08.173,"<p>So you can use two <a href=""https://docs.docker.com/develop/develop-images/multistage-build/"" rel=""nofollow noreferrer"">build stages</a> in your Dockerfile so you don't end up having unnecessary things inside container.  Anything from first stage is gone until you move it to second stage. Something like:</p>

<pre><code>FROM whatever as build-stage
WORKDIR /app
RUN apt-get update &amp;&amp; apt-get install -y unzip
RUN wget https://getcomposer.org/download/1.8.3/composer.phar
RUN php installer.php

FROM whatever as production-stage
COPY --from=build-stage /app ./
</code></pre>
",11764,2019-02-08T16:55:51.740,['FROM whatever as build-stage\nWORKDIR /app\nRUN apt-get update && apt-get install -y unzip\nRUN wget https://getcomposer.org/download/1.8.3/composer.phar\nRUN php installer.php\n\nFROM whatever as production-stage\nCOPY --from=build-stage /app ./\n']
727,6318,6317,CC BY-SA 4.0,2019-02-10T20:51:19.917,"<p>I didn't find a way to directly control this, but I noticed that the folder containing the docker-compose.yml is used as prefix when creating the name for the docker network. My solution was to write a wrapper script for docker-compose which creates a new folder with the name of the stage</p>

<pre><code>TARGET=/tmp/$STAGE_NAME

mkdir -p $TARGET

ln -sf $(pwd)/docker-compose.yml $TARGET/docker-compose.yml

cd $TARGET
docker-compose ""$@""
cd -
</code></pre>
",6726,2019-02-10T20:51:19.917,"['TARGET=/tmp/$STAGE_NAME\n\nmkdir -p $TARGET\n\nln -sf $(pwd)/docker-compose.yml $TARGET/docker-compose.yml\n\ncd $TARGET\ndocker-compose ""$@""\ncd -\n']"
728,6325,6231,CC BY-SA 4.0,2019-02-11T13:10:19.120,"<p>I also had this problem show up.  I think it's related to SSH.  I was writing a custom sshd_config.  Vagrant login's were slow after the first converge and verify was taking forever.  Removing the sshd_config stuff from my cookbook fixed the verify and slow logins.</p>

<p>Maybe it's not very helpful, but it's a place to start looking, anyway.  Short term, I hacked it together:</p>

<pre><code>unless ENV['TEST_KITCHEN']
  cookbook_file '/etc/ssh/sshd_config' do
    source 'sshd_config'
    mode '0644'
    notifies :restart, 'service[sshd]', :delayed
  end
end
</code></pre>

<p>Jye</p>
",12351,2019-02-11T13:10:19.120,"[""unless ENV['TEST_KITCHEN']\n  cookbook_file '/etc/ssh/sshd_config' do\n    source 'sshd_config'\n    mode '0644'\n    notifies :restart, 'service[sshd]', :delayed\n  end\nend\n""]"
729,6329,6323,CC BY-SA 4.0,2019-02-11T19:02:57.483,"<p>If you know what plugins are causing the issue, you can <a href=""https://jenkins.io/doc/book/managing/plugins/#install-with-cli"" rel=""nofollow noreferrer"">use the Jenkins CLI</a> to remove or downgrade those plugins.  For instance:</p>

<pre><code>java -jar jenkins-cli.jar -s http://localhost:8080/ install-plugin SOURCE ... [-deploy] [-name VAL] [-restart]

Installs a plugin either from a file, an URL, or from update center.

 SOURCE    : If this points to a local file, that file will be installed. If
             this is an URL, Jenkins downloads the URL and installs that as a
             plugin.Otherwise the name is assumed to be the short name of the
             plugin in the existing update center (like ""findbugs""),and the
             plugin will be installed from the update center.
 -deploy   : Deploy plugins right away without postponing them until the reboot.
 -name VAL : If specified, the plugin will be installed as this short name
             (whereas normally the name is inferred from the source name
             automatically).
 -restart  : Restart Jenkins upon successful installation.
</code></pre>

<p>I believe you can also just drop an .hpi file into a plugins directory in your Jenkins installation, but I've never needed to resort to this solution before, so I can't say how well it works.</p>
",4115,2019-02-11T19:02:57.483,"['java -jar jenkins-cli.jar -s http://localhost:8080/ install-plugin SOURCE ... [-deploy] [-name VAL] [-restart]\n\nInstalls a plugin either from a file, an URL, or from update center.\n\n SOURCE    : If this points to a local file, that file will be installed. If\n             this is an URL, Jenkins downloads the URL and installs that as a\n             plugin.Otherwise the name is assumed to be the short name of the\n             plugin in the existing update center (like ""findbugs""),and the\n             plugin will be installed from the update center.\n -deploy   : Deploy plugins right away without postponing them until the reboot.\n -name VAL : If specified, the plugin will be installed as this short name\n             (whereas normally the name is inferred from the source name\n             automatically).\n -restart  : Restart Jenkins upon successful installation.\n']"
730,6339,6317,CC BY-SA 4.0,2019-02-12T10:59:18.210,"<p>If you have <a href=""https://www.gnu.org/software/gettext/manual/html_node/envsubst-Invocation.html"" rel=""nofollow noreferrer""><code>envsubst</code></a> installed (part or gnu <code>gettext</code>) you can use something like that:</p>

<pre><code>export STAGE_NAME=""xyz""
export STAGE_NETWORK_PREFIX=""1.2.3.4""
docker-compose -f &lt;(envsubst docker-compose.yml) ...
</code></pre>

<p>If your shell does not support process substitution, something like that would do the trick:</p>

<pre><code>envsubst docker-compose.yml | docker-compose -f - ...
</code></pre>
",11179,2019-02-12T10:59:18.210,"['export STAGE_NAME=""xyz""\nexport STAGE_NETWORK_PREFIX=""1.2.3.4""\ndocker-compose -f <(envsubst docker-compose.yml) ...\n', 'envsubst docker-compose.yml | docker-compose -f - ...\n']"
731,6346,6344,CC BY-SA 4.0,2019-02-12T17:44:44.910,"<p>The simplest case is to use the Terraform Vault Provider (<a href=""https://www.terraform.io/docs/providers/vault/index.html"" rel=""nofollow noreferrer"">https://www.terraform.io/docs/providers/vault/index.html</a>) - which, caveat, I've not used myself. </p>

<p>Example from the Terraform site:</p>

<pre><code>provider ""vault"" {
  # It is strongly recommended to configure this provider through the
  # environment variables described above, so that each user can have
  # separate credentials set in the environment.
  #
  # This will default to using $VAULT_ADDR
  # But can be set explicitly
  # address = ""https://vault.example.net:8200""
}

resource ""vault_generic_secret"" ""example"" {
  path = ""secret/foo""

  data_json = &lt;&lt;EOT
{
  ""foo"":   ""bar"",
  ""pizza"": ""cheese""
}
EOT
}
</code></pre>

<p>Optionally you can write a script in whatever language you are comfortable with to make the call out to Vault and invoke via local-exec in Terraform. </p>

<p>Example of invoking a simple command from the Terraform site:</p>

<pre><code>resource ""aws_instance"" ""web"" {
  # ...

  provisioner ""local-exec"" {
    command = ""echo ${aws_instance.web.private_ip} &gt;&gt; private_ips.txt""
  }
}
</code></pre>
",9839,2019-02-12T17:44:44.910,"['provider ""vault"" {\n  # It is strongly recommended to configure this provider through the\n  # environment variables described above, so that each user can have\n  # separate credentials set in the environment.\n  #\n  # This will default to using $VAULT_ADDR\n  # But can be set explicitly\n  # address = ""https://vault.example.net:8200""\n}\n\nresource ""vault_generic_secret"" ""example"" {\n  path = ""secret/foo""\n\n  data_json = <<EOT\n{\n  ""foo"":   ""bar"",\n  ""pizza"": ""cheese""\n}\nEOT\n}\n', 'resource ""aws_instance"" ""web"" {\n  # ...\n\n  provisioner ""local-exec"" {\n    command = ""echo ${aws_instance.web.private_ip} >> private_ips.txt""\n  }\n}\n']"
732,6348,6347,CC BY-SA 4.0,2019-02-12T19:56:53.633,"<p>The <a href=""https://docs.docker.com/engine/reference/commandline/container_diff/"" rel=""nofollow noreferrer""><code>docker container diff</code></a> command shows the differences between a container and its base system.</p>

<p>In the output, files are reported as (A) if the file or directory was added, (D) if a file or directory was deleted or (C) if a file or directory was changed. File permission changes are reported as (C).</p>

<pre><code>she$ CID=$(sudo docker run --rm -d ubuntu sleep 500)
sh$ sudo docker exec $CID touch newfile
sh$ sudo docker exec $CID useradd bob
sh$ sudo docker exec $CID chmod o-x /usr/bin/cut
sh$ sudo docker diff $CID
C /etc
C /etc/group
A /etc/group-
C /etc/gshadow
A /etc/gshadow-
C /etc/passwd
A /etc/passwd-
C /etc/shadow
A /etc/shadow-
C /etc/subgid
A /etc/subgid-
C /etc/subuid
A /etc/subuid-
A /newfile
C /usr
C /usr/bin
C /usr/bin/cut
C /var
C /var/log
C /var/log/faillog
C /var/log/lastlog
C /var/log/tallylog
</code></pre>
",11179,2019-02-12T19:56:53.633,['she$ CID=$(sudo docker run --rm -d ubuntu sleep 500)\nsh$ sudo docker exec $CID touch newfile\nsh$ sudo docker exec $CID useradd bob\nsh$ sudo docker exec $CID chmod o-x /usr/bin/cut\nsh$ sudo docker diff $CID\nC /etc\nC /etc/group\nA /etc/group-\nC /etc/gshadow\nA /etc/gshadow-\nC /etc/passwd\nA /etc/passwd-\nC /etc/shadow\nA /etc/shadow-\nC /etc/subgid\nA /etc/subgid-\nC /etc/subuid\nA /etc/subuid-\nA /newfile\nC /usr\nC /usr/bin\nC /usr/bin/cut\nC /var\nC /var/log\nC /var/log/faillog\nC /var/log/lastlog\nC /var/log/tallylog\n']
733,6356,6349,CC BY-SA 4.0,2019-02-13T11:12:21.670,"<p>There was already a <a href=""https://stackoverflow.com/questions/21200304/docker-how-to-show-the-diffs-between-2-images"">stackoverflow question</a> about that topic, but the answers didn't really help me. The <a href=""https://github.com/GoogleContainerTools/container-diff"" rel=""nofollow noreferrer"">container-diff</a> tools was the most promising solution, but I would have preferred not relying on a third-party tool.</p>

<p>Finally, since docker can export an archive of a <em>container</em> filesystem, I end up with this solution:</p>

<pre><code>BASE_CID=$(sudo docker create ubuntu:18.04)
TARGET_CID=$(sudo docker create rogueimage:latest)

sudo docker export ""${BASE_CID}"" | tar tv &gt; base.filelist
sudo docker export ""${TARGET_CID}"" | tar tv &gt; target.filelist
</code></pre>

<p>Then using your favorite diff tool you can examine the difference:</p>

<pre><code>vimdiff {base,target}.filelist
</code></pre>
",11179,2019-02-13T11:12:21.670,"['BASE_CID=$(sudo docker create ubuntu:18.04)\nTARGET_CID=$(sudo docker create rogueimage:latest)\n\nsudo docker export ""${BASE_CID}"" | tar tv > base.filelist\nsudo docker export ""${TARGET_CID}"" | tar tv > target.filelist\n', 'vimdiff {base,target}.filelist\n']"
734,6358,6062,CC BY-SA 4.0,2019-02-13T15:53:06.710,"<p>I got this exact same error. I had to add the Audio Selectors. See the following JSON example:</p>

<pre><code>""Inputs"": [
  {
    ""AudioSelectors"": {
      ""Audio Selector 1"": {
        ""Offset"": 0,
        ""DefaultSelection"": ""DEFAULT"",
        ""SelectorType"": ""LANGUAGE_CODE"",
        ""ProgramSelection"": 1,
        ""LanguageCode"": ""ENM""
      }
    },
</code></pre>

<p>If you are using the Java SDK, add something similar to the following to your inputs:</p>

<pre><code>AudioSelector audioSelector = new AudioSelector()
            .withOffset(0)
            .withDefaultSelection(""DEFAULT"")
            .withLanguageCode(""ENM"")
            .withSelectorType(""LANGUAGE_CODE"")
            .withProgramSelection(1);

audioSelectors.put(""Audio Selector 1"", audioSelector);
</code></pre>
",12404,2019-02-13T15:53:06.710,"['""Inputs"": [\n  {\n    ""AudioSelectors"": {\n      ""Audio Selector 1"": {\n        ""Offset"": 0,\n        ""DefaultSelection"": ""DEFAULT"",\n        ""SelectorType"": ""LANGUAGE_CODE"",\n        ""ProgramSelection"": 1,\n        ""LanguageCode"": ""ENM""\n      }\n    },\n', 'AudioSelector audioSelector = new AudioSelector()\n            .withOffset(0)\n            .withDefaultSelection(""DEFAULT"")\n            .withLanguageCode(""ENM"")\n            .withSelectorType(""LANGUAGE_CODE"")\n            .withProgramSelection(1);\n\naudioSelectors.put(""Audio Selector 1"", audioSelector);\n']"
735,6371,6360,CC BY-SA 4.0,2019-02-14T18:12:50.533,"<p>From what I understand of <a href=""https://stackoverflow.com/questions/28734086/how-to-move-docker-containers-between-different-hosts"">https://stackoverflow.com/questions/28734086/how-to-move-docker-containers-between-different-hosts</a>, <code>docker export</code> will only save the container filesystem. But no metadata such as the default command, leading to that error when you try to run the imported archive:</p>

<pre><code>sh# IMAGE=$(docker import phpbb.tar)                                                                                                                                       
sh# docker run ""${IMAGE}""
docker: Error response from daemon: No command specified.
</code></pre>

<p><br>
Given my need, it is sufficient to <code>docker commit</code> the container to a new image, then <code>docker save</code> the image, and finally <code>docker load</code> and <code>docker run</code> it on the new host:</p>

<pre><code>old# docker commit CONTAINER name:tag
old# docker save name:tag |gzip &gt; archive.tar.gz
old# scp archive.tar.gz root@new:.
</code></pre>



<pre><code>new# docker load &lt; archive.tar.gz
new# docker run name:latest
</code></pre>

<p>It is important to save the image by repository <code>name:tag</code> and not by id to preserve the tag in the archive.</p>
",11179,2019-02-15T16:18:28.760,"['sh# IMAGE=$(docker import phpbb.tar)                                                                                                                                       \nsh# docker run ""${IMAGE}""\ndocker: Error response from daemon: No command specified.\n', 'old# docker commit CONTAINER name:tag\nold# docker save name:tag |gzip > archive.tar.gz\nold# scp archive.tar.gz root@new:.\n', 'new# docker load < archive.tar.gz\nnew# docker run name:latest\n']"
736,6391,6390,CC BY-SA 4.0,2019-02-16T15:24:04.267,"<p>Yes. And there are tools out there covering this piece of functionality. </p>

<p>Probably the most popular one is <a href=""https://kubernetes.io/"" rel=""nofollow noreferrer"">kubernetes</a> (see also <a href=""/questions/tagged/kubernetes"" class=""post-tag"" title=""show questions tagged &#39;kubernetes&#39;"" rel=""tag"">kubernetes</a>):</p>

<blockquote>
  <p><a href=""https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/"" rel=""nofollow noreferrer"">Kubernetes (k8s)</a> is an open-source system for automating
  deployment, scaling, and management of containerized applications.</p>
</blockquote>

<p>Depending on the provider for your deployment environment the actual orchestration tool/service may be already included and all you'd provide would be your desired scalability configuration. For example when deploying on the Google App Engine Flexible environment the <a href=""https://cloud.google.com/appengine/docs/flexible/python/reference/app-yaml#services"" rel=""nofollow noreferrer"">service scaling settings</a> could look like this:</p>

<blockquote>
<pre><code>automatic_scaling:
  min_num_instances: 1
  max_num_instances: 15
  cool_down_period_sec: 180
  cpu_utilization:
    target_utilization: 0.6
</code></pre>
</blockquote>
",47,2019-02-16T15:24:04.267,['automatic_scaling:\n  min_num_instances: 1\n  max_num_instances: 15\n  cool_down_period_sec: 180\n  cpu_utilization:\n    target_utilization: 0.6\n']
737,6396,5848,CC BY-SA 4.0,2019-02-17T14:20:40.143,"<p>I've been meaning to come back to this.
After consulting with AWS support it would seem that this is possible using some functions of the AWS CLI, that I was not aware of.</p>

<p>Specifically they recommended using 
<code>aws iam generate-service-last-accessed-details</code> and <code>aws iam get-service-last-accessed-details-with-entities</code>, and they referred me to <a href=""https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_access-advisor-view-data.html#access_policies_access-advisor-viewing-cli"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_access-advisor-view-data.html#access_policies_access-advisor-viewing-cli</a>.</p>

<p>For completion's sake here's how I used it:</p>

<pre>#! /bin/bash

ROLES=$(aws iam list-roles | jq -r .Roles[].Arn)
for ROLE in $ROLES
do 
    echo $ROLE
    JOBID=$(aws iam generate-service-last-accessed-details --arn $ROLE | jq -r .JobId)
    echo $JOBID
    NAMESPACES=$(aws iam get-service-last-accessed-details --job-id $JOBID | jq -r .ServicesLastAccessed[].ServiceNamespace)
    for NAMESPACE in $NAMESPACES
    do  
        echo $NAMESPACE
        aws iam get-service-last-accessed-details-with-entities --job-id $JOBID --service-namespace $NAMESPACE | jq '.JobCompletionDate,.EntityDetailsList[].EntityInfo.Name,.EntityDetailsList[].EntityInfo.Id'
    done    
done </pre>
",9308,2019-02-17T14:20:40.143,"[""#! /bin/bash\n\nROLES=$(aws iam list-roles | jq -r .Roles[].Arn)\nfor ROLE in $ROLES\ndo \n    echo $ROLE\n    JOBID=$(aws iam generate-service-last-accessed-details --arn $ROLE | jq -r .JobId)\n    echo $JOBID\n    NAMESPACES=$(aws iam get-service-last-accessed-details --job-id $JOBID | jq -r .ServicesLastAccessed[].ServiceNamespace)\n    for NAMESPACE in $NAMESPACES\n    do  \n        echo $NAMESPACE\n        aws iam get-service-last-accessed-details-with-entities --job-id $JOBID --service-namespace $NAMESPACE | jq '.JobCompletionDate,.EntityDetailsList[].EntityInfo.Name,.EntityDetailsList[].EntityInfo.Id'\n    done    \ndone ""]"
738,6409,2468,CC BY-SA 4.0,2019-02-19T03:24:24.977,"<p>you can use the feature of port-forward using kubectl,</p>

<pre><code>Examples:
  # Listen on ports 5000 and 6000 locally, forwarding data to/from ports 5000 and 6000 in the pod
  kubectl port-forward pod/mypod 5000 6000

  # Listen on ports 5000 and 6000 locally, forwarding data to/from ports 5000 and 6000 in a pod selected by the
deployment
  kubectl port-forward deployment/mydeployment 5000 6000

  # Listen on port 8888 locally, forwarding to 5000 in the pod
  kubectl port-forward pod/mypod 8888:5000

  # Listen on a random port locally, forwarding to 5000 in the pod
  kubectl port-forward pod/mypod :5000 
</code></pre>

<p>But if you want to expose your pod, so that other pods can communicate to it, use services. 
<a href=""https://kubernetes.io/docs/concepts/services-networking/service/"" rel=""nofollow noreferrer"">K8s service</a></p>
",12489,2019-02-19T03:24:24.977,"['Examples:\n  # Listen on ports 5000 and 6000 locally, forwarding data to/from ports 5000 and 6000 in the pod\n  kubectl port-forward pod/mypod 5000 6000\n\n  # Listen on ports 5000 and 6000 locally, forwarding data to/from ports 5000 and 6000 in a pod selected by the\ndeployment\n  kubectl port-forward deployment/mydeployment 5000 6000\n\n  # Listen on port 8888 locally, forwarding to 5000 in the pod\n  kubectl port-forward pod/mypod 8888:5000\n\n  # Listen on a random port locally, forwarding to 5000 in the pod\n  kubectl port-forward pod/mypod :5000 \n']"
739,6414,6393,CC BY-SA 4.0,2019-02-19T16:45:58.420,"<p>I have <a href=""https://github.com/simbo1905/microservices-demo-ansible"" rel=""nofollow noreferrer"">created a demo with a role</a> that can install many springboot microservices on a fleet of VMs where you name a subset of the VMs where you want to place each service. The playbook can then run on all hosts, compute whether each service should be on each host, and will either run the install.yaml or uninstall.yml tasks. </p>

<p>To install two of the same microservices with different runtime args you play something like:</p>

<pre>
roles:
    - {
      role: ""ansible-role-springboot"",
      sb_app_name: ""microservices-registration"",
      sb_app_group_id: ""org.springframework.samples.service.service"",
      sb_app_artifact_id: ""microservices-demo"",
      sb_app_version: ""2.0.0.RELEASE"",
      sb_app_run_args: '""registration 8082""',
      sb_app_healthcheck_urls: [
        ""http://localhost:8082/actuator/health""
      ],
      <b>sb_hosts: [
        ""my-test-vm""
      ]</b>
    }
    - {
      role: ""ansible-role-springboot"",
      sb_app_name: ""microservices-web"",
      sb_app_group_id: ""org.springframework.samples.service.service"",
      sb_app_artifact_id: ""microservices-demo"",
      sb_app_version: ""2.0.1.RELEASE"",
      sb_app_run_args: '""web 8083""',
      sb_app_healthcheck_urls: [
        ""http://localhost:8083/actuator/health""
      ],
      <b>sb_hosts: [
        ""my-test-vm""
      ]</b>
    }
</pre>

<p>The role is based upon <a href=""https://github.com/orachide/ansible-role-springboot"" rel=""nofollow noreferrer"">orachide/ansible-role-springboot</a> which seems very comprehensive. The new bit is in bold which is simply a list of host that should run the microservice. </p>

<p>Normally we would expect to use different artefact ids and versions each time we apply the role. In the example above, it is running an official <a href=""https://github.com/simbo1905/microservices-demo"" rel=""nofollow noreferrer"">springboot microservices mega jar</a> that takes different <code>RUN_AS</code> args to run as different services. That seems a bit odd and not something I would recommend yet the role is agnostic to such details. </p>

<p>What thing that the original role requires is that you use an executable jar file: </p>

<pre><code>        &lt;plugin&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;configuration&gt;
                &lt;executable&gt;true&lt;/executable&gt;
            &lt;/configuration&gt;
        &lt;/plugin&gt;
</code></pre>

<p>It role will create a symlink to that executable and create an environment files to run it and all that good stuff. </p>

<p>The modifications that I made were quite simple as the original role has logic to install or uninstall based on <code>sb_app_state</code>:</p>

<pre><code>- import_tasks: install.yml
  when: &gt;
        sb_app_state == 'present'

- import_tasks: uninstall.yml
  when: &gt;
        sb_app_state == 'absent'
</code></pre>

<p>So it was simply a matter of adding some logic to check whether the current hostname is in the <code>sb_hosts</code> list then update the value of <code>sb_app_state</code> as appropriate. That is done <a href=""https://github.com/simbo1905/microservices-demo-ansible/blob/cfca2542694633356bab9abb8f01bf818fcc8e99/roles/ansible-role-springboot/tasks/main.yml#L9"" rel=""nofollow noreferrer"">with a single line change</a>. </p>

<p>The demo codebase uses test kitchen ansible with testinfra to unit test that the playbook works. Getting that working was well worth the effort to do automated acceptance tests of the playbook logic. </p>
",10599,2019-02-20T06:42:07.087,"['\nroles:\n    - {\n      role: ""ansible-role-springboot"",\n      sb_app_name: ""microservices-registration"",\n      sb_app_group_id: ""org.springframework.samples.service.service"",\n      sb_app_artifact_id: ""microservices-demo"",\n      sb_app_version: ""2.0.0.RELEASE"",\n      sb_app_run_args: \'""registration 8082""\',\n      sb_app_healthcheck_urls: [\n        ""http://localhost:8082/actuator/health""\n      ],\n      sb_hosts: [\n        ""my-test-vm""\n      ]\n    }\n    - {\n      role: ""ansible-role-springboot"",\n      sb_app_name: ""microservices-web"",\n      sb_app_group_id: ""org.springframework.samples.service.service"",\n      sb_app_artifact_id: ""microservices-demo"",\n      sb_app_version: ""2.0.1.RELEASE"",\n      sb_app_run_args: \'""web 8083""\',\n      sb_app_healthcheck_urls: [\n        ""http://localhost:8083/actuator/health""\n      ],\n      sb_hosts: [\n        ""my-test-vm""\n      ]\n    }\n', '        <plugin>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n            <configuration>\n                <executable>true</executable>\n            </configuration>\n        </plugin>\n', ""- import_tasks: install.yml\n  when: >\n        sb_app_state == 'present'\n\n- import_tasks: uninstall.yml\n  when: >\n        sb_app_state == 'absent'\n""]"
740,6422,6421,CC BY-SA 4.0,2019-02-20T06:30:48.540,"<p>There is <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_module_defaults.html"" rel=""nofollow noreferrer"">module_defaults</a> playbook-level option:</p>

<pre><code>- hosts: localhost
  module_defaults:
    file:
      owner: root
      group: root
      mode: 0755
  tasks:
    - file:
        state: touch
        path: /tmp/file1
    - file:
        state: touch
        path: /tmp/file2
</code></pre>
",3509,2019-02-20T07:18:22.773,['- hosts: localhost\n  module_defaults:\n    file:\n      owner: root\n      group: root\n      mode: 0755\n  tasks:\n    - file:\n        state: touch\n        path: /tmp/file1\n    - file:\n        state: touch\n        path: /tmp/file2\n']
741,6423,6404,CC BY-SA 4.0,2019-02-20T08:08:24.997,"<p>A simple way would be to do: </p>

<pre><code>ansible -i &lt;inventory&gt; &lt;target group, lets' say some CentOS systems&gt; -m shell -a ""rpm -qa | grep &lt;package name&gt;""
</code></pre>

<p>That would display a list consisting of server name and package version.</p>
",775,2019-02-20T08:08:24.997,"['ansible -i <inventory> <target group, lets\' say some CentOS systems> -m shell -a ""rpm -qa | grep <package name>""\n']"
742,6435,6431,CC BY-SA 4.0,2019-02-21T15:27:56.347,"<p>Option <code>--rm</code> tells Docker explicitly to remove the container after the (main) command finished. Just leave it out.</p>

<p>Note that none of <a href=""https://github.com/anshumanbh/git-all-secrets#scanning-an-organization-team"" rel=""nofollow noreferrer"">the examples</a> contain this option; they only use it for <code>-help</code>.</p>

<p>As an alternative (which lets you keep <code>--rm</code>), you can tell Docker to <a href=""https://docs.docker.com/storage/volumes/"" rel=""nofollow noreferrer"">mount a volume</a> at <code>/root</code>. Volumes persist after the containers mounting them go away, so you can access the data written there. However, for your purposes here, a simple <a href=""https://docs.docker.com/storage/bind-mounts/"" rel=""nofollow noreferrer"">bind mount</a> is quite enough; add</p>

<pre><code>-v .:/root
</code></pre>

<p>to have it write the output file to the current (host) directory. You may have to adjust this if <code>/root</code> is used heavily; you probably want to use a previously empty directory on both sides.</p>
",12543,2019-02-21T19:14:06.690,['-v .:/root\n']
743,6455,6454,CC BY-SA 4.0,2019-02-24T16:49:44.370,"<p>Note: answer based only on docs, I didn't play with docker much.</p>

<p>If you choose scripting you could pick a higher layer than just <code>ps</code>, based on either:</p>

<ul>
<li>the <a href=""https://docs.docker.com/compose/reference/events/"" rel=""nofollow noreferrer""><code>docker-compose events</code></a> CLI:</li>
</ul>

<blockquote>
<pre><code>Usage: events [options] [SERVICE...]

Options:
    --json      Output events as a stream of json objects
</code></pre>
  
  <p>Stream container events for every container in the project.</p>
</blockquote>

<ul>
<li>the <a href=""https://docs.docker.com/engine/reference/commandline/events/"" rel=""nofollow noreferrer""><code>docker events</code></a> CLI:</li>
</ul>

<blockquote>
  <p><strong>Description</strong> </p>
  
  <p>Get real time events from the server</p>
</blockquote>

<p>You'd be looking for the <code>die</code> event of the container(from <a href=""https://docs.docker.com/engine/reference/commandline/#object-types"" rel=""nofollow noreferrer"">Extended description</a>):</p>

<blockquote>
  <p>Use <code>docker events</code> to get real-time events from the server. These
  events differ per Docker object type.</p>
  
  <p><strong>Object types</strong></p>
  
  <p>CONTAINERS</p>
  
  <ul>
  <li><code>die</code></li>
  </ul>
</blockquote>

<p>The event appears to be generated regardless of the restart policy (from <a href=""https://gliderlabs.com/devlog/2015/docker-events-explained/"" rel=""nofollow noreferrer"">Docker Events Explained</a>):</p>

<p><a href=""https://i.stack.imgur.com/6vYMW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6vYMW.png"" alt=""enter image description here""></a></p>

<p>But you're right, there's <a href=""https://www.google.com/search?q=docker%20monitor%20container"" rel=""nofollow noreferrer"">a ton of monitoring tools</a> out there, I also suspect some already do what you're seeking.</p>

<p>Just aimlessly wandering through those links I got to <a href=""https://scoutapp.com/blog/monitoring-docker-events"" rel=""nofollow noreferrer"">Implementing Docker event monitoring from scratch</a>:</p>

<blockquote>
  <p>What else? <strong>I can create alerts on them</strong>. The next time any of my
  containers decide to puke and die, I can get an SMS message about
  their doomed state.</p>
</blockquote>
",47,2019-02-24T16:59:28.927,['Usage: events [options] [SERVICE...]\n\nOptions:\n    --json      Output events as a stream of json objects\n']
744,6461,6431,CC BY-SA 4.0,2019-02-25T11:26:53.483,"<p>I don't know about <code>git-all-secret</code> specifically, but from what I understand you are trying to capture the output produced by that tool. Since docker maps by default the standard output of a container to the standard output of the client <code>docker</code> command, you may achieve the desired result using something like that (untested):</p>

<pre><code>sudo docker run --rm -it abhartiya/tools_gitallsecrets -org $org \
     -output /dev/stdout \
     -thogEntropy -token $githubtoken \
 &gt; ./output.txt
</code></pre>

<p>Many tools allow <code>-</code> as a synonym for /dev/stdout, so this might work:</p>

<pre><code>sudo docker run --rm -it abhartiya/tools_gitallsecrets -org $org \
     -output - \
     -thogEntropy -token $githubtoken \
 &gt; ./output.txt
</code></pre>
",11179,2019-02-25T11:26:53.483,"['sudo docker run --rm -it abhartiya/tools_gitallsecrets -org $org \\\n     -output /dev/stdout \\\n     -thogEntropy -token $githubtoken \\\n > ./output.txt\n', 'sudo docker run --rm -it abhartiya/tools_gitallsecrets -org $org \\\n     -output - \\\n     -thogEntropy -token $githubtoken \\\n > ./output.txt\n']"
745,6469,6465,CC BY-SA 4.0,2019-02-25T22:01:52.733,"<p>You need to use double quotes instead of single quotes.  Single-quoted strings don't perform string interpolation.</p>

<p>For instance:</p>

<pre><code>parameters {
    string(
        name: 'DEPLOY_BUILD_NUMBER',
        defaultValue: ""${BUILD_NUMBER}"",
        description: 'Fresh Build and Deploy OR Deploy Previous Build Number'
    )
}
</code></pre>
",4115,2019-02-25T22:01:52.733,"['parameters {\n    string(\n        name: \'DEPLOY_BUILD_NUMBER\',\n        defaultValue: ""${BUILD_NUMBER}"",\n        description: \'Fresh Build and Deploy OR Deploy Previous Build Number\'\n    )\n}\n']"
746,6475,3284,CC BY-SA 4.0,2019-02-26T05:08:14.583,"<blockquote>
  <p>solutions is: <strong>OpenConnect Plugin</strong> </p>
</blockquote>

<p>See here: <a href=""https://wiki.jenkins.io/display/JENKINS/OpenConnect+Plugin"" rel=""nofollow noreferrer"">https://wiki.jenkins.io/display/JENKINS/OpenConnect+Plugin</a></p>

<p>OR also you can use below method:</p>

<p>On Linux (Debian based)</p>

<pre><code>sudo apt-get install openconnect
</code></pre>

<p>Add the following lines to the bottom of /etc/sudoers (ubuntu configuration)</p>

<pre><code>jenkins ALL=NOPASSWD:/usr/sbin/openconnect*
jenkins ALL=NOPASSWD:/bin/kill*
</code></pre>

<p>Then you will get an option in the Jenkins run task called:</p>

<pre><code>Connect to Cisco AnyConnect VPN
</code></pre>
",11598,2019-02-26T05:08:14.583,"['sudo apt-get install openconnect\n', 'jenkins ALL=NOPASSWD:/usr/sbin/openconnect*\njenkins ALL=NOPASSWD:/bin/kill*\n', 'Connect to Cisco AnyConnect VPN\n']"
747,6485,6484,CC BY-SA 4.0,2019-02-26T15:04:14.870,"<p>OK. The answer was simple. I needed to template the item.path. I guess this is a beginner mistake.</p>
<pre><code>- hosts: localhost
  tasks:
    - name: Find ini files
      find:
        paths: /home/myuser/projects/infra/php
        file_type: file
        recurse: Yes
        patterns: &quot;*php.ini&quot;
      register: files_matched

    - name: Debug files_matched
      debug:
        var: files_matched.files

    - name: Debug files_matched loop
      debug:
        var: item.path
      loop: &quot;{{ files_matched.files|flatten(levels=1) }}&quot;
      loop_control:
        label: &quot;{{ item.path }}&quot;

    - name: Ensure &quot;sendmail_path=/opt/mailhog/mhsendmail is in section &quot;[mail function]&quot;
      ini_file:
        path: &quot;{{ item.path }}&quot;
        section: &quot;mail function&quot;
        option: sendmail_path
        value: /opt/mailhog/mhsendmail
        mode: 0644
        backup: no
      loop: &quot;{{ files_matched.files|flatten(levels=1) }}&quot;
      loop_control:
        label: &quot;{{ item.path }}&quot;
</code></pre>
",12635,2020-12-17T14:28:08.603,"['- hosts: localhost\n  tasks:\n    - name: Find ini files\n      find:\n        paths: /home/myuser/projects/infra/php\n        file_type: file\n        recurse: Yes\n        patterns: ""*php.ini""\n      register: files_matched\n\n    - name: Debug files_matched\n      debug:\n        var: files_matched.files\n\n    - name: Debug files_matched loop\n      debug:\n        var: item.path\n      loop: ""{{ files_matched.files|flatten(levels=1) }}""\n      loop_control:\n        label: ""{{ item.path }}""\n\n    - name: Ensure ""sendmail_path=/opt/mailhog/mhsendmail is in section ""[mail function]""\n      ini_file:\n        path: ""{{ item.path }}""\n        section: ""mail function""\n        option: sendmail_path\n        value: /opt/mailhog/mhsendmail\n        mode: 0644\n        backup: no\n      loop: ""{{ files_matched.files|flatten(levels=1) }}""\n      loop_control:\n        label: ""{{ item.path }}""\n']"
748,6497,4693,CC BY-SA 4.0,2019-02-28T13:16:39.100,"<p>It seems to me that your Dockerfile should be looking like this:</p>

<pre><code>FROM ~~container_on_private_registry~~
USER root
WORKDIR /root
ARG jenkins_jar_file=jenkins.jar
ENV jenkins_jar_file ${jenkins_jar_file}
RUN mkdir -p /root/app
COPY ${jenkins_jar_file} /root/app/app.jar
ENTRYPOINT [""java"", ""-jar"", ""/root/app/app.jar""]
</code></pre>

<p><strong>Explanation:</strong></p>

<p>We tell the Dockerfile to let Docker know, that it expects a variable named jenkins_jar_file to be passed to it during the build. Subsequent lines can reference that variable with a dollar notation.</p>

<p>Also when you build the image, use --no-cache so it will re-build all the layers of the image.</p>
",12614,2019-02-28T13:16:39.100,"['FROM ~~container_on_private_registry~~\nUSER root\nWORKDIR /root\nARG jenkins_jar_file=jenkins.jar\nENV jenkins_jar_file ${jenkins_jar_file}\nRUN mkdir -p /root/app\nCOPY ${jenkins_jar_file} /root/app/app.jar\nENTRYPOINT [""java"", ""-jar"", ""/root/app/app.jar""]\n']"
749,6498,6130,CC BY-SA 4.0,2019-02-28T14:27:21.647,"<p><code>docker build</code> <em>does</em> output the image ID:</p>

<pre><code>Successfully built 6fd2b9d56348
Successfully tagged foo:latest
</code></pre>

<p>Unfortunately, it doesn't seem like the <a href=""https://github.com/jenkinsci/docker-build-step-plugin"" rel=""nofollow noreferrer"">Docker Build Step plugin</a> exposes it to the pipeline (it <em>does</em> write it to the log!). You may want to open an issue with that project.</p>

<p>That said, <code>docker tag</code> itself accepts <code>name:tag</code>:</p>

<pre><code>$ docker help tag
Usage:  docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]
</code></pre>

<p>Since you (can) choose image name and first tag for <code>docker build</code>, try using those to identify the built image instead of its ID. If that doesn't work with the plugin, you may need a feature request after all.</p>

<p>As a workaround, you can always use <code>sh script: 'docker ...'</code> directly.</p>
",12543,2019-02-28T14:27:21.647,"['Successfully built 6fd2b9d56348\nSuccessfully tagged foo:latest\n', '$ docker help tag\nUsage:  docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]\n']"
750,6506,3947,CC BY-SA 4.0,2019-03-01T16:04:15.567,"<p>use the condition</p>

<pre><code>- when: variable is defined
  run_module_when_defined:
</code></pre>

<p>or </p>

<pre><code>- name:
  block:
    - task1
    - task2
  when: variable is defined
</code></pre>
",8858,2019-03-01T16:04:15.567,"['- when: variable is defined\n  run_module_when_defined:\n', '- name:\n  block:\n    - task1\n    - task2\n  when: variable is defined\n']"
751,6521,6519,CC BY-SA 4.0,2019-03-03T10:26:59.300,"<p><a href=""https://devops.stackexchange.com/users/12708/ibuildthecloud"">ibuildthecloud9</a> gave me the right hint. Since the github issue doesn't describe how to midify the dns, I figured it out and want to document it here in case someone need to change it, too. It's stored in the configmap <code>coredns</code> as <code>Corefile</code>:</p>

<pre><code>proxy . 1.1.1.1
</code></pre>

<p>You need to replace this by your dns server (192.168.0.19 in my case). It could be done manually using <code>kubectl edit cm -n kube-system coredns</code>. In case you also want to automate this process: </p>

<pre><code>kubectl get cm -n kube-system coredns -o yaml | sed ""s/proxy . 1.1.1.1/proxy . 192.168.0.19/g"" &gt; coredns-fixed.yml
</code></pre>

<p>Now you'll have the fixed yaml file, which got loaded by </p>

<pre><code>kubectl apply -f coredns-fixed.yml
</code></pre>

<h2>Test it</h2>

<p>Create <code>busybox.yml</code></p>

<pre><code>apiVersion: v1
kind: Pod
metadata:
    name: busybox
spec:
    containers:
    # for arm
    #- image: hypriot/armhf-busybox
    - image: busybox
      command:
          - sleep
          - ""3600""
      imagePullPolicy: IfNotPresent
      name: busybox
    restartPolicy: Always
</code></pre>

<p>Create the pod: <code>kubectl create -f busybox.yml</code>
And try to ping a host resolved by your dns: </p>

<pre><code>~$ kubectl exec -it busybox -- ping -c1 server2.fritz.box
PING server2.fritz.box (192.168.0.37): 56 data bytes
64 bytes from 192.168.0.37: seq=0 ttl=61 time=0.386 ms
</code></pre>

<p><strong>Before</strong> applying our dns (so 1.1.1.1 was used, which belongs to Cloudflare) this throws the following resolving error: </p>

<pre><code>*~$ kubectl exec -it busybox -- ping -c1 server2.fritz.box
ping: bad address 'server2.fritz.box'*
</code></pre>
",6923,2019-03-03T10:26:59.300,"['proxy . 1.1.1.1\n', 'kubectl get cm -n kube-system coredns -o yaml | sed ""s/proxy . 1.1.1.1/proxy . 192.168.0.19/g"" > coredns-fixed.yml\n', 'kubectl apply -f coredns-fixed.yml\n', 'apiVersion: v1\nkind: Pod\nmetadata:\n    name: busybox\nspec:\n    containers:\n    # for arm\n    #- image: hypriot/armhf-busybox\n    - image: busybox\n      command:\n          - sleep\n          - ""3600""\n      imagePullPolicy: IfNotPresent\n      name: busybox\n    restartPolicy: Always\n', '~$ kubectl exec -it busybox -- ping -c1 server2.fritz.box\nPING server2.fritz.box (192.168.0.37): 56 data bytes\n64 bytes from 192.168.0.37: seq=0 ttl=61 time=0.386 ms\n', ""*~$ kubectl exec -it busybox -- ping -c1 server2.fritz.box\nping: bad address 'server2.fritz.box'*\n""]"
752,6530,6510,CC BY-SA 4.0,2019-03-04T18:46:34.720,"<p>Yes, <strong>Resource</strong> is a required element on S3 bucket policies. If the resource is omitted, the API will respond with an error resembling this one below.</p>

<pre><code>status code: 400
Error putting S3 policy: MalformedPolicy: Statement is missing required element
</code></pre>

<p>The reasoning is that each statement could apply to the bucket itself, the contents of the bucket, or some subset of the bucket contents, and it's up to the user to clarify. In theory AWS could provide a default that includes both the bucket and all of its contents, but that design probably wasn't chosen because it makes it too easy to accidentally make the bucket policies broader than expected.</p>

<p>Additionally, it is <strong>not permissible</strong> to use a wildcard in the resource element of an S3 bucket policy. Attempts to do so will yield an error such as this:</p>

<pre><code>Error putting S3 policy: MalformedPolicy: Policy has invalid resource
</code></pre>
",7770,2019-03-04T18:52:01.400,"['status code: 400\nError putting S3 policy: MalformedPolicy: Statement is missing required element\n', 'Error putting S3 policy: MalformedPolicy: Policy has invalid resource\n']"
753,6534,5279,CC BY-SA 4.0,2019-03-05T20:58:30.790,"<p>I set credential globally in declarative pipeline like this and then my Jenkins could talk with Google Dataflow in all stages.  For example, I used a secret file (google service account). </p>

<pre>
<code>
pipeline {
    agent any
    environment {
        //Secret File ID was defined in Jenkins -> Credentials -> System -> Global credentials
        GOOGLE_APPLICATION_CREDENTIALS = credentials('mySecretFileId')

        GCP_PROJECT_NAME = 'myProject'
    }
   stages {
             stage('step 1') {
              steps {
                sh ""gcloud auth activate-service-account --key-file ${env.GOOGLE_APPLICATION_CREDENTIALS}""
                sh ""gcloud config set project ${env.GCP_PROJECT_NAME}""

                // access google dataflow
                sh ""gcloud dataflow jobs list --status=active""
                // ....
              }
             }
             stage('stage 2') {
               steps {
                  // access google dataflow
                  sh ""gcloud dataflow jobs list --status=active""
               }
             }
             //...
   }
}   

</code>
</pre>
",12743,2019-03-05T20:58:30.790,"['\n\npipeline {\n    agent any\n    environment {\n        //Secret File ID was defined in Jenkins -> Credentials -> System -> Global credentials\n        GOOGLE_APPLICATION_CREDENTIALS = credentials(\'mySecretFileId\')\n\n        GCP_PROJECT_NAME = \'myProject\'\n    }\n   stages {\n             stage(\'step 1\') {\n              steps {\n                sh ""gcloud auth activate-service-account --key-file ${env.GOOGLE_APPLICATION_CREDENTIALS}""\n                sh ""gcloud config set project ${env.GCP_PROJECT_NAME}""\n\n                // access google dataflow\n                sh ""gcloud dataflow jobs list --status=active""\n                // ....\n              }\n             }\n             stage(\'stage 2\') {\n               steps {\n                  // access google dataflow\n                  sh ""gcloud dataflow jobs list --status=active""\n               }\n             }\n             //...\n   }\n}   \n\n\n']"
754,6547,3902,CC BY-SA 4.0,2019-03-07T13:05:51.817,"<p>There is another option only using pipe:</p>

<pre><code>docker run -d -i --name $n alpine sh -c 'read A; echo ""[$A]""; exec some-server'
docker exec -i $n sh -c 'cat &gt; /proc/1/fd/0' &lt;&lt;&lt; _a_secret_
</code></pre>

<p>First, create the docker daemon with <code>-i</code>, the command <code>read A</code> will hang waiting for the input from <code>/proc/1/fd/0</code>;
Then run the second docker command, reading the secret from stdin and redirect to the last hanging process.</p>
",12774,2019-03-07T13:05:51.817,"['docker run -d -i --name $n alpine sh -c \'read A; echo ""[$A]""; exec some-server\'\ndocker exec -i $n sh -c \'cat > /proc/1/fd/0\' <<< _a_secret_\n']"
755,6551,6533,CC BY-SA 4.0,2019-03-07T14:43:09.170,"<p>After some more research I found the answer:</p>

<pre><code>  def coreImageTags = input(
    id: 'coreImageTags', message: 'Enter a comma separated list of additional tags for the image (0.0.1,some-tagname,etc):?', 
    parameters: [
      [$class: 'StringParameterDefinition', defaultValue: 'None', description: 'List of tags', name: 'coreImageTagsList'],
    ]
  )

  echo (""Image tags: ""+coreImageTags)
</code></pre>

<p><strong>Important note</strong></p>

<p>It is stated in the documentation but I want to point it out specifically: If you copy/paste my solution here, <code>coreImageTags</code> will contain a string directly. If you do multiple parameters like so:</p>

<pre><code>    parameters: [
      [$class: 'StringParameterDefinition', defaultValue: 'None', description: 'List of tags', name: 'coreImageTagsList'],
      [$class: 'StringParameterDefinition', defaultValue: 'None', description: 'Something else', name: 'somethingElse'],
    ]
</code></pre>

<p>You will not get a single values but an array of values:</p>

<pre><code>  echo (""Image tags: ""+coreImageTags['coreImageTagsList'])
  echo (""Image tags: ""+coreImageTags['somethingElse'])
</code></pre>

<p>The following posts will help:</p>

<p><a href=""https://stackoverflow.com/questions/47080683/read-interactive-input-in-jenkins-pipeline-to-a-variable"">stackoverflow.com read-interactive-input-in-jenkins-pipeline-to-a-variable</a></p>

<p><a href=""https://support.cloudbees.com/hc/en-us/articles/204986450-Pipeline-How-to-manage-user-inputs"" rel=""nofollow noreferrer"">CloudBees - Pipeline-How-to-manage-user-inputs</a></p>

<p>A list of classes you can use in this way and what they do is in the Jenkins Input-Step documentation:
<a href=""https://jenkins.io/doc/pipeline/steps/pipeline-input-step/"" rel=""nofollow noreferrer"">Pipeline - Input Step</a></p>
",7646,2019-03-07T14:43:09.170,"['  def coreImageTags = input(\n    id: \'coreImageTags\', message: \'Enter a comma separated list of additional tags for the image (0.0.1,some-tagname,etc):?\', \n    parameters: [\n      [$class: \'StringParameterDefinition\', defaultValue: \'None\', description: \'List of tags\', name: \'coreImageTagsList\'],\n    ]\n  )\n\n  echo (""Image tags: ""+coreImageTags)\n', ""    parameters: [\n      [$class: 'StringParameterDefinition', defaultValue: 'None', description: 'List of tags', name: 'coreImageTagsList'],\n      [$class: 'StringParameterDefinition', defaultValue: 'None', description: 'Something else', name: 'somethingElse'],\n    ]\n"", '  echo (""Image tags: ""+coreImageTags[\'coreImageTagsList\'])\n  echo (""Image tags: ""+coreImageTags[\'somethingElse\'])\n']"
756,6560,6552,CC BY-SA 4.0,2019-03-09T07:35:35.267,"<p>From the <a href=""https://jenkins.io/doc/book/pipeline/docker/#building-containers"" rel=""nofollow noreferrer"">official instructions on building Docker images with Jenkins Pipeline</a>:</p>

<blockquote>
  <p>The <code>build()</code> method builds the <code>Dockerfile</code> in the current directory
  by default. This can be overridden by providing a directory path
  containing a <code>Dockerfile</code> as the second argument of the <code>build()</code>
  method, for example:</p>

<pre><code>node {
    checkout scm
    def testImage = docker.build(""test-image"", ""./dockerfiles/test"") 

    testImage.inside {
        sh 'make test'
    }
}
</code></pre>
</blockquote>

<p>I'm not sure if you can create a Pipeline (i.e. Jenkinsfile) with this exact configuration through the Blue Ocean UI, but I would imagine you can.  However, I personally have found using Blue Ocean to create pipelines to be finicky at best, so I would recommend going over a Jenkinsfile created by Blue Ocean and making tweaks and adjustments by hand anyway.  This would give you the opportunity to adjust the Dockerfile location even if you aren't able to do it via Blue Ocean.</p>
",4115,2019-03-09T07:35:35.267,"['node {\n    checkout scm\n    def testImage = docker.build(""test-image"", ""./dockerfiles/test"") \n\n    testImage.inside {\n        sh \'make test\'\n    }\n}\n']"
757,6571,2558,CC BY-SA 4.0,2019-03-10T15:45:58.847,"<p>We're using CircleCI with <strong>Go</strong> monorepo.</p>

<p>Here’s how it’s done: </p>

<ol>
<li>Define a job for each service in circle config yaml. </li>
<li>A git push triggers CircleCI job that finds which services are part of the change.</li>
<li>For each service run a CircleCI job with:</li>
</ol>

<pre><code>{
  ""build_parameters"": {
      ""CIRCLE_JOB"": ""my-service""
  }
}
</code></pre>

<p>Also, published as an open source: <a href=""https://github.com/Tufin/circleci-monorepo"" rel=""nofollow noreferrer"">https://github.com/Tufin/circleci-monorepo</a></p>
",12823,2019-03-10T15:45:58.847,"['{\n  ""build_parameters"": {\n      ""CIRCLE_JOB"": ""my-service""\n  }\n}\n']"
758,6575,6568,CC BY-SA 4.0,2019-03-11T10:21:13.973,"<p>Docker registry credentials is seting up in <a href=""https://www.terraform.io/docs/providers/docker/index.html#registry-credentials"" rel=""nofollow noreferrer"">provider configuration</a>.</p>

<pre><code>provider ""docker"" {
  registry_auth {
    address = ""quay.io:8181""
    username = ""someuser""
    password = ""somepass""
  } 
}
</code></pre>

<p>Also possible to set env variables DOCKER_REGISTRY_USER and DOCKER_REGISTRY_PASS</p>
",12833,2019-03-11T10:21:13.973,"['provider ""docker"" {\n  registry_auth {\n    address = ""quay.io:8181""\n    username = ""someuser""\n    password = ""somepass""\n  } \n}\n']"
759,6581,6580,CC BY-SA 4.0,2019-03-11T23:44:36.910,"<p>You will notice in this upstream block:</p>

<pre><code>upstream api {
    server server:5000;
}
</code></pre>

<p>I called it <code>api</code> but then I say <code>server server:5000;</code>. That was the problem because I originally had it as:</p>

<pre><code>upstream server {
    server server:5000;
}
</code></pre>

<p>but then thought that <code>server</code> might be a reserved operator in the Nginx world so I changed it to <code>api</code> but did not change it inside the block.</p>

<p>So it should have been:</p>

<pre><code>upstream api {
    server api:5000;
}
</code></pre>

<p>After changing it, the xhr pending and timing out 502 errors went away.</p>
",6282,2019-03-11T23:44:36.910,"['upstream api {\n    server server:5000;\n}\n', 'upstream server {\n    server server:5000;\n}\n', 'upstream api {\n    server api:5000;\n}\n']"
760,6582,2422,CC BY-SA 4.0,2019-03-12T00:05:40.607,"<p><a href=""https://github.com/jenkinsci/bitbucket-build-status-notifier-plugin/pull/37"" rel=""nofollow noreferrer"">Based on this PR</a>, the <code>repoSlug</code> was added and now the status is sent to the right repository.</p>

<p>When it was not working:</p>

<pre><code>post {
    success {
        bitbucketStatusNotify(
                buildState: 'SUCCESSFUL',
                commitId: env.GIT_COMMIT
        )
    }
    failure {
        bitbucketStatusNotify(
                buildState: 'FAILED',
                commitId: env.GIT_COMMIT
        )
    }
}
</code></pre>

<p>Now it works:</p>

<pre><code>post {
    success {
        bitbucketStatusNotify(
                buildState: 'SUCCESSFUL',
                repoSlug: 'repoSlug aka repositoryName, e.g. some-app',
                commitId: env.GIT_COMMIT
        )
    }
    failure {
        bitbucketStatusNotify(
                buildState: 'FAILED',
                repoSlug: 'repoSlug aka repositoryName, e.g. some-app',
                commitId: env.GIT_COMMIT
        )
    }
}
</code></pre>

<p><a href=""https://github.com/jenkinsci/bitbucket-build-status-notifier-plugin"" rel=""nofollow noreferrer"">The README in the Github repo emphasized that</a>:</p>

<blockquote>
  <p>Note that the repoSlug and commitId parameters work only when they are
  both specified.</p>
</blockquote>
",210,2019-09-03T10:34:26.680,"[""post {\n    success {\n        bitbucketStatusNotify(\n                buildState: 'SUCCESSFUL',\n                commitId: env.GIT_COMMIT\n        )\n    }\n    failure {\n        bitbucketStatusNotify(\n                buildState: 'FAILED',\n                commitId: env.GIT_COMMIT\n        )\n    }\n}\n"", ""post {\n    success {\n        bitbucketStatusNotify(\n                buildState: 'SUCCESSFUL',\n                repoSlug: 'repoSlug aka repositoryName, e.g. some-app',\n                commitId: env.GIT_COMMIT\n        )\n    }\n    failure {\n        bitbucketStatusNotify(\n                buildState: 'FAILED',\n                repoSlug: 'repoSlug aka repositoryName, e.g. some-app',\n                commitId: env.GIT_COMMIT\n        )\n    }\n}\n""]"
761,6597,6552,CC BY-SA 4.0,2019-03-13T22:54:51.930,"<pre><code>node {
checkout scm 
app = docker.build(""test-image"",""-f path/to/dockerfile ."")
}
</code></pre>
",12885,2019-03-13T22:54:51.930,"['node {\ncheckout scm \napp = docker.build(""test-image"",""-f path/to/dockerfile ."")\n}\n']"
762,6598,4941,CC BY-SA 4.0,2019-03-14T00:26:03.140,"<p>Assuming this is a production <code>Dockerfile</code>, the boilerplate configuration for a Nodejs type of application would look like this:</p>

<pre><code>FROM node:alpine as builder
WORKDIR '/app'
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build
</code></pre>

<p>or like this:</p>

<pre><code>FROM node:alpine
WORKDIR ""/app""
COPY ./package.json ./
RUN npm install
COPY . .
CMD [""npm"", ""run"", ""start""]
</code></pre>

<p>and if you involve Nginx, you may additionally have a couple of lines that would look something like this:</p>

<pre><code>FROM nginx
EXPOSE 80
COPY --from=builder /app/build /usr/share/nginx/html
</code></pre>

<p>So now you have a couple of answers with a few variations of how you could write out the production ready <code>Dockerfile</code>.</p>
",6282,2019-03-14T00:26:03.140,"[""FROM node:alpine as builder\nWORKDIR '/app'\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build\n"", 'FROM node:alpine\nWORKDIR ""/app""\nCOPY ./package.json ./\nRUN npm install\nCOPY . .\nCMD [""npm"", ""run"", ""start""]\n', 'FROM nginx\nEXPOSE 80\nCOPY --from=builder /app/build /usr/share/nginx/html\n']"
763,6603,6599,CC BY-SA 4.0,2019-03-14T10:14:45.720,"<p>You can retrieve security group from <a href=""https://www.terraform.io/docs/providers/aws/d/security_group.html"" rel=""nofollow noreferrer"">data source</a></p>

<pre><code>variable ""security_group_id"" {}

data ""aws_security_group"" ""selected"" {
  id = ""${var.security_group_id}""
}
</code></pre>
",12833,2019-03-14T10:14:45.720,"['variable ""security_group_id"" {}\n\ndata ""aws_security_group"" ""selected"" {\n  id = ""${var.security_group_id}""\n}\n']"
764,6616,6615,CC BY-SA 4.0,2019-03-15T11:33:28.510,"<p>You can obtain old parameters from the properties file before using <strong>sed</strong>, e.g.</p>

<pre><code># get old parameters
$ export oldUsername=$(grep mysql.username $FILE | cut -d'=' -f2)
$ export oldPass=$(grep mysql.pass $FILE | cut -d'=' -f2)

# set new parameters
$ export newUsername=NEW_USERNAME
$ export newPass=NEW_PASS

# change parameters
$ sed -i ""s/$oldUsername/$newUsername/g"" $FILE
$ sed -i ""s/$oldPass/$newPass/g"" $FILE
</code></pre>
",12893,2019-03-15T11:33:28.510,"['# get old parameters\n$ export oldUsername=$(grep mysql.username $FILE | cut -d\'=\' -f2)\n$ export oldPass=$(grep mysql.pass $FILE | cut -d\'=\' -f2)\n\n# set new parameters\n$ export newUsername=NEW_USERNAME\n$ export newPass=NEW_PASS\n\n# change parameters\n$ sed -i ""s/$oldUsername/$newUsername/g"" $FILE\n$ sed -i ""s/$oldPass/$newPass/g"" $FILE\n']"
765,6617,6615,CC BY-SA 4.0,2019-03-15T11:42:24.493,"<p>You can use below. </p>

<pre><code>[user@xyz ~]$ hh='mysql.username=USERNAME';echo $hh | awk -F""="" '{OFS=FS}{ $2=""Mango""; print }'
mysql.username=Mango
</code></pre>
",6308,2019-03-15T11:42:24.493,"['[user@xyz ~]$ hh=\'mysql.username=USERNAME\';echo $hh | awk -F""="" \'{OFS=FS}{ $2=""Mango""; print }\'\nmysql.username=Mango\n']"
766,6628,6554,CC BY-SA 4.0,2019-03-16T10:53:52.223,"<p>You didn't say how the sls file is executed.</p>

<ul>
<li>One way would be to <a href=""https://docs.saltstack.com/en/getstarted/config/pillar.html#salt-pillar-on-the-command-line"" rel=""nofollow noreferrer"">pass pillars on command line</a>:</li>
</ul>

<pre><code>salt '*' state.apply ftpsync pillar='{""ftpusername"": ""test"", ""ftppassword"": ""0ydyfww3giq8""}'
</code></pre>

<ul>
<li><p>Or you can set the group name as a <a href=""https://docs.saltstack.com/en/latest/topics/grains/"" rel=""nofollow noreferrer"">grain</a> on the minion in advance.</p></li>
<li><p>Yet another way would be to set the group name as a jinja variable in the sls formula, depending on the hostname grain. Assuming your host names are set and standardized.</p></li>
</ul>
",12305,2019-03-16T10:53:52.223,"['salt \'*\' state.apply ftpsync pillar=\'{""ftpusername"": ""test"", ""ftppassword"": ""0ydyfww3giq8""}\'\n']"
767,6634,6631,CC BY-SA 4.0,2019-03-16T20:58:51.790,"<p>If the end result would be entirely contained in a directory somewhere you could simply archive that directory after the installation on one machine and restore it on the new machine. It does work for <em>some</em> apps.</p>

<p>But after going through the <a href=""https://www.pyimagesearch.com/2018/05/28/ubuntu-18-04-how-to-install-opencv/"" rel=""nofollow noreferrer"">Ubuntu 18.04: How to install OpenCV</a> procedure and peeking into the makefiles I believe this wouldn't be applicable to OpenCV: its artefacts are spread in various places on a Ubuntu system.</p>

<p>But I <em>think</em> it's possible to significantly reduce the installation time by skipping the actual build process, which appears to be the bulk of the process. From the above referenced procedure (which I'll also use in describing the proposed solution):</p>

<blockquote>
  <p>This process may take 30 minutes or longer, so go for a nice walk if
  you are able.</p>
</blockquote>

<p>I'll re-use the referenced procedure for describing the proposal, with a few tweaks (I'd like to think that the tweaks would easily be portable to future/similar versions of the procedure):</p>

<p><strong>In the initial installation:</strong></p>

<ul>
<li><p>after the build completes but before the <strong>Installing and verifying OpenCV</strong> step insert:</p>

<p><strong>Step 4a: save the pre-built official OpenCV source tree to S3</strong></p>

<p>Follow <a href=""https://serverfault.com/q/254599"">Copying from s3 to EC2 instance</a> instructions for S3 access setup, then run:</p>

<pre><code>tar cvfz pre_built_opencv.tgz opencv*
s3cmd put pre_built_opencv.tgz s3://&lt;bucket_name&gt;
</code></pre>

<p>Optional: you can remove the local archive copy now:</p>

<pre><code>rm pre_built_opencv.tgz
</code></pre></li>
</ul>

<p><strong>In the subsequent installations:</strong></p>

<ul>
<li><p>replace <strong>Step #2: Download the official OpenCV source</strong> with:</p>

<p><strong>Step #2: Extract the pre-built official OpenCV source tree from S3</strong></p>

<p>Follow <a href=""https://serverfault.com/q/254599"">Copying from s3 to EC2 instance</a> instructions for S3 access setup, then run:</p>

<pre><code>cd ~
s3cmd get s3://&lt;bucket_name&gt;/pre_built_opencv.tgz pre_built_opencv.tgz
tar xvzf pre_built_opencv.tgz
</code></pre>

<p>Optional: you can remove the local archive copy now:</p>

<pre><code>rm pre_built_opencv.tgz
</code></pre></li>
<li><p>in <strong>Step #4: Configure and compile OpenCV for Ubuntu 18.04</strong>:</p>

<ul>
<li>skip the <strong>Configure OpenCV with CMake</strong> section</li>
<li><p>replace the <strong>Compiling OpenCV on Ubuntu 18.04</strong> section with:</p>

<p><strong>Enter the pre-built OpenCV build directory</strong></p>

<pre><code>cd ~/opencv/build
</code></pre></li>
</ul></li>
</ul>

<p>I didn't run it myself, but I think it <em>should</em> work, at least for VMs of the same type. </p>

<p>I'd 1st try the same even for different VM types. If that doesn't work then I'd re-run the initial installation for them, using a different archive filename.</p>
",47,2019-03-16T20:58:51.790,"['tar cvfz pre_built_opencv.tgz opencv*\ns3cmd put pre_built_opencv.tgz s3://<bucket_name>\n', 'rm pre_built_opencv.tgz\n', 'cd ~\ns3cmd get s3://<bucket_name>/pre_built_opencv.tgz pre_built_opencv.tgz\ntar xvzf pre_built_opencv.tgz\n', 'rm pre_built_opencv.tgz\n', 'cd ~/opencv/build\n']"
768,6635,6629,CC BY-SA 4.0,2019-03-16T21:00:46.047,"<p>Lets take this line by line:</p>

<p>My additions are added as comments.</p>

<pre><code>trigger:
- master
# The branch you are building.

pool:
  vmImage: 'Ubuntu-16.04'
# The type of VM your code will run on.

variables:
  buildConfiguration: 'Release'
#This ends up defining which webconfig file to use.

steps:
- script: dotnet restore
  displayName: Restoring Dependencies

- script: dotnet build --configuration $(buildConfiguration)
  displayName: 'dotnet build $(buildConfiguration)'
# Builds your application
- task: DotNetCoreCLI@2
  displayName: Unit Tests
  inputs:
    command: test
    projects: '**/*Tests/*.csproj'
    arguments: '--configuration $(buildConfiguration)'
#Runs unit tests for your application
- task: DotNetCoreCLI@2
  displayName: Publishing
  inputs:
    command: publish
    publishWebProjects: True
    arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)'
    zipAfterPublish: True
#Pushes your application as an artifact (You'll be able to see it in your list of artifacts in Azure DevOps)
- task: PublishBuildArtifacts@1
</code></pre>

<p>As for your release script, you are forgetting to pass in the values so your release script isn't doing anything at the moment.
But when it does work, it will take the objects from your artifacts or container images and deploy them into your webapp the same way it would do it if you ran those commands from your local machine.</p>
",10,2019-03-16T21:00:46.047,"[""trigger:\n- master\n# The branch you are building.\n\npool:\n  vmImage: 'Ubuntu-16.04'\n# The type of VM your code will run on.\n\nvariables:\n  buildConfiguration: 'Release'\n#This ends up defining which webconfig file to use.\n\nsteps:\n- script: dotnet restore\n  displayName: Restoring Dependencies\n\n- script: dotnet build --configuration $(buildConfiguration)\n  displayName: 'dotnet build $(buildConfiguration)'\n# Builds your application\n- task: DotNetCoreCLI@2\n  displayName: Unit Tests\n  inputs:\n    command: test\n    projects: '**/*Tests/*.csproj'\n    arguments: '--configuration $(buildConfiguration)'\n#Runs unit tests for your application\n- task: DotNetCoreCLI@2\n  displayName: Publishing\n  inputs:\n    command: publish\n    publishWebProjects: True\n    arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)'\n    zipAfterPublish: True\n#Pushes your application as an artifact (You'll be able to see it in your list of artifacts in Azure DevOps)\n- task: PublishBuildArtifacts@1\n""]"
769,6640,6637,CC BY-SA 4.0,2019-03-17T19:34:21.880,"<p>Negation to the rescue:</p>

<pre><code>sed -i ""s/server.address=[^\ ].*\ /server.address=${SERVER_ADDRESS} /g""
</code></pre>

<p>This is telling to search zero or more characters (<code>.*</code>) NOT matching whitespace (<code>[^\ ]</code>) up to the first whitespace.</p>

<p>A good pattern is not to use real values to be replaced (<code>10.111.11.11:3197</code>) but to use a mark like <code>###SERVER_ADDRESS###</code>. If something goes wrong you can easily post-check with</p>

<pre><code>grep ""###"" &amp;&amp; exit -1
</code></pre>

<p>This can avoid continuing with dangerous values (mixing dev/pre/pro values)</p>
",12936,2019-04-02T04:06:24.447,"['sed -i ""s/server.address=[^\\ ].*\\ /server.address=${SERVER_ADDRESS} /g""\n', 'grep ""###"" && exit -1\n']"
770,6648,6639,CC BY-SA 4.0,2019-03-18T03:01:47.003,"<p>You cannot rely on <code>FROM node:10.15-alpine</code> alone to fix this. I had to go with the fix from the facebook team. So if anyone else did not get a fix from modifying your <code>Dockerfile</code> to <code>node:10.15-alpine</code>, go to your <code>package.json</code> file and change react-scripts to the following facebook fix:</p>

<p><code>""react-scripts"": ""3.0.0-next.b0cbf2ca""</code></p>

<p>Then go ahead and remove your <code>node_modules/</code> folder via <code>rm -rf node_modules</code> and then run <code>npm install</code>, check your <code>jest-util</code> file, it should now have an output like this:</p>

<pre><code>└─┬ react-scripts@3.0.0-next.b0cbf2ca
  ├─┬ babel-jest@24.5.0
  │ └─┬ @jest/transform@24.5.0
  │   ├─┬ jest-haste-map@24.5.0
  │   │ └── jest-util@24.5.0  deduped
  │   └── jest-util@24.5.0
  └─┬ jest@24.5.0
    └─┬ jest-cli@24.5.0
      ├─┬ @jest/core@24.5.0
      │ ├─┬ @jest/reporters@24.5.0
      │ │ └── jest-util@24.5.0  deduped
      │ ├─┬ jest-runner@24.5.0
      │ │ └── jest-util@24.5.0  deduped
      │ ├─┬ jest-runtime@24.5.0
      │ │ └── jest-util@24.5.0  deduped
      │ ├── jest-util@24.5.0  deduped
      │ └─┬ jest-watcher@24.5.0
      │   └── jest-util@24.5.0  deduped
      ├─┬ jest-config@24.5.0
      │ ├─┬ jest-environment-jsdom@24.5.0
      │ │ └── jest-util@24.5.0  deduped
      │ ├─┬ jest-environment-node@24.5.0
      │ │ └── jest-util@24.5.0  deduped
      │ ├─┬ jest-jasmine2@24.5.0
      │ │ ├─┬ jest-each@24.5.0
      │ │ │ └── jest-util@24.5.0  deduped
      │ │ └── jest-util@24.5.0  deduped
      │ └── jest-util@24.5.0  deduped
      └── jest-util@24.5.0  deduped
</code></pre>

<p>You should be good to run TravisCI build now. The issue is the react-scripts version <code>2.1.8</code> is conflicting with new version of Node. Suffered through this all day long, grateful to the facebook team for getting back to me. </p>

<p>For reference: <a href=""https://github.com/facebook/create-react-app/issues/6475"" rel=""nofollow noreferrer"">https://github.com/facebook/create-react-app/issues/6475</a></p>
",6282,2019-03-18T03:01:47.003,['└─┬ react-scripts@3.0.0-next.b0cbf2ca\n  ├─┬ babel-jest@24.5.0\n  │ └─┬ @jest/transform@24.5.0\n  │   ├─┬ jest-haste-map@24.5.0\n  │   │ └── jest-util@24.5.0  deduped\n  │   └── jest-util@24.5.0\n  └─┬ jest@24.5.0\n    └─┬ jest-cli@24.5.0\n      ├─┬ @jest/core@24.5.0\n      │ ├─┬ @jest/reporters@24.5.0\n      │ │ └── jest-util@24.5.0  deduped\n      │ ├─┬ jest-runner@24.5.0\n      │ │ └── jest-util@24.5.0  deduped\n      │ ├─┬ jest-runtime@24.5.0\n      │ │ └── jest-util@24.5.0  deduped\n      │ ├── jest-util@24.5.0  deduped\n      │ └─┬ jest-watcher@24.5.0\n      │   └── jest-util@24.5.0  deduped\n      ├─┬ jest-config@24.5.0\n      │ ├─┬ jest-environment-jsdom@24.5.0\n      │ │ └── jest-util@24.5.0  deduped\n      │ ├─┬ jest-environment-node@24.5.0\n      │ │ └── jest-util@24.5.0  deduped\n      │ ├─┬ jest-jasmine2@24.5.0\n      │ │ ├─┬ jest-each@24.5.0\n      │ │ │ └── jest-util@24.5.0  deduped\n      │ │ └── jest-util@24.5.0  deduped\n      │ └── jest-util@24.5.0  deduped\n      └── jest-util@24.5.0  deduped\n']
771,6650,6615,CC BY-SA 4.0,2019-03-18T03:46:32.257,"<p>Maybe, this is something you can try - in sed they are known as back-references:</p>

<p>$1 - is the value passed for username</p>

<p>$2 - is the value passed for password</p>

<p>\1 captures the back reference within \( and \)</p>

<pre><code>sed -i ""s/\(mysql\.username=\).*/\1$1"" propertiesfile
sed -i ""s/\(mysql\.pass=\).*/\1$2"" propertiesfile
</code></pre>
",11832,2019-03-18T03:46:32.257,"['sed -i ""s/\\(mysql\\.username=\\).*/\\1$1"" propertiesfile\nsed -i ""s/\\(mysql\\.pass=\\).*/\\1$2"" propertiesfile\n']"
772,6666,2731,CC BY-SA 4.0,2019-03-20T16:37:48.093,"<p>thanks for motivation.
I made a powershell version of it.
Check it out...
With it you can move in dockerhub containers to a restricted docker networks with a windows desktop and an ssh-scp tool to docker machine without root or administrator rights</p>

<p><a href=""https://gitlab.com/Jancsoj78/dockerless_docker_downloader"" rel=""nofollow noreferrer"">https://gitlab.com/Jancsoj78/dockerless_docker_downloader</a>
a new hacker tool :)</p>

<pre><code>$image = ""ubuntu""
$tag = ""latest""
$imageuri = ""https://auth.docker.io/token?service=registry.docker.io&amp;scope=repository:library/""+$image+"":pull""
$taguri = ""https://registry-1.docker.io/v2/library/""+$image+""/manifests/""+$tag
$bloburi = ""https://registry-1.docker.io/v2/library/""+$image+""/blobs/sha256:""

#token request
$token = Invoke-WebRequest -Uri $imageuri | ConvertFrom-Json | Select -expand token

#pull image manifest
$blobs = $($(Invoke-Webrequest -Headers @{Authorization=""Bearer $token""} -Method GET -Uri $taguri | ConvertFrom-Json | Select -expand fsLayers ) -replace ""sha256:"" -replace ""@{blobSum="" -replace ""}"")

#download blobs
for ($i=0; $i -lt $blobs.length; $i++) {
    $blobelement =$blobs[$i]

    Invoke-Webrequest -Headers @{Authorization=""Bearer $token""} -Method GET -Uri $bloburi$blobelement -OutFile blobtmp

    $source = ""blobtmp""
    $newfile = ""$blobelement.gz""

#overwrite
Copy-Item $source $newfile -Force -Recurse
#source blobs
ls *.gz
}
#postprocess
echo ""copy these .gz to your docker machine""
echo ""docker import .gz backward one by one""
echo ""lastone with ubuntu:latest""
echo ""after docker export and reimport to make a simple layer image""
</code></pre>
",12985,2019-03-22T19:46:14.327,"['$image = ""ubuntu""\n$tag = ""latest""\n$imageuri = ""https://auth.docker.io/token?service=registry.docker.io&scope=repository:library/""+$image+"":pull""\n$taguri = ""https://registry-1.docker.io/v2/library/""+$image+""/manifests/""+$tag\n$bloburi = ""https://registry-1.docker.io/v2/library/""+$image+""/blobs/sha256:""\n\n#token request\n$token = Invoke-WebRequest -Uri $imageuri | ConvertFrom-Json | Select -expand token\n\n#pull image manifest\n$blobs = $($(Invoke-Webrequest -Headers @{Authorization=""Bearer $token""} -Method GET -Uri $taguri | ConvertFrom-Json | Select -expand fsLayers ) -replace ""sha256:"" -replace ""@{blobSum="" -replace ""}"")\n\n#download blobs\nfor ($i=0; $i -lt $blobs.length; $i++) {\n    $blobelement =$blobs[$i]\n\n    Invoke-Webrequest -Headers @{Authorization=""Bearer $token""} -Method GET -Uri $bloburi$blobelement -OutFile blobtmp\n\n    $source = ""blobtmp""\n    $newfile = ""$blobelement.gz""\n\n#overwrite\nCopy-Item $source $newfile -Force -Recurse\n#source blobs\nls *.gz\n}\n#postprocess\necho ""copy these .gz to your docker machine""\necho ""docker import .gz backward one by one""\necho ""lastone with ubuntu:latest""\necho ""after docker export and reimport to make a simple layer image""\n']"
773,6677,6673,CC BY-SA 4.0,2019-03-21T21:13:24.143,"<p>I've created a couple crude methods of grabbing the latest major versions of releases, as well as absolute latest.</p>

<pre><code># Grab Latest Tomcat 7
curl -i https://www-us.apache.org/dist/tomcat/tomcat-7/ | grep -Po '(?&lt;=(&lt;a href=""v)).*(?=/""&gt;v)'

# Grab Latest Tomcat 8
curl -i https://www-us.apache.org/dist/tomcat/tomcat-8/ | grep -Po '(?&lt;=(&lt;a href=""v)).*(?=/""&gt;v)'

# Grab Latest Tomcat 9
curl -i https://www-us.apache.org/dist/tomcat/tomcat-9/ | grep -Po '(?&lt;=(&lt;a href=""v)).*(?=/""&gt;v)'

# Grab Latest Tomcat
curl -i https://api.github.com/repos/apache/tomcat/tags | grep '""name""' | head -1 | egrep -o ""([0-9]{1,}\.)+[0-9]{1,}""
</code></pre>

<p>It's a bit of a hack where I'm looking for text in-between two values on a web page to grab the version number. It's crude and I'm sure there's a more elegant way to grab this, but this what I was able to figure out with my skillset! Maybe it can help someone in the future, but if anyone has better ideas I'm all ears.</p>
",13000,2019-03-21T21:13:24.143,"['# Grab Latest Tomcat 7\ncurl -i https://www-us.apache.org/dist/tomcat/tomcat-7/ | grep -Po \'(?<=(<a href=""v)).*(?=/"">v)\'\n\n# Grab Latest Tomcat 8\ncurl -i https://www-us.apache.org/dist/tomcat/tomcat-8/ | grep -Po \'(?<=(<a href=""v)).*(?=/"">v)\'\n\n# Grab Latest Tomcat 9\ncurl -i https://www-us.apache.org/dist/tomcat/tomcat-9/ | grep -Po \'(?<=(<a href=""v)).*(?=/"">v)\'\n\n# Grab Latest Tomcat\ncurl -i https://api.github.com/repos/apache/tomcat/tags | grep \'""name""\' | head -1 | egrep -o ""([0-9]{1,}\\.)+[0-9]{1,}""\n']"
774,6678,4355,CC BY-SA 4.0,2019-03-22T02:09:00.207,"<p>You can use the ""<a href=""https://jenkins.io/doc/book/pipeline/syntax/#when"" rel=""noreferrer"">when</a>"" block combined with the built in ""changeset"" condition to conditionally run only certain stages of your monorepo's pipeline. From the when.changeset documentation:</p>

<p>changeset- 
Executes the stage if the build’s SCM changeset contains one or more files matching the given string or glob. Example: when { changeset ""**/*.js"" }</p>

<p>Here is an example Jenkinsfile using this strategy:</p>

<pre><code>pipeline {
    agent any
    stages {
        stage('build matchengine') {
            when {
                changeset ""**/matchengine/*.*""
            }
            steps {
                echo 'building match engine'
            }
        }
        stage('build posttrade') {
            when {
                changeset ""**/posttrade/*.*""
            }
            steps {
                echo 'building post trade'
            }
        }
    }
}
</code></pre>

<p>, applicable to the monorepo project structure shown below:</p>

<pre><code> .(my-project)
   |-- Jenkinsfile
   |-- matchengine
   |-- posttrade
   |-- serverless
   |-- ui
</code></pre>

<p>This strategy won't scale past small codebases because it would be hard to keep track of which modules depend one each other. You would be better off using a build system like Bazel. Your CI job would simply issue a bazel build //... (build everything), and Bazel would calculate what actually needs to be built, and what needs to be tested. Further, there even exist bazel rules such as rules_docker and rules_k8s which can calculate which of your containers need to be rebuilt and pushed to a container registry, and which of your applications need to be redeployed to Kubernetes.</p>
",13011,2019-07-31T22:04:21.493,"['pipeline {\n    agent any\n    stages {\n        stage(\'build matchengine\') {\n            when {\n                changeset ""**/matchengine/*.*""\n            }\n            steps {\n                echo \'building match engine\'\n            }\n        }\n        stage(\'build posttrade\') {\n            when {\n                changeset ""**/posttrade/*.*""\n            }\n            steps {\n                echo \'building post trade\'\n            }\n        }\n    }\n}\n', ' .(my-project)\n   |-- Jenkinsfile\n   |-- matchengine\n   |-- posttrade\n   |-- serverless\n   |-- ui\n']"
775,6684,6641,CC BY-SA 4.0,2019-03-23T22:51:17.280,"<p>I have made the scripts and tools that we use to solve these problems opensource on GitHub calling it <a href=""https://github.com/ocd-scm/ocd-meta/blob/master/README.md"" rel=""nofollow noreferrer"">OCD</a>. You mention that you have thought the following feels wrong:</p>
<blockquote>
<ul>
<li><p>Store all the environment configurations in separate &quot;configurations&quot; git repo</p>
</li>
<li><p>Use ansible or something similar to store the scripts and configurations for each environment.</p>
</li>
</ul>
</blockquote>
<p>With OCD we use <a href=""https://github.com/roboll/helmfile"" rel=""nofollow noreferrer"">Helmfile</a> which makes it easy to manage many helm release in either one of a small number of simple yaml file. If you are familiar with Ansible then it gives all the benefits of that tool but it only manages helm releases. It makes total sense to put the <code>helmfile.yml</code> configuration into Git. These act as the playbooks to setup your environment. They shouldn't live in the application repos it should be in one or more &quot;environments repo(s)&quot;.</p>
<p>We have created a generic chart to install secrets and another to install configmaps. Your folder structure might look like:</p>
<pre><code>|____config
| |____nexmo.yaml.secret // &lt;- gpg encrypted secret
| |____reepay.yaml.secret
| |____backoffice-db.yaml.secret
| |____helmfile.yaml // &lt;- hemlfile manages 3 secret releases and inline configmaps
|____backoffice-app
| |____helmfile.yaml // &lt;- hemlfile manages 1 app
|____frontoffice-app
| |____helmfile.yaml // &lt;- hemlfile manages 1 app
</code></pre>
<p>In the above example, we have three helmfiles. There is one that manages shared configuration and one each for two apps that use the shared config. Since shared config is going to be multipe secret and configmaps it just uses the two generic charts. It uses the <a href=""https://github.com/ocd-scm/ocd-secret"" rel=""nofollow noreferrer"">generic secret chart</a> to stamp out many separately <a href=""https://github.com/ocd-scm/ocd-meta/wiki/Encrypting-Secrets#introduction"" rel=""nofollow noreferrer"">encrypted secrets</a> using different values files. Likewise, one <a href=""https://github.com/ocd-scm/ocd-configmap"" rel=""nofollow noreferrer"">generic configmap chart</a> is used to stamp out many configmaps by feeding it different values.</p>
<p>With OCD you setup webhooks on your config repo to point at an <a href=""https://github.com/adnanh/webhook"" rel=""nofollow noreferrer"">adnanh/webhook</a>. When you push a change to the config repo the webhook fires. The webhook runs a script to checkout the config repo, decrypt the secrets, then does <code>helmfile apply</code> in each folder that has a <code>helmfile.yaml</code>. That does a helm diff on every release in each helmfile and so will upgrade any secrets, configmaps or application deployments where the yaml has changed.</p>
<p>We have a wizard script to install the webhook into a new environment. This means that a team can spin up a new environment using the config in git quickly. Since it is loading the config from git it is an accurate process. Here is a video of <a href=""https://vimeo.com/manage/318887046/general"" rel=""nofollow noreferrer"">setting up a new environment in six minutes</a> which would be quicker if I was not making a video.</p>
<p>Helmfile reduces the burden of having to go through all the files to try to find all the settings to change for a new team environment. The <code>helmfile.yaml</code> captures whatever you are overriding over the chart defaults. All the configmaps and secrets are organised to be easily found in one place. Helmfile has quite a lot of capabilities that make managing config and managing many helm releases easier.</p>
<p>We happen to be using openshift kubernetes so our application deployment chart for microservices uses openshift specific yaml. Yet the secrets and configmaps charts are vanilla k8s. So the OCD approach and scripts to manage config should work with any k8s distro. We plan to have a 1.0 release of OCD in the next couple of weeks. I was considering doing a demo of running OCD on vanilla k8s to manage configuration. So I would be really interested in your thoughts and perhaps we can collaborate. Just raise an issue on the ocd-meta github asking about running it on the version of k8s you are using.</p>
",10599,2019-03-24T07:59:11.237,['|____config\n| |____nexmo.yaml.secret // <- gpg encrypted secret\n| |____reepay.yaml.secret\n| |____backoffice-db.yaml.secret\n| |____helmfile.yaml // <- hemlfile manages 3 secret releases and inline configmaps\n|____backoffice-app\n| |____helmfile.yaml // <- hemlfile manages 1 app\n|____frontoffice-app\n| |____helmfile.yaml // <- hemlfile manages 1 app\n']
776,6688,6359,CC BY-SA 4.0,2019-03-25T15:02:44.513,"<p>My problem was that the docker-machine didn't have enough memory to run both services at the same time.</p>

<p>Using those commands fixed it:</p>

<pre><code>docker-machine stop
""C:\Program Files\Oracle\VirtualBox\VBoxManage.exe"" modifyvm default --cpus 2
""C:\Program Files\Oracle\VirtualBox\VBoxManage.exe"" modifyvm default --memory 4096
docker-machine start
</code></pre>

<p>(The path to the VBoxManage.exe maybe be different for other users and it can be change to just ""VBoxManage"" if adding it to the environment paths)</p>
",12286,2019-03-25T15:02:44.513,"['docker-machine stop\n""C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage.exe"" modifyvm default --cpus 2\n""C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage.exe"" modifyvm default --memory 4096\ndocker-machine start\n']"
777,6695,6694,CC BY-SA 4.0,2019-03-26T01:50:51.830,"<p>Sure enough, everything and including the last <code>spec:</code> needed to be tabbed to the left once:</p>

<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: client-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      component: web
  template:
    metadata:
      labels:
        component: web
    spec:
      containers:
        - name: client
          image: ldco2016/multi-client
          ports:
            - containerPort: 3000
</code></pre>

<p>Unfortunately, you can't tell the difference with how <code>yaml</code> is formatted when pasted here, so it would not have been an easy catch, but if you would be looking at the original file configuration you would have noticed it like I did when I looked a third time.</p>
",6282,2019-03-26T01:50:51.830,['apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: client-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      component: web\n  template:\n    metadata:\n      labels:\n        component: web\n    spec:\n      containers:\n        - name: client\n          image: ldco2016/multi-client\n          ports:\n            - containerPort: 3000\n']
778,6725,6669,CC BY-SA 4.0,2019-03-28T21:41:47.610,"<p>You can do that using this command:</p>

<pre><code>kubectl cp -n [NAMESPACE] [POD_NAME]:/[POD_DIRECTORY]/. .
</code></pre>
",13140,2019-03-28T21:41:47.610,['kubectl cp -n [NAMESPACE] [POD_NAME]:/[POD_DIRECTORY]/. .\n']
779,6742,6737,CC BY-SA 4.0,2019-04-01T04:36:21.827,"<blockquote>
  <p>This error occurrs because you do not add the root CA in your chain.pem file:</p>
</blockquote>

<p>for solutions add below chain in your chain.pem file:</p>

<pre><code>-----BEGIN CERTIFICATE-----
MIIDSjCCAjKgAwIBAgIQRK+wgNajJ7qJMDmGLvhAazANBgkqhkiG9w0BAQUFADA/
MSQwIgYDVQQKExtEaWdpdGFsIFNpZ25hdHVyZSBUcnVzdCBDby4xFzAVBgNVBAMT
DkRTVCBSb290IENBIFgzMB4XDTAwMDkzMDIxMTIxOVoXDTIxMDkzMDE0MDExNVow
PzEkMCIGA1UEChMbRGlnaXRhbCBTaWduYXR1cmUgVHJ1c3QgQ28uMRcwFQYDVQQD
Ew5EU1QgUm9vdCBDQSBYMzCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEB
AN+v6ZdQCINXtMxiZfaQguzH0yxrMMpb7NnDfcdAwRgUi+DoM3ZJKuM/IUmTrE4O
rz5Iy2Xu/NMhD2XSKtkyj4zl93ewEnu1lcCJo6m67XMuegwGMoOifooUMM0RoOEq
OLl5CjH9UL2AZd+3UWODyOKIYepLYYHsUmu5ouJLGiifSKOeDNoJjj4XLh7dIN9b
xiqKqy69cK3FCxolkHRyxXtqqzTWMIn/5WgTe1QLyNau7Fqckh49ZLOMxt+/yUFw
7BZy1SbsOFU5Q9D8/RhcQPGX69Wam40dutolucbY38EVAjqr2m7xPi71XAicPNaD
aeQQmxkqtilX4+U9m5/wAl0CAwEAAaNCMEAwDwYDVR0TAQH/BAUwAwEB/zAOBgNV
HQ8BAf8EBAMCAQYwHQYDVR0OBBYEFMSnsaR7LHH62+FLkHX/xBVghYkQMA0GCSqG
SIb3DQEBBQUAA4IBAQCjGiybFwBcqR7uKGY3Or+Dxz9LwwmglSBd49lZRNI+DT69
ikugdB/OEIKcdBodfpga3csTS7MgROSR6cz8faXbauX+5v3gTt23ADq1cEmv8uXr
AvHRAosZy5Q6XkjEGB5YGV8eAlrwDPGxrancWYaLbumR9YbK+rlmM6pZW87ipxZz
R8srzJmwN0jP41ZL9c8PDHIyh8bwRLtTcm1D9SZImlJnt1ir/md2cXjbDaJWFBM5
JDGFoqgCWjBH4d1QB7wCCZAA62RjYJsWvIjJEubSfZGL+T0yjWW06XyxV3bqxbYo
Ob8VZRzI9neWagqNdwvYkQsEjgfbKbYK7p2CNTUQ
-----END CERTIFICATE----- 
</code></pre>

<p>OR you can use below script for install Let's Encrypt SSL in your Zimbra server:</p>

<pre><code>#!/bin/bash

# SSL certificate installation in Zimbra
# with SSL certificate provided by Let's Encrypt (letsencrypt.org)
# Author: Subhash (serverkaka.com)

# Check if running as root
if [ ""$(id -u)"" != ""0"" ]; then
   echo ""This script must be run as root"" 1&gt;&amp;2
   exit 1
fi

read -p 'letsencrypt_email [xx@xx.xx]: ' letsencrypt_email
read -p 'mail_server_url [xx.xx.xx]: ' mail_server_url

# Check All variable have a value
if [ -z $mail_server_url ] || [ -z $letsencrypt_email ]
then
      echo run script again please insert all value. do not miss any value
else

# Installation start
# Stop the jetty or nginx service at Zimbra level
su - zimbra -c 'zmproxyctl stop'
su - zimbra -c 'zmmailboxdctl stop'

# Install git and letsencrypt
cd /opt/
apt-get install git
git clone https://github.com/letsencrypt/letsencrypt
cd letsencrypt

# Get SSL certificate
./letsencrypt-auto certonly --standalone --non-interactive --agree-tos --email $letsencrypt_email -d $mail_server_url --hsts
cd /etc/letsencrypt/live/$mail_server_url
cat &lt;&lt;EOF &gt;&gt;chain.pem
-----BEGIN CERTIFICATE-----
MIIDSjCCAjKgAwIBAgIQRK+wgNajJ7qJMDmGLvhAazANBgkqhkiG9w0BAQUFADA/
MSQwIgYDVQQKExtEaWdpdGFsIFNpZ25hdHVyZSBUcnVzdCBDby4xFzAVBgNVBAMT
DkRTVCBSb290IENBIFgzMB4XDTAwMDkzMDIxMTIxOVoXDTIxMDkzMDE0MDExNVow
PzEkMCIGA1UEChMbRGlnaXRhbCBTaWduYXR1cmUgVHJ1c3QgQ28uMRcwFQYDVQQD
Ew5EU1QgUm9vdCBDQSBYMzCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEB
AN+v6ZdQCINXtMxiZfaQguzH0yxrMMpb7NnDfcdAwRgUi+DoM3ZJKuM/IUmTrE4O
rz5Iy2Xu/NMhD2XSKtkyj4zl93ewEnu1lcCJo6m67XMuegwGMoOifooUMM0RoOEq
OLl5CjH9UL2AZd+3UWODyOKIYepLYYHsUmu5ouJLGiifSKOeDNoJjj4XLh7dIN9b
xiqKqy69cK3FCxolkHRyxXtqqzTWMIn/5WgTe1QLyNau7Fqckh49ZLOMxt+/yUFw
7BZy1SbsOFU5Q9D8/RhcQPGX69Wam40dutolucbY38EVAjqr2m7xPi71XAicPNaD
aeQQmxkqtilX4+U9m5/wAl0CAwEAAaNCMEAwDwYDVR0TAQH/BAUwAwEB/zAOBgNV
HQ8BAf8EBAMCAQYwHQYDVR0OBBYEFMSnsaR7LHH62+FLkHX/xBVghYkQMA0GCSqG
SIb3DQEBBQUAA4IBAQCjGiybFwBcqR7uKGY3Or+Dxz9LwwmglSBd49lZRNI+DT69
ikugdB/OEIKcdBodfpga3csTS7MgROSR6cz8faXbauX+5v3gTt23ADq1cEmv8uXr
AvHRAosZy5Q6XkjEGB5YGV8eAlrwDPGxrancWYaLbumR9YbK+rlmM6pZW87ipxZz
R8srzJmwN0jP41ZL9c8PDHIyh8bwRLtTcm1D9SZImlJnt1ir/md2cXjbDaJWFBM5
JDGFoqgCWjBH4d1QB7wCCZAA62RjYJsWvIjJEubSfZGL+T0yjWW06XyxV3bqxbYo
Ob8VZRzI9neWagqNdwvYkQsEjgfbKbYK7p2CNTUQ
-----END CERTIFICATE-----
EOF

# Verify commercial certificate
mkdir /opt/zimbra/ssl/letsencrypt
cp /etc/letsencrypt/live/$mail_server_url/* /opt/zimbra/ssl/letsencrypt/
chown zimbra:zimbra /opt/zimbra/ssl/letsencrypt/*
ls -la /opt/zimbra/ssl/letsencrypt/
su - zimbra -c 'cd /opt/zimbra/ssl/letsencrypt/ &amp;&amp; /opt/zimbra/bin/zmcertmgr verifycrt comm privkey.pem cert.pem chain.pem'

# Deploy the new Let's Encrypt SSL certificate
cp -a /opt/zimbra/ssl/zimbra /opt/zimbra/ssl/zimbra.$(date ""+%Y%m%d"")
cp /opt/zimbra/ssl/letsencrypt/privkey.pem /opt/zimbra/ssl/zimbra/commercial/commercial.key
sudo chown zimbra:zimbra /opt/zimbra/ssl/zimbra/commercial/commercial.key
su - zimbra -c 'cd /opt/zimbra/ssl/letsencrypt/ &amp;&amp; /opt/zimbra/bin/zmcertmgr deploycrt comm cert.pem chain.pem'

# Restart Zimbra
su - zimbra -c 'zmcontrol restart'

# setting auto https redirect
cd /opt &amp;&amp; touch https-redirect.sh &amp;&amp; chown zimbra:zimbra https-redirect.sh &amp;&amp; chmod +x https-redirect.sh
cat &lt;&lt;EOF &gt;&gt;/opt/https-redirect.sh
zmprov ms $mail_server_url zimbraReverseProxyMailMode redirect
EOF
su - zimbra -c '/opt/https-redirect.sh'
rm /opt/https-redirect.sh
if
</code></pre>

<p>read this link for more details: <a href=""https://github.com/SubhashPatel/Install-Zimbra-mail-server-ubuntu/blob/master/configure-ssl-zimbra.sh"" rel=""nofollow noreferrer"">https://github.com/SubhashPatel/Install-Zimbra-mail-server-ubuntu/blob/master/configure-ssl-zimbra.sh</a></p>
",11598,2019-04-01T07:46:46.933,"['-----BEGIN CERTIFICATE-----\nMIIDSjCCAjKgAwIBAgIQRK+wgNajJ7qJMDmGLvhAazANBgkqhkiG9w0BAQUFADA/\nMSQwIgYDVQQKExtEaWdpdGFsIFNpZ25hdHVyZSBUcnVzdCBDby4xFzAVBgNVBAMT\nDkRTVCBSb290IENBIFgzMB4XDTAwMDkzMDIxMTIxOVoXDTIxMDkzMDE0MDExNVow\nPzEkMCIGA1UEChMbRGlnaXRhbCBTaWduYXR1cmUgVHJ1c3QgQ28uMRcwFQYDVQQD\nEw5EU1QgUm9vdCBDQSBYMzCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEB\nAN+v6ZdQCINXtMxiZfaQguzH0yxrMMpb7NnDfcdAwRgUi+DoM3ZJKuM/IUmTrE4O\nrz5Iy2Xu/NMhD2XSKtkyj4zl93ewEnu1lcCJo6m67XMuegwGMoOifooUMM0RoOEq\nOLl5CjH9UL2AZd+3UWODyOKIYepLYYHsUmu5ouJLGiifSKOeDNoJjj4XLh7dIN9b\nxiqKqy69cK3FCxolkHRyxXtqqzTWMIn/5WgTe1QLyNau7Fqckh49ZLOMxt+/yUFw\n7BZy1SbsOFU5Q9D8/RhcQPGX69Wam40dutolucbY38EVAjqr2m7xPi71XAicPNaD\naeQQmxkqtilX4+U9m5/wAl0CAwEAAaNCMEAwDwYDVR0TAQH/BAUwAwEB/zAOBgNV\nHQ8BAf8EBAMCAQYwHQYDVR0OBBYEFMSnsaR7LHH62+FLkHX/xBVghYkQMA0GCSqG\nSIb3DQEBBQUAA4IBAQCjGiybFwBcqR7uKGY3Or+Dxz9LwwmglSBd49lZRNI+DT69\nikugdB/OEIKcdBodfpga3csTS7MgROSR6cz8faXbauX+5v3gTt23ADq1cEmv8uXr\nAvHRAosZy5Q6XkjEGB5YGV8eAlrwDPGxrancWYaLbumR9YbK+rlmM6pZW87ipxZz\nR8srzJmwN0jP41ZL9c8PDHIyh8bwRLtTcm1D9SZImlJnt1ir/md2cXjbDaJWFBM5\nJDGFoqgCWjBH4d1QB7wCCZAA62RjYJsWvIjJEubSfZGL+T0yjWW06XyxV3bqxbYo\nOb8VZRzI9neWagqNdwvYkQsEjgfbKbYK7p2CNTUQ\n-----END CERTIFICATE----- \n', '#!/bin/bash\n\n# SSL certificate installation in Zimbra\n# with SSL certificate provided by Let\'s Encrypt (letsencrypt.org)\n# Author: Subhash (serverkaka.com)\n\n# Check if running as root\nif [ ""$(id -u)"" != ""0"" ]; then\n   echo ""This script must be run as root"" 1>&2\n   exit 1\nfi\n\nread -p \'letsencrypt_email [xx@xx.xx]: \' letsencrypt_email\nread -p \'mail_server_url [xx.xx.xx]: \' mail_server_url\n\n# Check All variable have a value\nif [ -z $mail_server_url ] || [ -z $letsencrypt_email ]\nthen\n      echo run script again please insert all value. do not miss any value\nelse\n\n# Installation start\n# Stop the jetty or nginx service at Zimbra level\nsu - zimbra -c \'zmproxyctl stop\'\nsu - zimbra -c \'zmmailboxdctl stop\'\n\n# Install git and letsencrypt\ncd /opt/\napt-get install git\ngit clone https://github.com/letsencrypt/letsencrypt\ncd letsencrypt\n\n# Get SSL certificate\n./letsencrypt-auto certonly --standalone --non-interactive --agree-tos --email $letsencrypt_email -d $mail_server_url --hsts\ncd /etc/letsencrypt/live/$mail_server_url\ncat <<EOF >>chain.pem\n-----BEGIN CERTIFICATE-----\nMIIDSjCCAjKgAwIBAgIQRK+wgNajJ7qJMDmGLvhAazANBgkqhkiG9w0BAQUFADA/\nMSQwIgYDVQQKExtEaWdpdGFsIFNpZ25hdHVyZSBUcnVzdCBDby4xFzAVBgNVBAMT\nDkRTVCBSb290IENBIFgzMB4XDTAwMDkzMDIxMTIxOVoXDTIxMDkzMDE0MDExNVow\nPzEkMCIGA1UEChMbRGlnaXRhbCBTaWduYXR1cmUgVHJ1c3QgQ28uMRcwFQYDVQQD\nEw5EU1QgUm9vdCBDQSBYMzCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEB\nAN+v6ZdQCINXtMxiZfaQguzH0yxrMMpb7NnDfcdAwRgUi+DoM3ZJKuM/IUmTrE4O\nrz5Iy2Xu/NMhD2XSKtkyj4zl93ewEnu1lcCJo6m67XMuegwGMoOifooUMM0RoOEq\nOLl5CjH9UL2AZd+3UWODyOKIYepLYYHsUmu5ouJLGiifSKOeDNoJjj4XLh7dIN9b\nxiqKqy69cK3FCxolkHRyxXtqqzTWMIn/5WgTe1QLyNau7Fqckh49ZLOMxt+/yUFw\n7BZy1SbsOFU5Q9D8/RhcQPGX69Wam40dutolucbY38EVAjqr2m7xPi71XAicPNaD\naeQQmxkqtilX4+U9m5/wAl0CAwEAAaNCMEAwDwYDVR0TAQH/BAUwAwEB/zAOBgNV\nHQ8BAf8EBAMCAQYwHQYDVR0OBBYEFMSnsaR7LHH62+FLkHX/xBVghYkQMA0GCSqG\nSIb3DQEBBQUAA4IBAQCjGiybFwBcqR7uKGY3Or+Dxz9LwwmglSBd49lZRNI+DT69\nikugdB/OEIKcdBodfpga3csTS7MgROSR6cz8faXbauX+5v3gTt23ADq1cEmv8uXr\nAvHRAosZy5Q6XkjEGB5YGV8eAlrwDPGxrancWYaLbumR9YbK+rlmM6pZW87ipxZz\nR8srzJmwN0jP41ZL9c8PDHIyh8bwRLtTcm1D9SZImlJnt1ir/md2cXjbDaJWFBM5\nJDGFoqgCWjBH4d1QB7wCCZAA62RjYJsWvIjJEubSfZGL+T0yjWW06XyxV3bqxbYo\nOb8VZRzI9neWagqNdwvYkQsEjgfbKbYK7p2CNTUQ\n-----END CERTIFICATE-----\nEOF\n\n# Verify commercial certificate\nmkdir /opt/zimbra/ssl/letsencrypt\ncp /etc/letsencrypt/live/$mail_server_url/* /opt/zimbra/ssl/letsencrypt/\nchown zimbra:zimbra /opt/zimbra/ssl/letsencrypt/*\nls -la /opt/zimbra/ssl/letsencrypt/\nsu - zimbra -c \'cd /opt/zimbra/ssl/letsencrypt/ && /opt/zimbra/bin/zmcertmgr verifycrt comm privkey.pem cert.pem chain.pem\'\n\n# Deploy the new Let\'s Encrypt SSL certificate\ncp -a /opt/zimbra/ssl/zimbra /opt/zimbra/ssl/zimbra.$(date ""+%Y%m%d"")\ncp /opt/zimbra/ssl/letsencrypt/privkey.pem /opt/zimbra/ssl/zimbra/commercial/commercial.key\nsudo chown zimbra:zimbra /opt/zimbra/ssl/zimbra/commercial/commercial.key\nsu - zimbra -c \'cd /opt/zimbra/ssl/letsencrypt/ && /opt/zimbra/bin/zmcertmgr deploycrt comm cert.pem chain.pem\'\n\n# Restart Zimbra\nsu - zimbra -c \'zmcontrol restart\'\n\n# setting auto https redirect\ncd /opt && touch https-redirect.sh && chown zimbra:zimbra https-redirect.sh && chmod +x https-redirect.sh\ncat <<EOF >>/opt/https-redirect.sh\nzmprov ms $mail_server_url zimbraReverseProxyMailMode redirect\nEOF\nsu - zimbra -c \'/opt/https-redirect.sh\'\nrm /opt/https-redirect.sh\nif\n']"
780,6750,6673,CC BY-SA 4.0,2019-04-01T18:09:24.193,"<p>In general, I would not recommend scraping version numbers and download URLs from websites.  You will end up having to modify your scripts when they inevitably end up breaking &mdash; I have learned this the hard way time and time again.</p>

<p>For example, take the following script I wrote in 2016 to scrape the latest Tomcat version:</p>

<pre class=""lang-sh prettyprint-override""><code>curl https://tomcat.apache.org/whichversion.html | awk -n '
/class=""detail-table""/ {
    phase = 1
}
phase == 1 &amp;&amp; /&lt;th&gt;/ {
    target_column++
    if (/Actual release revision/) phase = 2
}
phase == 2 &amp;&amp; /&lt;tr&gt;/ {
    current_column = 0
}
phase == 2 &amp;&amp; /&lt;td&gt;/ {
    current_column++
}
phase == 2 &amp;&amp; current_column == target_column &amp;&amp; !/alpha|beta|superceded/ {
    print substr($0, match($0, /[0-9]+\.[0-9]+\.[0-9]+/), RLENGTH)
    exit
}'
</code></pre>

<p>Unfortunately, that script <strong>no longer works</strong>, and I do not know when it broke.  No amount of fancy scripting will save you from unexpected structural changes to a website you are scraping.</p>

<p>Sure, maybe a little bit of finagling will fix this one particular script, but if you try to download all your dependencies this way, you'll be playing catch-up till the end of time.  Aim for a solution that you only need to code once.</p>
",13190,2019-04-01T18:09:24.193,"['curl https://tomcat.apache.org/whichversion.html | awk -n \'\n/class=""detail-table""/ {\n    phase = 1\n}\nphase == 1 && /<th>/ {\n    target_column++\n    if (/Actual release revision/) phase = 2\n}\nphase == 2 && /<tr>/ {\n    current_column = 0\n}\nphase == 2 && /<td>/ {\n    current_column++\n}\nphase == 2 && current_column == target_column && !/alpha|beta|superceded/ {\n    print substr($0, match($0, /[0-9]+\\.[0-9]+\\.[0-9]+/), RLENGTH)\n    exit\n}\'\n']"
781,6752,6420,CC BY-SA 4.0,2019-04-01T22:20:11.107,"<p>I was unable to find a way to configure the build to behave like I wanted. Instead I needed to start using the TeamCity API to achieve this.</p>

<p>In the <code>build.sh</code> and <code>test.sh</code> file that TC runs, I extended the failure function (simple bash function we call whenever our build script fails):</p>

<pre><code>teamcityFailure () {
    . ./cancel_build_chain.sh
    echo ""##teamcity[buildProblem description='$1']""
    exit 1
}
</code></pre>

<p>This now calls off to this new <code>cancel_build_chain.sh</code> script, which looks something like this:</p>

<pre><code>#!/bin/bash

teamcityProgress () {
    echo ""##teamcity[progressMessage '$1']""
}

teamcityProgress ""Build step has failed, attempting to cancel the rest of the build chain...""

BUILD_ID=$TEAMCITY_BUILD_ID # passed in from build chain configuration

# Use the current failed step ID to query for the snapshotDependency ""from:"" here - which returns the final ""docker publish"" step
FINAL_STEP_DATA=$(curl --silent --request GET \
    ""https://teamcity/app/rest/builds/project:MyProjectName,snapshotDependency:(from:(id:$BUILD_ID),includeInitial:true),defaultFilter:false"" \
    --header ""Content-Type: application/xml"""")

# From the ""docker publish"" step, parse the XML and fetch out all dependent step IDs. One will be this current step, the others will be its sibling steps
# We do this twice, once for queued steps, and once for currently running steps. This is because we need to cancel running vs queued builds differently.
QUEUED_DEPENDENT_STEP_IDS=$(echo $FINAL_STEP_DATA \
 | grep -Eo '&lt;snapshot-dependencies.+&lt;build id=""[0-9]+"".+state=""queued""' \
 | grep -Eo 'id=""([0-9]+)""' \
 | grep -Eo '[0-9]+')

# Now remove the current step ID
QUEUED_DEPENDENT_STEP_IDS=${QUEUED_DEPENDENT_STEP_IDS/$BUILD_ID/}

# trim leading / trailing whitespace
QUEUED_DEPENDENT_STEP_IDS=QUEUED_DEPENDENT_STEP_IDS | sed 's/ *$//'

RUNNING_DEPENDENT_STEP_IDS=$(echo $FINAL_STEP_DATA \
 | grep -Eo '&lt;snapshot-dependencies.+&lt;build id=""[0-9]+"".+state=""running""' \
 | grep -Eo 'id=""([0-9]+)""' \
 | grep -Eo '[0-9]+')

# Now remove the current step ID
RUNNING_DEPENDENT_STEP_IDS=${RUNNING_DEPENDENT_STEP_IDS/$BUILD_ID/}

# trim leading / trailing whitespace
RUNNING_DEPENDENT_STEP_IDS=RUNNING_DEPENDENT_STEP_IDS | sed 's/ *$//'

for DEP_ID in $QUEUED_DEPENDENT_STEP_IDS
do
    teamcityProgress ""Cancelling queued build step $DEP_ID""
    curl --silent --request POST \
        ""https://teamcity/app/rest/buildQueue/project:MyProjectName,id:$DEP_ID"" \
        --data ""&lt;buildCancelRequest comment='Another part of the build chain failed so this sibling step was cancelled.' readdIntoQueue='false' /&gt;"" \
        --header ""Content-Type: application/xml""
done

for DEP_ID in $RUNNING_DEPENDENT_STEP_IDS
do
    teamcityProgress ""Cancelling running build step $DEP_ID""
    curl --silent --request POST \
        ""https://teamcity/app/rest/builds/project:MyProjectName,id:$DEP_ID"" \
        --data ""&lt;buildCancelRequest comment='Another part of the build chain failed so this sibling step was cancelled.' readdIntoQueue='false' /&gt;"" \
        --header ""Content-Type: application/xml""
done
</code></pre>

<p>Not super elegant but it gets the job done and prevents build agents sitting there running build steps for builds which have already failed.</p>
",12516,2019-04-01T22:20:11.107,"['teamcityFailure () {\n    . ./cancel_build_chain.sh\n    echo ""##teamcity[buildProblem description=\'$1\']""\n    exit 1\n}\n', '#!/bin/bash\n\nteamcityProgress () {\n    echo ""##teamcity[progressMessage \'$1\']""\n}\n\nteamcityProgress ""Build step has failed, attempting to cancel the rest of the build chain...""\n\nBUILD_ID=$TEAMCITY_BUILD_ID # passed in from build chain configuration\n\n# Use the current failed step ID to query for the snapshotDependency ""from:"" here - which returns the final ""docker publish"" step\nFINAL_STEP_DATA=$(curl --silent --request GET \\\n    ""https://teamcity/app/rest/builds/project:MyProjectName,snapshotDependency:(from:(id:$BUILD_ID),includeInitial:true),defaultFilter:false"" \\\n    --header ""Content-Type: application/xml"""")\n\n# From the ""docker publish"" step, parse the XML and fetch out all dependent step IDs. One will be this current step, the others will be its sibling steps\n# We do this twice, once for queued steps, and once for currently running steps. This is because we need to cancel running vs queued builds differently.\nQUEUED_DEPENDENT_STEP_IDS=$(echo $FINAL_STEP_DATA \\\n | grep -Eo \'<snapshot-dependencies.+<build id=""[0-9]+"".+state=""queued""\' \\\n | grep -Eo \'id=""([0-9]+)""\' \\\n | grep -Eo \'[0-9]+\')\n\n# Now remove the current step ID\nQUEUED_DEPENDENT_STEP_IDS=${QUEUED_DEPENDENT_STEP_IDS/$BUILD_ID/}\n\n# trim leading / trailing whitespace\nQUEUED_DEPENDENT_STEP_IDS=QUEUED_DEPENDENT_STEP_IDS | sed \'s/ *$//\'\n\nRUNNING_DEPENDENT_STEP_IDS=$(echo $FINAL_STEP_DATA \\\n | grep -Eo \'<snapshot-dependencies.+<build id=""[0-9]+"".+state=""running""\' \\\n | grep -Eo \'id=""([0-9]+)""\' \\\n | grep -Eo \'[0-9]+\')\n\n# Now remove the current step ID\nRUNNING_DEPENDENT_STEP_IDS=${RUNNING_DEPENDENT_STEP_IDS/$BUILD_ID/}\n\n# trim leading / trailing whitespace\nRUNNING_DEPENDENT_STEP_IDS=RUNNING_DEPENDENT_STEP_IDS | sed \'s/ *$//\'\n\nfor DEP_ID in $QUEUED_DEPENDENT_STEP_IDS\ndo\n    teamcityProgress ""Cancelling queued build step $DEP_ID""\n    curl --silent --request POST \\\n        ""https://teamcity/app/rest/buildQueue/project:MyProjectName,id:$DEP_ID"" \\\n        --data ""<buildCancelRequest comment=\'Another part of the build chain failed so this sibling step was cancelled.\' readdIntoQueue=\'false\' />"" \\\n        --header ""Content-Type: application/xml""\ndone\n\nfor DEP_ID in $RUNNING_DEPENDENT_STEP_IDS\ndo\n    teamcityProgress ""Cancelling running build step $DEP_ID""\n    curl --silent --request POST \\\n        ""https://teamcity/app/rest/builds/project:MyProjectName,id:$DEP_ID"" \\\n        --data ""<buildCancelRequest comment=\'Another part of the build chain failed so this sibling step was cancelled.\' readdIntoQueue=\'false\' />"" \\\n        --header ""Content-Type: application/xml""\ndone\n']"
782,6756,6730,CC BY-SA 4.0,2019-04-02T03:19:17.777,"<p>Finnaly, I found the solution, thanks to @simbo1905.</p>

<p>All that I need to fix that problem:
values.yaml Child Chart 1 (or two)</p>

<pre><code>postgresql:
  nameOverride: chart-1-postgres
</code></pre>

<p>In the Child Chart 2 <code>nameOverride</code> became to chart-2-postgres.</p>
",13146,2019-04-02T03:19:17.777,['postgresql:\n  nameOverride: chart-1-postgres\n']
783,6757,6637,CC BY-SA 4.0,2019-04-02T05:34:08.087,"<p>You can do this using <strong>perl</strong></p>

<p>For Example</p>

<pre><code>perl -pi -e ""s/server.address=localhost/server.address=${SERVER_ADDRESS}/g"" file_path
</code></pre>

<p>This command change server address value localhost to vaariable value.</p>

<p>Hope this works</p>
",11598,2019-04-02T05:34:08.087,"['perl -pi -e ""s/server.address=localhost/server.address=${SERVER_ADDRESS}/g"" file_path\n']"
784,6761,6747,CC BY-SA 4.0,2019-04-02T17:13:46.763,"<p>Just the way you can exit any stage prematurely by using <code>return</code> keyword, you can use the <code>return</code> keyword (outside of the stage) to exit the entire pipeline prematurely. You can re-use the <code>currentBuild.result</code> value outside of <code>Stage 4</code>. See below.</p>

<pre><code>node{
    withEnv([...]){
        stage('1'){
        ...
        }

        stage('2'){
        .....
        }

        if( env.BRANCH_NAME != 'master' ) {
            currentBuild.result = 'SUCCESS'
            return
        }

        stage('3'){
        ...
        }       
    }

    stage('4'){
        withEnv([...]){
            ...
        }
    }

    if(currentBuild.result == 'SUCCESS') {
        return //this will exit the pipeline
    }

    stage('5'){
        ...
    }

    stage('6'){
    ...
    }
}
</code></pre>
",6806,2019-04-02T17:13:46.763,"[""node{\n    withEnv([...]){\n        stage('1'){\n        ...\n        }\n\n        stage('2'){\n        .....\n        }\n\n        if( env.BRANCH_NAME != 'master' ) {\n            currentBuild.result = 'SUCCESS'\n            return\n        }\n\n        stage('3'){\n        ...\n        }       \n    }\n\n    stage('4'){\n        withEnv([...]){\n            ...\n        }\n    }\n\n    if(currentBuild.result == 'SUCCESS') {\n        return //this will exit the pipeline\n    }\n\n    stage('5'){\n        ...\n    }\n\n    stage('6'){\n    ...\n    }\n}\n""]"
785,6766,6764,CC BY-SA 4.0,2019-04-02T22:30:21.453,"<p>Unless I totally missed your question, roles are exactly what you need in this case. I'll use examples from my real world. My code below is just to illustrate my point (so it is not fully runnable, might contain errors and is not bullet proof rocket science: you will probably have to adapt/overcome tools limitations). But at least you'll be able to tell me if I got you wrong.</p>

<p>Let's say your servicing a large community of developers on different techs: java, php, nodejs, scala, python, ruby... needing some tools as well like apache, nginx, postgres, mysql, redis...</p>

<p>You have a role for each of these techs/tools, and possibly use existing ones from galaxy that you don't even have to write and that you can <a href=""https://www.vagrantup.com/docs/provisioning/ansible_common.html#galaxy_role_file"" rel=""nofollow noreferrer"">download at provisioning time</a>. These roles can possibly be controlled with vars to choose e.g. versions. (see vagrant provisionner config below)</p>

<p>Now, one way you can activate/deactivate roles in a play is with the use of <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html"" rel=""nofollow noreferrer"">tags</a></p>

<p>Your unique playbook could look something like this</p>

<pre><code>- name: Vagrant provisionning playbook
  hosts: all

  pre_tasks:
    # whatever you need to do before roles

  roles:
    - role: php
      tags: [php]
    - role: java
      tags: [java]
    - role: nginx
      tags: [nginx,php] # if you always deploy php with nginx
    - role: redis
      tags: [redis]
    # more roles here

    tasks:
      # Whatever tasks are needed to be played after roles
</code></pre>

<p>With such a structure, you can now configure your ansible provisioinner in vagrant <a href=""https://www.vagrantup.com/docs/provisioning/ansible_common.html#tags"" rel=""nofollow noreferrer"">defining the tags</a> and <a href=""https://www.vagrantup.com/docs/provisioning/ansible_intro.html#host-variables"" rel=""nofollow noreferrer"">specifying the vars</a> needed to provision with your single playbook.</p>

<pre><code>Vagrant.configure(2) do |config|

  config.vm define ""php_application"" do |php_application|

    # Some config for vm
    php_application.vm.provision ""ansible"" do |ansible| 
      ansible.playbook = ""playbook.yml""
      ansible.tags = ""php,nginx,untagged""
    end

  end

  # Host vars declared globally. You might be able to do
  # it on host by host basis but the doc does not specify it
  config.vm.provision ""ansible"" do |ansible|
    ansible.host_vars = {
      ""php_application"" =&gt; {""php_version"" =&gt; ""7.2""}
    }
  end
end 
</code></pre>

<p>Does this fit your needs ?</p>

<p>Note: if a single playbook is too much of a hassle, you can still use the roles and assemble in each playbook the techs/tools you need and reuse things that you will need in several places.</p>
",13111,2019-04-02T22:30:21.453,"['- name: Vagrant provisionning playbook\n  hosts: all\n\n  pre_tasks:\n    # whatever you need to do before roles\n\n  roles:\n    - role: php\n      tags: [php]\n    - role: java\n      tags: [java]\n    - role: nginx\n      tags: [nginx,php] # if you always deploy php with nginx\n    - role: redis\n      tags: [redis]\n    # more roles here\n\n    tasks:\n      # Whatever tasks are needed to be played after roles\n', 'Vagrant.configure(2) do |config|\n\n  config.vm define ""php_application"" do |php_application|\n\n    # Some config for vm\n    php_application.vm.provision ""ansible"" do |ansible| \n      ansible.playbook = ""playbook.yml""\n      ansible.tags = ""php,nginx,untagged""\n    end\n\n  end\n\n  # Host vars declared globally. You might be able to do\n  # it on host by host basis but the doc does not specify it\n  config.vm.provision ""ansible"" do |ansible|\n    ansible.host_vars = {\n      ""php_application"" => {""php_version"" => ""7.2""}\n    }\n  end\nend \n']"
786,6775,6774,CC BY-SA 4.0,2019-04-03T16:02:26.843,"<p>Is this what you're looking for?</p>

<pre><code>- hosts: all
  vars:
    bunch_of_specific_packages:
      - apache2
      - gcc
      - gedit
  tasks:
    - package:
        name: ""{{ item }}""
      loop: ""{{ bunch_of_specific_packages }}""
</code></pre>
",7715,2019-04-03T16:02:26.843,"['- hosts: all\n  vars:\n    bunch_of_specific_packages:\n      - apache2\n      - gcc\n      - gedit\n  tasks:\n    - package:\n        name: ""{{ item }}""\n      loop: ""{{ bunch_of_specific_packages }}""\n']"
787,6780,6779,CC BY-SA 4.0,2019-04-04T11:20:27.433,"<p>Well this seems to be a docker issue. It’s keeping a whole lot of dangling volumes.</p>

<p>check if you have some :</p>

<pre><code>docker volume ls -qf dangling=true
</code></pre>

<p>Get rid of them with :</p>

<pre><code>docker volume rm $(docker volume ls -qf dangling=true)
</code></pre>
",13258,2019-04-04T12:04:16.870,"['docker volume ls -qf dangling=true\n', 'docker volume rm $(docker volume ls -qf dangling=true)\n']"
788,6791,6789,CC BY-SA 4.0,2019-04-05T11:29:01.620,"<blockquote>
  <p>To append id_rsa.pub of a specific user from a remote ssh ServerA (no the controller machine ) to ServerB.</p>
</blockquote>

<p>1) Fetch the public keys from ServerA</p>

<pre><code>- host: ServerA
  vars:
    public_keys_dir: &lt;PUB_KEYS_DIR&gt;
    specific_user:
      - user1
      - user2
      - userN
  tasks:
    - name: Fetch pub keys
      fetch:
        src: ""/home/{{ item }}/.ssh/id_rsa.pub""
        dest: ""{{ public_keys_dir }}/{{ item }}-ServerA.id_rsa.pub""
        flat: yes
      loop: ""{{ specific_user }}""
</code></pre>

<p>2) Configure authorized keys at ServerB</p>

<pre><code>- host: ServerB
  vars:
    public_keys_dir: &lt;PUB_KEYS_DIR&gt;
    my_remote_user: admin
  tasks:
    - name: Set up authorized_keys
      authorized_key:
        user: ""{{ my_remote_user }}""
        key: ""{{ lookup('file', '{{ item }}')}}""
      with_fileglob:
        - ""{{ public_keys_dir }}/*-ServerA.id_rsa.pub""
</code></pre>

<p>(not tested)</p>
",7715,2019-04-05T11:29:01.620,"['- host: ServerA\n  vars:\n    public_keys_dir: <PUB_KEYS_DIR>\n    specific_user:\n      - user1\n      - user2\n      - userN\n  tasks:\n    - name: Fetch pub keys\n      fetch:\n        src: ""/home/{{ item }}/.ssh/id_rsa.pub""\n        dest: ""{{ public_keys_dir }}/{{ item }}-ServerA.id_rsa.pub""\n        flat: yes\n      loop: ""{{ specific_user }}""\n', '- host: ServerB\n  vars:\n    public_keys_dir: <PUB_KEYS_DIR>\n    my_remote_user: admin\n  tasks:\n    - name: Set up authorized_keys\n      authorized_key:\n        user: ""{{ my_remote_user }}""\n        key: ""{{ lookup(\'file\', \'{{ item }}\')}}""\n      with_fileglob:\n        - ""{{ public_keys_dir }}/*-ServerA.id_rsa.pub""\n']"
789,6792,6789,CC BY-SA 4.0,2019-04-05T12:03:54.993,"<pre><code>---
# tasks file for passwordless
- name: Play to setup Passowrdless
  remote_user: ""{{ ssh_user }}""
  vars_prompt:
    - name: ""ssh_user""
      prompt: ""Please specify ssh user name""
      private: no
  hosts: all
  tasks:
  - name: Get pub key value from edgenode
    #hosts: edgenode
    command:
      cat $HOME/.ssh/id_rsa.pub
    register: pubkey
    changed_when: false
    when: ""'group_edgenode' in  group_names""

  - name: Print copyout value
    debug:
      msg: ""{{ pubkey.stdout }}""
    when: ""'group_edgenode' in  group_names""

  - name: Append pub key value to datanodes
    #hosts: datanode
    lineinfile:
      path: $HOME/.ssh/authorized_keys
      #line: ""{{ pubkey.stdout }}""
      #line: ""{{ hostvars['192.168.0.103']['pubkey']['stdout'] }}""
      line: ""{{ hostvars[item]['pubkey']['stdout'] }}""
      #line: ""{{ groups['group_datanode'] | map('extract',hostvars, stdout) }}""
      state: present
      owner: ""{{ ssh_user }}""
      #group: domain
      mode: 0600
      backup: yes
      insertafter: EOF
    #when: inventory_hostname in groups['datanode']
    with_items: ""{{ groups['group_edgenode'] }}""
    when: ""'group_datanode' in  group_names""
</code></pre>

<p>In this solution edgenodes are ServerA while datanodes are ServerB.
Its tested and is working fine.</p>
",1133,2019-04-10T07:25:35.303,"['---\n# tasks file for passwordless\n- name: Play to setup Passowrdless\n  remote_user: ""{{ ssh_user }}""\n  vars_prompt:\n    - name: ""ssh_user""\n      prompt: ""Please specify ssh user name""\n      private: no\n  hosts: all\n  tasks:\n  - name: Get pub key value from edgenode\n    #hosts: edgenode\n    command:\n      cat $HOME/.ssh/id_rsa.pub\n    register: pubkey\n    changed_when: false\n    when: ""\'group_edgenode\' in  group_names""\n\n  - name: Print copyout value\n    debug:\n      msg: ""{{ pubkey.stdout }}""\n    when: ""\'group_edgenode\' in  group_names""\n\n  - name: Append pub key value to datanodes\n    #hosts: datanode\n    lineinfile:\n      path: $HOME/.ssh/authorized_keys\n      #line: ""{{ pubkey.stdout }}""\n      #line: ""{{ hostvars[\'192.168.0.103\'][\'pubkey\'][\'stdout\'] }}""\n      line: ""{{ hostvars[item][\'pubkey\'][\'stdout\'] }}""\n      #line: ""{{ groups[\'group_datanode\'] | map(\'extract\',hostvars, stdout) }}""\n      state: present\n      owner: ""{{ ssh_user }}""\n      #group: domain\n      mode: 0600\n      backup: yes\n      insertafter: EOF\n    #when: inventory_hostname in groups[\'datanode\']\n    with_items: ""{{ groups[\'group_edgenode\'] }}""\n    when: ""\'group_datanode\' in  group_names""\n']"
790,6798,6784,CC BY-SA 4.0,2019-04-06T07:25:28.610,"<p>Defining default value for ansible variables and overriding them via ansible playbooks can be achieved using Jinja2 templating.</p>

<pre><code>- name: Create a new user
  user:
    name: ""{{ username_variable | default('default_value') }}""
    password: ""{{ password_variable | default('default_value') }}""
    state: present
</code></pre>

<p>Then if these variables are passed from the playbook it will be used, or else the default values.</p>

<pre><code>  roles:
    - role: common
      vars:
        username_variable: ""frank""
        password_variable: ""/bib/zsh""
</code></pre>
",4128,2019-04-06T07:25:28.610,"['- name: Create a new user\n  user:\n    name: ""{{ username_variable | default(\'default_value\') }}""\n    password: ""{{ password_variable | default(\'default_value\') }}""\n    state: present\n', '  roles:\n    - role: common\n      vars:\n        username_variable: ""frank""\n        password_variable: ""/bib/zsh""\n']"
791,6799,6785,CC BY-SA 4.0,2019-04-06T13:05:16.287,"<p>From your container's perspective <code>localhost</code> is the container itself.  If you want to communicate with the host machine, you will need the IP address of the host itself.  Depending on your Operating System and Docker configuration, this IP address varies.</p>

<p><strong>edit</strong> <code>host.docker.internal</code> is recommended from 18.03 onward. </p>

<p>Here is an example of communicating with the Docker host from a container on Mac:</p>

<pre><code># Dockerfile

FROM python:3.7-alpine

RUN ping host.docker.internal -c 4
</code></pre>

<pre><code>sending build context to Docker daemon  562.7kB
Step 1/2 : FROM python:3.7-alpine
 ---&gt; a93594ce93e7
Step 2/2 : RUN ping host.docker.internal -c 4
 ---&gt; Running in 54ce465f7386
PING host.docker.internal (192.168.65.2): 56 data bytes
64 bytes from 192.168.65.2: seq=0 ttl=37 time=0.735 ms
64 bytes from 192.168.65.2: seq=1 ttl=37 time=1.898 ms
64 bytes from 192.168.65.2: seq=2 ttl=37 time=0.720 ms
64 bytes from 192.168.65.2: seq=3 ttl=37 time=0.643 ms

--- host.docker.internal ping statistics ---
4 packets transmitted, 4 packets received, 0% packet loss
round-trip min/avg/max = 0.643/0.999/1.898 ms
Removing intermediate container 54ce465f7386
 ---&gt; b2f32c26a135
Successfully built b2f32c26a135
</code></pre>
",6258,2019-04-06T13:16:51.583,"['# Dockerfile\n\nFROM python:3.7-alpine\n\nRUN ping host.docker.internal -c 4\n', 'sending build context to Docker daemon  562.7kB\nStep 1/2 : FROM python:3.7-alpine\n ---> a93594ce93e7\nStep 2/2 : RUN ping host.docker.internal -c 4\n ---> Running in 54ce465f7386\nPING host.docker.internal (192.168.65.2): 56 data bytes\n64 bytes from 192.168.65.2: seq=0 ttl=37 time=0.735 ms\n64 bytes from 192.168.65.2: seq=1 ttl=37 time=1.898 ms\n64 bytes from 192.168.65.2: seq=2 ttl=37 time=0.720 ms\n64 bytes from 192.168.65.2: seq=3 ttl=37 time=0.643 ms\n\n--- host.docker.internal ping statistics ---\n4 packets transmitted, 4 packets received, 0% packet loss\nround-trip min/avg/max = 0.643/0.999/1.898 ms\nRemoving intermediate container 54ce465f7386\n ---> b2f32c26a135\nSuccessfully built b2f32c26a135\n']"
792,6814,6813,CC BY-SA 4.0,2019-04-08T13:55:27.557,"<p>Disclaimer: This is very much an anti-pattern since it looks like you are trying to create something similar to a VM, or at the very least a pet that you modify in place rather than making all your changes via code and redeploying a new container for each change.</p>

<p>That disclaimer aside, you just need a command that will hang indefinitely. The most common one I've seen in a <code>tail -f /dev/null</code>, e.g.:</p>

<pre><code>FROM ubuntu:18.04

RUN apt update \
 &amp;&amp; apt install -y \
      cmake \
      curl \
      git \
      jq \
      libasound2-dev \
      libglu1-mesa-dev \
      libgtk2.0-dev \
      libjack-jackd2-dev \
      libx11-dev \
      libxcursor-dev \
      libxinerama-dev \
      libxi-dev \
      libxrandr-dev \
      zlib1g-dev

CMD [ ""tail"", ""-f"", ""/dev/null"" ]
</code></pre>

<p>I've also rearranged the Dockerfile to merge the update and install commands, this is a best practice for Dockerfile's since it avoids having a stale <code>apt update</code> command used from the cache when you change the <code>apt install</code> command months later. Also, putting each package on a separate line is better for version control to see what changed if you add a single new package.</p>

<p>When using this, you would <code>docker run -d --name your_container your_image</code> to run it in the background, and then <code>docker exec -it your_container /bin/bash</code> to open a shell.</p>
",7730,2019-04-08T13:55:27.557,"['FROM ubuntu:18.04\n\nRUN apt update \\\n && apt install -y \\\n      cmake \\\n      curl \\\n      git \\\n      jq \\\n      libasound2-dev \\\n      libglu1-mesa-dev \\\n      libgtk2.0-dev \\\n      libjack-jackd2-dev \\\n      libx11-dev \\\n      libxcursor-dev \\\n      libxinerama-dev \\\n      libxi-dev \\\n      libxrandr-dev \\\n      zlib1g-dev\n\nCMD [ ""tail"", ""-f"", ""/dev/null"" ]\n']"
793,6830,6828,CC BY-SA 4.0,2019-04-09T11:58:33.450,"<p>There's no &quot;easiest&quot; way per se, there's the better way for you.
I'd recommend using a configuration management tool like Chef or Puppet (for a pull model) for which there's already resources to configure and handle logstash restarts.</p>
<p>That said logstash is able to watch its config file and reload it itself, quoting elastic.co documentation:</p>
<blockquote>
<p>Starting with Logstash 2.3, you can set Logstash to detect and reload configuration changes automatically.</p>
<p>To enable automatic config reloading, start Logstash with the <code>--config.reload.automatic</code> (or <code>-r</code>) command-line option specified. For example:</p>
<pre><code>bin/logstash –f apache.config --config.reload.automatic
</code></pre>
</blockquote>
<p>So you may just set a crontab to <code>git pull</code> your repository periodically and have logstash reload itself.</p>
",13,2019-04-09T11:58:33.450,['bin/logstash –f apache.config --config.reload.automatic\n']
794,6831,2731,CC BY-SA 4.0,2019-04-09T13:13:10.790,"<p>Here is an adapted python script, thus having an OS independant solution: <a href=""https://github.com/NotGlop/docker-drag"" rel=""nofollow noreferrer"">docker-drag</a></p>

<p>Use it like that, and it will create a TAR archive that you will be able to import using docker load :</p>

<pre><code>python docker_pull.py hello-world
python docker_pull.py alpine:3.9
python docker_pull.py kalilinux/kali-linux-docker
</code></pre>
",13365,2019-04-09T13:17:13.340,['python docker_pull.py hello-world\npython docker_pull.py alpine:3.9\npython docker_pull.py kalilinux/kali-linux-docker\n']
795,6833,6832,CC BY-SA 4.0,2019-04-09T15:27:00.707,"<p>Another approach that I found uses the <code>include_role</code> directive. So instead of the playbook being: </p>

<pre><code>---
- hosts: M2
  - roles:
    - role: apache2
</code></pre>

<p>It becomes:</p>

<pre><code>---
- hosts: M2
  - tasks:
    - include_role: apache2
</code></pre>

<p>Then I can add tasks directly after that apache2 task that configure apache2:</p>

<pre><code>---
- hosts: M2
  - tasks:
    - include_role: apache2

    - copy:
        # etc
</code></pre>
",13217,2019-04-09T15:27:00.707,"['---\n- hosts: M2\n  - roles:\n    - role: apache2\n', '---\n- hosts: M2\n  - tasks:\n    - include_role: apache2\n', '---\n- hosts: M2\n  - tasks:\n    - include_role: apache2\n\n    - copy:\n        # etc\n']"
796,6837,6781,CC BY-SA 4.0,2019-04-10T00:18:31.483,"<p>It's recommended that you use a convention of prefixing your grouped references (like branches) with ""folder"" prefixes.</p>

<p>For example, when you create sprint branches, create them with the names:</p>

<pre><code>sprints/sprint01
sprints/sprint02
sprints/sprint03
</code></pre>

<p>Then, configure your build trigger <code>Include</code> filters with this prefix:</p>

<p><code>sprints/*</code></p>

<p>... and then an <code>Exclude</code> filter for <code>master</code>, since by default it is also included.</p>

<p>Once configured, this should build only the sprint branch (topic branch) that was committed to.</p>

<p>Reference: <a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/build/ci-build-git?view=azure-devops&amp;tabs=designer"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/devops/pipelines/build/ci-build-git?view=azure-devops&amp;tabs=designer</a></p>
",13112,2019-04-10T00:18:31.483,['sprints/sprint01\nsprints/sprint02\nsprints/sprint03\n']
797,6845,6811,CC BY-SA 4.0,2019-04-10T14:00:09.490,"<p>Not sure if you did, but put the vars into double quotes:</p>

<pre><code>... ""${BUILD_CAUSE}""
</code></pre>
",13391,2019-04-10T14:00:09.490,"['... ""${BUILD_CAUSE}""\n']"
798,6866,6539,CC BY-SA 4.0,2019-04-15T10:59:58.243,"<p><code>register</code> will always populate your registered var even when the task is skipped, e.g. you will end up with something like the following:</p>

<pre><code>""kafkaip"": {
    ""changed"": false,
    ""skip_reason"": ""Conditional result was False"",
    ""skipped"": true
}
</code></pre>

<p>Since only the commands differ depending on your env, I would store the command in a variable and then execute it, something like the following.</p>

<pre><code>- name: ""Set command for env &lt;&gt; QA""
  set_fact:
    get_ip_command: &gt;-
      aws cloudformation describe-stacks
      --stack-name ""{{ stack_kafka }}""
      --query ""Stacks[*].Outputs[?OutputKey=='KafkaLink'].OutputValue""
  when:
    - stack_kafka is defined
    - ( deployment_env != ""QA"" )

- name: ""Set command for env = QA""
  set_fact:
    get_ip_command: &gt;-
      aws ec2 describe-instances
      --filter ""Name=tag:StackName,Values=KafkaCluster""
      --query 'Reservations[].Instances[].PrivateIpAddress'
      --output text
  when:
    - stack_kafka is defined
    - ( deployment_env == ""QA"" )

- name: Get the Kafka InstancesPrivateIps
  shell: ""{{ get_ip_command }}""
  register: kafkaip
  when: stack_kafka is defined

- name: Register kafka_host
  set_fact:
    kafka_host: ""{{ kafkaip.stdout }}""
  when: stack_kafka is defined

</code></pre>

<ul>
<li><strong>Note1</strong>: there is an output redirection in your QA command which will prevent capturing the output as you wish, I left it out in my example.</li>
<li><strong>Note2</strong>: I used <code>set_fact</code> to create the command variable but you can put that in your vars or your inventory to have a leaner playbook.</li>
</ul>
",13111,2019-04-15T10:59:58.243,"['""kafkaip"": {\n    ""changed"": false,\n    ""skip_reason"": ""Conditional result was False"",\n    ""skipped"": true\n}\n', '- name: ""Set command for env <> QA""\n  set_fact:\n    get_ip_command: >-\n      aws cloudformation describe-stacks\n      --stack-name ""{{ stack_kafka }}""\n      --query ""Stacks[*].Outputs[?OutputKey==\'KafkaLink\'].OutputValue""\n  when:\n    - stack_kafka is defined\n    - ( deployment_env != ""QA"" )\n\n- name: ""Set command for env = QA""\n  set_fact:\n    get_ip_command: >-\n      aws ec2 describe-instances\n      --filter ""Name=tag:StackName,Values=KafkaCluster""\n      --query \'Reservations[].Instances[].PrivateIpAddress\'\n      --output text\n  when:\n    - stack_kafka is defined\n    - ( deployment_env == ""QA"" )\n\n- name: Get the Kafka InstancesPrivateIps\n  shell: ""{{ get_ip_command }}""\n  register: kafkaip\n  when: stack_kafka is defined\n\n- name: Register kafka_host\n  set_fact:\n    kafka_host: ""{{ kafkaip.stdout }}""\n  when: stack_kafka is defined\n\n']"
799,6870,3290,CC BY-SA 4.0,2019-04-15T20:58:33.923,"<p>you can use</p>

<pre>aws ec2 describe-instances --instance-ids (your Instance id) --query ""Reservations[].Instances[].SecurityGroups[].GroupId[]"" --output text</pre>

<p>replace <pre>(your instance id)</pre> with the specific instance id you are looking for.</p>
",13482,2019-04-15T20:58:33.923,"['aws ec2 describe-instances --instance-ids (your Instance id) --query ""Reservations[].Instances[].SecurityGroups[].GroupId[]"" --output text', '(your instance id)']"
800,6872,6868,CC BY-SA 4.0,2019-04-16T09:51:08.050,"<p>I found the solution, eventually it was just a volume issue, I had to add a specific line for modules :  </p>

<pre><code>volumes:
      - ./server:/app/server
      - /app/server/node_modules
</code></pre>

<p>After that I no longer got the ""Can't find module"" error<br>
Still not sure what the impact of this is though</p>
",13474,2019-04-16T09:51:08.050,['volumes:\n      - ./server:/app/server\n      - /app/server/node_modules\n']
801,6887,1017,CC BY-SA 4.0,2019-04-17T17:52:37.413,"<p>Following Vagrant file address this problem.</p>

<p>You can get all supporting key files along with this vagrant file at <a href=""https://github.com/malyabee/IaaC/tree/master/ansible_lab"" rel=""nofollow noreferrer"">https://github.com/malyabee/IaaC/tree/master/ansible_lab</a></p>

<pre><code>$commonscript = &lt;&lt;-SCRIPT
sudo yum update -y
sudo yum install python2 epel-release -y
sudo yum install -y ansible
sudo echo ""192.168.22.10    ansiblecontroller.example.com ansiblecontroller"" &gt;&gt; /etc/hosts
sudo echo ""192.168.22.11   node01.example.com   node01"" &gt;&gt; /etc/hosts
sudo echo ""192.168.22.12   node02.example.com      node02"" &gt;&gt; /etc/hosts
SCRIPT

$nodescript = &lt;&lt;-SCRIPT
cat /vagrant/ansible_lab.pub &gt;&gt; /home/vagrant/.ssh/authorized_keys
SCRIPT

$ansiblescript = &lt;&lt;-SCRIPT
sudo yum install ansible -y
sudo cp -r /vagrant/ansible_lab /home/vagrant/.ssh/id_rsa
sudo chmod 400  /home/vagrant/.ssh/id_rsa
sudo chown vagrant:vagrant /home/vagrant/.ssh/id_rsa
SCRIPT

Vagrant.configure(""2"") do |config|
  config.vm.provision ""shell"", inline: ""echo Hello""

  config.vm.define ""ansiblecontroller"" do |ansiblecontroller|
    ansiblecontroller.vm.box = ""centos/7""
    ansiblecontroller.vm.provider ""virtualbox"" do |v|
          v.memory = 512
          v.cpus = 1
       end
    ansiblecontroller.vm.network ""private_network"", ip: ""192.168.22.10"", virtualbox__intnet: ""mynetwork01""
    ansiblecontroller.vm.hostname = ""ansiblecontroller.example.com""
    # Installing required packages for ansible controller node
    ansiblecontroller.vm.provision ""shell"", inline: $commonscript
    ansiblecontroller.vm.provision ""shell"", inline: $ansiblescript
  end

  config.vm.define ""node01"" do |node01|
    node01.vm.box = ""centos/7""
    node01.vm.provider ""virtualbox"" do |v|
          v.memory = 512
          v.cpus = 1
       end
    node01.vm.network ""private_network"", ip: ""192.168.22.11"", virtualbox__intnet: ""mynetwork01""
    node01.vm.hostname = ""node01.example.com""
    # Installing required packages for  node01
    node01.vm.provision ""shell"", inline: $commonscript
    node01.vm.provision ""shell"", inline: $nodescript
  end
  config.vm.define ""node02"" do |node02|
    node02.vm.box = ""centos/7""
    node02.vm.provider ""virtualbox"" do |v|
          v.memory = 512
          v.cpus = 1
       end
    node02.vm.network ""private_network"", ip: ""192.168.22.12"", virtualbox__intnet: ""mynetwork01""
    node02.vm.hostname = ""node02.example.com""
    # Installing required packages for  node01
    node02.vm.provision ""shell"", inline: $commonscript
    node02.vm.provision ""shell"", inline: $nodescript
  end
end
</code></pre>
",13523,2019-04-17T17:52:37.413,"['$commonscript = <<-SCRIPT\nsudo yum update -y\nsudo yum install python2 epel-release -y\nsudo yum install -y ansible\nsudo echo ""192.168.22.10    ansiblecontroller.example.com ansiblecontroller"" >> /etc/hosts\nsudo echo ""192.168.22.11   node01.example.com   node01"" >> /etc/hosts\nsudo echo ""192.168.22.12   node02.example.com      node02"" >> /etc/hosts\nSCRIPT\n\n$nodescript = <<-SCRIPT\ncat /vagrant/ansible_lab.pub >> /home/vagrant/.ssh/authorized_keys\nSCRIPT\n\n$ansiblescript = <<-SCRIPT\nsudo yum install ansible -y\nsudo cp -r /vagrant/ansible_lab /home/vagrant/.ssh/id_rsa\nsudo chmod 400  /home/vagrant/.ssh/id_rsa\nsudo chown vagrant:vagrant /home/vagrant/.ssh/id_rsa\nSCRIPT\n\nVagrant.configure(""2"") do |config|\n  config.vm.provision ""shell"", inline: ""echo Hello""\n\n  config.vm.define ""ansiblecontroller"" do |ansiblecontroller|\n    ansiblecontroller.vm.box = ""centos/7""\n    ansiblecontroller.vm.provider ""virtualbox"" do |v|\n          v.memory = 512\n          v.cpus = 1\n       end\n    ansiblecontroller.vm.network ""private_network"", ip: ""192.168.22.10"", virtualbox__intnet: ""mynetwork01""\n    ansiblecontroller.vm.hostname = ""ansiblecontroller.example.com""\n    # Installing required packages for ansible controller node\n    ansiblecontroller.vm.provision ""shell"", inline: $commonscript\n    ansiblecontroller.vm.provision ""shell"", inline: $ansiblescript\n  end\n\n  config.vm.define ""node01"" do |node01|\n    node01.vm.box = ""centos/7""\n    node01.vm.provider ""virtualbox"" do |v|\n          v.memory = 512\n          v.cpus = 1\n       end\n    node01.vm.network ""private_network"", ip: ""192.168.22.11"", virtualbox__intnet: ""mynetwork01""\n    node01.vm.hostname = ""node01.example.com""\n    # Installing required packages for  node01\n    node01.vm.provision ""shell"", inline: $commonscript\n    node01.vm.provision ""shell"", inline: $nodescript\n  end\n  config.vm.define ""node02"" do |node02|\n    node02.vm.box = ""centos/7""\n    node02.vm.provider ""virtualbox"" do |v|\n          v.memory = 512\n          v.cpus = 1\n       end\n    node02.vm.network ""private_network"", ip: ""192.168.22.12"", virtualbox__intnet: ""mynetwork01""\n    node02.vm.hostname = ""node02.example.com""\n    # Installing required packages for  node01\n    node02.vm.provision ""shell"", inline: $commonscript\n    node02.vm.provision ""shell"", inline: $nodescript\n  end\nend\n']"
802,6889,6882,CC BY-SA 4.0,2019-04-17T19:16:53.993,"<p>You have a GIT permissions issue (you cannot write to files and or directory):</p>

<p><a href=""https://stackoverflow.com/questions/11774397/git-push-error-unable-to-unlink-old-permission-denied"">https://stackoverflow.com/questions/11774397/git-push-error-unable-to-unlink-old-permission-denied</a></p>

<pre><code>stderr:
error: unable to unlink old 'node_modules/express-session/HISTORY.md': Permission denied
error: unable to unlink old 'node_modules/express-session/LICENSE': Permission denied
error: unable to unlink old 'node_modules/express-session/README.md': Permission denied
error: unable to unlink old 'node_modules/express-session/index.js': Permission denied
error: unable to unlink old 'node_modules/express-session/package.json': Permission denied
error: unable to unlink old 'node_modules/express-session/session/cookie.js': Permission denied
error: unable to unlink old 'node_modules/express-session/session/memory.js': Permission denied
error: unable to unlink old 'node_modules/express-session/session/session.js': Permission denied
error: unable to unlink old 'node_modules/express-session/session/store.js': Permission denied
</code></pre>
",6579,2019-04-17T19:16:53.993,"[""stderr:\nerror: unable to unlink old 'node_modules/express-session/HISTORY.md': Permission denied\nerror: unable to unlink old 'node_modules/express-session/LICENSE': Permission denied\nerror: unable to unlink old 'node_modules/express-session/README.md': Permission denied\nerror: unable to unlink old 'node_modules/express-session/index.js': Permission denied\nerror: unable to unlink old 'node_modules/express-session/package.json': Permission denied\nerror: unable to unlink old 'node_modules/express-session/session/cookie.js': Permission denied\nerror: unable to unlink old 'node_modules/express-session/session/memory.js': Permission denied\nerror: unable to unlink old 'node_modules/express-session/session/session.js': Permission denied\nerror: unable to unlink old 'node_modules/express-session/session/store.js': Permission denied\n""]"
803,6901,6899,CC BY-SA 4.0,2019-04-18T19:28:34.143,"<p><a href=""https://docs.ansible.com/ansible/latest/modules/include_role_module.html#include-role-load-and-execute-a-role"" rel=""nofollow noreferrer"">include_role</a> is a task and the name is printed (see below). <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_blocks.html#blocks"" rel=""nofollow noreferrer"">block</a> is not a task and name is not printed by any <a href=""https://docs.ansible.com/ansible/latest/plugins/callback.html#plugin-list"" rel=""nofollow noreferrer"">plugin</a>.</p>

<p>The play</p>

<pre><code>tasks:
  - name: ""I'm a block!""
    block:
      - name: ""I'm a role!""
        include_role: name=role5
</code></pre>

<p>gives:</p>

<pre><code>PLAY [localhost]
TASK [I'm a role!]
TASK [role5 : I'm a task!]
</code></pre>
",7715,2019-04-18T19:28:34.143,"['tasks:\n  - name: ""I\'m a block!""\n    block:\n      - name: ""I\'m a role!""\n        include_role: name=role5\n', ""PLAY [localhost]\nTASK [I'm a role!]\nTASK [role5 : I'm a task!]\n""]"
804,6905,6899,CC BY-SA 4.0,2019-04-19T02:33:04.040,"<p>I was able to create a custom callback plugin. I started with the default callback code and modified it:</p>

<pre><code>    def v2_playbook_on_task_start(self, task, is_conditional):

        if(task._role is not None and task._role != self._current_role):
            self._current_role = task._role
            self._display.banner(""ROLE ["" + self._current_role.get_name() + ""]"", color=C.COLOR_DEBUG)

        self._task_start(task, prefix='TASK')
</code></pre>

<p>Now the output looks like:</p>

<pre><code>ROLE [some_role] *****************************************************

TASK [some_role : I'm a task!] ***************************************
ok: [MACHINE]

TASK [some_role : Some other task!] **********************************
ok: [MACHINE]

ROLE [another_role] **************************************************

TASK [some_role : I'm a task!] ***************************************
ok: [MACHINE]
</code></pre>

<p>With the role line being bolded. It's a work in progress, but it at least makes it a lot more obvious where roles are being executed. My determination on <code>block</code> is that it is impossible to do what I wanted, due to the way the block class is implemented in Ansible.</p>
",13217,2019-04-19T02:33:04.040,"['    def v2_playbook_on_task_start(self, task, is_conditional):\n\n        if(task._role is not None and task._role != self._current_role):\n            self._current_role = task._role\n            self._display.banner(""ROLE ["" + self._current_role.get_name() + ""]"", color=C.COLOR_DEBUG)\n\n        self._task_start(task, prefix=\'TASK\')\n', ""ROLE [some_role] *****************************************************\n\nTASK [some_role : I'm a task!] ***************************************\nok: [MACHINE]\n\nTASK [some_role : Some other task!] **********************************\nok: [MACHINE]\n\nROLE [another_role] **************************************************\n\nTASK [some_role : I'm a task!] ***************************************\nok: [MACHINE]\n""]"
805,6918,6917,CC BY-SA 4.0,2019-04-21T20:40:29.713,"<p>I searched for the <strong>healthcheck/postgres:alpine</strong> and I found the following repository with the <strong>Dockerfile</strong>:</p>

<p><a href=""https://github.com/docker-library/healthcheck/blob/master/postgres/Dockerfile.alpine"" rel=""nofollow noreferrer"">https://github.com/docker-library/healthcheck/blob/master/postgres/Dockerfile.alpine</a></p>

<p>Assuming this is the correct repo for your docker image, the dockerfile specifies:</p>

<pre><code>FROM postgres

COPY docker-healthcheck /usr/local/bin/

HEALTHCHECK CMD [""docker-healthcheck""]
</code></pre>

<p>So it extends the postgres docker image which is documented here:</p>

<p><a href=""https://hub.docker.com/_/postgres"" rel=""nofollow noreferrer"">https://hub.docker.com/_/postgres</a></p>

<p>Specifically for the password they mention the following:</p>

<blockquote>
  <p>POSTGRES_PASSWORD This environment variable is recommended for you to
  use the PostgreSQL image. This environment variable sets the superuser
  password for PostgreSQL. The default superuser is defined by the
  POSTGRES_USER environment variable.</p>
  
  <p>Note 1: The PostgreSQL image sets up trust authentication locally so
  you may notice a password is not required when connecting from
  localhost (inside the same container). However, a password will be
  required if connecting from a different host/container...</p>
</blockquote>

<p>Read the whole documentation at the image homepage.</p>
",3525,2019-04-21T20:40:29.713,"['FROM postgres\n\nCOPY docker-healthcheck /usr/local/bin/\n\nHEALTHCHECK CMD [""docker-healthcheck""]\n']"
806,6936,6820,CC BY-SA 4.0,2019-04-23T21:27:02.973,"<p>using bash script (or pipeline step <code>sh</code>), I would do:</p>

<pre><code>JIRA_ISSUE_KEY=$(python my_python_script.py)
echo ""$JIRA_ISSUE_KEY""
</code></pre>
",13616,2019-04-23T21:27:02.973,"['JIRA_ISSUE_KEY=$(python my_python_script.py)\necho ""$JIRA_ISSUE_KEY""\n']"
807,7941,6774,CC BY-SA 4.0,2019-04-24T09:53:54.443,"<p>Another way to do this would be to set a role variable in your host_vars file called ""role"" and assign the role to install that way.  You could also use the loop that Vladimir provided to install multiple roles.</p>

<pre><code>tasks:
  - name: ""Install Apache""
    become: true
    package:
      name: apache2
      state: latest
    when: role == ""apache""

  - name: ""Install GCC""
    become: true
    package:
      name: gcc
      state: latest
    when: role == ""gcc""
</code></pre>

<p>You could also use tags to control what gets run in your play:</p>

<pre><code>tasks:
  - name: ""Install Apache""
    become: true
    package:
      name: apache2
      state: latest
    tags:
       - web
  - name: ""Install GCC""
    become: true
    package:
      name: gcc
      state: latest
    tags:
       - gcc
</code></pre>

<p>And run your playbook setting the tags you require:</p>

<pre><code>ansible-playbook example.yml --tags ""web,gcc""
</code></pre>
",14617,2019-04-24T09:53:54.443,"['tasks:\n  - name: ""Install Apache""\n    become: true\n    package:\n      name: apache2\n      state: latest\n    when: role == ""apache""\n\n  - name: ""Install GCC""\n    become: true\n    package:\n      name: gcc\n      state: latest\n    when: role == ""gcc""\n', 'tasks:\n  - name: ""Install Apache""\n    become: true\n    package:\n      name: apache2\n      state: latest\n    tags:\n       - web\n  - name: ""Install GCC""\n    become: true\n    package:\n      name: gcc\n      state: latest\n    tags:\n       - gcc\n', 'ansible-playbook example.yml --tags ""web,gcc""\n']"
808,7951,6930,CC BY-SA 4.0,2019-04-25T02:34:22.673,"<p>The service hook will fire as part of the notifications process.  You can suppress all notifications by setting the URI parameter <code>suppressNotifications</code> to <code>true</code>.</p>

<p>An example request URI might be:</p>

<pre><code>PATCH https://dev.azure.com/fabrikam/_apis/wit/workitems/{id}?suppressNotifications=true&amp;api-version=5.0
</code></pre>

<p>See the <a href=""https://docs.microsoft.com/en-us/rest/api/azure/devops/wit/work%20items/update?view=azure-devops-rest-5.0#uri-parameters"" rel=""nofollow noreferrer"">work item update API documentation</a> for more information.</p>
",13112,2019-04-25T02:34:22.673,['PATCH https://dev.azure.com/fabrikam/_apis/wit/workitems/{id}?suppressNotifications=true&api-version=5.0\n']
809,7957,7956,CC BY-SA 4.0,2019-04-25T19:49:06.610,"<p>No, docker will delete the container when it stops, and there's no update option to change that behavior. You can see this in the help output:</p>

<pre><code>$ docker container update --help

Usage:  docker container update [OPTIONS] CONTAINER [CONTAINER...]

Update configuration of one or more containers

Options:
      --blkio-weight uint16        Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)
      --cpu-period int             Limit CPU CFS (Completely Fair Scheduler) period
      --cpu-quota int              Limit CPU CFS (Completely Fair Scheduler) quota
      --cpu-rt-period int          Limit the CPU real-time period in microseconds
      --cpu-rt-runtime int         Limit the CPU real-time runtime in microseconds
  -c, --cpu-shares int             CPU shares (relative weight)
      --cpus decimal               Number of CPUs
      --cpuset-cpus string         CPUs in which to allow execution (0-3, 0,1)
      --cpuset-mems string         MEMs in which to allow execution (0-3, 0,1)
      --kernel-memory bytes        Kernel memory limit
  -m, --memory bytes               Memory limit
      --memory-reservation bytes   Memory soft limit
      --memory-swap bytes          Swap limit equal to memory plus swap: '-1' to enable unlimited swap
      --pids-limit int             Tune container pids limit (set -1 for unlimited)
      --restart string             Restart policy to apply when a container exits
</code></pre>

<p>Trying to change the restart policy will result in an error:</p>

<pre><code>$ docker run --rm --name test-rm -d busybox tail -f /dev/null                                                                                                                                                                                 
14a7d9bfebc3356652e3c3f060e92d9cebb9f3eb4490873540c9eb1c272f6612

$ docker update --restart=unless-stopped test-rm
Error response from daemon: Cannot update container 14a7d9bfebc3356652e3c3f060e92d9cebb9f3eb4490873540c9eb1c272f6612: Restart policy cannot be updated because AutoRemove is enabled for the container
</code></pre>

<p>You can try to copy your data out of the container with:</p>

<pre><code>docker container cp $container_name:/path/in/container /path/on/host
</code></pre>

<p>If you don't know which files to save, list which files have changed in the container with:</p>

<pre><code>docker container diff $container_name
</code></pre>
",7730,2019-04-25T19:51:54.930,"[""$ docker container update --help\n\nUsage:  docker container update [OPTIONS] CONTAINER [CONTAINER...]\n\nUpdate configuration of one or more containers\n\nOptions:\n      --blkio-weight uint16        Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0)\n      --cpu-period int             Limit CPU CFS (Completely Fair Scheduler) period\n      --cpu-quota int              Limit CPU CFS (Completely Fair Scheduler) quota\n      --cpu-rt-period int          Limit the CPU real-time period in microseconds\n      --cpu-rt-runtime int         Limit the CPU real-time runtime in microseconds\n  -c, --cpu-shares int             CPU shares (relative weight)\n      --cpus decimal               Number of CPUs\n      --cpuset-cpus string         CPUs in which to allow execution (0-3, 0,1)\n      --cpuset-mems string         MEMs in which to allow execution (0-3, 0,1)\n      --kernel-memory bytes        Kernel memory limit\n  -m, --memory bytes               Memory limit\n      --memory-reservation bytes   Memory soft limit\n      --memory-swap bytes          Swap limit equal to memory plus swap: '-1' to enable unlimited swap\n      --pids-limit int             Tune container pids limit (set -1 for unlimited)\n      --restart string             Restart policy to apply when a container exits\n"", '$ docker run --rm --name test-rm -d busybox tail -f /dev/null                                                                                                                                                                                 \n14a7d9bfebc3356652e3c3f060e92d9cebb9f3eb4490873540c9eb1c272f6612\n\n$ docker update --restart=unless-stopped test-rm\nError response from daemon: Cannot update container 14a7d9bfebc3356652e3c3f060e92d9cebb9f3eb4490873540c9eb1c272f6612: Restart policy cannot be updated because AutoRemove is enabled for the container\n', 'docker container cp $container_name:/path/in/container /path/on/host\n', 'docker container diff $container_name\n']"
810,7961,4161,CC BY-SA 4.0,2019-04-26T08:32:53.560,"<p>Why do you want to create a new Manager node, risking damaging your raft consensus and cie?</p>
<p>I find it way easier to simply expose the <strong>docker socket</strong> locally, as if you were working inside the node, but with your Windows environment.</p>
<p>To do so, simply open a <strong>ssh tunnel</strong> that exposes <code>/var/run/docker.sock</code>:</p>
<pre><code> ssh -M -S ~/.docker.sock \
     -fnNT -4 -L localhost:1337:/var/run/docker.sock \
     USER@MANAGER_IP
</code></pre>
<p>Refer to <code>man ssh</code> to see what all these options mean.</p>
<p>It will open an ssh tunnel; you will still be in your local environment shell, only thing left to do is set the proper <code>DOCKER_HOST</code> environment var, so your docker cli is bound to your swarm manager.</p>
<p><code>export DOCKER_HOST=localhost:1337</code></p>
<p>And that's it.</p>
<p>Note: Docker also includes an option to do this; I've quickly searched for it but can't manage to find it. It's in the most recent version of docker.</p>
",552,2020-10-26T18:34:57.493,[' ssh -M -S ~/.docker.sock \\\n     -fnNT -4 -L localhost:1337:/var/run/docker.sock \\\n     USER@MANAGER_IP\n']
811,7962,7958,CC BY-SA 4.0,2019-04-26T08:48:54.820,"<p>Append the parameters after the command. See the example below.</p>

<pre><code># ansible -m shell --args ""pwd; touch test; ls -1 chdir=/scratch/tmp creates=/scratch/tmp/test"" localhost
localhost | CHANGED | rc=0 &gt;&gt;
/scratch/tmp
test

# ansible -m shell --args ""pwd; touch test; ls -1 chdir=/scratch/tmp creates=/scratch/tmp/test"" localhost
localhost | SUCCESS | rc=0 &gt;&gt;
skipped, since /scratch/tmp/test exists
</code></pre>
",7715,2019-05-04T11:57:03.880,"['# ansible -m shell --args ""pwd; touch test; ls -1 chdir=/scratch/tmp creates=/scratch/tmp/test"" localhost\nlocalhost | CHANGED | rc=0 >>\n/scratch/tmp\ntest\n\n# ansible -m shell --args ""pwd; touch test; ls -1 chdir=/scratch/tmp creates=/scratch/tmp/test"" localhost\nlocalhost | SUCCESS | rc=0 >>\nskipped, since /scratch/tmp/test exists\n']"
812,7963,6908,CC BY-SA 4.0,2019-04-26T09:24:46.683,"<p>Managing versions of different services can be tricky. For now I've never found a good HOW TO out there. Like most things you do what suit you the best. Here is a couple of suggestion you could use:</p>

<p>-> <strong>Tag docker image with their commit sha</strong>:
Pretty easy to do when you are using gitlab this is an already set environment variable that you can uses when building you image in the CI/CD pipeline. It's easy to track what code this container. Also when rolling back one of your service you can see directly the merge request you are rolling back on.</p>

<p>-> <strong>Continuous deploy on your staging environment</strong>: 
When one is merging a new feature on the master of one of your services deploy it as soon as possible so you can test the impact on all other services. </p>

<p>-> <strong>When staging looks good trigger a release job</strong>: 
That job release shall be present on all your services. The purpose of this job is to:</p>

<ul>
<li>Check if the service current version (commit sha) match the currently deployed in production. </li>
<li>If not trigger the deploy job to production for this commit sha pipeline.</li>
<li>If the deploy to production job work then we shall store the current sha deployed in a new folder somewhere in a K/V store that way we keep a single source of truth of what's is being deployed and when</li>
</ul>

<p>More on that K/V store and release job:</p>

<p>This shall be trigger form a different pipeline on a project you use only to remotely trigger the updated versions on your whole SOA-application.
That way we have a repo that contain a script that will trigger the job release of all the services. 
It will create a new folder on your K/V store and all the triggered release job of your application will write their current version in it (updated or not)
Once finished only service that had change will be deployed but you will have a major version for your wall application like this on the K/V store:</p>

<pre><code>release_0.1.5:
 - user_service = COMMIT_SHA
 - payment_service = COMMIT_SHA 
 - organisation_service = COMMIT_SHA
 - ect..
</code></pre>

<p>When this job is replay it will detect that the folder already exist and so will trigger the deploy of all the version present in it so you can rollback your App to an older state.</p>

<p>Deploy to production job on each of your service can be protected to only be triggered from the main release project. But for quick fix reason you could also let it open just make sure it update the current K/V folder.</p>
",552,2019-04-26T09:24:46.683,['release_0.1.5:\n - user_service = COMMIT_SHA\n - payment_service = COMMIT_SHA \n - organisation_service = COMMIT_SHA\n - ect..\n']
813,7964,7939,CC BY-SA 4.0,2019-04-26T10:10:14.037,"<p>Generally, Ansible is very flexible and often there are more ""correct"" solutions.</p>

<p>Start for example with the question ""Where do the configuration data come from?"", put the default data to the roles and decide which variables should be configured in ""<em>group_vars/host_vars</em>"", in the roles, and which in the playbooks. Review <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable"" rel=""nofollow noreferrer"">Variable precedence: Where should I put a variable?</a>. To set paths to the inventory, roles, and others see <a href=""https://docs.ansible.com/ansible/latest/reference_appendices/config.html#ansible-configuration-settings"" rel=""nofollow noreferrer"">Ansible Configuration Settings</a>.</p>

<p>To answer your questions:</p>

<blockquote>
  <p>Q1: If I run ansible-playbook -i /path to hostfile/ how do I pick the specific host I want to run against? ...where can I put the specific host that is in the hosts file?</p>
</blockquote>

<p>To pick for example ""<em>router1</em>"" start a play with:</p>

<pre><code>- hosts: router1
</code></pre>

<blockquote>
  <p>Q2: How do I point to the playbooks that are in the root folder without backing up directories each time like this: ""ansible-playbook -i hosttarget ../../myplaybook.yml""</p>
</blockquote>

<p>Configure <a href=""https://docs.ansible.com/ansible/latest/reference_appendices/config.html#default-host-list"" rel=""nofollow noreferrer"">DEFAULT_HOST_LIST</a>. For example:</p>

<pre><code># ANSIBLE_HOSTS=$PWD/inventory/client1/hosts ansible-playbook myplaybook.yml
</code></pre>

<blockquote>
  <p>Q3: How can I load additional credentials files or group variables?</p>
</blockquote>

<p>There are a lot of options described in <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable"" rel=""nofollow noreferrer"">Variable precedence: Where should I put a variable?</a>. For example ""<em>include_vars</em>"" might be useful to load additional credentials. For ""group variables"" pick from the <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#id17"" rel=""nofollow noreferrer"">options</a>.</p>
",7715,2019-04-30T21:50:45.363,"['- hosts: router1\n', '# ANSIBLE_HOSTS=$PWD/inventory/client1/hosts ansible-playbook myplaybook.yml\n']"
814,7976,1277,CC BY-SA 4.0,2019-04-29T10:15:00.350,"<p>I solved this by adding </p>

<pre><code>ignore_errors: true
register: results
</code></pre>

<p>to the no_log-task. This makes ansible continue to the next task, even when the task fails. Then for the next task define a debug task, which always fails and outputs the registered variable, but only runs when the previous task failed:</p>

<pre><code>- name: Error output
  debug:
     var: results
  failed_when: true
  when:
     results is failed
</code></pre>

<p>So even with no_log: true, this will make ansible display the output of the failed task.
This solution is not logging it to a file as requested but fullfils your need to 'see the log when failed' , and of course, you can redirect or use tee to output the full ansible output to a file, which will, with this solution also contain the the log of the failed task.</p>
",14664,2019-04-29T10:15:00.350,"['ignore_errors: true\nregister: results\n', '- name: Error output\n  debug:\n     var: results\n  failed_when: true\n  when:\n     results is failed\n']"
815,7977,7970,CC BY-SA 4.0,2019-04-29T13:03:59.650,"<p>There are options in docker that will retry the startup of a container, <a href=""https://docs.docker.com/compose/compose-file/#restart"" rel=""nofollow noreferrer"">restart in version 2</a> and <a href=""https://docs.docker.com/compose/compose-file/#restart_policy"" rel=""nofollow noreferrer"">restart-policy in version 3</a> (you'd need compatibility mode enabled for the version 3 syntax to work). However, I believe they only work when the issue is from the application inside the container fails, not when there is an issue creating the container like you see with a volume mount failing (or would also happen if the image couldn't be retrieved from a registry).</p>

<p>To handle the failing volume mount, I believe swarm mode is your best option despite your objections. You can create a single node cluster with <code>docker swarm init</code> and deploy your compose file with <code>docker stack deploy -c docker-compose.yml stack_name</code>, making an easy transition from docker-compose. Swarm mode looks at the overall state of the service and continuously tries to make the current state match your target state (as defined in the compose file), which will handle a failing volume mount that eventually corrects itself. I don't have an NFS server to test on right now, but here's a scenario with a bind mount to a missing folder:</p>

<pre><code>$ cat docker-compose.vol-bind.yml
version: '3'
volumes:
  bind-test:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /home/bmitch/data/docker/test/missing
services:
  bind-test:
    image: busybox
    command: tail -f /dev/null
    volumes:
      - bind-test:/bind-test

$ docker stack deploy -c docker-compose.vol-bind.yml voltest   
Creating network voltest_default                              
Creating service voltest_bind-test   

$ docker service ls
ID                  NAME                   MODE                REPLICAS            IMAGE                                             PORTS
omzaeo7mrour        voltest_bind-test      replicated          0/1                 busybox:latest

$ docker service ps omzaeo7mrour
ID                  NAME                      IMAGE               NODE                DESIRED STATE       CURRENT STATE           ERROR                              POR
TS
kpz0l79eucaw        voltest_bind-test.1       busybox:latest      bmitch-asusr556l    Ready               Ready 2 seconds ago
j6fylzhvcv60         \_ voltest_bind-test.1   busybox:latest      bmitch-asusr556l    Shutdown            Failed 5 seconds ago    ""starting container failed: er…""
61o6raohp0xl         \_ voltest_bind-test.1   busybox:latest      bmitch-asusr556l    Shutdown            Failed 12 seconds ago   ""starting container failed: er…""

$ docker inspect kpz0l79eucaw
[
    {
        ""ID"": ""kpz0l79eucaw1856obmwvcak1"",
        ""Version"": {
            ""Index"": 445
        },
        ""CreatedAt"": ""2019-04-29T12:57:25.925788528Z"",
        ""UpdatedAt"": ""2019-04-29T12:57:34.3467203Z"",
        ""Labels"": {},
        ""Spec"": {
            ""ContainerSpec"": {
                ""Image"": ""busybox:latest"",
                ""Labels"": {
                    ""com.docker.stack.namespace"": ""voltest""
                },
...
        ""Status"": {
            ""Timestamp"": ""2019-04-29T12:57:33.936048295Z"",
            ""State"": ""failed"",
            ""Message"": ""starting"",
            ""Err"": ""starting container failed: error while mounting volume '/home/var-docker/volumes/voltest_bind-test/_data': failed to mount local volume: mount /home
/bmitch/data/docker/test/missing:/home/var-docker/volumes/voltest_bind-test/_data, flags: 0x1000: no such file or directory"",
            ""ContainerStatus"": {
                ""ContainerID"": ""4c75c851bd43b5ef57b4785a4611f78501279933822eab90c693e1108f53ee82"",
                ""PID"": 0,
                ""ExitCode"": 128
            },
            ""PortStatus"": {}
        },
...

$ mkdir missing

$ docker service ps omzaeo7mrour
ID                  NAME                      IMAGE               NODE                DESIRED STATE       CURRENT STATE           ERROR                              POR
TS
okylli7smu1c        voltest_bind-test.1       busybox:latest      bmitch-asusr556l    Running             Running 4 seconds ago
9tpm188ysu2k         \_ voltest_bind-test.1   busybox:latest      bmitch-asusr556l    Shutdown            Failed 14 seconds ago   ""starting container failed: er…""
kpz0l79eucaw         \_ voltest_bind-test.1   busybox:latest      bmitch-asusr556l    Shutdown            Failed 21 seconds ago   ""starting container failed: er…""
</code></pre>

<p>From the above, you can see as soon as the missing directory was created, the bind mount succeeded, and the container that failed to be created as retried and started successfully.</p>
",7730,2019-04-29T13:03:59.650,"['$ cat docker-compose.vol-bind.yml\nversion: \'3\'\nvolumes:\n  bind-test:\n    driver: local\n    driver_opts:\n      type: none\n      o: bind\n      device: /home/bmitch/data/docker/test/missing\nservices:\n  bind-test:\n    image: busybox\n    command: tail -f /dev/null\n    volumes:\n      - bind-test:/bind-test\n\n$ docker stack deploy -c docker-compose.vol-bind.yml voltest   \nCreating network voltest_default                              \nCreating service voltest_bind-test   \n\n$ docker service ls\nID                  NAME                   MODE                REPLICAS            IMAGE                                             PORTS\nomzaeo7mrour        voltest_bind-test      replicated          0/1                 busybox:latest\n\n$ docker service ps omzaeo7mrour\nID                  NAME                      IMAGE               NODE                DESIRED STATE       CURRENT STATE           ERROR                              POR\nTS\nkpz0l79eucaw        voltest_bind-test.1       busybox:latest      bmitch-asusr556l    Ready               Ready 2 seconds ago\nj6fylzhvcv60         \\_ voltest_bind-test.1   busybox:latest      bmitch-asusr556l    Shutdown            Failed 5 seconds ago    ""starting container failed: er…""\n61o6raohp0xl         \\_ voltest_bind-test.1   busybox:latest      bmitch-asusr556l    Shutdown            Failed 12 seconds ago   ""starting container failed: er…""\n\n$ docker inspect kpz0l79eucaw\n[\n    {\n        ""ID"": ""kpz0l79eucaw1856obmwvcak1"",\n        ""Version"": {\n            ""Index"": 445\n        },\n        ""CreatedAt"": ""2019-04-29T12:57:25.925788528Z"",\n        ""UpdatedAt"": ""2019-04-29T12:57:34.3467203Z"",\n        ""Labels"": {},\n        ""Spec"": {\n            ""ContainerSpec"": {\n                ""Image"": ""busybox:latest"",\n                ""Labels"": {\n                    ""com.docker.stack.namespace"": ""voltest""\n                },\n...\n        ""Status"": {\n            ""Timestamp"": ""2019-04-29T12:57:33.936048295Z"",\n            ""State"": ""failed"",\n            ""Message"": ""starting"",\n            ""Err"": ""starting container failed: error while mounting volume \'/home/var-docker/volumes/voltest_bind-test/_data\': failed to mount local volume: mount /home\n/bmitch/data/docker/test/missing:/home/var-docker/volumes/voltest_bind-test/_data, flags: 0x1000: no such file or directory"",\n            ""ContainerStatus"": {\n                ""ContainerID"": ""4c75c851bd43b5ef57b4785a4611f78501279933822eab90c693e1108f53ee82"",\n                ""PID"": 0,\n                ""ExitCode"": 128\n            },\n            ""PortStatus"": {}\n        },\n...\n\n$ mkdir missing\n\n$ docker service ps omzaeo7mrour\nID                  NAME                      IMAGE               NODE                DESIRED STATE       CURRENT STATE           ERROR                              POR\nTS\nokylli7smu1c        voltest_bind-test.1       busybox:latest      bmitch-asusr556l    Running             Running 4 seconds ago\n9tpm188ysu2k         \\_ voltest_bind-test.1   busybox:latest      bmitch-asusr556l    Shutdown            Failed 14 seconds ago   ""starting container failed: er…""\nkpz0l79eucaw         \\_ voltest_bind-test.1   busybox:latest      bmitch-asusr556l    Shutdown            Failed 21 seconds ago   ""starting container failed: er…""\n']"
816,7984,4863,CC BY-SA 4.0,2019-04-30T06:28:31.267,"<p>We have moved onto using Jenkins templates and I have a workaround to keep the individual approver names list in one place. Sharing the sample code for your reference.</p>

<pre><code>#!/usr/bin/env groovy
import com.mm.Constants 
def call(String teamName = 'LOGIN') {
   // team name of null means UI
   teamName = teamName ?: 'UI'

   timeout(time:2, unit:'DAYS')
       {                                                              
           input message: 'Can you approve this ??', submitter: Constants.""${teamName}_APPROVERS""
      }
</code></pre>

<p>}</p>

<pre><code>#!/usr/bin/env groovy
class Constants {
   static final LOGIN_APPROVERS = 'approver1,approver2';
   static final UI_APPROVERS = 'approver2,approver3';
}
</code></pre>

<p>Below is how you call from the pipeline    </p>

<pre><code>stage ('Ship to QA?'){
    echo ""Waiting for QA approval""
    shipToQA('LOGIN')
}
</code></pre>
",9481,2019-04-30T06:33:35.057,"['#!/usr/bin/env groovy\nimport com.mm.Constants \ndef call(String teamName = \'LOGIN\') {\n   // team name of null means UI\n   teamName = teamName ?: \'UI\'\n\n   timeout(time:2, unit:\'DAYS\')\n       {                                                              \n           input message: \'Can you approve this ??\', submitter: Constants.""${teamName}_APPROVERS""\n      }\n', ""#!/usr/bin/env groovy\nclass Constants {\n   static final LOGIN_APPROVERS = 'approver1,approver2';\n   static final UI_APPROVERS = 'approver2,approver3';\n}\n"", 'stage (\'Ship to QA?\'){\n    echo ""Waiting for QA approval""\n    shipToQA(\'LOGIN\')\n}\n']"
817,7989,7988,CC BY-SA 4.0,2019-04-30T21:48:16.627,"<p>Mounted volumes can be used to preserve state between runs, apart from that Docker is stateless by design. To make a local directory available inside the Docker container, you can use the <code>-v</code> option, for example:</p>

<p><code>docker run -v /path/to/local/dir/:/mountpath/inside/docker ...</code></p>

<p>But if I understand your question correctly, you are asking for a faster feedback cycle while working on the Dockerfile. For that, I would recommend to start the container, and attach an interactive shell to try out your changes. Once you made some progress, update the Dockerfile.</p>

<pre><code>$ docker ps
CONTAINER ID  IMAGE        COMMAND  CREATED           STATUS        PORTS  NAMES
f1217635695d  ubuntu:18.04 ""bash""   23 seconds ago   Up 21 seconds         stoic_austin

$ docker exec -it f1217635695d bash
root@f1217635695d:/# ...
</code></pre>

<p>Also note that proper use of caching can speed up rebuilds of the Docker container after changes significantly.</p>

<blockquote>
  <p>(from your question)
  1. Kill the container and prune it out of the system.</p>
</blockquote>

<p>Pruning should not be necessary unless you run out of disk space. It should be sufficient to update the tag, for example:</p>

<pre><code>docker build -t test .
docker run --rm -it test
</code></pre>

<p><code>test:latest</code> will point to the last image id that was created. <code>docker images</code> will show that the previous images are not deleted, but as said, if you have enough disk space available, it is not a big concern.</p>
",2708,2019-04-30T21:48:16.627,"['$ docker ps\nCONTAINER ID  IMAGE        COMMAND  CREATED           STATUS        PORTS  NAMES\nf1217635695d  ubuntu:18.04 ""bash""   23 seconds ago   Up 21 seconds         stoic_austin\n\n$ docker exec -it f1217635695d bash\nroot@f1217635695d:/# ...\n', 'docker build -t test .\ndocker run --rm -it test\n']"
818,7995,7993,CC BY-SA 4.0,2019-05-02T05:06:24.720,"<p>First you need to install <a href=""http://sourceforge.net/projects/sshpass/"" rel=""nofollow noreferrer"">sshpass</a>.</p>

<ul>
<li>Ubuntu/Debian: <code>apt-get install sshpass</code>  </li>
<li>Fedora/CentOS: <code>yum install sshpass</code>  </li>
</ul>

<hr>

<p><strong>Example:</strong></p>



<pre class=""lang-none prettyprint-override""><code>sshpass -p ""YOUR_PASSWORD"" ssh -o StrictHostKeyChecking=no YOUR_USERNAME@SOME_SITE.COM
</code></pre>

<p><strong>Custom port example:</strong></p>

<pre class=""lang-none prettyprint-override""><code>sshpass -p ""YOUR_PASSWORD"" ssh -o StrictHostKeyChecking=no YOUR_USERNAME@SOME_SITE.COM:2400
</code></pre>

<p><strong>Notes:</strong></p>

<ul>
<li><code>sshpass</code> can also read a password from a file when the <code>-f</code> flag is passed.

<ul>
<li>Using <code>-f</code> prevents the password from being visible if the <code>ps</code> command is executed.</li>
<li>The file that the password is stored in should have secure permissions.</li>
</ul></li>
</ul>
",11598,2019-05-02T05:17:39.050,"['sshpass -p ""YOUR_PASSWORD"" ssh -o StrictHostKeyChecking=no YOUR_USERNAME@SOME_SITE.COM\n', 'sshpass -p ""YOUR_PASSWORD"" ssh -o StrictHostKeyChecking=no YOUR_USERNAME@SOME_SITE.COM:2400\n']"
819,8003,8001,CC BY-SA 4.0,2019-05-02T19:34:00.563,"<p>The magic you need is <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#accessing-information-about-other-hosts-with-magic-variables"" rel=""nofollow noreferrer"">magic variables</a>, in particular the <code>groups</code> variable, <a href=""https://docs.ansible.com/ansible/latest/reference_appendices/special_variables.html#magic"" rel=""nofollow noreferrer"">which is</a></p>

<blockquote>
  <p>a dictionary/map with all the groups in inventory and each group has the list of hosts that belong to it.</p>
</blockquote>

<p>Then you can use template <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html"" rel=""nofollow noreferrer"">filters</a> to format the list: use <code>map</code> with <code>regex_replace</code> to add the quotes to all list elements and then <code>join</code> them into the final result.</p>

<pre><code>{{ groups['elasticsearch_nodes']|map('regex_replace', '(.*)', '""\\1""')|join(',') }}
</code></pre>
",4224,2019-05-02T19:34:00.563,"['{{ groups[\'elasticsearch_nodes\']|map(\'regex_replace\', \'(.*)\', \'""\\\\1""\')|join(\',\') }}\n']"
820,8007,7955,CC BY-SA 4.0,2019-05-03T06:22:11.110,"<p>This is a glibc dependency issue on Alpine.</p>

<p>This <code>azcopy</code> binary is compatible with Linux distributions that use <a href=""https://www.gnu.org/software/libc"" rel=""noreferrer"">glibc</a>, GNU's C standard library. Alpine Linux uses a different libc implementation, <a href=""https://www.musl-libc.org/"" rel=""noreferrer"">musl-libc</a>, which is generally not compatible to glibc. When trying to run non-Alpine-built binaries on Alpine, they'll usually fail to link since the glibc shared object, <code>libc.so.6</code>, is missing. <code>azcopy: not found</code> is actually the result of the dynamic linker failing to resolve the requires libraries.</p>

<p>You could verify by running <code>ldd ./azcopy</code>:</p>

<pre><code>    /lib64/ld-linux-x86-64.so.2 (0x7fa0bc9c3000)
    libpthread.so.0 =&gt; /lib64/ld-linux-x86-64.so.2 (0x7fa0bc9c3000)
    libc.so.6 =&gt; /lib64/ld-linux-x86-64.so.2 (0x7fa0bc9c3000)
</code></pre>

<p>Note the <code>libc.so.6</code> dependency. On vanilla Alpine, there's only the musl libc binary, <code>libc.musl-x86_64.so.1</code>.</p>

<p>Fortunately, Alpine provides a light compatibility layer for glibc, through the <a href=""https://pkgs.alpinelinux.org/package/v3.9/main/x86/libc6-compat"" rel=""noreferrer"">libc6-compat</a> package. It installs a <code>libc.so.6</code> link which is redirected to the musl shared object, and adds some missing glibc interface functions. This seems to be enough to running azcopy.</p>

<p>Therefore, for running azcopy on Alpine, just install the <code>libc6-compat</code> package, using: </p>

<pre><code>apk add libc6-compat
</code></pre>
",4034,2019-05-03T06:22:11.110,"['    /lib64/ld-linux-x86-64.so.2 (0x7fa0bc9c3000)\n    libpthread.so.0 => /lib64/ld-linux-x86-64.so.2 (0x7fa0bc9c3000)\n    libc.so.6 => /lib64/ld-linux-x86-64.so.2 (0x7fa0bc9c3000)\n', 'apk add libc6-compat\n']"
821,8009,7993,CC BY-SA 4.0,2019-05-03T11:00:22.807,"<p>But storeing your password in a command is not the best way - it should be better to remove the password for this case - so you do not reveal your key password</p>

<pre><code>$ ssh-keygen -p [-P old_passphrase] [-N new_passphrase] [-f keyfile]
</code></pre>
",14754,2019-05-03T11:00:22.807,['$ ssh-keygen -p [-P old_passphrase] [-N new_passphrase] [-f keyfile]\n']
822,8013,8012,CC BY-SA 4.0,2019-05-03T13:33:24.503,"<p>This issue is due to the CTAN mirrors having yet to update. The issue appears in the <a href=""https://travis-ci.community/t/latex-error-file-inconsolata-sty-not-found-only-on-osx-when-building-r-package/3261"" rel=""nofollow noreferrer"">Travis R community forum</a>:</p>

<blockquote>
  <p>might be related to the recent switch to TexLive-2019 as the LaTeX package manager seems to fail finding inconsolata in the repository.</p>
  
  <p>...</p>
  
  <p>It looks to me like the mirror chosen was has not updated to 2019, so I think this will resolve itself naturally when the mirrors catch up. If not I can look into it.</p>
</blockquote>

<p>In the meantime, I solved it by forcing a previous version of TeXLive with a downgrade to OSX 10.12 in <code>.travis.yml</code>:</p>

<pre><code># macOS 10.12 version
osx_image: xcode9.2
</code></pre>

<p>See <a href=""https://docs.travis-ci.com/user/reference/osx#macos-version"" rel=""nofollow noreferrer"">this Travis page</a> for the correspondence between XCode and OSX versions.</p>
",14747,2019-05-03T14:01:06.237,['# macOS 10.12 version\nosx_image: xcode9.2\n']
823,8015,8014,CC BY-SA 4.0,2019-05-03T14:19:43.767,"<p>If you are using the recommended setting for R packages of upgrading warnings to errors, i.e. with this line in <code>.travis.yml</code>:</p>

<pre><code>warnings_are_errors: true
</code></pre>

<p>then the place to look is the previous heading in the Travis log, called <code>Checking package</code>.</p>

<h3>Example of problem with missing font</h3>

<p>In my case, the Travis log under the heading <code>Checking package</code> showed that the
<code>inconsolata</code> font was missing, so the vignettes failed to build:</p>

<pre><code>* checking PDF version of manual ... WARNING
LaTeX errors when creating PDF version.
This typically indicates Rd problems.
LaTeX errors found:
! LaTeX Error: File `inconsolata.sty' not found.
Type X to quit or &lt;RETURN&gt; to proceed,
or enter new name. (Default extension: sty)
! Emergency stop.
&lt;read *&gt; 

l.276 ^^M

!  ==&gt; Fatal error occurred, no output PDF file produced!
* checking PDF version of manual without hyperrefs or index ... ERROR
* DONE
Status: 1 ERROR, 1 WARNING
</code></pre>

<p>This caused an error for LaTeX, a warning for R, and an error for Travis.</p>

<h3>Solution to problem</h3>

<p>In my case, the problem was due to Travis using TeXLive 2019 and the CTAN
mirrors having yet to update to 2019.</p>

<p>The issue appears in the <a href=""https://travis-ci.community/t/latex-error-file-inconsolata-sty-not-found-only-on-osx-when-building-r-package/3261"" rel=""nofollow noreferrer"">Travis R community forum</a>:</p>

<blockquote>
  <p>might be related to the recent switch to TexLive-2019 as the LaTeX package manager seems to fail finding inconsolata in the repository.</p>
  
  <p>...</p>
  
  <p>It looks to me like the mirror chosen was has not updated to 2019, so I think this will resolve itself naturally when the mirrors catch up. If not I can look into it.</p>
</blockquote>

<p>In the meantime, I solved it by forcing a previous version of TeXLive with a downgrade to OSX 10.12 in <code>.travis.yml</code>:</p>

<pre><code># macOS 10.12 version
osx_image: xcode9.2
</code></pre>

<p>See <a href=""https://docs.travis-ci.com/user/reference/osx#macos-version"" rel=""nofollow noreferrer"">this Travis
page</a> for the
correspondence between XCode and OSX versions and <a href=""https://devops.stackexchange.com/questions/8012/testing-r-package-on-travis-fails-because-of-texlive-incompatible-versions/8013#8013"">the original thread in DevOps
StackExchange</a>.</p>
",14747,2019-05-03T14:19:43.767,"['warnings_are_errors: true\n', ""* checking PDF version of manual ... WARNING\nLaTeX errors when creating PDF version.\nThis typically indicates Rd problems.\nLaTeX errors found:\n! LaTeX Error: File `inconsolata.sty' not found.\nType X to quit or <RETURN> to proceed,\nor enter new name. (Default extension: sty)\n! Emergency stop.\n<read *> \n\nl.276 ^^M\n\n!  ==> Fatal error occurred, no output PDF file produced!\n* checking PDF version of manual without hyperrefs or index ... ERROR\n* DONE\nStatus: 1 ERROR, 1 WARNING\n"", '# macOS 10.12 version\nosx_image: xcode9.2\n']"
824,8019,5104,CC BY-SA 4.0,2019-05-03T15:33:20.930,"<p>There is a good practice called multistage build, in which you have one Dockerfile containing various image definitions that depend from one another, this helps you keep all your images updated with the latest changes and copy artifacts from one to another; this also helps reducing the image size if done right.
A simple example is like the following:</p>

<pre><code>FROM golang:1.9.2 as builder
ENV CGO_ENABLED=0 GOOS=linux
RUN go build -a \
             -installsuffix cgo \
             -o app .

FROM alpine:3.6
WORKDIR /root/
COPY --from=builder app .
CMD [""./app""]
</code></pre>

<p>In this example, in the first image you compile a go example application using the golang official image and then, using alpine to keep the size of the image small, you copy the executable to a new image and execute it.
This way you can keep your containers in one file and build all at the same time or you can build just a target stage:</p>

<pre><code>docker build --target builder -t somehub/sometag:latest .
</code></pre>

<p>You can even use remote images as stages:</p>

<pre><code>COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf
</code></pre>

<p>If you need anymore information regarding Docker multi-stage builds you can find it in the following <a href=""https://docs.docker.com/develop/develop-images/multistage-build/"" rel=""nofollow noreferrer"">link</a>.</p>
",13113,2019-05-03T15:33:20.930,"['FROM golang:1.9.2 as builder\nENV CGO_ENABLED=0 GOOS=linux\nRUN go build -a \\\n             -installsuffix cgo \\\n             -o app .\n\nFROM alpine:3.6\nWORKDIR /root/\nCOPY --from=builder app .\nCMD [""./app""]\n', 'docker build --target builder -t somehub/sometag:latest .\n', 'COPY --from=nginx:latest /etc/nginx/nginx.conf /nginx.conf\n']"
825,8020,8002,CC BY-SA 4.0,2019-05-03T16:24:31.103,"<p>I usually set the credential NAME into an environment variable</p>

<pre><code>environment {
    CERT = 'mycert'
}
</code></pre>

<p>Then I can use that name where ever I need it</p>

<pre><code>withCredentials([usernamePassword(credentialsId: ""${env.CERT}"",
                                  passwordVariable: 'CERT_PASSWORD',
                                  usernameVariable: 'CERT_USER')]) {
    // Do things needing environment variables
}
</code></pre>

<p>or</p>

<pre><code>checkout(poll: false,
         scm: [
               $class: 'GitSCM',
               userRemoteConfigs: [[credentialsId: ""${env.CERT}"", 
                                   url: 'https://code.example.org/somerepo']]
               ])
</code></pre>
",14762,2019-05-03T16:24:31.103,"[""environment {\n    CERT = 'mycert'\n}\n"", 'withCredentials([usernamePassword(credentialsId: ""${env.CERT}"",\n                                  passwordVariable: \'CERT_PASSWORD\',\n                                  usernameVariable: \'CERT_USER\')]) {\n    // Do things needing environment variables\n}\n', 'checkout(poll: false,\n         scm: [\n               $class: \'GitSCM\',\n               userRemoteConfigs: [[credentialsId: ""${env.CERT}"", \n                                   url: \'https://code.example.org/somerepo\']]\n               ])\n']"
826,8023,8016,CC BY-SA 4.0,2019-05-04T08:31:20.557,"<p>On top of protecting your root account as best as you can, you should be able to reduce the risk of such resource deletion if you have more than 1 resource to protect.</p>

<p>For example if all AWS resources you had to protect were 2 RDS database servers, you could create 2 other accounts that have access to only copy the snapshots of one of your database servers each - and no other access to any other resource. This setup would then require an intruder to hack both root accounts of your main and one backup account each, which should be significantly more difficult.</p>

<p>To copy snapshots from one account A (your current RDS account) to account B (your new account) you should need the following parts  (untested)</p>

<ul>
<li>Create a new IAM role in Account A, for access from account B:</li>
</ul>

<p><a href=""https://i.stack.imgur.com/XrRGs.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XrRGs.png"" alt=""enter image description here""></a></p>

<ul>
<li><p>Create a new policy for reading RDS snapshots from account A</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
        ""Effect"": ""Allow"",
        ""Action"":
            [
                ""rds:CopyDbSnapshot"",
                ""rds:DescribeDbSnapshots""


            ],
        ""Resource"": ""arn:aws:rds:::""
        }
   ]
}
</code></pre></li>
</ul>

<p>and assign it to the IAM role</p>

<ul>
<li><p>Check that the ""trust policy"" is enabled as described in this walk through for another cross account action: <a href=""https://aws.amazon.com/blogs/database/setting-up-for-cross-account-native-backup-and-restore-in-amazon-rds-for-microsoft-sql-server/"" rel=""nofollow noreferrer"">https://aws.amazon.com/blogs/database/setting-up-for-cross-account-native-backup-and-restore-in-amazon-rds-for-microsoft-sql-server/</a></p></li>
<li><p>Then in account B, you should be able to run copy-db-snapshot from account B: <a href=""https://docs.aws.amazon.com/cli/latest/reference/rds/copy-db-snapshot.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/cli/latest/reference/rds/copy-db-snapshot.html</a></p></li>
<li><p>To automate, I prefer to use Lambda functions, which can simply call AWS API calls, you can trigger them with a Cloudwatch Event</p></li>
</ul>
",8251,2019-05-05T07:07:36.610,"['{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n        ""Effect"": ""Allow"",\n        ""Action"":\n            [\n                ""rds:CopyDbSnapshot"",\n                ""rds:DescribeDbSnapshots""\n\n\n            ],\n        ""Resource"": ""arn:aws:rds:::""\n        }\n   ]\n}\n']"
827,8029,7952,CC BY-SA 4.0,2019-05-05T16:59:44.097,"<p>That shows that your docker service is not yet running . Try start the service</p>

<pre><code>open -a Docker
</code></pre>
",10131,2019-05-05T16:59:44.097,['open -a Docker\n']
828,8031,8025,CC BY-SA 4.0,2019-05-05T23:27:03.817,"<pre><code>    volumes:
      - /usr/app/node_modules
</code></pre>

<p>This volume could be overwriting what you have installed during the <code>RUN npm install</code> stage of the Dockerfile. As far as I can see you're not doing any installation when starting the container, so the contents of the mount are empty. If you remove that mount, the <code>node_modules</code> path will be populated with what was installed during the <code>docker build</code> (as defined by the Dockerfile) phase.</p>
",4369,2019-05-05T23:27:03.817,['    volumes:\n      - /usr/app/node_modules\n']
829,8034,413,CC BY-SA 4.0,2019-05-06T13:19:00.937,"<p>One could also use <a href=""https://github.com/wagoodman/dive"" rel=""nofollow noreferrer"">dive</a></p>

<pre><code>docker run --rm -it \
    -v /var/run/docker.sock:/var/run/docker.sock \
    wagoodman/dive:latest &lt;dive arguments...&gt;
</code></pre>

<p>to get a report about what waste could be removed from a docker image in order to reduce the size.</p>
",210,2019-05-06T13:19:00.937,['docker run --rm -it \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    wagoodman/dive:latest <dive arguments...>\n']
830,8039,8026,CC BY-SA 4.0,2019-05-07T00:30:59.520,"<p>You seem to be confused a bit about how Firestore stores data and what Google is suggesting you do.</p>

<blockquote>
  <p>What is the problem? You are backing up a bucket inside other bucket.</p>
</blockquote>

<p>This is not correct.  Firestore stores its data inside some sort of mostly opaque database format.  If you are copying this out to a GCS bucket, that really <em>is</em> an export into a different storage medium and a different format.</p>

<p>That being said, it's still reasonable that you might want to keep your data backups outside of Google (although GCS has <a href=""https://cloud.google.com/storage/sla"" rel=""nofollow noreferrer"">a good SLA</a>).  To do that, after you've exported your Firestore data to a GCS bucket, use <a href=""https://cloud.google.com/storage/docs/gsutil"" rel=""nofollow noreferrer"">the gsutil utility</a> to copy that bucket down:</p>

<pre><code>gsutil cp -r gs://your-bucket-name .
</code></pre>
",960,2019-05-07T00:30:59.520,['gsutil cp -r gs://your-bucket-name .\n']
831,8043,8042,CC BY-SA 4.0,2019-05-07T07:16:40.530,"<p>Use the <a href=""https://docs.ansible.com/ansible/latest/user_guide/intro_patterns.html?highlight=--limit"" rel=""nofollow noreferrer""><code>--limit</code></a> option to select a subset of hosts:</p>

<pre><code>ansible-playbook -i /path  test.yml --tags automation --limit host2
</code></pre>

<p>Its description from <a href=""https://docs.ansible.com/ansible/latest/cli/ansible-playbook.html#cmdoption-ansible-playbook-l"" rel=""nofollow noreferrer"">ansible-playbook documentation</a>:</p>

<blockquote>
  <p>further limit selected hosts to an additional pattern</p>
</blockquote>
",4224,2019-05-07T07:16:40.530,['ansible-playbook -i /path  test.yml --tags automation --limit host2\n']
832,8046,413,CC BY-SA 4.0,2019-05-07T12:38:54.647,"<p>There's a variety of techniques involved, with no single solution. You will likely want to do several of the following:</p>

<hr>

<p>First, optimize your image layers for reuse. Put frequently changing steps later in the Dockerfile to increase the chances that early layers are cached from previous builds. A reused layer will show up as more disk space in a <code>docker image ls</code>, but if you examine the underlying filesystem, only one copy of each layer is ever stored on disk. That means 3 images of 2 GB each, but which only have 50 MB different in the last few layers the build, will only take up 2.1 GB of disk space, even though the listing makes it appear that they are using 6 GB since you are double counting each of the reused layers.</p>

<p>Layer reuse is why you see images with infrequently changing build dependencies install those first before copying in code. See any python example that has a pattern like:</p>

<pre><code>FROM python
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
# note how the code is copied only after the pip install
# since code changes but requirements.txt doesn't
COPY . .
CMD [""gunicorn"", ""app:app""]
</code></pre>

<hr>

<p>Pick a minimal base image. This is why you see people go from <code>ubuntu</code> to <code>debian:slim</code> (the slim variants are smaller, shipping with fewer tools), or even <code>alpine</code>. This reduces the size of your starting point, and is very helpful if you are constantly pulling new versions of the base image. However, if your base image rarely changes, layer reuse removes much of the advantage of a minimal base image.</p>

<p>The smallest base image you can pick is <code>scratch</code>, which is nothing, no shell or libraries, and is only useful with statically compiled binaries. Otherwise, pick a base image that includes the tools you need without lots of tools you don't need.</p>

<hr>

<p>Next, any step that changes or deletes a file should be combined with previous steps that create that file. Otherwise the layered filesystem, which uses copy-on-write even on things like a file permission change, will have the original file in a previous layer and the image size will not shrink when you remove files. This is why your <code>rm</code> commands have no effect on resulting disk space. Instead, you can chain the commands, like:</p>

<pre><code>RUN apt-get update \
 &amp;&amp; apt-get install -y \
      a-package \
      wget \
 &amp;&amp; ... \
 &amp;&amp; apt-get purge -y wget \
 &amp;&amp; rm -r a-build-dir \
 &amp;&amp; apt-get purge -y a-package
</code></pre>

<p>Note that overuse of command chaining can slow down your builds since you need to reinstall the same toolset any time a prerequisite changes (e.g. the code being pulled with wget). See multi-stage below for a better alternative.</p>

<hr>

<p>Any file you create that you do not need in your resulting image should be deleted, in the step that creates it. This includes package caches, logs, man pages, etc. To discover what files are being created in each layer, you can use a tool like wagoodman/dive (which I have not personally vetted and would express caution since it runs with full root access on your host), or you can build your docker images without pruning the intermediate containers and then view the diff with:</p>

<pre><code># first create and leave containers from any RUN step using options on build
docker image build --rm=false --no-cache -t image_name . 
# review which layers use an unexpectedly large amount of space
docker image history image_name
# list all containers, particularly the exited ones from above
docker container ps -a 
# examine any of those containers
docker container diff ${container_id} 
# ... repeat the diff for other build steps
# then cleanup exited containers
docker container prune
</code></pre>

<p>With each of those intermediate containers, the diff will show what files are added, changed, or deleted in that step (these are indicated with an <code>A</code>, <code>C</code>, or <code>D</code> before each filename). What diff is showing is the container specific read/write filesystem, which is any file changed by the container from the image state using copy-on-write.</p>

<hr>

<p>The best way to reduce image size is eliminating any unneeded components, like compilers, from your shipped image. For that, multi-stage builds let you compile in one stage, and then copy only the resulting artifacts from the build stage to a runtime image that has only the minimum needed to run the application. This avoids the need to optimize any of the build steps since they are not shipped with the resulting image.</p>

<pre><code>FROM debian:9 as build
# still chain update with install to prevent stale cache issues
RUN apt-get update \
 &amp;&amp; apt-get install -y \
      a-package \
      wget \
RUN ... # perform any download/compile steps

FROM debian:9-slim as release
COPY --from=build /usr/local/bin/app /usr/local/bin/app
CMD [ ""/usr/local/bin/app"" ]
</code></pre>

<p>Multi-stage is ideal with statically compiled binaries which you can run with scratch as your base image, or transitioning from a compile environment like JDK to a runtime like JRE. This is the easiest way to dramatically reduce your image size while still having fast builds. You may still perform chaining of steps in your release stage if you have steps that change or delete files created in previous steps, but for the most part, the <code>COPY</code> from another stage isolates the release stage from any layer bloat experienced in the earlier build stages.</p>

<hr>

<p>Note, I do not recommend squashing images since this reduces the size of one image at the expense of eliminating layer reuse. That means future builds of the same image will require more disk and network traffic to send updates. To go back to the first example, squashing may reduce your image from 2 GB to 1 GB, but not 3 images may take up 3 GB instead of the 2.1 GB.</p>
",7730,2019-05-08T12:02:05.990,"['FROM python\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n# note how the code is copied only after the pip install\n# since code changes but requirements.txt doesn\'t\nCOPY . .\nCMD [""gunicorn"", ""app:app""]\n', 'RUN apt-get update \\\n && apt-get install -y \\\n      a-package \\\n      wget \\\n && ... \\\n && apt-get purge -y wget \\\n && rm -r a-build-dir \\\n && apt-get purge -y a-package\n', '# first create and leave containers from any RUN step using options on build\ndocker image build --rm=false --no-cache -t image_name . \n# review which layers use an unexpectedly large amount of space\ndocker image history image_name\n# list all containers, particularly the exited ones from above\ndocker container ps -a \n# examine any of those containers\ndocker container diff ${container_id} \n# ... repeat the diff for other build steps\n# then cleanup exited containers\ndocker container prune\n', 'FROM debian:9 as build\n# still chain update with install to prevent stale cache issues\nRUN apt-get update \\\n && apt-get install -y \\\n      a-package \\\n      wget \\\nRUN ... # perform any download/compile steps\n\nFROM debian:9-slim as release\nCOPY --from=build /usr/local/bin/app /usr/local/bin/app\nCMD [ ""/usr/local/bin/app"" ]\n']"
833,8050,8041,CC BY-SA 4.0,2019-05-07T18:28:42.450,"<p>I figured it out. I was cloning directly into the workspace and then setting my environment variables to point to the workspace as well. I modified both those things. I now create a dir in my workspace and clone into it and I also set my environment variables to directories inside my workspace. Like so:</p>

<pre><code>node('build-01') {
    withEnv([""CMAKE_INSTALL_DIR=${WORKSPACE}/cmake_install"", ""SDK_INSTALL_DIR=${WORKSPACE}/sdk""]){
        stage('Building') {
            echo ""[*] Starting build (id: ${env.BUILD_ID}) on ${env.JENKINS_URL}""
            try {
                sh 'ls -l'
                //ls shows the damn file
                dir('path/to/checkout') {
                    sh '. ./setup-target'
                }
            } catch(all) { 
                sh ""echo 'Failed to run setup-target script with error: ' ${all}""
            }
        }    
    }
}
</code></pre>

<p>This works. </p>

<p>Note: Since this site is in beta phase and I barely got any views I posted the same question to stackoverflow, here it is for refernce: <a href=""https://stackoverflow.com/questions/56015463/set-environment-variables-then-run-script-in-jenkins-scripted-pipeline"">https://stackoverflow.com/questions/56015463/set-environment-variables-then-run-script-in-jenkins-scripted-pipeline</a> </p>
",14791,2019-05-07T23:21:12.350,"['node(\'build-01\') {\n    withEnv([""CMAKE_INSTALL_DIR=${WORKSPACE}/cmake_install"", ""SDK_INSTALL_DIR=${WORKSPACE}/sdk""]){\n        stage(\'Building\') {\n            echo ""[*] Starting build (id: ${env.BUILD_ID}) on ${env.JENKINS_URL}""\n            try {\n                sh \'ls -l\'\n                //ls shows the damn file\n                dir(\'path/to/checkout\') {\n                    sh \'. ./setup-target\'\n                }\n            } catch(all) { \n                sh ""echo \'Failed to run setup-target script with error: \' ${all}""\n            }\n        }    \n    }\n}\n']"
834,8051,4341,CC BY-SA 4.0,2019-05-07T18:29:14.157,"<p>While I'd normally agree with the other answers that Kubernetes is overkill, <a href=""https://kubesail.com"" rel=""nofollow noreferrer"">KubeSail</a> simplifies it as much as possible in order to make it easy to run tasks like yours. There is a free tier that should let you run your job indefinitely. You just need to log in with GitHub, get your <a href=""https://kubesail.com/config"" rel=""nofollow noreferrer"">Kube config</a>, and then you can use the following:</p>

<pre><code>apiVersion: batch/v1
kind: Job
metadata:
  name: my-python-script
spec:
  template:
    spec:
      containers:
      - name: my-python-script
        image: asciimo/my-python-image
</code></pre>

<p>Just save out the above to <code>my-job.yaml</code>, replacing <code>image: asciimo/my-python-image</code> with the name of your image on dockerhub (or another registry), then run</p>

<pre><code>kubectl apply -f my-job.yaml
</code></pre>

<p>If you wanted to learn more about Jobs, the Kubernetes docs contain a lot more info and options: <a href=""https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/"" rel=""nofollow noreferrer"">https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/</a></p>

<p><em>Full disclosure, I am one of the KubeSail Founders</em></p>
",14809,2019-05-07T19:01:18.023,"['apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: my-python-script\nspec:\n  template:\n    spec:\n      containers:\n      - name: my-python-script\n        image: asciimo/my-python-image\n', 'kubectl apply -f my-job.yaml\n']"
835,8052,8037,CC BY-SA 4.0,2019-05-07T18:38:38.343,"<p>This seems to be the right idea: <a href=""https://stackoverflow.com/questions/29328278/installing-jenkins-plugins-to-docker-jenkins/29328489#29328489"">https://stackoverflow.com/questions/29328278/installing-jenkins-plugins-to-docker-jenkins/29328489#29328489</a></p>

<p>so in the Dockerfile you'd just use:</p>

<pre><code>COPY plugins.txt /usr/share/jenkins/plugins.txt
RUN /usr/local/bin/install-plugins.sh &lt; /usr/share/jenkins/plugins.txt
</code></pre>

<p>I tried it and it worked for me.</p>
",7837,2019-05-07T18:38:38.343,['COPY plugins.txt /usr/share/jenkins/plugins.txt\nRUN /usr/local/bin/install-plugins.sh < /usr/share/jenkins/plugins.txt\n']
836,8060,8059,CC BY-SA 4.0,2019-05-08T09:01:17.960,"<p>I suggest you mount your conf file as a volume:</p>

<pre><code>docker run -v nginx.conf:/etc/nginx/nginx.conf ....
</code></pre>

<p>This way you can easily change the file outside the container and then just restart the container. If you change your config file inside the container and then you should have to restart nginx to pick-up the changes. At that point your container will stop because you stopped the main process.</p>

<p>Your local nginx.conf should already have the initial configuration which you can copy from inside the container (cat /etc/nginx/nginx.conf).</p>
",13226,2019-05-08T09:01:17.960,['docker run -v nginx.conf:/etc/nginx/nginx.conf ....\n']
837,8061,8025,CC BY-SA 4.0,2019-05-08T09:06:43.927,"<p>You need to remove the volumes all together. Files are copied by your Dockerfile build:</p>

<pre><code>version: '3'
services:
  web:
    build: .
    command: npm start
    ports:
      - 80:8080
</code></pre>
",13226,2019-05-08T09:06:43.927,"[""version: '3'\nservices:\n  web:\n    build: .\n    command: npm start\n    ports:\n      - 80:8080\n""]"
838,8063,3588,CC BY-SA 4.0,2019-05-08T13:45:52.673,"<p>I met the same situation. I have <code>login1</code> for my machine, passwordless sudo and <code>login2</code>, under which I should perform some actions. I did not solve it by ansible means. But I made such a workaround:</p>

<pre><code>- name: ""Install nvm""
  shell: sudo -u buildkite-agent bash -c ""&lt;my commands to be performed on behalf of buildkite-agent&gt;""
  become: true
</code></pre>

<p>Such a case:</p>

<pre><code>- name: ""Install nvm""
  shell: sudo -u buildkite-agent &lt;my commands to be performed on behalf of buildkite-agent&gt;
  become: true
</code></pre>

<p>do not change home to <code>buildkite-agent</code>'s home, i.e. uses <code>/root</code> as home.</p>
",14820,2019-05-10T00:59:40.283,"['- name: ""Install nvm""\n  shell: sudo -u buildkite-agent bash -c ""<my commands to be performed on behalf of buildkite-agent>""\n  become: true\n', '- name: ""Install nvm""\n  shell: sudo -u buildkite-agent <my commands to be performed on behalf of buildkite-agent>\n  become: true\n']"
839,8067,8065,CC BY-SA 4.0,2019-05-09T00:47:43.013,"<p>What you're after is referred to as ""Review Apps"" by <a href=""https://about.gitlab.com/product/review-apps/"" rel=""nofollow noreferrer"">Gitlab</a> and <a href=""https://devcenter.heroku.com/articles/github-integration-review-apps"" rel=""nofollow noreferrer"">Heroku</a>. It relies on a CI/CD system that runs pipelines on every branch, and exposes the branch name to the build (usually as an environment variable). You can then use the branch name to namespace the resources created by your Infrastructure as Code.</p>

<p>You have mentioned Docker so I will use Kubernetes as an example, but this approach can be applied to just about any deployment method.</p>

<p>Normally when deploying a Docker image, you would name your deployment after the app, e.g.:</p>

<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
# ...
</code></pre>

<p>Using either some kind of preprocessor (Jinja, envsubst, etc.) or a tool like <a href=""https://helm.sh/"" rel=""nofollow noreferrer"">Helm</a> we can pass in some parameters to make the resource include the branch name during the pipeline:</p>

<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app-${BRANCH_NAME}
# ...
</code></pre>

<p>This way, branches do not deploy on top of each other. The resources they deploy are isolated to the branch.</p>

<p>For an API or web app, you'll want some kind of DNS name and load balancer. Kubernetes handles this quite easily with Ingress and DNS controllers, so I'll use CloudFormation as an example this time.</p>

<pre><code>AWSTemplateFormatVersion: '2010-09-09'
Parameters:
  Branch:
    Type: String
  Environment:
    Type: String
  Zone:
    Type: String

Resources:
# ALB resources omitted for brevity...

  Route53:
    Type: AWS::Route53::RecordSet
    Properties:
      Name: !Sub
        - ""my-app-${Branch}.${Environment}.${Zone}""
      HostedZoneName: !Ref Zone
      Type: A
      AliasTarget:
        HostedZoneId: !GetAtt ALB.CanonicalHostedZoneID
        DNSName: !GetAtt ALB.DNSName
</code></pre>

<p>Here we create a DNS record that is very specific to the branch. The DNS record resolves to a load balancer which should point to the containers deployed by the pipeline for this branch. The stack name is also specific to the branch, so pipelines on other branches will not affect it. The end result is that each feature branch will have a dedicated URL (<code>https://my-app-my-feature.dev.example.com</code>) that your developers can use to test and showcase to stakeholders.</p>

<blockquote>
  <p>Should we create 6 new servers/containers if we only make changes in application A?</p>
</blockquote>

<p>No. This isn't specifically related to Review Apps, but microservices in general should be self-contained: decoupled from each other so that they can be deployed in isolation. Removing dependencies and making small changes will increase your development/deployment velocity.</p>

<h2>Considerations</h2>

<h3>Cleanup</h3>

<p>What happens when you merge or delete your branch? Without setting up some kind of cleanup, those containers and DNS records will sit around forever. You need some kind of cleanup. Something that just runs periodically and deletes resources associated to old branches is pretty simple to write, or you could take webhooks from your git server and delete those resources on an event.</p>

<h3>Databases</h3>

<p>Some resources may not warrant getting deployed per-branch, although this should be the exception rather than the norm. You probably don't want to deploy a new database every time someone makes a branch (perhaps unless you have a good schema management tool and DB population scripts). You can have all deployments connect back to the same DB. Ensure that any changes you make to the schema are backwards compatible at least one version behind.</p>
",4369,2019-05-10T00:53:21.603,"['apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app\n# ...\n', 'apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-app-${BRANCH_NAME}\n# ...\n', 'AWSTemplateFormatVersion: \'2010-09-09\'\nParameters:\n  Branch:\n    Type: String\n  Environment:\n    Type: String\n  Zone:\n    Type: String\n\nResources:\n# ALB resources omitted for brevity...\n\n  Route53:\n    Type: AWS::Route53::RecordSet\n    Properties:\n      Name: !Sub\n        - ""my-app-${Branch}.${Environment}.${Zone}""\n      HostedZoneName: !Ref Zone\n      Type: A\n      AliasTarget:\n        HostedZoneId: !GetAtt ALB.CanonicalHostedZoneID\n        DNSName: !GetAtt ALB.DNSName\n']"
840,8068,8044,CC BY-SA 4.0,2019-05-09T08:07:01.960,"<p>While I don't know Bitbucket-specific solution, when it comes to triggering Jenkins builds, I prefer using a simple post-receive Git hook. </p>

<p>In Jenkins select <code>Trigger this build remotely</code> (or something similar, it's usually the very first option in <code>Build triggers</code> section), then set up the post-recevie hook to something like:</p>

<pre><code>#!/bin/bash

username=user
token=1234567890abcdefgh

echo ""Executing hook""

while read oldrev newrev refname
do
   branch_received=$(git rev-parse --symbolic --abbrev-ref $refname)
   echo ""   /===============================""
   echo ""   | PUSH RECEIVED""
   echo ""   | Old revision: $oldrev""
   echo ""   | New revision: $newrev""
   echo ""   | Reference   : $refname""
   echo ""   | Branch name : $branch_received""
   echo ""   \==============================""
   curl -X POST -d ""BRANCH=$branch_received"" http://$username:$token@jenkins/job/job_name/buildWithParameters?token=$token
   res=$?
   if test ""$res"" != ""0""; then
      echo ""The curl command failed with: $res""
   fi
done

exit 0
</code></pre>

<p>Of course, the above runs for every branch and passes the branch name as a parameter to the job. In your case, since you have different job for every branch, you would call different URL depending on what branch was pushed and probably use <code>build</code> rather than <code>buildWithParameters</code> endpoint.</p>
",12864,2019-05-09T08:07:01.960,"['#!/bin/bash\n\nusername=user\ntoken=1234567890abcdefgh\n\necho ""Executing hook""\n\nwhile read oldrev newrev refname\ndo\n   branch_received=$(git rev-parse --symbolic --abbrev-ref $refname)\n   echo ""   /===============================""\n   echo ""   | PUSH RECEIVED""\n   echo ""   | Old revision: $oldrev""\n   echo ""   | New revision: $newrev""\n   echo ""   | Reference   : $refname""\n   echo ""   | Branch name : $branch_received""\n   echo ""   \\==============================""\n   curl -X POST -d ""BRANCH=$branch_received"" http://$username:$token@jenkins/job/job_name/buildWithParameters?token=$token\n   res=$?\n   if test ""$res"" != ""0""; then\n      echo ""The curl command failed with: $res""\n   fi\ndone\n\nexit 0\n']"
841,8073,8071,CC BY-SA 4.0,2019-05-09T16:25:01.920,"<p>I do not have any clue of how your code once ran and produced the expected result. The <code>when</code> clause cannot be executed (as you found out from the error) and would anyway produce the reverse result you are expecting if I follow the underlying logic (install the package only when it is already installed). Moreover, your are in this simple case far from good ansible practice.</p>

<p>You should avoid using <code>shell</code> and <code>command</code> when there is an existing module that already does the job and manages idempotency for you. In present case, you can use the agnostic <a href=""https://docs.ansible.com/ansible/latest/modules/package_module.html"" rel=""nofollow noreferrer""><code>package</code></a> module or the specific <a href=""https://docs.ansible.com/ansible/latest/modules/apt_module.html"" rel=""nofollow noreferrer""><code>apt</code></a> (which I will prefer in my example since your playbook targets an Ubuntu install on wsl and a debian/ubuntu package anyway).</p>

<pre><code>tasks:
  - name: Ensure aptitude is installed
    apt:
      name: aptitude
      state: present
</code></pre>

<p>The above will simply install <code>aptitude</code> unless it is already there in a simple easy single task.</p>
",13111,2019-05-09T16:25:01.920,['tasks:\n  - name: Ensure aptitude is installed\n    apt:\n      name: aptitude\n      state: present\n']
842,8074,3702,CC BY-SA 4.0,2019-05-09T19:26:31.293,"<p>I have the same opinion as you, I see no point in using the Key Vault in such scenarios.</p>

<p>Instead I utilize Azure App Configuration <a href=""https://docs.microsoft.com/en-us/azure/azure-app-configuration/overview"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/azure-app-configuration/overview</a> , where I simply store all application settings. 
And the only string I store together within the actual app service/ func/ web job, would be the connection string for accessing the Azure App Configuration.</p>

<p>In my Startup where the configuration settings is applied I either read from ..settings.json, and if not present (which it should not be if running on Azure), I look for the connection string to the Azure App Configuration.</p>

<p>If ..settings.json is found, it means that I'm running locally. </p>

<p>..settings.json is encrypted if it is not in gitignore file.</p>

<p>It looks something like this: </p>

<pre><code>var appConfigEndpoint = Environment.GetEnvironmentVariable(""AppConfigEndpoint"");
            var appConfigLabel = Environment.GetEnvironmentVariable(""AppConfigLabel"");

            if (!string.IsNullOrEmpty(appConfigEndpoint))
            {
                config.AddAzureAppConfiguration(options =&gt;
                {
                    options.Connect(appConfigEndpoint);
                    options.Use(keyFilter: ""*"", labelFilter: appConfigLabel);
                });
            }
            else
            {
                config.AddJsonFile(""appsettings.test.json"", optional: false);
            }
</code></pre>
",14868,2019-05-09T19:26:31.293,"['var appConfigEndpoint = Environment.GetEnvironmentVariable(""AppConfigEndpoint"");\n            var appConfigLabel = Environment.GetEnvironmentVariable(""AppConfigLabel"");\n\n            if (!string.IsNullOrEmpty(appConfigEndpoint))\n            {\n                config.AddAzureAppConfiguration(options =>\n                {\n                    options.Connect(appConfigEndpoint);\n                    options.Use(keyFilter: ""*"", labelFilter: appConfigLabel);\n                });\n            }\n            else\n            {\n                config.AddJsonFile(""appsettings.test.json"", optional: false);\n            }\n']"
843,8084,8083,CC BY-SA 4.0,2019-05-10T14:34:49.520,"<p>On Linux, containers live in separate network namespaces, so localhost or 127.0.0.1 on the container is not localhost on the host. I'm not sure about other OSes. You could expose a port to the host like this:</p>

<pre><code>docker run -p 3306:3306 mysql
</code></pre>

<p>Then you can access it from any container at the host IP address, which for the default network is 172.17.0.1:3306. You can add -p many times, read the docs here: <a href=""https://docs.docker.com/"" rel=""nofollow noreferrer"">https://docs.docker.com/</a></p>

<p>All that the -p does on Linux, is essentially:</p>

<pre><code>sudo iptables -t nat -A DOCKER \! -i docker0 -p tcp --dport 3306 -j DNAT --to 172.17.0.2:3306
</code></pre>

<p>(Or whatever your mysql container IP address is.) Docker compose and similar utilities make containers able to see each other with <strong>--link</strong> eg.</p>

<pre><code>docker run --link web --link mysql:localmysql app
</code></pre>

<p>The only thing this does is to put the correct IP address for the container in a file called /etc/hosts inside the container (but this might change in future.) </p>

<p>If you want to use --link, all containers need to be on the same network. You can connect them while running with:</p>

<pre><code>docker network connect mynet web
</code></pre>

<p>The main reason for doing this is because the containers don't have fixed IP addresses. You can do:</p>

<pre><code>docker run --network mynet --ip 172.18.0.10 -d app
</code></pre>

<p>To give your container a static IP - and then just use that instead of the name. The docker team keeps changing how things work, so you might need to run additional commands to allow different networks to connect to each other. </p>

<p>You can of course also do all of this manually, on Linux, using the firewall, on the host machine. (Start learning about it here: <a href=""https://www.google.com/search?q=iptables"" rel=""nofollow noreferrer"">https://www.google.com/search?q=iptables</a> (Also look at the Images tab!)</p>

<pre><code>iptables -nvxL # shows the filter table
iptables -nvxL -t nat # shows the NAT table where port forwarding is done
</code></pre>

<p>To dynamically forward a port to a container, get its IP address, eg 172.18.0.10, then:</p>

<pre><code>iptables -t nat -A POSTROUTING -p tcp --dport 1234 -j DNAT --to 172.18.0.10:4567
</code></pre>

<p>Be keenly aware that if you do this, and your container restarts, or gets another IP address, that this will not automatically update, and unless you use iptables-save and iptables-restore in your startup and cron scripts, these manually created rules will disappear. Also that the docker command and compose scripts won't know about any configuration that you manually add like this.</p>

<p>If you really want localhost in your container to point somewhere else, you can edit /etc/hosts inside the container, and change the IP address of localhost - be very keenly aware that other things might break, because localhost is supposed to point to the same host, not another one, so there will be unintended consequences at some point. </p>
",14885,2019-05-10T15:04:05.200,"['docker run -p 3306:3306 mysql\n', 'sudo iptables -t nat -A DOCKER \\! -i docker0 -p tcp --dport 3306 -j DNAT --to 172.17.0.2:3306\n', 'docker run --link web --link mysql:localmysql app\n', 'docker network connect mynet web\n', 'docker run --network mynet --ip 172.18.0.10 -d app\n', 'iptables -nvxL # shows the filter table\niptables -nvxL -t nat # shows the NAT table where port forwarding is done\n', 'iptables -t nat -A POSTROUTING -p tcp --dport 1234 -j DNAT --to 172.18.0.10:4567\n']"
844,8085,8069,CC BY-SA 4.0,2019-05-10T15:13:48.107,"<p>Not knowing anything about the java appication, but just going on what you can do with docker: The workdir for the parent image is /root. You can try to omit the WORKDIR statement. The build script might be working in the current directory, which would not be /root, but /workdir. Or you can add WORKDIR /root again before CMD. </p>

<p>Also don't forget some basic checks, eg. </p>

<pre><code>df -h 
</code></pre>

<p>to check if your server has enough free space (granted, it would have given an error message.) Also remove old containers: </p>

<pre><code>docker ps -a 
docker rm containername
docker images
docker rmi imagename
</code></pre>

<p>If you add the WORKDIR root at the end, and the jar is created at</p>

<pre><code> /root/.ivy2/local/default/root_2.12/0.1.0-SNAPSHOT/jars/root_2.12.jar 
</code></pre>

<p>instead of, say:</p>

<pre><code>/root/.ivy2/local/com.test/myproject/1.0.1/jars/myproject.jar
</code></pre>

<p>You can try to find the scripts that generate that path with grep:</p>

<pre><code>egrep -r '(jars|root|default)' * 
</code></pre>

<p>This will recursively list all the files where those terms appear. You can scan them for clues so as to what configuration files or environment variables to use. Also check the configuration section of the documentation for the jar generating application. (It's not software I am familiar with.) If you find that there is an environment variable that informs the location, lets say for example PROJECT, then you can include it in the Dockerfile:</p>

<pre><code>ENV PROJECT myproject.test.com
</code></pre>

<p>Or if you want to dynamically pass it to the container when you run it:</p>

<pre><code>docker run -E PROJECT=myproject.test.com myproject:v1
</code></pre>

<p>More likely however, is that it is inside some sort of configuration file that you need to copy to the container. Because ""docker build"" copies all the files in the current directory, you can just create the file in the current directory. Or if you need to manually put it somewhere else:</p>

<pre><code>PUT configfile /some/path
</code></pre>

<p>Or</p>

<pre><code>RUN mv configfile /some/path
</code></pre>

<p>Or you can create it dynamically inside the container. If it's just one line that needs to be in a file in the container:</p>

<pre><code>RUN bash -c ""echo project: myproject.test.com &gt; /some/path/configfile""
</code></pre>

<p>As a plan B you can always just create a softlink inside the container, if it will solve your problem:</p>

<pre><code>mkdir -p /root/.ivy2/local/com.test/myproject/1.0.1
ln -s /root/.ivy2/local/default/root_2.12/0.1.0-SNAPSHOT/jars /root/.ivy2/local/com.test/myproject/1.0.1/
</code></pre>

<p>You can also add this as a RUN command before the CMD in the Dockerfile:</p>

<pre><code>RUN mkdir -p /root/.ivy2/local/com.test/myproject/1.0.1 &amp;&amp; /root/.ivy2/local/default/root_2.12/0.1.0-SNAPSHOT/jars /root/.ivy2/local/com.test/myproject/1.0.1/
</code></pre>
",14885,2019-05-13T06:48:03.743,"['df -h \n', 'docker ps -a \ndocker rm containername\ndocker images\ndocker rmi imagename\n', ' /root/.ivy2/local/default/root_2.12/0.1.0-SNAPSHOT/jars/root_2.12.jar \n', '/root/.ivy2/local/com.test/myproject/1.0.1/jars/myproject.jar\n', ""egrep -r '(jars|root|default)' * \n"", 'ENV PROJECT myproject.test.com\n', 'docker run -E PROJECT=myproject.test.com myproject:v1\n', 'PUT configfile /some/path\n', 'RUN mv configfile /some/path\n', 'RUN bash -c ""echo project: myproject.test.com > /some/path/configfile""\n', 'mkdir -p /root/.ivy2/local/com.test/myproject/1.0.1\nln -s /root/.ivy2/local/default/root_2.12/0.1.0-SNAPSHOT/jars /root/.ivy2/local/com.test/myproject/1.0.1/\n', 'RUN mkdir -p /root/.ivy2/local/com.test/myproject/1.0.1 && /root/.ivy2/local/default/root_2.12/0.1.0-SNAPSHOT/jars /root/.ivy2/local/com.test/myproject/1.0.1/\n']"
845,8086,6659,CC BY-SA 4.0,2019-05-10T15:22:34.067,"<p>Don't quote the command you're trying to run, just do:</p>

<pre><code>docker run --rm -it -v ~/Users/mow/Documents/devFolder/testdev:/app testdev_php php ./vendor/bin/phpunit
</code></pre>

<p>Your image is looking for a file called ""php ./vendor/bin/phpunit"" instead of looking for ""php"" and passing everything else on the line to it. </p>

<p>This is the real reason docker requires all your parameters before the image, because the parameter after the image is the command and everything after it is parameters to that command - don't quote everything. </p>

<p>The Dockerfile equivalent is:</p>

<pre><code>ENTRYPOINT [""/init"",""parameter1"",""parameter2"",""parameter3""]
</code></pre>

<p>If it still doesn't work, check the parent Dockerfiles for the location of ""php"" </p>

<pre><code>docker run --rm -it -v ~/Users/mow/Documents/devFolder/testdev:/app testdev_php /usr/local/bin/php ./vendor/bin/phpunit
</code></pre>
",14885,2019-05-10T15:22:34.067,"['docker run --rm -it -v ~/Users/mow/Documents/devFolder/testdev:/app testdev_php php ./vendor/bin/phpunit\n', 'ENTRYPOINT [""/init"",""parameter1"",""parameter2"",""parameter3""]\n', 'docker run --rm -it -v ~/Users/mow/Documents/devFolder/testdev:/app testdev_php /usr/local/bin/php ./vendor/bin/phpunit\n']"
846,8087,6131,CC BY-SA 4.0,2019-05-10T15:28:53.517,"<p>You need to learn a bit more about Debian or Ubuntu. If you look at every single Debian or Ubuntu container that installs things, you will notice, amongst other things:</p>

<pre><code>apt-get update &amp;&amp; apt -f install [whatever]
</code></pre>

<p>The reason for this is that aptitude doesn't know where to find anything without the ""apt update"".</p>

<p>See for example  <a href=""https://github.com/dockerfile/ubuntu/blob/master/Dockerfile"" rel=""nofollow noreferrer"">https://github.com/dockerfile/ubuntu/blob/master/Dockerfile</a></p>

<pre><code># Install.
RUN \
  sed -i 's/# \(.*multiverse$\)/\1/g' /etc/apt/sources.list &amp;&amp; \
  apt-get update &amp;&amp; \
  apt-get -y upgrade &amp;&amp; \
  apt-get install -y build-essential &amp;&amp; \
  apt-get install -y software-properties-common &amp;&amp; \
  apt-get install -y byobu curl git htop man unzip vim wget &amp;&amp; \
  rm -rf /var/lib/apt/lists/*
</code></pre>

<p>This updates all packages, then installs build-essential, then software-properties-common and then the packages in the second to last line. Of course you don't need all of this. </p>

<p>It is important however to have the apt-get update &amp;&amp; apt-get install on the same line, if you are ever going to deploy your Dockerfile to any CI system. If apt-get update is on its own line, then that layer will never get invalidated as the succeeding layers will have old sources that they build consequent layers from. Keep in mind that every single command generates its own layer, that is why commands are chained in this way - so as to create one layer instead of many that will never serve any purpose. </p>
",14885,2019-05-10T15:28:53.517,"['apt-get update && apt -f install [whatever]\n', ""# Install.\nRUN \\\n  sed -i 's/# \\(.*multiverse$\\)/\\1/g' /etc/apt/sources.list && \\\n  apt-get update && \\\n  apt-get -y upgrade && \\\n  apt-get install -y build-essential && \\\n  apt-get install -y software-properties-common && \\\n  apt-get install -y byobu curl git htop man unzip vim wget && \\\n  rm -rf /var/lib/apt/lists/*\n""]"
847,8088,5192,CC BY-SA 4.0,2019-05-10T15:33:15.747,"<p>The Docker website doesn't know about your operating system and has no docker installation for you. </p>

<p>Try the one packaged by raspbian:</p>

<pre><code>sudo apt install docker.io
</code></pre>

<p>The name is different in some distributions, you can use:</p>

<pre><code>apt-cache search docker
</code></pre>

<p>To see if you can find one. If you can't find any, then switch to an older (or newer?) version of Raspbian. </p>

<p>Or you can search for instructions on how to compile it from source code. </p>
",14885,2019-05-10T16:19:48.787,"['sudo apt install docker.io\n', 'apt-cache search docker\n']"
848,8091,8090,CC BY-SA 4.0,2019-05-11T05:27:08.513,"<p>When configuring PM2 is finished and it's working properly, you must run two commands to make your PM2 as a autostart service and enjoy that.
1) Run 'pm2 save': It's save all of your PM2 configure to a file.</p>

<pre><code>admin@server:~$ sudo pm2 save
</code></pre>

<p>2) Run 'pm2 startup': This command creates a system service and runs your last change saved with the first step. </p>

<pre><code>admin@server:~$ sudo pm2 startup
</code></pre>

<p>So, Run the first command when you changed the configuration to store the last changes.</p>
",11759,2019-05-11T05:27:08.513,"['admin@server:~$ sudo pm2 save\n', 'admin@server:~$ sudo pm2 startup\n']"
849,8094,8069,CC BY-SA 4.0,2019-05-12T09:04:24.540,"<p>You are using docker wrongly in this case IMHO and I have a serious doubt that your <code>docker exec</code> command is targeting the correct container because, from what I see (and my very limited knowledge of sbt/scala), it should be dead by the time the jar is published. Let me explain.</p>

<p><code>sbt publishLocal</code> is not a long living command. It will exit when the jar is published to the local <code>.ivy</code> store on disk. So when you launch a container from your image in foreground with <code>docker run --name mytestcontainer myproject:v1</code> (I added a name for easier debugging purpose on your side...), I am pretty sure you see all your above logs and that the command exits back to your shell.</p>

<p>At this point, if you issue a <code>docker ps</code>, your <code>mytestcontainer</code> will not show up, unless with <code>docker ps -a</code>where it will be listed in the exited container. If you try to start it again (<code>docker start mytestcontainer</code>), it will exit as soon as the jar is re-compiled/published. So there is no way to target an <code>exec</code> on this container since it is not running. The only way to have a shell in a running container out of this image is to override the start command in <code>docker run</code> but this will bypass your jar publication.</p>

<p>Now, what you first want is to publish the jar as part of the image, not to compile/publish it everytime you start a container out of the image.</p>

<pre><code>FROM hseeberger/scala-sbt:11.0.2_2.12.8_1.2.8
MAINTAINER Sara Waheed &lt;sarawaheed3191@gmail.com&gt;

WORKDIR /myproject
ADD . /myproject

RUN sbt publishLocal
</code></pre>

<p>In this case, the jar will be published during the build</p>

<pre><code>docker build -t myproject:v1
</code></pre>

<p>You can then run a container out of your image dropping to jshell as intended by the base image you are using:</p>

<pre><code>docker run -it --rm --name testcontainer myproject:v1
May 12, 2019 8:31:33 AM java.util.prefs.FileSystemPreferences$1 run
INFO: Created user preferences directory.
|  Welcome to JShell -- Version 11.0.2
|  For an introduction type: /help intro

jshell&gt;
</code></pre>

<p>Or if you want a more classic bash shell, you can override the start command:</p>

<pre><code>docker run -it --rm --name testcontainer myproject:v1 /bin/bash
</code></pre>

<p>To go further, if your intent is to deliver your application in a ready to use image, you should have a look at <a href=""https://docs.docker.com/develop/develop-images/multistage-build/"" rel=""nofollow noreferrer"">Docker multistage builds</a>. The idea is to build your jar in an image containing all the needed build tools and to copy the produced artifacts to an other image intended only for run that you will finally distribute. Here is the basic idea from your example. Image/command used are solely for illustration purpose and the process is highly perfectible (e.g. harcoded version....):</p>

<pre><code>FROM hseeberger/scala-sbt:11.0.2_2.12.8_1.2.8 as build
WORKDIR /myproject
ADD . /myproject
RUN sbt publishLocal

FROM openjdk:8-alpine
WORKDIR /myproject
COPY --from=build /root/.ivy2/local/com.test/myproject/1.0.1/jars/myproject.jar .
CMD['java', '-jar', 'myproject.jar']
</code></pre>
",13111,2019-05-12T09:04:24.540,"['FROM hseeberger/scala-sbt:11.0.2_2.12.8_1.2.8\nMAINTAINER Sara Waheed <sarawaheed3191@gmail.com>\n\nWORKDIR /myproject\nADD . /myproject\n\nRUN sbt publishLocal\n', 'docker build -t myproject:v1\n', 'docker run -it --rm --name testcontainer myproject:v1\nMay 12, 2019 8:31:33 AM java.util.prefs.FileSystemPreferences$1 run\nINFO: Created user preferences directory.\n|  Welcome to JShell -- Version 11.0.2\n|  For an introduction type: /help intro\n\njshell>\n', 'docker run -it --rm --name testcontainer myproject:v1 /bin/bash\n', ""FROM hseeberger/scala-sbt:11.0.2_2.12.8_1.2.8 as build\nWORKDIR /myproject\nADD . /myproject\nRUN sbt publishLocal\n\nFROM openjdk:8-alpine\nWORKDIR /myproject\nCOPY --from=build /root/.ivy2/local/com.test/myproject/1.0.1/jars/myproject.jar .\nCMD['java', '-jar', 'myproject.jar']\n""]"
850,8117,8108,CC BY-SA 4.0,2019-05-13T13:12:28.140,"<p>One could use <a href=""https://github.com/030/go-yq"" rel=""nofollow noreferrer"">go-yq</a> if one wants to lookup a value by applying jq style, i.e. if firefox_version then one could look it up by adding a dot:</p>

<blockquote>
<pre><code>docker run -v ${PWD}:/ansible-firefox utrecht/go-yq:2.1.0 \
       .firefox_version /ansible-firefox/defaults/main.yml
</code></pre>
</blockquote>
",210,2019-05-13T14:48:33.143,['docker run -v ${PWD}:/ansible-firefox utrecht/go-yq:2.1.0 \\\n       .firefox_version /ansible-firefox/defaults/main.yml\n']
851,8119,8095,CC BY-SA 4.0,2019-05-13T15:59:08.423,"<p>There is no perfect way to do this that I know of.  To explain why, take this pipeline script as an example:</p>

<pre><code>node('my-first-node') {
  stage('my-first-stage') {
    // some steps here 
  }
}

node('my-second-node') {
  stage('my-second-stage') {
    // some steps here
  }
}

node('my-first-node') {
  stage('my-third-stage') { // must be run after my-second-stage
    // some steps here
  }
}
</code></pre>

<p>This will run your stages in the correct order, but there is no guarantee that the node assigned to run my-first-stage will be the same node as the one assigned to run my-third-stage.  Furthermore, even if you can be confident that they are the same node (for instance, you only have one node with the ""my-first-node"" label in your executor pool), there is no guarantee that the assigned workspace folder will be the same for both stages either.  And even if you use the <a href=""https://jenkins.io/doc/pipeline/steps/workflow-durable-task-step/#ws-allocate-workspace"" rel=""nofollow noreferrer"">workspace step to manually assign a workspace directory</a>, there is no guarantee that the assigned workspace directory will be the one you asked for either.</p>

<p>However, if you don't care that my-first-stage and my-third-stage run in the same workspace directory on the same node and you only care about the order that your steps run in, this works fine.</p>
",4115,2019-05-13T15:59:08.423,"[""node('my-first-node') {\n  stage('my-first-stage') {\n    // some steps here \n  }\n}\n\nnode('my-second-node') {\n  stage('my-second-stage') {\n    // some steps here\n  }\n}\n\nnode('my-first-node') {\n  stage('my-third-stage') { // must be run after my-second-stage\n    // some steps here\n  }\n}\n""]"
852,8125,1943,CC BY-SA 4.0,2019-05-13T22:05:07.950,"<p>One could use <a href=""https://github.com/030/a2d"" rel=""nofollow noreferrer"">A2D</a> to bake an app into a docker image while taking certain things into account, e.g. non-root, permissions, location of the app:</p>

<blockquote>
<pre><code>docker run -v $PWD:/projectName utrecht/a2d:1.0.0 \
       -projectName someProjectName -dockerfile /projectName/Dockerfile
</code></pre>
</blockquote>

<p>returns:</p>

<blockquote>
<pre><code>FROM golang:1.12.4-alpine as builder
COPY . ./someProjectName/
WORKDIR someProjectName
RUN adduser -D -g '' someProjectName &amp;&amp; \
    apk add git &amp;&amp; \
    CGO_ENABLED=0 go build &amp;&amp; \
    cp someProjectName /someProjectName &amp;&amp; \
    chmod 100 /someProjectName

FROM scratch
COPY --from=builder /etc/group /etc/group
COPY --from=builder /etc/passwd /etc/passwd
COPY --from=builder --chown=someProjectName:someProjectName /someProjectName /usr/local/someProjectName
COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/
USER someProjectName
ENTRYPOINT [""/usr/local/someProjectName""]
</code></pre>
</blockquote>
",210,2019-05-13T22:05:07.950,"['docker run -v $PWD:/projectName utrecht/a2d:1.0.0 \\\n       -projectName someProjectName -dockerfile /projectName/Dockerfile\n', 'FROM golang:1.12.4-alpine as builder\nCOPY . ./someProjectName/\nWORKDIR someProjectName\nRUN adduser -D -g \'\' someProjectName && \\\n    apk add git && \\\n    CGO_ENABLED=0 go build && \\\n    cp someProjectName /someProjectName && \\\n    chmod 100 /someProjectName\n\nFROM scratch\nCOPY --from=builder /etc/group /etc/group\nCOPY --from=builder /etc/passwd /etc/passwd\nCOPY --from=builder --chown=someProjectName:someProjectName /someProjectName /usr/local/someProjectName\nCOPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/\nUSER someProjectName\nENTRYPOINT [""/usr/local/someProjectName""]\n']"
853,8127,8121,CC BY-SA 4.0,2019-05-14T01:28:01.627,"<p>For the second part, what happens if you <code>export PS1</code> in <code>~/.bashrc</code> or <code>~/ .bash_profile</code></p>

<pre><code>export PS1='$(whoami)@$(hostname):$(pwd)'
</code></pre>
",14903,2019-05-14T02:15:22.953,"[""export PS1='$(whoami)@$(hostname):$(pwd)'\n""]"
854,8129,5829,CC BY-SA 4.0,2019-05-14T05:29:31.670,"<pre><code>pip install --upgrade ansible-lint&gt;=4.1.0
</code></pre>

<p>Rule 405 has been dropped following the discussion in <a href=""https://github.com/ansible/ansible-lint/issues/456"" rel=""nofollow noreferrer"">https://github.com/ansible/ansible-lint/issues/456</a></p>
",14926,2019-05-14T05:29:31.670,['pip install --upgrade ansible-lint>=4.1.0\n']
855,8136,6126,CC BY-SA 4.0,2019-05-14T22:08:14.713,"<p>The variable must be defined in a <code>script</code> section.</p>

<pre><code>pipeline {
    agent none
    stages {
        stage(""first"") {
            script {
                 foo = ""bar""
            }
            sh ""echo ${foo}""
        }
    }
}
</code></pre>
",14941,2019-05-14T22:08:14.713,"['pipeline {\n    agent none\n    stages {\n        stage(""first"") {\n            script {\n                 foo = ""bar""\n            }\n            sh ""echo ${foo}""\n        }\n    }\n}\n']"
856,8137,8002,CC BY-SA 4.0,2019-05-14T22:24:25.530,"<p>Some credential types cannot be bound directly in an environment section. <a href=""https://jenkins.io/doc/book/pipeline/jenkinsfile/#handling-credentials"" rel=""nofollow noreferrer"">From the docs</a> : </p>

<blockquote>
  <p>If you need to set credentials in a Pipeline for anything other than secret text, usernames and passwords, or secret files - i.e SSH keys or certificates, then use Jenkins' Snippet Generator feature, which you can access through Jenkins' classic UI.</p>
</blockquote>

<p>So the generator would give you something looking like this:</p>

<pre><code>withCredentials([certificate(aliasVariable: '', credentialsId: 'myCert', keystoreVariable: 'CERT', passwordVariable: '')]) {
    // some block
}
</code></pre>
",14941,2019-05-14T22:24:25.530,"[""withCredentials([certificate(aliasVariable: '', credentialsId: 'myCert', keystoreVariable: 'CERT', passwordVariable: '')]) {\n    // some block\n}\n""]"
857,8147,5778,CC BY-SA 4.0,2019-05-16T06:29:08.073,"<p>This response is for 
Kernel: Linux 4.4.132-1075-rockchip-ayufan-ga83beded8524
Architecture: aarch64 aarch64 aarch64 GNU/Linux</p>

<p>I had the same issue when issuing commands to a cluster in swarm mode. </p>

<p>Running <code>docker info</code> would result in <code>Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?</code></p>

<p>Running <code>sudo systemctl start docker</code> would result in a failed service state and output reading </p>

<pre><code>Job for docker.service failed because the control process exited with error code.
See ""systemctl status docker.service"" and ""journalctl -xe"" for details.
</code></pre>

<p>Running <code>systemctl status docker.service</code> would result in</p>

<pre><code>docker.service - Docker Application Container Engine
   Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)
   Active: failed (Result: exit-code) since Thu 2019-05-16 06:03:46 UTC; 1min 12s ago
     Docs: https://docs.docker.com
  Process: 3874 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock (cod
 Main PID: 3874 (code=exited, status=2)
</code></pre>

<p>Running <code>journalctl -xe</code> wouldn't result in any information related to docker </p>

<p>Running <code>sudo dockerd -D</code> would result in lots of output with a certain line reading
<code>error=""name conflicts with an existing object"" module=node node.id=105rworelt1fvw9ttjhnf61aw</code></p>

<p>Looking in <code>/var/lib/docker</code> there is a folder called <code>swarm</code> and doing a grep on all files and folders in the swarm directory for the 
string <code>105rworelt1fvw9ttjhnf61aw</code> came up with two files with the string <code>105rworelt1fvw9ttjhnf61aw</code> in them.
sudo grep -r ""105rworelt1fvw9ttjhnf61aw"" /var/lib/docker/swarm/</p>

<p>Those two files were <code>/var/lib/docker/swarm/.tmp-state.json504201306</code> and <code>/var/lib/docker/swarm/state.json</code></p>

<p>At this point I wasn't feeling very surgical so I removed all files and folders under the <code>/var/lib/docker/swarm</code> and then tried <code>sudo systemctl start docker</code> again</p>

<pre><code>A bit surgical: sudo rm -ri /var/lib/docker/swarm/
</code></pre>

<p>Note: Don't delete the <code>swarm</code> directory. If you do just create it again.</p>

<p>After this a <code>docker info</code> would work and I was able to <code>docker swarm init</code> again and deploy a stack without issues</p>
",14967,2019-05-16T06:29:08.073,"['Job for docker.service failed because the control process exited with error code.\nSee ""systemctl status docker.service"" and ""journalctl -xe"" for details.\n', 'docker.service - Docker Application Container Engine\n   Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)\n   Active: failed (Result: exit-code) since Thu 2019-05-16 06:03:46 UTC; 1min 12s ago\n     Docs: https://docs.docker.com\n  Process: 3874 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock (cod\n Main PID: 3874 (code=exited, status=2)\n', 'A bit surgical: sudo rm -ri /var/lib/docker/swarm/\n']"
858,8159,8150,CC BY-SA 4.0,2019-05-17T16:48:54.870,"<blockquote>
  <p>How to formulate the code to get rid of [DEPRECATION WARNING] during runtime? </p>
</blockquote>

<p>Simply by following the tip in the error message.</p>

<pre><code>when: CURRENT_INSTALLED_VERSION.stdout is version(EXPECTED_REMOTE_SOFTWARE_VERSION,'&gt;=')
</code></pre>

<blockquote>
  <p>Is there are better way to apply the same logic?</p>
</blockquote>

<p>I don't see anything wrong if it meets your current needs.</p>

<p>Only remark: The first task is not idempotent. It will report change anytime it runs (because shell is supposed by default to change the remote system). Since your command is a simple grep that does not change anything, your can have the task report always ok by adding the option:</p>

<pre><code>changed_when: false
</code></pre>
",13111,2019-05-18T12:58:52.370,"[""when: CURRENT_INSTALLED_VERSION.stdout is version(EXPECTED_REMOTE_SOFTWARE_VERSION,'>=')\n"", 'changed_when: false\n']"
859,8176,8165,CC BY-SA 4.0,2019-05-20T22:01:21.123,"<p>This was covered in an <a href=""https://jenkins.io/blog/2018/07/02/whats-new-declarative-piepline-13x-sequential-stages/"" rel=""nofollow noreferrer"">official blog post</a> when the feature to nest stages inside a parallel block was added.</p>

<p>Here is the example copy-pasted from the blog post.  In this example, the Windows and Linux blocks are run in parallel, but the stages within each block are run sequentially:</p>

<pre><code>pipeline {
    agent none

    stages {
        stage(""build and deploy on Windows and Linux"") {
            parallel {
                stage(""windows"") {
                    agent {
                        label ""windows""
                    }
                    stages {
                        stage(""build"") {
                            steps {
                                bat ""run-build.bat""
                            }
                        }
                        stage(""deploy"") {
                            when {
                                branch ""master""
                            }
                            steps {
                                bat ""run-deploy.bat""
                            }
                        }
                    }
                }

                stage(""linux"") {
                    agent {
                        label ""linux""
                    }
                    stages {
                        stage(""build"") {
                            steps {
                                sh ""./run-build.sh""
                            }
                        }
                        stage(""deploy"") {
                             when {
                                 branch ""master""
                             }
                             steps {
                                sh ""./run-deploy.sh""
                            }
                        }
                    }
                }
            }
        }
    }
}
</code></pre>

<p>EDIT: I missed that you're trying to do this based on arbitrary input.  If you want to do that, you must use scripted Pipelines (or a script nested in a Declarative Pipeline).  Plain Declarative Pipelines don't support that kind of runtime-defined Pipelines.</p>
",4115,2019-05-20T22:01:21.123,"['pipeline {\n    agent none\n\n    stages {\n        stage(""build and deploy on Windows and Linux"") {\n            parallel {\n                stage(""windows"") {\n                    agent {\n                        label ""windows""\n                    }\n                    stages {\n                        stage(""build"") {\n                            steps {\n                                bat ""run-build.bat""\n                            }\n                        }\n                        stage(""deploy"") {\n                            when {\n                                branch ""master""\n                            }\n                            steps {\n                                bat ""run-deploy.bat""\n                            }\n                        }\n                    }\n                }\n\n                stage(""linux"") {\n                    agent {\n                        label ""linux""\n                    }\n                    stages {\n                        stage(""build"") {\n                            steps {\n                                sh ""./run-build.sh""\n                            }\n                        }\n                        stage(""deploy"") {\n                             when {\n                                 branch ""master""\n                             }\n                             steps {\n                                sh ""./run-deploy.sh""\n                            }\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n']"
860,8182,8167,CC BY-SA 4.0,2019-05-21T04:01:37.233,"<p>I have resolved the issue by update the gateway manifest.
Not sure why the error happen when adding multiple ""match"".</p>

<pre><code>apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-gateway
spec:
  selector:
    istio: ingressgateway #default istio ingressgateway
  servers:
  - port:
      number: 80
      name: http-istio-gateway
      protocol: HTTP
    hosts:
    - ""*""
    tls:
      httpsRedirect: true
  - port:
      number: 443
      name: https-istio-gateway
      protocol: HTTP
    hosts:
    - ""*""
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: api-gateway
spec:
  gateways:
  - istio-gateway
  hosts:
  - ""*""
  http:
  - match:
    - uri:
        prefix: ""/socket.io""
    route:
    - destination:
        host: api-gateway-ws.default.svc.cluster.local
        port:
          number: 5001
    websocketUpgrade: true
  - route:
    - destination:
        host: api-gateway.default.svc.cluster.local
        port:
          number: 5000
</code></pre>
",12348,2019-05-21T04:01:37.233,"['apiVersion: networking.istio.io/v1alpha3\nkind: Gateway\nmetadata:\n  name: istio-gateway\nspec:\n  selector:\n    istio: ingressgateway #default istio ingressgateway\n  servers:\n  - port:\n      number: 80\n      name: http-istio-gateway\n      protocol: HTTP\n    hosts:\n    - ""*""\n    tls:\n      httpsRedirect: true\n  - port:\n      number: 443\n      name: https-istio-gateway\n      protocol: HTTP\n    hosts:\n    - ""*""\n---\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: api-gateway\nspec:\n  gateways:\n  - istio-gateway\n  hosts:\n  - ""*""\n  http:\n  - match:\n    - uri:\n        prefix: ""/socket.io""\n    route:\n    - destination:\n        host: api-gateway-ws.default.svc.cluster.local\n        port:\n          number: 5001\n    websocketUpgrade: true\n  - route:\n    - destination:\n        host: api-gateway.default.svc.cluster.local\n        port:\n          number: 5000\n']"
861,8183,8138,CC BY-SA 4.0,2019-05-21T05:24:21.313,"<p>Git itself has a server-side <a href=""https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks"" rel=""nofollow noreferrer""><code>post-receive</code> hook</a>. You can use it to run a command that triggers your deployment whenever you push to your repo. Web services like Gitlab or Bitbucket rely on this mechanism to offer plug-ins that trigger CI services. Less flexible but you can configure it conveniently from the web front end.</p>

<hr>

<p>Another option would be to use a tool like Puppet on the target machine that periodically checks the repo for changes and pulls them in. The following Puppet code would clone/update the repo into the <code>/path/to/repo</code> directory (by default Puppet runs every 30 min):</p>

<pre><code>vcsrepo { '/path/to/repo':
  ensure   =&gt; latest,
  provider =&gt; git,
  source   =&gt; 'git://example.com/repo.git',
}
</code></pre>

<p>See the <a href=""https://forge.puppet.com/puppetlabs/vcsrepo"" rel=""nofollow noreferrer"">documentation of the vcsrepo module</a> for details.</p>
",15040,2019-05-21T05:24:21.313,"[""vcsrepo { '/path/to/repo':\n  ensure   => latest,\n  provider => git,\n  source   => 'git://example.com/repo.git',\n}\n""]"
862,8185,4292,CC BY-SA 4.0,2019-05-21T08:20:32.847,"<p>If you organize your code by modules, you could apply terraform only on a module, eg :</p>

<pre><code># securitygroup.tf
module ""securitygroup"" {
  source = ""git@github.com:user/securitygroup-terraform-module.git?ref=master""
}

$ tf apply -target=module.securitygroup
</code></pre>
",15035,2019-05-21T08:20:32.847,"['# securitygroup.tf\nmodule ""securitygroup"" {\n  source = ""git@github.com:user/securitygroup-terraform-module.git?ref=master""\n}\n\n$ tf apply -target=module.securitygroup\n']"
863,8195,5898,CC BY-SA 4.0,2019-05-22T10:47:55.483,"<p>It's in file <code>/etc/kubernetes/manifests/kube-controller-manager.yaml</code></p>

<pre><code># sudo grep cidr /etc/kubernetes/manifests/kube-*
/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --allocate-node-cidrs=true
/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --cluster-cidr=192.168.0.0/16
/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --node-cidr-mask-size=24
</code></pre>
",15067,2019-05-22T10:47:55.483,['# sudo grep cidr /etc/kubernetes/manifests/kube-*\n/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --allocate-node-cidrs=true\n/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --cluster-cidr=192.168.0.0/16\n/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --node-cidr-mask-size=24\n']
864,8202,3262,CC BY-SA 4.0,2019-05-22T20:39:22.930,"<p>Get the latest version of Tomcat:</p>

<pre><code>$ curl -s 'https://api.github.com/repos/apache/tomcat/tags?per_page=1' | jq -r .[].name
9.0.20
</code></pre>

<p>Get the latest version of Tomcat 9:</p>

<pre><code>$ curl -s 'https://api.github.com/repos/apache/tomcat/tags?per_page=100' | jq -r '.[] | .name' | sort -V | grep ^9 | tail -n 1
9.0.20
</code></pre>

<p>Get the latest version of Tomcat 8.5:</p>

<pre><code>$ curl -s 'https://api.github.com/repos/apache/tomcat/tags?per_page=100' | jq -r '.[] | .name' | sort -V | grep ^8.5 | tail -n 1
8.5.41
</code></pre>

<p>Get the latest version of Tomcat 7:</p>

<pre><code>$ curl -s 'https://api.github.com/repos/apache/tomcat/tags?per_page=100' | jq -r '.[] | .name' | sort -V | grep ^7 | tail -n 1
7.0.94
</code></pre>

<p>These all currently match the latest versions listed at <a href=""http://tomcat.apache.org/"" rel=""nofollow noreferrer"">http://tomcat.apache.org/</a></p>
",15079,2019-05-22T20:39:22.930,"[""$ curl -s 'https://api.github.com/repos/apache/tomcat/tags?per_page=1' | jq -r .[].name\n9.0.20\n"", ""$ curl -s 'https://api.github.com/repos/apache/tomcat/tags?per_page=100' | jq -r '.[] | .name' | sort -V | grep ^9 | tail -n 1\n9.0.20\n"", ""$ curl -s 'https://api.github.com/repos/apache/tomcat/tags?per_page=100' | jq -r '.[] | .name' | sort -V | grep ^8.5 | tail -n 1\n8.5.41\n"", ""$ curl -s 'https://api.github.com/repos/apache/tomcat/tags?per_page=100' | jq -r '.[] | .name' | sort -V | grep ^7 | tail -n 1\n7.0.94\n""]"
865,8203,3757,CC BY-SA 4.0,2019-05-22T21:12:25.540,"<p>The way you install certbot plugins depends on how you installed certbot itself. If you installed certbot using some package manager (apt, rpm, brew...), then you should look for compatible certbot plugins in that package manager's repository.</p>

<p>Let's Encrypt also support an alternative installation method: the certbot-auto wrapper. This wrapper creates a private Python virtual installation (generally in <code>/opt/eff.org/certbot/venv</code>), and install certbot into that directory. A nice feature of certbot-auto is that it automatically keeps the certbot client up-to-date. A major downside is that it does not <em>officially</em> supports plugins installation (that is, aside from four plugins that are installed by default).</p>

<p>It is easy enough to work around this limitation, as described in <a href=""https://devops.stackexchange.com/a/4845"">Ryan G's solution</a>. However, plugins installed through that procedure will be lost every time certbot-auto updates itself, which can result in random renew failures. Here, we have had a few situations where some certificates almost reached expiration because of that issue. Several tickets discuss this issue on certbot's bug tracker, and the team acknowledge the problem, but it seems that it might still be a long way before the issue is actually fixed.</p>

<p>Therefore, if using certbot-auto in an automated setup, it is desirable to either prevent certbot-auto's self updating (by running it with <code>--no-self-upgrade</code>), or to implement some strategy to ensure that required plugins are automatically reinstalled every time certbot is updated.</p>

<p>A possible solution to indeed ensure that required plugins are installed is to add a wrapper around certbot-auto. That wrapper could essentially look as follow:</p>

<pre><code>#!/bin/bash

# The list of plugins to be installed
CERTBOT_PLUGINS=""certbot-dns-route53""

# Force the venv directory to be where we can easily find it
export VENV_PATH=""/opt/eff.org/certbot/venv""

# Force certbot-auto to be where we expect it to be
export CERTBOT_AUTO=""/usr/local/bin/certbot-auto-upstream""

# Force certbot-auto to bootstrap or upgrade itself, but do no more
""${CERTBOT_AUTO}""  --install-only  ""$@""

# Check if required plugins are installed; install them if they are missing
(
    cd ${VENV_PATH}
    source bin/activate

    for plugin in $CERTBOT_PLUGINS ; do
        if ! pip show -q ""$plugin"" ; then
            pip install ""$plugin""
        fi
    done

    deactivate
)

# Execute the actual certbot command
""${VENV_PATH}/bin/letsencrypt"" ""$@""
</code></pre>

<p>I have made available a more complete version of that wrapper <a href=""https://gist.github.com/mjameswh/b9e1b3fef3369c1edcac34047f91a952"" rel=""nofollow noreferrer"">here</a>; the only differences with the longer version is that it ensures that the wrapper is being run as root, and it properly handle the <code>--help</code> argument.</p>

<p>To install that wrapper, download the official <code>certbot-auto</code> program to <code>/usr/local/bin/certbot-auto-upstream</code>, and copy the wrapper to <code>/usr/local/bin/certbot-auto</code>. Make sure both files have proper privileges (<code>chown root:root /usr/local/bin/certbot-auto*</code>, then <code>chmod 755 /usr/local/bin/certbot-auto*</code>). In the wrapper file, make sure the line <code>CERTBOT_PLUGINS=""...""</code> includes the list of plugins you actually need. And that's it. Simply use the <code>certbot-auto</code> command, as you would have done previously, and forget about the <code>certbot-auto-upstream</code> file.</p>
",11845,2019-05-22T21:12:25.540,"['#!/bin/bash\n\n# The list of plugins to be installed\nCERTBOT_PLUGINS=""certbot-dns-route53""\n\n# Force the venv directory to be where we can easily find it\nexport VENV_PATH=""/opt/eff.org/certbot/venv""\n\n# Force certbot-auto to be where we expect it to be\nexport CERTBOT_AUTO=""/usr/local/bin/certbot-auto-upstream""\n\n# Force certbot-auto to bootstrap or upgrade itself, but do no more\n""${CERTBOT_AUTO}""  --install-only  ""$@""\n\n# Check if required plugins are installed; install them if they are missing\n(\n    cd ${VENV_PATH}\n    source bin/activate\n\n    for plugin in $CERTBOT_PLUGINS ; do\n        if ! pip show -q ""$plugin"" ; then\n            pip install ""$plugin""\n        fi\n    done\n\n    deactivate\n)\n\n# Execute the actual certbot command\n""${VENV_PATH}/bin/letsencrypt"" ""$@""\n']"
866,8222,6809,CC BY-SA 4.0,2019-05-24T11:33:09.380,"<p>Yes, there is:</p>
<blockquote>
<p>If your commit message contains <code>[ci skip]</code> or <code>[skip ci]</code>, using any capitalization, the commit will be created but the pipeline will be skipped.</p>
<p>Alternatively, one can pass the <code>ci.skip</code> <a href=""https://git-scm.com/docs/git-push#Documentation/git-push.txt--oltoptiongt"" rel=""nofollow noreferrer"">Git push option</a> if using Git 2.10 or newer:</p>
<pre><code>git push -o ci.skip
</code></pre>
</blockquote>
<p>From: <a href=""https://docs.gitlab.com/ee/ci/yaml/#skip-pipeline"" rel=""nofollow noreferrer"">GitLab CI YAML documentation</a> - &quot;Skip Pipeline&quot;</p>
",15117,2021-02-06T05:59:35.310,['git push -o ci.skip\n']
867,8223,8221,CC BY-SA 4.0,2019-05-24T12:42:05.157,"<p>If you're able to connect to the <em>host</em></p>

<pre><code>$ ssh ansible@&lt;host&gt;
</code></pre>

<p>then try</p>

<pre><code>ansible &lt;hosts&gt; -u ansible -m ping
</code></pre>
",7715,2019-05-24T12:42:05.157,"['$ ssh ansible@<host>\n', 'ansible <hosts> -u ansible -m ping\n']"
868,8227,8207,CC BY-SA 4.0,2019-05-24T19:40:49.663,"<p>The thing that makes this complicated is that ansible registers variables and facts locally, on the target remote host - and then has a different set of variables and facts once it moves to the next host. So it would require a bit of fiddling to do this exactly the way you want.</p>

<p>One way to approach this would be to just use run_once, but it doesn't work with <code>serial: 1</code> which you are asking for (check one host at a time);</p>

<pre><code>---
  - name: test
    hosts: all
    vars:
      mem_to_look_for: 62950
    tasks:
      - name: do things
        debug:
          msg: ""hello""
        run_once: true
        when: ansible_memory_mb.real.total==mem_to_look_for

</code></pre>

<p>If you really want it to run serially, we could borrow some of the knowledge out of this article <a href=""https://stackoverflow.com/questions/42376123/how-to-terminate-an-ansible-playbook-run-when-it-is-successful-on-one-host"">https://stackoverflow.com/questions/42376123/how-to-terminate-an-ansible-playbook-run-when-it-is-successful-on-one-host</a> and tweak it a little.. and it works great!</p>

<pre><code>---
  - name: ""test""
    hosts: all
    gather_facts: no
    serial: 1
    vars:
      mem_to_look_for: 62950
    tasks:
      - meta: end_play
        when: ""{% for item in hostvars.values() %}{% if item.done|default(False) %}True{% endif %}{% endfor %}""

      - name: gather facts
        setup:

      - name: ensure host has the memory we're looking for
        set_fact:
          done: true
        when: ansible_memory_mb.real.total==mem_to_look_for

      - name: skip this host if it doesn't have the memory we're looking for
        meta: end_play
        when: ansible_memory_mb.real.total!=mem_to_look_for

      - name: run this thing only on one host
        debug:
          msg: ""running the thing""
</code></pre>

<p>I set the playbook to gather_facts: no because we don't want to continue gathering facts once we found the host we're looking for. It doesn't abort the playbook unfortunately, but just kind of runs a no-op on the remainder of hosts. You could also probably speed things up by tweaking the <code>setup:</code> module by specifying which subset of facts you want to collect, but I left it to collect all the facts in this example. <a href=""https://docs.ansible.com/ansible/latest/modules/setup_module.html"" rel=""nofollow noreferrer"">https://docs.ansible.com/ansible/latest/modules/setup_module.html</a> you may also want to just move the host selection to the setup module by adding <code>failed_when: ansible_memory_mb.real.total!=mem_to_look_for</code> at the end of the setup module, but then the hosts would be marked as failed. I'm not sure if that's what you're looking for, but it's really up to you on if you want them to be failed or just skipped. </p>

<p>Additionally, if you want it to completely stop checking hosts as soon as its done I think the any_errors_fatal property will do that. <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_error_handling.html#aborting-the-play"" rel=""nofollow noreferrer"">https://docs.ansible.com/ansible/latest/user_guide/playbooks_error_handling.html#aborting-the-play</a></p>
",15130,2019-05-26T01:27:49.873,"['---\n  - name: test\n    hosts: all\n    vars:\n      mem_to_look_for: 62950\n    tasks:\n      - name: do things\n        debug:\n          msg: ""hello""\n        run_once: true\n        when: ansible_memory_mb.real.total==mem_to_look_for\n\n', '---\n  - name: ""test""\n    hosts: all\n    gather_facts: no\n    serial: 1\n    vars:\n      mem_to_look_for: 62950\n    tasks:\n      - meta: end_play\n        when: ""{% for item in hostvars.values() %}{% if item.done|default(False) %}True{% endif %}{% endfor %}""\n\n      - name: gather facts\n        setup:\n\n      - name: ensure host has the memory we\'re looking for\n        set_fact:\n          done: true\n        when: ansible_memory_mb.real.total==mem_to_look_for\n\n      - name: skip this host if it doesn\'t have the memory we\'re looking for\n        meta: end_play\n        when: ansible_memory_mb.real.total!=mem_to_look_for\n\n      - name: run this thing only on one host\n        debug:\n          msg: ""running the thing""\n']"
869,8237,6689,CC BY-SA 4.0,2019-05-26T21:59:02.167,"<p>I noticed that the <a href=""https://github.com/microsoft/azure-pipelines-tasks/blob/master/Tasks/DotNetCoreCLIV2/README.md"" rel=""nofollow noreferrer"">description</a> for the filepath properties of the <strong>pack</strong> command is different than the descriptions in the <strong>test</strong> and <strong>publish</strong> commands:</p>

<pre><code>Pattern to search for csproj or nuspec files to pack.

You can separate multiple patterns with a semicolon, and you can
make a pattern negative by prefixing it with '-:'. Example:
**/*.csproj;-:**/*.Tests.csproj
</code></pre>

<p>So perhaps try <code>-:**/*[Tt]ests.csproj;**/*.csproj</code> instead. I don't think this explains why the unit tests are excluded and the integrated tests are not, though.</p>
",11069,2019-07-09T19:20:55.523,"[""Pattern to search for csproj or nuspec files to pack.\n\nYou can separate multiple patterns with a semicolon, and you can\nmake a pattern negative by prefixing it with '-:'. Example:\n**/*.csproj;-:**/*.Tests.csproj\n""]"
870,8242,8239,CC BY-SA 4.0,2019-05-28T06:14:10.487,"<p><strong>DEPRECATED PYTHON</strong></p>

<p>Originally you could install <code>docker-registry</code> via <code>pip</code> <a href=""https://github.com/docker/docker-registry"" rel=""nofollow noreferrer"">https://github.com/docker/docker-registry</a></p>

<p>But this was deprecated with the new generation of <code>docker-registry</code> in <code>golang</code>   </p>

<blockquote>
  <p>Notice: The classical python ""Docker Registry"" is deprecated, in favor
  of a new golang implementation. This here is kept for historical
  purpose, and will not receive any significant work/love any more. You
  should head to the landing page of the new registry or the ""Distribution"" github project instead.</p>
</blockquote>

<p>Here is an old guide that I wouldn't recommend.<br>
<strong>OLD GUIDE (2014):</strong> <a href=""https://www.ceondo.com/notes/docker-registry/"" rel=""nofollow noreferrer"">https://www.ceondo.com/notes/docker-registry/</a></p>

<hr>

<p><strong>LINUX SNAPS</strong></p>

<p>You can also look into Linux Snaps<br>
<strong>LINK:</strong> <a href=""https://snapcraft.io/docker"" rel=""nofollow noreferrer"">https://snapcraft.io/docker</a><br>
<strong>GUIDE:</strong> <a href=""https://www.allprogrammingtutorials.com/tutorials/installing-docker-on-ubuntu-centos-using-snap.php"" rel=""nofollow noreferrer"">https://www.allprogrammingtutorials.com/tutorials/installing-docker-on-ubuntu-centos-using-snap.php</a>  </p>

<pre><code># Lookup docker snap
snap info docker

# Install from stable channel
sudo snap install docker

# Install from a specific channel for deploying older versions
sudo snap install --channel=&lt;channel-name&gt; docker
</code></pre>

<hr>

<p><strong>USING DOCKER</strong></p>

<p>The fastest way to get a private docker registry server running is to install docker and then just run a detached container</p>

<pre><code>sudo apt-get update
sudo apt-get install docker.io
sudo systemctl start docker
sudo systemctl enable docker
docker --version
docker run -d -p 5000:5000 -v /registry/images:/var/lib/registry --restart=always --name registry registry:2
</code></pre>

<p>You may need to setup persistent volumes to store the library images.  </p>

<p>I'm currently using docker installed on a <a href=""https://www.storagereview.com/synology_diskstation_ds1815_review"" rel=""nofollow noreferrer"">Synology DiskStation</a> to host my own private docker registry container</p>
",12767,2019-05-28T06:19:23.557,"['# Lookup docker snap\nsnap info docker\n\n# Install from stable channel\nsudo snap install docker\n\n# Install from a specific channel for deploying older versions\nsudo snap install --channel=<channel-name> docker\n', 'sudo apt-get update\nsudo apt-get install docker.io\nsudo systemctl start docker\nsudo systemctl enable docker\ndocker --version\ndocker run -d -p 5000:5000 -v /registry/images:/var/lib/registry --restart=always --name registry registry:2\n']"
871,8245,8244,CC BY-SA 4.0,2019-05-28T12:33:13.873,"<p>There's apparently 2 methods one can use to leverage <code>tridentctl</code> to interact with a running Trident Pod in their Openshift/Kubernetes cluster.</p>

<h3>1. Server string</h3>

<p>The <code>tridentctl</code> CLI can be instructed to talk to whatever server you want remotely using the <code>-s</code> or <code>--server</code> argument. In this context you could use the approach of remote shelling into the Trident Pod and then directing it to interact with the local Trident Orchestrator daemon.</p>

<strong><em>For example</em></strong>

<pre><code>$ oc -n trident rsh trident-6bdbdbc5dd-l8qtr
Defaulting container name to trident-main.
Use 'oc describe pod/trident-6bdbdbc5dd-l8qtr -n trident' to see all of the containers in this pod.
/ #
</code></pre>

<p>Now to interact:</p>

<pre><code>/ # tridentctl -s 127.0.0.1:8000 get backend
+--------------------------+----------------+--------+---------+
|           NAME           | STORAGE DRIVER | ONLINE | VOLUMES |
+--------------------------+----------------+--------+---------+
| ontapnas_192.168.101.101 | ontap-nas      | true   |     389 |
+--------------------------+----------------+--------+---------+
/ #
</code></pre>

<h3>2. Creating a Bash Function</h3>

<p>To expand on the above method, one could construct a shell function or alias in Bash to streamline this interaction like so:</p>

<em>Openshift</em>

<pre><code>tridentctl () {
    oc rsh -t -n trident -c trident-main \
        $(oc get pods -n trident -l app=trident.netapp.io -o jsonpath=""{.items[].metadata.name}"") \
        tridentctl -s 127.0.0.1:8000 $*
}
</code></pre>

<em>Kubernetes</em>

<pre><code>tridentctl () {
    kubectl exec -t -n trident \
        $(kubectl get pods -n trident -l app=trident.netapp.io -o jsonpath=""{.items[].metadata.name}"") \
        -c trident-main -- tridentctl -s 127.0.0.1:8000 $*
}
</code></pre>

<p>With one of these functions set, you could then run the following command from your macOS system:</p>

<pre><code>$ tridentctl get storageclass -o json
{
  ""items"": [
    {
      ""Config"": {
        ""version"": ""1"",
        ""name"": ""basic"",
        ""attributes"": {
          ""backendType"": ""ontap-nas""
        },
        ""storagePools"": null,
        ""additionalStoragePools"": null
      },
      ""storage"": {
        ""ontapnas_192.168.101.101"": [
          ""NA_01_aggr1"",
          ""NA_01_aggr2""
        ]
      }
    }
  ]
}
</code></pre>

<strong><em>How it works</em></strong>

<p>The above function merely determines the name of the Pod within the <code>trident</code> namespace and then remotely executes the command <code>tridentctl</code> using the same method above (from method #1) of connecting to the locally running Trident Orchestrator daemon within the Pod using the <code>--server</code> string.</p>

<p>The advantage with one of these approaches is that you simply can use a function/alias to codify it.</p>

<strong><em>Caveats</em></strong>

<p>Keep in mind that with the above shell function/alias approach will not work with commands such as this:</p>

<pre><code>$ tridentctl create backend -f &lt;backend-file&gt;
</code></pre>

<p>because the files you'll be referencing with it, <code>-f &lt;backend-file&gt;</code>, will be local to the system where you'll be running the function/alias, but the <code>tridentctl</code> command will actually be executing within a Pod on another system. This Pod will not have access to your local system's filesystem.</p>

<p>Your only options in this situation will be to either copy the file into the Pod's <code>/tmp</code> filesystem and execute it from there or to redirect the contents of the file, <code>&lt;backend-file&gt;</code> through a pipe, (<code>|</code>), for example:</p>

<pre><code>$ cat &lt;backend-file&gt; | tridentctl create backend -f -
</code></pre>
",6619,2019-08-30T13:54:26.983,"[""$ oc -n trident rsh trident-6bdbdbc5dd-l8qtr\nDefaulting container name to trident-main.\nUse 'oc describe pod/trident-6bdbdbc5dd-l8qtr -n trident' to see all of the containers in this pod.\n/ #\n"", '/ # tridentctl -s 127.0.0.1:8000 get backend\n+--------------------------+----------------+--------+---------+\n|           NAME           | STORAGE DRIVER | ONLINE | VOLUMES |\n+--------------------------+----------------+--------+---------+\n| ontapnas_192.168.101.101 | ontap-nas      | true   |     389 |\n+--------------------------+----------------+--------+---------+\n/ #\n', 'tridentctl () {\n    oc rsh -t -n trident -c trident-main \\\n        $(oc get pods -n trident -l app=trident.netapp.io -o jsonpath=""{.items[].metadata.name}"") \\\n        tridentctl -s 127.0.0.1:8000 $*\n}\n', 'tridentctl () {\n    kubectl exec -t -n trident \\\n        $(kubectl get pods -n trident -l app=trident.netapp.io -o jsonpath=""{.items[].metadata.name}"") \\\n        -c trident-main -- tridentctl -s 127.0.0.1:8000 $*\n}\n', '$ tridentctl get storageclass -o json\n{\n  ""items"": [\n    {\n      ""Config"": {\n        ""version"": ""1"",\n        ""name"": ""basic"",\n        ""attributes"": {\n          ""backendType"": ""ontap-nas""\n        },\n        ""storagePools"": null,\n        ""additionalStoragePools"": null\n      },\n      ""storage"": {\n        ""ontapnas_192.168.101.101"": [\n          ""NA_01_aggr1"",\n          ""NA_01_aggr2""\n        ]\n      }\n    }\n  ]\n}\n', '$ tridentctl create backend -f <backend-file>\n', '$ cat <backend-file> | tridentctl create backend -f -\n']"
872,8261,8259,CC BY-SA 4.0,2019-05-30T10:53:48.390,"<p>I believe you would be using multiple modules to create various resources(EC2,ELB, Etc) in AWS using Terraform. You can create a custom module having output value of each variable you want to configure per your requirement like aws-region, etc.</p>

<p>Then source(import) this custom module into your resource module and use its values using $.</p>

<p>custom_module</p>

<pre><code>output ""aws_region"" {
  value = ""us-xyz-1""
}
output ""aws_anyproperty"" {
  value = ""abc""
}

Add above custom_module as source in your resource module

module ""custom_module"" {
  source=""../../../modules/custom_module""
}

provider ""aws"" {
  version=""~&gt; y.x""
  profile=""${module.custom_module.aws_anyproperty}""
  region=""${module.custom_module.aws_region}""
}
</code></pre>
",15203,2019-05-31T07:45:12.493,"['output ""aws_region"" {\n  value = ""us-xyz-1""\n}\noutput ""aws_anyproperty"" {\n  value = ""abc""\n}\n\nAdd above custom_module as source in your resource module\n\nmodule ""custom_module"" {\n  source=""../../../modules/custom_module""\n}\n\nprovider ""aws"" {\n  version=""~> y.x""\n  profile=""${module.custom_module.aws_anyproperty}""\n  region=""${module.custom_module.aws_region}""\n}\n']"
873,8262,8253,CC BY-SA 4.0,2019-05-30T11:06:37.783,"<p>If the artifacts in question are docker images then the recommended artifact management solution is the <a href=""https://cloud.google.com/container-registry/docs/"" rel=""nofollow noreferrer"">Container Registry</a>, well integrated with other GCP products producing and/or using such images.</p>

<p>AFAIK they don't have a real artifact manager for other kinds of artifacts, they suggest the rather general purpose Cloud Storage for that. You can find an example of such use in the <a href=""https://cloud.google.com/cloud-build/docs/quickstart-go"" rel=""nofollow noreferrer"">Quickstart for Go</a> guide. Most likely not what you're looking for:</p>

<pre><code>artifacts:
  objects:
    location: 'gs://[BUCKET_NAME]/'
    paths: ['hello']
</code></pre>
",47,2019-05-30T11:06:37.783,"[""artifacts:\n  objects:\n    location: 'gs://[BUCKET_NAME]/'\n    paths: ['hello']\n""]"
874,8264,8258,CC BY-SA 4.0,2019-05-30T12:49:45.137,"<p>Turns out the answer is iptables, by adding a simple rule:</p>

<pre><code>sudo iptables -I FORWARD -s &lt;source ip&gt; -j TEE --gateway &lt;destination ip&gt;
</code></pre>

<p>e.g.:  </p>

<pre><code>sudo iptables -I FORWARD -s 172.19.0.3 -j TEE --gateway 172.19.0.4
</code></pre>

<p>I can clone the traffic, so if I do this:</p>

<pre><code>sudo iptables -I FORWARD -s &lt;Container1 IP&gt; -j TEE --gateway &lt;Wireshark Container IP&gt;
sudo iptables -I FORWARD -s &lt;Container2 IP&gt; -j TEE --gateway &lt;Wireshark Container IP&gt;
</code></pre>

<p>I will clone all traffic going between Containers1 and 2 to Wireshark container.</p>

<p>(Note that although this solution is a proof of concept, at the time of writing this answer)</p>
",15198,2019-05-30T12:49:45.137,"['sudo iptables -I FORWARD -s <source ip> -j TEE --gateway <destination ip>\n', 'sudo iptables -I FORWARD -s 172.19.0.3 -j TEE --gateway 172.19.0.4\n', 'sudo iptables -I FORWARD -s <Container1 IP> -j TEE --gateway <Wireshark Container IP>\nsudo iptables -I FORWARD -s <Container2 IP> -j TEE --gateway <Wireshark Container IP>\n']"
875,8265,8256,CC BY-SA 4.0,2019-05-30T13:26:16.373,"<p>You need to add a <a href=""https://docs.docker.com/config/containers/start-containers-automatically/#use-a-restart-policy"" rel=""nofollow noreferrer"">restart policy</a> to your container.</p>

<p>example:</p>

<pre><code>docker run -dit --restart=always hello-world
</code></pre>

<p>In this example, I am telling docker to always restart the hello-world container no matter what happens (and also run it in the background interactively). If you do a <code>docker ps</code>, you will see it keeps restarting. To revert this, you need to update the container restart policy like this:</p>

<pre><code>docker update --restart=no &lt;CONTAINER_ID&gt;
</code></pre>
",5051,2019-05-30T13:26:16.373,"['docker run -dit --restart=always hello-world\n', 'docker update --restart=no <CONTAINER_ID>\n']"
876,8269,6542,CC BY-SA 4.0,2019-05-30T16:56:22.040,"<p>I had a similar issue with Jenkins running under Kubernetes with Azure-storage-backed PersistentVolumes.</p>

<p>Azure storage doesn't support symlinks by default.</p>

<p>As per: <a href=""https://docs.microsoft.com/en-us/azure/storage/files/storage-troubleshoot-linux-file-connection-problems#cannot-create-symbolic-links---ln-failed-to-create-symbolic-link-t-operation-not-supported"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/storage/files/storage-troubleshoot-linux-file-connection-problems#cannot-create-symbolic-links---ln-failed-to-create-symbolic-link-t-operation-not-supported</a></p>

<p>To resolve, I added the following to my PersistentVolume yaml:</p>

<pre><code>apiVersion: v1
kind: PersistentVolume
metadata:
  name: jenkins-pv
spec:
  storageClassName: azurefile
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  azureFile:
    secretName: azure-secret
    shareName: jenkins
  mountOptions:
    - dir_mode=0777
    - file_mode=0777
    - mfsymlinks
</code></pre>

<p>The <strong>mfsymlinks</strong> allows symlinks to be created on Azure storage.</p>
",15211,2019-05-30T16:56:22.040,['apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: jenkins-pv\nspec:\n  storageClassName: azurefile\n  capacity:\n    storage: 1Gi\n  accessModes:\n    - ReadWriteOnce\n  azureFile:\n    secretName: azure-secret\n    shareName: jenkins\n  mountOptions:\n    - dir_mode=0777\n    - file_mode=0777\n    - mfsymlinks\n']
877,8284,5552,CC BY-SA 4.0,2019-06-01T14:53:56.890,"<p>The problem was in this line:</p>

<pre><code>sudo docker network create --internal --subnet=192.168.2.0/24 netR
</code></pre>

<p>The <code>--internal</code> option makes the network unreachable from other Docker networks.</p>

<p>The solution was to remove this option.</p>
",11068,2019-06-01T14:53:56.890,['sudo docker network create --internal --subnet=192.168.2.0/24 netR\n']
878,8302,8294,CC BY-SA 4.0,2019-06-04T20:04:07.147,"<p>Setting </p>

<pre><code>export GOOGLE_APPLICATION_CREDENTIALS=${TF_CREDS}
</code></pre>

<p>solved the issue.</p>
",9556,2019-06-04T20:04:07.147,['export GOOGLE_APPLICATION_CREDENTIALS=${TF_CREDS}\n']
879,8308,8298,CC BY-SA 4.0,2019-06-06T00:57:07.153,"<p>TL;DR: <code>RUN</code> performs the step during the image build, <code>CMD</code> is the default command when you start a container. If you define <code>CMD</code> and then start your container with a different command (e.g. <code>docker run $my_image /bin/bash</code>), you'll never see it run since you replaced your <code>chmod</code> command with an empty <code>/bin/bash</code> command.</p>

<hr>

<p>The detailed explanation:</p>

<p>The <strong><code>RUN</code></strong> command creates a temporary container based off of the previous step of the build, executes your selected command, and when the command returns it captures the filesystem changes as a new layer of your image. Run is the equivalent of doing a <code>docker run</code> + <code>docker commit</code> to generate your image, but with a reproducible process.</p>

<p>The <strong><code>CMD</code></strong> command replaces the current value of the image metadata for the <code>command</code> value that you can see when you inspect the image. You can only have one value for <code>CMD</code> for your image. You can also easily override the value of the image command by passing any string after the image name, e.g. <code>docker run busybox echo hello</code> replaces the default <code>/bin/sh</code> command with an <code>echo hello</code> command for that specific container.</p>

<p>There's also <strong><code>ENTRYPOINT</code></strong> which defines the entrypoint for your image. When you define an entrypoint, any value for <code>CMD</code> gets passed as arguments to the entrypoint when starting your container (a container is only started with a single process as pid 1 and exits when that process exits).</p>

<hr>

<p><strong>Shell vs Exec syntax:</strong> Note that each of these accepts a command to run in two forms, the shell/string form, and the exec/json form. The shell form is anything that isn't a json list, and the result command is run as <code>/bin/sh -c ""$your_string_here""</code>. A shell is useful for IO redirection, chaining commands, and variable expansion. But a shell will also intercept signals which can cause issues when the container is stopped. The exec form runs your command directly in the OS without a shell, which is better for signals, but lacking all the other shell features. When you chain an entrypoint and cmd together, you almost always want the exec syntax since <code>/bin/sh -c</code> only accepts one argument. It's common to run a shell script but have the last command run be an <code>exec</code> which replaces the shell. E.g. a common entrypoint structure is:</p>

<p>Dockerfile:</p>

<pre><code>ENTRYPOINT [""/entrypoint.sh""]
CMD [""server"", ""arg1"", ""arg2""]
</code></pre>

<p>entrypoint.sh:</p>

<pre><code>#!/bin/sh
# ... steps to setup the host, make configs, fix permissions, copy files, etc ...
# ...
# now run the value of CMD, replacing this shell as pid 1:
exec ""$@""
</code></pre>
",7730,2019-06-06T01:02:11.893,"['ENTRYPOINT [""/entrypoint.sh""]\nCMD [""server"", ""arg1"", ""arg2""]\n', '#!/bin/sh\n# ... steps to setup the host, make configs, fix permissions, copy files, etc ...\n# ...\n# now run the value of CMD, replacing this shell as pid 1:\nexec ""$@""\n']"
880,8315,8314,CC BY-SA 4.0,2019-06-06T12:45:11.117,"<p>Since Ansible was installed via Homebrew on macOS, the workaround is to install Ansible using Pip.</p>

<pre><code>$ brew remove ansible
$ pip3 install ansible
$  pip3 list | grep -e ansible -e Jinja2
ansible      2.8.0  
Jinja2       2.8    
$  ansible-playbook check_jinja.yaml -v
TASK [jinja_version]
ok: [localhost] =&gt; {""changed"": false, ""msg"": ""2.8""}
</code></pre>
",3,2019-06-06T12:45:11.117,"['$ brew remove ansible\n$ pip3 install ansible\n$  pip3 list | grep -e ansible -e Jinja2\nansible      2.8.0  \nJinja2       2.8    \n$  ansible-playbook check_jinja.yaml -v\nTASK [jinja_version]\nok: [localhost] => {""changed"": false, ""msg"": ""2.8""}\n']"
881,8319,8311,CC BY-SA 4.0,2019-06-06T19:42:23.647,"<p><a href=""https://en.wikipedia.org/wiki/Single_responsibility_principle"" rel=""nofollow noreferrer"">Single responsibility principle (SRP)</a></p>

<blockquote>
  <p>Martin defines a responsibility as a reason to change, and concludes
  that a class or module should have one, and only one, reason to be
  changed (i.e. rewritten). As an example, consider a module that
  compiles and prints a report. Imagine such a module can be changed for
  two reasons. First, the content of the report could change. Second,
  the format of the report could change. These two things change for
  very different causes; one substantive, and one cosmetic. The single
  responsibility principle says that these two aspects of the problem
  are really two separate responsibilities, and should therefore be in
  separate classes or modules. It would be a bad design to couple two
  things that change for different reasons at different times.</p>
  
  <p>The reason it is important to keep a class focused on a single concern
  is that it makes the class more robust. Continuing with the foregoing
  example, if there is a change to the report compilation process, there
  is greater danger that the printing code will break if it is part of
  the same class.</p>
</blockquote>

<p><a href=""https://softwareengineering.stackexchange.com/a/133406/218283"">5-15 lines</a></p>

<blockquote>
  <p>Functions should normally be short, between 5-15 lines is my personal
  ""rule of thumb"" when coding in Java or C#. This is a good size for
  several reasons:</p>
  
  <ul>
  <li>It fits easily on your screen without scrolling</li>
  <li>It's about the conceptual size that you can hold in your head</li>
  <li>It's meaningful enough to require a function in its own right (as a standalone, meaningful chunk of logic)</li>
  <li>A function smaller than 5 lines is a hint that you are perhaps breaking the code up too much (which makes it harder to read /
  understand if you need to navigate between functions). Either that or
  your're forgetting your special cases / error handling!</li>
  </ul>
</blockquote>

<p><strong>Personal view</strong></p>

<p>I have the SRP in mind when creating Jenkins stages. This implies that I create a separate stage for checkout, build and publish for example. If a stage becomes too large, i.e. longer than 15 lines, then I create a script and run the script in this stage. One of the benefits is readability, possible to apply unit testing on the script and CI agnostic, i.e. migration to another CI would be possible as well.</p>

<p><a href=""https://jenkins.io/doc/book/pipeline/jenkinsfile/"" rel=""nofollow noreferrer"">Example</a></p>

<blockquote>
<pre><code>pipeline {
    agent any

    stages {
        stage('Build') {
            steps {
                echo 'Building..'
            }
        }
        stage('Test') {
            steps {
                echo 'Testing..'
            }
        }
        stage('Deploy') {
            steps {
                echo 'Deploying....'
            }
        }
    }
}
</code></pre>
</blockquote>
",210,2019-06-06T19:48:38.930,"[""pipeline {\n    agent any\n\n    stages {\n        stage('Build') {\n            steps {\n                echo 'Building..'\n            }\n        }\n        stage('Test') {\n            steps {\n                echo 'Testing..'\n            }\n        }\n        stage('Deploy') {\n            steps {\n                echo 'Deploying....'\n            }\n        }\n    }\n}\n""]"
882,8346,8344,CC BY-SA 4.0,2019-06-11T04:21:02.227,"<p>To replace all lines in the file <a href=""https://docs.ansible.com/ansible/latest/modules/replace_module.html#replace-replace-all-instances-of-a-particular-string-in-a-file-using-a-back-referenced-regular-expression"" rel=""nofollow noreferrer"">replace</a> module is needed. This is the equivalent (backup differs).</p>

<pre><code>  tasks:
    - lineinfile:
        path: myconffile
        backup: yes
        state: absent
        regexp: '\(ADDRESS = \(PROTOCOL = TCP\)\(HOST = 10.0.0.1\)\(PORT = 1501\)\)'
    - replace:
        path: myconffile
        backup: yes
        regexp: '\(ADDRESS = \(PROTOCOL = TCP\)\(HOST = 10.0.0.2\)\(PORT = 1501\)\)'
        replace: '(ADDRESS = (PROTOCOL = TCP)(HOST = my-site.com)(PORT = 1501))'
    - lineinfile:
        path: myconffile
        backup: yes
        state: absent
        regexp: '\(BALANCE = yes\)'
</code></pre>

<p>The simplified version is below.</p>

<pre><code>  tasks:
    - lineinfile:
        path: myconffile
        backup: yes
        state: absent
        regexp: ""{{ item }}""
      loop:
        - 'AAA'
        - 'DDD'
    - replace:
        path: myconffile
        backup: yes
        regexp: 'BBB'
        replace: 'CCC'
</code></pre>
",7715,2019-06-11T05:04:14.683,"[""  tasks:\n    - lineinfile:\n        path: myconffile\n        backup: yes\n        state: absent\n        regexp: '\\(ADDRESS = \\(PROTOCOL = TCP\\)\\(HOST = 10.0.0.1\\)\\(PORT = 1501\\)\\)'\n    - replace:\n        path: myconffile\n        backup: yes\n        regexp: '\\(ADDRESS = \\(PROTOCOL = TCP\\)\\(HOST = 10.0.0.2\\)\\(PORT = 1501\\)\\)'\n        replace: '(ADDRESS = (PROTOCOL = TCP)(HOST = my-site.com)(PORT = 1501))'\n    - lineinfile:\n        path: myconffile\n        backup: yes\n        state: absent\n        regexp: '\\(BALANCE = yes\\)'\n"", '  tasks:\n    - lineinfile:\n        path: myconffile\n        backup: yes\n        state: absent\n        regexp: ""{{ item }}""\n      loop:\n        - \'AAA\'\n        - \'DDD\'\n    - replace:\n        path: myconffile\n        backup: yes\n        regexp: \'BBB\'\n        replace: \'CCC\'\n']"
883,8347,5173,CC BY-SA 4.0,2019-06-11T08:37:21.213,"<p>There is a retry parameter in the <a href=""https://jenkins.io/doc/book/pipeline/syntax/#options"" rel=""nofollow noreferrer"">global options</a> when using declarative pipeline :</p>

<pre><code>pipeline {
    agent any
    options {
        retry(3)
    }
    stages {
        ...
    }
}
</code></pre>
",15385,2019-06-11T08:37:21.213,['pipeline {\n    agent any\n    options {\n        retry(3)\n    }\n    stages {\n        ...\n    }\n}\n']
884,8372,6698,CC BY-SA 4.0,2019-06-13T08:42:46.420,"<p>I think this is achieveable with <code>terraform</code>s <code>null_resource</code> (<a href=""https://www.terraform.io/docs/providers/null/resource.html"" rel=""nofollow noreferrer"">https://www.terraform.io/docs/providers/null/resource.html</a>) with <code>local-exec</code>.</p>

<p>Example (untested):</p>

<pre><code>resource ""null_resource"" ""helm_init_command"" {

  provisioner ""local-exec"" {
    command = ""helm --kubeconfig=&lt;...&gt; init""

}
</code></pre>
",6743,2019-06-13T10:36:33.307,"['resource ""null_resource"" ""helm_init_command"" {\n\n  provisioner ""local-exec"" {\n    command = ""helm --kubeconfig=<...> init""\n\n}\n']"
885,8379,8369,CC BY-SA 4.0,2019-06-13T17:05:21.053,"<p>The <code>resource ""azurerm_network_interface_backend_address_pool_association"" ""network_interface""</code> block doesn't have the <code>count</code> argument set, so <code>count.index</code> is not meaningful in that block.</p>

<p>Given the specific pair of resource types you're using here, I expect your intent was to create one association for each network interface, in which case you'd add the following <code>count</code> argument to the second block:</p>

<pre><code>  count = length(azurerm_network_interface.network_interface)
</code></pre>

<p>Although this didn't return an error on Terraform 0.11, it did not behave as I expect you intended: it would've created only one <code>azurerm_network_interface_backend_address_pool_association</code> for the <em>first</em> network interface, and left the others unassociated.</p>

<hr>

<p>If associating only the first one was your intent instead, then replace the <code>count.index</code> in the second block with <code>0</code> to be explicit that it's using only the first one:</p>

<pre><code>  network_interface_id    = azurerm_network_interface.network_interface[0]
</code></pre>
",2463,2019-06-13T17:05:21.053,"['  count = length(azurerm_network_interface.network_interface)\n', '  network_interface_id    = azurerm_network_interface.network_interface[0]\n']"
886,8380,8368,CC BY-SA 4.0,2019-06-13T17:49:59.410,"<p>Modelling these permutations as a single module with lots of parameters is possible as you've seen, but it's often not an ideal way to model things because this sort of careful rollout strategy tends to require control over individual steps, rather than rolling everything all at once.</p>

<p>The Terraform team recommends using <a href=""https://www.terraform.io/docs/modules/composition.html"" rel=""nofollow noreferrer"">module composition</a> instead. That means to split the problem into multiple smaller modules that the calling module can then combine to achieve the desired result.</p>

<p>In your specific case, it looks like there are three different building blocks: a load balancer, an optional Cloudfront distribution, and a DNS record. I'm going to show some examples of module composition using Terraform 0.12 features. If you're still using Terraform 0.11 then you can still follow a similar pattern, but Terraform 0.11's expression handling is more limited so the details would look different.</p>

<p>When breaking down this problem, my first step would be to identify what information needs to flow between these components. In this case:</p>

<ul>
<li>The load balancer has some arguments of its own, but it doesn't depend on the other components at all.</li>
<li>The optional Cloudfront distribution needs to know the hostname of the load balancer.</li>
<li>The Route53 record needs a record name and zone id to populate an <code>alias</code> block; they could be for either the load balancer or the Cloudfront distribution depending on which of the two architectures the calling module is following.</li>
</ul>

<p>In the full architecture where Cloudfront is used, these modules might be composed like this:</p>

<pre><code>module ""load_balancer"" {
  source = ""./modules/load-balancer""

  # ... load-balancer specific arguments
}

module ""cloudfront"" {
  source = ""./modules/cloudfront""

  target = module.load_balancer.dns_name
}

module ""dns"" {
  source = ""./modules/route53-record""

  alias = module.cloudfront.route53_alias
}
</code></pre>

<p>In the load-balancer-only architecture, we remove the <code>cloudfront</code> module and connect the DNS directly to the load balancer:</p>

<pre><code>module ""load_balancer"" {
  source = ""./modules/load-balancer""

  # ... load-balancer specific arguments
}

module ""dns"" {
  source = ""./modules/route53-record""

  alias = module.load_balancer.route53_alias
}
</code></pre>

<p>Terraform 0.12 allows us to define that <code>alias</code> variable on the <code>dns</code> module with a specific object type, to easily pass the alias settings between modules as a single object value:</p>

<pre><code># (in the route53-record module)
variable ""alias"" {
  type = object({
    name    = string
    zone_id = string
  })
}

resource ""aws_route53_record"" ""example"" {
  # (other arguments as in your example)

  alias {
    name                   = var.alias.name
    zone_id                = var.alias.zone_id
    evaluate_target_health = true
  }
}
</code></pre>

<p>The idea here is that both of the other modules follow this conventional structure so that the <code>route53-record</code> module can be compatible with either of them without caring which one is used. This would then correspond with outputs in each of the other modules following the same structure:</p>

<pre><code># in the load-balancer module
output ""route53_alias"" {
  value = {
    name    = aws_alb.example.dns_name
    zone_id = aws_alb.example.zone_id
  }
}
</code></pre>

<pre><code># in the cloudfront module
output ""route53_alias"" {
  value = {
    name    = aws_cloudfront_distribution.example.domain_name
    zone_id = aws_cloudfront_distribution.example.hosted_zone_id
  }
}
</code></pre>

<p>With this different design, we can address your original use-case by giving control to the author of the calling module to drive the switch between these two models. In order to avoid downtime when switching from Cloudfront back to the load balancer, we need to repoint the DNS first and then destroy the Cloudfront distribution only when it is no longer used. So we can do that in two steps, first by modifying the first example above to point the DNS record at the load balancer while retaining the Cloudfront distribution:</p>

<pre><code>module ""load_balancer"" {
  source = ""./modules/load-balancer""

  # ... load-balancer specific arguments
}

module ""cloudfront"" {
  source = ""./modules/cloudfront""

  target = module.load_balancer.dns_name
}

module ""dns"" {
  source = ""./modules/route53-record""

  alias = module.load_balanccer.route53_alias
}
</code></pre>

<p>Then, once the Cloudfront distribution has become idle, remove that module altogether at your leisure and apply again to clean it up.</p>

<p>Composition is the primary way we model relationships in Terraform, so it's most natural to use composition when working with modules too, rather than building big modules with lots of conditionals to handle every permutation. Composition allows flexibility in how to make changes to the infrastructure in future so that the maintainer of the top-level module can be the one to decide what tradeoffs to make, such as making smaller changes to avoid downtime.</p>

<hr>

<p>I used modules above because the original question was about modules, but I'd note also that after this decomposition we're left with one module per resource whose name is the resource type, which is one of the ""smell tests"" in <a href=""https://www.terraform.io/docs/modules/index.html#when-to-write-a-module"" rel=""nofollow noreferrer"">When to write a module?</a>.</p>

<p>If decomposing these into separate modules ends up just creating modules that are thin wrappers around single resource blocks then it's usually better to just eliminate the module altogether and just use the resource types directly.</p>

<p>However, if one or more of the modules still raises the level of abstraction (e.g. by providing hard-coded good values for most of the resource arguments and only exposing a small subset of them for customization) then that module in particular may still be warranted.</p>
",2463,2019-06-14T17:56:08.510,"['module ""load_balancer"" {\n  source = ""./modules/load-balancer""\n\n  # ... load-balancer specific arguments\n}\n\nmodule ""cloudfront"" {\n  source = ""./modules/cloudfront""\n\n  target = module.load_balancer.dns_name\n}\n\nmodule ""dns"" {\n  source = ""./modules/route53-record""\n\n  alias = module.cloudfront.route53_alias\n}\n', 'module ""load_balancer"" {\n  source = ""./modules/load-balancer""\n\n  # ... load-balancer specific arguments\n}\n\nmodule ""dns"" {\n  source = ""./modules/route53-record""\n\n  alias = module.load_balancer.route53_alias\n}\n', '# (in the route53-record module)\nvariable ""alias"" {\n  type = object({\n    name    = string\n    zone_id = string\n  })\n}\n\nresource ""aws_route53_record"" ""example"" {\n  # (other arguments as in your example)\n\n  alias {\n    name                   = var.alias.name\n    zone_id                = var.alias.zone_id\n    evaluate_target_health = true\n  }\n}\n', '# in the load-balancer module\noutput ""route53_alias"" {\n  value = {\n    name    = aws_alb.example.dns_name\n    zone_id = aws_alb.example.zone_id\n  }\n}\n', '# in the cloudfront module\noutput ""route53_alias"" {\n  value = {\n    name    = aws_cloudfront_distribution.example.domain_name\n    zone_id = aws_cloudfront_distribution.example.hosted_zone_id\n  }\n}\n', 'module ""load_balancer"" {\n  source = ""./modules/load-balancer""\n\n  # ... load-balancer specific arguments\n}\n\nmodule ""cloudfront"" {\n  source = ""./modules/cloudfront""\n\n  target = module.load_balancer.dns_name\n}\n\nmodule ""dns"" {\n  source = ""./modules/route53-record""\n\n  alias = module.load_balanccer.route53_alias\n}\n']"
887,8393,8363,CC BY-SA 4.0,2019-06-15T07:22:19.650,"<p>There is no equivalent for <code>before_script</code>. However you can define a function in your pipeline and call it in the begining of each stage. </p>

<pre><code>pipeline {
    agent any 
    stages {
        stage('Build') { 
            steps {
                cd
                // 
            }
        }
        stage('Test') { 
            steps {
                 cd
                // 
            }
        }
        stage('Deploy') { 
            steps {
                 cd
                // 
            }
        }
    }
}

def cd() {
   //your code
}
</code></pre>

<p>When you want to use your function in other pipelines as well you might want to look into <a href=""https://jenkins.io/doc/book/pipeline/shared-libraries/"" rel=""nofollow noreferrer"">shared libraries</a></p>
",4852,2019-06-20T07:00:11.967,"[""pipeline {\n    agent any \n    stages {\n        stage('Build') { \n            steps {\n                cd\n                // \n            }\n        }\n        stage('Test') { \n            steps {\n                 cd\n                // \n            }\n        }\n        stage('Deploy') { \n            steps {\n                 cd\n                // \n            }\n        }\n    }\n}\n\ndef cd() {\n   //your code\n}\n""]"
888,8396,8395,CC BY-SA 4.0,2019-06-15T18:48:46.317,"<p>I have been able to figure out how to get everything to work.</p>

<p>Let's start from the beginning:</p>

<p><strong>Changes to config file</strong></p>

<ol>
<li>Remove the selenium server settings (the docker container starts one on every run, and uses that automatically)</li>
<li>Add 'useAllAngular2AppRoots' otherwise the tests will all fail</li>
</ol>

<p>The resulting config file will be something like this (ignore the params section, that is just an object with additional parameters you can inject into your tests):</p>

<pre><code>// conf.js
var spec_files = ""tests/*.specs.js"";
exports.config = {
  framework: 'jasmine',
  specs: [spec_files],
  useAllAngular2AppRoots: true,
  multiCapabilities: [{
    browserName: 'chrome'
  }],
  restartBrowserBetweenTests: true,
  params: {
    sleepTime: 0
  }
}
</code></pre>

<p><strong>Setting up the build step in teamcity</strong></p>

<p>Usually when I want to run a build step I do it in a docker container, and execute command line steps inside that container.</p>

<p>To get this to run I could not do this, as we need to inject a few parameters at the end of the run command, so you need to create a docker command, looking like this:</p>

<p><a href=""https://i.stack.imgur.com/7tpa4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7tpa4.png"" alt=""enter image description here""></a></p>
",15475,2019-06-15T18:48:46.317,"['// conf.js\nvar spec_files = ""tests/*.specs.js"";\nexports.config = {\n  framework: \'jasmine\',\n  specs: [spec_files],\n  useAllAngular2AppRoots: true,\n  multiCapabilities: [{\n    browserName: \'chrome\'\n  }],\n  restartBrowserBetweenTests: true,\n  params: {\n    sleepTime: 0\n  }\n}\n']"
889,8405,4446,CC BY-SA 4.0,2019-06-17T12:54:17.883,"<p>Just in case anyone misses it, Rajesh commented above that <em>if using the .NET CLI Runner</em> you can simply add this to the <strong>Command line parameters</strong> option for the build step:</p>

<pre><code>/p:Version=%build.number%
</code></pre>

<p>..and it'll version all the binaries for you.  This worked for me and seems simpler than configuring the <code>File Content Replacer</code> as above.</p>

<p>I've added this as it seems to be a perfectly acceptable answer, and because Rajesh's comment didn't give full details (pointed me in the right direction though)</p>
",15496,2019-06-17T12:54:17.883,['/p:Version=%build.number%\n']
890,8418,8416,CC BY-SA 4.0,2019-06-18T14:20:01.370,"<p>You simply have an incorrect <a href=""https://learnxinyminutes.com/docs/yaml/"" rel=""nofollow noreferrer"">yaml syntax</a> in your <code>workflows</code> <code>jobs</code> list.</p>

<p>From what I could very quickly understand on <a href=""https://circleci.com/docs/2.0/configuration-reference/#jobs-1"" rel=""nofollow noreferrer"">circleCI's documentation</a>, jobs names are accepted as a shorthand if you don't define any parameters. If you have parameters, the list element is a hashmap with top element being the job name. In your specific case, this should give (note the column after the names of jobs with params):</p>

<pre><code>workflows:
  version: 2
  minimal:
    jobs:
      - build
      - tests:
          requires:
            - build
      - release:
          requires:
            - tests
          filters:
            tags:
              only: /^v.*$/
</code></pre>
",13111,2019-06-18T14:20:01.370,['workflows:\n  version: 2\n  minimal:\n    jobs:\n      - build\n      - tests:\n          requires:\n            - build\n      - release:\n          requires:\n            - tests\n          filters:\n            tags:\n              only: /^v.*$/\n']
891,8419,8353,CC BY-SA 4.0,2019-06-18T14:31:50.233,"<p>Yes, full cloning of LFS files can be restricted!  By default, GitLab will clone your repo into the CI/CD build directory.  To limit the clone from downloading the LFS files, tell it not to do it.  You do this by setting a variable in <code>.gitlab-ci.yml</code> like this.</p>

<pre><code># Other declarations etc above the specific job
jobname:
  variables:
    GIT_LFS_SKIP_SMUDGE: 1
# More job declarations, etc.
</code></pre>

<p>The ""smudge"" process replaces the link/pointers to the LFS files with the actual files.  By telling GitLab's CI job to skip the smudge, the LFS files aren't downloaded.</p>

<p>Placing <code>GIT_LFS_SKIP_SMUDGE: 1</code> in a variables section at the top may make it apply to all of the defined jobs.</p>
",15406,2019-06-18T14:31:50.233,"['# Other declarations etc above the specific job\njobname:\n  variables:\n    GIT_LFS_SKIP_SMUDGE: 1\n# More job declarations, etc.\n']"
892,8426,8409,CC BY-SA 4.0,2019-06-19T16:41:19.100,"<p>The workaround is to pull the current state file, edit it and use it as a base line. For example:</p>

<pre><code>$ terraform state pull &gt; terraform.tfstate
$ vim terraform.tfstate # Carefully remove invalid entries.
$ python -mjson.tool terraform.tfstate # Validate JSON.
</code></pre>

<p><sup>Note: In Vim, placing cursor on the opening bracket, hitting <kbd>d%</kbd> will remove the whole group.</sup></p>

<p>Then plan and apply:</p>

<pre><code>$ terraform plan -state=terraform.tfstate -refresh=false
$ terraform apply -state=terraform.tfstate -refresh=false
</code></pre>

<hr>

<p>Alternatively, pull, edit and push your local state file into remote state:</p>

<pre><code>$ terraform state pull &gt; terraform.tfstate
$ vim terraform.tfstate # Remove invalid entries and increase the serial value.
$ terraform state push terraform.tfstate
</code></pre>

<hr>

<p>For Azure, it's better to use <a href=""https://github.com/terraform-providers/terraform-provider-azurerm"" rel=""nofollow noreferrer""><code>terraform-provider-azurerm</code></a> instead of general DNS provider (<a href=""https://github.com/terraform-providers/terraform-provider-dns"" rel=""nofollow noreferrer""><code>terraform-provider-dns</code></a>).</p>
",3,2019-06-19T17:03:11.150,"['$ terraform state pull > terraform.tfstate\n$ vim terraform.tfstate # Carefully remove invalid entries.\n$ python -mjson.tool terraform.tfstate # Validate JSON.\n', '$ terraform plan -state=terraform.tfstate -refresh=false\n$ terraform apply -state=terraform.tfstate -refresh=false\n', '$ terraform state pull > terraform.tfstate\n$ vim terraform.tfstate # Remove invalid entries and increase the serial value.\n$ terraform state push terraform.tfstate\n']"
893,8431,8416,CC BY-SA 4.0,2019-06-20T03:06:37.570,"<p>Running your <code>config.yml</code> through <a href=""https://github.com/adrienverge/yamllint"" rel=""nofollow noreferrer"">yamllint</a>, produced the following:</p>

<pre><code>  1:1       warning  missing document start ""---""  (document-start)
  13:3      error    duplication of key ""build"" in mapping  (key-duplicates)
  25:19     error    syntax error: mapping values are not allowed here
</code></pre>

<p>When I add colons to the entry on lines 25 and 28: </p>

<pre><code>workflows:
  version: 2
  minimal:
    jobs:
      - build
      - tests:
          requires:
            - build
      - release:
          requires:
            - tests
          filters:
            tags:
              only: /^v.*$/
</code></pre>

<p>...the syntax error is no longer reported:</p>

<pre><code>1:1       warning  missing document start ""---""  (document-start)  
13:3      error    duplication of key ""build"" in mapping (key-duplicates)
</code></pre>
",9148,2019-06-20T03:06:37.570,"['  1:1       warning  missing document start ""---""  (document-start)\n  13:3      error    duplication of key ""build"" in mapping  (key-duplicates)\n  25:19     error    syntax error: mapping values are not allowed here\n', 'workflows:\n  version: 2\n  minimal:\n    jobs:\n      - build\n      - tests:\n          requires:\n            - build\n      - release:\n          requires:\n            - tests\n          filters:\n            tags:\n              only: /^v.*$/\n', '1:1       warning  missing document start ""---""  (document-start)  \n13:3      error    duplication of key ""build"" in mapping (key-duplicates)\n']"
894,8433,8402,CC BY-SA 4.0,2019-06-20T03:43:37.010,"<p>According to the <a href=""https://nginx.org/en/docs/ngx_core_module.html#user"" rel=""nofollow noreferrer"">Nginx docs</a> you can configure the user which runs Nginx. By default the user is <code>nobody</code>.</p>

<p>You can read <a href=""https://askubuntu.com/questions/97810/how-to-make-apache-run-as-current-user"">this</a> Ask Ubuntu question that explains how to configure Apache2 to run as a different user. The default user running Apache2 is <code>www-data</code>.</p>

<p>A common strategy, and one I think may work for your goal, is to assign the users that need to deploy the application to a common group. For instance, if you added them to the <code>www-data</code> group:</p>

<pre><code>sudo adduser &lt;user&gt; www-data
</code></pre>

<p>You can see which groups is a member of with:</p>

<pre><code>groups &lt;user&gt;
</code></pre>

<p>Then change the group of the directory where users will run <code>migrate.php</code>:</p>

<pre><code>sudo chgrp -R www-data /var/www/demoapp
</code></pre>

<p>Then assign the group read/write/execute permissions to the directory:</p>

<pre><code>sudo chmod -R g+rwx /var/www/demoapp/
</code></pre>

<p>The users in this group should now be able to write and run scripts within the <code>demoapp/</code> directory.</p>
",9148,2019-06-20T03:43:37.010,"['sudo adduser <user> www-data\n', 'groups <user>\n', 'sudo chgrp -R www-data /var/www/demoapp\n', 'sudo chmod -R g+rwx /var/www/demoapp/\n']"
895,8434,8363,CC BY-SA 4.0,2019-06-20T04:00:31.173,"<p>You can use the Jenkins provided step <a href=""https://jenkins.io/doc/pipeline/steps/workflow-basic-steps/#dir-change-current-directory"" rel=""nofollow noreferrer"">dir()</a> which changes the directory to one relative to the Jenkins <code>env.WORKSPACE</code> (<code>/var/lib/jenkins/workspace/JOB_NAME</code> by default).</p>

<pre><code>stage('Build') { 
    steps {
        dir('path/to/dir') {
            // do stuff
        }

        dir('path/to/other/dir') {
            // do other stuff
        }
    }
}
</code></pre>
",9148,2019-06-20T04:00:31.173,"[""stage('Build') { \n    steps {\n        dir('path/to/dir') {\n            // do stuff\n        }\n\n        dir('path/to/other/dir') {\n            // do other stuff\n        }\n    }\n}\n""]"
896,8443,8402,CC BY-SA 4.0,2019-06-21T05:36:04.230,"<p>I usually stick to a <code>755</code> (or <code>rwxr-xr-x</code>) on my web root, but I do not think this is the issue you're running into since your directory is already set to that.  <code>nginx</code> should have access to your directory.  The question then becomes the permissions (or existence of) the file you're trying to access.  The files within your directory will need to be readable by the user <code>nginx</code> is running as.  I usually leave these files set to a <code>755</code> (the same as the directory).  You can change the entire directory by doing</p>

<pre><code>sudo chmod -R 755 /var/www/demoapp/
sudo chgrp -R www-data /var/www/demoapp
</code></pre>

<p>If there is not an index file in the directory, however, you will still get the same error.  The index file is used when you request a directory that doesn't have directory listings enabled.  The most common index file is <code>index.html</code>.  This default can be edited in your config, however, using something like:</p>

<pre><code>location / {
    index index.php;
}
</code></pre>

<p>If you want <code>nginx</code> to generate a list of files in that directory for you, simply turn on <a href=""http://wiki.nginx.org/NginxHttpAutoindexModule"" rel=""nofollow noreferrer"">directory indexing</a>, like so:</p>

<pre><code>location  /  {
  autoindex  on;
}
</code></pre>
",11598,2019-06-21T05:36:04.230,"['sudo chmod -R 755 /var/www/demoapp/\nsudo chgrp -R www-data /var/www/demoapp\n', 'location / {\n    index index.php;\n}\n', 'location  /  {\n  autoindex  on;\n}\n']"
897,8445,8240,CC BY-SA 4.0,2019-06-21T19:09:25.813,"<p>I learned that it's not required to set the ingress class to nginx as I did in <code>kubernetes.io/ingress.class: nginx</code>. All annotations prefixed with <code>nginx.ingress.kubernetes.io</code> apply to the default Kubernetes ingress. Setting the timeouts is also not required. The only important annotation is</p>

<pre><code>nginx.ingress.kubernetes.io/proxy-body-size: ""0""
</code></pre>

<p>because the default value is way too small for Docker image layers. Without this annotation, we get <code>413 Request Entity Too Large</code> errors.</p>

<p>The main problem in my case was somewhere else: We had a HAProxy loadbalancer in front of our Kubernetes workers. Being new in those HA technology, it's configuration was pretty default. It contains the following directives:</p>

<pre><code>defaults
    # ...
    retries 3
    timeout connect     1000
    timeout client      1000
    timeout server      1000
</code></pre>

<p>According to <a href=""https://cbonte.github.io/haproxy-dconv/1.8/configuration.html#2.49"" rel=""nofollow noreferrer"">HAProxys time formats</a>, this got interpreted as ms. In our testing environment, I increased both client/server timeouts to 600s. This fixed all our pushing problems. </p>
",6643,2019-06-21T19:09:25.813,"['nginx.ingress.kubernetes.io/proxy-body-size: ""0""\n', 'defaults\n    # ...\n    retries 3\n    timeout connect     1000\n    timeout client      1000\n    timeout server      1000\n']"
898,8466,8430,CC BY-SA 4.0,2019-06-25T18:07:59.880,"<p>In case anyone else is running into this issue and can't figure it out, I fixed it by running this command:</p>

<pre><code>gcloud auth activate-service-account --key-file key-file.json
</code></pre>

<p>And then ran my docker push command and it pushed through.</p>
",15548,2019-06-25T18:07:59.880,['gcloud auth activate-service-account --key-file key-file.json\n']
899,8469,5890,CC BY-SA 4.0,2019-06-25T18:49:50.783,"<p>""I have two Filebeat pipes inputting into Logstash.""
---I assume this means that you have conditional logic and/or prospectors in your filebeat config to ship to the multiple logstash (5044 and 5043)ports?  I'd be interested to see that config.</p>

<p>Here's another approach that might acheive your goal:  Use the source value in a conditional output. An example of logstash conditional outputs can be found here: <a href=""https://discuss.elastic.co/t/conditional-statement-in-output/74672"" rel=""nofollow noreferrer"">https://discuss.elastic.co/t/conditional-statement-in-output/74672</a></p>

<p>If, for some reason filebeat's 'source' field will not suffice: you might inject your own fields, per prospector, as described by andrewkroh midway through the thread here: <a href=""https://discuss.elastic.co/t/how-to-tag-log-files-in-filebeat-for-logstash-ingestion/44713/6"" rel=""nofollow noreferrer"">https://discuss.elastic.co/t/how-to-tag-log-files-in-filebeat-for-logstash-ingestion/44713/6</a>.  Then you could do conditional output on your custom fields.  The example Andrew provided for adding custom fields by prospector is as follows:</p>

<pre><code>```filebeat:
```  prospectors:
```    - paths:
```        - /path/to/logs/access.log
```      fields:  {log_type: access}
```    - paths:
```        - /path/to/other/logs/errors.log
```      fields: {log_type: errors}
</code></pre>
",15648,2019-06-25T18:55:17.987,['```filebeat:\n```  prospectors:\n```    - paths:\n```        - /path/to/logs/access.log\n```      fields:  {log_type: access}\n```    - paths:\n```        - /path/to/other/logs/errors.log\n```      fields: {log_type: errors}\n']
900,8486,5898,CC BY-SA 4.0,2019-06-27T11:55:30.280,"<p>This will show pod network CIDR which used by <code>kube-proxy</code></p>

<pre><code>kubectl cluster-info dump | grep -m 1 cluster-cidr
</code></pre>
",15689,2019-06-27T11:55:30.280,['kubectl cluster-info dump | grep -m 1 cluster-cidr\n']
901,8494,8484,CC BY-SA 4.0,2019-06-28T00:23:38.533,"<p>Yes you can by doing a DNS SRV lookup. Here's an example:</p>

<pre><code>$ kubectl run -it srvlookup --image=tutum/dnsutils --rm --restart=Never -- dig SRV jira-headless.default.svc.cluster.local

; &lt;&lt;&gt;&gt; DiG 9.9.5-3ubuntu0.2-Ubuntu &lt;&lt;&gt;&gt; SRV jira-headless.default.svc.cluster.local
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 56846
;; flags: qr aa rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 2

;; QUESTION SECTION:
;jira-headless.default.svc.cluster.local. IN SRV

;; ANSWER SECTION:
jira-headless.default.svc.cluster.local. 30 IN SRV 10 50 0 jira-0.jira-headless.default.svc.cluster.local.
jira-headless.default.svc.cluster.local. 30 IN SRV 10 50 0 jira-1.jira-headless.default.svc.cluster.local.

;; ADDITIONAL SECTION:
jira-0.jira-headless.default.svc.cluster.local. 30 IN A 10.244.11.152
jira-1.jira-headless.default.svc.cluster.local. 30 IN A 10.244.0.188

;; Query time: 6 msec
;; SERVER: 10.233.0.3#53(10.233.0.3)
;; WHEN: Fri Jun 28 00:18:14 UTC 2019
;; MSG SIZE  rcvd: 143
</code></pre>

<p>In the example above I have a headless Service called <code>jira-headless.</code> If you pay attention to <code>ADDITIONAL SECTION:</code> you'll notice it provides the SRV record in the following format:</p>

<p><code>_service._proto.name. TTL class SRV priority weight port target.</code></p>

<p>Which maps to the Pods (along with their IPs) backing the Service:</p>

<pre><code>jira-0.jira-headless.default.svc.cluster.local. 30 IN A 10.244.11.152
jira-1.jira-headless.default.svc.cluster.local. 30 IN A 10.244.0.188
</code></pre>
",4907,2019-06-28T00:23:38.533,"['$ kubectl run -it srvlookup --image=tutum/dnsutils --rm --restart=Never -- dig SRV jira-headless.default.svc.cluster.local\n\n; <<>> DiG 9.9.5-3ubuntu0.2-Ubuntu <<>> SRV jira-headless.default.svc.cluster.local\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 56846\n;; flags: qr aa rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 2\n\n;; QUESTION SECTION:\n;jira-headless.default.svc.cluster.local. IN SRV\n\n;; ANSWER SECTION:\njira-headless.default.svc.cluster.local. 30 IN SRV 10 50 0 jira-0.jira-headless.default.svc.cluster.local.\njira-headless.default.svc.cluster.local. 30 IN SRV 10 50 0 jira-1.jira-headless.default.svc.cluster.local.\n\n;; ADDITIONAL SECTION:\njira-0.jira-headless.default.svc.cluster.local. 30 IN A 10.244.11.152\njira-1.jira-headless.default.svc.cluster.local. 30 IN A 10.244.0.188\n\n;; Query time: 6 msec\n;; SERVER: 10.233.0.3#53(10.233.0.3)\n;; WHEN: Fri Jun 28 00:18:14 UTC 2019\n;; MSG SIZE  rcvd: 143\n', 'jira-0.jira-headless.default.svc.cluster.local. 30 IN A 10.244.11.152\njira-1.jira-headless.default.svc.cluster.local. 30 IN A 10.244.0.188\n']"
902,8498,8497,CC BY-SA 4.0,2019-06-28T18:38:02.837,"<p>Q: <strong>&quot;<em>In the event that variable item.ppsize is not set I want to exclude that entire parameter from being included.</em>&quot;</strong></p>
<p>A: Use the <em>default</em> filter to omit module parameters using the special <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#omitting-parameters"" rel=""nofollow noreferrer""><em>omit</em></a> variable</p>
<pre class=""lang-yaml prettyprint-override""><code>    pp_size: &quot;{{ item.ppsize|default(omit) }}&quot;
</code></pre>
",7715,2021-01-18T20:39:51.633,"['    pp_size: ""{{ item.ppsize|default(omit) }}""\n']"
903,8499,8495,CC BY-SA 4.0,2019-06-29T07:57:18.537,"<p>the best way I think is to create a var  yml file and include it in your ansible-books:</p>

<pre><code>    - name: Include vars of stuff.yaml into the 'stuff' variable (2.2).
      include_vars:
        file: stuff.yaml
        name: stuff
</code></pre>

<p>see <a href=""https://docs.ansible.com/ansible/latest/modules/include_vars_module.html"" rel=""nofollow noreferrer"">include_vars_module</a></p>
",15739,2019-06-29T07:57:18.537,"[""    - name: Include vars of stuff.yaml into the 'stuff' variable (2.2).\n      include_vars:\n        file: stuff.yaml\n        name: stuff\n""]"
904,8501,8495,CC BY-SA 4.0,2019-06-30T10:18:35.037,"<p>This looks like you are trying to solve a problem (how express a desired state using appropriate OS-specific strategies), but selecting the ""wrong"" approach.</p>

<p>I would suggest that instead of maintaining separate playbooks (one for Windows, one for Debian, <em>etc</em>), you should write an OS-independent <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse_roles.html"" rel=""nofollow noreferrer"">role</a>. The role will use facts from the target machines to apply the relevant configuration. This can be done in a few ways :</p>

<ol>
<li>Set OS-specific variables and include them in the tasks using a <code>include_vars: ""{{ ansible_os_family }}.yml""</code> which will pick up a <code>Debian.yml</code> set of vars <em>e.g.</em>. You could then write <code>when</code> conditions on tasks to execute OS-specific tasks</li>
<li>Write OS-specific tasks to be included in the <code>tasks/main.yml</code> <em>e.g.</em> </li>
</ol>

<pre><code># tasks/main.yml
- import_tasks: ""{{ ansible_os_family }}.yml""

</code></pre>

<p>This will afford you some benefits:</p>

<ol>
<li>You will be able to test the role independently for different scenarios (using <a href=""https://molecule.readthedocs.org"" rel=""nofollow noreferrer"">molecule</a> <em>e.g.</em></li>
<li>You will be able to maintain the configuration (vars, tasks, etc) independently in separate files for respective OS's.</li>
<li>You won't have to maintain two separate playbooks</li>
<li>Your role will be easier to re-use</li>
</ol>

<p>See <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_reuse.html"" rel=""nofollow noreferrer"">writing re-usable playbooks</a> on the Ansible documentation.</p>
",354,2019-06-30T10:18:35.037,"['# tasks/main.yml\n- import_tasks: ""{{ ansible_os_family }}.yml""\n\n']"
905,8505,8467,CC BY-SA 4.0,2019-06-30T22:03:16.030,"<p>Your string isn't being interpolated at the correct time because it's in single quotes.  Instead it's being passed to the checkout method as an un-interpolated string.  By the time the checkout method interpolates the string, the <code>perf</code> variable is out of scope and so interpretation of this variable falls back to a blank string.  Something like this is what you (probably) want instead:</p>

<pre><code>view: ""\""//depot/Software/${perf[i].ID}/...\"""" + '//jenkins-${NODE_NAME}-${JOB_NAME}-${EXECUTOR_NUMBER}/...'
</code></pre>

<p>Note how this concatenates two strings, a double-quoted string and a single-quoted string.  This ensures that each string gets interpolated at different times.</p>
",4115,2019-06-30T22:03:16.030,"['view: ""\\""//depot/Software/${perf[i].ID}/...\\"""" + \'//jenkins-${NODE_NAME}-${JOB_NAME}-${EXECUTOR_NUMBER}/...\'\n']"
906,8524,8197,CC BY-SA 4.0,2019-07-02T19:05:09.823,"<p>In your <code>terraform {...}</code> section you need a backend directive to store your state somewhere: <a href=""https://www.terraform.io/docs/state/remote.html"" rel=""nofollow noreferrer"">https://www.terraform.io/docs/state/remote.html</a> (OP later explain that the code above is just a module imported from a main file).</p>

<p><a href=""https://www.terraform.io/docs/backends/types/s3.html"" rel=""nofollow noreferrer"">S3 backends</a> might be the easiest to use and probably to most commonly used backends to store remote state across different executions of Terraform:</p>

<pre><code>terraform {
  backend ""s3"" {
    bucket = ""mybucket""
    key    = ""path/to/my/key""
    region = ""us-east-1""
  }
}
</code></pre>

<p>Please note that Terraform <a href=""https://www.terraform.io/docs/commands/init.html"" rel=""nofollow noreferrer"">init</a> will not import existing resources into a state (there's Terraform <a href=""https://www.terraform.io/docs/import/"" rel=""nofollow noreferrer"">import</a> for that). It will therefore try to create new ones and you will get a conflict on the name. The Terraform documentation gives some pointers on <a href=""https://learn.hashicorp.com/terraform/development/running-terraform-in-automation"" rel=""nofollow noreferrer"">how to use Terraform in automation</a> and that includes using remote state.</p>

<p>It is possible to prevent the creation of the ECR through a data block as you hinted (with <code>count = ...</code>), but doing so would feel like a hack to me.</p>

<p>Once you have your remote backend configured, you can double check that everything works as expected by using the <code>terraform state</code> command in your pipeline. I would suggest using the show subcommand on a resource you expect to be there in order to validate that the state indeed contains the resource:</p>

<pre><code>terraform init -input=false
terraform state show module.name-of-your-module.aws_ecr_repository.frontend_ecr_repo_creation
</code></pre>
",246,2019-07-03T14:16:16.463,"['terraform {\n  backend ""s3"" {\n    bucket = ""mybucket""\n    key    = ""path/to/my/key""\n    region = ""us-east-1""\n  }\n}\n', 'terraform init -input=false\nterraform state show module.name-of-your-module.aws_ecr_repository.frontend_ecr_repo_creation\n']"
907,8527,8514,CC BY-SA 4.0,2019-07-03T05:30:04.103,"<p><strong>Attach a policy to the source bucket</strong></p>

<ol>
<li><p>Get the AWS account ID number of the destination account.</p></li>
<li><p>From the source account, attach a policy to the source bucket that allows the destination account to get objects, similar to the following:</p></li>
</ol>

<p><strong>Important:</strong> For the value of <strong>Principal</strong>, be sure to enter the AWS account ID number of the destination account.</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
            ""Sid"": ""DelegateS3Access"",
            ""Effect"": ""Allow"",
            ""Principal"": {""AWS"": ""222222222222""},
            ""Action"": [""s3:ListBucket"",""s3:GetObject""],
            ""Resource"": [
                ""arn:aws:s3:::sourcebucket/*"",
                ""arn:aws:s3:::sourcebucket""
            ]
        }
    ]
}
</code></pre>

<p><strong>Attach a policy to a user or group in the destination account</strong></p>

<p>Attach a policy to the destination account's IAM user or group that allows the user to copy objects from the source bucket to the destination bucket. The policy can be similar to the following example:</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""s3:ListBucket"",
                ""s3:GetObject""
            ],
            ""Resource"": [
                ""arn:aws:s3:::sourcebucket"",
                ""arn:aws:s3:::sourcebucket/*""
            ]
        },
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""s3:ListBucket"",
                ""s3:PutObject"",
                ""s3:PutObjectAcl""
            ],
            ""Resource"": [
                ""arn:aws:s3:::destinationbucket"",
                ""arn:aws:s3:::destinationbucket/*""
            ]
        }
    ]
}
</code></pre>

<p><strong>Copy objects from the source bucket to the destination bucket</strong></p>

<p>After you set up the policies on the source bucket and the destination account, the destination account can copy objects from the source bucket to the destination bucket. Then, the destination account owns the objects copied into the destination bucket.</p>

<p>To synchronize all content from the source bucket to the destination bucket, you can run this command:</p>

<pre><code>aws s3 sync s3://sourcebucket s3://destinationbucket
</code></pre>

<p>for more details check <a href=""https://medium.com/tensult/copy-s3-bucket-objects-across-aws-accounts-e46c15c4b9e1"" rel=""nofollow noreferrer"">this link</a> OR <a href=""https://aws.amazon.com/premiumsupport/knowledge-center/copy-s3-objects-account/"" rel=""nofollow noreferrer"">this link</a></p>
",11598,2019-07-03T05:30:04.103,"['{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Sid"": ""DelegateS3Access"",\n            ""Effect"": ""Allow"",\n            ""Principal"": {""AWS"": ""222222222222""},\n            ""Action"": [""s3:ListBucket"",""s3:GetObject""],\n            ""Resource"": [\n                ""arn:aws:s3:::sourcebucket/*"",\n                ""arn:aws:s3:::sourcebucket""\n            ]\n        }\n    ]\n}\n', '{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""s3:ListBucket"",\n                ""s3:GetObject""\n            ],\n            ""Resource"": [\n                ""arn:aws:s3:::sourcebucket"",\n                ""arn:aws:s3:::sourcebucket/*""\n            ]\n        },\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""s3:ListBucket"",\n                ""s3:PutObject"",\n                ""s3:PutObjectAcl""\n            ],\n            ""Resource"": [\n                ""arn:aws:s3:::destinationbucket"",\n                ""arn:aws:s3:::destinationbucket/*""\n            ]\n        }\n    ]\n}\n', 'aws s3 sync s3://sourcebucket s3://destinationbucket\n']"
908,8531,8064,CC BY-SA 4.0,2019-07-03T14:40:16.263,"<p>The problem is with the image
<code>microsoft-dsvm:linux-data-science-vm-ubuntu:linuxdsvmubuntu:18.12.01</code> (""Linux
Data Science VM"" (on the Azure portal). This is an old image with <code>R 3.4</code>
instead of the release version of <code>3.5</code>.</p>

<p>I succeeded with the following virtual machine (Ubuntu Server 19.04.19, size D64 v3):</p>

<pre><code>az vm create \
       --resource-group &lt;resource group&gt; \
       --name &lt;name&gt; \
       --image Canonical:UbuntuServer:19.04:19.04.201906280 \
       --size Standard_D64_v3 \
       --admin-username &lt;azure user&gt; \
       --generate-ssh-keys
</code></pre>

<p>and installed <code>R</code>, <code>Rstan</code>, and an SSL library for <code>curl</code> and <code>devtools</code> with:</p>

<pre><code>sudo apt update
sudo apt -y install r-base
sudo apt -y install r-cran-rstan

# Add LibSSL for installing curl and devtools, see:
# https://stackoverflow.com/questions/44228055/r-rstudio-install-devtools-fails
sudo apt-get install libcurl4-openssl-dev libssl-dev
</code></pre>

<p>and the machine can use multiple cores:</p>

<pre><code>Welcome to PosteriorBootstrap, a parallel approach for adaptive non-parametric learning
[1] ""Speedup performance""
[1] ""n_bootstrap = 100""
[1] ""num_cores = 1""
[1] ""Finished sampling""
[1] ""num_cores = 2""
[1] ""Finished sampling""
...
[1] ""num_cores = 64""
[1] ""Finished sampling""
</code></pre>

<p>I also checked the duration and the speedup is as I expected.</p>
",14747,2019-07-03T14:40:16.263,"['az vm create \\\n       --resource-group <resource group> \\\n       --name <name> \\\n       --image Canonical:UbuntuServer:19.04:19.04.201906280 \\\n       --size Standard_D64_v3 \\\n       --admin-username <azure user> \\\n       --generate-ssh-keys\n', 'sudo apt update\nsudo apt -y install r-base\nsudo apt -y install r-cran-rstan\n\n# Add LibSSL for installing curl and devtools, see:\n# https://stackoverflow.com/questions/44228055/r-rstudio-install-devtools-fails\nsudo apt-get install libcurl4-openssl-dev libssl-dev\n', 'Welcome to PosteriorBootstrap, a parallel approach for adaptive non-parametric learning\n[1] ""Speedup performance""\n[1] ""n_bootstrap = 100""\n[1] ""num_cores = 1""\n[1] ""Finished sampling""\n[1] ""num_cores = 2""\n[1] ""Finished sampling""\n...\n[1] ""num_cores = 64""\n[1] ""Finished sampling""\n']"
909,8542,4415,CC BY-SA 4.0,2019-07-05T22:52:50.250,"<p><code>Alternatively, is there another way I could allow an IAM user to launch an instance in line with a template, while preventing them from making changes (such as choosing a super-expensive instance type)?</code></p>

<p>I've encountered this problem last year and have circulated up to our AWS account's architect, who contacted their IAM division. </p>

<p>AWS's response is that this is <strong>intended behavior</strong>. Reason given was that <strong>""An instance-type spec on a launch template is not a resource, or conditional that can be used to granted/deny permissions to""</strong>. Notice that inside the IAM policy, specifying a launch template is a condition to action ""RunInstance"", and the resource of said policy is an ec2 instance. </p>

<p>According to AWS IAM team, in order for you to restrict instance-type (a condition on the resource, ""instance""), you must specify the restriction as part of the condition clause to be applied to the instance, like the following:</p>

<pre><code>{
  ""Effect"": ""Allow"",
  ""Action"": ""ec2:RunInstances"",
  ""Resource"": ""*"",
  ""Condition"": {
    ""ArnLike"": {
      ""ec2:LaunchTemplate"": ""arn:aws:ec2:ap-southeast-2:xxxxxxx:launch-template/lt-xxxxxxx""
    },
    ""Bool"": {
      ""ec2:IsLaunchTemplateResource"": ""true""
    },
    ""StringNotLikeIfExists"": {
      ""ec2:InstanceType"": [
        ""c5.*xlarge"",
        ""p3.*xlarge""
      ]
    }
  }
}
</code></pre>

<p>Obviously, it is near impossible to list all of the expensive instances we don't want our users to use, and kinda defeats the purpose of using a launch template.  But in a messed-up way, in the IAM world AWS created, this actually makes sense. </p>

<p>Consider the docs here: <a href=""https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ExamplePolicies_EC2.html#iam-example-runinstances-launch-templates"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ExamplePolicies_EC2.html#iam-example-runinstances-launch-templates</a></p>

<p>Note the language: <code>The policy uses the ec2:IsLaunchTemplateResource condition key to prevent users from overriding any of the launch template *resources* in the RunInstances request.</code>  So that clause only applies to resources (like NICs, IPs, etc), but not instance-type, which is not considered as a resource. </p>

<p>I asked that they revise their docs to explain this, and of course, nothing's changed. </p>
",15852,2019-07-05T22:52:50.250,"['{\n  ""Effect"": ""Allow"",\n  ""Action"": ""ec2:RunInstances"",\n  ""Resource"": ""*"",\n  ""Condition"": {\n    ""ArnLike"": {\n      ""ec2:LaunchTemplate"": ""arn:aws:ec2:ap-southeast-2:xxxxxxx:launch-template/lt-xxxxxxx""\n    },\n    ""Bool"": {\n      ""ec2:IsLaunchTemplateResource"": ""true""\n    },\n    ""StringNotLikeIfExists"": {\n      ""ec2:InstanceType"": [\n        ""c5.*xlarge"",\n        ""p3.*xlarge""\n      ]\n    }\n  }\n}\n']"
910,8550,8547,CC BY-SA 4.0,2019-07-07T10:00:18.290,"<p>Problem solved, I think: the agent comes with its own <code>libcurl.so.3</code> in <code>/opt/oms/lib</code>, it doesn't use the system one at all. Once I replaced that, it seems to be succeeding. Previously:</p>

<pre><code>$ cd /opt/microsoft/omsconfig/Scripts
$ ./PerformRequiredConfigurationChecks.py
instance of OMI_Error
{
    OwningEntity=OMI:CIMOM
    MessageID=OMI:MI_Result:1
    Message=cURL failed to perform on this base url: uks-agentservice-prod-1.azure-automation.net with this error message: Stream error in the HTTP/2 framing layer. Make sure cURL and SSL libraries are up to date.
    MessageArguments={}
    PerceivedSeverity=7
    ProbableCause=0
    ProbableCauseDescription=Unknown
    CIMStatusCode=1
    OMI_Code=1
    OMI_Category=0
    OMI_Type=MI
    OMI_ErrorMessage=A general error occurred, not covered by a more specific error code.
}
</code></pre>

<p>But now:</p>

<pre><code>$ ./PerformRequiredConfigurationChecks.py
instance of PerformRequiredConfigurationChecks
{
    ReturnValue=0
}
</code></pre>
",786,2019-07-07T10:05:23.810,"['$ cd /opt/microsoft/omsconfig/Scripts\n$ ./PerformRequiredConfigurationChecks.py\ninstance of OMI_Error\n{\n    OwningEntity=OMI:CIMOM\n    MessageID=OMI:MI_Result:1\n    Message=cURL failed to perform on this base url: uks-agentservice-prod-1.azure-automation.net with this error message: Stream error in the HTTP/2 framing layer. Make sure cURL and SSL libraries are up to date.\n    MessageArguments={}\n    PerceivedSeverity=7\n    ProbableCause=0\n    ProbableCauseDescription=Unknown\n    CIMStatusCode=1\n    OMI_Code=1\n    OMI_Category=0\n    OMI_Type=MI\n    OMI_ErrorMessage=A general error occurred, not covered by a more specific error code.\n}\n', '$ ./PerformRequiredConfigurationChecks.py\ninstance of PerformRequiredConfigurationChecks\n{\n    ReturnValue=0\n}\n']"
911,8552,8551,CC BY-SA 4.0,2019-07-07T13:07:06.107,"<p>Try to remove the easyrsa relation with kubernetes-master in juju.</p>

<pre><code>juju remove-relation easyrsa kubernetes-master
</code></pre>

<p>Recreate it afterwards:</p>

<pre><code>juju add-relation easyrsa kubernetes-master
</code></pre>

<p>The certificate seems to be recreated for the master, which should now include it's clusterip (10.152.183.1) address as well in the SAN record of the certificate.</p>
",15862,2019-07-07T13:07:06.107,"['juju remove-relation easyrsa kubernetes-master\n', 'juju add-relation easyrsa kubernetes-master\n']"
912,8554,8548,CC BY-SA 4.0,2019-07-08T07:05:22.463,"<p>The issue is that <code>prereqs-ubuntu.sh</code> uses <code>bash</code> to install the <code>npm</code>. While the <code>RUN</code> directive uses <code>sh</code> to run the commands. </p>

<p>Where is the npm installed</p>

<pre><code>root@2cd4a6af90f4:/app# type npm
npm is /root/.nvm/versions/node/v8.16.0/bin/npm
</code></pre>

<p>The <code>PATH</code> for the <code>RUN</code> directive</p>

<pre><code># echo $PATH
/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
</code></pre>
",15544,2019-07-08T07:05:22.463,"['root@2cd4a6af90f4:/app# type npm\nnpm is /root/.nvm/versions/node/v8.16.0/bin/npm\n', '# echo $PATH\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n']"
913,8569,8534,CC BY-SA 4.0,2019-07-09T16:04:27.133,"<p>Without seeing the specific error it looks like the container's runtime process is either crashing or exiting.  When a docker container's runtime process exits the container stops. 
 You can get more information about the specific error by using the <a href=""https://docs.docker.com/engine/reference/commandline/logs/"" rel=""nofollow noreferrer"">docker logs command</a>:</p>

<pre>docker logs 92455a993a54</pre>
",15792,2019-07-09T16:04:27.133,['docker logs 92455a993a54']
914,8578,8571,CC BY-SA 4.0,2019-07-10T13:46:03.153,"<p>If you let docker-compose manage the volumes for you, the volumes names in <code>docker-compose.yml</code> will not be the final ones created/used in docker. <code>docker-compose</code> will prepend the volumes names with the compose project name, which is by default the name of the folder holding the compose file. This is to allow separate projects to use the same names without conflict. For information, you will get the same naming convention for networks.</p>

<p>To get your data back correctly in your compose project, you have two choices.</p>

<h1>Prefered in your case: Move data to automated volumes.</h1>

<p>This will preserve the default compose volume management in your future runs.</p>

<ul>
<li>stop any running container using any of those volumes</li>
<li>launch a dummy container not having mysql (e.g. busybox) and mount all 4 volumes in separate identifiable paths</li>
<li>empty all volumes created by <code>docker-compose</code></li>
<li>copy all data from ""docker only"" volumes to ""compose"" volumes.</li>
<li>stop and recycle your dummy container.</li>
<li><code>docker-compose up -d</code> and enjoy.</li>
<li>if all went good and smooth, delete the other unneeded volumes.</li>
</ul>

<h1>If you know what your doing: use external volumes</h1>

<p>This will work as well but please check the <a href=""https://docs.docker.com/compose/compose-file/"" rel=""nofollow noreferrer"">documentation</a> (Ctrl-f ""Volume configuration reference"") for details. Specifically, be aware that <code>docker-compose up -d</code> will no longer try to create the unexisting volumes and fire an error and stop if they don't exist.</p>

<p>Simply change you volume section at the end of your file to:</p>

<pre><code>volumes:
  db-data-user:
    external:
      name: db-data-user
  db-data-system:
    external:
      name: db-data-system
</code></pre>
",13111,2019-07-10T13:46:03.153,['volumes:\n  db-data-user:\n    external:\n      name: db-data-user\n  db-data-system:\n    external:\n      name: db-data-system\n']
915,8599,8594,CC BY-SA 4.0,2019-07-12T20:04:05.647,"<p>A Scripted Pipeline is literally a Groovy script, so you can just use if/else conditionals like you would in a normal Groovy script.</p>

<pre><code>if (env.BRANCH_NAME == 'master') {
  // do steps here
} else {
  // do other steps here
}
</code></pre>
",4115,2019-07-12T20:04:05.647,"[""if (env.BRANCH_NAME == 'master') {\n  // do steps here\n} else {\n  // do other steps here\n}\n""]"
916,8630,8627,CC BY-SA 4.0,2019-07-16T17:00:49.880,"<p>Surprisingly indeed GitLab works weirdly with the env vars.<br>
It evaluates them internally, though it shouldn't in my view.</p>

<p>Value set as (in project Settings > CI/CD > Variables): <code>'aaa$bbb*%'</code><br>
becomes <code>'aaa*%'</code>
(with single quotes left!)</p>

<p>Couple of of proof links:</p>

<ul>
<li><a href=""https://gitlab.com/gitlab-org/gitlab-ce/issues/45173#note_101659865"" rel=""nofollow noreferrer"">https://gitlab.com/gitlab-org/gitlab-ce/issues/45173#note_101659865</a></li>
<li><a href=""https://gitlab.com/gitlab-org/gitlab-ce/issues/27436"" rel=""nofollow noreferrer"">https://gitlab.com/gitlab-org/gitlab-ce/issues/27436</a></li>
</ul>

<h2>Workarounds:</h2>

<p>1)
You can duplicate dollar ($) sign, i.e.: <code>aaa$$bbb*%</code><br>
(as mentioned on the first link above).</p>

<p>2)
Use base64 to encode and decode the value.</p>

<p>Do this first:</p>

<pre><code>$ echo 'aaa$bbb*%' | base64
YWFhJGJiYiolCg==
</code></pre>

<p>Then store this value in project Variables.</p>

<p>And then in your script decode it:</p>

<pre><code>PASS=$(echo ${sensitive_var} | base64 -D)
</code></pre>
",855,2019-07-17T17:06:55.167,"[""$ echo 'aaa$bbb*%' | base64\nYWFhJGJiYiolCg==\n"", 'PASS=$(echo ${sensitive_var} | base64 -D)\n']"
917,8638,8609,CC BY-SA 4.0,2019-07-17T06:43:55.617,"<p>Let's simplify the dictionary in the first task and loop the subelements in the second. The tasks below</p>
<pre class=""lang-yaml prettyprint-override""><code>    - set_fact:
        nginx_users_selected: &quot;{{ nginx_users_selected|
                                  default({})|
                                  combine({item.key: item.value})
                                  }}&quot;
      loop: &quot;{{ nginx_users|
                dict2items|
                json_query('[*].{key: key, value: value.basic_auth}')
                }}&quot;
      when: item.value
    - debug:
        msg: &quot;{{ item.0.key }} {{ item.1 }}&quot;
      loop: &quot;{{ nginx_users_selected|
                dict2items|
                subelements('value')
                }}&quot;
</code></pre>
<p>give</p>
<pre class=""lang-yaml prettyprint-override""><code>    &quot;msg&quot;: &quot;instance2 username1&quot;
    &quot;msg&quot;: &quot;instance2 username2&quot;
    &quot;msg&quot;: &quot;instance1 username1&quot;
    &quot;msg&quot;: &quot;instance1 username2&quot;
</code></pre>
<p>Then we can create the structure</p>
<pre class=""lang-yaml prettyprint-override""><code>    - set_fact:
        my_list: &quot;{{ my_list|default([]) +
                     [ item.0.key, [ item.1 ]] }}&quot;
      loop: &quot;{{ nginx_users_selected|
                dict2items|
                subelements('value') }}&quot;
    - debug:
        var: my_list
</code></pre>
<p>give</p>
<pre class=""lang-yaml prettyprint-override""><code>    &quot;my_list&quot;: [
        &quot;instance2&quot;, 
        [
            &quot;username1&quot;
        ], 
        &quot;instance2&quot;, 
        [
            &quot;username2&quot;
        ], 
        &quot;instance1&quot;, 
        [
            &quot;username1&quot;
        ], 
        &quot;instance1&quot;, 
        [
            &quot;username2&quot;
        ]
    ]
</code></pre>
",7715,2021-04-19T10:30:32.607,"['    - set_fact:\n        nginx_users_selected: ""{{ nginx_users_selected|\n                                  default({})|\n                                  combine({item.key: item.value})\n                                  }}""\n      loop: ""{{ nginx_users|\n                dict2items|\n                json_query(\'[*].{key: key, value: value.basic_auth}\')\n                }}""\n      when: item.value\n    - debug:\n        msg: ""{{ item.0.key }} {{ item.1 }}""\n      loop: ""{{ nginx_users_selected|\n                dict2items|\n                subelements(\'value\')\n                }}""\n', '    ""msg"": ""instance2 username1""\n    ""msg"": ""instance2 username2""\n    ""msg"": ""instance1 username1""\n    ""msg"": ""instance1 username2""\n', '    - set_fact:\n        my_list: ""{{ my_list|default([]) +\n                     [ item.0.key, [ item.1 ]] }}""\n      loop: ""{{ nginx_users_selected|\n                dict2items|\n                subelements(\'value\') }}""\n    - debug:\n        var: my_list\n', '    ""my_list"": [\n        ""instance2"", \n        [\n            ""username1""\n        ], \n        ""instance2"", \n        [\n            ""username2""\n        ], \n        ""instance1"", \n        [\n            ""username1""\n        ], \n        ""instance1"", \n        [\n            ""username2""\n        ]\n    ]\n']"
918,8640,8619,CC BY-SA 4.0,2019-07-17T12:12:54.507,"<blockquote>
  <p>my understanding is that I'll probably need to modify the images pulled to do this.</p>
</blockquote>

<p>Yes and no. It depends on how your <code>ReplicaSet</code> - specifically the associated <a href=""https://kubernetes.io/docs/concepts/workloads/controllers/deployment/"" rel=""nofollow noreferrer""><code>Deployment</code></a> - is configured. You can see the corresponding YAML configuration by doing </p>

<pre><code>kubectl -n yournamespace get deployment yourappdeployment -o yaml
# or 
kubectl -n yournamespace describe deployment yourappdeployment
</code></pre>

<p>Which will give you information about environment variables, images used, volumes, secrets, etc. </p>

<blockquote>
  <p>I am trying to pull the images down locally so I can modify them</p>
</blockquote>

<p>Pulling an image down and modify it in-place won't be of much help, except if you run a container based on this image and use something like <code>docker commit</code> yo actually update the image. Even if you do that, the Kubernetes objects may override aspects defined in your image (such as environment variables)</p>

<blockquote>
  <p>is there a way to see how the ReplicaSet is pulling the images down?</p>
</blockquote>

<p>Yes, first output the details of your ReplicaSet:</p>

<pre><code>$ kubectl -n yournamespace get replicaset yourreplicaset -o yaml

kind: ReplicaSet
spec:
  ...
  template:
    ...
    spec:
      ...
      containers:
        ...
      imagePullSecrets:
      - name: some-secret-name
</code></pre>

<p><code>imagePullSecrets</code> is the secret which should contains the credentials to pull your images. You can retrieve the data with:</p>

<pre><code>$ kubectl -n yournamespace get secret some-secret-name -o yaml

kind: Secret
...
data:
  .dockerconfigjson: eyJh...VeryLongBase64String
</code></pre>

<p>This is Docker authentication data encoded in Base64. You must decode them:</p>

<pre><code>$ echo ""eyJh...VeryLongBase64String"" | base64 -d

{""auths"": {""registry.yourcompany.com"": {""auth"": ""AnotherBase64EncodedString""}}}
</code></pre>

<p>Decode the <code>auth</code> value and you'll have your Docker registry login/password</p>

<pre><code>$ echo ""AnotherBase64EncodedString"" | base64 -d

username:password
</code></pre>
",12610,2019-07-17T12:12:54.507,"['kubectl -n yournamespace get deployment yourappdeployment -o yaml\n# or \nkubectl -n yournamespace describe deployment yourappdeployment\n', '$ kubectl -n yournamespace get replicaset yourreplicaset -o yaml\n\nkind: ReplicaSet\nspec:\n  ...\n  template:\n    ...\n    spec:\n      ...\n      containers:\n        ...\n      imagePullSecrets:\n      - name: some-secret-name\n', '$ kubectl -n yournamespace get secret some-secret-name -o yaml\n\nkind: Secret\n...\ndata:\n  .dockerconfigjson: eyJh...VeryLongBase64String\n', '$ echo ""eyJh...VeryLongBase64String"" | base64 -d\n\n{""auths"": {""registry.yourcompany.com"": {""auth"": ""AnotherBase64EncodedString""}}}\n', '$ echo ""AnotherBase64EncodedString"" | base64 -d\n\nusername:password\n']"
919,8644,8629,CC BY-SA 4.0,2019-07-17T18:53:47.113,"<p><a href=""https://docs.gitlab.com/ee/ci/yaml/"" rel=""nofollow noreferrer"">https://docs.gitlab.com/ee/ci/yaml/</a></p>

<p><a href=""https://gitlab.com/gitlab-org/gitlab-ce/issues/31296#note_34944784"" rel=""nofollow noreferrer"">https://gitlab.com/gitlab-org/gitlab-ce/issues/31296#note_34944784</a></p>

<blockquote>
<pre><code>integration-testing:
  stage: test
  only:
    - master
  script:
    - ./gradlew clean build asciidoctor
</code></pre>
</blockquote>

<p>Another option is to create a webhook</p>

<p><a href=""https://gitlab.scm.webanywhere.co.uk/help/user/project/integrations/webhooks.md"" rel=""nofollow noreferrer"">https://gitlab.scm.webanywhere.co.uk/help/user/project/integrations/webhooks.md</a></p>

<p>If the ""Merge request events"" is clicked one could trigger a pipeline if a Pull Request gets updated, created or merged.</p>
",210,2019-07-17T19:03:55.523,['integration-testing:\n  stage: test\n  only:\n    - master\n  script:\n    - ./gradlew clean build asciidoctor\n']
920,8647,8619,CC BY-SA 4.0,2019-07-18T05:33:50.850,"<blockquote>
  <p>I am trying to pull the images down locally so I can modify them</p>
</blockquote>

<p>Container images are immutable. The correct way to do this is to look for the <code>Dockerfile</code> (if you are using docker as the container engine) that corresponds to the image and make the relevant changes, rebuild the image and push it to the container registry. </p>

<p>The container registry will be evident to you in the Deployment manifest. You are looking for <code>spec.containers.image</code> attribute.  </p>

<p>To answer your question specifically around ""is the ReplicaSet pulling a fresh image"", this depends on the <code>imagePullPolicy</code> setup in the manifest. You can see the definition below:</p>

<pre><code>
FIELD:    imagePullPolicy &lt;string&gt;

DESCRIPTION:
     Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always
     if :latest tag is specified, or IfNotPresent otherwise. Cannot be updated.
     More info:
     https://kubernetes.io/docs/concepts/containers/images#updating-images
</code></pre>
",4907,2019-11-02T22:52:12.830,"['\nFIELD:    imagePullPolicy <string>\n\nDESCRIPTION:\n     Image pull policy. One of Always, Never, IfNotPresent. Defaults to Always\n     if :latest tag is specified, or IfNotPresent otherwise. Cannot be updated.\n     More info:\n     https://kubernetes.io/docs/concepts/containers/images#updating-images\n']"
921,8651,8626,CC BY-SA 4.0,2019-07-18T15:23:39.757,"<p>So here's how I managed to do it:</p>

<p>Assuming that I need to build an AMI with Packer, only if a new release is detected in the github repository of interest, my gitlab ci yaml looks like:</p>

<pre><code>image: ubuntu

variables:
  NEW_ECS_AGENT: ""false""

before_script:
  - apt update
  - apt -y install wget unzip jq curl httpie
  - current_version=$(curl -s https://checkpoint-api.hashicorp.com/v1/check/packer | jq -r .current_version | sed 's/v//g')
  - wget https://releases.hashicorp.com/packer/${current_version}/packer_${current_version}_linux_amd64.zip -O temp.zip; unzip temp.zip; rm temp.zip
  - mkdir -p /opt/hashicorp
  - mv packer /opt/hashicorp/
  - export PATH=""$PATH:/opt/hashicorp""
  - LAST_PUBLISH_TIMESTAMP=$(http -b GET https://api.github.com/repos/aws/amazon-ecs-agent/releases/latest | jq -r '.published_at')
  - LAST_PUBLISH_DATE=$(echo ${LAST_PUBLISH_TIMESTAMP:0:10} | sed 's/-//g')
  - TODAY=$(date +""%Y%m%d"")
  - TODAYS_DAY=$(echo ${TODAY:6:2})
  - if [[ (( 'TODAY - LAST_PUBLISH_DATE' -gt 0 ) &amp;&amp; ( 'TODAY - LAST_PUBLISH_DATE' -lt 2 )) || (( 'TODAY - LAST_PUBLISH_DATE' -ge 70 ) &amp;&amp; ( 'TODAY - LAST_PUBLISH_DATE' -le 72 ) &amp;&amp; ( ""$TODAYS_DAY"" == ""01"" )) || ( 'TODAY - LAST_PUBLISH_DATE' -eq 8870 ) ]] ; then eval export NEW_ECS_AGENT=""true"" ; fi
  - echo $NEW_ECS_AGENT
  - echo $CI_PIPELINE_SOURCE

build-zabbix-agent-scheduled:
  stage: build
  script:
    - echo $NEW_ECS_AGENT
    - if [[ ""$NEW_ECS_AGENT"" == ""false"" ]] &amp;&amp; [[ ""$CI_PIPELINE_SOURCE"" == ""schedule"" ]] ; then echo ""No new ecs-agent version detected. Skipping AMI building..."" &amp;&amp; exit ; fi
    - cd ecs-zabbix
    - packer build template.json
  only:
    refs:
      - schedules

</code></pre>

<p>First part of the <code>before_script</code> pulls the latest packer version and then it checks the aws/amazon-ecs-agent github repo for the latest release publish date, and detects if there is a new release, based on the diff with the current date.</p>

<p>I know the multiple if clauses look kinda stupid (they basically take into account all possibilities of dates diff (same month, different month, different year, goal is to check if a release was made the day before the pipeline runs, and if so, it builds it)) but at least it works.</p>

<p>Lastly, there is a conditional exit (inside the <code>script</code> key) if the above conditions are not met. It works, but in the interface it shows the pipeline as passed. I am not sure if there is a better way of doing this.</p>
",9344,2019-07-18T15:23:39.757,"['image: ubuntu\n\nvariables:\n  NEW_ECS_AGENT: ""false""\n\nbefore_script:\n  - apt update\n  - apt -y install wget unzip jq curl httpie\n  - current_version=$(curl -s https://checkpoint-api.hashicorp.com/v1/check/packer | jq -r .current_version | sed \'s/v//g\')\n  - wget https://releases.hashicorp.com/packer/${current_version}/packer_${current_version}_linux_amd64.zip -O temp.zip; unzip temp.zip; rm temp.zip\n  - mkdir -p /opt/hashicorp\n  - mv packer /opt/hashicorp/\n  - export PATH=""$PATH:/opt/hashicorp""\n  - LAST_PUBLISH_TIMESTAMP=$(http -b GET https://api.github.com/repos/aws/amazon-ecs-agent/releases/latest | jq -r \'.published_at\')\n  - LAST_PUBLISH_DATE=$(echo ${LAST_PUBLISH_TIMESTAMP:0:10} | sed \'s/-//g\')\n  - TODAY=$(date +""%Y%m%d"")\n  - TODAYS_DAY=$(echo ${TODAY:6:2})\n  - if [[ (( \'TODAY - LAST_PUBLISH_DATE\' -gt 0 ) && ( \'TODAY - LAST_PUBLISH_DATE\' -lt 2 )) || (( \'TODAY - LAST_PUBLISH_DATE\' -ge 70 ) && ( \'TODAY - LAST_PUBLISH_DATE\' -le 72 ) && ( ""$TODAYS_DAY"" == ""01"" )) || ( \'TODAY - LAST_PUBLISH_DATE\' -eq 8870 ) ]] ; then eval export NEW_ECS_AGENT=""true"" ; fi\n  - echo $NEW_ECS_AGENT\n  - echo $CI_PIPELINE_SOURCE\n\nbuild-zabbix-agent-scheduled:\n  stage: build\n  script:\n    - echo $NEW_ECS_AGENT\n    - if [[ ""$NEW_ECS_AGENT"" == ""false"" ]] && [[ ""$CI_PIPELINE_SOURCE"" == ""schedule"" ]] ; then echo ""No new ecs-agent version detected. Skipping AMI building..."" && exit ; fi\n    - cd ecs-zabbix\n    - packer build template.json\n  only:\n    refs:\n      - schedules\n\n']"
922,8668,8667,CC BY-SA 4.0,2019-07-21T13:18:38.280,"<p>Copy module should work</p>

<pre><code>- hosts: all  
  tasks:
    - copy:
        src: /data/new_config
        dest: /opt/zservice/etc/config
        owner: root
        group: wheel
        mode: '0750'
        backup: yes
</code></pre>

<p>If you worry about the number of the hosts take a look at <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_delegation.html#rolling-update-batch-size"" rel=""nofollow noreferrer"">serial</a>.</p>
",7715,2019-07-21T13:18:38.280,"[""- hosts: all  \n  tasks:\n    - copy:\n        src: /data/new_config\n        dest: /opt/zservice/etc/config\n        owner: root\n        group: wheel\n        mode: '0750'\n        backup: yes\n""]"
923,8672,8671,CC BY-SA 4.0,2019-07-22T10:03:42.470,"<p>Ah. Well a high level answer that allows for me to just 'get by' for now is this:</p>

<p>Docker will automatically create a network when running one or more containers. You can check what a container's IP address is on this virtual network by running:</p>

<pre><code>docker container inspect &lt;container name&gt;
</code></pre>

<p>I was able to find the gateway address of the postgres container that I want to query from and use it that way. </p>
",16129,2019-07-22T12:09:42.080,['docker container inspect <container name>\n']
924,8687,8684,CC BY-SA 4.0,2019-07-23T18:15:29.493,"<p>The problem is that port 6666 is considered unsafe by Chrome (hence the <code>ERR_UNSAFE_PORT</code> error), as it clashes with one used by Alternate IRC [Apple addition].</p>

<p>I looked into this and found a list of <a href=""https://superuser.com/a/188070/178675"">ports to avoid</a>, so as to avoid having to modify the Chrome shortcut as recommended by @Wesley Rolnick.</p>

<pre><code>1,       // tcpmux
7,       // echo
9,       // discard
11,      // systat
13,      // daytime
15,      // netstat
17,      // qotd
19,      // chargen
20,      // ftp data
21,      // ftp access
22,      // ssh
23,      // telnet
25,      // smtp
37,      // time
42,      // name
43,      // nicname
53,      // domain
77,      // priv-rjs
79,      // finger
87,      // ttylink
95,      // supdup
101,     // hostriame
102,     // iso-tsap
103,     // gppitnp
104,     // acr-nema
109,     // pop2
110,     // pop3
111,     // sunrpc
113,     // auth
115,     // sftp
117,     // uucp-path
119,     // nntp
123,     // NTP
135,     // loc-srv /epmap
139,     // netbios
143,     // imap2
179,     // BGP
389,     // ldap
427,     // SLP (Also used by Apple Filing Protocol)
465,     // smtp+ssl
512,     // print / exec
513,     // login
514,     // shell
515,     // printer
526,     // tempo
530,     // courier
531,     // chat
532,     // netnews
540,     // uucp
548,     // AFP (Apple Filing Protocol)
556,     // remotefs
563,     // nntp+ssl
587,     // stmp?
601,     // ??
636,     // ldap+ssl
993,     // ldap+ssl
995,     // pop3+ssl
2049,    // nfs
3659,    // apple-sasl / PasswordServer
4045,    // lockd
6000,    // X11
6665,    // Alternate IRC [Apple addition]
6666,    // Alternate IRC [Apple addition]
6667,    // Standard IRC [Apple addition]
6668,    // Alternate IRC [Apple addition]
6669,    // Alternate IRC [Apple addition]
6697,    // IRC + TLS
</code></pre>
",16146,2019-07-23T18:15:29.493,"['1,       // tcpmux\n7,       // echo\n9,       // discard\n11,      // systat\n13,      // daytime\n15,      // netstat\n17,      // qotd\n19,      // chargen\n20,      // ftp data\n21,      // ftp access\n22,      // ssh\n23,      // telnet\n25,      // smtp\n37,      // time\n42,      // name\n43,      // nicname\n53,      // domain\n77,      // priv-rjs\n79,      // finger\n87,      // ttylink\n95,      // supdup\n101,     // hostriame\n102,     // iso-tsap\n103,     // gppitnp\n104,     // acr-nema\n109,     // pop2\n110,     // pop3\n111,     // sunrpc\n113,     // auth\n115,     // sftp\n117,     // uucp-path\n119,     // nntp\n123,     // NTP\n135,     // loc-srv /epmap\n139,     // netbios\n143,     // imap2\n179,     // BGP\n389,     // ldap\n427,     // SLP (Also used by Apple Filing Protocol)\n465,     // smtp+ssl\n512,     // print / exec\n513,     // login\n514,     // shell\n515,     // printer\n526,     // tempo\n530,     // courier\n531,     // chat\n532,     // netnews\n540,     // uucp\n548,     // AFP (Apple Filing Protocol)\n556,     // remotefs\n563,     // nntp+ssl\n587,     // stmp?\n601,     // ??\n636,     // ldap+ssl\n993,     // ldap+ssl\n995,     // pop3+ssl\n2049,    // nfs\n3659,    // apple-sasl / PasswordServer\n4045,    // lockd\n6000,    // X11\n6665,    // Alternate IRC [Apple addition]\n6666,    // Alternate IRC [Apple addition]\n6667,    // Standard IRC [Apple addition]\n6668,    // Alternate IRC [Apple addition]\n6669,    // Alternate IRC [Apple addition]\n6697,    // IRC + TLS\n']"
925,8689,7942,CC BY-SA 4.0,2019-07-23T21:31:47.287,"<p>The issues were a lot, but the main one was not using Targets properly and then some YAML syntax problems.</p>

<pre><code>---
description: ""Example""
schemaVersion: ""0.3""
assumeRole: ""arn:aws:iam::{ID}:role/Example""
# parameters:
#   InstanceId:
#     type: ""StringList""
#     description: ""(Required) EC2 Instance(s) to start""
#   AutomationAssumeRole:
#     type: ""String""
#     description: ""(Optional) The ARN of the role that allows Automation to perform the actions on your behalf.""
#     default: """"
mainSteps:
## STEP 1
- name: StartExampleServiceOnServer1
  action: aws:runCommand
  maxAttempts: 2
  inputs:
    DocumentName: AWS-RunPowerShellScript
    Targets:
    - Key: tag:Name
      Values:
      - ExampleOne-SomeService-Dev
    Parameters:
      commands:
      # Start service for SomeService
      - Start-Service -Name ""ExampleOne""
      - Start-Sleep -s 30
  nextStep: ...
</code></pre>
",9754,2019-07-23T21:31:47.287,"['---\ndescription: ""Example""\nschemaVersion: ""0.3""\nassumeRole: ""arn:aws:iam::{ID}:role/Example""\n# parameters:\n#   InstanceId:\n#     type: ""StringList""\n#     description: ""(Required) EC2 Instance(s) to start""\n#   AutomationAssumeRole:\n#     type: ""String""\n#     description: ""(Optional) The ARN of the role that allows Automation to perform the actions on your behalf.""\n#     default: """"\nmainSteps:\n## STEP 1\n- name: StartExampleServiceOnServer1\n  action: aws:runCommand\n  maxAttempts: 2\n  inputs:\n    DocumentName: AWS-RunPowerShellScript\n    Targets:\n    - Key: tag:Name\n      Values:\n      - ExampleOne-SomeService-Dev\n    Parameters:\n      commands:\n      # Start service for SomeService\n      - Start-Service -Name ""ExampleOne""\n      - Start-Sleep -s 30\n  nextStep: ...\n']"
926,8692,2191,CC BY-SA 4.0,2019-07-23T23:36:17.910,"<p>Here is a short snippet you can just run from the jenkins script console, to dump all of your credentials to plain text.</p>

<pre class=""lang-java prettyprint-override""><code>com.cloudbees.plugins.credentials.SystemCredentialsProvider.getInstance().getCredentials().forEach{
  it.properties.each { prop, val -&gt;
    if (prop == ""secretBytes"") {
      println(prop + ""=&gt;\n"" + new String(com.cloudbees.plugins.credentials.SecretBytes.fromString(""${val}"").getPlainData()) + ""\n"")
    } else {
      println(prop + ' = ""' + val + '""')
    }
  }
  println(""-----------------------"")
}
</code></pre>

<p>A more complicated version that lists for non-system credential providers:</p>

<pre class=""lang-java prettyprint-override""><code>import com.cloudbees.plugins.credentials.CredentialsProvider
import com.cloudbees.plugins.credentials.Credentials
import com.cloudbees.plugins.credentials.domains.Domain
import jenkins.model.Jenkins
def indent = { String text, int indentationCount -&gt;
  def replacement = ""\t"" * indentationCount
  text.replaceAll(""(?m)^"", replacement)
}

Jenkins.get().allItems().collectMany{ CredentialsProvider.lookupStores(it).toList()}.unique().forEach { store -&gt;
  Map&lt;Domain, List&lt;Credentials&gt;&gt; domainCreds = [:]
  store.domains.each { domainCreds.put(it, store.getCredentials(it))}
  if (domainCreds.collectMany{ it.value}.empty) {
    return
  }
  def shortenedClassName = store.getClass().name.substring(store.getClass().name.lastIndexOf(""."") + 1)
  println ""Credentials for store context: ${store.contextDisplayName}, of type $shortenedClassName""
  domainCreds.forEach { domain , creds -&gt;
    println indent(""Domain: ${domain.name}"", 1)
    creds.each { cred -&gt;
      cred.properties.each { prop, val -&gt;
        println indent(""$prop = \""$val\"""", 2)
      }
      println indent(""-----------------------"", 2)
    }
  }
}
</code></pre>
",16159,2020-04-14T00:58:30.317,"['com.cloudbees.plugins.credentials.SystemCredentialsProvider.getInstance().getCredentials().forEach{\n  it.properties.each { prop, val ->\n    if (prop == ""secretBytes"") {\n      println(prop + ""=>\\n"" + new String(com.cloudbees.plugins.credentials.SecretBytes.fromString(""${val}"").getPlainData()) + ""\\n"")\n    } else {\n      println(prop + \' = ""\' + val + \'""\')\n    }\n  }\n  println(""-----------------------"")\n}\n', 'import com.cloudbees.plugins.credentials.CredentialsProvider\nimport com.cloudbees.plugins.credentials.Credentials\nimport com.cloudbees.plugins.credentials.domains.Domain\nimport jenkins.model.Jenkins\ndef indent = { String text, int indentationCount ->\n  def replacement = ""\\t"" * indentationCount\n  text.replaceAll(""(?m)^"", replacement)\n}\n\nJenkins.get().allItems().collectMany{ CredentialsProvider.lookupStores(it).toList()}.unique().forEach { store ->\n  Map<Domain, List<Credentials>> domainCreds = [:]\n  store.domains.each { domainCreds.put(it, store.getCredentials(it))}\n  if (domainCreds.collectMany{ it.value}.empty) {\n    return\n  }\n  def shortenedClassName = store.getClass().name.substring(store.getClass().name.lastIndexOf(""."") + 1)\n  println ""Credentials for store context: ${store.contextDisplayName}, of type $shortenedClassName""\n  domainCreds.forEach { domain , creds ->\n    println indent(""Domain: ${domain.name}"", 1)\n    creds.each { cred ->\n      cred.properties.each { prop, val ->\n        println indent(""$prop = \\""$val\\"""", 2)\n      }\n      println indent(""-----------------------"", 2)\n    }\n  }\n}\n']"
927,8702,8667,CC BY-SA 4.0,2019-07-24T17:10:58.917,"<p>You can use Ansible’s template module transfers templated files to remote hosts. 
It works similarly to the copy module, but with  major difference:</p>

<p>You can use the jinja2 templating language in your files, which will be templated out separately for each remote host and you can have conditional statements, loops, filters for transforming the data, do arithmetic calculations, etc. </p>

<pre><code>- hosts: all  
  tasks:

    - name: Update config on remote servers 
      template:
        #src: Update_config.j2  using jinja2 templating language, if we need  
                               transforming data 
        src: /data/new_config  # Static 
        dest: /opt/zservice/etc/config
        force: yes
        backup: yes
</code></pre>

<p>For more details see <a href=""https://docs.ansible.com/ansible/latest/modules/template_module.html"" rel=""nofollow noreferrer"">ansible template module</a></p>
",10607,2019-07-24T17:10:58.917,"['- hosts: all  \n  tasks:\n\n    - name: Update config on remote servers \n      template:\n        #src: Update_config.j2  using jinja2 templating language, if we need  \n                               transforming data \n        src: /data/new_config  # Static \n        dest: /opt/zservice/etc/config\n        force: yes\n        backup: yes\n']"
928,8705,8703,CC BY-SA 4.0,2019-07-25T09:50:34.683,"<p>Using a multi-branch pipeline you have several different ways of filtering branches, take for instance a regular expression for ""foo"". In order to use this job type, you must create a Jenkinsfile in your repo with build instructions using the scripted or declarative syntax. The term pull request is typically synonymous with services like Github and Bitbucket. </p>

<p><a href=""https://i.stack.imgur.com/TE8VV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/TE8VV.png"" alt=""multibranch pipeline branch source""></a>  </p>

<p>You can also filter within the pipeline itself using declarative syntax:</p>

<pre><code>when {changeRequest branch: ""foo.*"", comparator: 'REGEXP' }
</code></pre>

<p>And also scripted syntax:</p>

<pre><code>if (env.BRANCH_NAME ==~ /foo.*/){  
    ...
}
</code></pre>
",6579,2019-07-25T09:50:34.683,"['when {changeRequest branch: ""foo.*"", comparator: \'REGEXP\' }\n', 'if (env.BRANCH_NAME ==~ /foo.*/){  \n    ...\n}\n']"
929,8708,8706,CC BY-SA 4.0,2019-07-25T14:13:38.797,"<p>Ah I worked it out now.  The epp call needs the module name in it:</p>

<pre><code>content =&gt; epp('moduleName/file.epp')
</code></pre>
",16194,2019-07-25T14:13:38.797,"[""content => epp('moduleName/file.epp')\n""]"
930,8714,2115,CC BY-SA 4.0,2019-07-25T23:10:57.940,"<p>Terraform v0.12 added support for Dynamic Nested Blocks. The following example is derived from their <a href=""https://www.hashicorp.com/blog/hashicorp-terraform-0-12-preview-for-and-for-each"" rel=""noreferrer"">blog post</a> about the new features (see section <a href=""https://www.hashicorp.com/blog/hashicorp-terraform-0-12-preview-for-and-for-each#dynamic-nested-blocks"" rel=""noreferrer"">Dynamic Nested Blocks</a>):</p>

<pre><code>locals {
  standard_tags = {
    Name    = var.cluster_prefix
    Owner   = var.tag_Owner
    Project = var.tag_Project
  }
}

resource ""aws_autoscaling_group"" ""example"" {
  # ...

  dynamic ""tag"" {
    for_each = local.standard_tags

    content {
      key                 = tag.key
      value               = tag.value
      propagate_at_launch = true
    }
  }
}
</code></pre>
",2708,2019-07-25T23:10:57.940,"['locals {\n  standard_tags = {\n    Name    = var.cluster_prefix\n    Owner   = var.tag_Owner\n    Project = var.tag_Project\n  }\n}\n\nresource ""aws_autoscaling_group"" ""example"" {\n  # ...\n\n  dynamic ""tag"" {\n    for_each = local.standard_tags\n\n    content {\n      key                 = tag.key\n      value               = tag.value\n      propagate_at_launch = true\n    }\n  }\n}\n']"
931,8715,7975,CC BY-SA 4.0,2019-07-25T23:34:05.890,"<p>First, make sure that packer runs in debug mode (<code>packer build -debug ...</code>), otherwise the temporary key will not be written to disk but will only be kept in memory.</p>

<p>packer will store the key in its working directory. In other words, look in the same directory from which you started the packer process.</p>

<p>If you use AWS, the file will be called <code>ec2_amazon-ebs.pem</code>. Assuming you are building an Ubuntu image, you should be able to login to the instance with this command:</p>

<pre><code>ssh -i ec2_amazon-ebs.pem ubuntu@&lt;ip&gt;
</code></pre>

<p>(where <code>&lt;ip&gt;</code> can be found in the packer output or through the AWS console)</p>
",2708,2019-07-25T23:34:05.890,['ssh -i ec2_amazon-ebs.pem ubuntu@<ip>\n']
932,8726,8725,CC BY-SA 4.0,2019-07-27T09:24:44.550,"<p><a href=""https://docs.ansible.com/ansible/latest/modules/reboot_module.html"" rel=""nofollow noreferrer"">https://docs.ansible.com/ansible/latest/modules/reboot_module.html</a></p>

<blockquote>
<pre><code>- name: Unconditionally reboot the machine with all defaults
  reboot:

- name: Reboot a slow machine that might have lots of updates to apply
  reboot:
    reboot_timeout: 3600
</code></pre>
</blockquote>
",210,2019-07-27T09:24:44.550,['- name: Unconditionally reboot the machine with all defaults\n  reboot:\n\n- name: Reboot a slow machine that might have lots of updates to apply\n  reboot:\n    reboot_timeout: 3600\n']
933,8727,8724,CC BY-SA 4.0,2019-07-27T09:26:46.787,"<p><a href=""https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update.html"" rel=""nofollow noreferrer"">https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-update.html</a></p>

<blockquote>
<pre><code>POST test/_update/1
{
    ""script"" : {
        ""source"": ""if (ctx._source.tags.contains(params.tag)) { ctx._source.tags.remove(ctx._source.tags.indexOf(params.tag)) }"",
        ""lang"": ""painless"",
        ""params"" : {
            ""tag"" : ""blue""
        }
    }
}
</code></pre>
</blockquote>
",210,2019-07-27T09:26:46.787,"['POST test/_update/1\n{\n    ""script"" : {\n        ""source"": ""if (ctx._source.tags.contains(params.tag)) { ctx._source.tags.remove(ctx._source.tags.indexOf(params.tag)) }"",\n        ""lang"": ""painless"",\n        ""params"" : {\n            ""tag"" : ""blue""\n        }\n    }\n}\n']"
934,8728,8721,CC BY-SA 4.0,2019-07-27T09:30:51.730,"<p>According to <a href=""https://learn.hashicorp.com/vault/operations/ops-vault-ha-consul"" rel=""nofollow noreferrer"">this documentation</a>, each vault has to be unsealed in a HA setup.</p>

<blockquote>
  <p>Now you need to initializing and unsealing each Vault instance.</p>

<pre><code># Initialize vault_s1
$ vault operator init

# Unseal the vault_s1
$ vault operator unseal &lt;unseal_key_1&gt;

$ vault operator unseal &lt;unseal_key_2&gt;

$ vault operator unseal &lt;unseal_key_3&gt;
</code></pre>
</blockquote>
",210,2019-07-27T09:35:58.870,['# Initialize vault_s1\n$ vault operator init\n\n# Unseal the vault_s1\n$ vault operator unseal <unseal_key_1>\n\n$ vault operator unseal <unseal_key_2>\n\n$ vault operator unseal <unseal_key_3>\n']
935,8729,8717,CC BY-SA 4.0,2019-07-27T09:45:16.243,"<p>My personal opinion is that each deliverable should reside in its own repository. However if one would like to keep the monorepo one could use <a href=""https://devops.stackexchange.com/a/6678/210""><code>changeset</code> in conjunction with <code>when</code></a>:</p>

<blockquote>
<pre><code>pipeline {
    agent any
    stages {
        stage('build matchengine') {
            when {
                changeset ""**/matchengine/*.*""
            }
            steps {
                echo 'building match engine'
            }
        }
        stage('build posttrade') {
            when {
                changeset ""**/posttrade/*.*""
            }
            steps {
                echo 'building post trade'
            }
        }
    }
}
</code></pre>
</blockquote>

<p>or <a href=""https://stackoverflow.com/a/49189040/2777965"">change the directory in several build stage and build the code inside this directory</a>:</p>

<blockquote>
<pre><code>stage('Build') {
  dir('web_app') {
    sh 'ls'
    sh 'git pull'
  }
}
</code></pre>
</blockquote>

<p>One could also decide to use the <a href=""https://jenkins.io/blog/2017/09/25/declarative-1/"" rel=""nofollow noreferrer"">parallel option</a> to ensure that the build times will be shortened:</p>

<blockquote>
<pre><code>/* .. snip .. */
stage('run-parallel-branches') {
  steps {
    parallel(
      a: {
        echo ""This is branch a""
      },
      b: {
        echo ""This is branch b""
      }
    )
  }
}
/* .. snip .. */
</code></pre>
</blockquote>

<p>Regarding the question:</p>

<blockquote>
  <p>Set up Jenkins job which will trigger task only for repo where PUSH
  has occurred. e.g if my monorepo consist 2 merged repos repo1 and
  repo2 , so if any changes in repo1 should trigger only related task
  for repo1 and likewise for repo2.</p>
</blockquote>

<p>I think that <code>changeset</code> would be most useful: a change will trigger the build, but as a change only occurred in a certain path, only that build will be started.</p>
",210,2019-07-27T09:50:30.960,"['pipeline {\n    agent any\n    stages {\n        stage(\'build matchengine\') {\n            when {\n                changeset ""**/matchengine/*.*""\n            }\n            steps {\n                echo \'building match engine\'\n            }\n        }\n        stage(\'build posttrade\') {\n            when {\n                changeset ""**/posttrade/*.*""\n            }\n            steps {\n                echo \'building post trade\'\n            }\n        }\n    }\n}\n', ""stage('Build') {\n  dir('web_app') {\n    sh 'ls'\n    sh 'git pull'\n  }\n}\n"", '/* .. snip .. */\nstage(\'run-parallel-branches\') {\n  steps {\n    parallel(\n      a: {\n        echo ""This is branch a""\n      },\n      b: {\n        echo ""This is branch b""\n      }\n    )\n  }\n}\n/* .. snip .. */\n']"
936,8730,8703,CC BY-SA 4.0,2019-07-27T10:01:59.187,"<p>Once could use the <a href=""https://jenkins.io/doc/book/pipeline/syntax/"" rel=""nofollow noreferrer""><code>when</code> in conjunction with the <code>branch</code> keyword if Jenkins declarative pipelines would be used</a>:</p>

<blockquote>
<pre><code>pipeline {
    agent any
    stages {
        stage('Example Build') {
            steps {
                echo 'Hello World'
            }
        }
        stage('Example Deploy') {
            when {
                branch 'production'
            }
            steps {
                echo 'Deploying'
            }
        }
    }
}
</code></pre>
</blockquote>
",210,2019-07-27T10:01:59.187,"[""pipeline {\n    agent any\n    stages {\n        stage('Example Build') {\n            steps {\n                echo 'Hello World'\n            }\n        }\n        stage('Example Deploy') {\n            when {\n                branch 'production'\n            }\n            steps {\n                echo 'Deploying'\n            }\n        }\n    }\n}\n""]"
937,8749,8712,CC BY-SA 4.0,2019-07-30T07:36:19.803,"<p>On Windows (Dotnet Core) it can be done using powershell remote-invoke.</p>

<p>In the container you need to set a trusted host by doing:</p>

<p><code>RUN @powershell Set-Item WSMan:\localhost\Client\TrustedHosts -Value '*' -Force</code> </p>

<p>Ideally replace the <code>*</code> with the host actual IP address. Keep in mind it changes between system restarts.</p>

<p>On the host you need to create an Event Source called <code>MyLogger</code>.</p>

<p>After that in your app you can create a custom logger that you add to the Microsoft Logging pipeline.</p>

<p><strong>RemoteEventLogProvider.cs:</strong></p>

<pre><code>using System.Management.Automation;
using System.Net;
using Microsoft.Extensions.Logging;

namespace LogWriter
{
    public class RemoteEventLogProvider : ILoggerProvider
    {
        private readonly string _computer;
        private readonly PowerShell _powershell;
        private readonly NetworkCredential _credential;

        public RemoteEventLogProvider(string computer, NetworkCredential credential)
        {
            _computer = computer;
            _credential = credential;
            _powershell = PowerShell.Create();
        }

        public ILogger CreateLogger(string category)
        {
            return new RemoteEventLogger(_computer, _credential, _powershell, category);
        }

        public void Dispose()
        {
            _powershell.Dispose();
        }
    }
}
</code></pre>

<p><strong>RemoteEventLogger.cs</strong></p>

<pre><code>using System;
using System.Management.Automation;
using System.Net;
using Microsoft.Extensions.Logging;

namespace LogWriter
{
    public class RemoteEventLogger : ILogger
    {
        private readonly string _computer;
        private readonly string _category;
        private readonly PowerShell _powershell;
        private readonly NetworkCredential _credential;

        public RemoteEventLogger(string computer, NetworkCredential credential, PowerShell powershell, string category)
        {
            _computer = computer;
            _category = category;
            _credential = credential;
            _powershell = powershell;
        }

        public IDisposable BeginScope&lt;TState&gt;(TState state)
        {
            throw new NotImplementedException();
        }

        public bool IsEnabled(LogLevel logLevel)
        {
            return true;
        }

        public void Log&lt;TState&gt;(LogLevel logLevel, EventId eventId, TState state, Exception exception, Func&lt;TState, Exception, string&gt; formatter)
        {
            var script = ScriptBlock.Create($""$password = ConvertTo-SecureString '{_credential.Password}' -AsPlainText -Force;"" +
                                            $""$credential = New-Object System.Management.Automation.PSCredential ('{_credential.UserName}', $password);"" +
                                            $""Invoke-Command -ScriptBlock {{ Write-EventLog -EntryType {logLevel} -EventId 0 -Source MyLogger -LogName Application -Message \""{formatter(state, exception)}\"" }} -ComputerName {_computer} -Credential $credential;"");

            var results = _powershell.AddScript(script.ToString()).Invoke();

            _powershell.Commands.Clear();
        }
    }
}
</code></pre>

<p>Example usage <strong>Program.cs:</strong></p>

<pre><code>using System;
using System.Net;
using System.Threading.Tasks;
using Microsoft.Extensions.Configuration;
using Microsoft.Extensions.Logging;

namespace LogWriter
{
    class Program
    {
        static async Task Main(string[] args)
        {
            var config = new ConfigurationBuilder()
                      .AddCommandLine(args)
                      .AddEnvironmentVariables()
                      .Build();

            var computer = config[""ConnectionStrings:Host.Address""];
            var provider = new RemoteEventLogProvider(computer, new NetworkCredential($""{computer}\\username"", ""password""));

            using (var factory = new LoggerFactory().AddConsole())
            {
                factory.AddProvider(provider);

                var logger = factory.CreateLogger(""MyLogger"");

                logger.LogInformation($""Remote log at {computer}"");

                while (true)
                {
                    try
                    {
                        logger.LogInformation($""The time is {DateTime.UtcNow}"");

                        if (DateTime.UtcNow.Second % 2 == 0)
                        {
                            throw new Exception(""random shit"");
                        }
                        else
                        {
                            logger.LogWarning(""Example warning"");
                        }
                    }
                    catch (Exception ex)
                    {
                        logger.LogError(ex, ex.Message);
                    }

                    await Task.Delay(TimeSpan.FromSeconds(5));
                }
            }
        }
    }
}
</code></pre>

<p>Example <strong>Dockerfile</strong>:</p>

<pre><code># Build
FROM mcr.microsoft.com/dotnet/core/sdk:2.2 AS build-env
WORKDIR /app
COPY . /app

RUN dotnet publish -c Release -o /app/out

# Runtime
FROM mcr.microsoft.com/windows/servercore:ltsc2019
RUN curl -o c:\dotnet.exe https://download.visualstudio.microsoft.com/download/pr/a9bb6d52-5f3f-4f95-90c2-084c499e4e33/eba3019b555bb9327079a0b1142cc5b2/dotnet-hosting-2.2.6-win.exe
RUN c:\dotnet.exe /quiet /install

# Host
RUN @powershell Set-Item WSMan:\localhost\Client\TrustedHosts -Value '*' -Force

# Application
WORKDIR /app
COPY --from=build-env /app/out .

ENTRYPOINT dotnet LogWriter.dll
</code></pre>
",16201,2019-07-30T07:36:19.803,"['using System.Management.Automation;\nusing System.Net;\nusing Microsoft.Extensions.Logging;\n\nnamespace LogWriter\n{\n    public class RemoteEventLogProvider : ILoggerProvider\n    {\n        private readonly string _computer;\n        private readonly PowerShell _powershell;\n        private readonly NetworkCredential _credential;\n\n        public RemoteEventLogProvider(string computer, NetworkCredential credential)\n        {\n            _computer = computer;\n            _credential = credential;\n            _powershell = PowerShell.Create();\n        }\n\n        public ILogger CreateLogger(string category)\n        {\n            return new RemoteEventLogger(_computer, _credential, _powershell, category);\n        }\n\n        public void Dispose()\n        {\n            _powershell.Dispose();\n        }\n    }\n}\n', 'using System;\nusing System.Management.Automation;\nusing System.Net;\nusing Microsoft.Extensions.Logging;\n\nnamespace LogWriter\n{\n    public class RemoteEventLogger : ILogger\n    {\n        private readonly string _computer;\n        private readonly string _category;\n        private readonly PowerShell _powershell;\n        private readonly NetworkCredential _credential;\n\n        public RemoteEventLogger(string computer, NetworkCredential credential, PowerShell powershell, string category)\n        {\n            _computer = computer;\n            _category = category;\n            _credential = credential;\n            _powershell = powershell;\n        }\n\n        public IDisposable BeginScope<TState>(TState state)\n        {\n            throw new NotImplementedException();\n        }\n\n        public bool IsEnabled(LogLevel logLevel)\n        {\n            return true;\n        }\n\n        public void Log<TState>(LogLevel logLevel, EventId eventId, TState state, Exception exception, Func<TState, Exception, string> formatter)\n        {\n            var script = ScriptBlock.Create($""$password = ConvertTo-SecureString \'{_credential.Password}\' -AsPlainText -Force;"" +\n                                            $""$credential = New-Object System.Management.Automation.PSCredential (\'{_credential.UserName}\', $password);"" +\n                                            $""Invoke-Command -ScriptBlock {{ Write-EventLog -EntryType {logLevel} -EventId 0 -Source MyLogger -LogName Application -Message \\""{formatter(state, exception)}\\"" }} -ComputerName {_computer} -Credential $credential;"");\n\n            var results = _powershell.AddScript(script.ToString()).Invoke();\n\n            _powershell.Commands.Clear();\n        }\n    }\n}\n', 'using System;\nusing System.Net;\nusing System.Threading.Tasks;\nusing Microsoft.Extensions.Configuration;\nusing Microsoft.Extensions.Logging;\n\nnamespace LogWriter\n{\n    class Program\n    {\n        static async Task Main(string[] args)\n        {\n            var config = new ConfigurationBuilder()\n                      .AddCommandLine(args)\n                      .AddEnvironmentVariables()\n                      .Build();\n\n            var computer = config[""ConnectionStrings:Host.Address""];\n            var provider = new RemoteEventLogProvider(computer, new NetworkCredential($""{computer}\\\\username"", ""password""));\n\n            using (var factory = new LoggerFactory().AddConsole())\n            {\n                factory.AddProvider(provider);\n\n                var logger = factory.CreateLogger(""MyLogger"");\n\n                logger.LogInformation($""Remote log at {computer}"");\n\n                while (true)\n                {\n                    try\n                    {\n                        logger.LogInformation($""The time is {DateTime.UtcNow}"");\n\n                        if (DateTime.UtcNow.Second % 2 == 0)\n                        {\n                            throw new Exception(""random shit"");\n                        }\n                        else\n                        {\n                            logger.LogWarning(""Example warning"");\n                        }\n                    }\n                    catch (Exception ex)\n                    {\n                        logger.LogError(ex, ex.Message);\n                    }\n\n                    await Task.Delay(TimeSpan.FromSeconds(5));\n                }\n            }\n        }\n    }\n}\n', ""# Build\nFROM mcr.microsoft.com/dotnet/core/sdk:2.2 AS build-env\nWORKDIR /app\nCOPY . /app\n\nRUN dotnet publish -c Release -o /app/out\n\n# Runtime\nFROM mcr.microsoft.com/windows/servercore:ltsc2019\nRUN curl -o c:\\dotnet.exe https://download.visualstudio.microsoft.com/download/pr/a9bb6d52-5f3f-4f95-90c2-084c499e4e33/eba3019b555bb9327079a0b1142cc5b2/dotnet-hosting-2.2.6-win.exe\nRUN c:\\dotnet.exe /quiet /install\n\n# Host\nRUN @powershell Set-Item WSMan:\\localhost\\Client\\TrustedHosts -Value '*' -Force\n\n# Application\nWORKDIR /app\nCOPY --from=build-env /app/out .\n\nENTRYPOINT dotnet LogWriter.dll\n""]"
938,8757,8755,CC BY-SA 4.0,2019-07-30T15:42:35.223,"<p>Sounds like you want the <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html?highlight=filter#combining-hashes-dictionaries"" rel=""nofollow noreferrer"">combine</a> filter.</p>

<p>You could read each file into a specific variable, then use the combine filter to create <code>all-pets</code>. At that point, it would be in memory of course, so you might want to use the <a href=""https://stackoverflow.com/a/26640778/2707870"">answer</a> to <a href=""https://stackoverflow.com/questions/26638180/write-variable-to-a-file-in-ansible"">this question</a> to write it to a file:</p>

<pre><code>- name: Read vars
  include_vars:
    file: ""pets/{{ item }}_pets.yml""
    var: ""{{ item }}""
  loop:
    - steves
    - jacks

- name: Combine vars
  set_fact:
    all_pets: {{ steves | combine(jacks) }}


- name: Write the file
  copy:
    content: ""{{ all_pets | to_yaml }}""
    dest: pets/all_pets.yml
</code></pre>
",354,2019-07-30T15:49:37.170,"['- name: Read vars\n  include_vars:\n    file: ""pets/{{ item }}_pets.yml""\n    var: ""{{ item }}""\n  loop:\n    - steves\n    - jacks\n\n- name: Combine vars\n  set_fact:\n    all_pets: {{ steves | combine(jacks) }}\n\n\n- name: Write the file\n  copy:\n    content: ""{{ all_pets | to_yaml }}""\n    dest: pets/all_pets.yml\n']"
939,8761,8756,CC BY-SA 4.0,2019-07-30T21:10:55.160,"<blockquote>
  <p>Q: "" Prevent misspelled variables passed to Ansible roles ... remove the defaults/main.yml, ... But then I can't take advantage of the benefits of having defaults. Are there other solutions?</p>
</blockquote>

<p>A: Yes. Tell <em>include_role</em> to read other file <a href=""https://docs.ansible.com/ansible/latest/modules/include_role_module.html#parameters"" rel=""nofollow noreferrer""><em>defaults_from</em></a>. Fit the content of this file to your needs. For example</p>

<pre><code>- include_role:
    name: foo
    defaults_from: main_special.yml
  vars:
    fooo_version: ""2.0""
</code></pre>
",7715,2019-07-30T21:10:55.160,"['- include_role:\n    name: foo\n    defaults_from: main_special.yml\n  vars:\n    fooo_version: ""2.0""\n']"
940,8763,8756,CC BY-SA 4.0,2019-07-31T03:00:27.767,"<p>I came up with what I think is a pretty good solution.</p>

<p>First, it requires the addition of this to each role:</p>

<pre><code>- assert:
    that: ""{{ item.key }} is defined""
    fail_msg: ""Attempted to override an unknown variable: {{ item.key }}""
    quiet: yes
  loop: ""{{ q('dict', override) }}""

- set_fact: { ""{{ item.key }}"":""{{ item.value }}"" }
  loop: ""{{ q('dict', override) }}""
</code></pre>

<p>I added those two tasks to a file, <code>override.yml</code> within <code>ansible/tasks/</code>, and then used <code>include_tasks</code> to dynamically include that file only when <code>override</code> is actually defined:</p>

<pre><code>- include_tasks: ""tasks/override.yml""
  when: override is defined
</code></pre>

<p>Second, it requires that when you override defaults with <code>import_role</code> that you do the following:</p>

<pre><code>- include_role:
    name: foo
  vars:
    override:
      fooo_version: ""2.0""
</code></pre>

<p>The first block of code now loops through the passed <code>override</code> dictionary, and verifies that each key already is defined as a variable. So in the above example, the assert would fail because <code>fooo_version</code> is not defined. It then loops through the <code>override</code> dictionary a second time and uses <code>set_fact</code> to set the value of each key:val pair in the dictionary.</p>
",13217,2019-07-31T04:40:20.723,"['- assert:\n    that: ""{{ item.key }} is defined""\n    fail_msg: ""Attempted to override an unknown variable: {{ item.key }}""\n    quiet: yes\n  loop: ""{{ q(\'dict\', override) }}""\n\n- set_fact: { ""{{ item.key }}"":""{{ item.value }}"" }\n  loop: ""{{ q(\'dict\', override) }}""\n', '- include_tasks: ""tasks/override.yml""\n  when: override is defined\n', '- include_role:\n    name: foo\n  vars:\n    override:\n      fooo_version: ""2.0""\n']"
941,8764,2644,CC BY-SA 4.0,2019-07-31T05:49:27.473,"<p>Short Answer: You do programming here. Consider Programming Standards (cleancode) like ""package by feature"" and build role which are reusable and express the reason of the role.
e.g. </p>

<pre><code>roles:
  - role: jdk
  - role: tomcat  
      (contains tasks with 'install tomcat', 'configure tomcat' ) 
      (requires jdk)
  - role: the_wepapp 
      (requires tomcat)
</code></pre>

<p>Futhermore: The underlying role e.g. the jdk should never know about the tomcat role etc...</p>
",16282,2019-07-31T05:54:29.343,"[""roles:\n  - role: jdk\n  - role: tomcat  \n      (contains tasks with 'install tomcat', 'configure tomcat' ) \n      (requires jdk)\n  - role: the_wepapp \n      (requires tomcat)\n""]"
942,8781,8780,CC BY-SA 4.0,2019-08-01T13:03:59.127,"<p>According to Docker documentation <a href=""https://docs.docker.com/develop/develop-images/dockerfile_best-practices/"" rel=""nofollow noreferrer"">search for: ""Leverage build cache""</a>, there is checksum calculated on the directory - please see the article for details.</p>

<p>What I will suggest is a multistage build.</p>

<p>If we have static content of directory we could create container/image with its content. Then instead of using Docker copy, we could use FROM as a build stage and copy that directory into a new layer, which in fact will reuse that layer.
That is based on a fact that we don't operate on a directory (when a file could get a changed attribute like last accessed time). </p>

<h2>Base Dockerfile</h2>

<pre><code>FROM alpine:latest  
COPY /myDirectory .
</code></pre>

<p>Then you could tag this container as storage-base
O</p>

<h2>MultiStage Dockerfile</h2>

<pre><code>FROM storage-base AS storage

FROM alpine:latest  
RUN a command 
WORKDIR /root/
COPY --from=storage /myDirectory .
</code></pre>

<p>Please check more references here: <a href=""https://docs.docker.com/develop/develop-images/multistage-build/"" rel=""nofollow noreferrer"">Docker Multistage Build</a></p>

<h2>Edit</h2>

<ol>
<li>the image/container created in step 1 shall be only recreated when
directory content will change (by a trigger that knows that the data changed), so that means it will not be created on every build.</li>
<li>then we use the image that was created once (and re-use that layer)</li>
</ol>

<p>I just created a simple example to help express my idea - <a href=""https://github.com/profesor79/docker-cache-directory-as-an-image-multistage-build"" rel=""nofollow noreferrer"">Git repo</a> - run build-docker.sh script</p>

<p>I found that on reboot Docker is re-creating cache instead of reusing, but it takes just a few minutes and it is not critical.</p>
",16316,2019-08-01T17:02:28.277,"['FROM alpine:latest  \nCOPY /myDirectory .\n', 'FROM storage-base AS storage\n\nFROM alpine:latest  \nRUN a command \nWORKDIR /root/\nCOPY --from=storage /myDirectory .\n']"
943,8791,8790,CC BY-SA 4.0,2019-08-02T09:38:02.930,"<p>I think you want the <code>ancestor</code> filter :</p>

<p>From the <a href=""https://docs.docker.com/engine/reference/commandline/ps/"" rel=""nofollow noreferrer"">Docker Docs on <code>ps</code></a>:</p>

<blockquote>
  <p><code>ancestor</code> - Filters containers which share a given image as an ancestor. Expressed as <code>image-name[:&lt;tag&gt;]</code>, <code>image id</code>, or <code>image@digest</code></p>
</blockquote>

<pre><code>$docker run -d --rm redis 
c4cf36467d63c66f7d3d8271dd0f8e51ede4a627048eb5e294a2445f5b0d30ef
$ docker ps -f ""ancestor=redis""
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
c4cf36467d63        redis               ""docker-entrypoint.s…""   16 seconds ago      Up 15 seconds       6379/tcp            elated_yonath
</code></pre>
",354,2019-08-02T10:16:45.093,"['$docker run -d --rm redis \nc4cf36467d63c66f7d3d8271dd0f8e51ede4a627048eb5e294a2445f5b0d30ef\n$ docker ps -f ""ancestor=redis""\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES\nc4cf36467d63        redis               ""docker-entrypoint.s…""   16 seconds ago      Up 15 seconds       6379/tcp            elated_yonath\n']"
944,8796,8780,CC BY-SA 4.0,2019-08-02T15:05:56.330,"<p>The docker cache needs the following:</p>

<ul>
<li>Build has been run on the same docker host previously (or you explicitly added flags to trust a pulled image) and</li>
<li>The previous image needs to still be on the build host (not pruned) and</li>
<li>The same previous layer and either</li>
<li>The same command being run (including the same environment/args) or</li>
<li>The same hash on the files being copied</li>
</ul>

<p>If you see the cache being busted on a <code>COPY</code> or <code>ADD</code> command, and not the previous step, then you need to look at the hash being generated. All the files need to be identical, same file names, cases, file permissions, file owners, and the contents need to be bit for bit identical. You can look at the resulting checksum for this hash by running a <code>docker image history</code> command, e.g.:</p>

<pre><code>$ docker image history golang:alpine
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
6b21b4c6e7a3        3 weeks ago         /bin/sh -c #(nop) WORKDIR /go                   0B
&lt;missing&gt;           3 weeks ago         /bin/sh -c mkdir -p ""$GOPATH/src"" ""$GOPATH/b…   0B
&lt;missing&gt;           3 weeks ago         /bin/sh -c #(nop)  ENV PATH=/go/bin:/usr/loc…   0B
&lt;missing&gt;           3 weeks ago         /bin/sh -c #(nop)  ENV GOPATH=/go               0B
&lt;missing&gt;           3 weeks ago         /bin/sh -c set -eux;  apk add --no-cache --v…   344MB
&lt;missing&gt;           3 weeks ago         /bin/sh -c #(nop)  ENV GOLANG_VERSION=1.12.7    0B
&lt;missing&gt;           3 weeks ago         /bin/sh -c [ ! -e /etc/nsswitch.conf ] &amp;&amp; ec…   17B
&lt;missing&gt;           3 weeks ago         /bin/sh -c apk add --no-cache   ca-certifica…   551kB
&lt;missing&gt;           3 weeks ago         /bin/sh -c #(nop)  CMD [""/bin/sh""]              0B
&lt;missing&gt;           3 weeks ago         /bin/sh -c #(nop) ADD file:0eb5ea35741d23fe3…   5.58MB
</code></pre>

<p>You can include the <code>--no-trunc</code> option to get a full line. The key piece of data relevant to your question from the above image is in the <code>ADD</code> step where you see <code>file:0eb5ea35741d23fe3…</code>. If that checksum changes between two image builds, the cache will bust and you'll start a new set of layers.</p>
",7730,2019-08-02T15:05:56.330,"['$ docker image history golang:alpine\nIMAGE               CREATED             CREATED BY                                      SIZE                COMMENT\n6b21b4c6e7a3        3 weeks ago         /bin/sh -c #(nop) WORKDIR /go                   0B\n<missing>           3 weeks ago         /bin/sh -c mkdir -p ""$GOPATH/src"" ""$GOPATH/b…   0B\n<missing>           3 weeks ago         /bin/sh -c #(nop)  ENV PATH=/go/bin:/usr/loc…   0B\n<missing>           3 weeks ago         /bin/sh -c #(nop)  ENV GOPATH=/go               0B\n<missing>           3 weeks ago         /bin/sh -c set -eux;  apk add --no-cache --v…   344MB\n<missing>           3 weeks ago         /bin/sh -c #(nop)  ENV GOLANG_VERSION=1.12.7    0B\n<missing>           3 weeks ago         /bin/sh -c [ ! -e /etc/nsswitch.conf ] && ec…   17B\n<missing>           3 weeks ago         /bin/sh -c apk add --no-cache   ca-certifica…   551kB\n<missing>           3 weeks ago         /bin/sh -c #(nop)  CMD [""/bin/sh""]              0B\n<missing>           3 weeks ago         /bin/sh -c #(nop) ADD file:0eb5ea35741d23fe3…   5.58MB\n']"
945,8799,8797,CC BY-SA 4.0,2019-08-02T16:39:00.780,"<blockquote>
  <p>Is there any way to tell which AMI my EC2 instance was created from?</p>
</blockquote>

<h2>Short answer: yes.</h2>

<h2>Longer answer: yes - how would you like to get it?</h2>

<p>The AMI which the EC2 instance was launched with is part of the <a href=""https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-metadata.html"" rel=""nofollow noreferrer"">EC2 instance metadata</a></p>

<p>Every instance publishes its metadata, which you can retrieve via the HTTP interface:</p>

<pre><code>curl http://&lt;instance.ip.address&gt;/latest/meta-data/ami-id
</code></pre>

<p>(lifted directly from the AWS docs)</p>

<p>Many people prefer the Python library for the AWS API (<a href=""https://boto3.amazonaws.com/v1/documentation/"" rel=""nofollow noreferrer"">boto3</a>). In this particular case you would need to use the <code>instance.image_id</code> method.</p>
",354,2019-08-02T16:46:24.217,['curl http://<instance.ip.address>/latest/meta-data/ami-id\n']
946,8814,8811,CC BY-SA 4.0,2019-08-05T09:17:43.487,"<p>In PowerShell</p>

<pre><code>Get-WmiObject -Class win32_operatingsystem -Property TotalVisibleMemorySize,FreePhysicalMemory
</code></pre>

<p>Or </p>

<pre><code>wmic os get freephysicalmemory
</code></pre>

<p>Or</p>

<pre><code>systeminfo
</code></pre>
",786,2019-08-05T09:17:43.487,"['Get-WmiObject -Class win32_operatingsystem -Property TotalVisibleMemorySize,FreePhysicalMemory\n', 'wmic os get freephysicalmemory\n', 'systeminfo\n']"
947,8817,8811,CC BY-SA 4.0,2019-08-05T11:19:27.173,"<p>You must be Install the <strong>Virtio Balloon</strong> driver AND the <strong>Balloon service</strong> in the guest:</p>

<p>1-Open Device Manager and see if there is an unknown PCI device. If so, right click it and install the driver manually from D:\Balloon\2K16\amd64 (or 2k12, 2k8, etc)</p>

<p>2-Now copy the entire amd64 folder into C:\Program Files\ (NOT x86) and rename it ""Balloon"". So, now you have the amd64 folder from the disc copied as C:\Program Files\Balloon</p>

<p>3-Open an Administrative Command Prompt and cd to C:\Program Files\Balloon</p>

<p>4-Run this command:</p>

<pre><code>BLNSVR.exe -i
</code></pre>
",16392,2019-08-05T11:19:27.173,['BLNSVR.exe -i\n']
948,8821,8816,CC BY-SA 4.0,2019-08-06T00:55:09.813,"<p>For a local development using docker-compose it depends on the language you use to code. But almost all languages have some kind of watch mode to take care when the code changes and reload your service or application.</p>

<p>No matter what language you use for coding if you want to have an auto-refresh feature you need to use volumes on your docker-compose.yaml file to mount your local folder as a volume inside the container.</p>

<p>With that said one example of that would be using <a href=""https://nodemon.io/"" rel=""nofollow noreferrer"">nodemon</a> on a <a href=""https://nodejs.org/"" rel=""nofollow noreferrer"">nodeJS</a> project, but you have o take care not to use nodemon on production by using the <code>CMD</code> on the Dockerfile and docker-compose.yaml properly.</p>

<p>An example of Dockerfile:</p>

<pre><code>FROM node:12

WORKDIR /app

RUN npm i -g nodemon

COPY . /app

CMD node app.js
</code></pre>

<p>And on the docker-compose.yaml:</p>

<pre><code>version: 3
services:
  backend:
    build: .
    image: local-development
    volumes:
      - .:/app
      - /app/node_modules
    command: ['nodemon', 'app.js']
</code></pre>

<p>Look at the two volumes, the first one is for mounting your local directory on <code>/app</code>, but you need the second one to avoid mounting <code>/app/node_modules</code> because you can have problems with modules you have on local that are not the right architecture inside the container, for example, a MacOS compiled module inside a Linux container.</p>

<p>When you use the image on a production environment it will use <code>node app.js</code> as a command but on the <code>docker-compose.yaml</code> file is overridden by <code>nodemon app.js</code>.</p>
",6775,2019-08-06T00:55:09.813,"['FROM node:12\n\nWORKDIR /app\n\nRUN npm i -g nodemon\n\nCOPY . /app\n\nCMD node app.js\n', ""version: 3\nservices:\n  backend:\n    build: .\n    image: local-development\n    volumes:\n      - .:/app\n      - /app/node_modules\n    command: ['nodemon', 'app.js']\n""]"
949,8834,8723,CC BY-SA 4.0,2019-08-07T06:53:44.987,"<p>The fact that all the code is in a single repository doesn't mean that all the code is changing every time a commit is pushed. I would first make the ""pathways"" in the code explicit. E.g. perhaps you have a few subdirectories:</p>

<pre><code>- App1/
  - Docs/
  - Code/
  - Tests/
  - Makefile
- App2/
  - Docs/
  - Code/
  - Tests/
  - Makefile
</code></pre>

<p>Assuming that App1 is independent from App2, you could trigger it's build by checking if anything in that directory changed (see <a href=""https://stackoverflow.com/questions/424071/how-to-list-all-the-files-in-a-commit"">https://stackoverflow.com/questions/424071/how-to-list-all-the-files-in-a-commit</a>).</p>

<p>Most continuous integration tools have a git plugin or native feature that allows you to filter on a path. If you were using Jenkins, you could set up a few jobs, each with the included region to be be the pathway that should be triggered -- so, <em>e.g.</em> changes to <code>App1/*</code> would trigger <code>jobs/app1/</code> which executes <code>make -f App1/Makefile</code> or similar.</p>

<p>The trick then to maintaining this project is really in the Makefiles, or other build tool of your choice. You would write the dependencies in there.</p>

<p>You could also have a single global Makefile and use the <code>git diff-tree</code> trick in the question mentioned above:</p>

<pre><code>if grep -q App1 `git diff-tree --no-commit-id --name-only -r &lt;commit&gt;` ; then 
  # trigger pipeline App1
  cd App1
  make build
  make test
  make publish
fi
</code></pre>
",354,2019-08-07T06:53:44.987,"['- App1/\n  - Docs/\n  - Code/\n  - Tests/\n  - Makefile\n- App2/\n  - Docs/\n  - Code/\n  - Tests/\n  - Makefile\n', 'if grep -q App1 `git diff-tree --no-commit-id --name-only -r <commit>` ; then \n  # trigger pipeline App1\n  cd App1\n  make build\n  make test\n  make publish\nfi\n']"
950,8845,8840,CC BY-SA 4.0,2019-08-08T10:10:40.057,"<p>Seems to be just an issue with a Python package.</p>

<pre><code>Traceback (most recent call last):
  File ""a.py"", line 1, in &lt;module&gt;
    import cv2
ImportError: No module named 'cv2'
</code></pre>

<p>Is a common Python error, basically it can't find the package cv2.</p>

<p>You could try and install OpenCV through pip instead of installing through apt get.
Something could be up with dependancies that you may have missed.</p>

<pre><code>RUN pip3 install opencv-python 
</code></pre>
",13023,2019-08-08T10:10:40.057,"['Traceback (most recent call last):\n  File ""a.py"", line 1, in <module>\n    import cv2\nImportError: No module named \'cv2\'\n', 'RUN pip3 install opencv-python \n']"
951,8866,8855,CC BY-SA 4.0,2019-08-10T23:01:18.277,"<p>Your statements look ok. If I create a test case from the sparse info you provided and what I can observe when gathering facts from my own hosts, I can detect old/recent distributions correctly using your conditions. See my example below.</p>

<p>I suggest you double check the data gathered from your host to understand why it doesn't match. The easiest way for that: from the same host your use to launch your playbook, run</p>

<pre><code>ansible -i path/to/your_inventory.ini your_target_group_name -m setup -a ""filter=ansible_distribution*""
</code></pre>

<p>Here is the <code>test.yml</code> playbook I wrote to test your (known-so-far) values and your conditions</p>

<pre><code>---
- name: Statements for checking old/recent distribs
  hosts: localhost
  gather_facts: false

  vars:
    os_list:
      - ansible_distribution: ""Amazon""
        ansible_distribution_version: ""(Karoo)""
        ansible_distribution_major_version: ""(Karoo)""
      - ansible_distribution: ""Amazon""
        ansible_distribution_version: ""2018.03""
        ansible_distribution_major_version: ""2018""
      - ansible_distribution: ""RedHat""
        ansible_distribution_version: ""6.x""
        ansible_distribution_major_version: ""6""
      - ansible_distribution: ""RedHat""
        ansible_distribution_version: ""7.x""
        ansible_distribution_major_version: ""7""

  tasks:

    - name: Check conditions for recent distribs
      debug:
        msg: ""This is a recent distrib""
      loop: ""{{ os_list }}""
      loop_control:
        label: ""{{ item.ansible_distribution }}-{{ item.ansible_distribution_version }}""
      when: (
              item.ansible_distribution == ""Amazon""
              and
              item.ansible_distribution_version == ""(Karoo)""
            )
            or
            (
              item.ansible_distribution == ""RedHat""
              and
              item.ansible_distribution_major_version == ""7""
            )

    - name: Check conditions for old distribs
      debug:
        msg: ""This is an old distrib""
      loop: ""{{ os_list }}""
      loop_control:
        label: ""{{ item.ansible_distribution }}-{{ item.ansible_distribution_version }}""
      when: (
              item.ansible_distribution == ""Amazon""
              and
              item.ansible_distribution_version == ""2018.03""
            )
            or
            (
              item.ansible_distribution == ""RedHat""
              and
              item.ansible_distribution_major_version == ""6""
            )
</code></pre>

<p>And the result</p>

<pre><code>PLAY [Statements for checking old/recent distribs] ************************************************************************************************************************************************************************

TASK [Check conditions for recent distribs] *******************************************************************************************************************************************************************************
ok: [localhost] =&gt; (item=Amazon-(Karoo)) =&gt; {
    ""msg"": ""This is a recent distrib""
}
skipping: [localhost] =&gt; (item=Amazon-2018.03) 
skipping: [localhost] =&gt; (item=RedHat-6.x) 
ok: [localhost] =&gt; (item=RedHat-7.x) =&gt; {
    ""msg"": ""This is a recent distrib""
}

TASK [Check conditions for old distribs] **********************************************************************************************************************************************************************************
skipping: [localhost] =&gt; (item=Amazon-(Karoo)) 
ok: [localhost] =&gt; (item=Amazon-2018.03) =&gt; {
    ""msg"": ""This is an old distrib""
}
ok: [localhost] =&gt; (item=RedHat-6.x) =&gt; {
    ""msg"": ""This is an old distrib""
}
skipping: [localhost] =&gt; (item=RedHat-7.x) 

PLAY RECAP ****************************************************************************************************************************************************************************************************************
localhost                  : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
</code></pre>

<p>As you can see it does the job as expected. So either your data is not gathered correctly or your check the wrong values.</p>

<p><strong>Note</strong>: When @Vladimir Botka asks for an MCVE in the comments, this is a typical example.</p>
",13111,2019-08-10T23:01:18.277,"['ansible -i path/to/your_inventory.ini your_target_group_name -m setup -a ""filter=ansible_distribution*""\n', '---\n- name: Statements for checking old/recent distribs\n  hosts: localhost\n  gather_facts: false\n\n  vars:\n    os_list:\n      - ansible_distribution: ""Amazon""\n        ansible_distribution_version: ""(Karoo)""\n        ansible_distribution_major_version: ""(Karoo)""\n      - ansible_distribution: ""Amazon""\n        ansible_distribution_version: ""2018.03""\n        ansible_distribution_major_version: ""2018""\n      - ansible_distribution: ""RedHat""\n        ansible_distribution_version: ""6.x""\n        ansible_distribution_major_version: ""6""\n      - ansible_distribution: ""RedHat""\n        ansible_distribution_version: ""7.x""\n        ansible_distribution_major_version: ""7""\n\n  tasks:\n\n    - name: Check conditions for recent distribs\n      debug:\n        msg: ""This is a recent distrib""\n      loop: ""{{ os_list }}""\n      loop_control:\n        label: ""{{ item.ansible_distribution }}-{{ item.ansible_distribution_version }}""\n      when: (\n              item.ansible_distribution == ""Amazon""\n              and\n              item.ansible_distribution_version == ""(Karoo)""\n            )\n            or\n            (\n              item.ansible_distribution == ""RedHat""\n              and\n              item.ansible_distribution_major_version == ""7""\n            )\n\n    - name: Check conditions for old distribs\n      debug:\n        msg: ""This is an old distrib""\n      loop: ""{{ os_list }}""\n      loop_control:\n        label: ""{{ item.ansible_distribution }}-{{ item.ansible_distribution_version }}""\n      when: (\n              item.ansible_distribution == ""Amazon""\n              and\n              item.ansible_distribution_version == ""2018.03""\n            )\n            or\n            (\n              item.ansible_distribution == ""RedHat""\n              and\n              item.ansible_distribution_major_version == ""6""\n            )\n', 'PLAY [Statements for checking old/recent distribs] ************************************************************************************************************************************************************************\n\nTASK [Check conditions for recent distribs] *******************************************************************************************************************************************************************************\nok: [localhost] => (item=Amazon-(Karoo)) => {\n    ""msg"": ""This is a recent distrib""\n}\nskipping: [localhost] => (item=Amazon-2018.03) \nskipping: [localhost] => (item=RedHat-6.x) \nok: [localhost] => (item=RedHat-7.x) => {\n    ""msg"": ""This is a recent distrib""\n}\n\nTASK [Check conditions for old distribs] **********************************************************************************************************************************************************************************\nskipping: [localhost] => (item=Amazon-(Karoo)) \nok: [localhost] => (item=Amazon-2018.03) => {\n    ""msg"": ""This is an old distrib""\n}\nok: [localhost] => (item=RedHat-6.x) => {\n    ""msg"": ""This is an old distrib""\n}\nskipping: [localhost] => (item=RedHat-7.x) \n\nPLAY RECAP ****************************************************************************************************************************************************************************************************************\nlocalhost                  : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n']"
952,8875,3073,CC BY-SA 4.0,2019-08-12T10:06:36.227,"<p>Be aware, that dynamic build steps could cause some problems in some build steps, e.g. when you call an other job:</p>

<pre><code>pipeline {
    stages {
        stage('Test') {
            steps {
                script {
                    def tests = [:]
                    for (f in findFiles(glob: '**/html/*.html')) {
                        // Create temp variable, otherwise the name will be the last value of the for loop
                        def name = f
                        tests[""${name}""] = {
                            build job: ""${name}""
                        }
                    }
                    parallel tests
                }
            }
        }       
    }
}
</code></pre>
",16508,2019-08-12T10:06:36.227,"['pipeline {\n    stages {\n        stage(\'Test\') {\n            steps {\n                script {\n                    def tests = [:]\n                    for (f in findFiles(glob: \'**/html/*.html\')) {\n                        // Create temp variable, otherwise the name will be the last value of the for loop\n                        def name = f\n                        tests[""${name}""] = {\n                            build job: ""${name}""\n                        }\n                    }\n                    parallel tests\n                }\n            }\n        }       \n    }\n}\n']"
953,8879,8865,CC BY-SA 4.0,2019-08-12T14:07:21.070,"<p>This is a backdoor type script attempting to get information about global php configuration settings.</p>

<p><code>$alphabet</code> holds (in obfuscated form) the string ""base64_decode"". <code>base64_decode</code> is a function to unmangle the long base64 encoded $string value into this-:</p>

<pre><code>global auth_pass,$color,$default_action,$default_use_ajax,$default_charset,$sort;
global $cwd,$os,$safe_mode, $in;
</code></pre>

<p>A function with the above code is then created (reading the characters in <code>""noi"".""tcnuf"".""_eta"".""erc""</code> spells create_function) and then executed.</p>

<h2>NOTE</h2>

<p>PHP stores lots of useful information in $GLOBALS array, including HTTP requests, environmental settings and server settings. So files such as this are used to extract information from your system and from your user's posts.</p>
",16511,2019-08-12T16:04:24.757,"['global auth_pass,$color,$default_action,$default_use_ajax,$default_charset,$sort;\nglobal $cwd,$os,$safe_mode, $in;\n']"
954,8904,8901,CC BY-SA 4.0,2019-08-14T18:15:47.467,"<p>found the issue,  instead of 'dc' need to use 'deploy'</p>

<pre><code>oc scale deploy name_of_deployment--replicas=2
</code></pre>
",16571,2019-08-14T18:15:47.467,['oc scale deploy name_of_deployment--replicas=2\n']
955,8912,2191,CC BY-SA 4.0,2019-08-16T09:04:52.857,"<p>For the record, The following snippet to be pasted into the console also does the job :</p>

<pre class=""lang-java prettyprint-override""><code>def creds = com.cloudbees.plugins.credentials.CredentialsProvider.lookupCredentials(
    com.cloudbees.plugins.credentials.common.StandardUsernameCredentials.class,
    Jenkins.instance,
    null,
    null
)

for(c in creds) {
  if(c instanceof com.cloudbees.jenkins.plugins.sshcredentials.impl.BasicSSHUserPrivateKey){
    println(String.format(""id=%s  desc=%s key=%s\n"", c.id, c.description, c.privateKeySource.getPrivateKeys()))
  }
  if (c instanceof com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl){
    println(String.format(""id=%s  desc=%s user=%s pass=%s\n"", c.id, c.description, c.username, c.password))
  }
}
</code></pre>
",16556,2019-08-16T09:04:52.857,"['def creds = com.cloudbees.plugins.credentials.CredentialsProvider.lookupCredentials(\n    com.cloudbees.plugins.credentials.common.StandardUsernameCredentials.class,\n    Jenkins.instance,\n    null,\n    null\n)\n\nfor(c in creds) {\n  if(c instanceof com.cloudbees.jenkins.plugins.sshcredentials.impl.BasicSSHUserPrivateKey){\n    println(String.format(""id=%s  desc=%s key=%s\\n"", c.id, c.description, c.privateKeySource.getPrivateKeys()))\n  }\n  if (c instanceof com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl){\n    println(String.format(""id=%s  desc=%s user=%s pass=%s\\n"", c.id, c.description, c.username, c.password))\n  }\n}\n']"
956,8916,8906,CC BY-SA 4.0,2019-08-16T17:50:26.833,"<p>Been there done that... 
Try prompt ']' and upgrade ansible to the version 2.8.1</p>

<pre><code>    ""stdout_lines"": [
        [
            ""Running command on switch 1"", 
            ""Cleaning up unnecessary package files"", 
            ""No path specified, will use booted path flash:packages.conf"", 
            ""Cleaning flash:"", 
            ""  Scanning boot directory for packages ... done."", 
            ""  Preparing packages list to delete ... "", 
            ""    cat3k_caa-guestshell.16.03.07.SPA.pkg"", 
            ""      File is in use, will not delete."", 
            ""    cat3k_caa-rpbase.16.03.07.SPA.pkg"", 
            ""      File is in use, will not delete."", 
            ""    cat3k_caa-rpcore.16.03.07.SPA.pkg"", 
            ""      File is in use, will not delete."", 
            ""    cat3k_caa-srdriver.16.03.07.SPA.pkg"", 
            ""      File is in use, will not delete."", 
            ""    cat3k_caa-wcm.16.03.07.SPA.pkg"", 
            ""      File is in use, will not delete."", 
            ""    cat3k_caa-webui.16.03.07.SPA.pkg"", 
            ""      File is in use, will not delete."", 
            ""    packages.conf"", 
            ""      File is in use, will not delete."", 
            ""  done."", 
            ""  "", 
            ""The following files will be deleted:"", 
            ""[1]:"", 
            ""/flash/cat3k_caa-guestshell.16.03.06.SPA.pkg"", 
            ""/flash/cat3k_caa-rpbase.16.03.06.SPA.pkg"", 
            ""/flash/cat3k_caa-rpcore.16.03.06.SPA.pkg"", 
            ""/flash/cat3k_caa-srdriver.16.03.06.SPA.pkg"", 
            ""/flash/cat3k_caa-universalk9.16.03.07.SPA.conf"", 
            ""/flash/cat3k_caa-wcm.16.03.06.SPA.pkg"", 
            ""/flash/cat3k_caa-webui.16.03.06.SPA.pkg"", 
            ""/flash/packages.conf.00-"", 
            """", 
            ""Do you want to proceed? [y/n]y"", 
            """", 
            ""[1]:"", 
            ""Deleting file flash:cat3k_caa-guestshell.16.03.06.SPA.pkg ... done."", 
            ""Deleting file flash:cat3k_caa-rpbase.16.03.06.SPA.pkg ... done."", 
            ""Deleting file flash:cat3k_caa-rpcore.16.03.06.SPA.pkg ... done."", 
            ""Deleting file flash:cat3k_caa-srdriver.16.03.06.SPA.pkg ... done."", 
            ""Deleting file flash:cat3k_caa-universalk9.16.03.07.SPA.conf ... done."", 
            ""Deleting file flash:cat3k_caa-wcm.16.03.06.SPA.pkg ... done."", 
            ""Deleting file flash:cat3k_caa-webui.16.03.06.SPA.pkg ... done."", 
            ""Deleting file flash:packages.conf.00- ... done."", 
            ""SUCCESS: Files deleted.""
        ]
    ]
</code></pre>
",16605,2019-08-16T17:56:47.810,"['    ""stdout_lines"": [\n        [\n            ""Running command on switch 1"", \n            ""Cleaning up unnecessary package files"", \n            ""No path specified, will use booted path flash:packages.conf"", \n            ""Cleaning flash:"", \n            ""  Scanning boot directory for packages ... done."", \n            ""  Preparing packages list to delete ... "", \n            ""    cat3k_caa-guestshell.16.03.07.SPA.pkg"", \n            ""      File is in use, will not delete."", \n            ""    cat3k_caa-rpbase.16.03.07.SPA.pkg"", \n            ""      File is in use, will not delete."", \n            ""    cat3k_caa-rpcore.16.03.07.SPA.pkg"", \n            ""      File is in use, will not delete."", \n            ""    cat3k_caa-srdriver.16.03.07.SPA.pkg"", \n            ""      File is in use, will not delete."", \n            ""    cat3k_caa-wcm.16.03.07.SPA.pkg"", \n            ""      File is in use, will not delete."", \n            ""    cat3k_caa-webui.16.03.07.SPA.pkg"", \n            ""      File is in use, will not delete."", \n            ""    packages.conf"", \n            ""      File is in use, will not delete."", \n            ""  done."", \n            ""  "", \n            ""The following files will be deleted:"", \n            ""[1]:"", \n            ""/flash/cat3k_caa-guestshell.16.03.06.SPA.pkg"", \n            ""/flash/cat3k_caa-rpbase.16.03.06.SPA.pkg"", \n            ""/flash/cat3k_caa-rpcore.16.03.06.SPA.pkg"", \n            ""/flash/cat3k_caa-srdriver.16.03.06.SPA.pkg"", \n            ""/flash/cat3k_caa-universalk9.16.03.07.SPA.conf"", \n            ""/flash/cat3k_caa-wcm.16.03.06.SPA.pkg"", \n            ""/flash/cat3k_caa-webui.16.03.06.SPA.pkg"", \n            ""/flash/packages.conf.00-"", \n            """", \n            ""Do you want to proceed? [y/n]y"", \n            """", \n            ""[1]:"", \n            ""Deleting file flash:cat3k_caa-guestshell.16.03.06.SPA.pkg ... done."", \n            ""Deleting file flash:cat3k_caa-rpbase.16.03.06.SPA.pkg ... done."", \n            ""Deleting file flash:cat3k_caa-rpcore.16.03.06.SPA.pkg ... done."", \n            ""Deleting file flash:cat3k_caa-srdriver.16.03.06.SPA.pkg ... done."", \n            ""Deleting file flash:cat3k_caa-universalk9.16.03.07.SPA.conf ... done."", \n            ""Deleting file flash:cat3k_caa-wcm.16.03.06.SPA.pkg ... done."", \n            ""Deleting file flash:cat3k_caa-webui.16.03.06.SPA.pkg ... done."", \n            ""Deleting file flash:packages.conf.00- ... done."", \n            ""SUCCESS: Files deleted.""\n        ]\n    ]\n']"
957,8922,1390,CC BY-SA 4.0,2019-08-17T14:46:20.723,"<p>You need to remove dash in front of variable. Use syntax like that:</p>

<pre><code>   environment:
     NODE_CONFIG: '{""DATABASE_URL"":""http://db:5984""}'
</code></pre>
",16623,2019-08-17T14:46:20.723,"['   environment:\n     NODE_CONFIG: \'{""DATABASE_URL"":""http://db:5984""}\'\n']"
958,8934,8928,CC BY-SA 4.0,2019-08-20T10:52:30.793,"<p>I am using AzureDevOps and the trick we use when naming containers is to add build number to the label</p>

<pre><code>namespace/application:branch-name-bulidNumber
</code></pre>

<p>So in your case, you could try <a href=""https://docs.gitlab.com/ee/ci/variables/predefined_variables.html#predefined-environment-variables-reference"" rel=""nofollow noreferrer"">gitlab variable</a> <code>CI_CONCURRENT_PROJECT_ID</code></p>

<h1>After comment</h1>

<p>for images clean-up you can use:</p>

<pre><code>  docker image prune --all --filter until=48h 
</code></pre>

<p>As docker system prune and docker image prune have the until filter. So docker image prune --all --filter <strong>until=48h</strong> would remove all (not just dangling) images that were created more than 48 hours ago. Hopefully that helps. <a href=""https://forums.docker.com/t/simple-script-needed-to-delete-all-docker-images-over-4-weeks-old/28558/7"" rel=""nofollow noreferrer"">source here</a></p>
",16316,2019-08-20T11:40:06.240,"['namespace/application:branch-name-bulidNumber\n', '  docker image prune --all --filter until=48h \n']"
959,8939,8937,CC BY-SA 4.0,2019-08-20T17:28:42.270,"<p>It looks like your underlying goal here is to retrieve the full set of attributes for each of your subnets that are marked as <code>Tier = public</code>. Here's a different way to do that using features from Terraform 0.12.6:</p>

<pre><code>data ""aws_subnet_ids"" ""public"" {
  vpc_id = data.aws_vpc.vpc.id

  tags = {
    Tier = ""public""
  }
}

data ""aws_subnet"" ""public"" {  
  for_each = data.aws_subnet_ids.public.ids

  id = each.value
}
</code></pre>

<p>With the above, you should find that <code>data.aws_subnet.public</code> is a map from subnet id to the attributes of that particular subnet.</p>

<hr>

<p>The reason for the error in your case is that you used <code>count.index</code> but didn't set the <code>count</code> argument, and so there is no count index to return.</p>

<p>The <code>count</code>-based equivalent of the above, which is more similar to your original example, would be this:</p>

<pre><code>data ""aws_subnet_ids"" ""public"" {
  vpc_id = data.aws_vpc.vpc.id

  tags = {
    Tier = ""public""
  }
}

data ""aws_subnet"" ""public"" {  
  count = length(data.aws_subnet_ids.public.ids)

  id = sort(data.aws_subnet_ids.public.ids)[count.index]
}
</code></pre>

<p>The result of this is very similar to the <code>for_each</code>-based example I gave above, but with one significant difference: in this case <code>data.aws_subnet.public</code> will be a <em>list</em> of subnet objects, ordered by the lexical ordering of their subnet ids. That will usually make the result harder to use elsewhere in the configuration, so I'd suggest using the <code>for_each</code> approach unless there's a specific reason why you need a list.</p>

<p>(If you use a map and then later find that you need a list in a <em>specific context</em>, you can always use <code>values(data.aws_subnet.public)</code> to take the values from the map, in the same lexical order.)</p>
",2463,2019-08-20T17:55:09.553,"['data ""aws_subnet_ids"" ""public"" {\n  vpc_id = data.aws_vpc.vpc.id\n\n  tags = {\n    Tier = ""public""\n  }\n}\n\ndata ""aws_subnet"" ""public"" {  \n  for_each = data.aws_subnet_ids.public.ids\n\n  id = each.value\n}\n', 'data ""aws_subnet_ids"" ""public"" {\n  vpc_id = data.aws_vpc.vpc.id\n\n  tags = {\n    Tier = ""public""\n  }\n}\n\ndata ""aws_subnet"" ""public"" {  \n  count = length(data.aws_subnet_ids.public.ids)\n\n  id = sort(data.aws_subnet_ids.public.ids)[count.index]\n}\n']"
960,8947,8944,CC BY-SA 4.0,2019-08-21T12:28:45.103,"<p>CORS is not allowing subdomains, so you need to specify them in your server configuration.</p>

<p>If you are using NGINX (or you could use it as a proxy and solve your problem) by providing dynamic cors header response</p>

<pre><code>
server {

    root /path/to/your/stuff;

    index index.html index.htm;

     set $cors """";

    if ($http_origin ~* (.*\.yoursweetdomain.com)) {
        set $cors ""true"";
    }

    server_name yoursweetdomain.com;

    location / {

        if ($cors = ""true"") {
            add_header 'Access-Control-Allow-Origin' ""$http_origin"";
            add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, DELETE, PUT';
            add_header 'Access-Control-Allow-Credentials' 'true';
            add_header 'Access-Control-Allow-Headers' 'User-Agent,Keep-Alive,Content-Type';
        }


        if ($request_method = OPTIONS) {
            return 204;
        }

    }
}

</code></pre>

<p><a href=""http://rustyrazorblade.com/post/2013/2013-10-31-cors-with-wildcard-domains-and-nginx/"" rel=""nofollow noreferrer"">Source here</a></p>
",16316,2019-08-21T12:28:45.103,"['\nserver {\n\n    root /path/to/your/stuff;\n\n    index index.html index.htm;\n\n     set $cors """";\n\n    if ($http_origin ~* (.*\\.yoursweetdomain.com)) {\n        set $cors ""true"";\n    }\n\n    server_name yoursweetdomain.com;\n\n    location / {\n\n        if ($cors = ""true"") {\n            add_header \'Access-Control-Allow-Origin\' ""$http_origin"";\n            add_header \'Access-Control-Allow-Methods\' \'GET, POST, OPTIONS, DELETE, PUT\';\n            add_header \'Access-Control-Allow-Credentials\' \'true\';\n            add_header \'Access-Control-Allow-Headers\' \'User-Agent,Keep-Alive,Content-Type\';\n        }\n\n\n        if ($request_method = OPTIONS) {\n            return 204;\n        }\n\n    }\n}\n\n']"
961,8948,8936,CC BY-SA 4.0,2019-08-21T13:16:26.913,"<p>It's possible and pretty simple to do this with Jenkins. Here is a sample pipeline:</p>

<pre class=""lang-java prettyprint-override""><code>pipeline {
    agent any

    triggers {
        cron('*/5 * * * *')
    }

    stages {
        stage('Health checker') {
            steps {
                sh 'curl https://mywebsite.com'
            }

            post {
                failure {
                    mail to: 'notify-list@example.com',
                        from: 'jenkins@example.com',
                        subject: ""${env.JOB_NAME} - Failed"",
                        body: ""Job Failed""
                }
            }
        }
    }
}
</code></pre>
",16683,2019-08-22T12:44:28.083,"['pipeline {\n    agent any\n\n    triggers {\n        cron(\'*/5 * * * *\')\n    }\n\n    stages {\n        stage(\'Health checker\') {\n            steps {\n                sh \'curl https://mywebsite.com\'\n            }\n\n            post {\n                failure {\n                    mail to: \'notify-list@example.com\',\n                        from: \'jenkins@example.com\',\n                        subject: ""${env.JOB_NAME} - Failed"",\n                        body: ""Job Failed""\n                }\n            }\n        }\n    }\n}\n']"
962,8957,8956,CC BY-SA 4.0,2019-08-22T01:31:09.487,"<p>EDIT:
It might have a chance for me to misread your question at the first time, so let me add another one. </p>

<p>If you meant by Jenkinsfile as you have a manual parameter input in Jenkinsfile for Multibranch or Github Org pipeline, then probably bad idea.</p>

<p>Those kind of jobs should run with predefined parameters or take them on-the-fly like manipulating some environment variables without user input.</p>

<p>You can simply make another pipeline job for manual trigger if the predefined parameters can't cover all the case you need.</p>

<p>And for run function, it looks like <code>build job</code> is what you are looking for.</p>

<p><a href=""https://jenkins.io/doc/pipeline/steps/pipeline-build-step/#-build-%20build%20a%20job"" rel=""nofollow noreferrer"">https://jenkins.io/doc/pipeline/steps/pipeline-build-step/#-build-%20build%20a%20job</a></p>

<pre><code>build job: 'Another job in same Jenkins server', parameters: [string(name: 'param1', value: ${new_value})]
</code></pre>

<h2>--------------------------------------</h2>

<p>Are you sure the parameter input is waiting for slave containers?
or do you use some special choice plugins for build parameter?</p>

<p>I think a job is even not starting until a user fills out the parameters and hit the build button in Jenkins UI - so no container required until then.
We had same k8s slaves, but never had that issue.</p>

<p>(But some parameter plugins might need some pre process..)</p>
",16695,2019-08-22T01:54:32.993,"[""build job: 'Another job in same Jenkins server', parameters: [string(name: 'param1', value: ${new_value})]\n""]"
963,8960,8958,CC BY-SA 4.0,2019-08-22T08:30:21.703,"<p>This pipeline will run each day at 1 AM. It'll restart if the build fails.</p>

<pre class=""lang-java prettyprint-override""><code>pipeline {
    agent any

    triggers {
        cron('0 1 * * *')
    }

    stages {
        stage ('Build') {
            when {
                expression {
                    // When last build has failed
                    !hudson.model.Result.SUCCESS.equals(currentBuild.rawBuild.getPreviousBuild()?.getResult()) == true
                }
            }

            steps {
                sh ""./myjob.sh""
            }

            post {
                failure {
                    // If the current job has failed, trigger it without
                    // waiting.
                    build job: ""${JOB_NAME}"", wait: false
                }
            }
        }
    }
}
</code></pre>

<p>If you want to wait before to re-trigger the job, you can add the option <code>quietPeriod: (seconds)</code> to the <code>build</code> step (<a href=""https://jenkins.io/doc/pipeline/steps/pipeline-build-step/"" rel=""noreferrer"">https://jenkins.io/doc/pipeline/steps/pipeline-build-step/</a>).</p>

<p>You might have to add these methods to the scriptApproval:</p>

<p><a href=""https://i.stack.imgur.com/Wi1Ke.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/Wi1Ke.png"" alt=""enter image description here""></a></p>
",16683,2019-08-22T12:53:59.227,"['pipeline {\n    agent any\n\n    triggers {\n        cron(\'0 1 * * *\')\n    }\n\n    stages {\n        stage (\'Build\') {\n            when {\n                expression {\n                    // When last build has failed\n                    !hudson.model.Result.SUCCESS.equals(currentBuild.rawBuild.getPreviousBuild()?.getResult()) == true\n                }\n            }\n\n            steps {\n                sh ""./myjob.sh""\n            }\n\n            post {\n                failure {\n                    // If the current job has failed, trigger it without\n                    // waiting.\n                    build job: ""${JOB_NAME}"", wait: false\n                }\n            }\n        }\n    }\n}\n']"
964,8969,5061,CC BY-SA 4.0,2019-08-23T05:27:41.777,"<p>According to the <a href=""https://jenkins.io/doc/book/pipeline/syntax/#when"" rel=""nofollow noreferrer"">documentation</a>, the <code>when</code> directive is only allowed inside a <code>stage</code>. You have to use the <code>script</code> directive if you want to use conditional statements:</p>

<pre class=""lang-java prettyprint-override""><code>post {
  always {
    script {
      if (DeleteStack == 'true') {
        // Destroy what you want !
      }
    }
  }
}
</code></pre>
",16683,2019-08-23T05:27:41.777,"[""post {\n  always {\n    script {\n      if (DeleteStack == 'true') {\n        // Destroy what you want !\n      }\n    }\n  }\n}\n""]"
965,8971,8958,CC BY-SA 4.0,2019-08-23T07:10:48.370,"<p>First of all, a job should always be green on the first run in my opinion. I know that it can be very difficult, but every issue should be solved. That having said, we have also some jobs that get green after 5 retries. It are selenium tests that are very brittle and we do not get the time to fix them. Once a <code>retry</code> was added the builds are green for a couple of months now:</p>

<p><a href=""https://jenkins.io/doc/book/pipeline/syntax/"" rel=""nofollow noreferrer"">https://jenkins.io/doc/book/pipeline/syntax/</a></p>

<blockquote>
  <p>retry</p>

<pre><code>On failure, retry the entire Pipeline the specified number of times. For
example: options { retry(3) }
</code></pre>
</blockquote>

<p>I prefer a <code>retry</code> as it will only restart the job if there is a failure over <code>cron</code> as it does not check previous failures.</p>
",210,2019-08-23T07:10:48.370,"['On failure, retry the entire Pipeline the specified number of times. For\nexample: options { retry(3) }\n']"
966,8980,8977,CC BY-SA 4.0,2019-08-23T17:54:57.213,"<p>There is a clue in your error message, but it's only helpful if you know what you're looking for:</p>

<pre><code>    | module.mongodb.instance_names is tuple with 1 element
    | module.mongodb.private_ip is list of string with 1 element
</code></pre>

<p>Your declaration of the <code>instance_names</code> output includes this expression:</p>

<pre><code>[""${data.template_file.instance_tags_name.*.rendered}""]
</code></pre>

<p>The <code>data.template_file.instance_tags_name.*.rendered</code> part of this returns a list of strings, and then the <code>[ ... ]</code> around it then wraps an extra list (or rather, tuple) around it, creating a single-element tuple containing a list of strings. That's why the tuple contains only one element, rather than having an element for each of your <code>count</code> instances.</p>

<p>This situation is what the upgrade guide discusses under <a href=""https://www.terraform.io/upgrade-guides/0-12.html#referring-to-list-variables"" rel=""nofollow noreferrer"">Referring to List Variables</a>, and that documentation includes some more background information on why this previously worked in 0.11 and why the change is required now.</p>

<p>To fix this, you should refer to just the splat expression alone, producing the flat list of strings that your <code>formatlist</code> call is expecting:</p>

<pre><code>output ""instance_names"" {
  value = data.template_file.instance_tags_name.*.rendered
}
</code></pre>

<p>The automatic configuration upgrade tool described in <a href=""https://www.terraform.io/upgrade-guides/0-12.html"" rel=""nofollow noreferrer"">the upgrade guide</a> can make this change automatically in some cases, so I'd recommend using that as a starting point for your 0.12 upgrade process. It isn't able to fix everything, but it will do a lot of the straightforward rewriting work for you and will emit warnings about some more complex situations it's unable to handle.</p>
",2463,2019-08-23T17:54:57.213,"['    | module.mongodb.instance_names is tuple with 1 element\n    | module.mongodb.private_ip is list of string with 1 element\n', '[""${data.template_file.instance_tags_name.*.rendered}""]\n', 'output ""instance_names"" {\n  value = data.template_file.instance_tags_name.*.rendered\n}\n']"
967,8984,4292,CC BY-SA 4.0,2019-08-24T02:03:55.667,"<p>Using terraform module is preferred, but if you really have to run terraform apply against a single file, I made this bash script to generate terraform apply command against all targets and modules in one file:</p>

<pre class=""lang-sh prettyprint-override""><code>#!/usr/bin/env bash
if [[ -z ""$@"" ]]; then
  echo ""Missing file input arguments""
  exit 1
fi

echo ""terraform apply \\""
for FILE in ""$@""
do
  RESOURCE=$(sed -n 's/resource ""\([^""]*\)"" ""\([^""]*\)"".*/-target=\1.\2 \\/gp' $FILE)
  MODULE=$(sed -n 's/module ""\([^""]*\)"".*/-target=module.\1 \\/gp' $FILE)
  if [[ -z ""$RESOURCE"" ]] &amp;&amp; [[ -z ""$MODULE"" ]]; then
    echo ""Cannot detect terraform resource and module in $FILE""
    exit 1
  fi

  if [[ ! -z ""$RESOURCE"" ]]; then
    echo -e $""$RESOURCE""
  fi
  if [[ ! -z ""$MODULE"" ]]; then
    echo -e $""$MODULE""
  fi
done
echo ""-refresh=true""
</code></pre>

<p>I'm not really a bash expert, but it was tested to work on Mac.</p>

<p>EDIT: The sed command assumes that the resources and modules are formatted nicely according to <code>terraform fmt</code> like so:</p>

<pre class=""lang-sh prettyprint-override""><code>resource ""aws_eip"" ""my_public_ip"" {
}

resource ""aws_instance"" ""my_server"" {
}

module ""my_module"" {
}
</code></pre>
",16731,2020-04-03T14:00:12.217,"['#!/usr/bin/env bash\nif [[ -z ""$@"" ]]; then\n  echo ""Missing file input arguments""\n  exit 1\nfi\n\necho ""terraform apply \\\\""\nfor FILE in ""$@""\ndo\n  RESOURCE=$(sed -n \'s/resource ""\\([^""]*\\)"" ""\\([^""]*\\)"".*/-target=\\1.\\2 \\\\/gp\' $FILE)\n  MODULE=$(sed -n \'s/module ""\\([^""]*\\)"".*/-target=module.\\1 \\\\/gp\' $FILE)\n  if [[ -z ""$RESOURCE"" ]] && [[ -z ""$MODULE"" ]]; then\n    echo ""Cannot detect terraform resource and module in $FILE""\n    exit 1\n  fi\n\n  if [[ ! -z ""$RESOURCE"" ]]; then\n    echo -e $""$RESOURCE""\n  fi\n  if [[ ! -z ""$MODULE"" ]]; then\n    echo -e $""$MODULE""\n  fi\ndone\necho ""-refresh=true""\n', 'resource ""aws_eip"" ""my_public_ip"" {\n}\n\nresource ""aws_instance"" ""my_server"" {\n}\n\nmodule ""my_module"" {\n}\n']"
968,8999,8996,CC BY-SA 4.0,2019-08-26T12:17:24.440,"<p>I'd suggest that you first put some default values within the playbook (if you explicitly want your variables there, for the purpose of .. reducing interactivity/command line args lets say):</p>

<pre><code>- hosts: all
  vars:
    user: greatuser
    passa: greatpassword
</code></pre>

<p>Second, I'm pretty sure that <code>pass</code> is a reserved word somewhere, although I'm failing to find it in the <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html"" rel=""nofollow noreferrer"">documentation</a>. That's why I've changed your variable to <code>passa</code>. The final version of your playbook should look like this:</p>

<pre><code>- hosts: all
  vars:
     user: greatuser
     passa: greatpassword

  tasks:
     - name: Stop services
       shell: ""bash stopservices.sh""

     - name: Edit real hosts file
       shell: ""bash editrealmachinehosts.sh""

     - name: Create dirs and cloning
       command: python3 {{ user }} {{ passa }}
</code></pre>

<p>Note the way used to reference to the username and password variables in the third task - <code>{{ variable }}</code> instead of <code>variable</code>.</p>

<p>Execute your playbook with the following command:</p>

<pre><code>ansible-playbook createdeploy.yaml --extra-vars ""user=ras passa=ras"" -b --become-user=ras
</code></pre>

<p>As your target host is actually <code>localhost</code> (if I did understood you correctly), and since you're not showing your inventory file, I'd like to suggest that you might have to add <code>-c local</code> to the list of arguments of your <code>ansible-playbook</code> command. </p>
",775,2019-08-26T12:42:08.667,"['- hosts: all\n  vars:\n    user: greatuser\n    passa: greatpassword\n', '- hosts: all\n  vars:\n     user: greatuser\n     passa: greatpassword\n\n  tasks:\n     - name: Stop services\n       shell: ""bash stopservices.sh""\n\n     - name: Edit real hosts file\n       shell: ""bash editrealmachinehosts.sh""\n\n     - name: Create dirs and cloning\n       command: python3 {{ user }} {{ passa }}\n', 'ansible-playbook createdeploy.yaml --extra-vars ""user=ras passa=ras"" -b --become-user=ras\n']"
969,9004,9002,CC BY-SA 4.0,2019-08-26T16:43:21.097,"<p>Yes.  Just use ./ for you current directory that the Docker-compose file is in.  Docker-Compose does not allow you to use a context that is located above the compose file, so everything the compose file will use is below the folder with the .yml.  Your ""working directory"" for the compose file is just ""./"".  If you are trying to set a directory below that it would look something like: <pre><code>volumes:
  - ./DirectoryIWantToTarget:/tmp</code></pre></p>

<p>There's an example of this in the Docker-Compose documentation <a href=""https://docs.docker.com/compose/compose-file/#short-syntax-3"" rel=""noreferrer"">here</a>.  This approach makes the solution cross-platform as well.</p>
",15792,2019-08-26T16:43:21.097,['volumes:\n  - ./DirectoryIWantToTarget:/tmp']
970,9006,9002,CC BY-SA 4.0,2019-08-26T17:32:15.427,"<pre><code>PS C:\Users\gaius&gt; Write-Output $PSVersionTable.PSVersion

Major  Minor  Build  Revision
-----  -----  -----  --------
5      1      17763  592     



PS C:\Users\gaius&gt; Write-Output $pwd

Path          
----          
C:\Users\gaius
</code></pre>

<p>That appears to work as expected, what versions of things are you using?</p>

<p>Compare to Linux:</p>

<pre><code>gaius@klossy:~$ pwsh
PowerShell 6.2.2
Copyright (c) Microsoft Corporation. All rights reserved.

https://aka.ms/pscore6-docs
Type 'help' to get help.

PS /home/gaius&gt; echo $pwd

Path
----
/home/gaius

PS /home/gaius&gt; 
</code></pre>

<p>(<code>echo</code> is just an alias for <code>Write-Output</code>)</p>

<p>If you must have exact commonality between Windows and Linux there are a few solutions, Git comes with Bash for Windows, there's WSL, etc. </p>
",786,2019-08-26T18:41:14.023,"['PS C:\\Users\\gaius> Write-Output $PSVersionTable.PSVersion\n\nMajor  Minor  Build  Revision\n-----  -----  -----  --------\n5      1      17763  592     \n\n\n\nPS C:\\Users\\gaius> Write-Output $pwd\n\nPath          \n----          \nC:\\Users\\gaius\n', ""gaius@klossy:~$ pwsh\nPowerShell 6.2.2\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nhttps://aka.ms/pscore6-docs\nType 'help' to get help.\n\nPS /home/gaius> echo $pwd\n\nPath\n----\n/home/gaius\n\nPS /home/gaius> \n""]"
971,9018,9015,CC BY-SA 4.0,2019-08-27T13:06:27.453,"<p>The task which fails is this one:</p>

<pre><code> - name: replace hostname in config
   replace:
     path: /opt/agentd.conf
     regexp: #\s+Hostname\=
     replace: Hostname={{hname}}
     backup: yes
</code></pre>

<p>Try like this:</p>

<pre><code> - name: replace hostname in config
   replace:
     path: /opt/agentd.conf
     regexp: '#\s+Hostname\=.*$'
     replace: Hostname={{hname}}
     backup: yes
</code></pre>

<p>Note that if you don't add <code>.*$</code>, the task will only replace <code># Hostname=</code> and you will end up with a <code>Hostname=oldhostnamenewhostname</code>.</p>
",775,2019-08-27T13:06:27.453,"[' - name: replace hostname in config\n   replace:\n     path: /opt/agentd.conf\n     regexp: #\\s+Hostname\\=\n     replace: Hostname={{hname}}\n     backup: yes\n', "" - name: replace hostname in config\n   replace:\n     path: /opt/agentd.conf\n     regexp: '#\\s+Hostname\\=.*$'\n     replace: Hostname={{hname}}\n     backup: yes\n""]"
972,9022,9020,CC BY-SA 4.0,2019-08-27T16:39:08.490,"<p>You can use a custom build container image for your pipeline with Maven and all of your other dependencies. You will need to: </p>

<ol>
<li>Create a Dockerfile that installs Maven and all other dependencies that you have</li>
<li>Build the image and upload it to a custom Azure Container Registry</li>
<li>Modify your YAML pipeline file to reference the new build image</li>
</ol>

<p>Sample:</p>

<pre><code>resources:
   containers:
     - container: build_container
       image: demoxyz.azurecr.io/pipeline-build-image:latest
       endpoint: AzureCR
       options: '-v /usr/bin/docker:/usr/bin/docker -v /var/run/docker.sock:/var/run/docker.sock'
</code></pre>

<p>Here is an article that discusses the <a href=""https://yuriburger.net/2019/03/04/use-your-own-build-container-image-to-create-containerized-apps/"" rel=""nofollow noreferrer"">topic</a>. </p>
",4328,2019-08-27T16:39:08.490,"[""resources:\n   containers:\n     - container: build_container\n       image: demoxyz.azurecr.io/pipeline-build-image:latest\n       endpoint: AzureCR\n       options: '-v /usr/bin/docker:/usr/bin/docker -v /var/run/docker.sock:/var/run/docker.sock'\n""]"
973,9045,9043,CC BY-SA 4.0,2019-08-28T23:30:52.787,"<p>You can make changes in <code>Main.tf</code> as specified below:</p>

<pre><code>resource ""aws_s3_bucket"" ""b"" {
  count      = ""${length(var.domain_name)}""
  bucket     = ""${element(var.domain_name, count.index)}""
  acl        = ""public-read""
  policy     = ""${file(""bucket-policy.json"")}""

  website {
    index_document = ""index.html""
    error_document = ""error.html""

    routing_rules = &lt;&lt;EOF
EOF
  }
}
</code></pre>
",12138,2019-08-28T23:30:52.787,"['resource ""aws_s3_bucket"" ""b"" {\n  count      = ""${length(var.domain_name)}""\n  bucket     = ""${element(var.domain_name, count.index)}""\n  acl        = ""public-read""\n  policy     = ""${file(""bucket-policy.json"")}""\n\n  website {\n    index_document = ""index.html""\n    error_document = ""error.html""\n\n    routing_rules = <<EOF\nEOF\n  }\n}\n']"
974,9049,6482,CC BY-SA 4.0,2019-08-29T08:11:51.490,"<p>This can happen with releases in <code>FAILED</code> state as mentioned by <a href=""https://devops.stackexchange.com/users/10599/simbo1905"">simbo1905</a> in her/his <a href=""https://devops.stackexchange.com/a/6518/16821"">answer</a>. </p>

<p>Another case is if there's a previously deleted but not purged release with the same name. </p>

<p>Doing another delete with the purge option on the release will free the name for reuse.</p>

<pre><code>helm ls -a
helm ls -a | grep -e NAME -e name_of_release
helm delete --purge name_of_release
</code></pre>

<p>Note: This issue <a href=""https://github.com/helm/helm/issues/972"" rel=""nofollow noreferrer"">https://github.com/helm/helm/issues/972</a> suggests that there is a parameter to force reusing the same name, however it also suggests to not use in production (i.e. do not automate with <code>replace</code> unless you know what you're doing).</p>

<pre><code>&gt; helm install --help
[...]
    --replace    re-use the given name, even if that name is already used. This is unsafe in production
[...]
</code></pre>
",16821,2019-08-29T08:11:51.490,"['helm ls -a\nhelm ls -a | grep -e NAME -e name_of_release\nhelm delete --purge name_of_release\n', '> helm install --help\n[...]\n    --replace    re-use the given name, even if that name is already used. This is unsafe in production\n[...]\n']"
975,9056,8995,CC BY-SA 4.0,2019-08-30T09:42:12.580,"<p>Using <strong>systemd in Docker</strong> is not really that straightforward.  </p>

<p>However, <a href=""https://hub.docker.com/_/centos"" rel=""nofollow noreferrer"">according to the doc on the docker hub</a>, <strong>systemd</strong> is now included in both the <code>centos:7</code> and <code>centos:latest</code> base containers.<br>
However, you will need to include text similar to the example Dockerfile : </p>

<pre><code>FROM centos:7
ENV container docker
RUN (cd /lib/systemd/system/sysinit.target.wants/; for i in *; do [ $i == \
systemd-tmpfiles-setup.service ] || rm -f $i; done); \
rm -f /lib/systemd/system/multi-user.target.wants/*;\
rm -f /etc/systemd/system/*.wants/*;\
rm -f /lib/systemd/system/local-fs.target.wants/*; \
rm -f /lib/systemd/system/sockets.target.wants/*udev*; \
rm -f /lib/systemd/system/sockets.target.wants/*initctl*; \
rm -f /lib/systemd/system/basic.target.wants/*;\
rm -f /lib/systemd/system/anaconda.target.wants/*;
VOLUME [ ""/sys/fs/cgroup"" ]
CMD [""/usr/sbin/init""]
</code></pre>

<p><strong>I strongly recommend to read the full <a href=""https://hub.docker.com/_/centos?tab=description"" rel=""nofollow noreferrer"">description tab</a> documentation on the hub.</strong> This will help you make it run correctly.</p>
",16829,2019-08-30T09:42:12.580,"['FROM centos:7\nENV container docker\nRUN (cd /lib/systemd/system/sysinit.target.wants/; for i in *; do [ $i == \\\nsystemd-tmpfiles-setup.service ] || rm -f $i; done); \\\nrm -f /lib/systemd/system/multi-user.target.wants/*;\\\nrm -f /etc/systemd/system/*.wants/*;\\\nrm -f /lib/systemd/system/local-fs.target.wants/*; \\\nrm -f /lib/systemd/system/sockets.target.wants/*udev*; \\\nrm -f /lib/systemd/system/sockets.target.wants/*initctl*; \\\nrm -f /lib/systemd/system/basic.target.wants/*;\\\nrm -f /lib/systemd/system/anaconda.target.wants/*;\nVOLUME [ ""/sys/fs/cgroup"" ]\nCMD [""/usr/sbin/init""]\n']"
976,9059,9058,CC BY-SA 4.0,2019-08-30T14:47:17.487,"<p>The command line is order sensitive. This command:</p>

<pre><code>docker run bot --restart-policy always
</code></pre>

<p>Runs the <code>bot</code> image as a container with the value of <code>CMD</code> set to <code>--restart-policy always</code>. To modify the restart policy of the container being run, you need to pass the option after <code>run</code> and before your image name:</p>

<pre><code>docker run --restart-policy always bot
</code></pre>
",7730,2019-08-30T14:47:17.487,"['docker run bot --restart-policy always\n', 'docker run --restart-policy always bot\n']"
977,9062,3757,CC BY-SA 4.0,2019-08-31T16:25:00.880,"<p>This worked for me on Ubuntu 18.04 LTS</p>

<pre><code>apt install certbot
apt install python3-certbot-dns-digitalocean
</code></pre>

<p><a href=""https://github.com/certbot/certbot/issues/6531#issuecomment-443812851"" rel=""nofollow noreferrer"">See this certbot issue</a></p>
",16855,2019-08-31T16:25:00.880,['apt install certbot\napt install python3-certbot-dns-digitalocean\n']
978,9069,9068,CC BY-SA 4.0,2019-09-02T03:50:38.850,"<blockquote>
  <p>Q: <em>Is it possible to share variables across instances?</em></p>
</blockquote>

<p>A: Yes. The dictionary <em>hostvars</em> keeps the variables. Quoting from <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#accessing-information-about-other-hosts-with-magic-variables"" rel=""nofollow noreferrer"">Accessing information about other hosts with magic variables</a></p>

<blockquote>
  <p>hostvars lets you access variables for another host, including facts that have been gathered about that host. You can access host variables at any point in a playbook. ...</p>
</blockquote>

<pre><code>{{ hostvars['test.example.com']['ansible_facts']['distribution'] }}
</code></pre>

<p>For details see <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#scoping-variables"" rel=""nofollow noreferrer"">Scoping variables</a> and <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#caching-facts"" rel=""nofollow noreferrer"">Caching facts</a>.</p>

<hr>

<p>With “Fact Caching” disabled, to share information among Ansible playbooks, it's possible to store all <em>hostvars</em> in a file. For example with this template</p>

<pre><code>  $ cat my_hostvars.json.j2
  my_hostvars_all:
  {% for my_host in ansible_play_hosts_all %}
    {{ my_host }}:
      {{ hostvars[my_host]|to_nice_json }}
  {% endfor %}
</code></pre>

<p>the playbook below stores <em>hostvars</em> of all hosts in the dictionary
<em>my_hostvars_all</em> and put it into the file
<em>{{ inventory_dir }}/my_hostvars.json</em> at localhost(master)</p>

<pre><code>  - hosts: test_jails
    tasks:
      - set_fact:
          test_var: ""test_var_in_{{ inventory_hostname }}""
      - template:
          src: my_hostvars.json.j2
          dest: ""{{ inventory_dir }}/my_hostvars.json""
        delegate_to: localhost
        run_once: true
</code></pre>

<p>The dictionary can be included in the next playbook. For example the playbook below</p>

<pre><code>  - hosts: test_jails
    tasks:
      - include_vars: my_hostvars.json
      - set_fact:
          my_hostvars: ""{{ my_hostvars_all[inventory_hostname] }}""
      - debug:
          var: my_hostvars.test_var
</code></pre>

<p>gives</p>

<pre><code>  ok: [test_01] =&gt; {
      ""my_hostvars.test_var"": ""test_var_in_test_01""
  }
  ok: [test_02] =&gt; {
      ""my_hostvars.test_var"": ""test_var_in_test_02""
  }
  ok: [test_03] =&gt; {
      ""my_hostvars.test_var"": ""test_var_in_test_03""
  }
</code></pre>
",7715,2019-09-02T04:03:13.637,"[""{{ hostvars['test.example.com']['ansible_facts']['distribution'] }}\n"", '  $ cat my_hostvars.json.j2\n  my_hostvars_all:\n  {% for my_host in ansible_play_hosts_all %}\n    {{ my_host }}:\n      {{ hostvars[my_host]|to_nice_json }}\n  {% endfor %}\n', '  - hosts: test_jails\n    tasks:\n      - set_fact:\n          test_var: ""test_var_in_{{ inventory_hostname }}""\n      - template:\n          src: my_hostvars.json.j2\n          dest: ""{{ inventory_dir }}/my_hostvars.json""\n        delegate_to: localhost\n        run_once: true\n', '  - hosts: test_jails\n    tasks:\n      - include_vars: my_hostvars.json\n      - set_fact:\n          my_hostvars: ""{{ my_hostvars_all[inventory_hostname] }}""\n      - debug:\n          var: my_hostvars.test_var\n', '  ok: [test_01] => {\n      ""my_hostvars.test_var"": ""test_var_in_test_01""\n  }\n  ok: [test_02] => {\n      ""my_hostvars.test_var"": ""test_var_in_test_02""\n  }\n  ok: [test_03] => {\n      ""my_hostvars.test_var"": ""test_var_in_test_03""\n  }\n']"
979,9073,8748,CC BY-SA 4.0,2019-09-02T20:12:23.063,"<p>any <code>with_*</code> is actully a local lookup.</p>

<p>So as Zeitounator mentioned, you're going to need to use something like the <code>find</code> module to fetch the files you want.</p>

<p>so I imagine that something like this would work:</p>

<pre><code>- hosts: primary
  remote_user: root
  tasks:
    - name: gather list of files to fetch
      find:
        paths: ""/data1/""
        recurse: no
        patterns: ""{{ dbname }}.0.db2inst1.*""
        use_regex: no
      regisrer: db_backup_src
    - name: fetch backups to local disk
       fetch:
         src: ""{{ item['path'] }}""
         dest: /data1/backup/
         flat: yes
      loop: ""{{ db_backuo_src['files'] }}""

- hosts: standby
  remote_user: root
  tasks:
    - name: copy backup to standby
      copy:
        src: ""{{ item }}""
        dest: /data1
        mode: 0755
        owner: db2inst1
      with_fileglob:
        - ""/data1/backup/{{dbname}}.0.db2inst1.*""
</code></pre>
",677,2019-09-02T20:12:23.063,"['- hosts: primary\n  remote_user: root\n  tasks:\n    - name: gather list of files to fetch\n      find:\n        paths: ""/data1/""\n        recurse: no\n        patterns: ""{{ dbname }}.0.db2inst1.*""\n        use_regex: no\n      regisrer: db_backup_src\n    - name: fetch backups to local disk\n       fetch:\n         src: ""{{ item[\'path\'] }}""\n         dest: /data1/backup/\n         flat: yes\n      loop: ""{{ db_backuo_src[\'files\'] }}""\n\n- hosts: standby\n  remote_user: root\n  tasks:\n    - name: copy backup to standby\n      copy:\n        src: ""{{ item }}""\n        dest: /data1\n        mode: 0755\n        owner: db2inst1\n      with_fileglob:\n        - ""/data1/backup/{{dbname}}.0.db2inst1.*""\n']"
980,9076,9075,CC BY-SA 4.0,2019-09-03T05:01:54.983,"<blockquote>
  <p>Q: <em>Is it possible to have a pair of IPs in Ansible?</em></p>
</blockquote>

<p>A: Yes. It is possible. For example, it might be useful to create groups in the inventory with all pieces of information.</p>

<pre><code>[primary]
1.1.1.1
1.1.1.3
1.1.1.5

[standby]
1.1.1.2
1.1.1.4
1.1.1.6

[ha]
1.1.1.1 stdby=1.1.1.2
1.1.1.3 stdby=1.1.1.4
1.1.1.5 stdby=1.1.1.6
</code></pre>

<p>It's possible to simplify the fetching of the configuration.</p>

<pre><code>- hosts: primary, standby
  remote_user: root
  tasks:
  - name: copy the config to local
    fetch:
      src: /data1/cronjobs/gen_ddl
      dest: /AnsibleDir/conf
</code></pre>

<p>Without <code>flat: yes</code> the configuration files will be stored in</p>

<pre><code>/AnsibleDir/conf/{{ inventory_hostname }}/data1/cronjobs/gen_ddl
</code></pre>

<p>Then it's possible to reference the configuration files by the inventory hostname. For example <code>groups['primary']</code> (<code>secondary</code> the same way). Take a look at <code>myshell_output</code> and select the data for <code>content</code> and <code>dest</code> from the <code>items</code></p>

<pre><code>- hosts: 127.0.0.1
  connection: local
  remote_user: root
  tasks:
  - name: loop primary config
    command: ""/AnsibleDir/driver.py
              /AnsibleDir/conf/{{ item }}/data1/cronjobs/gen_ddl""
    register: myshell_output
    loop: ""{{ groups['primary'] }}""
  - name: copy the output to a local file
    copy:
      content: ""{{ &lt;SELECT-FROM-ITEM&gt; }}""
      dest: ""/AnsibleDir/output.{{ &lt;SELECT-FROM-ITEM&gt; }}""
    loop: ""{{ myshell_output.results }}""
</code></pre>

<p>To reference primary/standby pairs use group <code>ha</code>. For example the play below changes the configuration both at primary and standby for all hosts in <code>ha</code>.</p>

<pre><code>- hosts: ha
  tasks:
    - name: Change configuration at primary
      lineinfile:
        path: /AnsibleDir/conf/{{ inventory_hostname }}/data1/cronjobs/gen_dd
        regexp: &lt;ADD-REGEXP&gt;
        line: &lt;ADD-LINE&gt;
    - name: Change configuration at standby
      lineinfile:
        path: /AnsibleDir/conf/{{ hostvars[inventory_hostname].stdby }}/data1/cronjobs/gen_dd
        regexp: &lt;ADD-REGEXP&gt;
        line: &lt;ADD-LINE&gt;
</code></pre>

<blockquote>
  <p>Q: <em>I need to find the differences of configuration files in 2 machines. they need to be the same. In python script, it will find the differences and fix them. So I need to have both configurations on my local then run the python script for them.</em></p>
</blockquote>

<p>A: Fix the configuration files in 2 machines</p>

<pre><code>- hosts: ha
  tasks:
    - name: Fix primary and standby config
      command: ""/AnsibleDir/driver.py
                /AnsibleDir/conf/{{ inventory_hostname }}/data1/cronjobs/gen_ddl
                /AnsibleDir/conf/{{ hostvars[inventory_hostname].stdby }}/data1/cronjobs/gen_ddl""
</code></pre>
",7715,2019-09-03T06:45:27.597,"['[primary]\n1.1.1.1\n1.1.1.3\n1.1.1.5\n\n[standby]\n1.1.1.2\n1.1.1.4\n1.1.1.6\n\n[ha]\n1.1.1.1 stdby=1.1.1.2\n1.1.1.3 stdby=1.1.1.4\n1.1.1.5 stdby=1.1.1.6\n', '- hosts: primary, standby\n  remote_user: root\n  tasks:\n  - name: copy the config to local\n    fetch:\n      src: /data1/cronjobs/gen_ddl\n      dest: /AnsibleDir/conf\n', '/AnsibleDir/conf/{{ inventory_hostname }}/data1/cronjobs/gen_ddl\n', '- hosts: 127.0.0.1\n  connection: local\n  remote_user: root\n  tasks:\n  - name: loop primary config\n    command: ""/AnsibleDir/driver.py\n              /AnsibleDir/conf/{{ item }}/data1/cronjobs/gen_ddl""\n    register: myshell_output\n    loop: ""{{ groups[\'primary\'] }}""\n  - name: copy the output to a local file\n    copy:\n      content: ""{{ <SELECT-FROM-ITEM> }}""\n      dest: ""/AnsibleDir/output.{{ <SELECT-FROM-ITEM> }}""\n    loop: ""{{ myshell_output.results }}""\n', '- hosts: ha\n  tasks:\n    - name: Change configuration at primary\n      lineinfile:\n        path: /AnsibleDir/conf/{{ inventory_hostname }}/data1/cronjobs/gen_dd\n        regexp: <ADD-REGEXP>\n        line: <ADD-LINE>\n    - name: Change configuration at standby\n      lineinfile:\n        path: /AnsibleDir/conf/{{ hostvars[inventory_hostname].stdby }}/data1/cronjobs/gen_dd\n        regexp: <ADD-REGEXP>\n        line: <ADD-LINE>\n', '- hosts: ha\n  tasks:\n    - name: Fix primary and standby config\n      command: ""/AnsibleDir/driver.py\n                /AnsibleDir/conf/{{ inventory_hostname }}/data1/cronjobs/gen_ddl\n                /AnsibleDir/conf/{{ hostvars[inventory_hostname].stdby }}/data1/cronjobs/gen_ddl""\n']"
981,9111,9101,CC BY-SA 4.0,2019-09-06T10:59:15.283,"<p>I have cloned your repo and try that in my local machine. Here is the steps :</p>

<ol>
<li><p>Git clone </p></li>
<li><p>executing Dry run (testing everything before doing a release ""for real"" :</p>

<p>$ goreleaser release --skip-publish</p></li>
<li><p>show there is no error</p>

<pre><code> SIGNING ARTIFACTS
  • pipe skipped              error=artifact signing is disabled
• DOCKER IMAGES
  • pipe skipped              error=docker section is not configured
• PUBLISHING
  • pipe skipped              error=publishing is disabled
• release succeeded after 20.75s

</code></pre></li>
<li><p>execute goreleaser for release</p>

<p>$ goreleaser release</p></li>
<li><p>goreleaser will created <strong>dist</strong> folder inside project and this folder will consist of distribution packages (deb, rpm).</p></li>
</ol>

<p>I have encounter some issues and here is what I do :</p>

<ul>
<li>error=missing GITHUB_TOKEN, GITLAB_TOKEN and GITEA_TOKEN</li>
</ul>

<p>create github or gitlab token ( <a href=""https://github.com/settings/tokens"" rel=""nofollow noreferrer"">https://github.com/settings/tokens</a>) and put it as environment variabel</p>

<pre><code>export GITHUB_TOKEN=xxxxyyyyyzzzzz
</code></pre>

<p>resolve the issue.</p>

<ul>
<li>pre hook failed: xxxx is not within a known GOPATH/src</li>
</ul>

<p>as I see in your goreleaser.yaml </p>

<pre><code>hooks:
pre: dep ensure
</code></pre>

<p>you're using dep ensure, checking $GOPATH and make sure $GOPATH pointing to right path of your Go project. </p>

<ul>
<li>error=dist is not empty, remove it before running goreleaser or use the --rm-dist flag</li>
</ul>

<p>dist folder has been created before, you can either manually delete the folder or add flags --rm-dist when executing goreleaser command</p>

<pre><code>$ goreleaser release --skip-publish --rm-dist
</code></pre>

<ul>
<li>error=nfpm failed: rpmbuild not present in $PATH</li>
</ul>

<p>this error occured as I was running on mac machine so there is no rpmbuild installed, installing rpm, rpmbuild solve the issue</p>

<pre><code>$brew install rpm
</code></pre>

<ul>
<li>error=git is currently in a dirty state, please check in your pipeline what can be changing the following files:
M Gopkg.lock</li>
</ul>

<p>Goreleaser seems to check file diff, so as because running hook (dep ensure) updating the Gopkg.lock and this changes/updates are not pushed to git. The solution is always pushing the changes to git.</p>

<ul>
<li>error=git tag v1.0.5 was not made against commit 3ae83eebd904d33cc549117254e857ebea04df90</li>
</ul>

<p>reading from GoReleaser documentation which is ""GoReleaser enforces semantic versioning and will error on non-compliant tags. Your tag should be a valid semantic version. If it is not, GoReleaser will error.""</p>

<p>after pushing to git, make sure you have to update the tags, in this case I updates the tags to v1.0.6 (previously v1.0.5).</p>

<ul>
<li>error=GitHub/GitLab/Gitea Releases: failed to publish artifacts POST <a href=""http://xxxyyyzzz/releases"" rel=""nofollow noreferrer"">http://xxxyyyzzz/releases</a>: 404 Not Found []</li>
</ul>

<p>make sure release text is there.</p>
",16942,2019-09-06T10:59:15.283,"[' SIGNING ARTIFACTS\n  • pipe skipped              error=artifact signing is disabled\n• DOCKER IMAGES\n  • pipe skipped              error=docker section is not configured\n• PUBLISHING\n  • pipe skipped              error=publishing is disabled\n• release succeeded after 20.75s\n\n', 'export GITHUB_TOKEN=xxxxyyyyyzzzzz\n', 'hooks:\npre: dep ensure\n', '$ goreleaser release --skip-publish --rm-dist\n', '$brew install rpm\n']"
982,9117,9116,CC BY-SA 4.0,2019-09-07T06:59:55.037,"<p>You can indeed build RPMs on Debian. You need the <code>rpm</code> and <code>rpmbuild8</code> packages:</p>

<p>I tried it with a docker container:</p>

<pre><code>docker run --rm -it debian bash -c 'apt-get update &amp;&amp; \
apt-get -y install rpm librpmbuild8 &amp;&amp; which rpmbuild'
</code></pre>

<hr>

<p>More info on packages:</p>

<pre><code>The following additional packages will be installed:
  dbus debugedit libapparmor1 libarchive13 libdbus-1-3 libdw1 libexpat1 libgdbm-compat4 libgdbm6 libicu63 liblua5.2-0 libmagic-mgc libmagic1 libnspr4
  libnss3 libperl5.28 libpopt0 librpm8 librpmio8 librpmsign8 libsqlite3-0 libxml2 netbase perl perl-modules-5.28 rpm-common rpm2cpio
Suggested packages:
  default-dbus-session-bus | dbus-session-bus rpm-i18n lrzip gdbm-l10n file sensible-utils perl-doc libterm-readline-gnu-perl
  | libterm-readline-perl-perl make libb-debug-perl liblocale-codes-perl alien python elfutils rpmlint rpm2html
</code></pre>
",354,2019-09-08T09:31:19.790,"[""docker run --rm -it debian bash -c 'apt-get update && \\\napt-get -y install rpm librpmbuild8 && which rpmbuild'\n"", 'The following additional packages will be installed:\n  dbus debugedit libapparmor1 libarchive13 libdbus-1-3 libdw1 libexpat1 libgdbm-compat4 libgdbm6 libicu63 liblua5.2-0 libmagic-mgc libmagic1 libnspr4\n  libnss3 libperl5.28 libpopt0 librpm8 librpmio8 librpmsign8 libsqlite3-0 libxml2 netbase perl perl-modules-5.28 rpm-common rpm2cpio\nSuggested packages:\n  default-dbus-session-bus | dbus-session-bus rpm-i18n lrzip gdbm-l10n file sensible-utils perl-doc libterm-readline-gnu-perl\n  | libterm-readline-perl-perl make libb-debug-perl liblocale-codes-perl alien python elfutils rpmlint rpm2html\n']"
983,9124,9120,CC BY-SA 4.0,2019-09-09T06:54:09.213,"<p>You'll want to use the CHANGE_TARGET environment variable.  If that variable exists then you are dealing with a merge request. </p>

<p>You can use the following code snipped to then determine the branch name and alter the job's logic depending on which branch the code is being merged into.</p>

<p><code>branchName = env.CHANGE_TARGET ? env.CHANGE_TARGET : env.BRANCH_NAME</code></p>

<p>In your code example you would replace  </p>

<pre><code>        expression {
         return env.BRANCH_NAME != 'feature_cicd'
         echo env.BRANCH_NAME
        }
</code></pre>

<p>with   </p>

<pre><code>        expression {
         branchName = env.CHANGE_TARGET ? env.CHANGE_TARGET : env.BRANCH_NAME
         return branchName != 'feature_cicd'
         echo branchName
        }
</code></pre>
",10,2019-09-12T06:53:43.790,"[""        expression {\n         return env.BRANCH_NAME != 'feature_cicd'\n         echo env.BRANCH_NAME\n        }\n"", ""        expression {\n         branchName = env.CHANGE_TARGET ? env.CHANGE_TARGET : env.BRANCH_NAME\n         return branchName != 'feature_cicd'\n         echo branchName\n        }\n""]"
984,9126,6811,CC BY-SA 4.0,2019-09-09T07:50:26.867,"<p>If you want to use environment variables with the <code>${VAR}</code> syntax in the declarative pipeline, then you need to define those variables in the <code>environment { }</code> block.</p>

<p>for example:  </p>

<pre><code>environment {
        DISABLE_AUTH = 'true'
        DB_ENGINE    = 'sqlite'
    }

    stages {
        stage('Build') {
            steps {
                echo ""Database engine is ${DB_ENGINE}""
                echo ""DISABLE_AUTH is ${DISABLE_AUTH}""
                sh 'printenv'
            }
        }
    }

</code></pre>

<p>If you want to use environment variables that come from other plugins etc, then you need to access them with the <code>env.VAR</code> syntax.  For example:</p>

<p><code>echo ""Running ${env.BUILD_ID} on ${env.JENKINS_URL}""</code></p>
",10,2019-09-09T07:50:26.867,"['environment {\n        DISABLE_AUTH = \'true\'\n        DB_ENGINE    = \'sqlite\'\n    }\n\n    stages {\n        stage(\'Build\') {\n            steps {\n                echo ""Database engine is ${DB_ENGINE}""\n                echo ""DISABLE_AUTH is ${DISABLE_AUTH}""\n                sh \'printenv\'\n            }\n        }\n    }\n\n']"
985,9133,9130,CC BY-SA 4.0,2019-09-09T14:46:13.623,"<p>I've eventually created an umbrella chart with alias:</p>

<pre><code>dependencies:
  - name: app
    repository: file://./app
    version: 1.0.0
    alias: child1
  - name: app
    repository: file://./app
    version: 1.0.0
    alias: child2
</code></pre>

<p>And in values.yaml i've changed the needed values,
then added the grafana dashboard in the bundled yaml file.</p>
",16981,2019-09-09T14:46:13.623,['dependencies:\n  - name: app\n    repository: file://./app\n    version: 1.0.0\n    alias: child1\n  - name: app\n    repository: file://./app\n    version: 1.0.0\n    alias: child2\n']
986,9163,9161,CC BY-SA 4.0,2019-09-13T12:40:20.707,"<p>You need to expose the container ports locally using either:</p>

<ul>
<li><code>docker run --rm -it -p 8080:80 myapp</code></li>
<li>or a <code>docker-compose.yml</code> file:</li>
</ul>

<pre><code>services:
  myapp:
    image: myapp:tag
    ports:
    - 8080:80
</code></pre>

<p>Then, you'll be able to <code>curl localhost:8080</code>.</p>
",16683,2019-09-13T12:40:20.707,['services:\n  myapp:\n    image: myapp:tag\n    ports:\n    - 8080:80\n']
987,9169,9168,CC BY-SA 4.0,2019-09-14T03:32:14.667,"<p>Yes. It is possible to create a YAML data structure with Jinja and read the variable in with the filter <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#filters-for-formatting-data"" rel=""nofollow noreferrer"">from_yaml</a>.</p>

<p>The play</p>

<pre><code>- hosts: group1
  vars:
    script_dir: /tmp
  tasks:
    - debug:
        var: filewatches
</code></pre>

<p>with the group_vars</p>

<pre><code>$ cat group_vars/group1.yml 
filewatches: ""{{ filewatches_var|from_yaml }}""
filewatches_var: |
    {% for host in groups['worker'] %}
    - type: ""copy""
      directory_name: ""{{ host }}""
      shell_script: ""{{ script_dir }}/ascript.sh""
    {% endfor %}
</code></pre>

<p>and with the inventory</p>

<pre><code>$ cat hosts
...
group1:
  hosts:
    test_01

group2:
  hosts:
    test_02
    test_03
</code></pre>

<p>gives</p>

<pre><code>ok: [test_01] =&gt; {
    ""filewatches"": [
        {
            ""directory_name"": ""test_02"", 
            ""shell_script"": ""/tmp/ascript.sh"", 
            ""type"": ""copy""
        }, 
        {
            ""directory_name"": ""test_03"", 
            ""shell_script"": ""/tmp/ascript.sh"", 
            ""type"": ""copy""
        }
    ]
}
</code></pre>
",7715,2019-09-14T03:32:14.667,"['- hosts: group1\n  vars:\n    script_dir: /tmp\n  tasks:\n    - debug:\n        var: filewatches\n', '$ cat group_vars/group1.yml \nfilewatches: ""{{ filewatches_var|from_yaml }}""\nfilewatches_var: |\n    {% for host in groups[\'worker\'] %}\n    - type: ""copy""\n      directory_name: ""{{ host }}""\n      shell_script: ""{{ script_dir }}/ascript.sh""\n    {% endfor %}\n', '$ cat hosts\n...\ngroup1:\n  hosts:\n    test_01\n\ngroup2:\n  hosts:\n    test_02\n    test_03\n', 'ok: [test_01] => {\n    ""filewatches"": [\n        {\n            ""directory_name"": ""test_02"", \n            ""shell_script"": ""/tmp/ascript.sh"", \n            ""type"": ""copy""\n        }, \n        {\n            ""directory_name"": ""test_03"", \n            ""shell_script"": ""/tmp/ascript.sh"", \n            ""type"": ""copy""\n        }\n    ]\n}\n']"
988,9171,9146,CC BY-SA 4.0,2019-09-14T10:08:40.260,"<p>Found the answer <a href=""https://github.com/awslabs/amazon-eks-ami/issues/183#issuecomment-463687956"" rel=""nofollow noreferrer"">here</a></p>

<p>Just add <code>--network=host</code> to <code>docker build</code> or <code>docker run</code>.</p>

<pre><code> docker build --network=host foo/bar:latest .
</code></pre>
",4637,2019-09-14T10:08:40.260,[' docker build --network=host foo/bar:latest .\n']
989,9177,9147,CC BY-SA 4.0,2019-09-16T14:12:48.593,"<p>A closer reading of <a href=""https://circleci.com/docs/2.0/caching/#using-keys-and-templates"" rel=""nofollow noreferrer"">the documentation about using environment variables in cache keys</a> reveals the issue (emphasis mine):</p>

<blockquote>
  <p>The environment variable variableName (supports any environment variable exported by CircleCI or added to a specific Context—<strong>not any arbitrary environment variable</strong>).</p>
</blockquote>

<p>""exported by CircleCI"" seems to mean the list of mostly-<code>CIRCLE_...</code>-prefixed variables (documented as ""<a href=""https://circleci.com/docs/2.0/env-vars/#built-in-environment-variables"" rel=""nofollow noreferrer"">Built-In Environment Variables</a>"") while (unsupported) ""any arbitrary environment variable"" includes variables set in an <code>environment</code> section in <code>config.yml</code>.</p>

<p>I ended up working around this limitation something like this:</p>

<pre><code>jobs:
  build:
    docker:
      - image: ""nixorg/nix:circleci""

    environment:
      NIXPKGS_REV: ""3c83ad6ac13b67101cc3e2e07781963a010c1624""

    steps:
      - ""run"":
          name: ""Prepare For Cache Key""
          command: |
            echo ""${NIXPKGS_REV}"" &gt; nixpkgs.rev

      - restore_cache:
          name: ""Restore Nix Store Paths""
          keys:
            - paymentserver-nix-store-v1-{{ checksum ""nixpkgs.rev"" }}
            - paymentserver-nix-store-v1-
</code></pre>

<p>That is, instead of trying to use the value of <code>NIXPKGS_REV</code> from the environment in the cache key, an earlier step writes the value of that environment variable to a file and then the cache key is constructed using the checksum of that file.  Computing file checksums for use in cache keys is well supported so this produces a cache key which is derived from the value of the environment variable.  The key doesn't <em>contain</em> the value of the environment variable but since the key's only purpose is to be unique for certain unique inputs, using the checksum works just as well.</p>
",12089,2019-09-16T14:12:48.593,"['jobs:\n  build:\n    docker:\n      - image: ""nixorg/nix:circleci""\n\n    environment:\n      NIXPKGS_REV: ""3c83ad6ac13b67101cc3e2e07781963a010c1624""\n\n    steps:\n      - ""run"":\n          name: ""Prepare For Cache Key""\n          command: |\n            echo ""${NIXPKGS_REV}"" > nixpkgs.rev\n\n      - restore_cache:\n          name: ""Restore Nix Store Paths""\n          keys:\n            - paymentserver-nix-store-v1-{{ checksum ""nixpkgs.rev"" }}\n            - paymentserver-nix-store-v1-\n']"
990,9185,8919,CC BY-SA 4.0,2019-09-17T06:59:34.167,"<p>This might help you with your problem.
In the normal pipeline or any Jenkins job, we can define parameters which can be accessed via say <code>${env.SOME_VARIABLE}</code></p>

<p>My solution for using environment variables in the Jenkins Multibranch Pipeline.
Scenario. Say you have a variable named VARIABLE whose value is <code>123456789</code>.</p>

<p><strong>Create a secret text with id and description.</strong></p>

<ul>
<li>Secret Text: 123456789</li>
</ul>

<p><strong>NOTE</strong>: In Jenkins, the secret text will be completely hidden.</p>

<ul>
<li>Id: VARIABLE</li>
</ul>

<p><strong>NOTE</strong>: You can define it as you want. If left empty a random value will be assigned to it in the form as45f2sf-43rs-4sdf-s3f3-329f9bc9ae269</p>

<ul>
<li>Description: VARIABLE</li>
</ul>

<p><strong>NOTE</strong>: Description for the variable.</p>

<p>Once this is created in your multibranch pipeline Jenkinsfile, you can add the following to access those variables whenever required.</p>

<pre><code>pipeline {
  agent any
    environment { 
      SECRET_VARIABLE = credentials(""VARIABLE"") 
    }
    stages {
      stage('stage') {
        steps {
          echo ""This is a secret variable: $SECRET_VARIABLE""
        }
      }
   }
}         
</code></pre>

<p>**PS: The variables will appear in a format <code>****</code> **</p>
",16959,2019-09-17T07:08:10.917,"['pipeline {\n  agent any\n    environment { \n      SECRET_VARIABLE = credentials(""VARIABLE"") \n    }\n    stages {\n      stage(\'stage\') {\n        steps {\n          echo ""This is a secret variable: $SECRET_VARIABLE""\n        }\n      }\n   }\n}         \n']"
991,9196,8720,CC BY-SA 4.0,2019-09-18T13:30:05.860,"<p>I ended up using {{.ManagerStatus.Addr}} and stripping the port number from the results with sed.  </p>

<pre><code>for NODE in $(docker  node ls -f 'role=manager' --format '{{.Hostname}}'); do
  docker node inspect --format '{{.ManagerStatus.Addr}}' ${NODE} | sed 's/:2377//'
done
</code></pre>
",17150,2019-09-18T13:30:05.860,"[""for NODE in $(docker  node ls -f 'role=manager' --format '{{.Hostname}}'); do\n  docker node inspect --format '{{.ManagerStatus.Addr}}' ${NODE} | sed 's/:2377//'\ndone\n""]"
992,9208,8047,CC BY-SA 4.0,2019-09-19T13:42:45.883,"<p>Check <a href=""https://github.com/helm/helm/issues/3130"" rel=""nofollow noreferrer"">https://github.com/helm/helm/issues/3130</a>, this might help.
I followed the instruction in the post:</p>

<pre><code>kubectl --namespace kube-system create serviceaccount tiller

kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller

helm init --service-account tiller --upgrade
</code></pre>

<p>This works for me.</p>
",17175,2019-09-19T13:42:45.883,['kubectl --namespace kube-system create serviceaccount tiller\n\nkubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller\n\nhelm init --service-account tiller --upgrade\n']
993,9213,9209,CC BY-SA 4.0,2019-09-19T16:40:51.003,"<p>Ok, solved it :)</p>

<p>Here the task for everyone who intends to do the same.</p>

<p>Only the skip/changed console output could be replaced by a nicer message.</p>

<pre><code>- name: Register unwanted motd files
  stat:
    path: ""{{motd_path}}/{{item}}""
  register: filecheck
  with_items: ""{{ unwanted_motd_files | default([]) }}""

- name: Check if unwanted motd files are executable and remove the executable bit
  file:
    path: ""{{motd_path}}/{{item.item}}""
    state: touch
    mode: u-x,g-x,o-x
  with_items: ""{{ filecheck.results }}""
  when: item.stat.exists == true and item.stat.executable == True
</code></pre>
",17174,2019-09-19T16:40:51.003,"['- name: Register unwanted motd files\n  stat:\n    path: ""{{motd_path}}/{{item}}""\n  register: filecheck\n  with_items: ""{{ unwanted_motd_files | default([]) }}""\n\n- name: Check if unwanted motd files are executable and remove the executable bit\n  file:\n    path: ""{{motd_path}}/{{item.item}}""\n    state: touch\n    mode: u-x,g-x,o-x\n  with_items: ""{{ filecheck.results }}""\n  when: item.stat.exists == true and item.stat.executable == True\n']"
994,9230,9228,CC BY-SA 4.0,2019-09-20T22:18:17.470,"<p><a href=""https://github.com/jenkinsci/configuration-as-code-plugin/blob/master/demos/jenkins/jenkins.yaml"" rel=""nofollow noreferrer"">https://github.com/jenkinsci/configuration-as-code-plugin/blob/master/demos/jenkins/jenkins.yaml</a></p>

<p>It should be possible by configuring it like this:</p>

<pre><code>unclassified:
  globalLibraries:
    libraries:
      - name: ""some-lib""
        retriever:
          modernSCM:
            scm:
              git:
                remote: ""https://github.com/some-project.git""
                credentialsId: 'some-credentials'
</code></pre>
",210,2019-09-20T22:18:17.470,"['unclassified:\n  globalLibraries:\n    libraries:\n      - name: ""some-lib""\n        retriever:\n          modernSCM:\n            scm:\n              git:\n                remote: ""https://github.com/some-project.git""\n                credentialsId: \'some-credentials\'\n']"
995,9238,9229,CC BY-SA 4.0,2019-09-22T19:19:45.617,"<p>According to <a href=""https://jenkinsci.github.io/job-dsl-plugin/#path/job-scm-git-extensions-cloneOptions-shallow"" rel=""nofollow noreferrer"">the Jenkins Job DSL documentation</a> <code>shallow</code> has to be enabled:</p>

<pre><code>shallow(true)
</code></pre>

<p><a href=""https://i.stack.imgur.com/Gzo24.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Gzo24.png"" alt=""enter image description here""></a></p>
",210,2019-09-22T19:19:45.617,['shallow(true)\n']
996,9240,9216,CC BY-SA 4.0,2019-09-22T20:50:10.717,"<p>Note: the answer is rather speculative, based on docs only, I didn't actually use GitLab pipelines yet.</p>
<p>You may be able to use the <a href=""https://docs.gitlab.com/ee/api/pipelines.html"" rel=""nofollow noreferrer"">Pipelines API</a>. More specifically you could <a href=""https://docs.gitlab.com/ee/api/pipelines.html#get-variables-of-a-pipeline"" rel=""nofollow noreferrer"">get a pipeline's variables</a>:</p>
<blockquote>
<p>Get variables of a pipeline</p>
<pre><code>GET /projects/:id/pipelines/:pipeline_id/variables

Attribute Type            Required    Description
id            integer/string  yes         The ID or URL-encoded path of the project owned by the authenticated user
pipeline_id   integer         yes         The ID of a pipeline
</code></pre>
<p>Example of response</p>
<pre><code>[
  {
    &quot;key&quot;: &quot;RUN_NIGHTLY_BUILD&quot;,
    &quot;variable_type&quot;: &quot;env_var&quot;,
    &quot;value&quot;: &quot;true&quot;
  },
  {
    &quot;key&quot;: &quot;foo&quot;,
    &quot;value&quot;: &quot;bar&quot;
  }
]
</code></pre>
</blockquote>
<p>I'm suspecting that in the response you'd find the variables shown in a <a href=""https://docs.gitlab.com/ee/api/pipelines.html#create-a-new-pipeline"" rel=""nofollow noreferrer"">pipeline creation</a> response example, which include these which could be of interest to you:</p>
<blockquote>
<pre><code>  &quot;id&quot;: 61,
  &quot;sha&quot;: &quot;384c444e840a515b23f21915ee5766b87068a70d&quot;,

  &quot;before_sha&quot;: &quot;0000000000000000000000000000000000000000&quot;,
</code></pre>
</blockquote>
<p>I'm uncertain if the <code>before_sha</code> for the current pipeline is what you're looking for, if not you'd just get the <code>sha</code> for the previous pipeline ID, which you could derive from the current pipeline ID (via the <code>CI_PIPELINE_ID</code> environment variable, see <a href=""https://docs.gitlab.com/ee/ci/variables/README.html#predefined-environment-variables"" rel=""nofollow noreferrer"">Predefined environment variables</a>). I'm assuming that the pipeline IDs are consecutive.</p>
",47,2019-09-22T20:50:10.717,"['GET /projects/:id/pipelines/:pipeline_id/variables\n\nAttribute Type            Required    Description\nid            integer/string  yes         The ID or URL-encoded path of the project owned by the authenticated user\npipeline_id   integer         yes         The ID of a pipeline\n', '[\n  {\n    ""key"": ""RUN_NIGHTLY_BUILD"",\n    ""variable_type"": ""env_var"",\n    ""value"": ""true""\n  },\n  {\n    ""key"": ""foo"",\n    ""value"": ""bar""\n  }\n]\n', '  ""id"": 61,\n  ""sha"": ""384c444e840a515b23f21915ee5766b87068a70d"",\n\n  ""before_sha"": ""0000000000000000000000000000000000000000"",\n']"
997,9248,9225,CC BY-SA 4.0,2019-09-23T16:47:17.897,"<p>It seems that it is only possible by using a workaround as depicted in <a href=""https://stackoverflow.com/a/49637685/2777965"">this answer</a>.</p>

<p>After setting gitLFS in the UI, subsequently inspecting the <code>/var/lib/jenkins/jobs/some-job/config.xml</code> file it became obvious that the XML looked as follows:</p>

<pre><code>&lt;traits&gt;
   &lt;jenkins.plugins.git.traits.GitLFSPullTrait&gt;
      &lt;extension class=""hudson.plugins.git.extensions.impl.GitLFSPull""/&gt;
   &lt;/jenkins.plugins.git.traits.GitLFSPullTrait&gt;
&lt;/traits
</code></pre>

<p>After defining <code>jenkins.plugins.git.traits.GitLFSPullTrait</code>:</p>

<pre><code>jobs:
  - script: &gt;
      multibranchPipelineJob(""example"") {
        branchSources {
          ...
        }
        configure { node -&gt;
          node / sources / data / 'jenkins.branch.BranchSource' / source / traits {
            'jenkins.plugins.git.traits.GitLFSPullTrait'()
          }
        }
      }
</code></pre>

<p>Git-lfs was enabled.</p>
",210,2019-09-23T16:47:17.897,"['<traits>\n   <jenkins.plugins.git.traits.GitLFSPullTrait>\n      <extension class=""hudson.plugins.git.extensions.impl.GitLFSPull""/>\n   </jenkins.plugins.git.traits.GitLFSPullTrait>\n</traits\n', 'jobs:\n  - script: >\n      multibranchPipelineJob(""example"") {\n        branchSources {\n          ...\n        }\n        configure { node ->\n          node / sources / data / \'jenkins.branch.BranchSource\' / source / traits {\n            \'jenkins.plugins.git.traits.GitLFSPullTrait\'()\n          }\n        }\n      }\n']"
998,9271,9243,CC BY-SA 4.0,2019-09-25T05:55:35.037,"<p>I agree with <a href=""https://devops.stackexchange.com/users/17225/omri-spector"">Omri</a> that you are heading the wrong way. I would recommend using a <a href=""https://jenkins.io/doc/book/pipeline/shared-libraries/"" rel=""nofollow noreferrer"">shared library</a> which implements the pipeline. You would then have a simple Jenkins file which looks all the same. See <a href=""https://jenkins.io/blog/2017/10/02/pipeline-templates-with-shared-libraries/"" rel=""nofollow noreferrer"">https://jenkins.io/blog/2017/10/02/pipeline-templates-with-shared-libraries/</a></p>

<p>Let's say you have a shared library which contains a <code>vars/commonpipeline.groovy</code> which contains something like this:</p>

<pre><code>def call(body) {
    // evaluate the body block, and collect configuration into the object
    pipelineParams= [:]
    body.resolveStrategy = Closure.DELEGATE_FIRST
    body.delegate = pipelineParams
    body()

    pipeline {
        agent {
            label pipelineParams.nodes
        }
        options {
            buildDiscarder(logRotator(artifactNumToKeepStr: '1', numToKeepStr: '10'))
            disableConcurrentBuilds()
            timestamps()
            timeout(time: pipelineParams.timeout, unit: 'MINUTES')
        }

        stages {
            stage('Build') {
                steps {
                    //TO SOMETHING
                }
            }
        }
    }
}
</code></pre>

<p>Then you can have a <code>Jenkinsfile</code> in your dev project which loads the library and uses the common pipeline like this:</p>

<pre><code>import org.apache.commons.io.FileUtils
library identifier: 'shared-pipeline-library@master', retriever: modernSCM(
  [$class: 'GitSCMSource',
       remote: 'https://bitbucket/jenkins/hared-pipeline-library.git',
       credentialsId: 'bitbucket.service.user'
  ])

commonpipeline {
    nodes     = 'BUILD' /* label of jenkins nodes*/
    timeout   = '60'
}
</code></pre>
",4852,2020-05-04T05:20:11.117,"[""def call(body) {\n    // evaluate the body block, and collect configuration into the object\n    pipelineParams= [:]\n    body.resolveStrategy = Closure.DELEGATE_FIRST\n    body.delegate = pipelineParams\n    body()\n\n    pipeline {\n        agent {\n            label pipelineParams.nodes\n        }\n        options {\n            buildDiscarder(logRotator(artifactNumToKeepStr: '1', numToKeepStr: '10'))\n            disableConcurrentBuilds()\n            timestamps()\n            timeout(time: pipelineParams.timeout, unit: 'MINUTES')\n        }\n\n        stages {\n            stage('Build') {\n                steps {\n                    //TO SOMETHING\n                }\n            }\n        }\n    }\n}\n"", ""import org.apache.commons.io.FileUtils\nlibrary identifier: 'shared-pipeline-library@master', retriever: modernSCM(\n  [$class: 'GitSCMSource',\n       remote: 'https://bitbucket/jenkins/hared-pipeline-library.git',\n       credentialsId: 'bitbucket.service.user'\n  ])\n\ncommonpipeline {\n    nodes     = 'BUILD' /* label of jenkins nodes*/\n    timeout   = '60'\n}\n""]"
999,9274,9272,CC BY-SA 4.0,2019-09-25T13:40:58.670,"<p>If I am understanding your question correctly, what you are describing sounds like a perfect use case for SSM. You can store your RDS password as a <a href=""https://docs.aws.amazon.com/kms/latest/developerguide/services-parameter-store.html"" rel=""nofollow noreferrer"">secure string parameter encrypted by KMS</a>, then reference it in you terraform file as a <a href=""https://www.terraform.io/docs/providers/aws/d/ssm_parameter.html"" rel=""nofollow noreferrer"">data source</a> with decryption. With this method, you only have to reference your decrypted password, and never directly store the encrypted or plain text in your tf file. </p>

<pre><code>data ""aws_ssm_parameter"" ""foo"" {
  name = ""foo""
  with_decryption = true
}
</code></pre>
",4328,2019-09-25T13:49:33.533,"['data ""aws_ssm_parameter"" ""foo"" {\n  name = ""foo""\n  with_decryption = true\n}\n']"
1000,9280,9279,CC BY-SA 4.0,2019-09-25T18:32:26.680,"<p>Okay, so it turns out this wasn't my problem, but I know the answer to the question I asked:</p>

<p>The file <code>/opt/sensu/embedded/lib/ruby/gems/2.4.0/gems/sensu-plugins-microsoft-teams-2.0.0/bin/handler-microsoft-teams.rb</code> defines a function <code>get_setting</code>, which looks like this:</p>

<pre><code>def get_setting(name)
  settings[config[:json_config]][name]
end
</code></pre>

<p><code>config[:json_config]</code> is the string passed with the <code>-j</code> switch.</p>

<p>On to <code>config</code>: the file <code>/opt/sensu/embedded/lib/ruby/gems/2.4.0/gems/sensu-plugin-2.7.1/lib/sensu-handler.rb</code> requires <code>sensu-plugin/utils</code>, which defines the following:</p>

<pre><code>module Sensu
  module Plugin
    module Utils # rubocop:disable Metrics/ModuleLength
      def config_files
        if ENV['SENSU_LOADED_TEMPFILE'] &amp;&amp; File.file?(ENV['SENSU_LOADED_TEMPFILE'])
          IO.read(ENV['SENSU_LOADED_TEMPFILE']).split(':')
        elsif ENV['SENSU_CONFIG_FILES']
          ENV['SENSU_CONFIG_FILES'].split(':')
        else
          ['/etc/sensu/config.json'] + Dir['/etc/sensu/conf.d/**/*.json']
        end
      end

      def load_config(filename)
        JSON.parse(File.open(filename, 'r').read)
      rescue
        {}
      end

      def settings
        @settings ||= config_files.map { |f| load_config(f) }.reduce { |a, b| deep_merge(a, b) }
      end
...
</code></pre>

<p>So <code>settings</code> is going to load all JSON files nested anywhere under <code>/etc/sensu/conf.d/</code> and deep-merge them. Beyond that, the path is not relevant to Sensu's ability to load it using the string <code>slack</code>; that's the name of the entry in the JSON payload. This mechanism is common to all Sensu config, not just handler plugins. Documentation is here: <a href=""https://docs.sensu.io/sensu-core/1.8/reference/configuration/"" rel=""nofollow noreferrer"">https://docs.sensu.io/sensu-core/1.8/reference/configuration/</a>.</p>

<p>I looked at my log files, and it does seem to be finding and loading the files I had optimistically placed under <code>/etc/sensu/conf.d/teams.d/</code>, but it's not working.</p>

<p>Before I found the answer documented here, I took a stab and renamed the directory from <code>teams.d</code> to <code>microsoft-teams.d</code>, and the configuration object defined within from <code>teams</code> to <code>microsoft-teams</code>. I don't know why that would have had any effect, but it's working now. Maybe I had fat-fingered or copypasta'd something and resolved that inadvertently in the process of adding the <code>microsoft</code> prefix.</p>
",17284,2019-09-25T18:32:26.680,"['def get_setting(name)\n  settings[config[:json_config]][name]\nend\n', ""module Sensu\n  module Plugin\n    module Utils # rubocop:disable Metrics/ModuleLength\n      def config_files\n        if ENV['SENSU_LOADED_TEMPFILE'] && File.file?(ENV['SENSU_LOADED_TEMPFILE'])\n          IO.read(ENV['SENSU_LOADED_TEMPFILE']).split(':')\n        elsif ENV['SENSU_CONFIG_FILES']\n          ENV['SENSU_CONFIG_FILES'].split(':')\n        else\n          ['/etc/sensu/config.json'] + Dir['/etc/sensu/conf.d/**/*.json']\n        end\n      end\n\n      def load_config(filename)\n        JSON.parse(File.open(filename, 'r').read)\n      rescue\n        {}\n      end\n\n      def settings\n        @settings ||= config_files.map { |f| load_config(f) }.reduce { |a, b| deep_merge(a, b) }\n      end\n...\n""]"
1001,9282,9260,CC BY-SA 4.0,2019-09-25T18:40:51.667,"<p>If under unix, with gcloud SDK you can execute the following script:</p>

<pre><code>export expected_permission=billing.accounts.updateUsageExportSpec

for role in $(gcloud iam roles list --format='value(NAME)');                                     
do permissions=$(gcloud iam roles describe $role --format='value(includedPermissions)')
if [[ $permissions =~ $expected_permission  ]]; then echo ""-------------------------------------------------"" &amp;&amp;  echo $role &amp;&amp; echo ""-------------------------------------------------""; fi
done
</code></pre>

<p>Either way, there's <a href=""https://cloud.google.com/iam/docs/permissions-reference"" rel=""nofollow noreferrer"">this reference</a> in official docs where permission/roles mapping can be shown</p>
",8125,2019-09-25T18:40:51.667,"['export expected_permission=billing.accounts.updateUsageExportSpec\n\nfor role in $(gcloud iam roles list --format=\'value(NAME)\');                                     \ndo permissions=$(gcloud iam roles describe $role --format=\'value(includedPermissions)\')\nif [[ $permissions =~ $expected_permission  ]]; then echo ""-------------------------------------------------"" &&  echo $role && echo ""-------------------------------------------------""; fi\ndone\n']"
1002,9286,9285,CC BY-SA 4.0,2019-09-26T09:00:56.413,"<p>Looking at your code it seems you try to connect to a Windows host. Usually you connect windows via <code>WinRM</code> and not via ssh</p>

<p>The user guide for this can be found here: <a href=""https://docs.ansible.com/ansible/latest/user_guide/windows_winrm.html"" rel=""nofollow noreferrer"">https://docs.ansible.com/ansible/latest/user_guide/windows_winrm.html</a></p>

<blockquote>
  <p>For Ansible to communicate to a Windows host and use Windows modules, the Windows host must meet the following requirements:</p>
  
  <ul>
  <li>Ansible’s supported Windows versions generally match those under current and extended support from Microsoft. Supported desktop OSs include Windows 7, 8.1, and 10, and supported server OSs are Windows Server 2008, 2008 R2, 2012, 2012 R2, 2016, and 2019.</li>
  <li>Ansible requires PowerShell 3.0 or newer and at least .NET 4.0 to be installed on the Windows host.</li>
  <li>A WinRM listener should be created and activated. More details for this can be found below.</li>
  </ul>
</blockquote>

<p>Then you need to tell ansible to connect wia <code>winrm</code></p>

<pre><code>...
ansible_connection=winrm
...
</code></pre>

<p>Checkout the details here: <a href=""https://www.ansible.com/blog/connecting-to-a-windows-host"" rel=""nofollow noreferrer"">https://www.ansible.com/blog/connecting-to-a-windows-host</a></p>
",4852,2019-09-26T09:00:56.413,['...\nansible_connection=winrm\n...\n']
1003,9292,9241,CC BY-SA 4.0,2019-09-26T20:57:50.930,"<p>What your are describing can typically be addressed with a correct inventory design.</p>

<pre><code>[zone1]
serverA
serverB
serverC

[zone2]
server1
server2
server3

[zone3]
serverX
serverY
serverZ

[jenkins_master]
serverA
server1
serverX

[jenkins_slave]
serverB
serverC
server2
server3
serverY
serverZ
</code></pre>

<p>From there you can easily:</p>

<ul>
<li>create <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks.html"" rel=""nofollow noreferrer"">plays</a> that will target a group or a <a href=""https://docs.ansible.com/ansible/latest/user_guide/intro_patterns.html"" rel=""nofollow noreferrer"">pattern</a> and that you can limit to an other group or pattern at runtime, e.g. target <code>jenkins_master</code> and run the playbook on all of them or limit it to <code>zone1</code>.</li>
<li>create inventory vars for your hosts and groups so that e.g. servers in <code>zone1</code> will know what is the uri of the master in that zone.</li>
</ul>

<p>This is a super-quick overlook. I suggest you read in depth <a href=""https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html"" rel=""nofollow noreferrer"">working with inventory</a> to get a better understanding of all the inventory concepts and pay attention to the part concerning the <a href=""https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#organizing-host-and-group-variables"" rel=""nofollow noreferrer"">organization of variables in the inventory for groups and hosts</a></p>
",13111,2019-10-29T10:23:49.677,['[zone1]\nserverA\nserverB\nserverC\n\n[zone2]\nserver1\nserver2\nserver3\n\n[zone3]\nserverX\nserverY\nserverZ\n\n[jenkins_master]\nserverA\nserver1\nserverX\n\n[jenkins_slave]\nserverB\nserverC\nserver2\nserver3\nserverY\nserverZ\n']
1004,9296,9276,CC BY-SA 4.0,2019-09-27T10:57:58.580,"<p>Your default security groups and newly created security groups include default rules that <strong>do not enable you to access your instance from the Internet</strong>.
Add this:</p>

<pre><code>
resource ""aws_security_group"" ""allow-ssh"" {
  vpc_id = ""${aws_vpc.vpc.id}""

  ingress {
    from_port = 0
    to_port = 22
    protocol = ""tcp""
  }
}
</code></pre>

<p>Then add the line <code>vpc_security_group_ids = [aws_security_group.allow-ssh.id]</code> to the instance definitions.</p>
",9609,2019-09-27T10:57:58.580,"['\nresource ""aws_security_group"" ""allow-ssh"" {\n  vpc_id = ""${aws_vpc.vpc.id}""\n\n  ingress {\n    from_port = 0\n    to_port = 22\n    protocol = ""tcp""\n  }\n}\n']"
1005,9310,3866,CC BY-SA 4.0,2019-09-30T13:44:30.030,"<p>Sometimes it is easier to ask forgiveness than permission.</p>

<p>Instead of trying to figure out whether branch <code>b</code> exists, just try to check it out.  </p>

<p>If it fails, checkout branch <code>a</code>.</p>

<pre><code>script {
    try {
        checkout([
                $class: 'GitSCM',
                branches: [[name: 'b']],
                userRemoteConfigs: [[url: url]]
        ])
    }
    catch (Exception e) {
        checkout([
                $class: 'GitSCM',
                branches: [[name: 'a']],
                userRemoteConfigs: [[url: url]]
        ])
    }
}
</code></pre>
",9373,2019-09-30T13:44:30.030,"[""script {\n    try {\n        checkout([\n                $class: 'GitSCM',\n                branches: [[name: 'b']],\n                userRemoteConfigs: [[url: url]]\n        ])\n    }\n    catch (Exception e) {\n        checkout([\n                $class: 'GitSCM',\n                branches: [[name: 'a']],\n                userRemoteConfigs: [[url: url]]\n        ])\n    }\n}\n""]"
1006,9317,9311,CC BY-SA 4.0,2019-10-01T03:47:24.123,"<p>There is stages in gitlab ci and on 'docker build' stage I don't need ALL env variables. Usually its only a REACT_APP_SERVER_URI variable.
Later I use env file in compose.yml like you are. </p>

<pre><code>env_file:
  - ./envs/common.env
</code></pre>
",12833,2019-10-01T03:47:24.123,['env_file:\n  - ./envs/common.env\n']
1007,9346,3155,CC BY-SA 4.0,2019-10-03T13:02:19.680,"<p>chipping in with ansible task to install letsencrypt certbot on debian stretch</p>

<pre><code>---
- name: Add ""stretch-backports"" to APT sources (required for Certbot)
  become: yes
  apt_repository:
    repo: deb http://httpredir.debian.org/debian stretch-backports main
    state: present
    update_cache: yes

- name: ""Check LetsEncrypt/Certbot is installed""
  become: yes
  apt:
    name: 
      - certbot
      - python-certbot-apache # https://github.com/certbot/certbot/issues/3854
    state: present
    default_release: stretch-backports
    cache_valid_time: 3600
    update_cache: yes
</code></pre>
",17178,2019-10-03T13:02:19.680,"['---\n- name: Add ""stretch-backports"" to APT sources (required for Certbot)\n  become: yes\n  apt_repository:\n    repo: deb http://httpredir.debian.org/debian stretch-backports main\n    state: present\n    update_cache: yes\n\n- name: ""Check LetsEncrypt/Certbot is installed""\n  become: yes\n  apt:\n    name: \n      - certbot\n      - python-certbot-apache # https://github.com/certbot/certbot/issues/3854\n    state: present\n    default_release: stretch-backports\n    cache_valid_time: 3600\n    update_cache: yes\n']"
1008,9347,9340,CC BY-SA 4.0,2019-10-03T14:23:18.360,"<p>Since goss can use variables from a yaml or json file, I just modified the <code>verify.yml</code> example playbook to export this variable and use it in the goss command.</p>

<pre><code>- name: Verify
  hosts: all
  become: true
  vars:
    [...]
    goss_vars: ""{{ goss_test_directory }}/vars""
  tasks:
    [...]
    - name: Register hostvars
      copy:
        content: ""{'hostvars': {{ hostvars }}}""
        dest: ""{{ goss_vars }}""

    - name: Execute Goss tests
      command: ""{{ goss_bin }} --vars {{ goss_vars }} -g {{ item }} validate --format {{ goss_format }}""
      register: test_results
      with_items: ""{{ test_files.stdout_lines }}""
      failed_when: false

    [...]
</code></pre>

<p>Then the variable is available in goss test files as <code>{{ .Vars.hostvars }}</code>.</p>
",17413,2019-10-03T14:23:18.360,"['- name: Verify\n  hosts: all\n  become: true\n  vars:\n    [...]\n    goss_vars: ""{{ goss_test_directory }}/vars""\n  tasks:\n    [...]\n    - name: Register hostvars\n      copy:\n        content: ""{\'hostvars\': {{ hostvars }}}""\n        dest: ""{{ goss_vars }}""\n\n    - name: Execute Goss tests\n      command: ""{{ goss_bin }} --vars {{ goss_vars }} -g {{ item }} validate --format {{ goss_format }}""\n      register: test_results\n      with_items: ""{{ test_files.stdout_lines }}""\n      failed_when: false\n\n    [...]\n']"
1009,9349,9344,CC BY-SA 4.0,2019-10-03T18:06:16.047,"<p><strong>SOLUTION APPROACH</strong></p>

<p>The approach is to create a macvlan. This will create a virtual adapter, that is allowed to lease an IP address from the subnet defined.</p>

<p><strong>1) Activate Promiscous Mode</strong></p>

<p>For the virtual adapter one must enable promiscuous mode in the network. For Unifi controllers, do a SSH to your gateway and set:</p>

<pre><code>ifconfig [interface] promisc
</code></pre>

<p>Some network gateways/controllers have set promiscuous mode by default. Continue with step 2 before you're wasting time to find that out.</p>

<p><strong>2) Create macvlan</strong></p>

<p>Then one can create the macvlan.</p>

<pre><code>$ docker network create -d macvlan \
  --subnet=192.168.2.0/23 \
  --ip-range=192.168.2.5/25 \
  --gateway=192.168.2.1 \
  --aux-address=""my-router=192.168.2.10"" \
  -o parent=eth0 unifinet
</code></pre>

<ul>
<li><p>Limiting the IP range: use <code>--ip-range</code> to scope the possible IPs to lease.</p></li>
<li><p>Avoiding certain IPs: The <code>--aux-address</code> marks my Synology host, which should never ever battle for that IP address (It's marked in the unifi controller's DHCP service as a fixed IP anyways).</p></li>
<li>the <code>-o parent</code> is your network interface you want to attach your macvlan. In my case <code>unifinet</code>.</li>
</ul>

<p>Check with <code>docker network ls</code> if the macvlan has been properly created.</p>

<pre><code>NETWORK ID          NAME                DRIVER              SCOPE
c49094a4c914        bridge              bridge              local
b2315de1aa7e        host                host                local
c124eda0f9d2        none                null                local
a60da50f0d12        unifinet            macvlan             local
</code></pre>

<p><strong>3) Start Docker Container</strong></p>

<p>While you define the image (--name UnifiController jacobalberty/unifi) assign the freshly created macvlan (--network unifinet) to the container (UnifiController). It will grab the latest image respectively the latest Unifi Controller version available from Docker Hub.</p>

<pre><code>docker run -dit --network unifinet --name UnifiController jacobalberty/unifi
</code></pre>

<p>Verify if the container has been assigned to the network in the container section of the JSON config.</p>

<pre><code>sudo docker network inspect unifinet.

[
    {
        ""Name"": ""unifinet"",
        ""Id"": ""a60da50f0d1229d1a3c76210141e0c81567c17daf6c2b49d4f1c83d5ec9f02b3"",
        ""Created"": ""2019-10-04T14:39:37.377311991+02:00"",
        ""Scope"": ""local"",
        ""Driver"": ""macvlan"",
        ""EnableIPv6"": false,
        ""IPAM"": {
            ""Driver"": ""default"",
            ""Options"": {},
            ""Config"": [
                {
                    ""Subnet"": ""192.168.2.0/24"",
                    ""Gateway"": ""192.168.2.1""
                }
            ]
        },
        ""Internal"": false,
        ""Attachable"": false,
        ""Ingress"": false,
        ""ConfigFrom"": {
            ""Network"": """"
        },
        ""ConfigOnly"": false,
        ""Containers"": {
            ""b819bf1d6f3af459825a1a7b58f9a44e15e6e09489e7bf50653ed8e1e176fd73"": {
                ""Name"": ""UnifiController"",
                ""EndpointID"": ""41a048034ad63e48b46b58aed65661c9eaa2bf6937d3eebacefde4478ad26cce"",
                ""MacAddress"": ""02:42:c0:a8:02:02"",
                ""IPv4Address"": ""192.168.2.2/24"",
                ""IPv6Address"": """"
            }
        },
        ""Options"": {
            ""parent"": ""eth0""
        },
        ""Labels"": {}
    }
]
</code></pre>

<p>The IP 192.168.2.2 is assigned. The container workes properly and stable. </p>

<p><strong>4) Optional/Reminder</strong></p>

<p>If the IP was not assigned respectively one cannot connect to it for any service, the follow up on the promiscious mode setting as described in Step 1.</p>
",17415,2019-10-04T14:03:32.790,"['ifconfig [interface] promisc\n', '$ docker network create -d macvlan \\\n  --subnet=192.168.2.0/23 \\\n  --ip-range=192.168.2.5/25 \\\n  --gateway=192.168.2.1 \\\n  --aux-address=""my-router=192.168.2.10"" \\\n  -o parent=eth0 unifinet\n', 'NETWORK ID          NAME                DRIVER              SCOPE\nc49094a4c914        bridge              bridge              local\nb2315de1aa7e        host                host                local\nc124eda0f9d2        none                null                local\na60da50f0d12        unifinet            macvlan             local\n', 'docker run -dit --network unifinet --name UnifiController jacobalberty/unifi\n', 'sudo docker network inspect unifinet.\n\n[\n    {\n        ""Name"": ""unifinet"",\n        ""Id"": ""a60da50f0d1229d1a3c76210141e0c81567c17daf6c2b49d4f1c83d5ec9f02b3"",\n        ""Created"": ""2019-10-04T14:39:37.377311991+02:00"",\n        ""Scope"": ""local"",\n        ""Driver"": ""macvlan"",\n        ""EnableIPv6"": false,\n        ""IPAM"": {\n            ""Driver"": ""default"",\n            ""Options"": {},\n            ""Config"": [\n                {\n                    ""Subnet"": ""192.168.2.0/24"",\n                    ""Gateway"": ""192.168.2.1""\n                }\n            ]\n        },\n        ""Internal"": false,\n        ""Attachable"": false,\n        ""Ingress"": false,\n        ""ConfigFrom"": {\n            ""Network"": """"\n        },\n        ""ConfigOnly"": false,\n        ""Containers"": {\n            ""b819bf1d6f3af459825a1a7b58f9a44e15e6e09489e7bf50653ed8e1e176fd73"": {\n                ""Name"": ""UnifiController"",\n                ""EndpointID"": ""41a048034ad63e48b46b58aed65661c9eaa2bf6937d3eebacefde4478ad26cce"",\n                ""MacAddress"": ""02:42:c0:a8:02:02"",\n                ""IPv4Address"": ""192.168.2.2/24"",\n                ""IPv6Address"": """"\n            }\n        },\n        ""Options"": {\n            ""parent"": ""eth0""\n        },\n        ""Labels"": {}\n    }\n]\n']"
1010,9353,8627,CC BY-SA 4.0,2019-10-03T23:29:41.693,"<p>This is not answering only the question but also a bit more (I put this here for reference):<br>
I found out a decent way to tackle this and some complications coming afterwards... (after hours and hours of fiddling) - e.g. to execute the script in an SSH session:</p>

<pre class=""lang-yaml prettyprint-override""><code>deploy job:
  variables:
    # the variables could come from anywhere (e.g. GitLab Settings - environment variables)
    SSH_DIR: '/srv/app/'
    SCRIPT_CMD: |
      echo ""Double quotes are safe""
      echo 'Single quotes are safe'
      echo ""Code executions are safe -"" `whoami`@`hostname` $$(date)
      # the '$$' is needed as otherwise GitLab itself tries variable substitution

  # Here's the magic to get the code from the GitLab variable into a bash variable and then even executed on an SSH session
  script:
    # Put gitlab variable into shell variable to improve quote handling
    - CMD=$SCRIPT_CMD
    # Print for debugging
    - echo -e ""Executing:\n$CMD""
    - CMD=""set -e; cd $SSH_DIR; $CMD"" # 'set -e' = stop on error
    # redirect variable to stdin of ssh bash (the -x causes bash to print each command)
    - ssh -p $SSH_PORT $USERNAME@$SSH_HOST ""bash -x"" &lt;&lt;&lt; ""$CMD""

</code></pre>

<p>More detailed example <a href=""https://gist.github.com/TeNNoX/cd8d4b901775f379d74287fa85f924c3"" rel=""nofollow noreferrer"">here</a>.</p>
",17433,2019-10-03T23:44:18.603,"['deploy job:\n  variables:\n    # the variables could come from anywhere (e.g. GitLab Settings - environment variables)\n    SSH_DIR: \'/srv/app/\'\n    SCRIPT_CMD: |\n      echo ""Double quotes are safe""\n      echo \'Single quotes are safe\'\n      echo ""Code executions are safe -"" `whoami`@`hostname` $$(date)\n      # the \'$$\' is needed as otherwise GitLab itself tries variable substitution\n\n  # Here\'s the magic to get the code from the GitLab variable into a bash variable and then even executed on an SSH session\n  script:\n    # Put gitlab variable into shell variable to improve quote handling\n    - CMD=$SCRIPT_CMD\n    # Print for debugging\n    - echo -e ""Executing:\\n$CMD""\n    - CMD=""set -e; cd $SSH_DIR; $CMD"" # \'set -e\' = stop on error\n    # redirect variable to stdin of ssh bash (the -x causes bash to print each command)\n    - ssh -p $SSH_PORT $USERNAME@$SSH_HOST ""bash -x"" <<< ""$CMD""\n\n']"
1011,9356,5254,CC BY-SA 4.0,2019-10-04T21:46:21.603,"<p>You just have to use the hostname on your docker compose file like this:</p>

<pre><code>hostname: whatever-{{.Node.Hostname}}
</code></pre>

<p>Note that you have to prepend something to the hostname to avoid hostnames duplicates. </p>
",17449,2019-10-05T16:02:51.783,['hostname: whatever-{{.Node.Hostname}}\n']
1012,9370,9342,CC BY-SA 4.0,2019-10-07T07:57:14.783,"<p>OK, a good week-end does its job as usual: My issue was indeed caused by my company proxy (a good thing would be to add this requirement in the jenkins doc, i might have  missed it anyway).
So the fix is actually simple, just need to add the correct options to the jenkins start command, as in:</p>

<pre><code>-Dhttp.proxyHost=&lt;your_proxy_ip_here&gt; -Dhttp.proxyPort=&lt;your_proxy_port_here&gt; -Dhttps.proxyHost=&lt;your_proxy_ip_here&gt; -Dhttps.proxyPort=&lt;your_proxy_port_here&gt;
</code></pre>

<p>Full example:</p>

<pre><code>/usr/bin/java -Djava.net.preferIPv4Stack=true -Dhttp.proxyHost=10.21.92.40 -Dhttp.proxyPort=3128 -Dhttps.proxyHost=10.21.92.40 -Dhttps.proxyPort=3128 -jar /usr/share/jenkins/jenkins.war --webroot=/var/cache/jenkins/war --httpPort=8080
</code></pre>

<p>tcpdump was the savior here (+ a colleague :) )</p>
",6356,2019-10-07T07:57:14.783,"['-Dhttp.proxyHost=<your_proxy_ip_here> -Dhttp.proxyPort=<your_proxy_port_here> -Dhttps.proxyHost=<your_proxy_ip_here> -Dhttps.proxyPort=<your_proxy_port_here>\n', '/usr/bin/java -Djava.net.preferIPv4Stack=true -Dhttp.proxyHost=10.21.92.40 -Dhttp.proxyPort=3128 -Dhttps.proxyHost=10.21.92.40 -Dhttps.proxyPort=3128 -jar /usr/share/jenkins/jenkins.war --webroot=/var/cache/jenkins/war --httpPort=8080\n']"
1013,9372,9144,CC BY-SA 4.0,2019-10-07T15:00:06.757,"<p>I also use the classic editor, and I have implemented this for our builds. My use case was that I have a set of common set of build/release scripts stored in their own repository, and I want the ability to bring them into the application builds that I am executing.</p>

<p>I created a custom <strong>Task Group</strong> with an <strong>Inline PowerShell script</strong> to do this:</p>

<pre><code># Reference: https://blog.rsuter.com/script-to-clone-all-git-repositories-from-your-vsts-collection/
Write-Host ""Cloning MyRepo from Azure DevOps...""

$sourcesDir = $env:SYSTEM_DEFAULTWORKINGDIRECTORY
Write-Host ""Source directory: $sourcesDir""
$repoDir = Join-Path -Path ""$sourcesDir"" -ChildPath ""MyRepo""
Write-Host ""Target directory: $repoDir""

$url = ""https://dev.azure.com/my_org/my_team_project/_git/MyRepo""

# Since using PAT, don't need real username, just non-empty username. Use ""x"".
$username = ""x""
$pat = $env:PAT # passed into inline script as environment variable
$credentials = (""{0}:{1}"" -f  $username, $pat)
$urlWithCreds = $url -Replace ""://"", (""://{0}@"" -f $credentials)
Write-Host ""Clone URL: $urlWithCreds""

git --version
git clone --progress $urlWithCreds
Set-Location ""$repoDir""
git checkout master
git log -1 # show the latest commit
</code></pre>

<p>You will have to create a PAT with code permissions and pass it into the script as an environment variable. This task will clone the repository to a directory of the same name <em>within</em> your existing repo.</p>

<p>Putting it in a task group allows me to manage it in one place, and then all my more complicated build scripts can be under version control.</p>

<p>There is an active feature request for the capability to source from multiple repos. It looks like it is in the roadmap: <a href=""https://developercommunity.visualstudio.com/idea/365522/allow-tfs-build-to-depend-on-multiple-repositories.html"" rel=""nofollow noreferrer"">https://developercommunity.visualstudio.com/idea/365522/allow-tfs-build-to-depend-on-multiple-repositories.html</a></p>
",11069,2019-10-07T15:00:06.757,"['# Reference: https://blog.rsuter.com/script-to-clone-all-git-repositories-from-your-vsts-collection/\nWrite-Host ""Cloning MyRepo from Azure DevOps...""\n\n$sourcesDir = $env:SYSTEM_DEFAULTWORKINGDIRECTORY\nWrite-Host ""Source directory: $sourcesDir""\n$repoDir = Join-Path -Path ""$sourcesDir"" -ChildPath ""MyRepo""\nWrite-Host ""Target directory: $repoDir""\n\n$url = ""https://dev.azure.com/my_org/my_team_project/_git/MyRepo""\n\n# Since using PAT, don\'t need real username, just non-empty username. Use ""x"".\n$username = ""x""\n$pat = $env:PAT # passed into inline script as environment variable\n$credentials = (""{0}:{1}"" -f  $username, $pat)\n$urlWithCreds = $url -Replace ""://"", (""://{0}@"" -f $credentials)\nWrite-Host ""Clone URL: $urlWithCreds""\n\ngit --version\ngit clone --progress $urlWithCreds\nSet-Location ""$repoDir""\ngit checkout master\ngit log -1 # show the latest commit\n']"
1014,9380,3757,CC BY-SA 4.0,2019-10-08T08:35:34.737,"<p>I had the same problem, after I updated certbot on OS X I could not get the digitalocean plugin to appear, even after re-installing it with <code>pip install certbot-dns-digitalocean</code>.</p>

<p>The solution was to uninstall it and then re-install it. I used sudo just to be safe:</p>

<pre><code>sudo pip uninstall certbot-dns-digitalocean 
sudo pip install certbot-dns-digitalocean
</code></pre>

<p>It then appeared ok in the <code>certbot plugins</code> list.</p>
",17502,2019-10-08T08:35:34.737,['sudo pip uninstall certbot-dns-digitalocean \nsudo pip install certbot-dns-digitalocean\n']
1015,9384,863,CC BY-SA 4.0,2019-10-08T15:59:11.523,"<p>I saw this elegant, low tech method to test Terraform suggested by <a href=""https://github.com/apparentlymart"" rel=""nofollow noreferrer"">apparentlymart</a> in a GitHub issue thread. It's not a appropriate for every situation but it's great for verifying module logic.</p>

<p>Create a root module that includes the module under test and verifies the under-test outputs. Here is a simple example using two files:</p>

<ul>
<li><code>main.tf</code> that will run the tests</li>
<li><code>simple_module/outputs.tf</code> that represents a module under test</li>
</ul>

<h2>./main.tf</h2>

<pre><code>terraform {
  required_version = ""&gt;= 0.12""
}

module ""simple_module"" {
  source = ""./simple_module""
}

locals {
  expected = 1
  got      = module.simple_module.module-returns-1
}

# Test Output
output ""expect-1"" {
  value = upper(local.expected == local.got)
}

output ""expect-other"" {
  value = ""other"" == local.got ? upper(true) : ""FALSE. Got ${local.got}""
}
</code></pre>

<h2>./simple_module/outputs.tf</h2>

<pre><code>output ""module-returns-1"" {
  value = 1
}
</code></pre>

<h2>Run the tests</h2>

<pre><code>terraform init
terraform apply -auto-approve
</code></pre>

<pre><code>Apply complete! Resources: 0 added, 0 changed, 0 destroyed.

Outputs:

expect-1 = TRUE
expect-other = FALSE. Got 1
</code></pre>
",17512,2019-10-08T15:59:11.523,"['terraform {\n  required_version = "">= 0.12""\n}\n\nmodule ""simple_module"" {\n  source = ""./simple_module""\n}\n\nlocals {\n  expected = 1\n  got      = module.simple_module.module-returns-1\n}\n\n# Test Output\noutput ""expect-1"" {\n  value = upper(local.expected == local.got)\n}\n\noutput ""expect-other"" {\n  value = ""other"" == local.got ? upper(true) : ""FALSE. Got ${local.got}""\n}\n', 'output ""module-returns-1"" {\n  value = 1\n}\n', 'terraform init\nterraform apply -auto-approve\n', 'Apply complete! Resources: 0 added, 0 changed, 0 destroyed.\n\nOutputs:\n\nexpect-1 = TRUE\nexpect-other = FALSE. Got 1\n']"
1016,9408,9405,CC BY-SA 4.0,2019-10-10T19:40:34.530,"<p>After some more time I found my answer.</p>

<p>The service I wanted to deploy was a slightly different version of a service we already have. Stack file for the ""original"" service:</p>

<pre><code>version: '3.7'

services:
my-service:
    image: my-repo:port/company/my-service
    ports:
    - 81:81
    networks:
    - my-network
    deploy:
    replicas: 1
    restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
networks:
my-network:
    driver: overlay
    internal: false
    attachable: true
    ipam:
    driver: default
    config:
        - subnet: 10.1.99.0/24
</code></pre>

<p>We took <strong>the same file</strong> but on a different git branch to deploy the slightly altered version (as makes sense from a ""code"" perspective).</p>

<p>From a Docker perspective this meant however that the stack with the original service with the <strong>exact same network definition</strong> was still running and we deployed another stack with <strong>the exact same network definition</strong> again, which lead to the service never being scheduled as, apparently, you must not re-declare the same network twice.</p>

<p>Of course it will get a different network name, but the overlay/subnet config will be identical.</p>

<p>It would be nice of Docker to inform you of this when you're trying to do that, but, as it so often is: Crap in, crap out. Our fault!</p>

<p>For future readers who do not have the exact same problem but their containers are getting stuck in ""new"" state: It might be safe to assume that it has something to do with your stack-file, your network definition or even something like correct YAML indentation. It is most certainly something ""meta"" and not something related to your Docker host and specifically not your image or your container (as when the task is stuck in ""new"" state, there is not even a container in existence as it never got scheduled).</p>
",7646,2019-10-10T19:40:34.530,"[""version: '3.7'\n\nservices:\nmy-service:\n    image: my-repo:port/company/my-service\n    ports:\n    - 81:81\n    networks:\n    - my-network\n    deploy:\n    replicas: 1\n    restart_policy:\n        condition: on-failure\n        delay: 5s\n        max_attempts: 3\n        window: 120s\nnetworks:\nmy-network:\n    driver: overlay\n    internal: false\n    attachable: true\n    ipam:\n    driver: default\n    config:\n        - subnet: 10.1.99.0/24\n""]"
1017,9412,9339,CC BY-SA 4.0,2019-10-11T13:34:43.093,"<blockquote>
  <p>the definition of the replicated pods are always a copy-paste of a pod template file</p>
</blockquote>

<p>This behavior is implemented by Kubernetes itself: it takes the <code>template</code> part of the deployment spec and creates <code>replicas</code> identical pods.</p>

<p>The corollary to this is that you don't need to manually write out the pod spec as a separate object.  Including it in the <code>template</code> part of a deployment (job, statefulset, daemonset) is enough.</p>

<blockquote>
  <p>Is it possible to rather use a reference to the yaml file (or an url) defining a pod</p>
</blockquote>

<p>No, individual Kubernetes objects must be self-contained (except where there are facilities to do things like inject Secret values into environment variables).  The Kubernetes server doesn't know about your local file system.</p>

<p>Using one of the templating systems out there (<a href=""https://helm.sh/"" rel=""nofollow noreferrer"">Helm</a> is more-or-less standard but not the only choice) could help reduce this duplication, if you really need near-identical deployments and also bare pods.  You could write something like</p>

<pre><code>---
apiVersion: v1
kind: Pod
{{ template ""pod-spec"" . }}
---
apiVersion: apps/v1
kind: Deployment
spec:
  template:
{{ include ""pod-spec"" . | trim | indent 4 }}
</code></pre>
",17579,2019-10-11T13:34:43.093,"['---\napiVersion: v1\nkind: Pod\n{{ template ""pod-spec"" . }}\n---\napiVersion: apps/v1\nkind: Deployment\nspec:\n  template:\n{{ include ""pod-spec"" . | trim | indent 4 }}\n']"
1018,9415,413,CC BY-SA 4.0,2019-10-11T23:50:02.293,"<p>Use <code>docker ps</code> to check the current running containers. For example:</p>
<pre><code>FROM ubuntu16
    
MAINTAINER sreeni (email/domain)
    
RUN apt-get update
    
RUN apt-get install -y nginx
    
ENTRYPOINT [“/usr/sbin/nginx”,”-g”,”daemon off;”]
    
EXPOSE 80 (port)
</code></pre>
<p>Use below docker command to run the container:</p>
<pre><code>docker run -d -p 80:80 --name web server ubuntu16
</code></pre>
<p>After that, check localhost or ip address:80 (open browser and check)</p>
",11341,2020-09-09T07:23:11.723,"['FROM ubuntu16\n    \nMAINTAINER sreeni (email/domain)\n    \nRUN apt-get update\n    \nRUN apt-get install -y nginx\n    \nENTRYPOINT [“/usr/sbin/nginx”,”-g”,”daemon off;”]\n    \nEXPOSE 80 (port)\n', 'docker run -d -p 80:80 --name web server ubuntu16\n']"
1019,9420,9402,CC BY-SA 4.0,2019-10-14T08:31:19.293,"<p>Eventually I just got rid of the group_vars all together.
I specified a new role that includes several other roles with 'include_role:' and added the vars directly to those roles with inline-vault variables:</p>

<pre><code>- name: include ipaclient
  include_role:
    name: ipaclient
  vars:
    my_user: user
    my_password: !vault |
          $ANSIBLE_VAULT;1.1;AES256
          123456123456123456123456123456132456...
</code></pre>
",17556,2019-10-14T08:31:19.293,['- name: include ipaclient\n  include_role:\n    name: ipaclient\n  vars:\n    my_user: user\n    my_password: !vault |\n          $ANSIBLE_VAULT;1.1;AES256\n          123456123456123456123456123456132456...\n']
1020,9432,9427,CC BY-SA 4.0,2019-10-14T14:53:23.377,"<p>You'll want to look through the Kubernetes <a href=""https://kubernetes.io/docs/concepts/storage/volumes/"" rel=""nofollow noreferrer"">Volume documentation</a> to see what options are available.</p>

<p>In particular look into the <a href=""https://kubernetes.io/docs/concepts/storage/volumes/#persistentvolumeclaim"" rel=""nofollow noreferrer"">PersistentVolumeClaim</a>.  This allows you to setup a shared data volume for your pods.  Here's an example snippet from a k8s deployment YAML using a volume:</p>

<pre><code>spec:
      containers:
      - image: **yourdbcontainer**
        name: mysql-db
        env:
        - name: example
          value: example_value
        ports:
        - containerPort: 3306
          name: mysql-db
        volumeMounts:
        - name: mysql-persistent-storage
          mountPath: /var/lib/mysql
      volumes:
      - name: mysql-persistent-storage
        persistentVolumeClaim:
          claimName: mysql-pv-claim
</code></pre>
",15792,2019-10-14T14:53:23.377,['spec:\n      containers:\n      - image: **yourdbcontainer**\n        name: mysql-db\n        env:\n        - name: example\n          value: example_value\n        ports:\n        - containerPort: 3306\n          name: mysql-db\n        volumeMounts:\n        - name: mysql-persistent-storage\n          mountPath: /var/lib/mysql\n      volumes:\n      - name: mysql-persistent-storage\n        persistentVolumeClaim:\n          claimName: mysql-pv-claim\n']
1021,9446,9359,CC BY-SA 4.0,2019-10-15T18:15:33.080,"<p>I might have skipped the optional installation of docker in my Ubuntu instance, so if the gitlab runner is going to use Docker, remember to install it:</p>

<pre><code>curl -sSL https://get.docker.com/ | sh
</code></pre>

<p>I got back to this issue and seem to have partially fixed it by checking it the gitlab runner is running</p>

<pre><code>gitlab-runner status

systemctl is-enabled gitlab-runner

systemctl is-enabled docker
</code></pre>

<p>I do have a different issue to solve, but it doesn't seem to be related. That is:</p>

<pre><code>error during connect: Post http://docker:2375/v1.40/images/ [...] dial tcp: lookup docker on xx.xxx.xx.x:xx: no such host
</code></pre>

<p>Then I found the solution, there's a problem in Gitlab CI that is reported here ( <a href=""https://gitlab.com/gitlab-org/gitlab-runner/issues/4566#note_199261985"" rel=""noreferrer"">https://gitlab.com/gitlab-org/gitlab-runner/issues/4566#note_199261985</a> ); And there are a lot of ways to fix this but my solution follows:</p>

<p>1) Set the <code>.gitlab-ci.yml</code> services to use an older dind version:</p>

<pre><code>services:
  - docker:18.09.7-dind
</code></pre>

<p>2) Check the toml file <code>/etc/gitlab-runner/config.toml</code>, set the DOCKER_HOST just in case, to point to the right place, make sure it runs in <code>privileged</code> mode. My working version is:</p>

<pre><code>concurrent = 1
check_interval = 0

[session_server]
  session_timeout = 1800

[[runners]]
  name = ""xxxxxx xxxxxxxx""
  url = ""https://gitlab.com/""
  token = ""xxxxxxxxxx""
  executor = ""docker""
  pre_build_script = ""export DOCKER_HOST=tcp://docker:2375""
  [runners.custom_build_dir]
  [runners.docker]
    tls_cert_path = """"
    tls_verify = false
    image = ""alpine:latest""
    privileged = true
    disable_entrypoint_overwrite = false
    oom_kill_disable = false
    disable_cache = false
    volumes = [""/cache""]
    shm_size = 0
  [runners.cache]
    [runners.cache.s3]
    [runners.cache.gcs]
</code></pre>

<p>Hope this helps someone else in the future!</p>
",17458,2019-10-17T10:57:30.357,"['curl -sSL https://get.docker.com/ | sh\n', 'gitlab-runner status\n\nsystemctl is-enabled gitlab-runner\n\nsystemctl is-enabled docker\n', 'error during connect: Post http://docker:2375/v1.40/images/ [...] dial tcp: lookup docker on xx.xxx.xx.x:xx: no such host\n', 'services:\n  - docker:18.09.7-dind\n', 'concurrent = 1\ncheck_interval = 0\n\n[session_server]\n  session_timeout = 1800\n\n[[runners]]\n  name = ""xxxxxx xxxxxxxx""\n  url = ""https://gitlab.com/""\n  token = ""xxxxxxxxxx""\n  executor = ""docker""\n  pre_build_script = ""export DOCKER_HOST=tcp://docker:2375""\n  [runners.custom_build_dir]\n  [runners.docker]\n    tls_cert_path = """"\n    tls_verify = false\n    image = ""alpine:latest""\n    privileged = true\n    disable_entrypoint_overwrite = false\n    oom_kill_disable = false\n    disable_cache = false\n    volumes = [""/cache""]\n    shm_size = 0\n  [runners.cache]\n    [runners.cache.s3]\n    [runners.cache.gcs]\n']"
1022,9461,9458,CC BY-SA 4.0,2019-10-17T10:11:44.970,"<p>Simple one.
You should either add <code>ansible_ssh_extra_args=""-o StrictHostKeyChecking=no""</code> to inventory or <code>disableHostKeyChecking: true</code> into Jenkins pipeline script (inside ansiblePlaybook block).</p>

<p>Like this:</p>

<pre><code>ansiblePlaybook(
  colorized: true,
  installation: 'ansible27'
  inventory: '[hostsfile]'
  playbook: '[playbook]'
  disableHostKeyChecking: true
)
</code></pre>
",17661,2019-10-17T10:16:49.540,"[""ansiblePlaybook(\n  colorized: true,\n  installation: 'ansible27'\n  inventory: '[hostsfile]'\n  playbook: '[playbook]'\n  disableHostKeyChecking: true\n)\n""]"
1023,9475,3965,CC BY-SA 4.0,2019-10-17T23:39:16.207,"<p>The indentation looks incorrect for the artifacts section in your <code>buildspec-test.yml</code> file. It is nested under the phases section. That way it is not being output properly and can't be picked up by the next build.</p>

<p>It should be the same as in your second file.</p>

<pre><code>version: 0.2
phases:
  build:
    commands:
      - $ANDROID_HOME/tools/bin/sdkmanager ""build-tools;27.0.3"" ""platforms;android-27""
      - sh gradlew assembleDebug
artifacts:
  files:
    - app/build/outputs/apk/debug/app-debug.apk
  #some other stuff here.
</code></pre>
",17676,2019-10-18T03:56:48.907,"['version: 0.2\nphases:\n  build:\n    commands:\n      - $ANDROID_HOME/tools/bin/sdkmanager ""build-tools;27.0.3"" ""platforms;android-27""\n      - sh gradlew assembleDebug\nartifacts:\n  files:\n    - app/build/outputs/apk/debug/app-debug.apk\n  #some other stuff here.\n']"
1024,9477,8725,CC BY-SA 4.0,2019-10-18T07:42:57.540,"<p>Use this source code for reboot your client machine</p>

<pre><code>---
  - name: System Reboot
    hosts: debian
    become_method: sudo
    become_user: root
    become: true
    tasks:
      - name: reboot nodes     # Reboot client side debian machine 
        shell: sleep 2 &amp;&amp; shutdown -r now ""Ansible reboot""
        async: 1
        poll: 0
        ignore_errors: true
      - name: wait for the server to come back  # when server timeout it through error. That error is handle by ignore_errors.
        local_action: wait_for
        args:
          host: ""{{ inventory_hostname }}""
          port: 22
          state: started
          delay: 120
          timeout: 200
        ignore_errors: true
</code></pre>
",17679,2019-10-18T07:42:57.540,"['---\n  - name: System Reboot\n    hosts: debian\n    become_method: sudo\n    become_user: root\n    become: true\n    tasks:\n      - name: reboot nodes     # Reboot client side debian machine \n        shell: sleep 2 && shutdown -r now ""Ansible reboot""\n        async: 1\n        poll: 0\n        ignore_errors: true\n      - name: wait for the server to come back  # when server timeout it through error. That error is handle by ignore_errors.\n        local_action: wait_for\n        args:\n          host: ""{{ inventory_hostname }}""\n          port: 22\n          state: started\n          delay: 120\n          timeout: 200\n        ignore_errors: true\n']"
1025,9485,9456,CC BY-SA 4.0,2019-10-18T15:12:27.587,"<p>I found the solution to my problem:</p>

<p>In the main.yml task :</p>

<pre class=""lang-yaml prettyprint-override""><code>- include: wait_rds_are_stopped.yml
  when: chosen_action == ""stop""
  loop: ""{{ vars[ 'list_rds_resources_ids1_' + environment ] + vars[ 'list_rds_resources_ids2_' + environment ] }}""
  loop_control:
    loop_var: outer_item
</code></pre>

<p>In the wait_rds_are_stopped.yml task:</p>

<pre class=""lang-yaml prettyprint-override""><code>- name: Wait for RDS stop to finish
  rds_instance_facts:
    aws_access_key: ""{{ assumed_role.sts_creds.access_key }}""
    aws_secret_key: ""{{ assumed_role.sts_creds.secret_key }}""
    security_token: ""{{ assumed_role.sts_creds.session_token }}""
    db_instance_identifier: ""{{ outer_item }}""
    region: ""{{ region }}""
  register: aws_rds_facts
  until: aws_rds_facts.instances[0].db_instance_status == ""stopped""
  retries: 90
  delay: 10
</code></pre>

<p>Thus, the loop control is outside. The stop of the 3 databases has been launched before, without waiting, so we save time. And the external loop will finish only when all the databases are stopped.</p>
",16556,2019-10-18T15:12:27.587,"['- include: wait_rds_are_stopped.yml\n  when: chosen_action == ""stop""\n  loop: ""{{ vars[ \'list_rds_resources_ids1_\' + environment ] + vars[ \'list_rds_resources_ids2_\' + environment ] }}""\n  loop_control:\n    loop_var: outer_item\n', '- name: Wait for RDS stop to finish\n  rds_instance_facts:\n    aws_access_key: ""{{ assumed_role.sts_creds.access_key }}""\n    aws_secret_key: ""{{ assumed_role.sts_creds.secret_key }}""\n    security_token: ""{{ assumed_role.sts_creds.session_token }}""\n    db_instance_identifier: ""{{ outer_item }}""\n    region: ""{{ region }}""\n  register: aws_rds_facts\n  until: aws_rds_facts.instances[0].db_instance_status == ""stopped""\n  retries: 90\n  delay: 10\n']"
1026,9497,5304,CC BY-SA 4.0,2019-10-20T16:01:22.340,"<p>We also switched from Git Flow to GitLab Flow several months ago and so far we're very happy with our decision. It works very well with GitLab, it's easy to understand and less error-prone and you don't need additional Git commands (which are quite slow on Windows).</p>

<p>We use <a href=""https://docs.docker.com/compose/"" rel=""nofollow noreferrer"">Docker Compose</a> to organize our microservices and have a separate project/repository just for the staging and production compose file(s) of our actual application. In the project and CI of each service you can then combine such compose files with a specific one that just tells Docker to use the specific branch of the specific service (and maybe other branch specific settings).</p>

<p>The production compose file contains the production specific settings and tells each service to use a specific tag:</p>

<pre><code>service1:
    image: examples/service1:1.5.4     
    ports: 
        - ""8000:8000""
    volumes: 
        - ""/data"" 
service2:
    image: examples/service2:3.5.2
</code></pre>

<p>The staging compose file tells each service to use the image of the master branch:</p>

<pre><code>service1:
    image: examples/service1/master:latest          
service2:
    image: examples/service2/master:latest
</code></pre>

<p>Then the compose file for a specific branch of service 1 just looks like that:</p>

<pre><code>service1:
    image: examples/service1/some-branch-name:latest
</code></pre>

<p>When you deploy a review environment for the specific branch with all three compose files at once you'll get something like the following:</p>

<pre><code>service1:
    image: examples/service1/some-branch-name:latest
    ports: 
        - ""8000:8000""
    volumes: 
        - ""/data"" 
service2:
    image: examples/service2/master:latest
</code></pre>
",17696,2019-10-21T07:43:04.850,"['service1:\n    image: examples/service1:1.5.4     \n    ports: \n        - ""8000:8000""\n    volumes: \n        - ""/data"" \nservice2:\n    image: examples/service2:3.5.2\n', 'service1:\n    image: examples/service1/master:latest          \nservice2:\n    image: examples/service2/master:latest\n', 'service1:\n    image: examples/service1/some-branch-name:latest\n', 'service1:\n    image: examples/service1/some-branch-name:latest\n    ports: \n        - ""8000:8000""\n    volumes: \n        - ""/data"" \nservice2:\n    image: examples/service2/master:latest\n']"
1027,9506,9483,CC BY-SA 4.0,2019-10-21T14:14:36.627,"<p>To do this, you’ll first need your <code>kubeadm</code> configuration file. This creates a file named <code>kubeadm.yaml</code>:</p>

<p><code>kubectl -n kube-system get configmap kubeadm-config -o jsonpath='{.data.ClusterConfiguration}' &gt; kubeadm.yaml</code></p>

<p>Now open the file in an editor, and find the <code>certSANs</code> list under the <code>apiServer</code> section. If it does not exist, you’ll need to add it; if so, you’ll just add another entry to that list. Example:</p>

<pre><code>apiServer:
  certSANs:
  - ""172.29.50.162""
  - ""k8s.domain.com""
  - ""other-k8s.domain.net""
  extraArgs:
    authorization-mode: Node,RBAC
  timeoutForControlPlane: 4m0s
</code></pre>

<p>Now move the old certificates to another folder, otherwise <code>kubeadm</code> will not recreate new ones:</p>

<p><code>mv /etc/kubernetes/pki/apiserver.{crt,key} ~</code> </p>

<p>Use <code>kubeadm</code> to generate new apiserver certificates:</p>

<p><code>kubeadm init phase certs apiserver --config kubeadm.yaml</code></p>

<p>Now restart your <em>kubeapiserver</em> container:</p>

<ol>
<li>Run <code>docker ps | grep kube-apiserver | grep -v pause</code> to get the
container ID for the container running the Kubernetes API server</li>
<li>Run <code>docker kill &lt;containerID&gt;</code> to kill the container.</li>
<li><em>The Kubelet will automatically restart the container, which will pick up the new certificate.</em></li>
</ol>

<p>If everything is working as expected, don't forget to update the <code>kubeadm</code> ConfigMap stored in the cluster, otherwise, future <code>kubeadm</code> upgrade will be lacking your new config:</p>

<p>If using Kubernetes &lt; v1.15:</p>

<p><code>kubeadm config upload from-file --config kubeadm.yaml</code></p>

<p>For Kubernetes version >= <a href=""https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.15.md#deprecations-and-removals"" rel=""nofollow noreferrer"">v1.15</a>:</p>

<p><code>kubeadm init phase upload-config kubeadm --config kubeadm.yaml</code></p>

<p><em>This article has a more complete guide on how to <a href=""https://blog.scottlowe.org/2019/07/30/adding-a-name-to-kubernetes-api-server-certificate/"" rel=""nofollow noreferrer"">Adding a Name to the Kubernetes API Server Certificate</a></em></p>
",13139,2019-11-04T02:41:42.347,"['apiServer:\n  certSANs:\n  - ""172.29.50.162""\n  - ""k8s.domain.com""\n  - ""other-k8s.domain.net""\n  extraArgs:\n    authorization-mode: Node,RBAC\n  timeoutForControlPlane: 4m0s\n']"
1028,9519,9518,CC BY-SA 4.0,2019-10-22T07:16:28.367,"<p>You can certainly do this through a handler or task, but first you need to generate the trigger conditions. The swap space is in the <a href=""https://docs.ansible.com/ansible/latest/reference_appendices/special_variables.html#facts"" rel=""nofollow noreferrer"">Ansible facts</a> that are returned when <code>setup:</code> is run. From the Ansible docs:</p>

<blockquote>
  <p>Facts</p>
  
  <p>These are variables that contain information pertinent to the current host (inventory_hostname). They are only available if gathered first.</p>
  
  <p>ansible_facts
     Contains any facts gathered or cached for the inventory_hostname Facts are normally gathered by the setup module automatically in a play, but any module can return facts.</p>
  
  <p>ansible_local
     Contains any ‘local facts’ gathered or cached for the inventory_hostname. The keys available depend on the custom facts created. See the setup module for more details.</p>
</blockquote>

<p>As an example:</p>

<pre><code>ansible -i localhost, all -c local -m setup -a filter=*swap*
localhost | SUCCESS =&gt; {
    ""ansible_facts"": {
        ""ansible_swapfree_mb"": 437,
        ""ansible_swaptotal_mb"": 979
    },
    ""changed"": false
}
</code></pre>

<p>In your playbook your task to reset swap should then have the conditional like:</p>

<p><code>when: ansible_swap_free_mb &lt; 500</code></p>

<p>In your case, however you want to trigger on swap used, so you would have to compute the difference between total and free.</p>
",354,2019-10-22T07:16:28.367,"['ansible -i localhost, all -c local -m setup -a filter=*swap*\nlocalhost | SUCCESS => {\n    ""ansible_facts"": {\n        ""ansible_swapfree_mb"": 437,\n        ""ansible_swaptotal_mb"": 979\n    },\n    ""changed"": false\n}\n']"
1029,9523,9522,CC BY-SA 4.0,2019-10-22T13:18:24.563,"<p>It seems there is a spacing issue in your yaml</p>

<p>You should change the compose file to</p>

<pre><code>version : '3.4'

services:
    testando-volume-compartilhado-a:
      image: carloshenriquecarniatto/teste:latest

    volumes:        
        - D:\App:/app  # &lt;- extra space here
    ports:
        - ""10001:80""
        - ""44378:443"" 
</code></pre>
",354,2019-10-22T16:55:28.810,"['version : \'3.4\'\n\nservices:\n    testando-volume-compartilhado-a:\n      image: carloshenriquecarniatto/teste:latest\n\n    volumes:        \n        - D:\\App:/app  # <- extra space here\n    ports:\n        - ""10001:80""\n        - ""44378:443"" \n']"
1030,9530,3866,CC BY-SA 4.0,2019-10-23T05:35:26.730,"<p>When using <a href=""https://jenkins.io/doc/book/pipeline/jenkinsfile/"" rel=""nofollow noreferrer"">Declarative Pipelines</a> you can achieve the goal of running some steps only for certain branches by using the <a href=""https://jenkins.io/doc/book/pipeline/syntax/#when"" rel=""nofollow noreferrer"">when directive</a> with the build-in condition <code>branch</code>:</p>

<blockquote>
  <p><strong><code>branch</code></strong> Execute the stage when the branch being built matches the branch pattern (ANT style path glob) given, for example: when { branch 'master' }. Note that this only works on a multibranch Pipeline.</p>
</blockquote>

<pre class=""lang-java prettyprint-override""><code>pipeline {
    agent any 
    stages { 
        stage(""Build"") {
            when { branch ""master"" }
            steps { 
               echo ""I am a master branch""
            }
        }
    }
}
</code></pre>

<p>You may also access the <code>BRANCH_NAME</code> from environment variable and do something with it:</p>

<pre class=""lang-java prettyprint-override""><code>if (env.BRANCH_NAME == 'master') {
   //do something
}
</code></pre>

<p>Also have a look at <a href=""https://jenkins.io/doc/book/pipeline/syntax/#flow-control"" rel=""nofollow noreferrer"">Flow Control</a> to understand how you can control the flow of your pipeline.</p>
",4852,2019-10-23T05:35:26.730,"['pipeline {\n    agent any \n    stages { \n        stage(""Build"") {\n            when { branch ""master"" }\n            steps { \n               echo ""I am a master branch""\n            }\n        }\n    }\n}\n', ""if (env.BRANCH_NAME == 'master') {\n   //do something\n}\n""]"
1031,9532,9531,CC BY-SA 4.0,2019-10-23T09:30:42.307,"<p>I suspect what is happening here is you are trying to insert the <strong>private key</strong> into the <code>authorized_keys</code> file, which is invalid as only the <strong>public key</strong> is required on the target machine.</p>

<p>What you need to do is <a href=""https://docs.ansible.com/ansible/latest/modules/openssl_publickey_module.html"" rel=""nofollow noreferrer"">extract the public key from the private key</a>:</p>

<pre><code>- name: Generate an OpenSSL public key with a passphrase protected private key
  openssl_publickey:
    path: /tmp/key-{{ item.username }}.pub
    privatekey_path: {{ item.pem_file_path }}
    privatekey_passphrase: ansible
    format: OpenSSH
  with_items:
    - ""{{ users }}""
</code></pre>

<p>and then use the public key:</p>

<pre><code>- name: Set Authorized key token from the file
  become: true
  authorized_key:
    user: ""{{ item.username }}""
    state: present
    key: ""{{ lookup('file', '/tmp/key-{{ item.username }}.pub') }}""
  with_items:
    - ""{{ users }}""
</code></pre>
",397,2019-10-23T09:30:42.307,"['- name: Generate an OpenSSL public key with a passphrase protected private key\n  openssl_publickey:\n    path: /tmp/key-{{ item.username }}.pub\n    privatekey_path: {{ item.pem_file_path }}\n    privatekey_passphrase: ansible\n    format: OpenSSH\n  with_items:\n    - ""{{ users }}""\n', '- name: Set Authorized key token from the file\n  become: true\n  authorized_key:\n    user: ""{{ item.username }}""\n    state: present\n    key: ""{{ lookup(\'file\', \'/tmp/key-{{ item.username }}.pub\') }}""\n  with_items:\n    - ""{{ users }}""\n']"
1032,9537,9536,CC BY-SA 4.0,2019-10-23T13:08:34.537,"<p>Use <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#selecting-json-data-json-queries"" rel=""nofollow noreferrer"">json_query</a>. For example</p>
<pre class=""lang-yaml prettyprint-override""><code>    - set_fact:
        my_device: &quot;{{ ansible_mounts|json_query(query) }}&quot;
      vars:
        query: &quot;[?mount=='/'].device &quot;
    - debug:
        var: my_device
</code></pre>
<p>gives</p>
<pre class=""lang-yaml prettyprint-override""><code>    my_device:
      - /dev/sdc1
</code></pre>
<p>To get the first element of the list only append the filter <a href=""https://jinja.palletsprojects.com/en/latest/templates/#jinja-filters.first"" rel=""nofollow noreferrer"">first</a></p>
<pre class=""lang-yaml prettyprint-override""><code>    - set_fact:
        my_device: &quot;{{ ansible_mounts|json_query(query)|first }}&quot;
</code></pre>
",7715,2021-05-20T12:28:49.570,"['    - set_fact:\n        my_device: ""{{ ansible_mounts|json_query(query) }}""\n      vars:\n        query: ""[?mount==\'/\'].device ""\n    - debug:\n        var: my_device\n', '    my_device:\n      - /dev/sdc1\n', '    - set_fact:\n        my_device: ""{{ ansible_mounts|json_query(query)|first }}""\n']"
1033,9539,9538,CC BY-SA 4.0,2019-10-23T14:48:30.613,"<p>This looks like it was added to Terraform back in May 2017, you enable it with the <code>tracing_config</code> block:</p>

<pre><code>tracing_config {
  mode = ""Active""
}
</code></pre>

<p>You will also need to make sure that Terraform has a minimum of Write access to X-ray to enable the above to work:</p>

<pre><code>data ""aws_iam_policy"" ""aws_xray_write_only_access"" {
  arn = ""arn:aws:iam::aws:policy/AWSXrayWriteOnlyAccess""
}
</code></pre>
",397,2019-10-23T14:48:30.613,"['tracing_config {\n  mode = ""Active""\n}\n', 'data ""aws_iam_policy"" ""aws_xray_write_only_access"" {\n  arn = ""arn:aws:iam::aws:policy/AWSXrayWriteOnlyAccess""\n}\n']"
1034,9545,885,CC BY-SA 4.0,2019-10-23T17:08:30.497,"<p>The <a href=""https://javadoc.jenkins-ci.org/hudson/model/Executor.html#interrupt-hudson.model.Result-"" rel=""noreferrer""><code>Executor.interrupt(Result)</code></a> method is the cleanest, most direct way I could find to stop a build prematurely <em>and</em> mark it as a success.</p>

<pre><code>script {
    currentBuild.getRawBuild().getExecutor().interrupt(Result.SUCCESS)
    sleep(1)   // Interrupt is not blocking and does not take effect immediately.
}
</code></pre>

<p><strong>Pros</strong>:</p>

<ul>
<li>Works in a declarative pipeline just as well as a scripted one.</li>
<li>No try/catch or exceptions to handle.</li>
<li>Marks the calling stage and any successive stages as green/passing in the UI.</li>
</ul>

<p><strong>Cons</strong>:</p>

<ul>
<li>Requires a number of in-process script approvals, including one that is <a href=""https://github.com/jenkinsci/script-security-plugin/pull/69"" rel=""noreferrer"">considered insecure</a>. Approve and use with caution.</li>
</ul>
",17761,2020-01-16T23:10:13.997,['script {\n    currentBuild.getRawBuild().getExecutor().interrupt(Result.SUCCESS)\n    sleep(1)   // Interrupt is not blocking and does not take effect immediately.\n}\n']
1035,9550,9548,CC BY-SA 4.0,2019-10-23T20:29:26.820,"<p>The split function returns a list of strings. I believe encapsulating the function in a list is what is giving you the error. Have you tried removing the brackets around the split function? Something like:</p>

<pre><code>!Select [ ""0"",  !Split [ "","" , !ImportValue [ !Sub ""${ExportPrefix}-SubNets"" ] ] ]
</code></pre>
",4328,2019-10-23T20:29:26.820,"['!Select [ ""0"",  !Split [ "","" , !ImportValue [ !Sub ""${ExportPrefix}-SubNets"" ] ] ]\n']"
1036,9574,9560,CC BY-SA 4.0,2019-10-25T08:04:04.837,"<p>If you check the <a href=""https://wiki.jenkins.io/display/JENKINS/Git+Plugin#GitPlugin-Environmentvariables"" rel=""nofollow noreferrer"">Git plugin documentation</a>, you can see that there is a <code>GIT_BRANCH</code> environment variable that you can use in your pipeline.</p>

<pre><code>GIT_BRANCH - Name of the remote repository (defaults to origin),
             followed by name of the branch currently being used,
             e.g. ""origin/master"" or ""origin/foo""
</code></pre>

<p>So, in your pipeline:</p>

<pre class=""lang-java prettyprint-override""><code>stage('Push to Bitbucket') {
    steps {
        withCredentials([usernamePassword(credentialsId: '8e2ca0a6-2dc5-4f89-b76a-03076d6b0843',
                                          passwordVariable: 'GIT_PASSWORD',
                                          usernameVariable: 'GIT_USERNAME')]) {
            sh '''
            # Content omitted
            git checkout ${GIT_BRANCH}
            # Content omitted
            '''
        }
    }
}
</code></pre>
",16683,2019-10-25T10:31:21.480,"['GIT_BRANCH - Name of the remote repository (defaults to origin),\n             followed by name of the branch currently being used,\n             e.g. ""origin/master"" or ""origin/foo""\n', ""stage('Push to Bitbucket') {\n    steps {\n        withCredentials([usernamePassword(credentialsId: '8e2ca0a6-2dc5-4f89-b76a-03076d6b0843',\n                                          passwordVariable: 'GIT_PASSWORD',\n                                          usernameVariable: 'GIT_USERNAME')]) {\n            sh '''\n            # Content omitted\n            git checkout ${GIT_BRANCH}\n            # Content omitted\n            '''\n        }\n    }\n}\n""]"
1037,9580,9414,CC BY-SA 4.0,2019-10-25T14:18:09.557,"<p>This is the approach I came up with.  It's kinda ugly, but it does work:</p>

<pre><code>- run:
    name: Create unique build identifier
    command: |
        GIT_SHA=$( git rev-parse --short HEAD )
        echo ""export GIT_SHA=${GIT_SHA}"" &gt;&gt; ""${BASH_ENV}""

        # the always-increasing counter, based on CIRCLE_BUILD_NUM
        BUILD_COUNTER=""${CIRCLE_BUILD_NUM}""
        echo ""export BUILD_COUNTER=${BUILD_COUNTER}"" &gt;&gt; ""${BASH_ENV}""

        # the build identifier, which includes the short git sha
        BUILD_NUMBER=""CIRC${BUILD_COUNTER}-${GIT_SHA}""
        echo ""export BUILD_NUMBER=${BUILD_NUMBER}"" &gt;&gt; ""${BASH_ENV}""

        # output build id and counter
        echo -e ""\nbuild counter: ${BUILD_COUNTER}; build id: ${BUILD_NUMBER}\n""
</code></pre>

<p>Then <code>${BUILD_NUMBER}</code> is available as an environment variable in other steps.</p>
",17805,2019-10-25T14:18:09.557,"['- run:\n    name: Create unique build identifier\n    command: |\n        GIT_SHA=$( git rev-parse --short HEAD )\n        echo ""export GIT_SHA=${GIT_SHA}"" >> ""${BASH_ENV}""\n\n        # the always-increasing counter, based on CIRCLE_BUILD_NUM\n        BUILD_COUNTER=""${CIRCLE_BUILD_NUM}""\n        echo ""export BUILD_COUNTER=${BUILD_COUNTER}"" >> ""${BASH_ENV}""\n\n        # the build identifier, which includes the short git sha\n        BUILD_NUMBER=""CIRC${BUILD_COUNTER}-${GIT_SHA}""\n        echo ""export BUILD_NUMBER=${BUILD_NUMBER}"" >> ""${BASH_ENV}""\n\n        # output build id and counter\n        echo -e ""\\nbuild counter: ${BUILD_COUNTER}; build id: ${BUILD_NUMBER}\\n""\n']"
1038,9592,1186,CC BY-SA 4.0,2019-10-27T20:36:05.613,"<p>Below presented there are is a Bash script functions based on <code>awscli</code> to get <strong>AWS EBS volumes encryption state</strong> for different scenarios</p>

<p><strong>NOTE1:</strong> your IAM Profile and that is currently running</p>

<p>source public github gist: <a href=""https://gist.github.com/exequielrafaela/4cce5cf7198d5f239153e339587ab392"" rel=""nofollow noreferrer"">https://gist.github.com/exequielrafaela/4cce5cf7198d5f239153e339587ab392</a></p>

<p><strong>NOTE2:</strong> You'll find other bash scripts for some usual Sec &amp; Audit validations.</p>

<pre><code>#!/bin/bash

#
# Bash script functions based on awscli to get AWS EBS volumes encryption state for different scenarios
# your IAM Profile and that is currently running
#

#
# Your AWS IAM profile here (~/.aws/credentials &amp; ~/.aws/config).
#
AWS_IAM_PROFILE=""your-aws-iam-profile-here""

#
# AWS EBS status -&gt; attached || deattached
#
AWS_EBS_ATTACHMENT_STATUS=""attached""


#=========================================#
# Functions                               #
#=========================================#
func_aws_ec2_ebs_list_encrypted(){
    #
    # Get all running AWS EC2 accessible via your ${AWS_IAM_PROFILE} role.
    #
    instances=`aws ec2 describe-instances --region us-east-1 \
    --filters Name=instance-state-name,Values=running \
    --query ""Reservations[*].Instances[0].InstanceId"" \
    --output text \
    --profile ${AWS_IAM_PROFILE}`

    #
    # Iterate over the Instances list and present:
    # echo ""${instance} $name Volumes: $count VolumeId: $volumeid Encrypted: $encrypted""
    # eg: i-111111111111111 Jenkins Volumes: 2 VolumeId: vol-111111111111111 Encrypted: false
    #
    echo ""#===============================================#""
    echo ""# EBS Volumes attached to running EC2 Instances #""
    echo ""#===============================================#""
    for instance in ${instances};
    do
      count=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \
      --filters Name=attachment.status,Values=${AWS_EBS_ATTACHMENT_STATUS} Name=attachment.instance-id,Values=${instance} \
      --query ""Volumes[]""  | jq  -r '. | length';`

      name=`aws ec2 describe-tags --profile ${AWS_IAM_PROFILE} \
      --filters Name=resource-id,Values=${instance} Name=key,Values=Name \
      --query Tags[].Value | jq -r '.[0]'`

      if [[ ${count} -gt 0 ]]; then
        START=0
        END=${count}
        for ((i=START; i&lt;END; i++))
        do
           #echo ""i: $i""
           encrypted=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \
           --filters Name=attachment.status,Values=${AWS_EBS_ATTACHMENT_STATUS} Name=attachment.instance-id,Values=${instance} \
           --query ""Volumes[]""  | jq  -r "".[$i].Encrypted"";`

           volumeid=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \
           --filters Name=attachment.status,Values=${AWS_EBS_ATTACHMENT_STATUS} Name=attachment.instance-id,Values=${instance} \
           --query ""Volumes[]""  | jq  -r "".[$i].VolumeId"";`

           echo ""EC2: ${instance} $name Volumes: $count EbsVolumeId: $volumeid Encrypted: $encrypted ""
        done
      fi
    done
}

func_aws_ebs_list_encrypted(){
    echo """"
    echo ""#==============================================#""
    echo ""# All EBS Volumes                              #""
    echo ""#==============================================#""
    ebs_count=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \
    --query ""Volumes[]""  | jq "".[].VolumeId | length"" | wc -l`

    echo ""N° AWS EBS VOLUMES: ${ebs_count}""
    echo """"

    if [[ ${ebs_count} -gt 0 ]]; then
    START=0
    END=${ebs_count}
    for ((i=START; i&lt;END; i++))
    do
       #echo ""i: $i""
        ebs_volumeid=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \
        --query ""Volumes[]""  | jq -r "".[$i].VolumeId""`

        ebs_encrypted=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \
        --query ""Volumes[]""  | jq -r "".[$i].Encrypted""`

       echo ""EbsVolumeId: ${ebs_volumeid} Encrypted: ${ebs_encrypted}""
    done
    fi
}

#=========================================#
# Main() - Function calls                 #
#=========================================#
func_aws_ec2_ebs_list_encrypted
func_aws_ebs_list_encrypted
</code></pre>
",13596,2019-10-27T20:36:05.613,"['#!/bin/bash\n\n#\n# Bash script functions based on awscli to get AWS EBS volumes encryption state for different scenarios\n# your IAM Profile and that is currently running\n#\n\n#\n# Your AWS IAM profile here (~/.aws/credentials & ~/.aws/config).\n#\nAWS_IAM_PROFILE=""your-aws-iam-profile-here""\n\n#\n# AWS EBS status -> attached || deattached\n#\nAWS_EBS_ATTACHMENT_STATUS=""attached""\n\n\n#=========================================#\n# Functions                               #\n#=========================================#\nfunc_aws_ec2_ebs_list_encrypted(){\n    #\n    # Get all running AWS EC2 accessible via your ${AWS_IAM_PROFILE} role.\n    #\n    instances=`aws ec2 describe-instances --region us-east-1 \\\n    --filters Name=instance-state-name,Values=running \\\n    --query ""Reservations[*].Instances[0].InstanceId"" \\\n    --output text \\\n    --profile ${AWS_IAM_PROFILE}`\n\n    #\n    # Iterate over the Instances list and present:\n    # echo ""${instance} $name Volumes: $count VolumeId: $volumeid Encrypted: $encrypted""\n    # eg: i-111111111111111 Jenkins Volumes: 2 VolumeId: vol-111111111111111 Encrypted: false\n    #\n    echo ""#===============================================#""\n    echo ""# EBS Volumes attached to running EC2 Instances #""\n    echo ""#===============================================#""\n    for instance in ${instances};\n    do\n      count=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \\\n      --filters Name=attachment.status,Values=${AWS_EBS_ATTACHMENT_STATUS} Name=attachment.instance-id,Values=${instance} \\\n      --query ""Volumes[]""  | jq  -r \'. | length\';`\n\n      name=`aws ec2 describe-tags --profile ${AWS_IAM_PROFILE} \\\n      --filters Name=resource-id,Values=${instance} Name=key,Values=Name \\\n      --query Tags[].Value | jq -r \'.[0]\'`\n\n      if [[ ${count} -gt 0 ]]; then\n        START=0\n        END=${count}\n        for ((i=START; i<END; i++))\n        do\n           #echo ""i: $i""\n           encrypted=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \\\n           --filters Name=attachment.status,Values=${AWS_EBS_ATTACHMENT_STATUS} Name=attachment.instance-id,Values=${instance} \\\n           --query ""Volumes[]""  | jq  -r "".[$i].Encrypted"";`\n\n           volumeid=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \\\n           --filters Name=attachment.status,Values=${AWS_EBS_ATTACHMENT_STATUS} Name=attachment.instance-id,Values=${instance} \\\n           --query ""Volumes[]""  | jq  -r "".[$i].VolumeId"";`\n\n           echo ""EC2: ${instance} $name Volumes: $count EbsVolumeId: $volumeid Encrypted: $encrypted ""\n        done\n      fi\n    done\n}\n\nfunc_aws_ebs_list_encrypted(){\n    echo """"\n    echo ""#==============================================#""\n    echo ""# All EBS Volumes                              #""\n    echo ""#==============================================#""\n    ebs_count=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \\\n    --query ""Volumes[]""  | jq "".[].VolumeId | length"" | wc -l`\n\n    echo ""N° AWS EBS VOLUMES: ${ebs_count}""\n    echo """"\n\n    if [[ ${ebs_count} -gt 0 ]]; then\n    START=0\n    END=${ebs_count}\n    for ((i=START; i<END; i++))\n    do\n       #echo ""i: $i""\n        ebs_volumeid=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \\\n        --query ""Volumes[]""  | jq -r "".[$i].VolumeId""`\n\n        ebs_encrypted=`aws ec2 describe-volumes --profile ${AWS_IAM_PROFILE} \\\n        --query ""Volumes[]""  | jq -r "".[$i].Encrypted""`\n\n       echo ""EbsVolumeId: ${ebs_volumeid} Encrypted: ${ebs_encrypted}""\n    done\n    fi\n}\n\n#=========================================#\n# Main() - Function calls                 #\n#=========================================#\nfunc_aws_ec2_ebs_list_encrypted\nfunc_aws_ebs_list_encrypted\n']"
1039,9604,3584,CC BY-SA 4.0,2019-10-29T11:15:17.083,"<p>I find it strange that nobody mentioned the <a href=""https://github.com/jenkinsci/configuration-as-code-plugin"" rel=""nofollow noreferrer"">Configuration as Code</a> plugin. Our solution to this problem is to maintain a base Docker image for jenkins, provisioned with two config files:</p>

<ul>
<li>jenkins.yml</li>
<li>plugins.txt</li>
</ul>

<p>The plugins are installed by the <code>install-plugins.sh</code> script provided by the base Jenkins image:</p>

<pre><code>COPY casc_configs/plugins.txt /usr/share/jenkins/ref/plugins.txt
COPY casc_configs/jenkins.yml /usr/share/jenkins/ref/jenkins.yml
RUN /usr/local/bin/install-plugins.sh &lt; /usr/share/jenkins/ref/plugins.txt
</code></pre>

<p>and Jenkins itself is configured using the <code>jenkins.yml</code>.</p>

<p>The plugin file is generated from a template:</p>

<pre><code>{% for plugin in jenkins.plugins %}
{{ plugin.name }}:{{ plugin.version }}
{%endfor%}
</code></pre>

<p>where the variable <code>jenkins.plugins</code> is a big list of dicts:</p>

<pre><code>jenkins:
  plugins:
    - name: configuration-as-code
      version: 1.14
</code></pre>

<p>Doing things this way makes it possible to create and destroy fully configured jenkins instances on the fly. If you want, you can keep the <code>jenkins.yml</code> and <code>plugins.txt</code> on a mount that Jenkins can read when it starts.</p>
",354,2019-10-29T11:15:17.083,"['COPY casc_configs/plugins.txt /usr/share/jenkins/ref/plugins.txt\nCOPY casc_configs/jenkins.yml /usr/share/jenkins/ref/jenkins.yml\nRUN /usr/local/bin/install-plugins.sh < /usr/share/jenkins/ref/plugins.txt\n', '{% for plugin in jenkins.plugins %}\n{{ plugin.name }}:{{ plugin.version }}\n{%endfor%}\n', 'jenkins:\n  plugins:\n    - name: configuration-as-code\n      version: 1.14\n']"
1040,9608,9458,CC BY-SA 4.0,2019-10-29T19:42:48.713,"<p>Got the solution :</p>

<p>in the inventory file (<code>/etc/ansible/hosts</code>) :</p>

<pre><code>[host]
192.XXX.XXX.XXX ansible_user=ubuntu1(target hostname) ansible_become_password=XXXXXXXX(target pwd)
</code></pre>

<p>and in the play we have to set</p>

<pre><code>- hosts: host
  become: yes
  tasks:
    -name : Update XYZ app
     script: update.py

</code></pre>

<p>I have already written a python script for my process so I have giving same script here in .yml</p>
",17043,2019-10-31T06:24:04.550,"['[host]\n192.XXX.XXX.XXX ansible_user=ubuntu1(target hostname) ansible_become_password=XXXXXXXX(target pwd)\n', '- hosts: host\n  become: yes\n  tasks:\n    -name : Update XYZ app\n     script: update.py\n\n']"
1041,9613,9609,CC BY-SA 4.0,2019-10-30T09:29:15.447,"<p>It looks like you tried to compile multiple policies into one.<br>
Each original had a statement with its array of statements and you nested them.</p>

<p>This (untested) should work with each statement block within the array of Statement of the policy:</p>

<pre><code>{
  ""Version"": ""2012-10-17"",
  ""Statement"": [
    {
      ""Effect"": ""Allow"",
      ""Action"": [
        ""s3:ListBucket"",
        ""s3:GetBucketLocation"",
        ""s3:ListBucketMultipartUploads""
      ],
      ""Resource"": ""arn:aws:s3:::&lt;my bucket&gt;"",
      ""Principal"": {
        ""AWS"": [
          ""arn:aws:iam::560184616970:user/&lt;my username&gt;""
        ]
      }
    },
    {
      ""Effect"": ""Allow"",
      ""Action"": [
        ""s3:AbortMultipartUpload"",
        ""s3:DeleteObject"",
        ""s3:DeleteObjectVersion"",
        ""s3:GetObject"",
        ""s3:GetObjectAcl"",
        ""s3:GetObjectVersion"",
        ""s3:GetObjectVersionAcl"",
        ""s3:PutObject"",
        ""s3:PutObjectAcl"",
        ""s3:PutObjectAclVersion""
      ],
      ""Resource"": ""arn:aws:s3:::&lt;my-bucket&gt;/*"",
      ""Principal"": {
        ""AWS"": [
          ""arn:aws:iam::560184616970:user/&lt;my-username&gt;""
        ]
      }
    },
    {
      ""Effect"": ""Allow"",
      ""Action"": ""s3:ListAllMyBuckets"",
      ""Resource"": ""*""
    }
  ]
}
</code></pre>

<p>An alternative could be to use <a href=""https://awspolicygen.s3.amazonaws.com/policygen.html"" rel=""nofollow noreferrer"">aws bucket policy generator</a></p>
",13,2019-10-30T09:29:15.447,"['{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""s3:ListBucket"",\n        ""s3:GetBucketLocation"",\n        ""s3:ListBucketMultipartUploads""\n      ],\n      ""Resource"": ""arn:aws:s3:::<my bucket>"",\n      ""Principal"": {\n        ""AWS"": [\n          ""arn:aws:iam::560184616970:user/<my username>""\n        ]\n      }\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""s3:AbortMultipartUpload"",\n        ""s3:DeleteObject"",\n        ""s3:DeleteObjectVersion"",\n        ""s3:GetObject"",\n        ""s3:GetObjectAcl"",\n        ""s3:GetObjectVersion"",\n        ""s3:GetObjectVersionAcl"",\n        ""s3:PutObject"",\n        ""s3:PutObjectAcl"",\n        ""s3:PutObjectAclVersion""\n      ],\n      ""Resource"": ""arn:aws:s3:::<my-bucket>/*"",\n      ""Principal"": {\n        ""AWS"": [\n          ""arn:aws:iam::560184616970:user/<my-username>""\n        ]\n      }\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""s3:ListAllMyBuckets"",\n      ""Resource"": ""*""\n    }\n  ]\n}\n']"
1042,9627,9614,CC BY-SA 4.0,2019-10-30T18:56:56.473,"<p>In Nexus, go to the Admin Backend.</p>

<p>Create a blob store if you haven't already. Guidance can be found here: <a href=""https://help.sonatype.com/repomanager3/configuration/repository-management#RepositoryManagement-BlobStores"" rel=""nofollow noreferrer"">https://help.sonatype.com/repomanager3/configuration/repository-management#RepositoryManagement-BlobStores</a></p>

<p>Once you have a blob store, continue like so:</p>

<p>Choose ""Repositories"", hit ""Create Repository"". Choose ""docker (proxy)"" as the recipe.</p>

<p>Give it any name (for example ""docker-hub"").</p>

<p>Under ""Remote storage"" enter <code>https://registry-1.docker.io</code>.</p>

<p>As ""Docker Index"" select <code>Use Docker Hub</code>.</p>

<p>Select a blob store for it (which you have created above).</p>

<p>Hit ""Create repository"". No more configuration is needed for the proxy repo.</p>

<p>Next up: A group repository, from which you will pull:</p>

<p>Go back to ""Repositories"" and hit ""Create repository"" again. This time select ""docker (group)"".</p>

<p>Call it anything you like (for example ""docker-group"").</p>

<p>For ""HTTPS"" enter any port you like. (we have 10500)</p>

<p>For blob store select any blob store (for example the one you have created above).</p>

<p>Under ""Group"" select for ""member repositories"" the repository you have created above.</p>

<p>You can also add a ""docker (hosted)"" repository as well if you have one set up. (I will explain later)</p>

<p>Hit ""Create repository"".</p>

<p>Now open your Docker cli and do a pull of some Docker Hub image but don't pull it from Docker Hub, pull it through the HTTPs endpoint of your docker (group) repo that you have created above like so:</p>

<pre><code>$ docker pull my.repository.com:10500/phpmyadmin/phpmyadmin
</code></pre>

<p>This will create a pull request to your Nexus OSS, which will proxy the request to Docker Hub. The image from Docker Hub will be cached in your Nexus and will be delivered to you.</p>

<p>After pulling browse your docker (proxy) repo that you have created above and check the images inside. You will find a phpmyadmin/phpmyadmin inside (or any other image you have checked out) with a current timestamp.</p>

<p>Hope that helps!</p>
",7646,2019-10-30T18:56:56.473,['$ docker pull my.repository.com:10500/phpmyadmin/phpmyadmin\n']
1043,9628,9610,CC BY-SA 4.0,2019-10-30T18:59:56.233,"<p>An example will be maybe worth a thousand words:</p>

<pre><code>$ sudo apt install git
$ ssh 192.168.0.110
kub@host:~$ git init --bare repo1 
Initialized empty Git repository in /home/kub/repo1/
kub@host:~$ logout
Connection to 192.168.0.110 closed.
</code></pre>

<p>Voila, We already posses a self-hosted version control system. Let's use it as an example client:</p>

<pre><code>$ git clone 192.168.0.110:repo1 /tmp/r
Cloning into '/tmp/r'...
</code></pre>
",4083,2019-10-30T18:59:56.233,"['$ sudo apt install git\n$ ssh 192.168.0.110\nkub@host:~$ git init --bare repo1 \nInitialized empty Git repository in /home/kub/repo1/\nkub@host:~$ logout\nConnection to 192.168.0.110 closed.\n', ""$ git clone 192.168.0.110:repo1 /tmp/r\nCloning into '/tmp/r'...\n""]"
1044,9629,4446,CC BY-SA 4.0,2019-10-31T00:29:58.863,"<p>Using <code>/p</code> switch didn't work for my. However <code>-p</code> works just fine</p>

<pre><code>dotnet build -p:Version=1.2.3.4
</code></pre>

<p>You can also apply the same switch to the dotnet pack</p>

<pre><code>dotnet pack Yourproject.csproj -p:Version=1.2.3.4
</code></pre>

<p>look at this page <a href=""https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-build#msbuild"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-build#msbuild</a> for details.</p>
",17920,2019-10-31T00:29:58.863,"['dotnet build -p:Version=1.2.3.4\n', 'dotnet pack Yourproject.csproj -p:Version=1.2.3.4\n']"
1045,9632,9518,CC BY-SA 4.0,2019-10-31T09:04:17.130,"<p>I have a solution on that way :</p>

<pre><code>---
- hosts: hostnametest
  tasks:
   - name: we take swap space used (megabytes)
     shell : free -m | grep Swap | awk '{print $3}'
     register: swap_used

   - name: Turn off swap
     shell: ""swapoff -a""
     when: (swap_used.stdout_lines[0] | int) &gt; 100

   - name: Turn on swap
     shell: ""swapon -a""
     when: (swap_used.stdout_lines[0] | int) &gt; 100
</code></pre>
",16553,2019-10-31T09:04:17.130,"['---\n- hosts: hostnametest\n  tasks:\n   - name: we take swap space used (megabytes)\n     shell : free -m | grep Swap | awk \'{print $3}\'\n     register: swap_used\n\n   - name: Turn off swap\n     shell: ""swapoff -a""\n     when: (swap_used.stdout_lines[0] | int) > 100\n\n   - name: Turn on swap\n     shell: ""swapon -a""\n     when: (swap_used.stdout_lines[0] | int) > 100\n']"
1046,9638,9637,CC BY-SA 4.0,2019-10-31T17:42:44.950,"<p>Docker is an awesome tool for creating a database, seeding data into it, and disposing of it.</p>

<p>For an example check out <a href=""https://docs.microsoft.com/en-us/sql/linux/quickstart-install-connect-docker?view=sql-server-2017&amp;pivots=cs1-bash"" rel=""nofollow noreferrer"">Microsoft's SQL Server with Docker</a>.  The following would pull and run a sql server 2017 instance: <pre><code>docker run -e ""ACCEPT_EULA=Y"" -e ""SA_PASSWORD="" 
   -p 1433:1433 --name sql1</code>
   -d mcr.microsoft.com/mssql/server:2017-latest</pre>After running this you now have a developer ready SQL instance that you can then connect to SQL Management Studio (or any other GUI management tool), or you can even connect via the <a href=""https://docs.microsoft.com/en-us/sql/linux/quickstart-install-connect-docker?view=sql-server-2017&amp;pivots=cs1-powershell#connect-to-sql-server"" rel=""nofollow noreferrer"">command line</a>.</p>

<p>If you are not using SQL you can run a container for the desired database type (check out the options on Dockerhub).</p>

<p>Once you have your database up and running, run the scripts to set it up, seed the data, and test without worrying about messing up your production database.</p>
",15792,2019-10-31T17:42:44.950,"['docker run -e ""ACCEPT_EULA=Y"" -e ""SA_PASSWORD="" \n   -p 1433:1433 --name sql1\n   -d mcr.microsoft.com/mssql/server:2017-latest']"
1047,9644,9616,CC BY-SA 4.0,2019-11-01T12:35:34.497,"<p>Create and add token to be able to connect to SonarQube.<br>
You have create project in SonarQube and use it as a parameter:</p>

<pre><code>sh """"""
   ${scannerHome}/bin/sonar-scanner \
   -Dsonar.projectKey=your_project_key_created_in_sonarqube_as_project \
   -Dsonar.sources=. \
""""""
</code></pre>

<hr>

<p>Copied from <a href=""https://stackoverflow.com/a/58626625/4944847"">[StackOverflow] Problem with Connecting Jenkins to SonarQube</a>.</p>
",17955,2019-11-01T12:35:34.497,"['sh """"""\n   ${scannerHome}/bin/sonar-scanner \\\n   -Dsonar.projectKey=your_project_key_created_in_sonarqube_as_project \\\n   -Dsonar.sources=. \\\n""""""\n']"
1048,9651,9566,CC BY-SA 4.0,2019-11-01T19:33:53.317,"<blockquote>
  <p>Access to AWS Secrets Manager requires AWS credentials. Those
  credentials must have permissions to access the AWS resources that you
  want to access, such as your Secrets Manager secrets. The following
  sections provide details on how you can use AWS Identity and Access
  Management (IAM) policies to help secure access to your secrets and
  control who can access and administer them.</p>
</blockquote>

<p>so you need to provide the <code>aws</code> credentials to docker which has access to the manger</p>

<p>you can follow on of these methods:</p>

<p>providing the credentials with <code>run</code> command:</p>

<pre><code>docker run -e AWS_ACCESS_KEY_ID=XXXX -e AWS_SECRET_ACCESS_KEY=XXXX myimage
</code></pre>

<p>or providing the file <code>~/.aws/credentials</code> and then create your container:</p>

<pre><code>docker-machine create --driver amazonec2 --amazonec2-open-port 8000 --amazonec2-region us-west-1 aws-sandbox
</code></pre>

<p>see <a href=""https://docs.docker.com/machine/examples/aws/"" rel=""nofollow noreferrer"">this</a></p>
",15739,2019-11-01T19:33:53.317,"['docker run -e AWS_ACCESS_KEY_ID=XXXX -e AWS_SECRET_ACCESS_KEY=XXXX myimage\n', 'docker-machine create --driver amazonec2 --amazonec2-open-port 8000 --amazonec2-region us-west-1 aws-sandbox\n']"
1049,9652,9606,CC BY-SA 4.0,2019-11-01T21:37:48.380,"<p>Maybe a simple shell script would be more useful. If must to use ansible, it could be something like that (assuming you have all servers in group <code>testall</code>):</p>

<pre><code>- hosts: testall
  connection: local
  gather_facts: false
  tasks:

    - wait_for:
        timeout: 2
        port: 43
        host: '{{ (ansible_ssh_host|default(ansible_host))|default(inventory_hostname) }}'
      register: waitfor
      ignore_errors: true

    - copy:
        content: |
          {% for host in groups['testall'] %}
          {% if hostvars[host].waitfor.failed %}{{ hostvars[host].inventory_hostname }} {% endif %}
          {% endfor %}
        dest: /tmp/bad_file
      delegate_to: localhost

    - copy:
        content: |
          {% for host in groups['testall'] %}
          {% if not hostvars[host].waitfor.failed %}{{ hostvars[host].inventory_hostname }} {% endif %}
          {% endfor %}
        dest: /tmp/good_file
      delegate_to: localhost

</code></pre>

<p>hosts that have this port opened will be in <code>/tmp/good_file</code>, others are in <code>/tmp/bad_file</code></p>
",9924,2019-11-01T21:37:48.380,"[""- hosts: testall\n  connection: local\n  gather_facts: false\n  tasks:\n\n    - wait_for:\n        timeout: 2\n        port: 43\n        host: '{{ (ansible_ssh_host|default(ansible_host))|default(inventory_hostname) }}'\n      register: waitfor\n      ignore_errors: true\n\n    - copy:\n        content: |\n          {% for host in groups['testall'] %}\n          {% if hostvars[host].waitfor.failed %}{{ hostvars[host].inventory_hostname }} {% endif %}\n          {% endfor %}\n        dest: /tmp/bad_file\n      delegate_to: localhost\n\n    - copy:\n        content: |\n          {% for host in groups['testall'] %}\n          {% if not hostvars[host].waitfor.failed %}{{ hostvars[host].inventory_hostname }} {% endif %}\n          {% endfor %}\n        dest: /tmp/good_file\n      delegate_to: localhost\n\n""]"
1050,9655,9654,CC BY-SA 4.0,2019-11-02T09:46:34.527,"<p>Ok, it seems that the default docker MTU (1500) is not acceptable for me because I use a PPPoE Internet connection on the host on which I run the docker service:</p>

<pre><code>ip addr show eth0
48: eth0@if49: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default 
    link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0
       valid_lft forever preferred_lft forever
</code></pre>

<p>The solution is to create the network with an appropriate MTU:</p>

<pre><code>docker network create --opt com.docker.network.driver.mtu=1492 albums-webapp
docker network inspect albums-webapp | grep -i mtu
</code></pre>

<p>Be aware that while no container is running the command below will still show the 1500 MTU:</p>

<pre><code>ip link show | grep 4d725814c237 | grep mtu
</code></pre>

<p>Be also aware that newly created network must be allowed to go outside - so check it also with the firewall.</p>

<p>Also see the related issue: 
<a href=""https://github.com/moby/moby/issues/28314"" rel=""nofollow noreferrer"">https://github.com/moby/moby/issues/28314</a></p>
",17969,2019-11-03T15:14:16.740,"['ip addr show eth0\n48: eth0@if49: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n', 'docker network create --opt com.docker.network.driver.mtu=1492 albums-webapp\ndocker network inspect albums-webapp | grep -i mtu\n', 'ip link show | grep 4d725814c237 | grep mtu\n']"
1051,9683,9665,CC BY-SA 4.0,2019-11-04T17:05:38.333,"<p>When you want to refer to a specific instance of a resource that has multiple instances due to using <code>for_each</code>, you need to include the specific key of the instance you want in your references:</p>

<pre><code>  subnet_id = aws_subnet.private[""us-east-1a""].id
</code></pre>

<p>If you just want to select any one subnet from the list, without needing to specify its name directly, you can use an expression like the following to select a single key by sorting the keys lexically and taking the first one:</p>

<pre><code>  subnet_id = aws_subnet.private[keys(aws_subnet.private)[0]].id
</code></pre>

<p>However, beware that if you do the above then any later changes to <code>var.subnet_numbers_private</code> that affect which subnet sorts first will cause a different subnet id to be selected, which will then in turn cause Terraform to plan to replace your instance to move it into a new subnet.</p>

<hr>

<p>From the way you wrote the question it sounds like you want just one instance in a single subnet rather than one instance <em>per</em> subnet, but if you did want an instance per subnet then you can achieve that by putting <code>for_each</code> in the <code>aws_instance</code> resource too, using the subnet resource itself (represented in expressions as a map) as the repetition expression:</p>

<pre><code>resource ""aws_instance"" ""jenkins"" {
  for_each = aws_subnet.private

  # ...
  subnet_id = each.value.id
  # ...
}
</code></pre>

<p>In this latter case, the <code>aws_instance.jenkins</code> instances will also be identified by the keys you selected for the subnets, so you'd have instances with addresses like <code>aws_instance.jenkins[""us-east-1a""]</code> and <code>aws_instance.jenkins[""us-east-1b""]</code> so both you and Terraform can see which instance belongs to which subnet.</p>
",2463,2019-11-04T17:05:38.333,"['  subnet_id = aws_subnet.private[""us-east-1a""].id\n', '  subnet_id = aws_subnet.private[keys(aws_subnet.private)[0]].id\n', 'resource ""aws_instance"" ""jenkins"" {\n  for_each = aws_subnet.private\n\n  # ...\n  subnet_id = each.value.id\n  # ...\n}\n']"
1052,9684,9662,CC BY-SA 4.0,2019-11-04T17:14:22.960,"<p>A Terraform module is represented by a whole directory, not an individual file. If you create a directory <code>./modules/queues</code> and move <code>./modules/queues.tf</code> to <code>./modules/queues/queues.tf</code> then you can call that module like this:</p>

<pre><code>module ""pae_queues"" {
  source = ""./modules/queues""

  environments = var.environments
}
</code></pre>
",2463,2019-11-04T17:14:22.960,"['module ""pae_queues"" {\n  source = ""./modules/queues""\n\n  environments = var.environments\n}\n']"
1053,9685,8520,CC BY-SA 4.0,2019-11-04T19:57:52.467,"<p>See my answer <a href=""https://stackoverflow.com/a/58700185/399058"">here</a>:</p>
<blockquote>
<p>Ran into this today when trying to use Garden.io for a cluster running in Jelastic.</p>
<p>Found the solution in <a href=""https://github.com/helm/helm/issues/1455#issuecomment-533802309"" rel=""nofollow noreferrer"">this Github comment</a>:</p>
<p>First acquire a local binary for Tiller (server-version of Helm), either by <a href=""https://helm.sh/docs/using_helm/#from-source-linux-macos"" rel=""nofollow noreferrer"">compiling</a> or by <a href=""https://github.com/helm/helm/releases/tag/v2.14.3"" rel=""nofollow noreferrer"">downloading it from the release page</a>.</p>
<p>Then run:</p>
<pre><code>$ export HELM_HOST=&quot;:44134&quot;
$ tiller -listen ${HELM_HOST} -alsologtostderr &gt;/dev/null 2&gt;&amp;1 &amp;
</code></pre>
<p>This will run a local version of the Kubernetes Helm Server. Now try your original command again, kubectl, that will delegate to this local Helm instead and manage to connect.</p>
</blockquote>
",17994,2019-11-04T19:57:52.467,"['$ export HELM_HOST="":44134""\n$ tiller -listen ${HELM_HOST} -alsologtostderr >/dev/null 2>&1 &\n']"
1054,9688,9687,CC BY-SA 4.0,2019-11-04T20:42:21.280,"<p>It turns out that <code>/etc/ssl/cert.pem</code> is the bundle scanned by <code>apk</code> to verify a repo behind HTTPS, so the following works:</p>

<pre><code>wget our.cert.server.com/CA.crt
cat CA.crt &gt;&gt; /etc/ssl/cert.pem
sed -i 's,http://dl-cdn.alpinelinux.org/alpine,https://nexus-endpoint.company.com/repository/alpine-proxy,' /etc/apk/repositories
apk update
</code></pre>
",10718,2019-11-04T20:42:21.280,"[""wget our.cert.server.com/CA.crt\ncat CA.crt >> /etc/ssl/cert.pem\nsed -i 's,http://dl-cdn.alpinelinux.org/alpine,https://nexus-endpoint.company.com/repository/alpine-proxy,' /etc/apk/repositories\napk update\n""]"
1055,9692,9679,CC BY-SA 4.0,2019-11-05T00:06:25.253,"<p>I've done something similar to this in the past:</p>

<pre><code>stage('Step Tests') {
  steps {
    dir('test') {
      script {
        try {
          timeout(time: 5, unit: 'MINUTES', activity: true) {
            sh ""yarn step-tests""
          }
        } catch (Exception e) {
          currentBuild.result = 'FAILURE'
        }
      }
    }
  }
}
</code></pre>

<p>I haven't tested this code exactly as I wrote it here, so think of this more as a kind of rough sketch rather than polished final product.</p>
",4115,2019-11-05T00:06:25.253,"['stage(\'Step Tests\') {\n  steps {\n    dir(\'test\') {\n      script {\n        try {\n          timeout(time: 5, unit: \'MINUTES\', activity: true) {\n            sh ""yarn step-tests""\n          }\n        } catch (Exception e) {\n          currentBuild.result = \'FAILURE\'\n        }\n      }\n    }\n  }\n}\n']"
1056,9693,9691,CC BY-SA 4.0,2019-11-05T00:33:08.687,"<p><a href=""https://stackoverflow.com/q/32113330/2777965"">A related Q&amp;A</a> was already created on StackOverflow back in the day.</p>

<p>Several answers simply do a <code>docker pull image-to-be-checked</code>. If exit 0, the image exists in a certain registry. If not then the image seems to be omitted. However, if an image is large, e.g. X>1GB or the (office) internet is slow (due to proxies), this could take a while.</p>

<p>The best option to mitigate this is to use <code>docker manifest inspect docker-image</code> as suggested by <a href=""https://stackoverflow.com/a/52077346/2777965"">@morty</a> in conjunction with <code>DOCKER_CLI_EXPERIMENTAL=enabled</code> <a href=""https://stackoverflow.com/questions/32113330/check-if-imagetag-combination-already-exists-on-docker-hub#comment101216063_52077346"">as suggested in a comment by @ChrisDeacy</a></p>

<p>Although this command works for dockerhub images, it fails if images have to be checked on quay.io:</p>

<pre><code>unsupported manifest media type and no default available:
application/vnd.docker.distribution.manifest.v1+prettyjws
</code></pre>

<p>Therefor I decided to stick to the <code>docker pull</code> approach to make the check docker-registry agnostic.</p>

<p>Today I released version 1.0.0 of Docker Image Patrol (<a href=""https://github.com/030/dip"" rel=""nofollow noreferrer"">DIP</a>). This tool is able to check whether an image exists in a docker-registry. One could check the existence by running:</p>

<pre><code>./dip -image nginx -registry quay.io/some.org/ -debug
DEBU[0000] debug: true; image: nginx; registry: quay.io/some.org/ 
DEBU[0002] Command: docker pull quay.io/some.org/nginx; Output: Using
default tag: latest
Error response from daemon: unauthorized: access to the requested resource
is not authorized 
DEBU[0002] 1                                            
Is image: 'nginx' absent in registry: 'quay.io/some.org/'? -&gt; true
</code></pre>
",210,2019-11-05T16:46:56.987,"['unsupported manifest media type and no default available:\napplication/vnd.docker.distribution.manifest.v1+prettyjws\n', ""./dip -image nginx -registry quay.io/some.org/ -debug\nDEBU[0000] debug: true; image: nginx; registry: quay.io/some.org/ \nDEBU[0002] Command: docker pull quay.io/some.org/nginx; Output: Using\ndefault tag: latest\nError response from daemon: unauthorized: access to the requested resource\nis not authorized \nDEBU[0002] 1                                            \nIs image: 'nginx' absent in registry: 'quay.io/some.org/'? -> true\n""]"
1057,9697,4609,CC BY-SA 4.0,2019-11-05T10:01:24.380,"<p>Since the original question is also tagged with Nexus this is how to do bulk upload with Nexus 3:</p>

<pre><code>find &lt;directory name&gt;/ \! -type d -print0 | xargs -P10 -0 -I@ curl -v --user &lt;user&gt;:&lt;password&gt; --upload-file ./@ http://localhost:8081/repository/&lt;repository name&gt;/@
</code></pre>
",18003,2019-11-05T10:01:24.380,['find <directory name>/ \\! -type d -print0 | xargs -P10 -0 -I@ curl -v --user <user>:<password> --upload-file ./@ http://localhost:8081/repository/<repository name>/@\n']
1058,9704,9703,CC BY-SA 4.0,2019-11-05T18:39:47.597,"<p>Try to chain <code>withRegistry</code> like this:</p>

<pre class=""lang-java prettyprint-override""><code>docker.withRegistry('https://registry:10500', 'credentials-id') {
    docker.withRegistry('https://registry:10501', 'credentials-id') {
        docker.build(imageToBuild.getName(), '-f ' + imageToBuild.tag + '.Dockerfile .').push();
    }
}
</code></pre>
",16683,2019-11-05T18:39:47.597,"[""docker.withRegistry('https://registry:10500', 'credentials-id') {\n    docker.withRegistry('https://registry:10501', 'credentials-id') {\n        docker.build(imageToBuild.getName(), '-f ' + imageToBuild.tag + '.Dockerfile .').push();\n    }\n}\n""]"
1059,9710,6306,CC BY-SA 4.0,2019-11-06T10:09:28.960,"<p>You can use a <code>Makefile</code> for this:</p>

<pre><code>PHPBB_VERSION := 3.2.4

build:
    docker build \
        --build-arg PHPBB_VERSION=${PHPBB_VERSION} \
        --tag phpbb:${PHPBB_VERSION} - &lt; Dockerfile
</code></pre>

<p><code>Dockerfile</code>:</p>

<pre><code>FROM php:7.2-cli                                                                           

ARG PHPBB_VERSION                                                                          

RUN wget -nv -O- https://github.com/phpbb/phpbb/archive/release-${PHPBB_VERSION}.tar.gz | \
    tar xzf - --strip-components=1                                                         
</code></pre>

<p>Then, in a shell: <code>make build</code>.</p>
",16683,2019-11-06T10:09:28.960,"['PHPBB_VERSION := 3.2.4\n\nbuild:\n    docker build \\\n        --build-arg PHPBB_VERSION=${PHPBB_VERSION} \\\n        --tag phpbb:${PHPBB_VERSION} - < Dockerfile\n', 'FROM php:7.2-cli                                                                           \n\nARG PHPBB_VERSION                                                                          \n\nRUN wget -nv -O- https://github.com/phpbb/phpbb/archive/release-${PHPBB_VERSION}.tar.gz | \\\n    tar xzf - --strip-components=1                                                         \n']"
1060,9734,9731,CC BY-SA 4.0,2019-11-07T21:15:11.587,"<p>So you need to create packages for each of the three sites so that you can deploy each one individually.</p>

<p>The first step is to <a href=""https://octopus.com/docs/packaging-applications/create-packages/octopack"" rel=""nofollow noreferrer"">create a <code>.nuspec</code></a> file for each of the IIS websites you want to package:</p>

<ol>
<li>Install OctoPack and <a href=""https://octopus.com/docs/packaging-applications/create-packages/octopack"" rel=""nofollow noreferrer"">read the entire article</a></li>
<li>Create three empty text files next to the <code>.csproj</code>, give it the same base filename as the <code>.csproj</code>, thus if it is <code>MyApp.API.csproj</code> you want to create an empty text file called <code>MyApp.API.nuspec</code>.</li>
<li>In each of these <code>.nuspec</code> files paste in the following template:

<pre><code>&lt;?xml version=""1.0""?&gt;
&lt;package xmlns=""http://schemas.microsoft.com/packaging/2010/07/nuspec.xsd""&gt;
&lt;metadata&gt;
    &lt;id&gt;Sample.Web&lt;/id&gt;
    &lt;title&gt;Your Web Application&lt;/title&gt;
    &lt;version&gt;1.0.0&lt;/version&gt;
    &lt;authors&gt;Your name&lt;/authors&gt;
    &lt;owners&gt;Your name&lt;/owners&gt;
    &lt;licenseUrl&gt;http://yourcompany.com&lt;/licenseUrl&gt;
    &lt;projectUrl&gt;http://yourcompany.com&lt;/projectUrl&gt;
    &lt;requireLicenseAcceptance&gt;false&lt;/requireLicenseAcceptance&gt;
    &lt;description&gt;A sample project&lt;/description&gt;
    &lt;releaseNotes&gt;This release contains the following changes...&lt;/releaseNotes&gt;
&lt;/metadata&gt;
&lt;/package&gt;
</code></pre></li>
<li>Customize the template for each of your projects.</li>
<li>Update TeamCity to add <code>/p:RunOctoPack=true</code> to the <code>msbuild</code> command line</li>
<li>Publish your packages with the following msbuild arguments:

<ul>
<li><code>/p:OctoPackPublishPackageToHttp=http://your.octopusserver.com/nuget/packages</code></li>
<li><code>/p:OctoPackPublishApiKey=API-ABCDEFGMYAPIKEY</code></li>
</ul></li>
</ol>

<p>You may have to play around a bit, but essentially the above is taken from <a href=""https://octopus.com/docs/packaging-applications/create-packages/octopack"" rel=""nofollow noreferrer"">this article</a> so treat that as your bible.</p>
",397,2019-11-07T21:15:11.587,"['<?xml version=""1.0""?>\n<package xmlns=""http://schemas.microsoft.com/packaging/2010/07/nuspec.xsd"">\n<metadata>\n    <id>Sample.Web</id>\n    <title>Your Web Application</title>\n    <version>1.0.0</version>\n    <authors>Your name</authors>\n    <owners>Your name</owners>\n    <licenseUrl>http://yourcompany.com</licenseUrl>\n    <projectUrl>http://yourcompany.com</projectUrl>\n    <requireLicenseAcceptance>false</requireLicenseAcceptance>\n    <description>A sample project</description>\n    <releaseNotes>This release contains the following changes...</releaseNotes>\n</metadata>\n</package>\n']"
1061,9746,9745,CC BY-SA 4.0,2019-11-09T03:20:37.770,"<p>Figured out the answer, fourtinately for me I had missed the example in the blog post about terraform 0.12 linked below</p>

<p>Here is my final (working how I want) security group</p>

<pre><code>resource ""aws_security_group"" ""mongo"" {
  name        = ""Mongo""
  description = ""Allow mongo traffic""
  vpc_id      = aws_vpc.Main_VPC.id

  ingress {
    from_port   = 27017
    to_port     = 27017
    protocol    = ""tcp""
    cidr_blocks = [
      for num in var.private_subnet_numbers:
      cidrsubnet(aws_vpc.Main_VPC.cidr_block, 8, num)
    ]
  }

  tags = {
    Name = ""Mongo""
  }
}
</code></pre>

<p>Link to blog post about foreach - <a href=""https://www.hashicorp.com/blog/hashicorp-terraform-0-12-preview-for-and-for-each/"" rel=""nofollow noreferrer"">https://www.hashicorp.com/blog/hashicorp-terraform-0-12-preview-for-and-for-each/</a></p>
",11221,2019-11-09T03:20:37.770,"['resource ""aws_security_group"" ""mongo"" {\n  name        = ""Mongo""\n  description = ""Allow mongo traffic""\n  vpc_id      = aws_vpc.Main_VPC.id\n\n  ingress {\n    from_port   = 27017\n    to_port     = 27017\n    protocol    = ""tcp""\n    cidr_blocks = [\n      for num in var.private_subnet_numbers:\n      cidrsubnet(aws_vpc.Main_VPC.cidr_block, 8, num)\n    ]\n  }\n\n  tags = {\n    Name = ""Mongo""\n  }\n}\n']"
1062,9749,9705,CC BY-SA 4.0,2019-11-10T09:02:08.303,"<p>Not to take away from @vaporwave_sailor or @Alex, answers, but to add to..</p>

<p>The basic answer is <strong>you MUST upgrade the war first, then the plugins.</strong> All plugins depend on a minimum Jenkins version and the <a href=""https://github.com/jenkins-infra/update-center2/tree/master/site"" rel=""nofollow noreferrer"">Update Centre</a> will give you different information back.</p>

<p>If you don't upgrade often, use the <a href=""https://jenkins.io/download/"" rel=""nofollow noreferrer"">LTS version</a>. <strong>READ the <a href=""https://jenkins.io/doc/upgrade-guide"" rel=""nofollow noreferrer"">Upgrade Guide</a>. READ the <a href=""https://jenkins.io/changelog-stable"" rel=""nofollow noreferrer"">Changelog</a>. Re-READ the <a href=""https://jenkins.io/doc/upgrade-guide"" rel=""nofollow noreferrer"">Upgrade Guide</a></strong>. Do the same for all your <strong>core plugins</strong>. There are <strong>significant changes</strong>, especially around security which may require modifications on your part. Many previously bundled are no longer bundled. Long unsupported plugins may have better alternatives or contain security issues you should be aware of. Behaviors and settings may change.</p>

<hr>

<p>The following are NOT exact steps, rather things to do in the process. Descriptive, not prescriptive.</p>

<p>Consider installing the Jenkins <a href=""https://plugins.jenkins.io/configuration-as-code"" rel=""nofollow noreferrer"">Configuration as Code (JCasC) plugi</a>n to your existing installation first. That will generally let you export almost your entire configuration and simply reload into a new instance. Much easier, but does not handle plugins. For now rip a solution from <a href=""https://github.com/jenkinsci/docker/blob/master/install-plugins.sh"" rel=""nofollow noreferrer"">docker/install_plugins.sh</a> for local use; see <a href=""https://github.com/jenkinsci/docker/blob/master/README.md#preinstalling-plugins"" rel=""nofollow noreferrer"">Preinstalling Plugins</a>.</p>

<p>Take a backup of your existing Jenkins and install install a ""Dev"" location. Validate your upgrade there before applying to Prod. ALWAYS. (Also, regularly backup your Prod anyway).</p>

<p>Split the backup in two parts, the system configuration and the jobs. Jobs are in ${JENKINS_HOME}/jobs. The system configuration includes (in <code>${JENKINS_HOME}</code>),  <code>./*.xml ./secret.key* ./secrets ./security-tokens ./nodes</code> , possibly others.</p>

<p>Back to the plugins for a minute. I agree w/adding them in segments:</p>

<ul>
<li>Authentication plugins</li>
<li>Presentation plugins (eg:Active-directory, credentials)</li>
<li>SCM plugins (eg: Git)</li>
<li>Adminstrative plugins (eg: greenballs, windows-slaves)</li>
<li>Tools plugins (eg: ant, maven-plugin)</li>
<li>Pipeline plugins (eg: workflow-aggregator, Blue-Ocean, K8s) </li>
</ul>

<p>All the above are ""Global plugins, with Configurations""</p>

<ul>
<li>Finally, job step plugins; these are job specific.</li>
</ul>

<p>If using the install_plugins.sh approach, you only need worry about the highest level plugin as it will pull the dependencies. If you install blueocean, it installs some 25 plugins. Just specify the first and you get the rest. Bear in mind, install_plugins.sh is dynamic, in that it gets the available dependencies at the time. So, we decide on the top list, manage that, run once to get the complete list, then read the validated explicit list into the Prod instance (manage the short one, use the complete one, save both). We manage 55 top-level plugins, but there are 160 installed including all dependencies in the full list.</p>

<p>This groovy script will get you your existing plugins:</p>

<pre><code>Jenkins.instance.pluginManager.plugins.sort(false) { a, b -&gt; a.getShortName().toLowerCase() &lt;=&gt; b.getShortName().toLowerCase()}.each { plugin -&gt;
   println ""${plugin.getShortName()}:${plugin.getVersion()} | ${plugin.getDisplayName()} ""
}
   // the following may also be useful
   // println ""+++ ${plugin.getDependants()}""
   // println ""... ${plugin.getDependencies()""
</code></pre>

<p>In the Dev instance, install the war, install the plugins, create a file <code>${JENKINS_HOME}/init.groovy</code>, add the line:
<code>Hudson.instance.doQuietDown();</code>. That lets your system start without letting any <a href=""https://www.praqma.com/stories/jenkins-quiet-startup/"" rel=""nofollow noreferrer"">jobs start</a>. That way you can examine the system logs w/o panicking or getting confused. Look at everything before <code>INFO: Jenkins is fully up and running</code>.</p>

<p>Now, you can install the system configurations, but not the <code>./jobs</code> and not the <code>./nodes</code>. Start it up and <strong>check the logs</strong> for information, warning alerts and errors. </p>

<p>You might even want to start with your existing war version and existing plugins and basic config, fire that up and save the logs as references. Then, using the UI, upgrade the war, then restart, then the plugins using the UI, then restart, then check and save the logs as references.</p>

<p>If using JCasC, you may go w/a slim install of the configurations,then import your JCasC configurations. <a href=""https://github.com/jenkinsci/configuration-as-code-plugin/blob/master/README.md"" rel=""nofollow noreferrer"">JCasC usage here</a>.</p>

<p>*NB: You will notice one major change is more plugins are moving to their own xml configuration instead of adding to the master config.xml. There are many plugins especially that say this configuration is NOT backward compatible. You would have to restore the old config when ""downgrading"" (correct language - start again from step 1)</p>

<p>Only once your core system starts fine, then I would add the jobs (with <code>QuietDown()</code> in place ), no nodes and in QuiteDown. Start up again, examine logs for errors, upgrade warnings, etc. Deal w/those. Many plugins will change their data format, hence the many warnings you see, and the <a href=""https://jenkins.io/doc/book/managing/plugins/#removing-old-data"" rel=""nofollow noreferrer"">""Manage Old Data""</a>. IF you're truly paranoid, you may even write a little groovy script that finds all your jobs and re-saves them. While Jenkins knows of the configuration changes, it does not actually change and update the plugin references in the jobs until the job is run or saved (if you need a script, ask a separate question).</p>

<p>Shutdown, delete the jobs directory (this is your DEV instance, so you are OK). </p>

<p>Startup up again and create a small set of validation jobs. These validate all the steps of your real jobs but without impacting them. They are the ""test cases"" @Alex refers to. We use ""sampleApps"" of different flavors we have and jobs that cover all the steps. We have test jobs that just get on a node, dump the environment, jobs that clone a repo and build (in the flavors), one that does the whole cycle: clone, build analyze, test, deploy, as well as pipeline jobs (phased). You can now add the nodes configuration and startup and execute those. <strong>They are your validation</strong>. If they work, then you are as prepared as you can be. You can now export the JCasC configuration as well.</p>

<p>Now, delete the entire Dev instance and <strong>REDO</strong> using only your finalized configuration and steps as you documented. Did everything work as expected? Run JCasC again, did they match?</p>

<p>Now you can apply the same finalized configuration to your Prod. Shutdown Production and TAKE ANOTHER BACKUP. I'd add the <code>QuietDown()</code> first to Prod. </p>

<p>Finally, consider taking advantage of some new ""<a href=""https://wiki.jenkins.io/display/JENKINS/Features+controlled+by+system+properties"" rel=""nofollow noreferrer"">System Properties</a>"". You can now set locations outside of ${JENKINS_HOME} for <code>jenkins.model.Jenkins.buildsDir</code> (ps: sym-links in builds are <a href=""https://wiki.jenkins.io/display/JENKINS/Build+Symlink+Plugin"" rel=""nofollow noreferrer"">now optional</a>) and <code>jenkins.model.Jenkins.workspacesDir</code>, removing useless data from the ${JENKINS_HOME}. Your backups will be smaller and simpler and your system performacne may improve! You'll also want to set <code>jenkins.install.runSetupWizard</code> to false.</p>

<p>Remember, this is descriptive, not preservative. Tailor to your own needs and risk tolerance.</p>
",13379,2020-05-31T10:49:52.807,"['Jenkins.instance.pluginManager.plugins.sort(false) { a, b -> a.getShortName().toLowerCase() <=> b.getShortName().toLowerCase()}.each { plugin ->\n   println ""${plugin.getShortName()}:${plugin.getVersion()} | ${plugin.getDisplayName()} ""\n}\n   // the following may also be useful\n   // println ""+++ ${plugin.getDependants()}""\n   // println ""... ${plugin.getDependencies()""\n']"
1063,9764,9760,CC BY-SA 4.0,2019-11-12T09:34:09.087,"<p>I would be inclined to implement the <a href=""https://www.openpolicyagent.org/docs/latest/kubernetes-introduction/"" rel=""nofollow noreferrer"">Open Policy Agent</a> as this will give you the ability to define a policy similar to this:</p>

<pre><code>apiVersion: constraints.gatekeeper.sh/v1beta1
kind: K8sContainerLimits
metadata:
  name: container-must-have-limits
spec:
  match:
    kinds:
      - apiGroups: [""""]
        kinds: [""Pod""]
  parameters:
    cpu: ""200m""
    memory: ""1Gi""
</code></pre>

<p>OPA will enforce any policy you defined via an <a href=""https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/"" rel=""nofollow noreferrer"">Admission Controller</a>, beware though it's very powerful and I have bricked clusters by not thinking through the options carefully.</p>
",397,2019-11-12T09:34:09.087,"['apiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sContainerLimits\nmetadata:\n  name: container-must-have-limits\nspec:\n  match:\n    kinds:\n      - apiGroups: [""""]\n        kinds: [""Pod""]\n  parameters:\n    cpu: ""200m""\n    memory: ""1Gi""\n']"
1064,9772,9771,CC BY-SA 4.0,2019-11-12T12:23:14.003,"<p>I suspect you haven't set up the host in <a href=""http://docs.ansible.com/ansible/latest/intro_inventory.html"" rel=""nofollow noreferrer"">your inventory</a> you can figure out where your hosts are being pulled from with the following command:</p>

<pre><code>ansible-config dump | grep HOST
</code></pre>

<p>In practice, you probably just need to create an <code>inventory</code> file with the following content:</p>

<pre><code>[nodes]
node01 ansible_host=IP OF YOUR FIRST NODE HERE!!!
node02 ansible_host=35.228.80.9
</code></pre>

<p>Then specify the <code>-i</code> parameter to <code>ansible-playbook</code>:</p>

<pre><code>ansible-playbook -i inventory -k playbook.yml
</code></pre>

<p>Depending on your exact use cases it might be more scalable and maintainable to use <a href=""https://docs.ansible.com/ansible/latest/scenario_guides/guide_gce.html#gce-dynamic-inventory"" rel=""nofollow noreferrer"">GCE Dynamic Inventory</a>, although this does require a little bit of extra setup.</p>
",397,2019-11-12T12:23:14.003,"['ansible-config dump | grep HOST\n', '[nodes]\nnode01 ansible_host=IP OF YOUR FIRST NODE HERE!!!\nnode02 ansible_host=35.228.80.9\n', 'ansible-playbook -i inventory -k playbook.yml\n']"
1065,9785,9784,CC BY-SA 4.0,2019-11-13T11:33:08.147,"<p>You cannot change the default registry (see <a href=""https://github.com/moby/moby/issues/7203"" rel=""nofollow noreferrer"">this</a>). You have to specify which registry to use like this:</p>

<pre><code>docker pull myprivatereg:port/library/image
</code></pre>

<p>Or, in a Dockerfile:</p>

<pre><code>FROM myprivatereg:port/library/image
</code></pre>

<p>(This question was also asked in <a href=""https://stackoverflow.com/questions/33054369/how-to-change-the-default-docker-registry-from-docker-io-to-my-private-registry"">StackOverlow</a>).</p>
",16683,2019-11-13T12:50:55.270,"['docker pull myprivatereg:port/library/image\n', 'FROM myprivatereg:port/library/image\n']"
1066,9796,8885,CC BY-SA 4.0,2019-11-13T23:35:45.527,"<p>What do you mean by ""it doesn't work""? I got an error suggesting that the log format wasn't correct:</p>

<pre><code>Fatal error has occurred
Error occured at: src/goaccess.c - set_curses - 1394
No time format was found on your conf file.
</code></pre>

<p>When I edited <code>/etc/goaccess.conf</code> (i.e. uncommented/selected <code>time-format</code>, <code>date-format</code> and <code>log-format</code>) the <code>docker logs mycontainer | goaccess -</code> command works as expected.</p>

<p>As an aside, for my <code>nginx</code> proxy inside my docker container, I had to set my <code>log_format</code> as follows:</p>

<pre><code>log-format %v %h %^ %^ [%d:%t %^] ""%r"" %s %b ""%R"" ""%u""
</code></pre>
",18165,2019-11-13T23:35:45.527,"['Fatal error has occurred\nError occured at: src/goaccess.c - set_curses - 1394\nNo time format was found on your conf file.\n', 'log-format %v %h %^ %^ [%d:%t %^] ""%r"" %s %b ""%R"" ""%u""\n']"
1067,9811,9810,CC BY-SA 4.0,2019-11-14T19:33:36.570,"<p>As the name of the container is randomly generated you cannot get it before it's generated (by definition). You can use <a href=""https://frightanic.com/goodies_content/docker-names.php"" rel=""nofollow noreferrer"">this</a> service to generate random names :</p>

<pre><code>NAME=$(curl -s https://frightanic.com/goodies_content/docker-names.php); \
docker run -ti --name $NAME --hostname $NAME ubuntu:latest
</code></pre>
",16683,2019-11-14T19:33:36.570,['NAME=$(curl -s https://frightanic.com/goodies_content/docker-names.php); \\\ndocker run -ti --name $NAME --hostname $NAME ubuntu:latest\n']
1068,9817,9816,CC BY-SA 4.0,2019-11-15T09:33:28.090,"<p>A pretty simple solution is to declare a global variable on top of your pipeline, and check it's value in your last conditional stage:</p>

<pre class=""lang-java prettyprint-override""><code>def flag = false;

pipeline {
    stages {
        stage('1 - Always') {
            steps {
                sh './always.sh'
            }
        }

        stage('2 - Maybe') {
            when { condition }

            steps {
                sh './maybe.sh'
                script { flag = true }
            }
        }

        stage('3 - If Maybe was executed') {
            when { expression { flag == true } }

            steps {
                sh './conditional.sh'
            }
        }
    }
}
</code></pre>
",16683,2019-11-15T09:59:44.287,"[""def flag = false;\n\npipeline {\n    stages {\n        stage('1 - Always') {\n            steps {\n                sh './always.sh'\n            }\n        }\n\n        stage('2 - Maybe') {\n            when { condition }\n\n            steps {\n                sh './maybe.sh'\n                script { flag = true }\n            }\n        }\n\n        stage('3 - If Maybe was executed') {\n            when { expression { flag == true } }\n\n            steps {\n                sh './conditional.sh'\n            }\n        }\n    }\n}\n""]"
1069,9819,9810,CC BY-SA 4.0,2019-11-15T17:49:22.167,"<p>Yes, there is a built in way.  You can define your own ""friendly name"" by using the --name parameter when creating the container:<pre><code>docker run -ti --hostname OTHER_CONTAINER_FRIENDLY_NAME --name MY_NAME ubuntu:latest</code></pre></p>

<p>If you are trying to automate this process then your build tool can supply the name from a variable or via the run script.  If you are using a docker-compose file you can specify the name directly in the yaml:<pre><code>services:
  myservice:
    container_name: example_friendly_name</code></pre></p>
",15792,2019-11-15T17:49:22.167,"['docker run -ti --hostname OTHER_CONTAINER_FRIENDLY_NAME --name MY_NAME ubuntu:latest', 'services:\n  myservice:\n    container_name: example_friendly_name']"
1070,9823,9815,CC BY-SA 4.0,2019-11-16T16:13:42.197,"<p>There was used wrong type for <code>variable</code>, should be:</p>

<pre><code>variable ""ssh_keys"" {
  type = ""map""
  default = {
    ""atolkachev"" = ""ssh-rsa my_key atolkachev""
  }
}
</code></pre>
",1084,2019-11-16T16:13:42.197,"['variable ""ssh_keys"" {\n  type = ""map""\n  default = {\n    ""atolkachev"" = ""ssh-rsa my_key atolkachev""\n  }\n}\n']"
1071,9837,3262,CC BY-SA 4.0,2019-11-18T10:48:08.537,"<p>Today <code>8.5.49</code> was returned as a 'stable' version, while it should have been <code>8.5.47</code>. The following:</p>

<pre><code>URL=https://tomcat.apache.org/download-80.cgi
curl -s $URL  | grep ""8\.5\.[0-9]\+&lt;/a&gt;"" | sed -e 's|.*&gt;\(.*\)&lt;.*|\1|g'
</code></pre>

<p>returns:</p>

<pre><code>8.5.47
</code></pre>
",210,2019-11-18T10:48:08.537,"['URL=https://tomcat.apache.org/download-80.cgi\ncurl -s $URL  | grep ""8\\.5\\.[0-9]\\+</a>"" | sed -e \'s|.*>\\(.*\\)<.*|\\1|g\'\n', '8.5.47\n']"
1072,9848,9844,CC BY-SA 4.0,2019-11-18T20:45:05.053,"<p>You can send the output of your python script to <code>stdout</code> and capture it in a environment variable and that variable can be passed to other stages in the pipeline. Also, the environment variables can be used inside the scripts.</p>

<p>You can do something like this:</p>

<pre><code>def call(Map parameters)
{
    def CREDENITAL_ID = parameters.secret
    def DOMAIN_DESCRIPTOR_URL = parameters.url
    env.artifacts = sh(script: ""python amd_distribution_input_transformation.py"", returnStdout: true )

    }             
}
</code></pre>

<p>Here, the output of the script <code>amd_distribution_input_transformation.py</code> will be stored in the variable <code>artifacts</code> and will be available further.</p>
",12138,2019-11-18T20:45:05.053,"['def call(Map parameters)\n{\n    def CREDENITAL_ID = parameters.secret\n    def DOMAIN_DESCRIPTOR_URL = parameters.url\n    env.artifacts = sh(script: ""python amd_distribution_input_transformation.py"", returnStdout: true )\n\n    }             \n}\n']"
1073,9850,9846,CC BY-SA 4.0,2019-11-18T22:35:54.193,"<p>Prior to apps/v1 the selector field was implicitly picked up from the pod template's labels. So in your case it would be:</p>

<pre><code>spec:
  selector:
    matchLabels:
      io.kompose.service: web
</code></pre>

<p>Starting with apps/v1 an explicit selector field is required by the Kubernetes API.</p>

<p>I would suggest not to change the iptables on your own as it it the responsibility of your Kubernetes network plugin and is most likely done well.</p>

<p>As far as I am concerned you may simple update the Deployment manifest and no uninstall is required.</p>
",18256,2019-11-18T22:35:54.193,['spec:\n  selector:\n    matchLabels:\n      io.kompose.service: web\n']
1074,9859,9856,CC BY-SA 4.0,2019-11-19T19:50:09.887,"<p>It seems that the <code>jenkinsParam</code> is holding the output after escaping the special characters.
You are assuming that <code>jenkinsParam = ""test\ntest""</code> and however it looks like it stores it as <code>jenkinsParam = ""test\\ntest""</code></p>

<p>See how it behaves if I use echo it these two different cases:</p>

<p>(I have tested this in groovy shell)</p>

<p><strong>1st Case:</strong></p>

<pre><code>jenkinsParam = ""test\ntest""
print jenkinsParam
test
test
</code></pre>

<p>** 2nd Case:**</p>

<pre><code>jenkinsParam = ""test\\ntest""
print jenkinsParam
test\ntest
</code></pre>

<p>In order to replace the <code>payload</code> which is stored in the <code>jenkinsParam</code> (2nd case behaviour), you need to replace the complete <code>\\n</code> from the string. Check the example below:</p>

<pre><code>output = jenkinsParam.replaceAll('\\\\n', 'yes')
print output
testyestest
</code></pre>
",12138,2019-11-19T19:59:30.690,"['jenkinsParam = ""test\\ntest""\nprint jenkinsParam\ntest\ntest\n', 'jenkinsParam = ""test\\\\ntest""\nprint jenkinsParam\ntest\\ntest\n', ""output = jenkinsParam.replaceAll('\\\\\\\\n', 'yes')\nprint output\ntestyestest\n""]"
1075,9864,3741,CC BY-SA 4.0,2019-11-20T16:20:33.363,"<p>From close reading of the <a href=""https://docs.ansible.com/ansible/latest/modules/azure_rm_virtualmachine_module.html"" rel=""nofollow noreferrer"">Ansible doc page</a> on creating Azure VMs, it's clear that you can refer to a resource such as a virtual network or NIC using its resource ID.  This lets you specify any resource, just like RM templates.</p>

<p>To specify a NIC created in another resource group by the networking team, with the <code>networking_rg_name</code> var set to that group name, you would use a resource ID like this:</p>

<pre><code>- set_fact:
    nic_id: ""/subscriptions/{{ subscription_id }}/resourceGroups/{{ networking_rg_name }}/providers/Microsoft.Network/networkInterfaces/{{ nic_name }}""

- name: ""Create VM {{vm_type}} - {{name}}""
  azure_rm_virtualmachine:
    resource_group: ""{{rg_name}}""
    name: ""{{name}}""
    vm_size: ""{{size}}""
    admin_username: ""{{user}}""
    admin_password: ""{{pass}}""
    os_type: ""{{os_type}}""
    network_interfaces: ""{{nic_id}}""     # Use the nic_id instead of name
    image: ""{{image}}""
    tags: ""{{tags}}""
</code></pre>

<p>This works for any resources that are in a different resource group, including virtual networks.</p>
",519,2019-11-23T10:46:11.903,"['- set_fact:\n    nic_id: ""/subscriptions/{{ subscription_id }}/resourceGroups/{{ networking_rg_name }}/providers/Microsoft.Network/networkInterfaces/{{ nic_name }}""\n\n- name: ""Create VM {{vm_type}} - {{name}}""\n  azure_rm_virtualmachine:\n    resource_group: ""{{rg_name}}""\n    name: ""{{name}}""\n    vm_size: ""{{size}}""\n    admin_username: ""{{user}}""\n    admin_password: ""{{pass}}""\n    os_type: ""{{os_type}}""\n    network_interfaces: ""{{nic_id}}""     # Use the nic_id instead of name\n    image: ""{{image}}""\n    tags: ""{{tags}}""\n']"
1076,9867,9156,CC BY-SA 4.0,2019-11-20T17:33:18.283,"<p>Here is my YAML for multiple artifacts from a single build.</p>

<pre><code>pool:
  name: Hosted Windows 2019 with VS2019
  demands:
  - msbuild
  - visualstudio
  - vstest
  - npm

steps:
- task: NuGetToolInstaller@0
  displayName: 'Use NuGet 4.4.1'
  inputs:
    versionSpec: 4.4.1

- task: NuGetCommand@2
  displayName: 'NuGet restore'
  inputs:
    restoreSolution: '$(Parameters.solution)'

- task: VSBuild@1
  displayName: 'Build solution WebApi'
  inputs:
    solution: '$(Parameters.solution)'
    msbuildArgs: '/p:DeployOnBuild=true /p:WebPublishMethod=Package /p:PackageAsSingleFile=true /p:SkipInvalidConfigurations=true /p:PackageLocation=""$(build.artifactstagingdirectory)\\""'
    platform: '$(BuildPlatform)'
    configuration: '$(BuildConfiguration)'
    msbuildArchitecture: x64

- task: PublishBuildArtifacts@1
  displayName: 'Publish Artifact: WebApi'
  inputs:
    PathtoPublish: '$(build.artifactstagingdirectory)'
    ArtifactName: 'dotnet-webapi'
  condition: succeededOrFailed()

- task: DeleteFiles@1
  displayName: 'Delete build.artifactstagingdirectory for Angular'
  inputs:
    SourceFolder: '$(build.artifactstagingdirectory)'
    Contents: '**'

- task: Npm@1
  displayName: 'npm install'
  inputs:
    workingDir: project/ClientApp
    verbose: false

- task: Npm@1
  displayName: 'npm run prod-build'
  inputs:
    command: custom
    workingDir: project/ClientApp
    verbose: false
    customCommand: 'run prod-build'

- task: Npm@1
  displayName: 'npm run dev-build'
  inputs:
    command: custom
    workingDir: project/ClientApp
    verbose: false
    customCommand: 'run prod-dev'
  enabled: false

- task: CopyFiles@2
  displayName: 'Copy Angular/Dist to build.artifactstagingdirectory'
  inputs:
    SourceFolder: project/ClientApp/dist/ClientApp
    Contents: |
     **
     !config.json
    TargetFolder: '$(build.artifactstagingdirectory)'

- task: PublishBuildArtifacts@1
  displayName: 'Publish Artifact: Angular'
  inputs:
    ArtifactName: angular

</code></pre>
",17030,2019-11-20T17:33:18.283,"['pool:\n  name: Hosted Windows 2019 with VS2019\n  demands:\n  - msbuild\n  - visualstudio\n  - vstest\n  - npm\n\nsteps:\n- task: NuGetToolInstaller@0\n  displayName: \'Use NuGet 4.4.1\'\n  inputs:\n    versionSpec: 4.4.1\n\n- task: NuGetCommand@2\n  displayName: \'NuGet restore\'\n  inputs:\n    restoreSolution: \'$(Parameters.solution)\'\n\n- task: VSBuild@1\n  displayName: \'Build solution WebApi\'\n  inputs:\n    solution: \'$(Parameters.solution)\'\n    msbuildArgs: \'/p:DeployOnBuild=true /p:WebPublishMethod=Package /p:PackageAsSingleFile=true /p:SkipInvalidConfigurations=true /p:PackageLocation=""$(build.artifactstagingdirectory)\\\\""\'\n    platform: \'$(BuildPlatform)\'\n    configuration: \'$(BuildConfiguration)\'\n    msbuildArchitecture: x64\n\n- task: PublishBuildArtifacts@1\n  displayName: \'Publish Artifact: WebApi\'\n  inputs:\n    PathtoPublish: \'$(build.artifactstagingdirectory)\'\n    ArtifactName: \'dotnet-webapi\'\n  condition: succeededOrFailed()\n\n- task: DeleteFiles@1\n  displayName: \'Delete build.artifactstagingdirectory for Angular\'\n  inputs:\n    SourceFolder: \'$(build.artifactstagingdirectory)\'\n    Contents: \'**\'\n\n- task: Npm@1\n  displayName: \'npm install\'\n  inputs:\n    workingDir: project/ClientApp\n    verbose: false\n\n- task: Npm@1\n  displayName: \'npm run prod-build\'\n  inputs:\n    command: custom\n    workingDir: project/ClientApp\n    verbose: false\n    customCommand: \'run prod-build\'\n\n- task: Npm@1\n  displayName: \'npm run dev-build\'\n  inputs:\n    command: custom\n    workingDir: project/ClientApp\n    verbose: false\n    customCommand: \'run prod-dev\'\n  enabled: false\n\n- task: CopyFiles@2\n  displayName: \'Copy Angular/Dist to build.artifactstagingdirectory\'\n  inputs:\n    SourceFolder: project/ClientApp/dist/ClientApp\n    Contents: |\n     **\n     !config.json\n    TargetFolder: \'$(build.artifactstagingdirectory)\'\n\n- task: PublishBuildArtifacts@1\n  displayName: \'Publish Artifact: Angular\'\n  inputs:\n    ArtifactName: angular\n\n']"
1077,9870,9869,CC BY-SA 4.0,2019-11-20T18:56:51.530,"<p>While creating the credentials parameter in jenkins job, you can specify <code>required: true</code>, then jenkins should validate the credentials paramter.</p>

<pre><code>parameters {
    credentials(name: 'GPG_PASSPHRASE', defaultValue: '', credentialType: ""Username with password"", required: true )
}
</code></pre>

<p>You can also check the details mentioned in the link <a href=""https://docwhat.org/jenkins-user-credentials"" rel=""nofollow noreferrer"">https://docwhat.org/jenkins-user-credentials</a></p>

<p>Adding Parameter</p>

<pre><code>/* EXAMPLE */
parameters {
    credentials(
        credentialType: 'com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl',
        defaultValue: '',
        description: 'The credentials needed to deploy.',
        name: 'deployCredentialsId',
        required: true
    )
}
</code></pre>

<p>Using in the stage</p>

<pre><code>/* EXAMPLE */
steps {
    withCredentials([usernamePassword(
        credentialsId: '${deployCredentialsId}',
        usernameVariable: 'DEPLOY_USERNAME',
        passwordVariable: 'DEPLOY_PASSWORD',
    )]) {
        sh './my-command.bash --username=""${DEPLOY_USERNAME}"" --password=""${DEPLOY_PASSWORD}""'
    }
}
</code></pre>

<p>If you just want to check if the variable is empty or not, you can check <code>isEmpty()</code> in groovy script. Your code can be as follows:</p>

<pre><code>stage (""create bundle""){
        steps{
            script{
                    if ( GPG_PASSPHRASE.isEmpty()​​ ) {
                             GPG_PASSPHRASE = 'custom_string'
                     }
                    amd_distribution_create_bundle credential_id: params.DISTRIBUTION_CREDENTIAL_ID, distribution_url: params.DISTRIBUTION_URL, gps_credential_id: params.GPG_PASSPHRASE, bundle_name: params.BUNDLE_NAME, bundle_version: BUNDLE_VERSION
            }
        }
    }
</code></pre>
",12138,2019-11-20T19:13:02.637,"['parameters {\n    credentials(name: \'GPG_PASSPHRASE\', defaultValue: \'\', credentialType: ""Username with password"", required: true )\n}\n', ""/* EXAMPLE */\nparameters {\n    credentials(\n        credentialType: 'com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl',\n        defaultValue: '',\n        description: 'The credentials needed to deploy.',\n        name: 'deployCredentialsId',\n        required: true\n    )\n}\n"", '/* EXAMPLE */\nsteps {\n    withCredentials([usernamePassword(\n        credentialsId: \'${deployCredentialsId}\',\n        usernameVariable: \'DEPLOY_USERNAME\',\n        passwordVariable: \'DEPLOY_PASSWORD\',\n    )]) {\n        sh \'./my-command.bash --username=""${DEPLOY_USERNAME}"" --password=""${DEPLOY_PASSWORD}""\'\n    }\n}\n', 'stage (""create bundle""){\n        steps{\n            script{\n                    if ( GPG_PASSPHRASE.isEmpty()\u200b\u200b ) {\n                             GPG_PASSPHRASE = \'custom_string\'\n                     }\n                    amd_distribution_create_bundle credential_id: params.DISTRIBUTION_CREDENTIAL_ID, distribution_url: params.DISTRIBUTION_URL, gps_credential_id: params.GPG_PASSPHRASE, bundle_name: params.BUNDLE_NAME, bundle_version: BUNDLE_VERSION\n            }\n        }\n    }\n']"
1078,9875,9862,CC BY-SA 4.0,2019-11-20T21:28:37.870,"<p>As per the <a href=""https://cloud.google.com/compute/docs/instances/adding-removing-ssh-keys#instance-only"" rel=""nofollow noreferrer"">link</a>, You can add keys via metadata. You can try the following. </p>

<pre><code>   metadata:
     ssh-keys: ""[USERNAME]:ssh-rsa [NEW_KEY_VALUE] [USERNAME]""
</code></pre>

<p>Replace [USERNAME] &amp; [NEW_KEY_VALUE] with actual key value. </p>
",18271,2019-11-20T21:28:37.870,"['   metadata:\n     ssh-keys: ""[USERNAME]:ssh-rsa [NEW_KEY_VALUE] [USERNAME]""\n']"
1079,9876,9358,CC BY-SA 4.0,2019-11-20T23:19:21.457,"<p>I think what you are looking for is lifecycle hooks.</p>

<p><a href=""https://kitchen.ci/docs/reference/lifecycle-hooks/"" rel=""nofollow noreferrer"">https://kitchen.ci/docs/reference/lifecycle-hooks/</a></p>

<p>For example, you could have this in you kitchen.yml file.</p>

<pre><code>
suites:
- name: default
  lifecycle:
    post_verify:
    - local: &lt;script&gt;
</code></pre>
",18248,2019-11-20T23:19:21.457,['\nsuites:\n- name: default\n  lifecycle:\n    post_verify:\n    - local: <script>\n']
1080,9882,9881,CC BY-SA 4.0,2019-11-21T15:01:14.880,"<p>I just figured it out.
Splitting it up into more commands worked perfectly</p>

<pre><code>  - name: doit
    command: chdir=/tmp/proftpd/ ./configure

  - name: a shit here we go again
    command: chdir=/tmp/proftpd/ make

  - name: another one
    command: chdir=/tmp/proftpd/ sudo make install
</code></pre>
",18304,2019-11-21T15:01:14.880,['  - name: doit\n    command: chdir=/tmp/proftpd/ ./configure\n\n  - name: a shit here we go again\n    command: chdir=/tmp/proftpd/ make\n\n  - name: another one\n    command: chdir=/tmp/proftpd/ sudo make install\n']
1081,9890,9889,CC BY-SA 4.0,2019-11-22T10:23:39.020,"<p>The Dockerfile provided in the Q&amp;A indicates that the image uses the latest <code>php:7</code> as a base image. One could inspect the version as follows:    </p>

<pre><code>docker run -it php:7 php -v
</code></pre>

<p><strong>Result</strong></p>

<pre><code>PHP 7.3.11 (cli) (built: Oct 25 2019 02:24:51) ( NTS )
Copyright (c) 1997-2018 The PHP Group
Zend Engine v3.3.11, Copyright (c) 1998-2018 Zend Technologies
</code></pre>

<hr>

<p><strong>How to use an older version of php in conjunction with this container?</strong></p>

<p>It is possible to use a specific version by checking the <a href=""https://hub.docker.com/_/php?tab=tags"" rel=""nofollow noreferrer"">tags of php on dockerhub</a>. According to this list, <code>7.2.25</code> is currently the latest <code>7.2</code>. If one changes the from of the Dockerfile to <code>FROM php:7.2.25</code> and build the image again, then <code>7.2.25</code> instead <code>7.3.11</code> will be used inside the container.</p>
",210,2019-11-22T11:24:42.590,"['docker run -it php:7 php -v\n', 'PHP 7.3.11 (cli) (built: Oct 25 2019 02:24:51) ( NTS )\nCopyright (c) 1997-2018 The PHP Group\nZend Engine v3.3.11, Copyright (c) 1998-2018 Zend Technologies\n']"
1082,9897,9798,CC BY-SA 4.0,2019-11-22T15:56:37.077,"<p>You probably don't want to delete the file, just remove it from your path.  You will need to look through your System and Account environment variables and look for <code>PATH</code> and remove <code>C:\Program Files\Docker\Docker\Resources\bin\</code>.</p>

<p>There is a good chance it that that will just work, I have both Docker Desktop and <code>gcloud</code> installed on this computer and I don't have the folder above in my <code>PATH</code> and both products work just fine without any warnings about old tools hanging about.</p>

<p>If you do continue to run into problems, for example with MiniKube, it can be helpful to use the <code>Get-Command</code> PowerShell command to figure out which executable is getting called:</p>

<pre><code>Get-Command kubectl | Format-List
</code></pre>

<p>Will give you the full path to the executable that would be run if you issued the command <code>kubectl</code>:</p>

<pre><code>Name            : kubectl.exe
CommandType     : Application
Definition      : C:\Program Files\Docker\Docker\Resources\bin\kubectl.exe
Extension       : .exe
Path            : C:\Program Files\Docker\Docker\Resources\bin\kubectl.exe
FileVersionInfo : File:             C:\Program Files\Docker\Docker\Resources\bin\kubectl.exe
                  InternalName:
                  OriginalFilename:
                  FileVersion:
                  FileDescription:
                  Product:
                  ProductVersion:
                  Debug:            False
                  Patched:          False
                  PreRelease:       False
                  PrivateBuild:     False
                  SpecialBuild:     False
                  Language:
</code></pre>
",397,2019-11-22T15:56:37.077,"['Get-Command kubectl | Format-List\n', 'Name            : kubectl.exe\nCommandType     : Application\nDefinition      : C:\\Program Files\\Docker\\Docker\\Resources\\bin\\kubectl.exe\nExtension       : .exe\nPath            : C:\\Program Files\\Docker\\Docker\\Resources\\bin\\kubectl.exe\nFileVersionInfo : File:             C:\\Program Files\\Docker\\Docker\\Resources\\bin\\kubectl.exe\n                  InternalName:\n                  OriginalFilename:\n                  FileVersion:\n                  FileDescription:\n                  Product:\n                  ProductVersion:\n                  Debug:            False\n                  Patched:          False\n                  PreRelease:       False\n                  PrivateBuild:     False\n                  SpecialBuild:     False\n                  Language:\n']"
1083,9900,9866,CC BY-SA 4.0,2019-11-22T17:45:31.267,"<p>It seems like the intent of this expression is to take the result of encoding that data structure which contains numbers and boolean values in quotes and produce a new version with those values unquoted.</p>

<p>For example, anywhere the result contains the sequence <code>""true""</code> it would be replaced with <code>true</code>, quotes removed to produce a real JSON boolean value rather than a string.</p>

<p>A more direct way to achieve that result would be to set the values in <code>cadvisor_container_definition</code> to be of the intended type immediately:</p>

<pre><code>locals {
  cadvisor_container_definition = {
    name         = local.cadvisor_container
    image        = ""google/cadvisor:latest""
    portMappings = [
      {
        containerPort = 8080
        hostPort      = 8080
      },
    ]
    mountPoints = [
      {
        sourceVolume  = ""root""
        containerPath = ""/rootfs""
        readOnly      = true
      },
      {
        sourceVolume  = ""var_run""
        containerPath = ""/var/run""
        readOnly      = false
      },
      {
        sourceVolume  = ""sys""
        containerPath = ""/sys""
        readOnly      = true
      },
      {
        sourceVolume  = ""var_lib_docker""
        containerPath = ""/var/lib/docker""
        readOnly      = true
      },
      {
        sourceVolume  = ""cgroup"",
        containerPath = ""/sys/fs/cgroup""
        readOnly      = true
      }
    ]
    memory            = var.cadvisor_memory[var.env]
    memoryReservation = var.cadvisor_memory_reservation[var.env]
  }
}
</code></pre>

<p>I changed the literal values in the above to their numeric or boolean equivalents. I can't see from what you shared whether <code>memory</code> and <code>memoryReservation</code> are also supposed to be numbers, but if they are then that can be arranged by writing <code>tonumber(var.cadvisor_memory[var.env])</code> and <code>tonumber(var.cadvisor_memory_reservation[var.env])</code>.</p>

<p>The above examples use Terraform 0.12 syntax. It's possible that the configuration you are looking at here is written for Terraform 0.11 instead, which would explain this unusual string substitution technique because the Terraform 0.11 version of <code>jsonencode</code> suffered from Terraform 0.11's tendency to convert all primitive-typed values to strings. If you are still using Terraform 0.11 then the strange expression you found is likely still needed, but if you are using Terraform 0.12 then a change like I described above should work to simplify the confusing expression to just a straightforward <code>jsonencode</code>:</p>

<pre><code>jsonencode([local.cadvisor_container_definition])
</code></pre>
",2463,2019-11-22T17:45:31.267,"['locals {\n  cadvisor_container_definition = {\n    name         = local.cadvisor_container\n    image        = ""google/cadvisor:latest""\n    portMappings = [\n      {\n        containerPort = 8080\n        hostPort      = 8080\n      },\n    ]\n    mountPoints = [\n      {\n        sourceVolume  = ""root""\n        containerPath = ""/rootfs""\n        readOnly      = true\n      },\n      {\n        sourceVolume  = ""var_run""\n        containerPath = ""/var/run""\n        readOnly      = false\n      },\n      {\n        sourceVolume  = ""sys""\n        containerPath = ""/sys""\n        readOnly      = true\n      },\n      {\n        sourceVolume  = ""var_lib_docker""\n        containerPath = ""/var/lib/docker""\n        readOnly      = true\n      },\n      {\n        sourceVolume  = ""cgroup"",\n        containerPath = ""/sys/fs/cgroup""\n        readOnly      = true\n      }\n    ]\n    memory            = var.cadvisor_memory[var.env]\n    memoryReservation = var.cadvisor_memory_reservation[var.env]\n  }\n}\n', 'jsonencode([local.cadvisor_container_definition])\n']"
1084,9902,9231,CC BY-SA 4.0,2019-11-22T20:04:06.893,"<p>After further research, it's evident that it's currently impossible to do this natively.  Therefore, we have to do this in the shell with the <code>command</code> module:</p>

<pre class=""lang-sh prettyprint-override""><code>command: openstack container set --property Full-Key={{ KEY }} {{ CONTAINER }}
</code></pre>
",16151,2019-11-22T20:04:06.893,['command: openstack container set --property Full-Key={{ KEY }} {{ CONTAINER }}\n']
1085,9905,9904,CC BY-SA 4.0,2019-11-22T21:07:26.973,"<p>Have you tried setting <code>returnStdout</code> to true in the <code>sh()</code> command per the <a href=""https://jenkins.io/doc/pipeline/steps/workflow-durable-task-step/#sh-shell-script"" rel=""nofollow noreferrer"">Jenkins documentation</a>?</p>

<p>You can then assign that output to a variable within your pipeline:</p>

<pre><code>def artifactsList = sh(label: 'Running amd_distribution_input transformation', returnStdout: true, script: 'python amd_distribution_input_transformation.py')
</code></pre>

<p>and check what kind of object that variable is, and act on it accordinly</p>

<pre><code>echo(artifactsList.getClass())
</code></pre>
",9148,2019-11-22T21:07:26.973,"[""def artifactsList = sh(label: 'Running amd_distribution_input transformation', returnStdout: true, script: 'python amd_distribution_input_transformation.py')\n"", 'echo(artifactsList.getClass())\n']"
1086,9918,9119,CC BY-SA 4.0,2019-11-25T07:59:35.407,"<p>I just experienced the same issue. It seems the eksctl that is being installed upon first use is not working for me. I went to the eksctl site and installed it from there (<a href=""https://eksctl.io/introduction/installation/"" rel=""nofollow noreferrer"">https://eksctl.io/introduction/installation/</a>)</p>

<p>With the jx eksctl binary : </p>

<pre><code>➜  ~ jx create cluster eks --cluster-name=konsek-cloud --skip-installation=true --verbose
DEBUG: eksctl is already available on your PATH at /Users/&lt;user&gt;/.jx/bin/eksctl
DEBUG: aws-iam-authenticator is already available on your PATH at /Users/&lt;user&gt;/.jx/bin/aws-iam-authenticator
DEBUG: Dependencies to be installed: 
DEBUG: kubectl is already available on your PATH at /usr/local/bin/kubectl
DEBUG: helm is already available on your PATH at /usr/local/bin/helm
DEBUG: brew is already available on your PATH at /usr/local/bin/brew
error: exit status 1
</code></pre>

<p>With the manually installed binary : </p>

<pre><code>➜  ~ jx create cluster eks --cluster-name=konsek-cloud --skip-installation=true --verbose
DEBUG: eksctl is already available on your PATH at /usr/local/bin/eksctl
DEBUG: aws-iam-authenticator is already available on your PATH at /usr/local/bin/aws-iam-authenticator
DEBUG: Dependencies to be installed: 
DEBUG: kubectl is already available on your PATH at /usr/local/bin/kubectl
DEBUG: helm is already available on your PATH at /usr/local/bin/helm
DEBUG: brew is already available on your PATH at /usr/local/bin/brew
Creating EKS cluster - this can take a while so please be patient...
... 
</code></pre>
",18360,2019-11-25T08:59:49.670,"['➜  ~ jx create cluster eks --cluster-name=konsek-cloud --skip-installation=true --verbose\nDEBUG: eksctl is already available on your PATH at /Users/<user>/.jx/bin/eksctl\nDEBUG: aws-iam-authenticator is already available on your PATH at /Users/<user>/.jx/bin/aws-iam-authenticator\nDEBUG: Dependencies to be installed: \nDEBUG: kubectl is already available on your PATH at /usr/local/bin/kubectl\nDEBUG: helm is already available on your PATH at /usr/local/bin/helm\nDEBUG: brew is already available on your PATH at /usr/local/bin/brew\nerror: exit status 1\n', '➜  ~ jx create cluster eks --cluster-name=konsek-cloud --skip-installation=true --verbose\nDEBUG: eksctl is already available on your PATH at /usr/local/bin/eksctl\nDEBUG: aws-iam-authenticator is already available on your PATH at /usr/local/bin/aws-iam-authenticator\nDEBUG: Dependencies to be installed: \nDEBUG: kubectl is already available on your PATH at /usr/local/bin/kubectl\nDEBUG: helm is already available on your PATH at /usr/local/bin/helm\nDEBUG: brew is already available on your PATH at /usr/local/bin/brew\nCreating EKS cluster - this can take a while so please be patient...\n... \n']"
1087,9922,9921,CC BY-SA 4.0,2019-11-25T10:35:21.513,"<p>Try to use <code>php -S 0.0.0.0:8080</code>:</p>

<pre><code>docker run --name php -v $(pwd):/app -w /app -p 8080:8080 -d --rm php:cli php -S 0.0.0.0:8080 -t . index.php
</code></pre>

<p><em>Explanation</em>:</p>

<p>The <code>localhost</code>(or <code>127.0.0.1</code>) address is attached to the container namespace, so anything outside of this namespace cannot have access to it. Furthermore, the <code>0.0.0.0</code> (in this context) is a specific address that means <em>all IPv4 addresses on the local machine</em>. If you check inside the container, you could see:</p>

<pre><code>$ ip a
lo:
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
eth0:
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
</code></pre>

<p>The <code>eth0</code> interface is the interface used when you forward the port. As you don't specify the IP address of the container, you can use the <code>0.0.0.0</code> to listen on the <code>eth0</code> interface.</p>

<p>I don't know if I make my self clear, but you can (should) read this if you want to know more:</p>

<ul>
<li><a href=""https://pythonspeed.com/articles/docker-connection-refused/"" rel=""nofollow noreferrer"">https://pythonspeed.com/articles/docker-connection-refused/</a></li>
<li><a href=""https://superuser.com/questions/949428/whats-the-difference-between-127-0-0-1-and-0-0-0-0"">https://superuser.com/questions/949428/whats-the-difference-between-127-0-0-1-and-0-0-0-0</a></li>
</ul>
",16683,2019-11-25T14:47:02.223,"['docker run --name php -v $(pwd):/app -w /app -p 8080:8080 -d --rm php:cli php -S 0.0.0.0:8080 -t . index.php\n', '$ ip a\nlo:\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\neth0:\n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n']"
1088,9924,9913,CC BY-SA 4.0,2019-11-25T14:51:04.307,"<p>Yes, the <code>PersistentVolumeClaim</code> is the workhorse here. You can evict pods, delete deployments, etc., to your heart's content and so long as you don't delete the PVC, your data will be there.  </p>

<p>You don't need to use <code>StatefulSet</code> for this.  From the docs:</p>

<pre><code>Unlike a Deployment, a StatefulSet maintains a sticky identity for each of their Pods. These pods are created from the same spec, but are not interchangeable: each has a persistent identifier that it maintains across any rescheduling.
</code></pre>

<p><a href=""https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/"" rel=""nofollow noreferrer"">https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/</a></p>

<p>You might want that anyway, but it does nothing for keeping your PV/PVCs around.</p>
",17508,2019-11-25T14:51:04.307,"['Unlike a Deployment, a StatefulSet maintains a sticky identity for each of their Pods. These pods are created from the same spec, but are not interchangeable: each has a persistent identifier that it maintains across any rescheduling.\n']"
1089,9928,9916,CC BY-SA 4.0,2019-11-25T17:04:20.697,"<p>You can use the below command to get all the policy attached to an iam user. (You must be having permissions to list-users and list-user-policies before using the below commands)</p>

<pre><code>aws iam list-attached-user-policies --user-name username | jq -r '.AttachedPolicies[].PolicyArn' | awk -F'policy/' {'print $NF'}
</code></pre>

<p>(Make sure to replace <code>username</code> with some actual iam username in the above command)</p>

<p>If you want to get the list of all users and user-policies attached to those users, you can use the below one line command. The below command will get all the <code>iam users</code> and then will find the <code>user-policies</code> attached to that user and will put in a CSV file. The first column will contain <code>username</code> and second column will contain `policies separated by spaces. </p>

<pre><code>for u_name in $(aws iam list-users | jq -r '.Users[].UserName') ; do permissions=""$(aws iam list-attached-user-policies --user-name ${u_name} | jq -r '.AttachedPolicies[].PolicyArn' | awk -F'policy/' {'print $NF'} | tr '\n' ' ')"" ; echo ""${u_name}, ${permissions}"" &gt;&gt; iam_users.csv ; done
</code></pre>
",12138,2019-11-25T17:04:20.697,"[""aws iam list-attached-user-policies --user-name username | jq -r '.AttachedPolicies[].PolicyArn' | awk -F'policy/' {'print $NF'}\n"", 'for u_name in $(aws iam list-users | jq -r \'.Users[].UserName\') ; do permissions=""$(aws iam list-attached-user-policies --user-name ${u_name} | jq -r \'.AttachedPolicies[].PolicyArn\' | awk -F\'policy/\' {\'print $NF\'} | tr \'\\n\' \' \')"" ; echo ""${u_name}, ${permissions}"" >> iam_users.csv ; done\n']"
1090,9930,9888,CC BY-SA 4.0,2019-11-25T18:03:18.523,"<p>You can use <a href=""https://registry.terraform.io/providers/hashicorp/tfe/0.11.1"" rel=""nofollow noreferrer"">the Terraform Cloud provider</a> to manage workspace configuration in Terraform Cloud in the same way as you might manage any other infrastructure objects with Terraform. For historical reasons the provider is named <code>tfe</code>, but it can be used to manage both Terraform Enterprise and Terraform Cloud.</p>

<p>In particular, you can use <a href=""https://registry.terraform.io/providers/hashicorp/tfe/0.11.1/docs/resources/variable"" rel=""nofollow noreferrer"">the <code>tfe_variable</code> resource type</a> to manage both Terraform variables and environment variables for a workspace:</p>

<pre><code>variable ""environment_variables"" {
  type = map(string)
}

variable ""workspace_id"" {
  type = string
}

provider ""tfe"" {
  hostname = ""app.terraform.io"" # Terraform Cloud
}

resource ""tfe_variable"" ""test"" {
  for_each = var.environment_variables

  key          = each.key
  value        = each.value
  category     = ""env""
  workspace_id = var.workspace_id
}
</code></pre>

<p>To integrate this with the script you've already written, you could perhaps use PowerShell's JSON encoder to produce a file <code>azure.tfvars.json</code> with content like this:</p>

<pre><code>{
  ""workspace_id"": ""organization/workspace"",
  ""environment_variables"": {
    ""ARM_CLIENT_ID"": ""..."",
    ""ARM_CLIENT_SECRET"": ""..."",
    ""ARM_SUBSCRIPTION_ID"": ""..."",
    ""ARM_TENANT_ID"": ""...""
  }
}
</code></pre>

<p>You can then run the above Terraform configuration using a command like this:</p>

<pre><code>terraform apply -var-file=azure.tfvars.json
</code></pre>

<p>When considering automation of this sort it's worth considering where the Terraform state snapshots for this ""early"" Terraform configuration would live. You could potentially create an additional Terraform Cloud workspace for this special configuration and be sure to configure it to <em>not</em> use remote operations, so that a local run of this one workspace can then arrange for your other workspace to support remote operations.</p>
",2463,2019-11-25T18:03:18.523,"['variable ""environment_variables"" {\n  type = map(string)\n}\n\nvariable ""workspace_id"" {\n  type = string\n}\n\nprovider ""tfe"" {\n  hostname = ""app.terraform.io"" # Terraform Cloud\n}\n\nresource ""tfe_variable"" ""test"" {\n  for_each = var.environment_variables\n\n  key          = each.key\n  value        = each.value\n  category     = ""env""\n  workspace_id = var.workspace_id\n}\n', '{\n  ""workspace_id"": ""organization/workspace"",\n  ""environment_variables"": {\n    ""ARM_CLIENT_ID"": ""..."",\n    ""ARM_CLIENT_SECRET"": ""..."",\n    ""ARM_SUBSCRIPTION_ID"": ""..."",\n    ""ARM_TENANT_ID"": ""...""\n  }\n}\n', 'terraform apply -var-file=azure.tfvars.json\n']"
1091,9943,9942,CC BY-SA 4.0,2019-11-26T20:14:06.197,"<p>There seems to be some syntax issues and also I would suggest to use <code>bash</code> instead if using <code>sh</code> shell.</p>

<p>Try the below code and see if this works properly. 
(EDIT - Put shebang on first line to accept as answer)</p>

<pre><code>sh label: 'Stop and Remove Old Docker Container', script: '''#!/usr/bin/env bash
                docker ps -a
                echo $APP_CONTAINER_NAME

                docker ps -a | grep $APP_CONTAINER_NAME || true
                status=(""${PIPESTATUS[@]}"")
                DOCKERCODE=${status[0]}
                GREPCODE=${status[1]}
                echo ""Docker Command Code: $DOCKERCODE""

                echo ""Grep Command Code: $GREPCODE""

                if [ $DOCKERCODE -eq 0 ]; then
                    docker stop $APP_CONTAINER_NAME
                    docker rm $APP_CONTAINER_NAME
                else
                    echo ""WARNING: Docker command was empty or had an error""
                fi
            '''
</code></pre>

<p>In the above code, I have made changes in the way you were trying to get output of command <code>docker ps -a | grep $APP_CONTAINER_NAME || true</code> using <code>PIPESTATUS</code> variable. 
Since <code>PIPESTATUS</code> is a special variable, it's value gets updated after every command, so you were not getting any value of <code>${PIPESTATUS[1]}</code></p>

<p>The other change I have made is fixing the syntax issue in the line <code>if [ $DOCKERCODE -eq 0 ] then;</code> to <code>if [ $DOCKERCODE -eq 0 ]; then</code></p>

<p>You can test out the code further.</p>
",12138,2019-12-13T11:25:01.353,"['sh label: \'Stop and Remove Old Docker Container\', script: \'\'\'#!/usr/bin/env bash\n                docker ps -a\n                echo $APP_CONTAINER_NAME\n\n                docker ps -a | grep $APP_CONTAINER_NAME || true\n                status=(""${PIPESTATUS[@]}"")\n                DOCKERCODE=${status[0]}\n                GREPCODE=${status[1]}\n                echo ""Docker Command Code: $DOCKERCODE""\n\n                echo ""Grep Command Code: $GREPCODE""\n\n                if [ $DOCKERCODE -eq 0 ]; then\n                    docker stop $APP_CONTAINER_NAME\n                    docker rm $APP_CONTAINER_NAME\n                else\n                    echo ""WARNING: Docker command was empty or had an error""\n                fi\n            \'\'\'\n']"
1092,9948,3329,CC BY-SA 4.0,2019-11-27T08:59:53.353,"<p>Docker Prepends the current folder name with all the components name created using docker compose file.</p>

<p>Eg : If the current folder name containing the docker-compose.yml file is test, all the volumes,network and container names will get test appended to it. In order to solve the problem people earlier proposed the idea of using <strong>-p</strong> flag with docker-compose command but the solution is not the most feasible one as a project name is required just after the -p attribute. The project name then gets appended to all the components created using docker compose file.</p>

<p>The <strong>Solution</strong> to the above problem is using the <strong>name</strong> property as in below.</p>

<pre><code>volumes: 
  data:
    driver: local
    name: mongodata

networks: 
  internal-network:
    driver: bridge
    name: frontend-network
</code></pre>

<p>This volume can be referred in the service section as </p>

<pre><code>services:
  mongo-database:
      volumes: 
        - data:/data/db
      networks: 
        - internal-network
</code></pre>

<p>The above <strong>name</strong> attribute will prevent docker-compose to prepend folder name.</p>

<p>Note : For the container name one could use the property <strong>container_name</strong></p>

<pre><code>services:
  mongo-database:
    container_name: mongo
</code></pre>
",15382,2019-11-27T08:59:53.353,"['volumes: \n  data:\n    driver: local\n    name: mongodata\n\nnetworks: \n  internal-network:\n    driver: bridge\n    name: frontend-network\n', 'services:\n  mongo-database:\n      volumes: \n        - data:/data/db\n      networks: \n        - internal-network\n', 'services:\n  mongo-database:\n    container_name: mongo\n']"
1093,9952,9868,CC BY-SA 4.0,2019-11-27T10:58:09.197,"<p>What you need here are the <a href=""https://docs.microsoft.com/en-us/cli/azure/ad/app/permission?view=azure-cli-latest#commands"" rel=""nofollow noreferrer"">az ad app permission</a> commands.</p>

<p>Here is a complete example (assuming powershell):</p>

<pre><code>$apiId = ""00000002-0000-0000-c000-000000000000"" # Windows Azure Active Directory 
$apiPermissionsId = ""78c8a3c8-a07e-4b9e-af1b-b5ccab50a175"" # Directory.ReadWrite.All
$spn = az ad sp create-for-rbac --role=""Owner"" --name blah | ConvertFrom-Json 
az ad app permission add --id $spn.appId --api $apiId --api-permissions (""{0}=Scope"" -f $apiPermissionsId)
az ad app permission grant --id $spn.appId --api $apiId
az ad app permission admin-consent --id $spn.appId
</code></pre>

<p>For reference, Microsoft has <a href=""https://blogs.msdn.microsoft.com/aaddevsup/2018/06/06/guid-table-for-windows-azure-active-directory-permissions/"" rel=""nofollow noreferrer"">a list</a> of the GUIDs used for various applications.</p>

<p>On some occasions I have been unable to find documentation for the magic GUIDs required for a particular app/permission, in which case I would resort to adding them through the portal manually (Azure Active Directory ➔ App Registrations ➔ Required Permissions) and then reading the JSON manifest back to reveal the required GUIDs which can then be plugged into automation.</p>
",18409,2019-11-27T13:45:55.527,"['$apiId = ""00000002-0000-0000-c000-000000000000"" # Windows Azure Active Directory \n$apiPermissionsId = ""78c8a3c8-a07e-4b9e-af1b-b5ccab50a175"" # Directory.ReadWrite.All\n$spn = az ad sp create-for-rbac --role=""Owner"" --name blah | ConvertFrom-Json \naz ad app permission add --id $spn.appId --api $apiId --api-permissions (""{0}=Scope"" -f $apiPermissionsId)\naz ad app permission grant --id $spn.appId --api $apiId\naz ad app permission admin-consent --id $spn.appId\n']"
1094,9961,9953,CC BY-SA 4.0,2019-11-27T22:35:42.237,"<p>Please try splitting this line:</p>

<p><code>RUN apk add git &amp;&amp; git clone https://github.com/s0md3v/Photon.git Photon</code></p>

<p>into two:</p>

<pre><code>RUN apk add git

RUN git clone https://github.com/s0md3v/Photon.git Photon
</code></pre>

<p>This will tell you exactly which piece of the command fails. If it is the <code>apk add git</code> part maybe try this: <code>RUN apk update &amp;&amp; apk add git</code>.</p>

<p>Also you may fixing to a specific tag in the <code>FROM python:3-alpine</code> as <code>3-alpine</code> follows the latest alpine release which may have some unknown/unfixed issues.</p>

<p>See <a href=""https://hub.docker.com/_/python/"" rel=""nofollow noreferrer"">https://hub.docker.com/_/python/</a> for available tags.</p>
",18256,2019-11-27T22:35:42.237,['RUN apk add git\n\nRUN git clone https://github.com/s0md3v/Photon.git Photon\n']
1095,9967,9964,CC BY-SA 4.0,2019-11-28T17:22:30.863,"<p>There is no default password, actually none at all. You must create a new user with</p>

<pre><code>➜ npm adduser --registry  http://localhost:4873/
Username: wow
Password: 
Email: (this IS public) verdaccio.does.ignore.email@whatever.com
Logged in as wow on http://localhost:4873/
</code></pre>

<p>Then you are logged in.</p>
",18428,2019-11-28T17:22:30.863,['➜ npm adduser --registry  http://localhost:4873/\nUsername: wow\nPassword: \nEmail: (this IS public) verdaccio.does.ignore.email@whatever.com\nLogged in as wow on http://localhost:4873/\n']
1096,9968,9909,CC BY-SA 4.0,2019-11-28T21:33:28.423,"<p>With a bridged adapter, your VM would get its IP from the host machine's network DHCP server. This would allow it to be pinged from your internal network. </p>

<p>I'd also specify in your configuration that your cable is connected as so:</p>

<pre><code>VBoxManage modifyvm ""VM"" --cableconnected1 on
</code></pre>

<p>Port forwarding in the VM's configuration would also work. It would allow access from the host machine's IP by just specifying the forwarded port.</p>

<p>To forward port 22 to 2222 you would do as so: </p>

<pre><code>VBoxManage modifyvm ""VM"" --nic1 nat
VBoxManage modifyvm ""VM"" --natpf1 ""guestssh,tcp,,2222,,22""
VBoxManage modifyvm ""VM"" --cableconnected1 on
</code></pre>

<p>If you want it to be accessible by the internet, you would need do port forwarding on your router to route access from your public ip:port to your internal ip:port.</p>

<p><a href=""https://i.stack.imgur.com/Lre4M.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Lre4M.png"" alt=""enter image description here""></a></p>
",13089,2019-11-28T21:33:28.423,"['VBoxManage modifyvm ""VM"" --cableconnected1 on\n', 'VBoxManage modifyvm ""VM"" --nic1 nat\nVBoxManage modifyvm ""VM"" --natpf1 ""guestssh,tcp,,2222,,22""\nVBoxManage modifyvm ""VM"" --cableconnected1 on\n']"
1097,9969,9893,CC BY-SA 4.0,2019-11-29T02:53:54.737,"<p>You have this in your config file:</p>

<pre><code>[inventory]
enable_plugins = host_list, script, auto, yaml, ini, toml
</code></pre>

<p>Do you really need all these plugins?  If not, they'll just add time to your processing.  There is also a small chance that one of them is successfully parsing your inventory file as an empty inventory.  And the <a href=""https://docs.ansible.com/ansible/latest/plugins/inventory.html"" rel=""nofollow noreferrer"">documentation</a> states that</p>

<blockquote>
  <p>Once an inventory plugin succeeds at parsing a source, any remaining inventory plugins will be skipped for that source.</p>
</blockquote>

<p>If you do not need those plugins, I'd comment that line (or rework it to remove some of the items).</p>

<p>Also, are you sure that it is using the local <code>hosts.ini</code>?  The command <code>ansible-config</code> might help confirming that.</p>

<p>Regarding your first question (""<em>Why I have empty hosts.ini in my execute directory</em>""), there is nothing in your playbooks pointing to that file being created or modified.  Did you mean to  have it modified?  Or you don't know how it was created?  The question there is not clear.</p>
",16819,2019-11-29T02:53:54.737,"['[inventory]\nenable_plugins = host_list, script, auto, yaml, ini, toml\n']"
1098,9974,9893,CC BY-SA 4.0,2019-11-29T15:46:42.240,"<p>It sounds like you need to gather facts again once you've updated the inventory. You start off with</p>

<blockquote>
  <p>First I add new host to my hosts.ini file</p>
</blockquote>

<p>However, <strong>Ansible is not notified about this</strong> until you tell it that the inventory has changed. If this is done <em>during</em> a play, you should use the <a href=""https://docs.ansible.com/ansible/latest/modules/add_host_module.html#add-host-module"" rel=""nofollow noreferrer"">add_host</a> module:</p>

<pre><code>- name: Add host gluster1 to group gluster
  add_host:
    name: gluster1
    groups: gluster
</code></pre>

<p>This will update Ansible's facts, <em>i.e.</em> it will contact the new host and find out everything about it, now that it knows it is in the <code>gluster</code> group.</p>

<p>Note that then you should start a new play, against this host:</p>

<pre><code>---
- name: First play to build hosts
  hosts: localhost
  tasks:
    - name: Add host gluster1 to group gluster
      add_host:
        name: gluster1
        groups: gluster
    - name: Persist inventory
      blockinfile:
        path: /var/lib/awx/projects/_52__glusterfs/hosts.ini
        block: |
          gluster1 ansible_user=&lt;user&gt; ansible_host=&lt;ip&gt;
        state: present

- name: Second play to do gluster things
  hosts: gluster  # This group now exists in Ansible's in-memory inventory
  tasks:
    - name: Wait for hosts up
      wait_for:
        host: gluster1
        port: 22
    - name: Be awesome
      debug:
        msg: ""Awesomeness Achieved""
</code></pre>
",354,2019-11-29T15:46:42.240,"['- name: Add host gluster1 to group gluster\n  add_host:\n    name: gluster1\n    groups: gluster\n', '---\n- name: First play to build hosts\n  hosts: localhost\n  tasks:\n    - name: Add host gluster1 to group gluster\n      add_host:\n        name: gluster1\n        groups: gluster\n    - name: Persist inventory\n      blockinfile:\n        path: /var/lib/awx/projects/_52__glusterfs/hosts.ini\n        block: |\n          gluster1 ansible_user=<user> ansible_host=<ip>\n        state: present\n\n- name: Second play to do gluster things\n  hosts: gluster  # This group now exists in Ansible\'s in-memory inventory\n  tasks:\n    - name: Wait for hosts up\n      wait_for:\n        host: gluster1\n        port: 22\n    - name: Be awesome\n      debug:\n        msg: ""Awesomeness Achieved""\n']"
1099,9995,9984,CC BY-SA 4.0,2019-12-02T23:34:33.997,"<p>You can install the Heroku CLI via <code>npm</code> - which might be the simplest. </p>

<p>Note that your Heroku API key has to have the env var name <code>HEROKU_API_KEY</code> for the Heroku CLI to accept it as an auth token (ie. to avoid having to do <code>heroku login</code>). </p>

<pre><code>          - npm install -g heroku

          # build the Docker image (this will use the Dockerfile in the root of the repo)
          - docker build -t $HEROKU_APPLICATION_NAME ./backend
          # authenticate with the Docker Hub registry
          - docker login --username=_ --password $HEROKU_API_KEY registry.heroku.com

          - docker tag $HEROKU_APPLICATION_NAME registry.heroku.com/$HEROKU_APPLICATION_NAME/web
          - docker push registry.heroku.com/$HEROKU_APPLICATION_NAME/web
          - heroku container:release web -a=$HEROKU_APPLICATION_NAME

</code></pre>
",7118,2019-12-02T23:34:33.997,['          - npm install -g heroku\n\n          # build the Docker image (this will use the Dockerfile in the root of the repo)\n          - docker build -t $HEROKU_APPLICATION_NAME ./backend\n          # authenticate with the Docker Hub registry\n          - docker login --username=_ --password $HEROKU_API_KEY registry.heroku.com\n\n          - docker tag $HEROKU_APPLICATION_NAME registry.heroku.com/$HEROKU_APPLICATION_NAME/web\n          - docker push registry.heroku.com/$HEROKU_APPLICATION_NAME/web\n          - heroku container:release web -a=$HEROKU_APPLICATION_NAME\n\n']
1100,9999,9992,CC BY-SA 4.0,2019-12-03T11:47:00.933,"<p>Changing logging driver form journald to json has fixed it. 
I edited <code>/etc/sysconfig/docker</code>, and set </p>

<pre><code>OPTIONS='--selinux-enabled --log-driver=json-file --signature-verification=false'
</code></pre>

<p>Then restarted docker on the nodes I needed:</p>

<pre><code>systemctl daemon-reload &amp;&amp; systemctl restart docker
</code></pre>
",17329,2019-12-03T12:53:52.610,"[""OPTIONS='--selinux-enabled --log-driver=json-file --signature-verification=false'\n"", 'systemctl daemon-reload && systemctl restart docker\n']"
1101,10008,10007,CC BY-SA 4.0,2019-12-03T15:50:01.090,"<p>Elastic was not able to start. The logging indicated:</p>

<pre><code>[2019-12-09T10:22:15,124][INFO ][o.e.b.BootstrapChecks    ] [kViKuCL] bound
or publishing to a non-loopback address, enforcing bootstrap checks
ERROR: [1] bootstrap checks failed
[1]: max virtual memory areas vm.max_map_count [65530] is too low,
increase to at least [262144]
</code></pre>

<p>The latter is also depicted in the <a href=""https://github.com/elastic/stack-docker"" rel=""nofollow noreferrer"">README.md</a>:</p>

<pre><code>sudo sysctl -w vm.max_map_count=262144
</code></pre>

<p>Once this was changed and </p>

<pre><code>docker-compose -f setup.yml up --remove-orphans
</code></pre>

<p><a href=""https://github.com/elastic/stack-docker/issues/73#issuecomment-476068864"" rel=""nofollow noreferrer"">was run</a>, the logging continued:</p>

<pre><code>setup_1  | setup_packetbeat       | Loading dashboards (Kibana must be running and reachable)
setup_1  | setup_heartbeat        | Loaded dashboards
setup_1  | setup_heartbeat        | Copy keystore to ./config dir
setup_1  | setup_heartbeat exited with code 0
setup_1  | setup_auditbeat        | Loaded dashboards
setup_1  | setup_auditbeat        | Copy keystore to ./config dir
setup_1  | setup_auditbeat exited with code 0
setup_1  | setup_packetbeat       | Loaded dashboards
setup_1  | setup_packetbeat       | Copy keystore to ./config dir
setup_1  | setup_packetbeat exited with code 0
setup_1  | setup_metricbeat       | Loaded dashboards
setup_1  | setup_metricbeat       | Copy keystore to ./config dir
setup_1  | setup_metricbeat exited with code 0
setup_1  | setup_filebeat         | Loaded dashboards
setup_1  | setup_filebeat         | Loaded machine learning job configurations
setup_1  | setup_filebeat         | Copy keystore to ./config dir
setup_1  | setup_filebeat exited with code 0
setup_1  | Setup completed successfully. To start the stack please run:
setup_1  |   docker-compose up -d
setup_1  | 
setup_1  | If you wish to remove the setup containers please run:
setup_1  |  docker-compose -f docker-compose.yml -f docker-compose.setup.yml down --remove-orphans
setup_1  | 
setup_1  | You will have to re-start the stack after removing setup containers.
setup_1  | 
setup_1  | Your 'elastic' user password is: mnQ9c5FCGT09sRgHPnw27A==
stack-docker_setup_1 exited with code 0
</code></pre>

<p>Subsequently, running <code>docker-compose up -d</code>, resulted in:</p>

<pre><code>Recreating elasticsearch ... done
Recreating kibana        ... done
Creating logstash        ... done
Creating apm_server      ... done
Creating packetbeat      ... done
Creating metricbeat      ... done
Creating filebeat        ... done
Creating heartbeat       ... done
Creating auditbeat       ... done
</code></pre>

<p>Navigating to <a href=""http://localhost:5601"" rel=""nofollow noreferrer"">http://localhost:5601</a> returns the kibana UI.</p>

<p><a href=""https://i.stack.imgur.com/kIFlT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kIFlT.png"" alt=""enter image description here""></a></p>
",210,2019-12-09T10:25:39.880,"['[2019-12-09T10:22:15,124][INFO ][o.e.b.BootstrapChecks    ] [kViKuCL] bound\nor publishing to a non-loopback address, enforcing bootstrap checks\nERROR: [1] bootstrap checks failed\n[1]: max virtual memory areas vm.max_map_count [65530] is too low,\nincrease to at least [262144]\n', 'sudo sysctl -w vm.max_map_count=262144\n', 'docker-compose -f setup.yml up --remove-orphans\n', ""setup_1  | setup_packetbeat       | Loading dashboards (Kibana must be running and reachable)\nsetup_1  | setup_heartbeat        | Loaded dashboards\nsetup_1  | setup_heartbeat        | Copy keystore to ./config dir\nsetup_1  | setup_heartbeat exited with code 0\nsetup_1  | setup_auditbeat        | Loaded dashboards\nsetup_1  | setup_auditbeat        | Copy keystore to ./config dir\nsetup_1  | setup_auditbeat exited with code 0\nsetup_1  | setup_packetbeat       | Loaded dashboards\nsetup_1  | setup_packetbeat       | Copy keystore to ./config dir\nsetup_1  | setup_packetbeat exited with code 0\nsetup_1  | setup_metricbeat       | Loaded dashboards\nsetup_1  | setup_metricbeat       | Copy keystore to ./config dir\nsetup_1  | setup_metricbeat exited with code 0\nsetup_1  | setup_filebeat         | Loaded dashboards\nsetup_1  | setup_filebeat         | Loaded machine learning job configurations\nsetup_1  | setup_filebeat         | Copy keystore to ./config dir\nsetup_1  | setup_filebeat exited with code 0\nsetup_1  | Setup completed successfully. To start the stack please run:\nsetup_1  |   docker-compose up -d\nsetup_1  | \nsetup_1  | If you wish to remove the setup containers please run:\nsetup_1  |  docker-compose -f docker-compose.yml -f docker-compose.setup.yml down --remove-orphans\nsetup_1  | \nsetup_1  | You will have to re-start the stack after removing setup containers.\nsetup_1  | \nsetup_1  | Your 'elastic' user password is: mnQ9c5FCGT09sRgHPnw27A==\nstack-docker_setup_1 exited with code 0\n"", 'Recreating elasticsearch ... done\nRecreating kibana        ... done\nCreating logstash        ... done\nCreating apm_server      ... done\nCreating packetbeat      ... done\nCreating metricbeat      ... done\nCreating filebeat        ... done\nCreating heartbeat       ... done\nCreating auditbeat       ... done\n']"
1102,10010,9990,CC BY-SA 4.0,2019-12-03T16:27:32.727,"<p>The problem is twofold:</p>

<ul>
<li><p>The Win10 LTSB is on its newest version and Docker has stopped supporting this version.<br>
This stops Docker from updating.</p></li>
<li><p>Microsoft has moved to its own container registry and in doing so abandoned support for older Docker versions. So while I was pulling from the right registry it could not find a fitting image.</p></li>
</ul>

<p><strong>Solution:</strong> get an up-to-date, non-LTSB version of Windows</p>

<p>Additional Info:<br>
While the error message did not help in finding the cause the docker log did:</p>

<pre><code>[WindowsDaemon  ][Info   ] debug: a Windows version 10.0.18363-based image is incompatible with a 10.0.14393 host
</code></pre>
",18471,2019-12-03T16:27:32.727,['[WindowsDaemon  ][Info   ] debug: a Windows version 10.0.18363-based image is incompatible with a 10.0.14393 host\n']
1103,10015,10013,CC BY-SA 4.0,2019-12-03T19:14:07.400,"<p>AzureFile didn't support that operation, so I tried AzureDisk and it worked. This is what I used:</p>

<pre><code>apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: cockroach-disk
  namespace: cockroach
provisioner: kubernetes.io/azure-disk
parameters:
  storageaccounttype: Standard_LRS
  kind: Managed
  #resourceGroup: CockroachStorage
reclaimPolicy: Retain
allowVolumeExpansion: true
</code></pre>
",18489,2019-12-03T19:14:07.400,['apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: cockroach-disk\n  namespace: cockroach\nprovisioner: kubernetes.io/azure-disk\nparameters:\n  storageaccounttype: Standard_LRS\n  kind: Managed\n  #resourceGroup: CockroachStorage\nreclaimPolicy: Retain\nallowVolumeExpansion: true\n']
1104,10028,9944,CC BY-SA 4.0,2019-12-05T05:31:38.983,"<p>You may use and update a flag to <code>false</code> in the <code>catch</code> and then use that flag in the <code>when</code> directive of other stage(s) that you want to skip because of any failure in the given stage. Example:  </p>

<pre><code>boolean flagStageOneSuccess = false

pipeline {
    agent any

    stages {
        stage ('stage-1') {
            steps {
                try {
                    // Do something that might fail

                    flagStageOneSuccess = true

                } catch (Exception e) {
                    // Handle the exception
                    flagStageOneSuccess = false
                }
            }
        }

        stage ('stage-2') {
            when {
                equals expected: true, actual: flagStageOneSuccess
            }
            steps {
                // Do something in stage-2
            }
        }
    }
}
</code></pre>

<p>It would also benefit you in viewing the status of your stage in <code>Blue Ocean</code>. If the stage is skipped, it shows as 'Not built'.</p>
",17684,2019-12-05T05:41:04.413,"[""boolean flagStageOneSuccess = false\n\npipeline {\n    agent any\n\n    stages {\n        stage ('stage-1') {\n            steps {\n                try {\n                    // Do something that might fail\n\n                    flagStageOneSuccess = true\n\n                } catch (Exception e) {\n                    // Handle the exception\n                    flagStageOneSuccess = false\n                }\n            }\n        }\n\n        stage ('stage-2') {\n            when {\n                equals expected: true, actual: flagStageOneSuccess\n            }\n            steps {\n                // Do something in stage-2\n            }\n        }\n    }\n}\n""]"
1105,10045,10042,CC BY-SA 4.0,2019-12-07T01:14:58.410,"<p>You are not accessing the hosts network interface information. Rather you are receiving data of the bridge adapter created for your Docker Containers Network.</p>

<p>Please note the results from my web server:</p>

<p>Container networking info:</p>

<pre><code># docker exec -it ghost sh
/var/lib/ghost # ifconfig
eth0      Link encap:Ethernet  HWaddr 02:42:AC:12:00:02  
          inet addr:172.18.0.2  Bcast:172.18.255.255  Mask:255.255.0.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:20 errors:0 dropped:0 overruns:0 frame:0
          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0 
          RX bytes:1536 (1.5 KiB)  TX bytes:0 (0.0 B)
</code></pre>

<p>Host network info:</p>

<pre><code>root@li293-xxx:/data/mydomain.us# ifconfig
br-08d99d9f172e: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
    inet 172.18.0.1  netmask 255.255.0.0  broadcast 172.18.255.255
    inet6 fe80::42:57ff:fe74:c49b  prefixlen 64  scopeid 0x20&lt;link&gt;
    ether 02:42:57:74:c4:9b  txqueuelen 0  (Ethernet)
    RX packets 150  bytes 16535 (16.5 KB)
    RX errors 0  dropped 0  overruns 0  frame 0
    TX packets 234  bytes 21425 (21.4 KB)
    TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

docker0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500
    inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255
    ether 02:42:82:3d:17:63  txqueuelen 0  (Ethernet)
    RX packets 0  bytes 0 (0.0 B)
    RX errors 0  dropped 0  overruns 0  frame 0
    TX packets 0  bytes 0 (0.0 B)
    TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
    inet 66.xxx.xxx.205  netmask 255.255.255.0  broadcast 66.xxx.xxx.255
</code></pre>

<p>Please review the networking documentation at <a href=""https://docs.docker.com/v17.09/engine/userguide/networking/"" rel=""nofollow noreferrer"">https://docs.docker.com/v17.09/engine/userguide/networking/</a></p>
",6131,2019-12-07T01:14:58.410,"['# docker exec -it ghost sh\n/var/lib/ghost # ifconfig\neth0      Link encap:Ethernet  HWaddr 02:42:AC:12:00:02  \n          inet addr:172.18.0.2  Bcast:172.18.255.255  Mask:255.255.0.0\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:20 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:1536 (1.5 KiB)  TX bytes:0 (0.0 B)\n', 'root@li293-xxx:/data/mydomain.us# ifconfig\nbr-08d99d9f172e: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n    inet 172.18.0.1  netmask 255.255.0.0  broadcast 172.18.255.255\n    inet6 fe80::42:57ff:fe74:c49b  prefixlen 64  scopeid 0x20<link>\n    ether 02:42:57:74:c4:9b  txqueuelen 0  (Ethernet)\n    RX packets 150  bytes 16535 (16.5 KB)\n    RX errors 0  dropped 0  overruns 0  frame 0\n    TX packets 234  bytes 21425 (21.4 KB)\n    TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\ndocker0: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500\n    inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255\n    ether 02:42:82:3d:17:63  txqueuelen 0  (Ethernet)\n    RX packets 0  bytes 0 (0.0 B)\n    RX errors 0  dropped 0  overruns 0  frame 0\n    TX packets 0  bytes 0 (0.0 B)\n    TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500\n    inet 66.xxx.xxx.205  netmask 255.255.255.0  broadcast 66.xxx.xxx.255\n']"
1106,10049,9991,CC BY-SA 4.0,2019-12-07T20:51:39.123,"<p>According to <a href=""https://serverfault.com/questions/757210/no-command-specified-from-re-imported-docker-image-container#comment1247323_797619"">@earcam</a> one can run a <code>docker inspect &lt;id&gt;</code> to check whether an image contains a CMD. If one builds a docker image using the provided packer snippet in the Q&amp;A, imports it and subsequently runs a <code>docker inspect 1127c20077ef | grep -i cmd</code>, the CMD has not been set:</p>

<pre><code>""Cmd"": null,
</code></pre>

<p>According to <a href=""https://serverfault.com/a/797619/215599"">@Greendrake</a> when has to set the context when importing an image by defining <code>--change 'CMD [""somecommand""]'</code></p>

<pre><code>docker import --change 'CMD [""bash""]' image.tar
</code></pre>

<p>and subsequently issue an:</p>

<pre><code>docker inspect b604fa244510 | grep -A3 -i cmd
        ""Cmd"": [
            ""bash""
        ],
</code></pre>

<p>Once the image has been imported and docker run is issued a shell is opened:</p>

<pre><code>docker run -it b604fa244510
root@69df4b3f48a2:/#
</code></pre>

<p>instead of</p>

<pre><code>docker run -p 21:21 -it --rm 02163a32f3b7
docker: Error response from daemon: No command specified.
See 'docker run --help'.
</code></pre>
",210,2019-12-07T20:51:39.123,"['""Cmd"": null,\n', 'docker import --change \'CMD [""bash""]\' image.tar\n', 'docker inspect b604fa244510 | grep -A3 -i cmd\n        ""Cmd"": [\n            ""bash""\n        ],\n', 'docker run -it b604fa244510\nroot@69df4b3f48a2:/#\n', ""docker run -p 21:21 -it --rm 02163a32f3b7\ndocker: Error response from daemon: No command specified.\nSee 'docker run --help'.\n""]"
1107,10051,10050,CC BY-SA 4.0,2019-12-07T22:33:23.207,"<p>One option to solve this issue is a suggestion as provided by <a href=""https://stackoverflow.com/a/51889996/2777965"">@AndreasGajdosik</a>, i.e. deleting the <code>.minishift</code> directory.</p>

<p>Once <code>rm -rf ~/.minishift</code> was issued and <code>minishift status</code> was run, the issue has been solved:</p>

<pre><code>user@host$ minishift status
Does Not Exist
</code></pre>
",210,2019-12-07T22:33:23.207,['user@host$ minishift status\nDoes Not Exist\n']
1108,10052,9991,CC BY-SA 4.0,2019-12-08T20:57:17.317,"<blockquote>
  <p>And then I start like this <code>docker run -p 21:21 -it --rm 52c0b0362362 bash</code></p>
</blockquote>

<p>This would not work by design. When you run the image with the command above you are instructing Docker to overwrite the <code>CMD</code> instruction from your Dockerfile and therefore telling it to execute <code>bash</code> instead of <code>sudo myprogram</code>. It doesn't matter what you have set in the <code>CMD</code> instruction - it would never be executed.</p>

<p>One way you could go around this would be to use <a href=""https://docs.docker.com/engine/reference/builder/#entrypoint"" rel=""noreferrer""><code>ENTRYPOINT</code></a> as others have suggested. This will make <code>sudo myprogram</code> the default command and then <code>CMD</code> can act as ""additional arguments"" to the default command (<code>sudo myprogram</code>). </p>

<p>Here's a working example:</p>

<pre><code># build.json
{
    ""builders"": [
        {
            ""type"": ""docker"",
            ""image"": ""ubuntu:latest"",
            ""commit"": true,
            ""changes"": [
                ""ONBUILD RUN apt-get -q update"",
                ""ONBUILD RUN apt-get install -y -q htop"",
                ""ENTRYPOINT [\""top\""]""
            ]
        }
    ]
}

# /packer build ./build.json

# run top with delay 3 sec
# docker run --rm -it sha256:hash

# run top with delay 1 sec
# docker run --rm -it sha256:hash -d 1
</code></pre>

<p>The other solution would be to keep the <code>CMD [\""sudo myprogram\""]</code> instruction but to run the image without adding a command at the end: <code>docker run -it --rm HASH_ID</code>. </p>
",5592,2019-12-08T20:57:17.317,"['# build.json\n{\n    ""builders"": [\n        {\n            ""type"": ""docker"",\n            ""image"": ""ubuntu:latest"",\n            ""commit"": true,\n            ""changes"": [\n                ""ONBUILD RUN apt-get -q update"",\n                ""ONBUILD RUN apt-get install -y -q htop"",\n                ""ENTRYPOINT [\\""top\\""]""\n            ]\n        }\n    ]\n}\n\n# /packer build ./build.json\n\n# run top with delay 3 sec\n# docker run --rm -it sha256:hash\n\n# run top with delay 1 sec\n# docker run --rm -it sha256:hash -d 1\n']"
1109,10056,10054,CC BY-SA 4.0,2019-12-09T18:43:56.717,"<p>kubernetes is picky and case-sensitive:</p>

<p><code>kind: Pod</code></p>

<p>should do it.</p>

<p>Also, <code>spec</code> should not be in <code>metadata</code>:</p>

<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: Testing
spec:
  containers:
  - name: mysql
    image: mysql
    imagePullPolicy: Always
    command: [""echo"", ""SUCCESS""]
</code></pre>
",17508,2019-12-09T18:43:56.717,"['apiVersion: v1\nkind: Pod\nmetadata:\n  name: Testing\nspec:\n  containers:\n  - name: mysql\n    image: mysql\n    imagePullPolicy: Always\n    command: [""echo"", ""SUCCESS""]\n']"
1110,10081,10070,CC BY-SA 4.0,2019-12-12T04:09:13.693,"<p>I needed to add:</p>

<pre><code>variables:
- group: front_end-storage
</code></pre>

<p>At the top of my pipeline for the pipeline to pick up on the variables and authorize the group.</p>
",18606,2019-12-12T04:09:13.693,['variables:\n- group: front_end-storage\n']
1111,10085,10084,CC BY-SA 4.0,2019-12-12T09:52:31.930,"<p>Yes, it can be done.</p>

<p>You can either create an IAM instance role which allows the instance to use ec2 actions such as ""create-image"" or you can create an IAM user and create for this user access and secret keys and a policy which allows this user to create images in ec2 and then configure the access and secret keys locally on the server using the ""aws configure"" command.</p>

<p>Whatever method you choose from the above options, the next step would be from within the instance itself and assuming you have aws-cli installed in the instance, first run:</p>

<p><code>ec2-metadata -i</code> to get the instance id.</p>

<p>and then run:</p>

<pre><code>aws ec2 create-image --instance-id INSTANCEID --name NameOfImage --no-reboot --region REGION
</code></pre>

<p>And it will create an image of this instance in the region you provided without rebooting the instance.</p>

<p>The create-image command will create an image of the instance, also called AMI which then you can use to create new instances from.</p>
",12614,2019-12-12T09:52:31.930,['aws ec2 create-image --instance-id INSTANCEID --name NameOfImage --no-reboot --region REGION\n']
1112,10100,5256,CC BY-SA 4.0,2019-12-13T06:34:32.073,"<p>There is Tomcat configuration file for the logging: <code>TOMCAT_HOME/conf/logging.properties</code>.
Edit the file and remove all the handlers except the console handler:</p>

<pre><code>.handlers = java.util.logging.ConsoleHandler
</code></pre>

<p>This will direct all logging to the console, <strong>except</strong> for access logs (localhost_access_log.XXXX.txt). It is always written to file by the AccessLogValve, configured in 'server.xml'. To redirect that one you need to configure own implementation of the AbstractAccessLogValve... which requires coding.</p>
",18649,2019-12-13T06:34:32.073,['.handlers = java.util.logging.ConsoleHandler\n']
1113,10105,10104,CC BY-SA 4.0,2019-12-13T14:42:08.947,"<p>I don't know of any current plugins for doing this.  That may because a lot of backup functionality is built into MSSQL.</p>

<p>The easiest way to automate a backup via Jenkins may be to use a command line script to use a <a href=""https://docs.microsoft.com/en-us/sql/relational-databases/backup-restore/create-a-full-database-backup-sql-server?view=sql-server-ver15"" rel=""nofollow noreferrer"">sql command</a>:</p>

<pre><code>Sqlcmd -E -S touch -Q"" BACKUP DATABASE [DBName] TO DISK = 'C:\artifact_directory\my_db_backup.BAK'</code></pre>

<p>You could also also avoid automating this via Jenkins and just create a <a href=""https://support.microsoft.com/en-us/help/2019698/how-to-schedule-and-automate-backups-of-sql-server-databases-in-sql-se"" rel=""nofollow noreferrer"">scheduled backup</a> directly within SQL Server.</p>
",15792,2019-12-13T14:42:08.947,"['Sqlcmd -E -S touch -Q"" BACKUP DATABASE [DBName] TO DISK = \'C:\\artifact_directory\\my_db_backup.BAK\'']"
1114,10123,10111,CC BY-SA 4.0,2019-12-16T07:56:49.673,"<p>You can use -e switch for that purpose:</p>

<pre><code>ansible-playbook -e 'foo=${FOO}'
</code></pre>

<p>where the FOO can be defined in the Jenkins envirionment variables. If it is defined within the parameters block of your Jenkinsfile, then you need to use <code>${params.foo}</code>. Then, the value can be accessed by the Ansible playbook with <code>{{ foo }}</code>.</p>
",18678,2019-12-16T08:11:02.677,"[""ansible-playbook -e 'foo=${FOO}'\n""]"
1115,10129,2155,CC BY-SA 4.0,2019-12-16T18:40:08.193,"<p>At a command prompt run <code>ipconfig /all</code> and look for a <code>DNS Servers</code> line in the output with something that looks like an IP address. That's your host machine's DNS server(s).</p>

<p>Edit <code>C:\ProgramData\Docker\config\daemon.json</code> and add a <code>dns</code> entry with that IP address. For example, if your DNS Server is 192.10.0.2 and 8.8.8.8 is Google's DNS as a backup:</p>

<pre><code>{
    ""dns"": [""192.10.0.2"", ""8.8.8.8""]
}
</code></pre>

<p>Now restart Docker Desktop and the remote URLs can be resolved by Docker, either at build or runtime.</p>

<p>This solution came from Faithful Anere at <a href=""https://medium.com/@faithfulanere/solved-docker-build-could-not-resolve-archive-ubuntu-com-apt-get-fails-to-install-anything-9ea4dfdcdcf2"" rel=""nofollow noreferrer"">https://medium.com/@faithfulanere/solved-docker-build-could-not-resolve-archive-ubuntu-com-apt-get-fails-to-install-anything-9ea4dfdcdcf2</a></p>
",18687,2019-12-16T18:40:08.193,"['{\n    ""dns"": [""192.10.0.2"", ""8.8.8.8""]\n}\n']"
1116,10131,10114,CC BY-SA 4.0,2019-12-17T08:30:48.867,"<p>Migrating data directory between major db version can be problematic.</p>

<p>I can suggest to create and restore db dump.
You can upgrade postgresql db container as follow:</p>

<ol>
<li>Backup database  </li>
<li>Shutdown postgres 11 container </li>
<li>Run new postgres 12 container </li>
<li>Restore backup</li>
</ol>

<p>or single line command:</p>

<pre><code>docker exec postgres-11-container pg_dumpall -U postgres | docker exec -i postgres-12-container psql -U postgres
</code></pre>
",6060,2019-12-17T08:30:48.867,['docker exec postgres-11-container pg_dumpall -U postgres | docker exec -i postgres-12-container psql -U postgres\n']
1117,10136,10135,CC BY-SA 4.0,2019-12-17T13:25:53.780,"<p>I used something like that in the simple flask app image:</p>

<pre><code>stage('Deploy') {
        steps {
            sh 'docker build -t flask-sample:latest .'
            sh 'docker run -d --rm --name hello_app_flask -p 4010:4000 flask-sample:latest'
}
</code></pre>

<p>But I don't know wether it is approppriate option. Maybe, someone knows the 'proper' way to do it.</p>
",18678,2019-12-17T13:25:53.780,"[""stage('Deploy') {\n        steps {\n            sh 'docker build -t flask-sample:latest .'\n            sh 'docker run -d --rm --name hello_app_flask -p 4010:4000 flask-sample:latest'\n}\n""]"
1118,10137,10135,CC BY-SA 4.0,2019-12-17T13:40:27.293,"<p>You have to extend the <code>jenkins/jenkins:lts</code> to install the Docker client:</p>

<pre><code>FROM jenkins/jenkins:lts

# Switch to root
USER root

ENV DOCKER_VERSION      docker-18.06.3-ce
ARG DOCKER_GID=993 # put the correct docker gid

# Download and install docker client
RUN wget --quiet -O- \
  https://download.docker.com/linux/static/stable/x86_64/${DOCKER_VERSION}.tgz | \
  tar zx --strip-components=1 -C /usr/local/bin docker/docker \
  &amp;&amp; groupadd -g ${DOCKER_GID} docker \
  &amp;&amp; usermod -aG docker jenkins

# Switch back to jenkins user
USER jenkins
</code></pre>

<p>You can now declare pipelines with docker agents.</p>
",16683,2019-12-17T13:40:27.293,['FROM jenkins/jenkins:lts\n\n# Switch to root\nUSER root\n\nENV DOCKER_VERSION      docker-18.06.3-ce\nARG DOCKER_GID=993 # put the correct docker gid\n\n# Download and install docker client\nRUN wget --quiet -O- \\\n  https://download.docker.com/linux/static/stable/x86_64/${DOCKER_VERSION}.tgz | \\\n  tar zx --strip-components=1 -C /usr/local/bin docker/docker \\\n  && groupadd -g ${DOCKER_GID} docker \\\n  && usermod -aG docker jenkins\n\n# Switch back to jenkins user\nUSER jenkins\n']
1119,10141,10140,CC BY-SA 4.0,2019-12-17T18:15:11.787,"<p>You can specify the script in the ""execute shell"" step of the build. <em>Where</em> it gets executed will depend on what labels the job needs, and which nodes those labels are associated with.</p>

<p>It sounds like you want to execute this script on an agent. As long as the agent is available, you can request it via a label in the job configuration. It's a bit difficult to determine this without having access to your setup, but if <em>e.g.</em> you have a set of agents on Debian boxes, you could attach the label <code>debian</code> to them, and specify that the job should run on <code>debian</code> nodes in the job configuration. </p>

<p>If on the other hand it should be run on <code>master</code> (where Jenkins itself is running), you can specify the label <code>master</code>.</p>

<p>You thus need to put your script into the ""Execute Shell"" box that Jenkins provides you, perhaps declaring what shell and options you want to use:</p>

<pre><code>/bin/bash -xe
du -sh /bbhome/shared/data/repositories/* |sort -h |tail -20 |
while IFS= read -r line;do
        DIR=`echo $line | awk '{print$2}'`
        Rep=`cat $DIR/repository-config |grep 'project\|repo' |  tr '\n' ' '`
        Size=`echo $line | awk '{print $1}' `
        echo $Size $Rep
done
</code></pre>

<blockquote>
  <p>I need also to add an ssh command to the environment. This should be executed using passwordless authentication.</p>
</blockquote>

<p>For this to happen, you need ssh keys to be exchanged with the host onto which you want to ssh into.</p>
",354,2019-12-18T07:45:13.100,"[""/bin/bash -xe\ndu -sh /bbhome/shared/data/repositories/* |sort -h |tail -20 |\nwhile IFS= read -r line;do\n        DIR=`echo $line | awk '{print$2}'`\n        Rep=`cat $DIR/repository-config |grep 'project\\|repo' |  tr '\\n' ' '`\n        Size=`echo $line | awk '{print $1}' `\n        echo $Size $Rep\ndone\n""]"
1120,10143,10142,CC BY-SA 4.0,2019-12-18T00:22:31.457,"<p>Since this confused the hell out of me and cost me about an hour to figure out, I am going to post an answer.</p>

<p>As you can see I am using <code>ansible_python</code> to determine the Python version and install the appropriate version of <code>dnspython</code>. Since this is on Ubuntu 18.04 it defaults to <code>python3</code>. I am suppressing the respective warning with <code>interpreter_python=auto</code> in the <code>ansible.cfg</code> inside the same folder.</p>

<p>But here's the bummer. Apparently <code>connection: local</code> somehow violates the rule about using <code>python3</code> whose <code>dnspython</code> package is installed. It made sense once I looked for <code>dig.py</code> (hoping for the <a href=""https://docs.ansible.com/ansible/latest/plugins/lookup/dig.html"" rel=""nofollow noreferrer"">Ansible lookup module of the same name</a>). And indeed I found it:</p>

<pre><code>$ locate dig.py
/usr/lib/python2.7/dist-packages/ansible/plugins/lookup/dig.py
/usr/lib/python2.7/dist-packages/ansible/plugins/lookup/dig.pyc
</code></pre>

<p>... alas, this means my version of Ansible uses Python 2.7 and so the <code>dig</code> module won't be able to make use of the <code>python3-dnspython</code> (Debian) package which I installed.</p>

<p>Still puzzling. But with the cause determined, I can work around it now.</p>
",10715,2019-12-18T00:22:31.457,['$ locate dig.py\n/usr/lib/python2.7/dist-packages/ansible/plugins/lookup/dig.py\n/usr/lib/python2.7/dist-packages/ansible/plugins/lookup/dig.pyc\n']
1121,10144,10142,CC BY-SA 4.0,2019-12-18T02:53:21.290,"<blockquote>
  <p>Q: <em>""None of that explains why - and that is/was my point - <strong>ansible_python wrongly claims to be running on Python 3.x on the local node</strong>. Because all I do by setting <strong>interpreter_python</strong> in ansible.cfg is to give Ansible free rein on how it interprets things.""</em></p>
</blockquote>

<p>A: Configuration option <em>interpreter_python</em> works as expected i.e. there is nothing wrong when Python3 is discovered (when asked by <code>interpreter_python=auto</code>). See Note 1) and examples below.</p>

<ul>
<li><a href=""https://docs.ansible.com/ansible/latest/reference_appendices/config.html#interpreter-python"" rel=""nofollow noreferrer"">auto_legacy</a> default is <em>/usr/bin/python</em></li>
</ul>

<blockquote>
  <p><em>""The default value of <strong>auto_legacy</strong> provides all the same behavior, but for backwards-compatibility with older Ansible releases that always defaulted to <strong>/usr/bin/python</strong>, will use that interpreter if present (and issue a warning that the default behavior will change to that of auto in a future Ansible release.""</em></p>
</blockquote>

<pre><code>interpreter_python=auto_legacy
</code></pre>

<pre><code>$ ansible localhost -m setup -a 'filter=ansible_python_version'
[DEPRECATION WARNING]: Distribution Ubuntu 19.04 on host localhost should use /usr/bin/python3, but is using /usr/bin/python for backward compatibility with prior Ansible releases. A future
 Ansible release will default to using the discovered platform python for this host. See https://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more 
information. This feature will be removed in version 2.12. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.
localhost | SUCCESS =&gt; {
    ""ansible_facts"": {
        ""ansible_python_version"": ""2.7.16"", 
        ""discovered_interpreter_python"": ""/usr/bin/python""
    }, 
    ""changed"": false
}
</code></pre>

<ul>
<li>auto</li>
</ul>

<p>See implementation details of the function <a href=""https://github.com/ansible/ansible/blob/devel/lib/ansible/executor/interpreter_discovery.py"" rel=""nofollow noreferrer"">discover_interpreter</a>.</p>

<p>When the version of the distro is not in <a href=""https://docs.ansible.com/ansible/latest/reference_appendices/config.html#interpreter-python-distro-map"" rel=""nofollow noreferrer"">INTERPRETER_PYTHON_DISTRO_MAP</a></p>

<blockquote>
  <p><em>""return nearest previous version we're newer than""</em></p>
</blockquote>

<pre><code>def _version_fuzzy_match(version, version_map):
...
    # slot match; return nearest previous version we're newer than
    kpos = bisect.bisect(sorted_looseversions, find_looseversion)
</code></pre>

<pre><code>interpreter_python=auto
</code></pre>

<pre><code>$ ansible localhost -m setup -a 'filter=ansible_python_version'
localhost | SUCCESS =&gt; {
    ""ansible_facts"": {
        ""ansible_python_version"": ""3.7.3"", 
        ""discovered_interpreter_python"": ""/usr/bin/python3""
    }, 
    ""changed"": false
}
</code></pre>

<blockquote>
  <p>Q: <em>""What does the ansible command line tool have to do with the behavior I see with ansible-playbook?""</em></p>
</blockquote>

<p>A: Both ansible command line tool and ansible-playbook will report the same value of <em>ansible_python_version</em>. For example</p>

<pre><code>$ ansible localhost -m setup | grep ansible_python_version
        ""ansible_python_version"": ""2.7.16"",
</code></pre>

<pre><code>$ cat playbook.yml
- hosts: localhost
  tasks:
    - debug:
        var: ansible_python_version

$ ansible-playbook playbook.yml

ok: [localhost] =&gt; {
    ""ansible_python_version"": ""2.7.16""
}
</code></pre>

<p><hr>
Notes</p>

<p>1) <a href=""https://docs.ansible.com/ansible/latest/reference_appendices/config.html#interpreter-python"" rel=""nofollow noreferrer"">interpreter_python</a> configuration parameter says:</p>

<blockquote>
  <p>Path to the Python interpreter to be used for module execution <strong>on remote targets</strong></p>
</blockquote>

<p>See <a href=""https://stackoverflow.com/questions/59380824/how-to-choose-a-python-interpreter-for-ansible-playbook/"">how to choose a python interpreter for Ansible playbook?</a></p>

<p>2) Ansible will tell what Python is used <strong>on master</strong></p>

<pre><code>$ ansible --version
ansible 2.9.2
  config file = /home/vlado/.ansible.cfg
  configured module search path = [u'/home/vlado/.ansible/my_modules']
  ansible python module location = /usr/lib/python2.7/dist-packages/ansible
  executable location = /usr/bin/ansible
  python version = 2.7.16 (default, Oct  7 2019, 17:36:04) [GCC 8.3.0]
</code></pre>

<p>3) <a href=""https://docs.ansible.com/ansible/latest/plugins/lookup/dig.html#dig-query-dns-using-the-dnspython-library"" rel=""nofollow noreferrer"">dig</a> says</p>

<blockquote>
  <p>The below requirements are needed <strong>on the local master node</strong> that executes this lookup: dnspython</p>
</blockquote>

<p>4) It's possible to install both versions</p>

<pre><code>$ dpkg -l | grep dnspython
ii  python-dnspython         1.16.0-1 all          DNS toolkit for Python
ii  python3-dnspython        1.16.0-1 all          DNS toolkit for Python 3
</code></pre>

<p>5) All <a href=""https://packages.ubuntu.com/search?keywords=ansible"" rel=""nofollow noreferrer"">Ansible packages in Ubuntu</a> have been built with Python2 at the moment.</p>

<p>6) <code>ansible_python_interpreter</code> works as expected</p>

<p>With Ubuntu <strong>on master</strong> the playbook</p>

<pre><code>$ cat playbook.yml
- hosts: test_01
  tasks:
    - getent:
        database: hosts
</code></pre>

<pre><code>$ cat hosts
test_01 ansible_python_interpreter=/usr/local/bin/python3.6
</code></pre>

<pre><code>$ ansible-playbook playbook.yml -i hosts -vvv | grep python
</code></pre>

<p>gives</p>

<blockquote>
  <p>ansible python module location = /usr/lib/python2.7/dist-packages/ansible
    python version = 2.7.16 (default, Oct  7 2019, 17:36:04) [GCC 8.3.0]</p>
</blockquote>

<p>...</p>

<blockquote>
  <p> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""admin""' -o ConnectTimeout=10 -o ControlPath=/export/home/vlado.config/.ansible/cp/5a3ab05cf7 -tt test_01 '/bin/sh -c '""'""'sudo -H -S -n  -u root /bin/sh -c '""'""'""'""'""'""'""'""'echo BECOME-SUCCESS-xnvwkdksdqqoehvrgebdgcnrzcrmoszv ; /usr/local/bin/python3.6 /home/admin/.ansible/tmp/ansible-tmp-1576667662.62-67468482045094/AnsiballZ_getent.py'""'""'""'""'""'""'""'""' &amp;&amp; sleep 0'""'""''</p>
</blockquote>

<ul>
<li>ansible-playbook <strong>on master</strong> runs with <code>python version = 2.7.16</code></li>
<li>module <strong>on remote</strong> (test_01) runs with <code>/usr/local/bin/python3.6</code></li>
</ul>

<p><strong>Change ansible_python_interpreter</strong></p>

<p>When the ansible_python_interpreter is changed</p>

<pre><code>$ cat hosts
test_01 ansible_python_interpreter=/usr/local/bin/python2.7
</code></pre>

<p>the same playbook gives</p>

<blockquote>
  <p>ansible python module location = /usr/lib/python2.7/dist-packages/ansible
    python version = 2.7.16 (default, Oct  7 2019, 17:36:04) [GCC 8.3.0]</p>
</blockquote>

<p>...</p>

<blockquote>
  <p> SSH: EXEC ssh -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User=""admin""' -o ConnectTimeout=10 -o ControlPath=/export/home/vlado.config/.ansible/cp/5a3ab05cf7 -tt test_01 '/bin/sh -c '""'""'sudo -H -S -n  -u root /bin/sh -c '""'""'""'""'""'""'""'""'echo BECOME-SUCCESS-fidpgwptggdoizirumvjmzuorxqawypu ; /usr/local/bin/python2.7 /home/admin/.ansible/tmp/ansible-tmp-1576668475.22-210929624017605/AnsiballZ_getent.py'""'""'""'""'""'""'""'""' &amp;&amp; sleep 0'""'""''</p>
</blockquote>

<ul>
<li>ansible-playbook <strong>on master</strong> runs with <code>python version = 2.7.16</code></li>
<li>but module <strong>on remote</strong> (test_01) runs with <code>/usr/local/bin/python2.7</code> as requested</li>
</ul>
",7715,2019-12-18T17:52:00.100,"['interpreter_python=auto_legacy\n', '$ ansible localhost -m setup -a \'filter=ansible_python_version\'\n[DEPRECATION WARNING]: Distribution Ubuntu 19.04 on host localhost should use /usr/bin/python3, but is using /usr/bin/python for backward compatibility with prior Ansible releases. A future\n Ansible release will default to using the discovered platform python for this host. See https://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more \ninformation. This feature will be removed in version 2.12. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.\nlocalhost | SUCCESS => {\n    ""ansible_facts"": {\n        ""ansible_python_version"": ""2.7.16"", \n        ""discovered_interpreter_python"": ""/usr/bin/python""\n    }, \n    ""changed"": false\n}\n', ""def _version_fuzzy_match(version, version_map):\n...\n    # slot match; return nearest previous version we're newer than\n    kpos = bisect.bisect(sorted_looseversions, find_looseversion)\n"", 'interpreter_python=auto\n', '$ ansible localhost -m setup -a \'filter=ansible_python_version\'\nlocalhost | SUCCESS => {\n    ""ansible_facts"": {\n        ""ansible_python_version"": ""3.7.3"", \n        ""discovered_interpreter_python"": ""/usr/bin/python3""\n    }, \n    ""changed"": false\n}\n', '$ ansible localhost -m setup | grep ansible_python_version\n        ""ansible_python_version"": ""2.7.16"",\n', '$ cat playbook.yml\n- hosts: localhost\n  tasks:\n    - debug:\n        var: ansible_python_version\n\n$ ansible-playbook playbook.yml\n\nok: [localhost] => {\n    ""ansible_python_version"": ""2.7.16""\n}\n', ""$ ansible --version\nansible 2.9.2\n  config file = /home/vlado/.ansible.cfg\n  configured module search path = [u'/home/vlado/.ansible/my_modules']\n  ansible python module location = /usr/lib/python2.7/dist-packages/ansible\n  executable location = /usr/bin/ansible\n  python version = 2.7.16 (default, Oct  7 2019, 17:36:04) [GCC 8.3.0]\n"", '$ dpkg -l | grep dnspython\nii  python-dnspython         1.16.0-1 all          DNS toolkit for Python\nii  python3-dnspython        1.16.0-1 all          DNS toolkit for Python 3\n', '$ cat playbook.yml\n- hosts: test_01\n  tasks:\n    - getent:\n        database: hosts\n', '$ cat hosts\ntest_01 ansible_python_interpreter=/usr/local/bin/python3.6\n', '$ ansible-playbook playbook.yml -i hosts -vvv | grep python\n', '$ cat hosts\ntest_01 ansible_python_interpreter=/usr/local/bin/python2.7\n']"
1122,10147,10135,CC BY-SA 4.0,2019-12-18T08:36:13.380,"<p>What are the permissions set to Jenkins docker container you are using in the instance?</p>

<p>This is one of the solution.
You can use the following docker-compose along with the Dockerfile.</p>

<p>docker-compose.yml</p>

<pre><code>version: ""3.7""

services:
  jenkins:
    build:
      context: .
      dockerfile: Dockerfile
    image: jenkins
    container_name: jenkins
    restart: always
    volumes:
      - ""/var/run/docker.sock:/var/run/docker.sock""
      - ""/etc/sysconfig/docker:/etc/sysconfig/docker""
      - ""/home/ubuntu/jenkins/volume:/var/jenkins_home""
    ports:
      - ""8443:8080""
    privileged: true
</code></pre>

<p>Dockerfile</p>

<pre><code>FROM jenkins/jenkins:lts

#Switching to root user
USER root
RUN apt update &amp;&amp; \
    apt install sudo curl jq apt-utils -y

RUN curl -sSL https://get.docker.com/ | sh
RUN  sudo apt-get install docker-compose -y

#install aws
RUN sudo apt-get install -y python-pip python-dev build-essential
RUN pip install awscli --upgrade --user
RUN export PATH=~/.local/bin:$PATH
#updating path to support aws 
ENV PATH=""~/.local/bin:${PATH}""

#php installation 
#----------------
RUN apt install ca-certificates apt-transport-https 
RUN wget -q https://packages.sury.org/php/apt.gpg -O- | sudo apt-key add -
RUN echo ""deb https://packages.sury.org/php/ stretch main"" | sudo tee /etc/apt/sources.list.d/php.list

RUN apt update
RUN apt install -y php7.2
RUN apt-get install -y php7.2-common php7.2-opcache php7.2-curl php7.2-mbstring php7.2-mysql php7.2-zip php7.2-xml

#install composer
RUN curl -sS https://getcomposer.org/installer | php -- --install-dir=/usr/bin --filename=composer

#install phpunit
RUN curl -sSL https://phar.phpunit.de/phpunit.phar -o phpunit.phar
RUN chmod +x phpunit.phar
RUN mv phpunit.phar /usr/local/bin/phpunit
</code></pre>

<p>Create a volume in the same directory named <code>volume</code></p>

<p>This will allow you to run the docker command without any issue.</p>
",16959,2019-12-18T08:36:13.380,"['version: ""3.7""\n\nservices:\n  jenkins:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    image: jenkins\n    container_name: jenkins\n    restart: always\n    volumes:\n      - ""/var/run/docker.sock:/var/run/docker.sock""\n      - ""/etc/sysconfig/docker:/etc/sysconfig/docker""\n      - ""/home/ubuntu/jenkins/volume:/var/jenkins_home""\n    ports:\n      - ""8443:8080""\n    privileged: true\n', 'FROM jenkins/jenkins:lts\n\n#Switching to root user\nUSER root\nRUN apt update && \\\n    apt install sudo curl jq apt-utils -y\n\nRUN curl -sSL https://get.docker.com/ | sh\nRUN  sudo apt-get install docker-compose -y\n\n#install aws\nRUN sudo apt-get install -y python-pip python-dev build-essential\nRUN pip install awscli --upgrade --user\nRUN export PATH=~/.local/bin:$PATH\n#updating path to support aws \nENV PATH=""~/.local/bin:${PATH}""\n\n#php installation \n#----------------\nRUN apt install ca-certificates apt-transport-https \nRUN wget -q https://packages.sury.org/php/apt.gpg -O- | sudo apt-key add -\nRUN echo ""deb https://packages.sury.org/php/ stretch main"" | sudo tee /etc/apt/sources.list.d/php.list\n\nRUN apt update\nRUN apt install -y php7.2\nRUN apt-get install -y php7.2-common php7.2-opcache php7.2-curl php7.2-mbstring php7.2-mysql php7.2-zip php7.2-xml\n\n#install composer\nRUN curl -sS https://getcomposer.org/installer | php -- --install-dir=/usr/bin --filename=composer\n\n#install phpunit\nRUN curl -sSL https://phar.phpunit.de/phpunit.phar -o phpunit.phar\nRUN chmod +x phpunit.phar\nRUN mv phpunit.phar /usr/local/bin/phpunit\n']"
1123,10149,10140,CC BY-SA 4.0,2019-12-18T08:44:02.890,"<p>For executing the command in the Jenkins Freestyle Job.</p>

<pre><code>#!/bin/bash

du -sh /bbhome/shared/data/repositories/* |sort -h |tail -20 |
while IFS= read -r line;do
        DIR=`echo $line | awk '{print$2}'`
        Rep=`cat $DIR/repository-config |grep 'project\|repo' |  tr '\n' ' '`
        Size=`echo $line | awk '{print $1}' `
        echo $Size $Rep
done
</code></pre>

<p>For ssh</p>

<pre><code>ssh -o StrictHostKeyChecking=no user@host '
   command_1 to execute
   command_2 to execute
   ./script.sh to execute
   command_3 to execute
'
</code></pre>
",16959,2019-12-18T08:44:02.890,"[""#!/bin/bash\n\ndu -sh /bbhome/shared/data/repositories/* |sort -h |tail -20 |\nwhile IFS= read -r line;do\n        DIR=`echo $line | awk '{print$2}'`\n        Rep=`cat $DIR/repository-config |grep 'project\\|repo' |  tr '\\n' ' '`\n        Size=`echo $line | awk '{print $1}' `\n        echo $Size $Rep\ndone\n"", ""ssh -o StrictHostKeyChecking=no user@host '\n   command_1 to execute\n   command_2 to execute\n   ./script.sh to execute\n   command_3 to execute\n'\n""]"
1124,10168,10163,CC BY-SA 4.0,2019-12-20T01:46:28.410,"<p>Each module has its own set of input variables.</p>

<p>The input variables for the root module are set when you run Terraform, e.g. on the command like with the <code>-var</code> option.</p>

<p>The input variables for any child module, like your <code>module ""logs""</code> here, are set inside the <code>module</code> block.</p>

<p>Each variable declaration is valid only for the module it appears in. You happen to have given both of these variables the same name, which is fine and sensible as it helps a human reader understand that they represent the same concept, but Terraform considers these two variables entirely separate and requires you to declare and set both of them.</p>

<p>As an analogy, consider a module as being somewhat equivalent to a function in a programming language. Each function defines its own arguments, and two functions might have an argument of the same name but they are still distinct by virtue of belonging to different functions:</p>

<pre><code>function main(env: string) {
  logs(env)
}

function logs(env: string) {
  // ""env"" in here is ""test"" because it was passed through
  // the arguments of both of these functions, not because
  // the arguments happened to have the same name in both
  // functions.
}

// Calling main here is, for the purposes of this analogy,
// corresponding to running: terraform apply -var=""env=test""
main(""test"")
</code></pre>
",2463,2019-12-20T01:46:28.410,"['function main(env: string) {\n  logs(env)\n}\n\nfunction logs(env: string) {\n  // ""env"" in here is ""test"" because it was passed through\n  // the arguments of both of these functions, not because\n  // the arguments happened to have the same name in both\n  // functions.\n}\n\n// Calling main here is, for the purposes of this analogy,\n// corresponding to running: terraform apply -var=""env=test""\nmain(""test"")\n']"
1125,10169,8686,CC BY-SA 4.0,2019-12-20T08:36:37.750,"<p>According to the log there is something wrong with the Etcd certificate:</p>

<pre><code>Error:  client: etcd cluster is unavailable or misconfigured; error #0: x509:
certificate signed by unknown authority

error #0: x509: certificate signed by unknown authority
</code></pre>

<p>Please read the documentation how to create etcd certificates again and try to fix it.</p>
",210,2019-12-20T08:36:37.750,['Error:  client: etcd cluster is unavailable or misconfigured; error #0: x509:\ncertificate signed by unknown authority\n\nerror #0: x509: certificate signed by unknown authority\n']
1126,10170,10099,CC BY-SA 4.0,2019-12-20T10:10:28.487,"<p>The issue has been resolved.
This is for nodejs</p>

<p>Need to install necessary dependencies either using yarn or npm.
Once done, run </p>

<pre><code>nyc --reporter=lcov yarn unit unit
$ ./cc-test-reporter after-build -t lcov --exit-code $?
</code></pre>
",16959,2019-12-20T10:10:28.487,['nyc --reporter=lcov yarn unit unit\n$ ./cc-test-reporter after-build -t lcov --exit-code $?\n']
1127,10172,9877,CC BY-SA 4.0,2019-12-20T11:15:35.217,"<p>Based on the error message it seems that the yaml is invalid:</p>

<pre><code>Unsupported value: ""IfNotPresent:ef86dfe0b703"": supported values: 
""Always"", ""IfNotPresent"", ""Never""
</code></pre>

<p>It seems that <code>IfNotPresent</code> contains some tag and that is unsupported.</p>
",210,2019-12-20T11:15:35.217,"['Unsupported value: ""IfNotPresent:ef86dfe0b703"": supported values: \n""Always"", ""IfNotPresent"", ""Never""\n']"
1128,10175,10174,CC BY-SA 4.0,2019-12-20T14:18:45.517,"<p>One could use <code>-vvv</code> to get the output of the commands while running the playbook:</p>

<pre><code>changed: [localhost] =&gt; (item=echo helloworld) =&gt; {
    ""ansible_loop_var"": ""item"", 
    ""changed"": true, 
    ""cmd"": [
        ""echo"", 
        ""helloworld""
    ], 
    ""delta"": ""0:00:00.002517"", 
    ""end"": ""2019-12-20 15:20:09.042020"", 
    ""invocation"": {
        ""module_args"": {
            ""_raw_params"": ""echo helloworld"", 
            ""_uses_shell"": false, 
            ""argv"": null, 
            ""chdir"": null, 
            ""creates"": null, 
            ""executable"": null, 
            ""removes"": null, 
            ""stdin"": null, 
            ""stdin_add_newline"": true, 
            ""strip_empty_ends"": true, 
            ""warn"": true
        }
    }, 
    ""item"": ""echo helloworld"", 
    ""rc"": 0, 
    ""start"": ""2019-12-20 15:20:09.039503"", 
    ""stderr"": """", 
    ""stderr_lines"": [], 
    ""stdout"": ""helloworld"", 
    ""stdout_lines"": [
        ""helloworld""
    ]
}
</code></pre>
",210,2019-12-20T14:18:45.517,"['changed: [localhost] => (item=echo helloworld) => {\n    ""ansible_loop_var"": ""item"", \n    ""changed"": true, \n    ""cmd"": [\n        ""echo"", \n        ""helloworld""\n    ], \n    ""delta"": ""0:00:00.002517"", \n    ""end"": ""2019-12-20 15:20:09.042020"", \n    ""invocation"": {\n        ""module_args"": {\n            ""_raw_params"": ""echo helloworld"", \n            ""_uses_shell"": false, \n            ""argv"": null, \n            ""chdir"": null, \n            ""creates"": null, \n            ""executable"": null, \n            ""removes"": null, \n            ""stdin"": null, \n            ""stdin_add_newline"": true, \n            ""strip_empty_ends"": true, \n            ""warn"": true\n        }\n    }, \n    ""item"": ""echo helloworld"", \n    ""rc"": 0, \n    ""start"": ""2019-12-20 15:20:09.039503"", \n    ""stderr"": """", \n    ""stderr_lines"": [], \n    ""stdout"": ""helloworld"", \n    ""stdout_lines"": [\n        ""helloworld""\n    ]\n}\n']"
1129,10188,10157,CC BY-SA 4.0,2019-12-20T20:05:52.717,"<p>Not sure if this would work for you, but what I do is store all of the build metadata into a <code>BuildInfo.json</code> file. You could just save it as an XML file like you said, but I found it easier to parse info with Groovy if it was a JSON file. Along with the most recent commit hash, we store most of the build information in this file, including the result, duration, user who kicked off the build, etc.</p>

<p>One advantage of this approach is we're able to create other jobs that take action of already built products, such as for deployments. These jobs can just look for the presence of a <code>BuildInfo.json</code> file and take action based off the information contained within. Example:</p>

<pre><code>import groovy.json.*

def build_info = [
    'Product': 'MyApp',
    'Build Type': 'Full',
    'Build Name': currentBuild.displayName,
    'Version': '1.2.3.4',
    'Source Branch' : params.Branch,
]

def json_output = readJSON text: groovy.json.JsonOutput.toJson(build_info)
writeJSON file: ""BuildInfo.json"", json: json_output, pretty: 4
</code></pre>
",9148,2019-12-20T20:05:52.717,"['import groovy.json.*\n\ndef build_info = [\n    \'Product\': \'MyApp\',\n    \'Build Type\': \'Full\',\n    \'Build Name\': currentBuild.displayName,\n    \'Version\': \'1.2.3.4\',\n    \'Source Branch\' : params.Branch,\n]\n\ndef json_output = readJSON text: groovy.json.JsonOutput.toJson(build_info)\nwriteJSON file: ""BuildInfo.json"", json: json_output, pretty: 4\n']"
1130,10189,10125,CC BY-SA 4.0,2019-12-20T20:15:06.463,"<p>According the the Jenkins docs, you could use your custom docker image as the <a href=""https://jenkins.io/doc/book/pipeline/docker/#execution-environment"" rel=""nofollow noreferrer"">execution environment</a>, assuming the server Jenkins is running on has Docker installed/running. </p>

<pre><code>pipeline {
    agent {
        docker { image 'your-custom-image' }
    }
    stages {
        stage('Build') {
            steps {
                sh 'commands to run in your docker image here'
            }
        }
    }
}
</code></pre>
",9148,2019-12-20T20:15:06.463,"[""pipeline {\n    agent {\n        docker { image 'your-custom-image' }\n    }\n    stages {\n        stage('Build') {\n            steps {\n                sh 'commands to run in your docker image here'\n            }\n        }\n    }\n}\n""]"
1131,10193,3100,CC BY-SA 4.0,2019-12-21T17:39:50.770,"<p>You can upload using aws-cli.</p>

<pre><code>aws configure

aws lambda list-functions

aws lambda update-function-code \
    --function-name MyLambdaFunction \
    --zip-file fileb://index.zip
</code></pre>

<p>See <a href=""https://developer.amazon.com/blogs/post/Tx1UE9W1NQ0GYII/Publishing-Your-Skill-Code-to-Lambda-via-the-Command-Line-Interface"" rel=""nofollow noreferrer"">https://developer.amazon.com/blogs/post/Tx1UE9W1NQ0GYII/Publishing-Your-Skill-Code-to-Lambda-via-the-Command-Line-Interface</a></p>
",3283,2019-12-21T17:39:50.770,['aws configure\n\naws lambda list-functions\n\naws lambda update-function-code \\\n    --function-name MyLambdaFunction \\\n    --zip-file fileb://index.zip\n']
1132,10200,9982,CC BY-SA 4.0,2019-12-22T10:30:14.880,"<p>You may find the following format to be helpful:</p>

<pre><code>- name: Recursively change ownership of a directory  
file:  
  path: /etc/foo
  state: directory
  recurse: yes
  owner: foo
  group: foo
</code></pre>
",18771,2019-12-22T10:30:14.880,['- name: Recursively change ownership of a directory  \nfile:  \n  path: /etc/foo\n  state: directory\n  recurse: yes\n  owner: foo\n  group: foo\n']
1133,10201,10192,CC BY-SA 4.0,2019-12-22T13:42:41.163,"<p>There are several options:</p>

<ul>
<li>The first one is like you mentioned, creating an image yourself, push it to dockerhub and run <code>docker run yourimage git</code> etc.</li>
<li><p>Another option is to use an image that has already been published like <a href=""https://hub.docker.com/r/dockerinpractice/docker-dev-tools-image/dockerfile"" rel=""nofollow noreferrer"">this one</a>. One could run it by issuing:</p>

<pre><code>docker run dockerinpractice/docker-dev-tools-image git
</code></pre></li>
<li><p>A third option is to add git to an existing image by using a Dockerfile:</p>

<pre><code>FROM alpine/git:1.0.7

RUN apk add --update zip
</code></pre></li>
</ul>

<p>Personally I wonder whether docker is the right tool for the job in this case.</p>
",210,2019-12-22T13:42:41.163,"['docker run dockerinpractice/docker-dev-tools-image git\n', 'FROM alpine/git:1.0.7\n\nRUN apk add --update zip\n']"
1134,10205,9567,CC BY-SA 4.0,2019-12-23T09:49:24.410,"<pre><code>Resources:                                                                                                                                                                                  
    TargetGroup:                                                                                                                                                                              
        Type: AWS::ElasticLoadBalancingV2::TargetGroup                                                                                                                                        
        Properties:                                                                                                                                                                           
          VpcId:                                                                                                                                                                              
            Fn::ImportValue:                                                                                                                                                                  
              !Sub ""${Prefix}-VpcId""                                                                                                                                                          
          TargetType: instance                                                                                                                                                                
          Port: 443                                                                                                                                                                           
          Protocol: HTTPS                                                                                                                                                                     
    AutoScalingGroup:                                                                                                                                                                         
        Type: AWS::AutoScaling::AutoScalingGroup                                                                                                                                              
        Properties:                                                                                                                                                                           
          AutoScalingGroupName: Autoscaling Group Alpha                                                                                                                                       
          Cooldown: ""120""                                                                                                                                                                     
          DesiredCapacity: ""1""                                                                                                                                                                
          LaunchConfigurationName: AlphaLaunchConfiguration                                                                                                                                   
          MaxSize: ""1""                                                                                                                                                                        
          MinSize: ""1""                                                                                                                                                                        
          Tags:                                                                                                                                                                               
            -                                                                                                                                                                                 
              Key: Name                                                                                                                                                                       
              Value: Alpha ASG                                                                                                                                                                
              PropagateAtLaunch: true                                                                                                                                                         
          TargetGroupARNs:                                                                                                                                                                    
            - Ref: TargetGroup
</code></pre>

<p>As the error message states, TargetGroupARNs value should be of type List.
<a href=""https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-as-group.html#cfn-as-group-targetgrouparns"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-as-group.html#cfn-as-group-targetgrouparns</a></p>
",18782,2019-12-23T09:49:24.410,"['Resources:                                                                                                                                                                                  \n    TargetGroup:                                                                                                                                                                              \n        Type: AWS::ElasticLoadBalancingV2::TargetGroup                                                                                                                                        \n        Properties:                                                                                                                                                                           \n          VpcId:                                                                                                                                                                              \n            Fn::ImportValue:                                                                                                                                                                  \n              !Sub ""${Prefix}-VpcId""                                                                                                                                                          \n          TargetType: instance                                                                                                                                                                \n          Port: 443                                                                                                                                                                           \n          Protocol: HTTPS                                                                                                                                                                     \n    AutoScalingGroup:                                                                                                                                                                         \n        Type: AWS::AutoScaling::AutoScalingGroup                                                                                                                                              \n        Properties:                                                                                                                                                                           \n          AutoScalingGroupName: Autoscaling Group Alpha                                                                                                                                       \n          Cooldown: ""120""                                                                                                                                                                     \n          DesiredCapacity: ""1""                                                                                                                                                                \n          LaunchConfigurationName: AlphaLaunchConfiguration                                                                                                                                   \n          MaxSize: ""1""                                                                                                                                                                        \n          MinSize: ""1""                                                                                                                                                                        \n          Tags:                                                                                                                                                                               \n            -                                                                                                                                                                                 \n              Key: Name                                                                                                                                                                       \n              Value: Alpha ASG                                                                                                                                                                \n              PropagateAtLaunch: true                                                                                                                                                         \n          TargetGroupARNs:                                                                                                                                                                    \n            - Ref: TargetGroup\n']"
1135,10269,10260,CC BY-SA 4.0,2019-12-24T07:22:51.593,"<pre><code>kops delete secret --name cluster-1.dev.transein.com sshpublickey admin 2c:yy
</code></pre>
",18159,2019-12-25T08:39:21.503,['kops delete secret --name cluster-1.dev.transein.com sshpublickey admin 2c:yy\n']
1136,10276,10192,CC BY-SA 4.0,2019-12-24T12:36:52.347,"<p>If you have don't want to push your images to docker.com, are on an isolated network, or if you are doing this kind of thing regularly, you could consider setting up your own local docker registry.  Doing this would </p>

<p>Setting up a docker registry is not a trivial task, you can find detailed instructions for setting up a docker registry at <a href=""https://docs.docker.com/registry/deploying/"" rel=""nofollow noreferrer"">docker.com</a>, but here is a brief summary:</p>

<ol>
<li><p>Get/run the docker registry image (yes, the registry will run inside docker):</p>

<p><code>docker run -d -p 5000:5000 --restart=always --name registry registry:2</code></p></li>
<li><p>build your image or use an existing one:</p>

<p><code>docker tag ubuntu:16.04 localhost:5000/my-ubuntu</code></p></li>
<li><p>Push this image to your logcal registry:</p>

<p><code>docker push localhost:5000/my-ubuntu</code></p></li>
</ol>

<p>Once you do this, you will be able to treat this local registry like Docker Hub; you could delete your ""local"" copy of this ubuntu image, then pull it down from your local repository again:</p>

<pre><code>docker image remove ubuntu:16.04
docker image remove localhost:5000/my-ubuntu
docker pull localhost:5000/my-ubuntu
</code></pre>
",18801,2019-12-24T12:36:52.347,['docker image remove ubuntu:16.04\ndocker image remove localhost:5000/my-ubuntu\ndocker pull localhost:5000/my-ubuntu\n']
1137,10277,4639,CC BY-SA 4.0,2019-12-24T13:19:14.003,"<p><strong>Get newest tag</strong></p>

<p>How I mitigated it was by creating several bots. The first one uses <a href=""https://github.com/030/dip"" rel=""nofollow noreferrer"">dip</a> to get the latest version of a specific docker image. E.g.:</p>

<pre><code>go run main.go -image ubuntu -latest ""xenial-\d.*""
</code></pre>

<p>to get the latest tag of Ubuntu Xenial. If the docker image does not exist in your local docker registry, then it will be pushed.</p>

<p><strong>Update tag in several Dockerfiles</strong></p>

<p>The second bot, updates the tags in the Dockerfiles. If the build is successful then it is merged. Currently an approval is always required, but if it works for a couple of months and the team has enough confidence then an auto merge can be done.</p>

<p><strong>Update orchestration</strong></p>

<p>The third bot updates the docker-compose.yml files, k8s files or whatever orchestration is used. If an approval is done then it will be merged into master. Again if there is enough confidence then this could be automated as well, but I always prefer some manual intervention if production is applicable. Then the team is aware that there was an update and could revert if needed. On the other hand if the monitoring works well then the team will be notified right a way and if updates are done frequently, i.e. at least once every two weeks then the team is trained and knows how to deal with this. </p>
",210,2019-12-24T13:19:14.003,"['go run main.go -image ubuntu -latest ""xenial-\\d.*""\n']"
1138,10284,6232,CC BY-SA 4.0,2019-12-24T17:18:49.497,"<p>One could use <a href=""https://composerize.com/"" rel=""nofollow noreferrer"">Composerize</a> to create a consistent docker-compose.yml.</p>

<p>There seems to be two options. Options one is to enter some docker run command, e.g. <code>docker run app/test_clients</code> on their website, which will return:</p>

<pre><code>version: '3.3'
services:
    test_clients:
        image: app/test_clients
</code></pre>

<p>Or use the <a href=""https://github.com/magicmark/composerize#cli"" rel=""nofollow noreferrer"">command line</a>: <code>composerize docker run app/test_clients</code>.</p>
",210,2019-12-24T17:18:49.497,"[""version: '3.3'\nservices:\n    test_clients:\n        image: app/test_clients\n""]"
1139,10286,6233,CC BY-SA 4.0,2019-12-24T18:59:44.123,"<p><a href=""https://github.com/docker/compose/issues/5586#issuecomment-375580132"" rel=""nofollow noreferrer"">@decoomanj on github</a> indicated that <code>scale</code> has to be replaced by <code>deploy</code> in conjunction with <code>replicas</code>. </p>

<p>According to <a href=""https://github.com/docker/compose/issues/5586#issuecomment-475250276"" rel=""nofollow noreferrer"">mrampant-nist on github</a> one has to use <code>--compatibility</code> as well.</p>

<p>Let's test this. First of all all docker-compose.yml is needed:</p>

<pre><code>version: '3.3'
services:
    nginx:
      image: nginx
      scale: 6
</code></pre>

<p>and issuing:</p>

<pre><code>docker-compose up
</code></pre>

<p>results in:</p>

<pre><code>ERROR: The Compose file './docker-compose.yml' is invalid because:
Unsupported config option for services.nginx: 'scale'
</code></pre>

<p>Applying @decoomanj's suggestion, i.e. replacing replicas:</p>

<pre><code>version: '3.3'
services:
    nginx:
      image: nginx
      deploy:
        replicas: 6
</code></pre>

<p>results in:</p>

<pre><code>WARNING: Some services (nginx) use the 'deploy' key, which will be ignored. Compose does not support 'deploy' configuration - use `docker stack deploy` to deploy to a swarm.
</code></pre>

<p>Running <code>docker-compose --compatibility up</code> starts 6 services:</p>

<pre><code>CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
f19aa54634d7        nginx               ""nginx -g 'daemon of…""   5 seconds ago       Up 4 seconds        80/tcp              6233_nginx_5
749cff4ac1c3        nginx               ""nginx -g 'daemon of…""   5 seconds ago       Up 3 seconds        80/tcp              6233_nginx_3
b86ed7b217fe        nginx               ""nginx -g 'daemon of…""   5 seconds ago       Up 1 second         80/tcp              6233_nginx_6
0b92e5ef4a0e        nginx               ""nginx -g 'daemon of…""   5 seconds ago       Up 2 seconds        80/tcp              6233_nginx_2
e414bca52b53        nginx               ""nginx -g 'daemon of…""   5 seconds ago       Up 4 seconds        80/tcp              6233_nginx_4
e9f33dc634a8        nginx               ""nginx -g 'daemon of…""   6 seconds ago       Up 5 seconds        80/tcp              6233_nginx_1
</code></pre>

<p>In conclusion, <code>replicas</code> has to be replaced by <code>deploy</code> and <code>replicas</code> and <code>--compatibility</code> is needed to solve the issue. </p>
",210,2019-12-24T19:19:39.710,"[""version: '3.3'\nservices:\n    nginx:\n      image: nginx\n      scale: 6\n"", 'docker-compose up\n', ""ERROR: The Compose file './docker-compose.yml' is invalid because:\nUnsupported config option for services.nginx: 'scale'\n"", ""version: '3.3'\nservices:\n    nginx:\n      image: nginx\n      deploy:\n        replicas: 6\n"", ""WARNING: Some services (nginx) use the 'deploy' key, which will be ignored. Compose does not support 'deploy' configuration - use `docker stack deploy` to deploy to a swarm.\n"", 'CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES\nf19aa54634d7        nginx               ""nginx -g \'daemon of…""   5 seconds ago       Up 4 seconds        80/tcp              6233_nginx_5\n749cff4ac1c3        nginx               ""nginx -g \'daemon of…""   5 seconds ago       Up 3 seconds        80/tcp              6233_nginx_3\nb86ed7b217fe        nginx               ""nginx -g \'daemon of…""   5 seconds ago       Up 1 second         80/tcp              6233_nginx_6\n0b92e5ef4a0e        nginx               ""nginx -g \'daemon of…""   5 seconds ago       Up 2 seconds        80/tcp              6233_nginx_2\ne414bca52b53        nginx               ""nginx -g \'daemon of…""   5 seconds ago       Up 4 seconds        80/tcp              6233_nginx_4\ne9f33dc634a8        nginx               ""nginx -g \'daemon of…""   6 seconds ago       Up 5 seconds        80/tcp              6233_nginx_1\n']"
1140,10298,7971,CC BY-SA 4.0,2019-12-25T08:52:19.270,"<p>It looks like that there is a name conflict:</p>

<pre><code>The name of your virtual machine couldn't be set because VirtualBox
is reporting another VM with that name already exists. Most of the
time, this is because of an error with VirtualBox not cleaning up
properly. To fix this, verify that no VMs with that name do exist
(by opening the VirtualBox GUI). If they don't, then look at the
folder in the error message from VirtualBox below and remove it
if there isn't any information you need in there.
</code></pre>

<p>According to <a href=""https://github.com/hashicorp/vagrant/issues/1817#issuecomment-20976959"" rel=""nofollow noreferrer"">@xofer on Github</a> on has to set the <code>name</code>. However in the example you provided in conjunction with the logging, the issue seems to be caused by a VM that was created and still exists in Virtualbox. In other words one has to ensure that the VM has been removed or another name has to be defined to prevent this collision.</p>
",210,2019-12-25T08:52:19.270,"[""The name of your virtual machine couldn't be set because VirtualBox\nis reporting another VM with that name already exists. Most of the\ntime, this is because of an error with VirtualBox not cleaning up\nproperly. To fix this, verify that no VMs with that name do exist\n(by opening the VirtualBox GUI). If they don't, then look at the\nfolder in the error message from VirtualBox below and remove it\nif there isn't any information you need in there.\n""]"
1141,10307,8408,CC BY-SA 4.0,2019-12-25T11:40:39.260,"<p>After consulting <a href=""https://devhints.io/git-log-format"" rel=""nofollow noreferrer"">this cheatsheet</a>, I think that you are looking for the subject. If I apply:</p>

<pre><code>git log --pretty=""%s""
</code></pre>

<p>to one of my git repositories, the following is returned:</p>

<pre><code>learning pointers in golang
receiver struct in golang
embedded structs in golang
multiple spanish words
</code></pre>

<p>In conclusion, I think you should include <code>%s</code> to get the git messages or basically the <code>commit subjects</code>.</p>
",210,2019-12-25T11:40:39.260,"['git log --pretty=""%s""\n', 'learning pointers in golang\nreceiver struct in golang\nembedded structs in golang\nmultiple spanish words\n']"
1142,10317,10090,CC BY-SA 4.0,2019-12-26T15:53:13.367,"<p>You should be able to use the flag <code>spec.containers[].resources.limits.cpu</code> to set your desired state on a deployment.</p>

<p>The official docs <a href=""https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/"" rel=""nofollow noreferrer"">here</a> and <a href=""https://kubernetes.io/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/"" rel=""nofollow noreferrer"">here</a> have some examples of how to specify this in the yaml.  You can set a global default along with min/max limits:</p>

<pre><code>spec:
  limits:
  - default:
      cpu: 1000m
    defaultRequest:
      cpu: 300m
  - min:
      cpu: 300m
  - max:
      cpu: 1000m
</code></pre>
",15792,2019-12-27T15:56:51.180,['spec:\n  limits:\n  - default:\n      cpu: 1000m\n    defaultRequest:\n      cpu: 300m\n  - min:\n      cpu: 300m\n  - max:\n      cpu: 1000m\n']
1143,10328,9887,CC BY-SA 4.0,2019-12-27T16:09:42.330,"<p>This is quite complicated to achieve in Jenkins. We had a similar issue and here's how we solved it:</p>

<ol>
<li>We have a shared library where we keep our scripts ins <code>./vars/someScriptName.groovy</code></li>
<li>We created a <code>groovy</code> script that generates the stages.</li>
</ol>

<p>Here's a working pipeline code for you to try it out:</p>

<pre><code>def generateITParallelStages(body)
{
    def config = [:]
    config.stages = []

    body.resolveStrategy = Closure.DELEGATE_FIRST
    body.delegate = config
    body()

    def buildStages = [:]
    config.stages.each { String stage, closure -&gt;
        // default settings, if you want to have any
        def settings = [:]
        settings.type = 'online'; // if you don't define the type, it will be 'online' by default
        settings.suite = 'internal'; // if you don't define the suite it will be 'internal' by default

        closure.resolveStrategy = Closure.DELEGATE_FIRST
        closure.delegate = settings
        closure()

        buildStages.put(stage, prepareStage(stage, settings))
    }

    return buildStages
}

def prepareStage(String stage, Map settings)
{
    return {
        print ""Run ${settings.type} application  '\\n${stage}' in test suite '${settings.suite}'""
    }
}

pipeline {
    agent any
    stages {
        stage('Add regression tests') {
            steps {
                script {
                    parallel generateITParallelStages {
                        stages = [
                                webgoat: {
                                    type = 'offline'
                                    suite = 'open-source'
                                },
                                'juice-shop': {
                                    type = 'offline'
                                    suite = 'open-source'
                                },
                                'our-website': {
                                    type = 'online'
                                    suite = 'internal'
                                }
                        ]
                    }
                }
            }
        }
    }
}
</code></pre>

<p>And here's the result:</p>

<p><a href=""https://i.stack.imgur.com/am8XK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/am8XK.png"" alt=""pipeline-view""></a></p>

<p>This is the only way we have been able to dynamically generate the parallel stages. Everything else will fail (at least at the time of writing this). </p>

<p>Other people seem to be having a hard time figuring this out as well - <a href=""https://issues.jenkins-ci.org/browse/JENKINS-53032"" rel=""nofollow noreferrer"">JENKINS-53032</a>. If you feel the same make some noise :)</p>
",5592,2019-12-27T18:00:21.757,"['def generateITParallelStages(body)\n{\n    def config = [:]\n    config.stages = []\n\n    body.resolveStrategy = Closure.DELEGATE_FIRST\n    body.delegate = config\n    body()\n\n    def buildStages = [:]\n    config.stages.each { String stage, closure ->\n        // default settings, if you want to have any\n        def settings = [:]\n        settings.type = \'online\'; // if you don\'t define the type, it will be \'online\' by default\n        settings.suite = \'internal\'; // if you don\'t define the suite it will be \'internal\' by default\n\n        closure.resolveStrategy = Closure.DELEGATE_FIRST\n        closure.delegate = settings\n        closure()\n\n        buildStages.put(stage, prepareStage(stage, settings))\n    }\n\n    return buildStages\n}\n\ndef prepareStage(String stage, Map settings)\n{\n    return {\n        print ""Run ${settings.type} application  \'\\\\n${stage}\' in test suite \'${settings.suite}\'""\n    }\n}\n\npipeline {\n    agent any\n    stages {\n        stage(\'Add regression tests\') {\n            steps {\n                script {\n                    parallel generateITParallelStages {\n                        stages = [\n                                webgoat: {\n                                    type = \'offline\'\n                                    suite = \'open-source\'\n                                },\n                                \'juice-shop\': {\n                                    type = \'offline\'\n                                    suite = \'open-source\'\n                                },\n                                \'our-website\': {\n                                    type = \'online\'\n                                    suite = \'internal\'\n                                }\n                        ]\n                    }\n                }\n            }\n        }\n    }\n}\n']"
1144,10342,10341,CC BY-SA 4.0,2019-12-30T22:16:13.233,"<p>IAM Role for Fargate has <strong>two policies</strong>:</p>

<ol>
<li><p>The first one describes which service can assume the role and its permissions. In this case it will be the <code>ecs-tasks.amazonaws.com</code> service (= Fargate) that can call <code>sts:AssumeRole</code> to get all the permissions from this Role.</p></li>
<li><p>When Fargate <em>assumes</em> the role it gets the permissions specified within, these are the SSM, KMS and SecretsManager permissions.</p></li>
</ol>

<p>If you are using CloudFormation you can do something like this:</p>

<pre><code>  FargateRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        # This says that Fargate can assume this role
        Version: '2012-10-17'
        Statement:
        - Action: sts:AssumeRole
          Effect: Allow
          Principal:
            Service: ecs-tasks.amazonaws.com
      Path: /
      Policies:
      - PolicyName: FargatePermissions
        PolicyDocument:
          # This says what permissions will 
          # the Fargate container receive
          Statement:
          - Action:
            - ssm:GetParameters
            - secretsmanager:GetSecretValue
            - kms:Decrypt
            Effect: Allow
            Resource: '*'
</code></pre>

<p>If you are building the role manually in the console be sure to select in the first step that it's an <em>IAM Role</em> for <em>ECS Task</em>, that will create the equivalent of <code>AssumeRolePolicyDocument</code> from the above code snippet.</p>

<p><a href=""https://i.stack.imgur.com/3NSJT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3NSJT.png"" alt=""IAM Role Configuration""></a></p>

<p>Then in the next step add the policy <em>without</em> the <code>sts:AssumeRole</code>:</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
            ""Effect"": ""Allow"",
            ""Action"": [
                ""secretsmanager:GetSecretValue"",
                ""ssm:GetParameters"",
                ""kms:Decrypt""
            ],
            ""Resource"": ""*""
        }
    ]
}
</code></pre>

<p>That should create the IAM Role you need. Ideally you should also restrict the access only to specific resources instead of using <code>""Resource"": ""*""</code> but for start it's easier to just use the wildcard.</p>

<p>Hope that helps :)</p>
",8800,2019-12-30T22:16:13.233,"[""  FargateRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        # This says that Fargate can assume this role\n        Version: '2012-10-17'\n        Statement:\n        - Action: sts:AssumeRole\n          Effect: Allow\n          Principal:\n            Service: ecs-tasks.amazonaws.com\n      Path: /\n      Policies:\n      - PolicyName: FargatePermissions\n        PolicyDocument:\n          # This says what permissions will \n          # the Fargate container receive\n          Statement:\n          - Action:\n            - ssm:GetParameters\n            - secretsmanager:GetSecretValue\n            - kms:Decrypt\n            Effect: Allow\n            Resource: '*'\n"", '{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Effect"": ""Allow"",\n            ""Action"": [\n                ""secretsmanager:GetSecretValue"",\n                ""ssm:GetParameters"",\n                ""kms:Decrypt""\n            ],\n            ""Resource"": ""*""\n        }\n    ]\n}\n']"
1145,10351,9887,CC BY-SA 4.0,2019-12-31T15:26:27.783,"<p>I hope this helps. We had a similar issue and solved it using the below method.</p>

<p>Our project contains about 12 or so different components (programs) that we wanted to build in parallel. Because some take longer than others, we decided to break them up into 4 individual ""tracks"" that would run in parallel. To begin, assume we have an array where each element is a new component object. The object has some properties, like name for the name of the component and track for which track, 1, 2, 3, or 4, that the component is assigned to. I'm not focusing on this part as it's probably not relevant to what you're trying to do. </p>

<p>First we define our <code>createParallelStage</code> function which iterates over an ArrayList of components, setting them up to build.</p>

<pre><code>def createParallelStage(ArrayList components) {
    return{
        // iterate over list of components objects
        components.each { component -&gt;
            dir(buildFolder) {
                // build the component
                sh ""./build.sh ${component}""

            }
        }
    }
}
</code></pre>

<p>We'll use a list of component objects called BuildComponents, iterate over them, and add them to <code>parallelGroups[i]</code> where <code>i</code> is the value of the objects <code>track</code> property</p>

<pre><code>BuildComponents.each { component -&gt;
    parallelGroups[component.track].add(component.name)
    echo ""${component.name} is going to parallel track ${component.track}""
    // example: IPCService is going to parallel track 3
    }
}
</code></pre>

<p>We're now left with iterating over <code>parallelGroups</code>, passing each element to <code>createParallelStage()</code> while adding it to the <code>parallelStages</code> ArrayList.</p>

<pre><code>parallelGroups.each{i, component -&gt;
    parallelStages.put(i, createParallelStage(component))
}
</code></pre>

<p>We then set <code>failFast</code> to true, so if any of our components fail, the whole build job will fail, and then pass our list of <code>parallelStages</code> to the <code>parallel()</code> function.</p>

<pre><code>parallelStages.failFast = true
parallel(parallelStages)
</code></pre>

<p>I hope this was specific to the question you were asking. I wish I could be a little more detailed, but then it might be too specific of a solution to work for you.</p>
",9148,2019-12-31T15:26:27.783,"['def createParallelStage(ArrayList components) {\n    return{\n        // iterate over list of components objects\n        components.each { component ->\n            dir(buildFolder) {\n                // build the component\n                sh ""./build.sh ${component}""\n\n            }\n        }\n    }\n}\n', 'BuildComponents.each { component ->\n    parallelGroups[component.track].add(component.name)\n    echo ""${component.name} is going to parallel track ${component.track}""\n    // example: IPCService is going to parallel track 3\n    }\n}\n', 'parallelGroups.each{i, component ->\n    parallelStages.put(i, createParallelStage(component))\n}\n', 'parallelStages.failFast = true\nparallel(parallelStages)\n']"
1146,10369,10367,CC BY-SA 4.0,2019-12-31T21:56:11.253,"<p><strong>Makefile</strong></p>

<pre><code>all: test dosomething

test:
    @echo ""hello""

dosomething:
    @if [ ""a"" = ""a"" ]; then\
        echo ""world"";\
        exit 0;\
    fi
</code></pre>

<p>Running: <code>make</code> will return:</p>

<pre><code>hello
world
</code></pre>
",210,2019-12-31T21:56:11.253,"['all: test dosomething\n\ntest:\n    @echo ""hello""\n\ndosomething:\n    @if [ ""a"" = ""a"" ]; then\\\n        echo ""world"";\\\n        exit 0;\\\n    fi\n', 'hello\nworld\n']"
1147,10372,10040,CC BY-SA 4.0,2020-01-02T11:55:36.360,"<p>This is my solution how to output usernames and passwords:</p>

<p>In the module:</p>

<pre><code>output ""mysql_credentials"" {
  value = [
    for user in var.mysql_users :
    { ""username"" = ""${user}@${var.cluster_name}"" // Hostname is for Azure MySQL service
      ""password"" = ""${random_password.test[user][""result""]}""
    }
  ]
}
</code></pre>

<p>In the terraform file referencing the module:</p>

<pre><code>output ""mysql_service_credentials"" {
  value = module.cluster.mysql_credentials
}
</code></pre>

<p>The output:</p>

<pre><code>mysql_credentials = [
  {
    ""Password"" = ""OecheeP1Iequ6zeis2aipai5eiyooL8g""
    ""Username"" = ""stage-cat@stage""
  },
  {
    ""Password"" = ""xaed1EiGh4ahbea4ohjeetouw0Geph8o""
    ""Username"" = ""stage-dog@stage""
  },
  {
    ""Password"" = ""Seu8ieciewoh4Ohl6Ut7em1aiVie1Ao0""
    ""Username"" = ""stage-snake@stage""
  },
]
</code></pre>
",2867,2020-01-02T11:55:36.360,"['output ""mysql_credentials"" {\n  value = [\n    for user in var.mysql_users :\n    { ""username"" = ""${user}@${var.cluster_name}"" // Hostname is for Azure MySQL service\n      ""password"" = ""${random_password.test[user][""result""]}""\n    }\n  ]\n}\n', 'output ""mysql_service_credentials"" {\n  value = module.cluster.mysql_credentials\n}\n', 'mysql_credentials = [\n  {\n    ""Password"" = ""OecheeP1Iequ6zeis2aipai5eiyooL8g""\n    ""Username"" = ""stage-cat@stage""\n  },\n  {\n    ""Password"" = ""xaed1EiGh4ahbea4ohjeetouw0Geph8o""\n    ""Username"" = ""stage-dog@stage""\n  },\n  {\n    ""Password"" = ""Seu8ieciewoh4Ohl6Ut7em1aiVie1Ao0""\n    ""Username"" = ""stage-snake@stage""\n  },\n]\n']"
1148,10379,10312,CC BY-SA 4.0,2020-01-03T11:50:29.897,"<p>I will give it a try and explain all required steps with examples.</p>

<p>Please add comments with questions and improvement suggestions if anything is not well enough explained.</p>

<p>The OP (original poster) refers to <code>awscli</code>; while I provide corresponding examples, I also discuss limitations of this approach and give examples of doing same with Python.</p>

<h1>EC2 deployment</h1>

<p>The purpose of this answer is to demonstrate that as OP correctly assumed, no Web UI access neither human interaction is mandatory to deploy a container on an AWS EC2 instance.</p>

<p><strong>Scope and limitations</strong></p>

<p>In this use case, we want to start just one container manually for demo/research purposes, therefore we explicitly decide to do no <em><a href=""/questions/tagged/orchestration"" class=""post-tag"" title=""show questions tagged &#39;orchestration&#39;"" rel=""tag"">orchestration</a></em>. </p>

<p>For a complex and possibly more realistic deployment scenario, this example is therefore not reusable. For same simplicity reasons, we will use EC2 service and create there a single virtual machine.</p>

<p>According to a short documentation research, there seems to be no official AMI with pre-installed Docker daemon. Thus we need to deploy some default EC2 instance and install there Docker daemon, then start the daemon. </p>

<p>While using a private registry, a login there is required; for simplicity purposes, I give also an example to run a container from the public Docker Hub registry.</p>

<p>Also, I am not going to provide a copy-paste automation script but single steps which can be easily adopted towards individual needs. In any case, intermediate results require parsing and passing operations which is then a pure programming activity concern.</p>

<p>A boilerplate automation could be done either with bash using awscli or with Python, using the <a href=""https://boto3.amazonaws.com/v1/documentation/api/latest/index.html"" rel=""nofollow noreferrer"">boto3 SDK</a> for AWS.</p>

<p>Python is worth to consider because you can do better processing of JSON responses you get from AWS. You can also tell Python to execute SSH login and bash commands on the remote host.</p>

<p><strong>Execution plan</strong></p>

<ul>
<li>A. Identify recent Linux AMI (Amazon Machine Image) ID</li>
<li>B. Create keypair and instance (further, also referenced as VM)</li>
<li>C. Connect to the instance</li>
<li>D. Install and configure Docker daemon</li>
<li>E. Run container</li>
</ul>

<p><strong>A. Identify recent Linux AMI image ID</strong></p>

<p>Search for a recent and up-to-date Amazon Linux image following the official <a href=""https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/finding-an-ami.html#finding-an-ami-aws-cli"" rel=""nofollow noreferrer"">documentation</a>:</p>

<pre><code>$ aws ec2 describe-images --owners amazon --filters 'Name=name,Values=amzn2-ami-hvm-2.0.????????.?-x86_64-gp2' 'Name=state,Values=available' --query 'reverse(sort_by(Images, &amp;CreationDate))[:1].ImageId' --output text
ami-01f14919ba412de34
</code></pre>

<p><strong>B. Create keypair and VM</strong></p>

<p>With <code>awscli</code>, you would just say:</p>

<pre><code>$ aws ec2 create-key-pair --key-name ec2-docker-test
</code></pre>

<p>However, the API sends you your public key wrapped in a JSON data message. Therefore, using <a href=""https://blog.ipswitch.com/how-to-create-an-ec2-instance-with-python"" rel=""nofollow noreferrer"">Python</a> it is way easier to process this data message to a <em>.pem</em> file:</p>

<pre><code>import boto3
ec2 = boto3.resource('ec2')

# create a file to store the key locally
outfile = open('ec2-keypair.pem','w')

# call the boto ec2 function to create a key pair
key_pair = ec2.create_key_pair(KeyName='ec2-docker-test')

# capture the key and store it in a file
KeyPairOut = str(key_pair.key_material)
print(KeyPairOut)
outfile.write(KeyPairOut)
</code></pre>

<p>With the AMI ID we have got previously we can now create the VM:</p>

<pre><code>instances = self.ec2r.create_instances(
                 ImageId=AMI_ID,  
                 MinCount=1,
                 MaxCount=1,
                 InstanceType=instance_type,
                 KeyName='ec2-docker-test'
             )
</code></pre>

<p>AWS API allows also lookup of instance state and IP. With little bit more  Python/<em>boto3</em> stanzas you can acquire this data to know when you can proceed.</p>

<p><strong>Note: Firewall consideration</strong></p>

<p>To configure firewall access, please <a href=""https://boto3.amazonaws.com/v1/documentation/api/latest/guide/ec2-example-security-group.html"" rel=""nofollow noreferrer"">create a security group and link it to machines's VPC</a>. For readability reasons, example is not included.</p>

<p><strong>C. Test SSH connection</strong></p>

<p>As soon as the instance is up and running, you can do everything you like by means of <em>remote command execution</em>.</p>

<p>In a Bash script, you would use <code>ssh</code> only or <code>scp</code> to upload a local bash script and run it remotely.</p>

<pre><code> ssh -t &lt;REMOTE_IP&gt; -i &lt;KEY_FILE&gt; &lt;COMMAND&gt;
</code></pre>

<p>With Python, you use further modules like <a href=""http://www.paramiko.org/"" rel=""nofollow noreferrer"">paramiko</a> to establish SSH connection and run commands remotely. </p>

<pre><code>client = paramiko.SSHClient()
client.connect(ip, username=username, key_filename=key_filename, port=port,
                           timeout=timeout,
                           auth_timeout=timeout)

stdin, stdout, stderr = ssh.exec_command(""whoami"")
</code></pre>

<p>For readability purposes, I list further commands unwrapped. In your script, you might want to use elementary helper subroutines to have calls like <code>ssh_call(command)</code>.</p>

<p><strong>D. Install and configure Docker daemon</strong></p>

<p>As said above, anything else from here is running remote commands. </p>

<p>That is, the concluding steps are, following an example in the <a href=""https://docs.aws.amazon.com/AmazonECS/latest/developerguide/docker-basics.html"" rel=""nofollow noreferrer"">official documentation</a>; proceeding is same as you would do it locally, but you need to wrap it in your script and pass over intermediate results if required:</p>

<ul>
<li>install and configure Docker daemon </li>
<li>login to your Docker registry if needed</li>
<li>pull image</li>
<li>run Docker container</li>
</ul>

<pre><code>    sudo yum update -y
    sudo amazon-linux-extras install docker
    sudo service docker start
    sudo usermod -a -G docker ec2-user
    # relogin or continue with sudo, which you shouldn't
    aws ecr get-login --no-include-email --region region


</code></pre>

<p><strong>E. Run container</strong></p>

<p>Pull custom image and run container from a private registry in AWS.</p>

<pre><code>    docker pull aws_account_id.REGISTRY.ecr.REGION.amazonaws.com/REPOSITORY/IMAGE:TAG
    docker run --name MYSERVICENAME -d -p PORT_HOST:PORT_CONTAINER IMAGE:TAG

</code></pre>

<p>Pull an official public  image and run another container listening on port 8001 in a single step:</p>

<pre><code>    docker run --name nginx -d -p 8001:80 nginx:latest

</code></pre>

<hr>

<h1>Alternative scenario with ECS</h1>

<p>As described in these Python/boto3 examples <a href=""https://github.com/kgoedecke/python-ecs-example/blob/master/python_ecs_example/deployment.py"" rel=""nofollow noreferrer"">here</a> and <a href=""https://github.com/AlexIoannides/py-docker-aws-example-project/blob/master/deploy_to_aws.py"" rel=""nofollow noreferrer"">here</a>, it's possible to define an machine cluster with the AWS ECS service and run containers there.</p>

<p>Please note that ECS cluster offers you an <a href=""https://aws.amazon.com/de/ecs/pricing/"" rel=""nofollow noreferrer"">abstraction</a> either from AWS EC2 or AWS Fargate to deliver the actual virtual machines.</p>

<p>If we go for EC2, again we need to <a href=""https://docs.aws.amazon.com/AmazonECS/latest/developerguide/retrieve-ecs-optimized_AMI.html"" rel=""nofollow noreferrer"">pick up</a> a recent machine image, but this we need a machine optimized for ECS. In a nutshell, these machines will have an ECS agent; through its configuration, we assign a machine to our target cluster. </p>

<p>A small bonus is also that ECS machines have Docker daemon already preinstalled.</p>

<p>So, we create an ECS cluster and add a virtual machine to it.</p>

<pre><code>ecs_client.create_cluster(clusterName=cluster_name)

ec2_client.run_instances(
        ImageId=AMI_ID,
        MinCount=1,
        MaxCount=1,
        InstanceType=""t2.micro"",
        IamInstanceProfile={
            ""Name"": ""ecsInstanceRole""
        },
        UserData=""#!/bin/bash \n echo ECS_CLUSTER="" + cluster_name + "" &gt;&gt; /etc/ecs/ecs.config""
    )

</code></pre>

<p>In the cluster, we can create a task definition of the service which are both abstract of the container concept.</p>

<pre><code>ecs_client.register_task_definition(
        containerDefinitions=[
        {
          ""name"": ""&lt;MY_SERVICE&gt;"",
          ""image"": ""&lt;MY_IMAGE&gt;"",
          ""portMappings"": [
            {
              ""containerPort"": 80,
              ""hostPort"": 80
            }
          ]
        }
        ],
        family=""hello_world""
    )
</code></pre>

<p>Now, possibly you ask yourself, how would the Docker daemon on the instance know about your private registry to pull the specified image? For that, the machine's ECS agent needs <a href=""https://docs.aws.amazon.com/AmazonECS/latest/developerguide/private-auth-container-instances.html"" rel=""nofollow noreferrer"">additional configuration</a>.</p>

<p>Now, you can launch the service, which will use the previously defined task to tell the previously authorized Docker daemon to pull the previously built and published image from ECR and run the container on the machine you've included in the ECS cluster <s>in the data center house that Jeff built.</s></p>

<pre><code>ecs_client.create_service(
        cluster=cluster_name,
        serviceName=service_name,
        taskDefinition=task_name,
        desiredCount=1,
        clientToken='request_identifier_string',
        deploymentConfiguration={
            'maximumPercent': 200,
            'minimumHealthyPercent': 50
        }
    )
</code></pre>

<p>Configuration of security groups in the ECS context has been highlighted on StackOverlow <a href=""https://stackoverflow.com/questions/57827251/change-aws-ecs-services-security-groups"">already</a>. In short, these are further calls to the API parts related to security group management.</p>

<h1>Conclusion</h1>

<p>Both Bash and Python implementation options have their benefits and drawbacks.</p>

<p>Seen on long term, Python being a general purpose programming language with large community, allows complex string manipulation and abstractions from a cloud API or a system process.</p>

<p>Without knowing the real goal of the deployment, an end-to end of above steps might not be worth the effort in terms that for deploying a set of related containers which is more typical scenario, other approaches could be more pragmatic. </p>

<p>Before stepping into technical implementation, best is to make well elaborated decisions and choices addressing business goals and budget:</p>

<ul>
<li>how many times will automation need to run and in which time period vs. time to implement it end-to-end from the beginning?</li>
<li>assess whether you need only EC2, or ECS with EC2 either <a href=""https://www.dragonspears.com/blog/aws-container-orchestration-101-ecs-vs-fargate-vs-eks"" rel=""nofollow noreferrer"">Fargate</a> for stateless tasks, or maybe you need Kubernetes?</li>
</ul>

<p>Further reading: ""<em>The Benefits of Managed Kubernetes vs. Amazon ECS</em>"" (short argument from a cloud consultant <a href=""https://www.fairwinds.com/blog/the-benefits-of-managed-kubernetes-vs-amazon-ecs"" rel=""nofollow noreferrer"">blog</a> as of August 2019).</p>

<blockquote>
  <p>A <a href=""https://www.cncf.io/blog/2018/08/29/cncf-survey-use-of-cloud-native-technologies-in-production-has-grown-over-200-percent/"" rel=""nofollow noreferrer"">2018 CNCF</a> survey cites <strong>83%</strong> of organizations use Kubernetes as
  their container orchestration solution vs. <strong>24%</strong> for ECS.</p>
</blockquote>
",707,2020-01-09T19:14:43.570,"[""$ aws ec2 describe-images --owners amazon --filters 'Name=name,Values=amzn2-ami-hvm-2.0.????????.?-x86_64-gp2' 'Name=state,Values=available' --query 'reverse(sort_by(Images, &CreationDate))[:1].ImageId' --output text\nami-01f14919ba412de34\n"", '$ aws ec2 create-key-pair --key-name ec2-docker-test\n', ""import boto3\nec2 = boto3.resource('ec2')\n\n# create a file to store the key locally\noutfile = open('ec2-keypair.pem','w')\n\n# call the boto ec2 function to create a key pair\nkey_pair = ec2.create_key_pair(KeyName='ec2-docker-test')\n\n# capture the key and store it in a file\nKeyPairOut = str(key_pair.key_material)\nprint(KeyPairOut)\noutfile.write(KeyPairOut)\n"", ""instances = self.ec2r.create_instances(\n                 ImageId=AMI_ID,  \n                 MinCount=1,\n                 MaxCount=1,\n                 InstanceType=instance_type,\n                 KeyName='ec2-docker-test'\n             )\n"", ' ssh -t <REMOTE_IP> -i <KEY_FILE> <COMMAND>\n', 'client = paramiko.SSHClient()\nclient.connect(ip, username=username, key_filename=key_filename, port=port,\n                           timeout=timeout,\n                           auth_timeout=timeout)\n\nstdin, stdout, stderr = ssh.exec_command(""whoami"")\n', ""    sudo yum update -y\n    sudo amazon-linux-extras install docker\n    sudo service docker start\n    sudo usermod -a -G docker ec2-user\n    # relogin or continue with sudo, which you shouldn't\n    aws ecr get-login --no-include-email --region region\n\n\n"", '    docker pull aws_account_id.REGISTRY.ecr.REGION.amazonaws.com/REPOSITORY/IMAGE:TAG\n    docker run --name MYSERVICENAME -d -p PORT_HOST:PORT_CONTAINER IMAGE:TAG\n\n', '    docker run --name nginx -d -p 8001:80 nginx:latest\n\n', 'ecs_client.create_cluster(clusterName=cluster_name)\n\nec2_client.run_instances(\n        ImageId=AMI_ID,\n        MinCount=1,\n        MaxCount=1,\n        InstanceType=""t2.micro"",\n        IamInstanceProfile={\n            ""Name"": ""ecsInstanceRole""\n        },\n        UserData=""#!/bin/bash \\n echo ECS_CLUSTER="" + cluster_name + "" >> /etc/ecs/ecs.config""\n    )\n\n', 'ecs_client.register_task_definition(\n        containerDefinitions=[\n        {\n          ""name"": ""<MY_SERVICE>"",\n          ""image"": ""<MY_IMAGE>"",\n          ""portMappings"": [\n            {\n              ""containerPort"": 80,\n              ""hostPort"": 80\n            }\n          ]\n        }\n        ],\n        family=""hello_world""\n    )\n', ""ecs_client.create_service(\n        cluster=cluster_name,\n        serviceName=service_name,\n        taskDefinition=task_name,\n        desiredCount=1,\n        clientToken='request_identifier_string',\n        deploymentConfiguration={\n            'maximumPercent': 200,\n            'minimumHealthyPercent': 50\n        }\n    )\n""]"
1149,10386,8722,CC BY-SA 4.0,2020-01-04T08:41:06.747,"<p>Others have pointed it out already; Certbot makes it easy to handle certificates
while <code>acme_certificate</code> module is more flexible and transparent.</p>

<h2>Acquire Certificate</h2>

<p>To request the ssl certificate with <code>acme_certificate</code>, there are good examples
on <a href=""https://www.digitalocean.com/community/tutorials/how-to-acquire-a-let-s-encrypt-certificate-using-ansible-on-ubuntu-18-04"" rel=""nofollow noreferrer"">DigitalOcean</a>
or on <a href=""https://www.reddit.com/r/ansible/comments/9eyyug/is_there_a_way_to_fully_automate_setting_up_ssl/"" rel=""nofollow noreferrer"">Reddit</a>.
These examples boil down to following tasks:</p>

<ol>
<li>Ensure you have a private key for your acme account. (module <code>openssl_privatekey</code>)</li>
<li>Ensure you have a private key for your certificate. (module <code>openssl_privatekey</code>)</li>
<li>Ensure you have a certificate signing request. (module <code>openssl_csr</code>)</li>
<li>Then a challenge is requested from letsencrypt. (module `acme_certificate')</li>
<li>One of the challenges <code>dns-01</code>, <code>http-01</code> or <code>tls-alpn-01</code> is implemented.</li>
<li>The certficate from letsencrypt is requested. (module `acme_certificate')</li>
<li>(optional) The challenge implementation is removed.</li>
<li>The server configuration is updated with the ssl certificates.</li>
</ol>

<p>With Certbot you can have all these steps in one handy command. They provide
<a href=""https://certbot.eff.org/instructions"" rel=""nofollow noreferrer"">instructions for any platform</a>.</p>

<pre><code>sudo certbot --nginx
</code></pre>

<p>Module <code>acme_certificate</code> is Ansible native and a playbook with all these steps 
is only written once. The tasks in the playbook are transparent and you have
the certificates and keys for your server configuration at hand. With Certbot
you have to know the directory <code>/etc/letsencrypt/live/my.domain.com</code> wherein
those artifacts are generated.</p>

<h2>Renew Certificate</h2>

<p>A crucial point is the responsibility for certificate renewal. Above Certbot
command has already created a cron job which checks the validity of the
certificate and renews it if required. If the certificate is managed with
Ansible you have to run an Ansible playbook for renewal.</p>

<p><a href=""https://letsencrypt.org/2015/11/09/why-90-days.html"" rel=""nofollow noreferrer"">Letsencrypt certificates are valid for 90 days, so the renewal process gets automated.</a>
For the renewal, above Ansible playbook works, it does the renewal as well.
However, it is advised to create a new csr (3) and certificate key (2) when a certificate
is renewed. Handling this properly, the playbook will grow quite a bit.</p>

<p>On Ubuntu, above certbot command has already created a cron job which handles certificate
renewal, so nothing else needs to be done.</p>

<h2>Conclusion</h2>

<p>There are roles in <a href=""https://galaxy.ansible.com/"" rel=""nofollow noreferrer"">Ansible Galaxy</a> for Certbot and
<code>acme_certificate</code> module. Personally, I like <code>acme_certificate</code> module for its transparency and because it's an Ansible native solution. However, I run Ansible from my personal notebook
and do not want to remember running a playbook for certificate renewal.
Therefore, I have installed Certbot which runs on the host and does the renewal without an external trigger.</p>
",18932,2020-01-06T00:45:02.570,['sudo certbot --nginx\n']
1150,10387,10113,CC BY-SA 4.0,2020-01-04T10:47:42.107,"<p>The answer is <code>Key Based SSH</code> </p>

<p>Reasons </p>

<ol>
<li>You can SSH multiple host machines using the same key or Different keys. </li>
<li>If you reboot your machine while playbook running it again SSH using your provided key so your ansible-playbook runs without occurring any errors.</li>
<li>Also, you get authentication using the appropriate user.</li>
</ol>

<p>use can use <strong>inventory.ini</strong> file </p>

<p><strong>example</strong> </p>

<pre><code>[hostMachine]
ubuntu@xx.xx.xx.xx  ansible_ssh_user=ubuntu ansible_ssh_private_key_file=/path of your pem file

[ABCDMachine]
ABCD@xx.xx.xx.xx ansible_ssh_user=ABCD ansible_ssh_private_key_file=/path of your pem file
</code></pre>

<p><strong>Command for run ansible-playbook</strong></p>

<blockquote>
  <p>ansible-playbook -i inventory.ini main.yml</p>
</blockquote>
",17679,2020-01-04T10:47:42.107,['[hostMachine]\nubuntu@xx.xx.xx.xx  ansible_ssh_user=ubuntu ansible_ssh_private_key_file=/path of your pem file\n\n[ABCDMachine]\nABCD@xx.xx.xx.xx ansible_ssh_user=ABCD ansible_ssh_private_key_file=/path of your pem file\n']
1151,10400,10102,CC BY-SA 4.0,2020-01-06T07:45:02.450,"<p>There are two options either you make sure you use the same Python version on each host or you make sure the right packages are installed on each platform.</p>

<h2>Chose same Python interpreter</h2>

<p>Provide the python binary to use. Since you have a Debian on each host, the location is always the same. If you know a Python version that is available on each host, go for this.</p>

<p>Either in your inventory <code>hosts</code></p>

<pre><code>[webserver]
srv1.example.com
srv2.example.com

[webserver:vars]
ansible_python_interpreter=/usr/bin/python3
</code></pre>

<p>Or in your Ansible configuration <code>ansible.cfg</code></p>

<pre><code>ansible_python_interpreter=/usr/bin/python3
</code></pre>

<p>See also <a href=""https://docs.ansible.com/ansible/latest/reference_appendices/python_3_support.html#using-python-3-on-the-managed-machines-with-commands-and-playbooks"" rel=""nofollow noreferrer"">https://docs.ansible.com/ansible/latest/reference_appendices/python_3_support.html#using-python-3-on-the-managed-machines-with-commands-and-playbooks</a></p>

<h2>Package per Python version</h2>

<p>If you do not know whether either Python 3 or 2 is available on each host, ensure to get the right package for each Python version.</p>

<pre><code>- apt:
    name: python-pip
  when: ansible_python.version.major==2

- apt:
    name: python3-pip
  when: ansible_python.version.major==3
</code></pre>

<p>You may face the same issue when installing Python packages. So you can put your Pythone version specific tasks in a v2 and in a v3 file and conditionally include one for version 2 and the other for version 3.</p>
",18932,2020-01-07T03:34:58.833,"['[webserver]\nsrv1.example.com\nsrv2.example.com\n\n[webserver:vars]\nansible_python_interpreter=/usr/bin/python3\n', 'ansible_python_interpreter=/usr/bin/python3\n', '- apt:\n    name: python-pip\n  when: ansible_python.version.major==2\n\n- apt:\n    name: python3-pip\n  when: ansible_python.version.major==3\n']"
1152,10410,10409,CC BY-SA 4.0,2020-01-07T07:09:37.417,"<p>Apparently <code>delegate_to</code> and <code>lininfile</code> or <code>blockinfile</code> do not work properly together, <a href=""https://github.com/ansible/ansible/issues/28313"" rel=""nofollow noreferrer"">https://github.com/ansible/ansible/issues/28313</a>.</p>

<h2>Module <code>blockinfile</code></h2>

<p>It seems redundant lines have not been written as you would expect. Eventually, <code>blockinfile</code> without a marker does the job.</p>

<pre><code>- name: copy the output to a local file
  blockinfile:
    dest: ""{{ myshell_output4.stdout }}""
    marker: false
    block: |
      ########################################################
      ###############HOSTNAME:{{ inventory_hostname }}################
      {{ myshell_output3.stdout }}
      ########################END#############################
  delegate_to: localhost
</code></pre>

<h2>Concatenate files at the end</h2>

<p>Alternatively, you can write to different files and concatenate those files after all tasks have run.</p>

<pre><code>- name: copy the output to a local file
  copy:
    content: |
      ########################################################
      ###############HOSTNAME:{{ inventory_hostname }}################
      {{ myshell_output3.stdout }}
      ########################END#############################
    dest: tmp/{{ inventory_hostname }}
  delegate_to: localhost

- name: log files are concatenated
  assemble:
    src: tmp/
    dest: ""{{ myshell_output4.stdout }}""
  delegate_to: localhost
  run_once: true

- name: tmp folder is absent
  path:
    src: tmp/
    state: absent
  delegate_to: localhost
  run_once: true
</code></pre>

<p>In case your local file <code>myshell_output4.stdout</code> does exist already and you want to append to an  existing file, you assemble the files <code>tmp/*</code> into <code>tmp/assembled</code> and the append them with <code>lineinfile</code>.</p>

<pre><code>- name: append assembled to a local file
  lineinfile:
    dest: ""{{ myshell_output4.stdout }}""
    line: ""{{ lookup('file', tmp/assembled) }}""
  delegate_to: localhost
  run_once: true
</code></pre>
",18932,2020-01-07T12:56:52.167,"['- name: copy the output to a local file\n  blockinfile:\n    dest: ""{{ myshell_output4.stdout }}""\n    marker: false\n    block: |\n      ########################################################\n      ###############HOSTNAME:{{ inventory_hostname }}################\n      {{ myshell_output3.stdout }}\n      ########################END#############################\n  delegate_to: localhost\n', '- name: copy the output to a local file\n  copy:\n    content: |\n      ########################################################\n      ###############HOSTNAME:{{ inventory_hostname }}################\n      {{ myshell_output3.stdout }}\n      ########################END#############################\n    dest: tmp/{{ inventory_hostname }}\n  delegate_to: localhost\n\n- name: log files are concatenated\n  assemble:\n    src: tmp/\n    dest: ""{{ myshell_output4.stdout }}""\n  delegate_to: localhost\n  run_once: true\n\n- name: tmp folder is absent\n  path:\n    src: tmp/\n    state: absent\n  delegate_to: localhost\n  run_once: true\n', '- name: append assembled to a local file\n  lineinfile:\n    dest: ""{{ myshell_output4.stdout }}""\n    line: ""{{ lookup(\'file\', tmp/assembled) }}""\n  delegate_to: localhost\n  run_once: true\n']"
1153,10428,10421,CC BY-SA 4.0,2020-01-08T08:00:14.377,"<p>As a suggestion... Can you try calling the absolute path of the python executable in the environment? I mean: when you change conda environments, what happens is that the python executable you call changes path; you can find which python executable would be executed by</p>

<pre><code>which python
</code></pre>

<p>Inside the environment. Then just forget about calling conda in the Jenkins pipeline. That should work if that’s what you’re changing environments for. Or are you changing the conda environment for some other reason?</p>

<p>EDIT: the same would happen when calling ansible as a library installed in the environment. It will change path to something like:</p>

<pre><code>~/conda/envs/your_env/lib/ansible
</code></pre>
",18765,2020-01-08T08:00:14.377,"['which python\n', '~/conda/envs/your_env/lib/ansible\n']"
1154,10430,10426,CC BY-SA 4.0,2020-01-08T09:10:19.257,"<p>Have you got AWS credentials configured on that machine?</p>

<pre><code>~ $ aws configure
</code></pre>

<p>And then verify with:</p>

<pre><code>~ $ aws sts get-caller-identity
</code></pre>

<p>Hope that helps :)</p>
",8800,2020-01-08T09:10:19.257,"['~ $ aws configure\n', '~ $ aws sts get-caller-identity\n']"
1155,10433,10368,CC BY-SA 4.0,2020-01-08T13:22:13.460,"<p>That's because you forgot to link the <code>&lt;configuration&gt;</code> for the plugin with the <code>&lt;server&gt;</code> definition in settings.xml., and the tomcat7 plugin is trying to deploy as un-authenticated because it has not credentials to try.</p>

<p>Add <code>&lt;server&gt;maven-tomcat-war-deployment-server&lt;/server&gt;</code> in the configuration section of the plugin:    </p>

<pre><code>&lt;configuration&gt;
    &lt;server&gt;maven-tomcat-war-deployment-server&lt;/server&gt;
    &lt;url&gt;http://localhost:8080/manager/text&lt;/url&gt;
    &lt;path&gt;/my-project-url-path&lt;/path&gt;
&lt;/configuration&gt;
</code></pre>
",185,2020-01-08T13:22:13.460,['<configuration>\n    <server>maven-tomcat-war-deployment-server</server>\n    <url>http://localhost:8080/manager/text</url>\n    <path>/my-project-url-path</path>\n</configuration>\n']
1156,10458,10457,CC BY-SA 4.0,2020-01-10T09:21:07.943,"<p>If you're using Jenkins pipeline, you can use the <a href=""https://jenkins.io/doc/pipeline/tour/post/#email"" rel=""nofollow noreferrer"">email notification post action</a>, as a way to <em>send</em> the message:</p>

<pre><code>post {
    failure {
        mail to: 'team@example.com',
             subject: ""Failed Pipeline: ${currentBuild.fullDisplayName}"",
             body: ""Something is wrong with ${env.BUILD_URL}""
    }
}
</code></pre>

<p>(you would have to configure the server and credentials for your case)</p>

<p>The message itself can be constructed from the job data. The easiest way is perhaps to tee the output of the job to a file and use it as an artifact to attach to the message that gets sent.</p>
",354,2020-01-10T09:21:07.943,"['post {\n    failure {\n        mail to: \'team@example.com\',\n             subject: ""Failed Pipeline: ${currentBuild.fullDisplayName}"",\n             body: ""Something is wrong with ${env.BUILD_URL}""\n    }\n}\n']"
1157,10479,10440,CC BY-SA 4.0,2020-01-13T19:37:15.340,"<p>This error <code>CannotPullContainerError</code> usually occurs when you have no access to the Internet from ECS and thus it doesn't able to pull an image from registry.</p>

<p>Make sure you have networking configured in such a way to have an access to Internet <a href=""https://stackoverflow.com/questions/48226547/aws-fargate-cannotpullcontainererror-500"">https://stackoverflow.com/questions/48226547/aws-fargate-cannotpullcontainererror-500</a></p>

<p>Manually you can confirm everything with such steps</p>

<ol>
<li>Find route table. Check whether it belongs
to your VPC.</li>
<li>Find proper NAT (you need NAT Gateway ID) (<strong>IMPORTANT</strong>: NAT should be launched in PUBLIC
subnet)</li>
<li><p>Create a route for that</p>

<p>$ aws ec2 create-route --route-table-id ""rtb-037148d7b5967a231"" --destination-cidr-block ""0.0.0.0/0"" --nat-gateway-id ""nat-0c137ae8a2b409088""</p></li>
</ol>

<p>You can also use internet gateway instead of NAT but the main idea is the same - to create connectivity from service to registry.
If you have that in place and verified you can easily rewrite that to ansible tasks.</p>

<p><strong>Update</strong>
To start an ECS task you want to use <code>ecs_task</code> module <a href=""https://docs.ansible.com/ansible/latest/modules/ecs_task_module.html"" rel=""nofollow noreferrer"">https://docs.ansible.com/ansible/latest/modules/ecs_task_module.html</a></p>

<p>To pull image from repository and start it you can use these tasks</p>

<pre><code>- name: docker login
  shell: ""$(aws ecr get-login --no-include-email --region {{ default_region }})""
  args:
    executable: ""/bin/bash""

- name: pull latest app image
  docker_image:
    name: ""{{ ecr_repository }}/myapp:{{ image_tag }}""
    force: yes

- name: run application with docker compose
  docker_service:  # module is called docker_service before Ansible 2.8
    project_name: ""myapp""
    project_src: ""{{ app_dir }}""  # path to a directory containing a docker-compose.yml
    pull: yes
    recreate: always  # run scheduler from a clean state
    remove_orphans: yes  # remove containers for services not defined in the compose file
    state: present  # specifying present is the same as running docker-compose up
    restarted: yes  # use with state present to restart all containers
  register: output
</code></pre>

<p>but in case of Fargate the above is not needed as everything is handled by task definition</p>
",19083,2020-01-14T10:20:00.960,"['- name: docker login\n  shell: ""$(aws ecr get-login --no-include-email --region {{ default_region }})""\n  args:\n    executable: ""/bin/bash""\n\n- name: pull latest app image\n  docker_image:\n    name: ""{{ ecr_repository }}/myapp:{{ image_tag }}""\n    force: yes\n\n- name: run application with docker compose\n  docker_service:  # module is called docker_service before Ansible 2.8\n    project_name: ""myapp""\n    project_src: ""{{ app_dir }}""  # path to a directory containing a docker-compose.yml\n    pull: yes\n    recreate: always  # run scheduler from a clean state\n    remove_orphans: yes  # remove containers for services not defined in the compose file\n    state: present  # specifying present is the same as running docker-compose up\n    restarted: yes  # use with state present to restart all containers\n  register: output\n']"
1158,10483,9560,CC BY-SA 4.0,2020-01-13T23:52:55.183,"<p>Note that if you're not actually checking out a Jenkinsfile (if you're coding in the Pipeline Script config window), <code>GIT_BRANCH</code> will be <code>null</code>, and Hedi Nasr's answer will fail (you can access the var with <code>${env.GIT_BRANCH}</code> instead to avoid the hard fail, but it will still be <code>null</code>).</p>

<p>You don't give any information about how you checked out the project, so I'm going to assume you cloned it at some point during the execution of your Jenkinsfile. In that case, the repository will be in a <a href=""https://git-scm.com/docs/git-checkout#Documentation/git-checkout.txt-emgitcheckoutem--detachltbranchgt"" rel=""nofollow noreferrer"">detached state</a>, even if you cloned it with a target branch:</p>

<pre><code>git status
# HEAD detached at 9a92344
</code></pre>

<p>In this case before you can commit you need to checkout your branch as Hedi Nasr points out. You should know your target branch in advance, and can inject it with <a href=""https://wiki.jenkins.io/display/JENKINS/EnvInject+Plugin"" rel=""nofollow noreferrer"">envInject</a>'s Properties Content if you need to vary by instance.</p>

<p>You can also discover branches with:</p>

<pre><code>git branch -a
</code></pre>
",5743,2020-01-13T23:58:28.747,"['git status\n# HEAD detached at 9a92344\n', 'git branch -a\n']"
1159,10484,6126,CC BY-SA 4.0,2020-01-14T00:11:38.437,"<p>You can also use environment block to inject an environment variable.</p>

<p>(Side note: <code>sh</code> is not needed for echo)</p>

<pre><code>pipeline {
    agent none
    environment {
        FOO = ""bar""
    }
    stages {
        stage(""first"") {
            steps {
                echo ""${env.FOO}""
                // or echo ""${FOO}""
            }
        }
    }
}
</code></pre>

<p>You can even define the env var inside the stage block to limit the scope:</p>

<pre><code>pipeline {
    agent none
    stages {
        stage(""first"") {
            environment {
                FOO = ""bar""
            }
            steps {
                // prints ""bar""
                echo ""${env.FOO}""
                // or echo ""${FOO}""
            }
        }
        stage(""second"") {
            steps {
                // prints ""null""
                echo ""${env.FOO}""
                // or echo ""${FOO}"", pipeline would fail here
            }
        }
    }
}
</code></pre>
",5743,2020-01-14T00:11:38.437,"['pipeline {\n    agent none\n    environment {\n        FOO = ""bar""\n    }\n    stages {\n        stage(""first"") {\n            steps {\n                echo ""${env.FOO}""\n                // or echo ""${FOO}""\n            }\n        }\n    }\n}\n', 'pipeline {\n    agent none\n    stages {\n        stage(""first"") {\n            environment {\n                FOO = ""bar""\n            }\n            steps {\n                // prints ""bar""\n                echo ""${env.FOO}""\n                // or echo ""${FOO}""\n            }\n        }\n        stage(""second"") {\n            steps {\n                // prints ""null""\n                echo ""${env.FOO}""\n                // or echo ""${FOO}"", pipeline would fail here\n            }\n        }\n    }\n}\n']"
1160,10500,10491,CC BY-SA 4.0,2020-01-15T02:28:32.280,"<p>What you've described here is the recommended way to pass dependencies between modules, but it relies on features introduced in Terraform 0.12. You appear to be using Terraform 0.11, where unfortunately these features are not available.</p>

<p>For Terraform 0.12 it would be idiomatic to write it using the ""first-class expressions"" syntax, like this (with these examples spanning the three modules just like you did in your opening example):</p>

<pre><code>output ""alb_arn"" {
  value = aws_alb.model-server.arn
}
</code></pre>

<pre><code>module ""common"" {
  source = ""./modules/common""
}

module ""other"" {
  source = ""./modules/other""

  target_group_depends_on = module.common.alb_arn
}
</code></pre>

<pre><code>variable ""target_group_depends_on"" {
  type    = any # only the dependencies matter, not the value
  default = null
}

resource ""aws_alb_target_group"" ""modelServer"" {
  # ...

  depends_on = [var.target_group_depends_on]
}
</code></pre>

<hr>

<p>The main missing feature for the above in Terraform 0.11 is that it only supports resources in <code>depends_on</code>, and not other kinds of object like variables.</p>

<p>However, it's possible to work around that by introducing an additional do-nothing resource that exists only to be a dependency:</p>

<pre><code>output ""alb_arn"" {
  value = ""${aws_alb.model-server.arn}""
}
</code></pre>

<pre><code>module ""common"" {
  source = ""./modules/common""
}

module ""other"" {
  source = ""./modules/other""

  target_group_depends_on = ""${module.common.alb_arn}""
}
</code></pre>

<pre><code>variable ""target_group_depends_on"" {
  type    = ""string"" # (because ""any"" isn't supported in 0.11)
  default = """"
}

resource ""null_resource"" ""target_group_depends_on"" {
  triggers = {
    # The reference to the variable here creates an implicit
    # dependency on the variable.
    dependency = ""${var.target_group_depends_on}""
  }
}

resource ""aws_alb_target_group"" ""modelServer"" {
  # ...

  # Marking the null_resource as an explicit dependency
  # means this indirectly depends on everything the
  # null_resource depends on.
  depends_on = [""null_resource.target_group_depends_on""]
}
</code></pre>

<p>Note that in Terraform 0.11 the <code>depends_on</code> argument takes a list of literal strings containing resource addresses, not interpolated values. That was the specific reason for the error message you saw when you tried your example, but a reference like <code>""var.dependency""</code> would not have worked there either because only resource addresses are accepted as explicit dependencies in Terraform 0.11.</p>
",2463,2020-01-15T02:28:32.280,"['output ""alb_arn"" {\n  value = aws_alb.model-server.arn\n}\n', 'module ""common"" {\n  source = ""./modules/common""\n}\n\nmodule ""other"" {\n  source = ""./modules/other""\n\n  target_group_depends_on = module.common.alb_arn\n}\n', 'variable ""target_group_depends_on"" {\n  type    = any # only the dependencies matter, not the value\n  default = null\n}\n\nresource ""aws_alb_target_group"" ""modelServer"" {\n  # ...\n\n  depends_on = [var.target_group_depends_on]\n}\n', 'output ""alb_arn"" {\n  value = ""${aws_alb.model-server.arn}""\n}\n', 'module ""common"" {\n  source = ""./modules/common""\n}\n\nmodule ""other"" {\n  source = ""./modules/other""\n\n  target_group_depends_on = ""${module.common.alb_arn}""\n}\n', 'variable ""target_group_depends_on"" {\n  type    = ""string"" # (because ""any"" isn\'t supported in 0.11)\n  default = """"\n}\n\nresource ""null_resource"" ""target_group_depends_on"" {\n  triggers = {\n    # The reference to the variable here creates an implicit\n    # dependency on the variable.\n    dependency = ""${var.target_group_depends_on}""\n  }\n}\n\nresource ""aws_alb_target_group"" ""modelServer"" {\n  # ...\n\n  # Marking the null_resource as an explicit dependency\n  # means this indirectly depends on everything the\n  # null_resource depends on.\n  depends_on = [""null_resource.target_group_depends_on""]\n}\n']"
1161,10503,10475,CC BY-SA 4.0,2020-01-15T10:41:16.763,"<p>So I ended up using this simple shell script</p>

<pre><code>docker images -q --filter ""before=ecr.us-east-1.amazonaws.com/myapp:02e56bac4ee3f27a4d5670a6ac0d578e3dd5b2e5"" | xargs docker rmi --force
</code></pre>

<p>First you <a href=""https://docs.docker.com/engine/reference/commandline/images/#filtering"" rel=""nofollow noreferrer"">filter your images to list</a> only those created before the latest one (you either know your recent tag or just use <code>latest</code> one)</p>

<p>The you <a href=""https://docs.docker.com/engine/reference/commandline/rmi/"" rel=""nofollow noreferrer"">just remove</a> those images with <code>docker rmi</code> piping it to <a href=""http://man7.org/linux/man-pages/man1/xargs.1.html"" rel=""nofollow noreferrer"">xargs</a></p>

<p>You can invoke this on each deploy or setup a cron to do that periodically.</p>
",19083,2020-01-15T10:41:16.763,"['docker images -q --filter ""before=ecr.us-east-1.amazonaws.com/myapp:02e56bac4ee3f27a4d5670a6ac0d578e3dd5b2e5"" | xargs docker rmi --force\n']"
1162,10505,1039,CC BY-SA 4.0,2020-01-15T14:21:16.443,"<p>GitLab CI includes caching of directories, <strong>relative to working directory</strong>. You can use this to cache maven local repository.</p>

<pre><code>myjob:
  image: maven
  variables:
    MAVEN_OPTS: ""-Dmaven.repo.local=${CI_PROJECT_DIR}/.repository/""
  cache:
    key: maven
    paths: [.repository/]
  script:
  - mvn clean verify
</code></pre>

<p>You'll see something like this in job log:</p>

<pre><code>Checking cache for maven...
Downloading cache.zip from https://storage.googleapis.com/gitlab-com-runners-cache/project/133221/maven 
...
Creating cache maven...
 .repository/: found 948 matching files             
 Uploading cache.zip to https://storage.googleapis.com/gitlab-com-runners-cache/project/133221/maven 
</code></pre>

<p>See <a href=""https://docs.gitlab.com/ee/ci/caching/"" rel=""nofollow noreferrer"">GitLab caching documentation</a>.</p>
",19123,2020-01-15T14:21:16.443,"['myjob:\n  image: maven\n  variables:\n    MAVEN_OPTS: ""-Dmaven.repo.local=${CI_PROJECT_DIR}/.repository/""\n  cache:\n    key: maven\n    paths: [.repository/]\n  script:\n  - mvn clean verify\n', 'Checking cache for maven...\nDownloading cache.zip from https://storage.googleapis.com/gitlab-com-runners-cache/project/133221/maven \n...\nCreating cache maven...\n .repository/: found 948 matching files             \n Uploading cache.zip to https://storage.googleapis.com/gitlab-com-runners-cache/project/133221/maven \n']"
1163,10514,10511,CC BY-SA 4.0,2020-01-17T03:05:28.473,"<p>Assuming that you're already planning on executing each command in a separate task, you can just use a folding block scalar (<code>&gt;</code>). While these are typically used for multi-line strings since they replace newlines with a single space, a bonus is that they don't evaluate escape sequences, so nothing needs to be escaped.</p>

<p>However, <code>&gt;</code> alone won't strip the trailing newline character which is where <code>-</code> comes in.</p>

<pre><code>- name: Enable rapid scan
  command: &gt;-
    imunify360-agent config update '{""MALWARE_SCANNING"": {""rapid_scan"": true}}'

- name: Cleanup scan schedule
  command: &gt;-
    imunify360-agent config update '{""MALWARE_SCANNING"": {""default_action"": ""cleanup""}, ""MALWARE_SCAN_SCHEDULE"":{""interval"": ""week""}}'

- name: Enable scan inotify
  command: &gt;-
    imunify360-agent config update '{""MALWARE_SCANNING"": {""enable_scan_inotify"": true}}'
</code></pre>
",19156,2020-01-17T03:05:28.473,"['- name: Enable rapid scan\n  command: >-\n    imunify360-agent config update \'{""MALWARE_SCANNING"": {""rapid_scan"": true}}\'\n\n- name: Cleanup scan schedule\n  command: >-\n    imunify360-agent config update \'{""MALWARE_SCANNING"": {""default_action"": ""cleanup""}, ""MALWARE_SCAN_SCHEDULE"":{""interval"": ""week""}}\'\n\n- name: Enable scan inotify\n  command: >-\n    imunify360-agent config update \'{""MALWARE_SCANNING"": {""enable_scan_inotify"": true}}\'\n']"
1164,10520,1635,CC BY-SA 4.0,2020-01-17T16:47:47.843,"<p>For example, if you want to run systemd in a Arch Linux container,
run this command: <code>docker run -it --privileged -v /sys/fs/cgroup:/sys/fs/cgroup:ro --name=ArchLinux archlinux /bin/sh -c ""if [ -x /etc/docker-start ]; then exec /etc/docker-start; else exec /bin/sh; fi""</code></p>

<p>Then run these commands in the container:</p>

<pre><code>echo 'Server = https://THE_FASTEST_MIRROR_FOR_YOU/archlinux/$repo/os/$arch' &gt;/etc/pacman.d/mirrorlist
pacman -Sy --noconfirm systemd systemd-sysvcompat
passwd -d root
echo -en '#!/bin/sh\numount /etc/hostname; umount /etc/hosts; umount /etc/resolv.conf; exec /usr/lib/systemd/systemd' &gt;/etc/docker-start
chmod 700 /etc/docker-start
echo -e 'nameserver 8.8.8.8' &gt;/etc/resolv.conf
exit
</code></pre>

<p>Then start the container and attach to it: <code>docker start -ia ArchLinux</code></p>

<p>You need to run with <code>--privileged</code>, and this may cause some security problems. Please try to avoid it if possible.</p>
",19172,2020-01-18T14:09:01.603,"[""echo 'Server = https://THE_FASTEST_MIRROR_FOR_YOU/archlinux/$repo/os/$arch' >/etc/pacman.d/mirrorlist\npacman -Sy --noconfirm systemd systemd-sysvcompat\npasswd -d root\necho -en '#!/bin/sh\\numount /etc/hostname; umount /etc/hosts; umount /etc/resolv.conf; exec /usr/lib/systemd/systemd' >/etc/docker-start\nchmod 700 /etc/docker-start\necho -e 'nameserver 8.8.8.8' >/etc/resolv.conf\nexit\n""]"
1165,10522,10511,CC BY-SA 4.0,2020-01-18T00:57:38.237,"<p>It turns out single quote works where double quote and backslash didn't.</p>

<blockquote>
<pre><code>- name: Enable rapid scan
  command: imunify360-agent config update '{""MALWARE_SCANNING""':' {""rapid_scan""':' true}}'
</code></pre>
</blockquote>

<p>I learned that folding block scalar (>) is an easy alternative and a good way to avoid escaping.</p>
",19154,2020-01-18T00:57:38.237,"['- name: Enable rapid scan\n  command: imunify360-agent config update \'{""MALWARE_SCANNING""\':\' {""rapid_scan""\':\' true}}\'\n']"
1166,10535,10534,CC BY-SA 4.0,2020-01-20T13:08:25.250,"<p>You need to add the <code>jenkins</code> user to the <code>docker</code> group:</p>

<pre><code># run the following command as root
usermod -aG docker jenkins
</code></pre>
",16683,2020-01-20T13:08:25.250,['# run the following command as root\nusermod -aG docker jenkins\n']
1167,10544,10542,CC BY-SA 4.0,2020-01-21T19:06:20.673,"<p>I think this <em>might</em> be as easy as adding a sleep with the value of seconds you'd like to wait before rebooting. Also, since Ansible runs in parallel by default, we'll have to specify that we only want it to run as one process (what Ansible calls forks) instead of the default of 5. So, like this:</p>

<pre><code>ansible -i inventory nodes -a ""sleep 30 &amp;&amp; /sbin/reboot"" -f 1
</code></pre>
",9148,2020-01-21T19:06:20.673,"['ansible -i inventory nodes -a ""sleep 30 && /sbin/reboot"" -f 1\n']"
1168,10546,10542,CC BY-SA 4.0,2020-01-21T22:42:56.963,"<p>@Argyle explained the <code>--fork 1</code> trick to achieve a serial run.</p>

<p>I suggest you have a look at the <a href=""https://docs.ansible.com/ansible/latest/modules/reboot_module.html"" rel=""nofollow noreferrer""><code>reboot</code> module</a> that might be better suited than running a command directly. </p>

<p>A quick example that will reboot all your nodes one by one waiting for each to be fully booted before moving to the next one.</p>

<pre><code>ansible -i inventory nodes --forks 1 -m reboot 
</code></pre>

<p>Pass needed parameters to the module depending on your requirements with the <code>-a</code> option.</p>
",13111,2020-01-21T22:42:56.963,['ansible -i inventory nodes --forks 1 -m reboot \n']
1169,10554,10532,CC BY-SA 4.0,2020-01-22T17:02:49.080,"<p>The best way to deploy prometheus to kubernetes is with the helm chart:</p>

<p><a href=""https://github.com/helm/charts/tree/master/stable/prometheus"" rel=""nofollow noreferrer"">https://github.com/helm/charts/tree/master/stable/prometheus</a></p>

<p>If you haven't used helm yet, its a very simple install to your laptop/etc and the cluster (and the newest version doesn't even require a cluster side install).  It takes like 30 seconds.  It's a package manager for kubernetes and it allows you to install, upgrade, list, and delete ""charts"" which are basically simple wrappers around kubernetes YAML files (with some nice templating).  It would even be good to wrap your spring boot apps in a helm chart =).</p>

<p>Once you've got prometheus running well, there is a good tutorial here on setting up actuator's prometheus endpoint in spring-boot and getting it picked up by prometheus by editing its values.yaml.</p>

<p><a href=""https://www.callicoder.com/spring-boot-actuator-metrics-monitoring-dashboard-prometheus-grafana/"" rel=""nofollow noreferrer"">https://www.callicoder.com/spring-boot-actuator-metrics-monitoring-dashboard-prometheus-grafana/</a></p>

<pre><code># my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - ""first_rules.yml""
  # - ""second_rules.yml""

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=&lt;job_name&gt;` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
    static_configs:
    - targets: ['127.0.0.1:9090']

  - job_name: 'spring-actuator'
    metrics_path: '/actuator/prometheus'
    scrape_interval: 5s
    static_configs:
    - targets: ['HOST_IP:8080']
</code></pre>

<p>There's also some info at the end of the tutorial about surfacing all this in Grafana for slick visualization.</p>
",16059,2020-01-22T17:02:49.080,"['# my global config\nglobal:\n  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.\n  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.\n  # scrape_timeout is set to the global default (10s).\n\n# Load rules once and periodically evaluate them according to the global \'evaluation_interval\'.\nrule_files:\n  # - ""first_rules.yml""\n  # - ""second_rules.yml""\n\n# A scrape configuration containing exactly one endpoint to scrape:\n# Here it\'s Prometheus itself.\nscrape_configs:\n  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.\n  - job_name: \'prometheus\'\n    # metrics_path defaults to \'/metrics\'\n    # scheme defaults to \'http\'.\n    static_configs:\n    - targets: [\'127.0.0.1:9090\']\n\n  - job_name: \'spring-actuator\'\n    metrics_path: \'/actuator/prometheus\'\n    scrape_interval: 5s\n    static_configs:\n    - targets: [\'HOST_IP:8080\']\n']"
1170,10568,10539,CC BY-SA 4.0,2020-01-23T13:39:16.853,"<p>Thanks for your response @Zeitounator. I'm running Ansible 2.8
Since posting this I have received an answer that works for me. I realized that these facts are presented as a list of dicts as noted in the <a href=""https://docs.ansible.com/ansible/2.8/modules/vmware_vm_facts_module.html"" rel=""nofollow noreferrer"">doco</a>, but I was still having trouble for some reason (confused myself badly.) The solution hinges on using with_items instead of with_dict and using an appropriate conditional like so:</p>

<pre><code>  - name: Test vmware_vm_facts
    vmware_vm_facts:
      hostname: ""{{ vcenter_hostname }}""
      username: ""{{ vcenter_username }}""
      password: ""{{ vcenter_password }}""
      validate_certs: no
    delegate_to: localhost
    register: rc


  - debug:
      msg: ""IP of {{ item.guest_name }} ({{ item.uuid }}) is {{ item.ip_address }} and power is {{ item.power_state }}""
    with_items: ""{{ rc.virtual_machines }}""
    when: item.guest_name is search(inventory_hostname)
</code></pre>
",19224,2020-01-23T13:39:16.853,"['  - name: Test vmware_vm_facts\n    vmware_vm_facts:\n      hostname: ""{{ vcenter_hostname }}""\n      username: ""{{ vcenter_username }}""\n      password: ""{{ vcenter_password }}""\n      validate_certs: no\n    delegate_to: localhost\n    register: rc\n\n\n  - debug:\n      msg: ""IP of {{ item.guest_name }} ({{ item.uuid }}) is {{ item.ip_address }} and power is {{ item.power_state }}""\n    with_items: ""{{ rc.virtual_machines }}""\n    when: item.guest_name is search(inventory_hostname)\n']"
1171,10589,10588,CC BY-SA 4.0,2020-01-24T20:49:15.977,"<p>As it says, <code>No such file or directory: 'gpg'</code>, so you probably need to install <code>gnupg</code> before adding the PPA repository:</p>

<pre><code>apt-get install gnupg
</code></pre>
",16683,2020-01-25T08:40:56.617,['apt-get install gnupg\n']
1172,10593,10485,CC BY-SA 4.0,2020-01-25T09:35:06.903,"<p>I think I see what you are after. Build variables created in the Variables tab of the GUI designer are scoped to the entire definition. But you can set a Job Scoped variable from a script within a <a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&amp;tabs=classic%2Cpowershell#set-variables-in-scripts"" rel=""nofollow noreferrer"">GUI based pipeline</a>. </p>

<p>So within the context of each of the Agent Jobs you have defined above, you would add a powershell task that would allow you to set the variable(s) that you then use for the automagic variable substitution in your xml.</p>

<h3>YAML is better</h3>

<p>If you want to go the <a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/get-started/pipelines-get-started?view=azure-devops&amp;tabs=yaml"" rel=""nofollow noreferrer"">YAML definition</a> route you can actually create Job scoped variables directly in yaml. This example below substitutes against a JSON file but the concepts are similar for xml.</p>

<p>This is the Json file it substitutes against <code>test.json</code>.</p>

<pre><code>{
    ""menu"": {
        ""id"": ""file"",
        ""value"": ""File""
    }
}
</code></pre>

<pre><code>trigger:
- master

pool:
  vmImage: 'ubuntu-latest'

jobs:
- job: Production
  variables:
    - name: menu.id # Substituting this value in test.json
      value: 'productionValue'
  steps:
    - task: FileTransform@1
      displayName: 'File Transform:'
      inputs:
        folderPath: '$(System.DefaultWorkingDirectory)'
        fileType: json
        targetFiles: test.json
    - task: PowerShell@2
      inputs:
          targetType: 'inline'
          script: |
            Get-Content -Path test.json

- job: Staging
  variables:
    - name: menu.id  # Substituting this value in test.json
      value: 'stagingValue'
  steps:
    - task: FileTransform@1
      displayName: 'File Transform:'
      inputs:
        folderPath: '$(System.DefaultWorkingDirectory)'
        fileType: json
        targetFiles: test.json
    - task: PowerShell@2
      inputs:
          targetType: 'inline'
          script: |
            Get-Content -Path test.json
</code></pre>

<h3>Custom Conditions</h3>

<p>Another thing you might want to dig into is that Azure DevOps exposes task level <a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/process/conditions?view=azure-devops&amp;tabs=classic"" rel=""nofollow noreferrer"">custom conditions</a>. You could add both transform tasks for Stage and Production to the pipeline definition and then only conditionally run the step you want. You could potentially collapse this into just one job and only build what you need to.</p>

<p>You need to decide on what that condition is. For example, you could do it based on the source branch (probably better) or just a variable that you can set at queue time. </p>
",19296,2020-01-25T09:41:39.143,"['{\n    ""menu"": {\n        ""id"": ""file"",\n        ""value"": ""File""\n    }\n}\n', ""trigger:\n- master\n\npool:\n  vmImage: 'ubuntu-latest'\n\njobs:\n- job: Production\n  variables:\n    - name: menu.id # Substituting this value in test.json\n      value: 'productionValue'\n  steps:\n    - task: FileTransform@1\n      displayName: 'File Transform:'\n      inputs:\n        folderPath: '$(System.DefaultWorkingDirectory)'\n        fileType: json\n        targetFiles: test.json\n    - task: PowerShell@2\n      inputs:\n          targetType: 'inline'\n          script: |\n            Get-Content -Path test.json\n\n- job: Staging\n  variables:\n    - name: menu.id  # Substituting this value in test.json\n      value: 'stagingValue'\n  steps:\n    - task: FileTransform@1\n      displayName: 'File Transform:'\n      inputs:\n        folderPath: '$(System.DefaultWorkingDirectory)'\n        fileType: json\n        targetFiles: test.json\n    - task: PowerShell@2\n      inputs:\n          targetType: 'inline'\n          script: |\n            Get-Content -Path test.json\n""]"
1173,10595,10594,CC BY-SA 4.0,2020-01-25T16:13:38.317,"<p>As usual I think I came up with the answers shortly after spelling out the problem carefully here. I would be great if someone could confirm that my understanding is correct.</p>

<hr>

<h2>TL;DR: It's not possible to use <code>--build-arg</code> for <code>FROM</code> images</h2>

<p>The <code>FROM</code> command basically tells docker what binary image to start from. The <code>FROM</code> image is not built recursively. This obviously means that <code>--build-arg</code> won't be taken into account in the <code>FROM</code> image.</p>

<h2>So why is <code>uid</code> and <code>gid</code> even <code>ARG</code>s in the first place if I can't use them?</h2>

<p>It <em>is</em> possible to use them in a reasonable straight forward way. <code>docker build</code> accepts git repo URLs when building, so you can indeed kick off a Jenkins docker with custom <code>uid</code> and <code>gid</code> quite easily as follows:</p>

<pre><code>docker build -t my-jenkins --build-arg uid=1003 --build-arg gid=1003 https://github.com/jenkinsci/docker.git
docker run -it -p 8080:8080 --rm my-jenkins
</code></pre>

<h2>But I need to create my own <code>Dockerfile</code> :-(</h2>

<p>If you really need to custobmize the Jenkins image <em>and</em> need a custom uid / gid, the best way forward is to change the uid / gid of the Jenkins user in your Dockerfile. The uid = 1000 and gid = 1000 is already hardwired when your part of the Dockerfile kicks in.</p>
",19317,2020-01-25T16:13:38.317,['docker build -t my-jenkins --build-arg uid=1003 --build-arg gid=1003 https://github.com/jenkinsci/docker.git\ndocker run -it -p 8080:8080 --rm my-jenkins\n']
1174,10596,10588,CC BY-SA 4.0,2020-01-25T18:22:11.973,"<p>This is how I managed to test your scenario manually against the <code>php:7.0-apache</code> docker image. Note that this image is based on <code>debian:stretch</code>. In your question, you are following the install guide for ubuntu which will fail anyway in debian stretch.</p>

<p>I'm using the correct scenario below. See the <a href=""https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html#installing-ansible-on-debian"" rel=""nofollow noreferrer"">ansible install documentation</a> for more details. I also kept the install of sudo which was in your initial provisioning script.</p>

<pre><code>apt-get update
apt-get install -y gnupg sudo
apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 93C4A3FD7BB9C367
echo deb http://ppa.launchpad.net/ansible/ansible/ubuntu trusty main &gt;&gt; /etc/apt/sources.list
apt-get update
apt-get install -y ansible
apt-get clean
</code></pre>

<p>After playing this, result:</p>

<pre><code>root@18ab6da8ac92:/var/www/html# ansible --version              
ansible 2.9.4
  config file = /etc/ansible/ansible.cfg
  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python2.7/dist-packages/ansible
  executable location = /usr/bin/ansible
  python version = 2.7.13 (default, Sep 26 2018, 18:42:22) [GCC 6.3.0 20170516]
</code></pre>

<p>Now, the above is installing ansible from deb packages that will run in python 2.7 that has been obsoleted. I much rather prefer the following scenario using pip that will install ansible as well but in python3 and does not need to add a supplementary apt repo neither requires to install gnupg</p>

<pre><code>apt-get update
apt-get install -y python3-pip
pip3 install --upgrade pip
pip install ansible
apt-get clean
</code></pre>

<p>And the result</p>

<pre><code>root@e6b73a5f1d59:/var/www/html# ansible --version
ansible 2.9.4
  config file = None
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/local/lib/python3.5/dist-packages/ansible
  executable location = /usr/local/bin/ansible
  python version = 3.5.3 (default, Sep 27 2018, 17:25:39) [GCC 6.3.0 20170516]
</code></pre>
",13111,2020-01-26T20:48:52.357,"['apt-get update\napt-get install -y gnupg sudo\napt-key adv --keyserver keyserver.ubuntu.com --recv-keys 93C4A3FD7BB9C367\necho deb http://ppa.launchpad.net/ansible/ansible/ubuntu trusty main >> /etc/apt/sources.list\napt-get update\napt-get install -y ansible\napt-get clean\n', ""root@18ab6da8ac92:/var/www/html# ansible --version              \nansible 2.9.4\n  config file = /etc/ansible/ansible.cfg\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/lib/python2.7/dist-packages/ansible\n  executable location = /usr/bin/ansible\n  python version = 2.7.13 (default, Sep 26 2018, 18:42:22) [GCC 6.3.0 20170516]\n"", 'apt-get update\napt-get install -y python3-pip\npip3 install --upgrade pip\npip install ansible\napt-get clean\n', ""root@e6b73a5f1d59:/var/www/html# ansible --version\nansible 2.9.4\n  config file = None\n  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/local/lib/python3.5/dist-packages/ansible\n  executable location = /usr/local/bin/ansible\n  python version = 3.5.3 (default, Sep 27 2018, 17:25:39) [GCC 6.3.0 20170516]\n""]"
1175,10607,10580,CC BY-SA 4.0,2020-01-27T06:12:31.150,"<p><a href=""https://github.com/Plykiya/Docker-Nginx-PHP-MySQL-PHPMyAdmin-Gitlab/blob/master/README.md"" rel=""nofollow noreferrer"">Answered my own question, documented my steps on my Github repo.</a></p>

<p>Recap:</p>

<p>Add Nginx config to desired domains:</p>

<pre><code>location ~ /.well-known/acme-challenge {
        allow all;
        try_files $uri $uri/ /index.php;
    }
</code></pre>

<p>Use certbot staging to try out test certificates before running the real deal.</p>

<pre><code>sudo docker run -it --rm -v /some/place/to/save/letsencrypt:/etc/letsencrypt -v /some/place/to/save/lib:/var/lib/letsencrypt -v /some/place/to/have/html:/data/letsencrypt certbot/certbot certonly --webroot --register-unsafely-without-email --agree-tos --webroot-path=/data/letsencrypt --staging -d example.com
</code></pre>

<p>Run the real thing once ready</p>

<pre><code>sudo docker run -it --rm --v /some/place/to/save/letsencrypt:/etc/letsencrypt -v /some/place/to/save/lib:/var/lib/letsencrypt -v /some/place/to/have/html:/data/letsencrypt certbot/certbot certonly --webroot --email someemail@account.com
</code></pre>

<p>And then add in Nginx configs redirecting from http to https with ssl cert locations, updating nginx in docker-compose.yml to have access to certs. Go a tiny bit more in-depth about it in my repo</p>
",19290,2020-01-27T06:12:31.150,"['location ~ /.well-known/acme-challenge {\n        allow all;\n        try_files $uri $uri/ /index.php;\n    }\n', 'sudo docker run -it --rm -v /some/place/to/save/letsencrypt:/etc/letsencrypt -v /some/place/to/save/lib:/var/lib/letsencrypt -v /some/place/to/have/html:/data/letsencrypt certbot/certbot certonly --webroot --register-unsafely-without-email --agree-tos --webroot-path=/data/letsencrypt --staging -d example.com\n', 'sudo docker run -it --rm --v /some/place/to/save/letsencrypt:/etc/letsencrypt -v /some/place/to/save/lib:/var/lib/letsencrypt -v /some/place/to/have/html:/data/letsencrypt certbot/certbot certonly --webroot --email someemail@account.com\n']"
1176,10610,10609,CC BY-SA 4.0,2020-01-27T10:56:41.260,"<p>The important part of the blog post you link to isn't testing the syntax of the YAML file; it's testing the semantics of the Prometheus configuration.</p>

<p>The core configuration in that post includes a fragment:</p>

<pre><code>- alert: MyAlert
  expr: avg without(instance)(up) &lt; 0.75
  for: 2m
  labels:
    severity: page
</code></pre>

<p>How do you know this is the right configuration?  If it's misconfigured then either your on-call team gets paged when the system is healthy, or it doesn't get paged when the system is down; both are bad.</p>

<p>The test setup shown in the blog post would let you test your Prometheus alerting setup, with artificial sample data (the ""bar"" instance is up for 5 minutes, then down for 5 minutes, and it's expected to page after it's been down for longer than 2 minutes), before you deploy it for real and without actually paging anyone.  That gives you some confidence your monitoring setup will do what you expect, before you deploy it for real.</p>
",17579,2020-01-27T10:56:41.260,['- alert: MyAlert\n  expr: avg without(instance)(up) < 0.75\n  for: 2m\n  labels:\n    severity: page\n']
1177,10616,10597,CC BY-SA 4.0,2020-01-28T00:05:48.443,"<p>Following you comment: no I cannot reproduce your problem. Since you did not provide the rest of your files (inventory, etc...) and I cannot guess where is your problem, here is a quick proof by example using the <code>php:7.0-apache</code> image.</p>

<ul>
<li>The inventory (<code>inventories/docker_test/hosts.yml</code>)</li>
</ul>

<pre><code>---
all:
  hosts:
    docker_test:
      ansible_connection: docker
</code></pre>

<ul>
<li>Launching the test container</li>
</ul>

<pre><code>docker run -d --rm --name docker_test php:7.0-apache
</code></pre>

<ul>
<li>The test <code>playbook.yml</code></li>
</ul>

<pre><code>---
- hosts: docker_test
  gather_facts: false

  tasks:
    # Your image does not have python which is mandatory for ansible
    # Please note this is for demo only. You should get python installed
    # by extending the image through a Dockerfile and build it.
    - name: Dirty low-level command to get python installed
      raw: apt-get update &amp;&amp; apt-get install -y python3

    - name: Gather facts now we can
      setup:

    - name: Copy a dummy file
      copy:
        dest: /etc/apache2/sites-available/dummy.conf
        content: ""# I'm a dummy file""
</code></pre>

<ul>
<li>Playbook run and output</li>
</ul>

<pre><code>$ ansible-playbook -i inventories/docker_test/ playbook.yml 

PLAY [docker_test] ********************************************************************************************************************************************************************************************************

TASK [Dirty low-level command to get python installed] ********************************************************************************************************************************************************************
changed: [docker_test]

TASK [Gather facts now we can] ********************************************************************************************************************************************************************************************
[WARNING]: Platform linux on host docker_test is using the discovered Python interpreter at /usr/bin/python3.5, but future installation of another Python interpreter could change this. See
https://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information.

ok: [docker_test]

TASK [Copy a dummy file] **************************************************************************************************************************************************************************************************
changed: [docker_test]

PLAY RECAP ****************************************************************************************************************************************************************************************************************
docker_test                : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


</code></pre>
",13111,2020-01-28T00:05:48.443,"['---\nall:\n  hosts:\n    docker_test:\n      ansible_connection: docker\n', 'docker run -d --rm --name docker_test php:7.0-apache\n', '---\n- hosts: docker_test\n  gather_facts: false\n\n  tasks:\n    # Your image does not have python which is mandatory for ansible\n    # Please note this is for demo only. You should get python installed\n    # by extending the image through a Dockerfile and build it.\n    - name: Dirty low-level command to get python installed\n      raw: apt-get update && apt-get install -y python3\n\n    - name: Gather facts now we can\n      setup:\n\n    - name: Copy a dummy file\n      copy:\n        dest: /etc/apache2/sites-available/dummy.conf\n        content: ""# I\'m a dummy file""\n', '$ ansible-playbook -i inventories/docker_test/ playbook.yml \n\nPLAY [docker_test] ********************************************************************************************************************************************************************************************************\n\nTASK [Dirty low-level command to get python installed] ********************************************************************************************************************************************************************\nchanged: [docker_test]\n\nTASK [Gather facts now we can] ********************************************************************************************************************************************************************************************\n[WARNING]: Platform linux on host docker_test is using the discovered Python interpreter at /usr/bin/python3.5, but future installation of another Python interpreter could change this. See\nhttps://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information.\n\nok: [docker_test]\n\nTASK [Copy a dummy file] **************************************************************************************************************************************************************************************************\nchanged: [docker_test]\n\nPLAY RECAP ****************************************************************************************************************************************************************************************************************\ndocker_test                : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n\n\n']"
1178,10629,10628,CC BY-SA 4.0,2020-01-28T21:54:15.813,"<p>While someone with knowledge about the innards of GitLab may have known what the error pointed to, it took me some time and bisecting my revision history to find the root cause.</p>

<p>I had introduced a Jinja2 conditional like this in the inlined YAML for LDAP servers:</p>

<pre><code>gitlab_rails['ldap_servers'] = YAML.load &lt;&lt;-EOS # remember to close this block with 'EOS' below
main: # 'main' is the GitLab 'provider ID' of this LDAP server
  somekey: somevalue
  {% if some_variable is defined %}
  key: value
  {% endif %}
EOS
</code></pre>

<p>The <code># remember to close this block with 'EOS' below</code> remark isn't the only caveat you have to worry about here. Indentation is too, as I found out.</p>

<p>Provided the condition became true, the about would have evaluated to:</p>

<pre><code>gitlab_rails['ldap_servers'] = YAML.load &lt;&lt;-EOS # remember to close this block with 'EOS' below
main: # 'main' is the GitLab 'provider ID' of this LDAP server
  somekey: somevalue
    key: value
  EOS
</code></pre>

<p>... where the additional indentation tripped up the YAML parser and caused the unspecific error symptoms (and message).</p>

<p>Hope this helps someone else to avoid a lengthy analysis of the cause, if they run into a similar condition.</p>
",10715,2020-01-31T08:02:27.987,"[""gitlab_rails['ldap_servers'] = YAML.load <<-EOS # remember to close this block with 'EOS' below\nmain: # 'main' is the GitLab 'provider ID' of this LDAP server\n  somekey: somevalue\n  {% if some_variable is defined %}\n  key: value\n  {% endif %}\nEOS\n"", ""gitlab_rails['ldap_servers'] = YAML.load <<-EOS # remember to close this block with 'EOS' below\nmain: # 'main' is the GitLab 'provider ID' of this LDAP server\n  somekey: somevalue\n    key: value\n  EOS\n""]"
1179,10630,6085,CC BY-SA 4.0,2020-01-28T23:14:39.020,"<p>For Windows you could use <code>curl</code> in a powershell prompt:</p>
<pre><code>curl  ${BUILD_URL}\consoleText -OutFile C:\SomeLocation\SomeFile.txt
</code></pre>
<p>For MacOS:</p>
<pre><code>curl  ${BUILD_URL}/consoleText -o /SomeLocation/SomeFile.txt
</code></pre>
",19369,2021-01-05T19:29:13.623,"['curl  ${BUILD_URL}\\consoleText -OutFile C:\\SomeLocation\\SomeFile.txt\n', 'curl  ${BUILD_URL}/consoleText -o /SomeLocation/SomeFile.txt\n']"
1180,10633,9221,CC BY-SA 4.0,2020-01-29T07:34:12.173,"<p>This script can be used as a bootstrap script to register private Gitlab runner and configure runner to access AWS ECR. You can use Ubuntu 18 LTS AMI and launch AWS EC2 instance to host the Gitlab runner.</p>

<p>Attach AWS IAM role to grant EC2 instance to access AWS ECR and push-pull docker images. Also, awscli AWS configure command can be used or export AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY as environment variable.</p>

<p>Need to export GITLAB_RUNNER_TOKEN and AWS_REGION as variable to run the script successfully.</p>

<pre><code>#!/bin/bash
set -e
apt update -y &amp;&amp; apt install awscli make -y
curl -LJO https://gitlab-runner-downloads.s3.amazonaws.com/latest/deb/gitlab-runner_amd64.deb
dpkg -i gitlab-runner_amd64.deb
sed -i -e '/volumes/s/\[""\/cache\""]/\[""\/cache"",""\/var\/run\/docker.sock:\/var\/run\/docker.sock""]/' /etc/gitlab-runner/config.toml
curl -fsSL https://get.docker.com -o get-docker.sh &amp;&amp; sh get-docker.sh &amp;&amp; usermod -aG docker gitlab-runner
gitlab-runner register \
  --non-interactive \
  --url ""https://gitlab.com/"" \
  --registration-token ""${GITLAB_RUNNER_TOKEN}"" \
  --executor ""docker"" \
  --docker-image ""docker:latest"" \
  --description ""gitlab-runner"" \
  --tag-list ""gitlab,runner,aws"" \
  --run-untagged=""true"" \
  --locked=""false"" \
  --access-level=""not_protected""
echo -e ""export AWS_SDK_LOAD_CONFIG=true \nexport AWS_REGION=${AWS_REGION}"" &gt;&gt; ~/.bashrc
source ~/.bashrc &amp;&amp; mkdir ~/.docker
cat &lt;&lt;EOF &gt;&gt;~/.docker/config.json
{
  ""credsStore"": ""ecr-login""
}
EOF
git clone https://github.com/awslabs/amazon-ecr-credential-helper.git
cd amazon-ecr-credential-helper/ &amp;&amp; make docker
cp bin/local/docker-credential-ecr-login /usr/local/bin/
systemctl restart docker  &amp;&amp; gitlab-runner restart
export AWS_REGION=${AWS_REGION} &amp;&amp; docker-credential-ecr-login list
</code></pre>
",19373,2020-01-29T07:34:12.173,"['#!/bin/bash\nset -e\napt update -y && apt install awscli make -y\ncurl -LJO https://gitlab-runner-downloads.s3.amazonaws.com/latest/deb/gitlab-runner_amd64.deb\ndpkg -i gitlab-runner_amd64.deb\nsed -i -e \'/volumes/s/\\[""\\/cache\\""]/\\[""\\/cache"",""\\/var\\/run\\/docker.sock:\\/var\\/run\\/docker.sock""]/\' /etc/gitlab-runner/config.toml\ncurl -fsSL https://get.docker.com -o get-docker.sh && sh get-docker.sh && usermod -aG docker gitlab-runner\ngitlab-runner register \\\n  --non-interactive \\\n  --url ""https://gitlab.com/"" \\\n  --registration-token ""${GITLAB_RUNNER_TOKEN}"" \\\n  --executor ""docker"" \\\n  --docker-image ""docker:latest"" \\\n  --description ""gitlab-runner"" \\\n  --tag-list ""gitlab,runner,aws"" \\\n  --run-untagged=""true"" \\\n  --locked=""false"" \\\n  --access-level=""not_protected""\necho -e ""export AWS_SDK_LOAD_CONFIG=true \\nexport AWS_REGION=${AWS_REGION}"" >> ~/.bashrc\nsource ~/.bashrc && mkdir ~/.docker\ncat <<EOF >>~/.docker/config.json\n{\n  ""credsStore"": ""ecr-login""\n}\nEOF\ngit clone https://github.com/awslabs/amazon-ecr-credential-helper.git\ncd amazon-ecr-credential-helper/ && make docker\ncp bin/local/docker-credential-ecr-login /usr/local/bin/\nsystemctl restart docker  && gitlab-runner restart\nexport AWS_REGION=${AWS_REGION} && docker-credential-ecr-login list\n']"
1181,10636,795,CC BY-SA 4.0,2020-01-29T15:14:35.103,"<p><strong>bitbucket-pipelines.yml</strong></p>

<pre><code>image: python:3.8.1

pipelines:
  branches:
    ""**"":
      - step:
          name: Build
          services:
            - docker
          caches:
            - docker
            - pip
          script:
            - pip install docker-compose
            - docker network create dockernet
            - docker-compose build

definitions:
  services:
    docker:
      memory: 2048
</code></pre>
",19384,2020-01-29T15:14:35.103,"['image: python:3.8.1\n\npipelines:\n  branches:\n    ""**"":\n      - step:\n          name: Build\n          services:\n            - docker\n          caches:\n            - docker\n            - pip\n          script:\n            - pip install docker-compose\n            - docker network create dockernet\n            - docker-compose build\n\ndefinitions:\n  services:\n    docker:\n      memory: 2048\n']"
1182,10638,10634,CC BY-SA 4.0,2020-01-29T19:49:44.630,"<p>Verify that you have the correct <a href=""https://jenkins.io/doc/pipeline/steps/cmakebuilder/"" rel=""nofollow noreferrer"">CMake Plugin</a> installed. Also, add parenthesis to your cmakeBuild statement in your pipeline</p>

<pre><code>pipeline {
  agent any
  stages {
    stage('build') {
      steps {
          cmakeBuild(
            installation: 'InSearchPath'
          )
      }
    }
  }
}
</code></pre>
",4328,2020-01-29T19:49:44.630,"[""pipeline {\n  agent any\n  stages {\n    stage('build') {\n      steps {\n          cmakeBuild(\n            installation: 'InSearchPath'\n          )\n      }\n    }\n  }\n}\n""]"
1183,10649,10297,CC BY-SA 4.0,2020-01-30T13:34:55.860,"<p>Gitlab Subgroups are essentially only additional path identifiers on the Gitlab server.</p>

<p>For example if you have:  </p>

<ul>
<li>Gitlab server on <code>localhost</code>   </li>
<li>Group: <code>test</code></li>
<li>Subgroup <code>subgroup1</code>  </li>
<li>Repository <code>myawesomerepo</code></li>
</ul>

<p>Then the path to your repository will be:</p>

<pre><code>http://localhost/test/subgroup1/myawesomerepo
</code></pre>

<p>And cloning the repo will be</p>

<pre><code>git clone git@localhost/test/subgroup1/myawesomerepo.git
</code></pre>

<p>So when you connect any Jenkins pipelines to the repo you will need to connect them to that full path.  </p>

<p>Any changes being done or API's added to the Git repository itself can easily be monitored automatically to do some action via Jenkins.  </p>

<p>However, since a Gitlab Subgroup is not a Git feature rather a Gitlab feature, you need to try and write you own logic to query on the full URL and to see if there were any new Subgroups/ API endpoints added.</p>
",19394,2020-01-30T13:34:55.860,"['http://localhost/test/subgroup1/myawesomerepo\n', 'git clone git@localhost/test/subgroup1/myawesomerepo.git\n']"
1184,10653,10651,CC BY-SA 4.0,2020-01-30T21:19:48.330,"<p>Ok figured it out. It was due to using <code>staging</code> like so:</p>

<pre><code>apiVersion: cert-manager.io/v1alpha2
kind: ClusterIssuer
metadata:
  name: letsencrypt-staging
  namespace: cert-manager
spec:
  acme:
    server: https://acme-staging-v02.api.letsencrypt.org/directory
    email: &lt;email&gt;
    privateKeySecretRef:
      name: letsencrypt-staging
    solvers:
      - http01:
          ingress:
            class: nginx
</code></pre>

<p>Changed it <code>prod</code> like so and that cleared up the issue:</p>

<pre><code>apiVersion: cert-manager.io/v1alpha2
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
  namespace: cert-manager
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: &lt;email&gt;
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
      - http01:
          ingress:
            class: nginx
</code></pre>

<p>Apparently that is the expected behavior when using <code>staging</code> according to <a href=""https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nginx-ingress-with-cert-manager-on-digitalocean-kubernetes"" rel=""nofollow noreferrer"">this well written and accurate tutorial</a>.</p>

<p>That being said I didn't initially think it worked. Even after a hard reload and empty cache + hard reload, HTTPS still wasn't working. Tried incognito and it worked, so closed all my browser instances, reopened, and HTTPS worked.</p>

<p>And also, <code>certificate.yaml</code> was not necessary at all.</p>
",11490,2020-01-30T21:19:48.330,"['apiVersion: cert-manager.io/v1alpha2\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-staging\n  namespace: cert-manager\nspec:\n  acme:\n    server: https://acme-staging-v02.api.letsencrypt.org/directory\n    email: <email>\n    privateKeySecretRef:\n      name: letsencrypt-staging\n    solvers:\n      - http01:\n          ingress:\n            class: nginx\n', 'apiVersion: cert-manager.io/v1alpha2\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-prod\n  namespace: cert-manager\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: <email>\n    privateKeySecretRef:\n      name: letsencrypt-prod\n    solvers:\n      - http01:\n          ingress:\n            class: nginx\n']"
1185,10657,10655,CC BY-SA 4.0,2020-01-30T22:53:08.570,"<p>Once again, come across the answer right after asking the question.</p>

<p>Needed to look at the <code>Kubectl task</code> and not the <code>Kubernetes manifest task</code>. Particularly the <a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/deploy/kubernetes?view=azure-devops#commands"" rel=""nofollow noreferrer"">Commands section</a>:</p>

<pre><code>- task: Kubernetes@1
  displayName: kubectl apply using arguments
  inputs:
    connectionType: Azure Resource Manager
    azureSubscriptionEndpoint: $(azureSubscriptionEndpoint)
    azureResourceGroup: $(azureResourceGroup)
    kubernetesCluster: $(kubernetesCluster)
    command: apply
    arguments: -f mhc-aks.yaml
</code></pre>
",11490,2020-01-30T22:53:08.570,['- task: Kubernetes@1\n  displayName: kubectl apply using arguments\n  inputs:\n    connectionType: Azure Resource Manager\n    azureSubscriptionEndpoint: $(azureSubscriptionEndpoint)\n    azureResourceGroup: $(azureResourceGroup)\n    kubernetesCluster: $(kubernetesCluster)\n    command: apply\n    arguments: -f mhc-aks.yaml\n']
1186,10660,10597,CC BY-SA 4.0,2020-01-31T08:07:31.880,"<p>Use the following source code for copy multiple files on your client machine.</p>

<pre><code>---
  - name: Copy data to the client machine
    hosts: hostname
    become_method: sudo
    become_user: root
    become: true
    tasks: 
      # Copy twice as sometimes files get skipped (mostly only one file skipped from a folder if the folder does not exist)
      - name: Copy UFO-Server 
        copy:
          src: ""source files path""
          dest: ""destination file path""
          owner: root
          group: root
          mode: 0644
          backup: yes
        ignore_errors: true
</code></pre>

<p>Note: </p>

<ol>
<li><p>If you are passing multiple paths by using variable then </p>

<p>src:  ""/root/{{ item }}""</p></li>
<li><p>If you are passing path by using a variable for different items then</p>

<p>src:  ""/root/{{ item.source_path }}"" </p></li>
</ol>
",17679,2020-01-31T08:07:31.880,"['---\n  - name: Copy data to the client machine\n    hosts: hostname\n    become_method: sudo\n    become_user: root\n    become: true\n    tasks: \n      # Copy twice as sometimes files get skipped (mostly only one file skipped from a folder if the folder does not exist)\n      - name: Copy UFO-Server \n        copy:\n          src: ""source files path""\n          dest: ""destination file path""\n          owner: root\n          group: root\n          mode: 0644\n          backup: yes\n        ignore_errors: true\n']"
1187,10667,10658,CC BY-SA 4.0,2020-01-31T20:23:08.347,"<p>You can include the arguments in the deployment yaml.  The <a href=""https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/"" rel=""nofollow noreferrer"">official docs</a> include examples and further customization.</p>

<pre><code>spec:
   containers:
     image: myimage
     name: myContainerName
     args: [""me"", ""yes"", ""https://my.url""]</code></pre>
",15792,2020-01-31T20:23:08.347,"['spec:\n   containers:\n     image: myimage\n     name: myContainerName\n     args: [""me"", ""yes"", ""https://my.url""]']"
1188,10677,10670,CC BY-SA 4.0,2020-02-01T20:08:02.213,"<blockquote>
  <p>To exclude a set of nodes when submitting a job in kubernetes.</p>
</blockquote>

<p>you should use <code>Node affinity</code> which is conceptually similar to <code>nodeSelector</code> –and will allow you to constrain which nodes your pod is eligible to be scheduled on, based on labels on the node and you should be able to use hostname.</p>

<p>On below example i run a job to 5 completions and all are started on node-01 of my cluster with node affinity defined.</p>

<p>Example : job.yaml</p>

<pre><code>apiVersion: batch/v1
kind: Job
metadata:
  creationTimestamp: null
  labels:
    run: busybox
  name: busybox
spec:
  completions: 5
  template:
    metadata:
      creationTimestamp: null
      labels:
        run: busybox
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: kubernetes.io/hostname
                operator: In
                values:
                - k8s-node01
      containers:
      - image: busybox
        name: busybox
        resources: {}
      restartPolicy: OnFailure
</code></pre>

<p>Result :</p>

<pre><code>ubuntu@k8s-master:~$ kubectl get all -o wide
NAME                READY   STATUS      RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATES
pod/busybox-2gdp6   0/1     Completed   0          3m20s   192.168.85.204   k8s-node01   &lt;none&gt;           &lt;none&gt;
pod/busybox-l654d   0/1     Completed   0          3m55s   192.168.85.201   k8s-node01   &lt;none&gt;           &lt;none&gt;
pod/busybox-n7dbr   0/1     Completed   0          3m29s   192.168.85.203   k8s-node01   &lt;none&gt;           &lt;none&gt;
pod/busybox-pfc79   0/1     Completed   0          4m11s   192.168.85.200   k8s-node01   &lt;none&gt;           &lt;none&gt;
pod/busybox-r4xln   0/1     Completed   0          3m16s   192.168.85.205   k8s-node01   &lt;none&gt;           &lt;none&gt;

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR
service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   31h   &lt;none&gt;

NAME                COMPLETIONS   DURATION   AGE     CONTAINERS   IMAGES    SELECTOR
job.batch/busybox   5/5           60s        4m11s   busybox      busybox   controller-uid=e12f136b-d828-4f7b-a49b-303499496a8a
</code></pre>

<p>I had two worker nodes on my cluster on job yaml i defined affinity to node01 only.</p>

<pre><code>$ kubectl get nodes
NAME         STATUS   ROLES    AGE   VERSION
k8s-master   Ready    master   31h   v1.17.2
k8s-node01   Ready    &lt;none&gt;   31h   v1.17.2
k8s-node02   Ready    &lt;none&gt;   31h   v1.17.2
</code></pre>
",19264,2020-02-01T20:21:55.767,"['apiVersion: batch/v1\nkind: Job\nmetadata:\n  creationTimestamp: null\n  labels:\n    run: busybox\n  name: busybox\nspec:\n  completions: 5\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        run: busybox\n    spec:\n      affinity:\n        nodeAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n            nodeSelectorTerms:\n            - matchExpressions:\n              - key: kubernetes.io/hostname\n                operator: In\n                values:\n                - k8s-node01\n      containers:\n      - image: busybox\n        name: busybox\n        resources: {}\n      restartPolicy: OnFailure\n', 'ubuntu@k8s-master:~$ kubectl get all -o wide\nNAME                READY   STATUS      RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATES\npod/busybox-2gdp6   0/1     Completed   0          3m20s   192.168.85.204   k8s-node01   <none>           <none>\npod/busybox-l654d   0/1     Completed   0          3m55s   192.168.85.201   k8s-node01   <none>           <none>\npod/busybox-n7dbr   0/1     Completed   0          3m29s   192.168.85.203   k8s-node01   <none>           <none>\npod/busybox-pfc79   0/1     Completed   0          4m11s   192.168.85.200   k8s-node01   <none>           <none>\npod/busybox-r4xln   0/1     Completed   0          3m16s   192.168.85.205   k8s-node01   <none>           <none>\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   31h   <none>\n\nNAME                COMPLETIONS   DURATION   AGE     CONTAINERS   IMAGES    SELECTOR\njob.batch/busybox   5/5           60s        4m11s   busybox      busybox   controller-uid=e12f136b-d828-4f7b-a49b-303499496a8a\n', '$ kubectl get nodes\nNAME         STATUS   ROLES    AGE   VERSION\nk8s-master   Ready    master   31h   v1.17.2\nk8s-node01   Ready    <none>   31h   v1.17.2\nk8s-node02   Ready    <none>   31h   v1.17.2\n']"
1189,10683,3444,CC BY-SA 4.0,2020-02-02T12:47:34.107,"<blockquote>
  <p>Note : It is one of the Kubernetes <strong>best practices to allow termination with grace</strong>.</p>
</blockquote>

<p>Kubernetes waits for a specified time called the termination grace period. By default, this is 30 seconds. It’s important to note that this happens in parallel to the preStop hook and the SIGTERM signal. </p>

<blockquote>
  <p>NOTE : Kubernetes does not wait for the preStop hook to finish.<strong>If your app finishes shutting down and exits before the terminationGracePeriod is done, Kubernetes moves to the next step immediately</strong>.</p>
</blockquote>

<p>If your pod usually takes longer than 30 seconds to shut down, make sure you increase the grace period. You can do that by setting the <strong><code>terminationGracePeriodSeconds</code></strong> option in the Pod YAML. </p>

<blockquote>
  <p>It’s important that your application <strong>terminate gracefully so that there is minimal impact on the end user</strong> and the time-to-recovery is as fast as possible!</p>
</blockquote>

<p>To change it to value lower or higher than default value of 30 seconds include the flag as below example.</p>

<p>Example : </p>

<pre><code>apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: nginx
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx
  terminationGracePeriodSeconds: 0
</code></pre>

<p>We can always make use of <code>kubectl explain</code> command to find supported options under spec.</p>

<p>For example : <code>kubectl explain deployment.spec.template.spec</code></p>

<pre><code>master $ kubectl explain deployment.spec.template.spec.terminationGracePeriodSeconds
KIND:     Deployment
VERSION:  apps/v1

FIELD:    terminationGracePeriodSeconds &lt;integer&gt;

DESCRIPTION:
     Optional duration in seconds the pod needs to terminate gracefully. May be
     decreased in delete request. Value must be non-negative integer. The value
     zero indicates delete immediately. If this value is nil, the default grace
     period will be used instead. The grace period is the duration in seconds
     after the processes running in the pod are sent a termination signal and
     the time when the processes are forcibly halted with a kill signal. Set
     this value longer than the expected cleanup time for your process. Defaults
     to 30 seconds.
</code></pre>
",19264,2020-02-02T12:47:34.107,"['apiVersion: v1\nkind: Pod\nmetadata:\n  creationTimestamp: null\n  labels:\n    run: nginx\n  name: nginx\nspec:\n  containers:\n  - image: nginx\n    name: nginx\n  terminationGracePeriodSeconds: 0\n', 'master $ kubectl explain deployment.spec.template.spec.terminationGracePeriodSeconds\nKIND:     Deployment\nVERSION:  apps/v1\n\nFIELD:    terminationGracePeriodSeconds <integer>\n\nDESCRIPTION:\n     Optional duration in seconds the pod needs to terminate gracefully. May be\n     decreased in delete request. Value must be non-negative integer. The value\n     zero indicates delete immediately. If this value is nil, the default grace\n     period will be used instead. The grace period is the duration in seconds\n     after the processes running in the pod are sent a termination signal and\n     the time when the processes are forcibly halted with a kill signal. Set\n     this value longer than the expected cleanup time for your process. Defaults\n     to 30 seconds.\n']"
1190,10685,10639,CC BY-SA 4.0,2020-02-02T17:10:04.923,"<p>You can try below options to debug this further. </p>

<p>First verify <code>values.yaml</code> and check the values for <code>serviceAccount</code> (default value is true ) that means the helm chart when deployed will create a service account for the deployment. When you create a pod, <strong>if you do not specify a service account, it is automatically assigned the default service account in the given namespace</strong>. </p>

<pre><code>serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name:
</code></pre>

<p>Try to deploy your helm chart with create: false and verify if it solves your issue.</p>

<p>Else remove the file <code>hello-world/templates/serviceaccount.yaml</code> and mark serviceaccount as <code>create: false</code> in <code>value.yaml</code> and pass name as default service account of your deployment try to deploy as below</p>

<p>Note I have removed the <code>serviceaccount.yaml</code> </p>

<pre><code>~/hello$ tree
.
└── hello-world
    ├── charts
    ├── Chart.yaml
    ├── templates
    │   ├── deployment.yaml
    │   ├── _helpers.tpl
    │   ├── ingress.yaml
    │   ├── NOTES.txt
    │   ├── service.yaml
    │   └── tests
    │       └── test-connection.yaml
    └── values.yaml

4 directories, 8 files
</code></pre>

<p>set create field as false under <code>values.yaml</code></p>

<pre><code>$ cat hello-world/values.yaml | grep -i serviceaccount -A 10

serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: default
</code></pre>

<p>You can fetch your list of serviceaccounts available as below</p>

<pre><code>$ kubectl get serviceaccounts
NAME      SECRETS   AGE
default   1         2d4h
</code></pre>

<p>Once deployed helm list will show the namespace used to deploy your chart and serviceaccount from the name space is used for deploeyemnt</p>

<pre><code>$ helm list
NAME                    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART               APP VERSION
hello-world-1580665905  default         1               2020-02-02 17:51:45.631330487 +0000 UTC deployed        hello-world-0.1.0   1.16.0
</code></pre>

<p>Get chart details and values post deploeyemtn as below </p>

<pre><code>$ helm show chart hello-world
apiVersion: v2
appVersion: 1.16.0
description: A Helm chart for Kubernetes
name: hello-world
type: application
version: 0.1.0

$ helm show values hello-world | grep -i serviceaccount -A 10
serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: default

podSecurityContext: {}
  # fsGroup: 2000
</code></pre>

<p>Get deployed resources as below </p>

<pre><code>$ kubectl get all -o wide
NAME                                          READY   STATUS    RESTARTS   AGE    IP               NODE         NOMINATED NODE   READINESS GATES
pod/hello-world-1580665905-84b9d4d469-xv5mx   1/1     Running   0          118s   192.168.58.215   k8s-node02   &lt;none&gt;           &lt;none&gt;

NAME                             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE    SELECTOR
service/hello-world-1580665905   ClusterIP   10.108.73.21   &lt;none&gt;        80/TCP    118s   app.kubernetes.io/instance=hello-world-1580665905,app.kubernetes.io/name=hello-world
service/kubernetes               ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP   2d4h   &lt;none&gt;

NAME                                     READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS    IMAGES         SELECTOR
deployment.apps/hello-world-1580665905   1/1     1            1           118s   hello-world   nginx:1.16.0   app.kubernetes.io/instance=hello-world-1580665905,app.kubernetes.io/name=hello-world

NAME                                                DESIRED   CURRENT   READY   AGE    CONTAINERS    IMAGES         SELECTOR
replicaset.apps/hello-world-1580665905-84b9d4d469   1         1         1       118s   hello-world   nginx:1.16.0   app.kubernetes.io/instance=hello-world-1580665905,app.kubernetes.io/name=hello-world,pod-template-hash=84b9d4d469
</code></pre>
",19264,2020-02-04T17:32:53.237,"['serviceAccount:\n  # Specifies whether a service account should be created\n  create: true\n  # Annotations to add to the service account\n  annotations: {}\n  # The name of the service account to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name:\n', '~/hello$ tree\n.\n└── hello-world\n    ├── charts\n    ├── Chart.yaml\n    ├── templates\n    │\xa0\xa0 ├── deployment.yaml\n    │\xa0\xa0 ├── _helpers.tpl\n    │\xa0\xa0 ├── ingress.yaml\n    │\xa0\xa0 ├── NOTES.txt\n    │\xa0\xa0 ├── service.yaml\n    │\xa0\xa0 └── tests\n    │\xa0\xa0     └── test-connection.yaml\n    └── values.yaml\n\n4 directories, 8 files\n', '$ cat hello-world/values.yaml | grep -i serviceaccount -A 10\n\nserviceAccount:\n  # Specifies whether a service account should be created\n  create: false\n  # Annotations to add to the service account\n  annotations: {}\n  # The name of the service account to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name: default\n', '$ kubectl get serviceaccounts\nNAME      SECRETS   AGE\ndefault   1         2d4h\n', '$ helm list\nNAME                    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART               APP VERSION\nhello-world-1580665905  default         1               2020-02-02 17:51:45.631330487 +0000 UTC deployed        hello-world-0.1.0   1.16.0\n', '$ helm show chart hello-world\napiVersion: v2\nappVersion: 1.16.0\ndescription: A Helm chart for Kubernetes\nname: hello-world\ntype: application\nversion: 0.1.0\n\n$ helm show values hello-world | grep -i serviceaccount -A 10\nserviceAccount:\n  # Specifies whether a service account should be created\n  create: false\n  # Annotations to add to the service account\n  annotations: {}\n  # The name of the service account to use.\n  # If not set and create is true, a name is generated using the fullname template\n  name: default\n\npodSecurityContext: {}\n  # fsGroup: 2000\n', '$ kubectl get all -o wide\nNAME                                          READY   STATUS    RESTARTS   AGE    IP               NODE         NOMINATED NODE   READINESS GATES\npod/hello-world-1580665905-84b9d4d469-xv5mx   1/1     Running   0          118s   192.168.58.215   k8s-node02   <none>           <none>\n\nNAME                             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE    SELECTOR\nservice/hello-world-1580665905   ClusterIP   10.108.73.21   <none>        80/TCP    118s   app.kubernetes.io/instance=hello-world-1580665905,app.kubernetes.io/name=hello-world\nservice/kubernetes               ClusterIP   10.96.0.1      <none>        443/TCP   2d4h   <none>\n\nNAME                                     READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS    IMAGES         SELECTOR\ndeployment.apps/hello-world-1580665905   1/1     1            1           118s   hello-world   nginx:1.16.0   app.kubernetes.io/instance=hello-world-1580665905,app.kubernetes.io/name=hello-world\n\nNAME                                                DESIRED   CURRENT   READY   AGE    CONTAINERS    IMAGES         SELECTOR\nreplicaset.apps/hello-world-1580665905-84b9d4d469   1         1         1       118s   hello-world   nginx:1.16.0   app.kubernetes.io/instance=hello-world-1580665905,app.kubernetes.io/name=hello-world,pod-template-hash=84b9d4d469\n']"
1191,10688,10654,CC BY-SA 4.0,2020-02-02T21:07:51.947,"<h2>User Data Persistance</h2>

<p>If I create an image with Packer or other tool, I'll include normally a userdata initialization script that would allow connecting via WinRM. This is required as the default AMI settings wouldn't allow the tooling to connect. In this scenario Packer would create the instance from an AMI with my provided userdata. </p>

<p>However, when I then take an AMI of this configured instance and try to use it as a new instance, this new image has it's own userdata. If I wanted to run the exact same command, I would need to create the userdata in this new instance. </p>

<p>Userdata isn't persisted in your AMI, it's more an instance level configuration value. </p>

<h3>Follow-Up Comments on This</h3>

<p>The goal should be to create your AMI with the tooling, for example git, and then your new instance should not even need to run that command in the first place as you've ""baked"" it into your ""golden ami"". Consider this in your approach. Also consider decoupling any installation directly from userdata and use something like AWS Simple Systems Manager Command documents to run the installation. This would decouple your installation code from your infrastructure allowing you to apply automatically as well as on demand without having to repeat your work.</p>

<h2>User Data Content</h2>

<p>The code example above has a typo in the closing tag for PowerShell. I'd try replacing this and see if that's the root issue. If there's further issues after fixing that, post a comment on this answer and I'd be glad to look further.</p>

<p>Also as far as powershell syntax consider using join path for proper path parsing. </p>

<p>For example <code>$exe = Join-Path $ENV:ProgramData 'git/git.exe</code></p>

<p>The. You can run </p>

<pre><code>&amp;$exe --config --global ....
</code></pre>

<p>I'd also recommend that you consider looking at Amazon systems manager documents. You can create a  document that initializes a setting such as get config. </p>

<p>Then you create a AWS association to this document on a tag, at that point it will run automatically anytime a new instance is created without you having to continue to maintain it. It also allows you to update the document independently of the user data, and then ensure you can run it manually as needed as well. I'm a big fan of decoupling any type of configuration scripts from the userdata and using that as a last resort.</p>

<p>One last item...</p>

<pre><code>Remove-Item C:\c -Recurse -ErrorAction Ignore
</code></pre>

<p>Highly recommend you revisit that. That's seems super easy to mess up and start deleting stuff you didn't mean to. I'd make sure you use a fully qualified path with <code>Join-Path</code> and also use the <code>-LiteralPath</code> instead of positional argument by default. If anyone created a folder c on c drive I'd reject that in a heartbeat in a code review.</p>
",12831,2020-02-14T19:57:55.483,"['&$exe --config --global ....\n', 'Remove-Item C:\\c -Recurse -ErrorAction Ignore\n']"
1192,10689,10679,CC BY-SA 4.0,2020-02-02T23:08:00.167,"<p>Q: <em>&quot;<strong>Is it possible to use Ansible to manage the order of programs?</strong>&quot;</em></p>
<p>A: Yes. It's possible. For example, the playbook below does the job</p>
<pre class=""lang-yaml prettyprint-override""><code>- hosts: HostA
  tasks:
    - include_role:
        name: startprogram

- hosts: HostB
  tasks:
    - include_role:
        name: runcommand
      when: hostvars.HostA.HostAprogram_started|default(false)

- hosts: HostC
  tasks:
    - include_role:
        name: startsecprogram
      when: hostvars.HostB.HostBcommand_passed|default(false)

- hosts: HostD,HostE
  tasks:
    - debug:
        msg: command on {{ inventory_hostname }} which requires HostC program to run
      when: hostvars.HostC.HostCprogram_started|default(false)
</code></pre>
<hr>
<p>Example of the roles for the purpose of testing</p>
<pre class=""lang-yaml prettyprint-override""><code>shell&gt; cat roles/startprogram/tasks/main.yml
- debug:
    msg: /etc/init.d/HostAprogram.sh start
- set_fact:
    HostAprogram_started: true

shell&gt; cat roles/runcommand/tasks/main.yml
- debug:
    msg: command which using host A
- set_fact:
    HostBcommand_passed: true

shell&gt; cat roles/startsecprogram/tasks/main.yml
- debug:
    msg: /etc/init.d/HostCprogram.sh start
- set_fact:
    HostCprogram_started: true
</code></pre>
<p>Example of the output</p>
<pre class=""lang-yaml prettyprint-override""><code>ok: [HostA] =&gt; {
    &quot;msg&quot;: &quot;/etc/init.d/HostAprogram.sh start&quot;
}
ok: [HostB] =&gt; {
    &quot;msg&quot;: &quot;command which using host A&quot;
}
ok: [HostC] =&gt; {
    &quot;msg&quot;: &quot;/etc/init.d/HostCprogram.sh start&quot;
}
ok: [HostD] =&gt; {
    &quot;msg&quot;: &quot;command on HostD which requires HostC program to run&quot;
}
ok: [HostE] =&gt; {
    &quot;msg&quot;: &quot;command on HostE which requires HostC program to run&quot;
}
</code></pre>
",7715,2021-03-26T08:48:24.410,"['- hosts: HostA\n  tasks:\n    - include_role:\n        name: startprogram\n\n- hosts: HostB\n  tasks:\n    - include_role:\n        name: runcommand\n      when: hostvars.HostA.HostAprogram_started|default(false)\n\n- hosts: HostC\n  tasks:\n    - include_role:\n        name: startsecprogram\n      when: hostvars.HostB.HostBcommand_passed|default(false)\n\n- hosts: HostD,HostE\n  tasks:\n    - debug:\n        msg: command on {{ inventory_hostname }} which requires HostC program to run\n      when: hostvars.HostC.HostCprogram_started|default(false)\n', 'shell> cat roles/startprogram/tasks/main.yml\n- debug:\n    msg: /etc/init.d/HostAprogram.sh start\n- set_fact:\n    HostAprogram_started: true\n\nshell> cat roles/runcommand/tasks/main.yml\n- debug:\n    msg: command which using host A\n- set_fact:\n    HostBcommand_passed: true\n\nshell> cat roles/startsecprogram/tasks/main.yml\n- debug:\n    msg: /etc/init.d/HostCprogram.sh start\n- set_fact:\n    HostCprogram_started: true\n', 'ok: [HostA] => {\n    ""msg"": ""/etc/init.d/HostAprogram.sh start""\n}\nok: [HostB] => {\n    ""msg"": ""command which using host A""\n}\nok: [HostC] => {\n    ""msg"": ""/etc/init.d/HostCprogram.sh start""\n}\nok: [HostD] => {\n    ""msg"": ""command on HostD which requires HostC program to run""\n}\nok: [HostE] => {\n    ""msg"": ""command on HostE which requires HostC program to run""\n}\n']"
1193,10694,10668,CC BY-SA 4.0,2020-02-03T15:35:21.457,"<p>Using some shell commands in cmder to parse the json and filter the results I was able to filter the results. Here is the command:</p>

<pre><code>.\sensuctl.exe dump entity --all-namespaces --format wrapped-json | jq "".metadata.name"" | grep -i &lt;filtertext&gt;
</code></pre>
",19432,2020-02-03T15:35:21.457,"['.\\sensuctl.exe dump entity --all-namespaces --format wrapped-json | jq "".metadata.name"" | grep -i <filtertext>\n']"
1194,10705,4166,CC BY-SA 4.0,2020-02-04T13:09:31.933,"<p>You can use this following command to run your performance test</p>

<pre><code>jmeter -n -t GenericPerformanceScript.jmx &gt; output.log &amp;
</code></pre>
",19488,2020-02-05T04:30:36.460,['jmeter -n -t GenericPerformanceScript.jmx > output.log &\n']
1195,10708,10707,CC BY-SA 4.0,2020-02-04T17:09:52.413,"<p>Possibly you are looking for this  <a href=""https://github.com/kubernetes/kubeadm/issues/1392"" rel=""nofollow noreferrer"">feature</a> which is closed with no action since there are ways to work around this problem.</p>

<blockquote>
  <p>kubeadm already allows to set taints for the joining node using the configuration file at join time (<strong><em>check my other <a href=""https://devops.stackexchange.com/a/10717/19264"">answer</a> for details on how to do that</em></strong>)</p>
</blockquote>

<p>One Other way to achieve this is by running join as usual but taking few extra steps as below after join</p>

<blockquote>
  <p>1) After successful join , <strong>Force Drain the new node</strong> to make sure it removes unwanted pod which might have scaled to it post join operation <code>kubectl drain &lt;node name&gt; --force</code> </p>
  
  <p>2) <strong>Drain command will auto cordon</strong> off the node. (Note : also <strong>consider special handling to remove any daemonset</strong> which might have scaled to this node after join)</p>
  
  <p>3) Now <strong>Taint the new node</strong> as needed <strong>and then uncordon</strong> it</p>
  
  <p>4) <strong>Add nodeselector plus tolerance to pods</strong> you want to be scheduled on this new node.</p>
</blockquote>

<p>Logs of above steps for reference are listed below.</p>

<p>On below example i have joined a new node-02 and assume that some pod were scaled in an existing deployment so new node got used immediately on join, so before adding we need drain action and then taint the node so going forward no scheduling can be done unless pod has tolerance to the taint added</p>

<p><strong>Nodes Before Drain or Taint</strong></p>

<pre><code>$ kubectl get all -o wide
NAME                         READY   STATUS    RESTARTS   AGE   IP               NODE                NOMINATED NODE   READINESS GATES
pod/nginx-86c57db685-8cdkx   1/1     Running   0          27s   192.168.58.120   k8s-node02-calico   &lt;none&gt;           &lt;none&gt;
pod/nginx-86c57db685-xnh6q   1/1     Running   0          65s   192.168.182.78   k8s-node01-calico   &lt;none&gt;           &lt;none&gt;

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR
service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   2d    &lt;none&gt;

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES   SELECTOR
deployment.apps/nginx   2/2     2            2           65s   nginx        nginx    app=nginx

NAME                               DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES   SELECTOR
replicaset.apps/nginx-86c57db685   2         2         2       65s   nginx        nginx    app=nginx,pod-template-hash=86c57db685
</code></pre>

<p><strong>Drain The node</strong></p>

<pre><code>$ kubectl drain k8s-node02-calico
node/k8s-node02-calico cordoned
evicting pod ""nginx-86c57db685-8cdkx""
pod/nginx-86c57db685-8cdkx evicted
node/k8s-node02-calico evicted


$ kubectl get nodes
NAME                STATUS                     ROLES    AGE   VERSION
k8s-master-calico   Ready                      master   2d    v1.17.2
k8s-node01-calico   Ready                      &lt;none&gt;   2d    v1.17.2
k8s-node02-calico   Ready,SchedulingDisabled   &lt;none&gt;   2d    v1.17.2
</code></pre>

<p><strong>Taint the new node</strong></p>

<pre><code>$ kubectl taint node k8s-node02-calico newnode=nobodyallowed:NoSchedule
node/k8s-node02-calico tainted
</code></pre>

<p><strong>Now we are good to uncordon the node, no more pods should be able to use this noe unless they add toleration to the new taint</strong>.</p>

<pre><code>$ kubectl uncordon k8s-node02-calico
node/k8s-node02-calico uncordoned


$ kubectl get nodes
NAME                STATUS   ROLES    AGE   VERSION
k8s-master-calico   Ready    master   2d    v1.17.2
k8s-node01-calico   Ready    &lt;none&gt;   2d    v1.17.2
k8s-node02-calico   Ready    &lt;none&gt;   2d    v1.17.2
</code></pre>

<p><strong>We test by scaling the deployment and nothign should be added on node02</strong></p>

<pre><code>$ kubectl scale deployment --replicas=3 nginx
deployment.apps/nginx scaled

$ kubectl get all -o wide
NAME                         READY   STATUS    RESTARTS   AGE     IP               NODE                NOMINATED NODE   READINESS GATES
pod/nginx-86c57db685-vm8ql   1/1     Running   0          3m30s   192.168.182.75   k8s-node01-calico   &lt;none&gt;           &lt;none&gt;
pod/nginx-86c57db685-xnh6q   1/1     Running   0          10m     192.168.182.78   k8s-node01-calico   &lt;none&gt;           &lt;none&gt;
pod/nginx-86c57db685-zh2sj   1/1     Running   0          8m19s   192.168.182.76   k8s-node01-calico   &lt;none&gt;           &lt;none&gt;

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR
service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   2d    &lt;none&gt;

NAME                    READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES   SELECTOR
deployment.apps/nginx   3/3     3            3           10m   nginx        nginx    app=nginx

NAME                               DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES   SELECTOR
replicaset.apps/nginx-86c57db685   3         3         3       10m   nginx        nginx    app=nginx,pod-template-hash=86c57db685
</code></pre>
",19264,2020-02-05T11:39:20.160,"['$ kubectl get all -o wide\nNAME                         READY   STATUS    RESTARTS   AGE   IP               NODE                NOMINATED NODE   READINESS GATES\npod/nginx-86c57db685-8cdkx   1/1     Running   0          27s   192.168.58.120   k8s-node02-calico   <none>           <none>\npod/nginx-86c57db685-xnh6q   1/1     Running   0          65s   192.168.182.78   k8s-node01-calico   <none>           <none>\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   2d    <none>\n\nNAME                    READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES   SELECTOR\ndeployment.apps/nginx   2/2     2            2           65s   nginx        nginx    app=nginx\n\nNAME                               DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES   SELECTOR\nreplicaset.apps/nginx-86c57db685   2         2         2       65s   nginx        nginx    app=nginx,pod-template-hash=86c57db685\n', '$ kubectl drain k8s-node02-calico\nnode/k8s-node02-calico cordoned\nevicting pod ""nginx-86c57db685-8cdkx""\npod/nginx-86c57db685-8cdkx evicted\nnode/k8s-node02-calico evicted\n\n\n$ kubectl get nodes\nNAME                STATUS                     ROLES    AGE   VERSION\nk8s-master-calico   Ready                      master   2d    v1.17.2\nk8s-node01-calico   Ready                      <none>   2d    v1.17.2\nk8s-node02-calico   Ready,SchedulingDisabled   <none>   2d    v1.17.2\n', '$ kubectl taint node k8s-node02-calico newnode=nobodyallowed:NoSchedule\nnode/k8s-node02-calico tainted\n', '$ kubectl uncordon k8s-node02-calico\nnode/k8s-node02-calico uncordoned\n\n\n$ kubectl get nodes\nNAME                STATUS   ROLES    AGE   VERSION\nk8s-master-calico   Ready    master   2d    v1.17.2\nk8s-node01-calico   Ready    <none>   2d    v1.17.2\nk8s-node02-calico   Ready    <none>   2d    v1.17.2\n', '$ kubectl scale deployment --replicas=3 nginx\ndeployment.apps/nginx scaled\n\n$ kubectl get all -o wide\nNAME                         READY   STATUS    RESTARTS   AGE     IP               NODE                NOMINATED NODE   READINESS GATES\npod/nginx-86c57db685-vm8ql   1/1     Running   0          3m30s   192.168.182.75   k8s-node01-calico   <none>           <none>\npod/nginx-86c57db685-xnh6q   1/1     Running   0          10m     192.168.182.78   k8s-node01-calico   <none>           <none>\npod/nginx-86c57db685-zh2sj   1/1     Running   0          8m19s   192.168.182.76   k8s-node01-calico   <none>           <none>\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   2d    <none>\n\nNAME                    READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES   SELECTOR\ndeployment.apps/nginx   3/3     3            3           10m   nginx        nginx    app=nginx\n\nNAME                               DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES   SELECTOR\nreplicaset.apps/nginx-86c57db685   3         3         3       10m   nginx        nginx    app=nginx,pod-template-hash=86c57db685\n']"
1196,10713,10698,CC BY-SA 4.0,2020-02-05T08:36:06.070,"<p>Thanks to arghya-sadhu's comments on stackoverflow, I've got it working:</p>

<pre><code>apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: get-pod-and-node
  labels:
    rbac.authorization.k8s.io/aggregate-to-view: ""true""
rules:
- apiGroups: [""metrics.k8s.io""]
  resources: [""pods"", ""nodes""]
  verbs: [""get"", ""watch"", ""list""]
</code></pre>

<p>(I'm aggregating to the standard 'view' role)</p>
",19466,2020-02-05T08:36:06.070,"['apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: get-pod-and-node\n  labels:\n    rbac.authorization.k8s.io/aggregate-to-view: ""true""\nrules:\n- apiGroups: [""metrics.k8s.io""]\n  resources: [""pods"", ""nodes""]\n  verbs: [""get"", ""watch"", ""list""]\n']"
1197,10717,10707,CC BY-SA 4.0,2020-02-05T09:37:27.330,"<blockquote>
  <p><strong>kubeadm already allows to set taints for the joining node using the configuration file at join time</strong>.</p>
</blockquote>

<p><strong>Steps on how to do this at node join time are as below</strong></p>

<p>Construct a <strong>Config.yaml file with taint details and bootstrap details</strong> as recived from master at kubeadm init time.</p>

<p><strong>Example config.yaml</strong> you should update values as per your cluster info on below</p>

<pre><code>apiVersion: kubeadm.k8s.io/v1beta1
kind: JoinConfiguration
discovery:
  bootstrapToken:
    apiServerEndpoint: ""&lt;control_plain_ip&gt;:6443""
    token: ""your_token""
    caCertHashes:
    - sha256:$CERT_HASH
nodeRegistration:
  taints:
  - effect: NoSchedule
    key: specialnode1.kubernetes.io/SpecialNode1
</code></pre>

<p><strong>Pass this config from node you want to join</strong> it will join with a taint set at startup.</p>

<pre><code>root@k8s-node01:# kubeadm join --config=config.yaml

[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
</code></pre>

<p><strong>Node should join the cluster and will have a taint at startup time so pods not having  tolerance will not be scheduled on this new node</strong>.</p>

<pre><code>ubuntu@k8s-master:~$ kubectl get nodes
NAME         STATUS   ROLES    AGE     VERSION
k8s-master   Ready    master   18m     v1.17.2
k8s-node01   Ready    &lt;none&gt;   8m11s   v1.17.2
</code></pre>

<p><strong>Verify the taint as below</strong></p>

<pre><code>$ kubectl describe node k8s-node01 | grep -i Taint

Taints:             specialnode1.kubernetes.io/SpecialNode1:NoSchedule
</code></pre>

<p><strong>To further test this we will create a daemon set which will run on node01 and add another node02 with new taint , daemon set should not autoscale to new node with new taint</strong>.</p>

<pre><code>ubuntu@k8s-master:~$ kubectl get nodes
NAME         STATUS   ROLES    AGE   VERSION
k8s-master   Ready    master   24m   v1.17.2
k8s-node01   Ready    &lt;none&gt;   14m   v1.17.2


ubuntu@k8s-master:~$ kubectl get all -o wide
NAME              READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATES
pod/nginx-npmz5   1/1     Running   0          50s   192.168.85.193   k8s-node01   &lt;none&gt;           &lt;none&gt;

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR
service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   24m   &lt;none&gt;

NAME                   DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS   IMAGES   SELECTOR
daemonset.apps/nginx   1         1         1       1            1           &lt;none&gt;          50s   nginx        nginx    app=nginx
</code></pre>

<p><strong>Add new Node with new config.yaml and verify the node is ready and taint is set on new node added to cluster</strong></p>

<pre><code>apiVersion: kubeadm.k8s.io/v1beta1
    kind: JoinConfiguration
    discovery:
      bootstrapToken:
        apiServerEndpoint: ""&lt;control_plain_ip&gt;:6443""
        token: ""your_token""
        caCertHashes:
        - sha256:$CERT_HASH
    nodeRegistration:
      taints:
      - effect: NoSchedule
        key: specialnode2.kubernetes.io/SpecialNode2

$ kubectl get nodes
NAME         STATUS   ROLES    AGE   VERSION
k8s-master   Ready    master   25m   v1.17.2
k8s-node01   Ready    &lt;none&gt;   15m   v1.17.2
k8s-node02   Ready    &lt;none&gt;   22s   v1.17.2
</code></pre>

<p><strong>Note the new taint on node02</strong></p>

<pre><code>$ kubectl describe node k8s-node02 | grep -i Taint
Taints:             specialnode2.kubernetes.io/SpecialNode2:NoSchedule
</code></pre>

<p><strong>Now check if daemon set has scaled to new node or not, it will not unless we remove the taint or add tolerance to daemonset</strong></p>

<pre><code>$ kubectl get all -o wide
NAME              READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATES
pod/nginx-npmz5   1/1     Running   0          3m46s   192.168.85.193   k8s-node01   &lt;none&gt;           &lt;none&gt;

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR
service/kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   27m   &lt;none&gt;

NAME                   DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE     CONTAINERS   IMAGES   SELECTOR
daemonset.apps/nginx   1         1         1       1            1           &lt;none&gt;          3m46s   nginx        nginx    app=nginx
</code></pre>

<blockquote>
  <p><strong>So we can use above steps to add  a new node to a running cluster and choose what is scheduled on it using taints</strong>.</p>
</blockquote>
",19264,2020-02-05T11:43:51.547,"['apiVersion: kubeadm.k8s.io/v1beta1\nkind: JoinConfiguration\ndiscovery:\n  bootstrapToken:\n    apiServerEndpoint: ""<control_plain_ip>:6443""\n    token: ""your_token""\n    caCertHashes:\n    - sha256:$CERT_HASH\nnodeRegistration:\n  taints:\n  - effect: NoSchedule\n    key: specialnode1.kubernetes.io/SpecialNode1\n', ""root@k8s-node01:# kubeadm join --config=config.yaml\n\n[kubelet-start] Starting the kubelet\n[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...\n\nThis node has joined the cluster:\n* Certificate signing request was sent to apiserver and a response was received.\n* The Kubelet was informed of the new secure connection details.\n\nRun 'kubectl get nodes' on the control-plane to see this node join the cluster.\n"", 'ubuntu@k8s-master:~$ kubectl get nodes\nNAME         STATUS   ROLES    AGE     VERSION\nk8s-master   Ready    master   18m     v1.17.2\nk8s-node01   Ready    <none>   8m11s   v1.17.2\n', '$ kubectl describe node k8s-node01 | grep -i Taint\n\nTaints:             specialnode1.kubernetes.io/SpecialNode1:NoSchedule\n', 'ubuntu@k8s-master:~$ kubectl get nodes\nNAME         STATUS   ROLES    AGE   VERSION\nk8s-master   Ready    master   24m   v1.17.2\nk8s-node01   Ready    <none>   14m   v1.17.2\n\n\nubuntu@k8s-master:~$ kubectl get all -o wide\nNAME              READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATES\npod/nginx-npmz5   1/1     Running   0          50s   192.168.85.193   k8s-node01   <none>           <none>\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   24m   <none>\n\nNAME                   DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE   CONTAINERS   IMAGES   SELECTOR\ndaemonset.apps/nginx   1         1         1       1            1           <none>          50s   nginx        nginx    app=nginx\n', 'apiVersion: kubeadm.k8s.io/v1beta1\n    kind: JoinConfiguration\n    discovery:\n      bootstrapToken:\n        apiServerEndpoint: ""<control_plain_ip>:6443""\n        token: ""your_token""\n        caCertHashes:\n        - sha256:$CERT_HASH\n    nodeRegistration:\n      taints:\n      - effect: NoSchedule\n        key: specialnode2.kubernetes.io/SpecialNode2\n\n$ kubectl get nodes\nNAME         STATUS   ROLES    AGE   VERSION\nk8s-master   Ready    master   25m   v1.17.2\nk8s-node01   Ready    <none>   15m   v1.17.2\nk8s-node02   Ready    <none>   22s   v1.17.2\n', '$ kubectl describe node k8s-node02 | grep -i Taint\nTaints:             specialnode2.kubernetes.io/SpecialNode2:NoSchedule\n', '$ kubectl get all -o wide\nNAME              READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATES\npod/nginx-npmz5   1/1     Running   0          3m46s   192.168.85.193   k8s-node01   <none>           <none>\n\nNAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR\nservice/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   27m   <none>\n\nNAME                   DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE     CONTAINERS   IMAGES   SELECTOR\ndaemonset.apps/nginx   1         1         1       1            1           <none>          3m46s   nginx        nginx    app=nginx\n']"
1198,10724,10659,CC BY-SA 4.0,2020-02-05T15:54:24.857,"<p>The best way is of course (like Zeitounator comments) to use a inventory var. Either you use the version number in the docker-compose task as a variable or you create a Jinja2 template docker-compose.yml.j2 and use the variable there. That's what I do.</p>

<p>Example:</p>

<pre><code>all:
  hosts:
    host1.prod:
      image: ""xyz/12""
    host2.dev:
      image: ""xyz/latest""
</code></pre>

<p>And the <code>docker-compose.yml.j2</code> contains the variable:</p>

<pre><code>version: '2.1'

services:
  myservice:
    image: ""{{ image }}""
    ...
</code></pre>
",17486,2020-02-05T15:54:24.857,"['all:\n  hosts:\n    host1.prod:\n      image: ""xyz/12""\n    host2.dev:\n      image: ""xyz/latest""\n', 'version: \'2.1\'\n\nservices:\n  myservice:\n    image: ""{{ image }}""\n    ...\n']"
1199,10727,10726,CC BY-SA 4.0,2020-02-05T22:04:12.910,"<p>It looks like your Dockerfile is attempting a <a href=""https://docs.docker.com/develop/develop-images/multistage-build/"" rel=""nofollow noreferrer"">multistage build</a>:</p>

<pre><code>FROM ubuntu:latest
...
FROM python:2.7
...
</code></pre>

<p>This is a feature that enables you to build parts of your image in a <em>separate</em> build container and then import what you need. Unless you import stuff into your end container, it will be lost in the build process; this is exactly what is happening with your <code>RUN apt-get...</code> statement. To fix it, try removing the extra stages of the build, (<code>FROM ubuntu:latest</code> and <code>FROM python:2.7</code>) and moving your commands to after <code>FROM cassandra:3.11.4</code> like so:</p>

<pre><code>FROM cassandra:3.11.4

USER root

RUN apt-get -y update \
    &amp;&amp; apt-get -y upgrade \
    &amp;&amp; apt-get install -y \
        python-pip \
        nmap \
        vim-tiny

RUN pip install --no-cache-dir cassandra-driver
...
</code></pre>

<p>I'm sorry you're having a hard time with Docker. Hopefully this helps and it starts making more sense. Good luck, friend!</p>
",19410,2020-02-05T22:28:34.410,"['FROM ubuntu:latest\n...\nFROM python:2.7\n...\n', 'FROM cassandra:3.11.4\n\nUSER root\n\nRUN apt-get -y update \\\n    && apt-get -y upgrade \\\n    && apt-get install -y \\\n        python-pip \\\n        nmap \\\n        vim-tiny\n\nRUN pip install --no-cache-dir cassandra-driver\n...\n']"
1200,10728,10712,CC BY-SA 4.0,2020-02-06T03:54:02.160,"<pre><code>data ""aws_subnet"" ""subnets"" {
  for_each = toset(var.aws_subnet_ids)
  id       = each.value
}

locals {
  cidr_blocks = [
    for subnet in data.aws_subnet.subnets :
      subnet.cidr_block
    ]

  cidr_blocks_rendered = [
    for cidr_block in local.cidr_blocks :
     {
       from_port   = 6443,
       to_port     = 6443,
       protocol    = ""tcp"",
       cidr_blocks = cidr_block
     }
  ]
}

output ""output1-1"" {
  value = local.cidr_blocks_rendered
}
</code></pre>

<p>This is what ultimately I needed.</p>
",10354,2020-02-06T03:54:02.160,"['data ""aws_subnet"" ""subnets"" {\n  for_each = toset(var.aws_subnet_ids)\n  id       = each.value\n}\n\nlocals {\n  cidr_blocks = [\n    for subnet in data.aws_subnet.subnets :\n      subnet.cidr_block\n    ]\n\n  cidr_blocks_rendered = [\n    for cidr_block in local.cidr_blocks :\n     {\n       from_port   = 6443,\n       to_port     = 6443,\n       protocol    = ""tcp"",\n       cidr_blocks = cidr_block\n     }\n  ]\n}\n\noutput ""output1-1"" {\n  value = local.cidr_blocks_rendered\n}\n']"
1201,10754,10192,CC BY-SA 4.0,2020-02-10T02:28:10.680,"<p>I can answer half of your question: If you have a set of images you're trying to investigate, the best way would be to use <code>which</code> in a new container using the image in question. This way you can quickly see if a particular image has the binaries your are looking for already on <code>PATH</code>:</p>

<pre><code>docker run --rm ubuntu:latest which zip git
# no result

docker run --rm ubuntu:latest which bash sh
/bin/bash
/bin/sh
# ^-- both bash and sh are in the image
</code></pre>

<p>I don't know of a way to discover the set of images in question, as there is no manifest of files that a registry will provide. That is, yes, an image is a set of tar files, which you can extract a set of files/directory names... however, you'd still need to pull the entire image to get this information, so it would be easier to run the <code>which</code> command above.</p>

<p>There are tools for exploring information that a registry exposes (skopeo, doocker-ls, reg, manifest-tool, etc) but none of them will do exactly what you're looking for, which is ""find a repository within a registry which contains an image that has a particular binary in it"". </p>
",19591,2020-02-10T02:28:10.680,['docker run --rm ubuntu:latest which zip git\n# no result\n\ndocker run --rm ubuntu:latest which bash sh\n/bin/bash\n/bin/sh\n# ^-- both bash and sh are in the image\n']
1202,10759,10751,CC BY-SA 4.0,2020-02-10T14:47:26.930,"<p>Going from this, your ClusterRole isn't configured to allow access to deployments, and the ClusterRole you've listed isn't properly bound to your service account. You could configure it with something like I did below as a troubleshooting measure/to make sure you're able to properly configure permissions and rule out an issue with the serviceaccount's role bindings. </p>

<pre><code>apiVersion: v1
kind: ServiceAccount
metadata:
  name: gitlab-admin
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: gitlab-admin-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: deployment-reader
subjects:
- kind: ServiceAccount
  name: gitlab-admin
  namespace: kube-system
</code></pre>

<p>A new ClusterRole</p>

<pre><code>kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: deployment-reader
rules:
- apiGroups: [""extensions"", ""apps""]
  resources: [""deployments""]
  verbs: [""get"", ""watch"", ""list""]
</code></pre>

<p>Then to check to make sure the service account can properly access the resource in the default namespace you can check with the following command</p>

<pre><code>kubectl get deployments --as system:serviceaccount:kube-system:gitlab-admin -n default
</code></pre>
",19588,2020-02-10T14:47:26.930,"['apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: gitlab-admin\n  namespace: kube-system\n---\napiVersion: rbac.authorization.k8s.io/v1beta1\nkind: ClusterRoleBinding\nmetadata:\n  name: gitlab-admin-binding\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: deployment-reader\nsubjects:\n- kind: ServiceAccount\n  name: gitlab-admin\n  namespace: kube-system\n', 'kind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: deployment-reader\nrules:\n- apiGroups: [""extensions"", ""apps""]\n  resources: [""deployments""]\n  verbs: [""get"", ""watch"", ""list""]\n', 'kubectl get deployments --as system:serviceaccount:kube-system:gitlab-admin -n default\n']"
1203,10763,10757,CC BY-SA 4.0,2020-02-10T19:24:08.633,"<p>I'm running crio 1.17.0-rc1 with kubernetes 1.17.1 on RHEL7/CENTOS7.  One thing I had to do was build crio 1.17 myself because there was no package available and I read the version should match (crio 1.17 and k8 1.17).</p>

<p>I am using systemd as the cgroup driver. I'm not sure what your issue might be, but my setup goes like this:</p>

<pre><code>cat /etc/sysconfig/kubelet
KUBELET_EXTRA_ARGS=--cgroup-driver=systemd --container-runtime-endpoint=unix:///var/run/crio/crio.sock --cloud-provider=external
</code></pre>

<p>My kubeadm init line is (I'm using an env variable to set the control plain endpoint):</p>

<pre><code>kubeadm init --pod-network-cidr=10.244.0.0/16 --control-plane-endpoint {{ lookup('env','master_lb_ip_address') }}:6443 --upload-certs &gt;&gt; $HOME/log/init-cluster.log
</code></pre>

<p>I also edited /etc/crio/crio.conf to set systemd as the cgroup manager.</p>

<pre><code>cgroup_manager = ""systemd""
</code></pre>

<p>Also make sure you are enabling the modules / sysconfig options specified on <a href=""https://kubernetes.io/docs/setup/production-environment/container-runtimes/#cri-o"" rel=""nofollow noreferrer"">this page</a>.</p>

<pre><code>modprobe overlay
modprobe br_netfilter

# Setup required sysctl params, these persist across reboots.
cat &gt; /etc/sysctl.d/99-kubernetes-cri.conf &lt;&lt;EOF
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF

sysctl --system
</code></pre>
",19609,2020-02-10T19:24:08.633,"['cat /etc/sysconfig/kubelet\nKUBELET_EXTRA_ARGS=--cgroup-driver=systemd --container-runtime-endpoint=unix:///var/run/crio/crio.sock --cloud-provider=external\n', ""kubeadm init --pod-network-cidr=10.244.0.0/16 --control-plane-endpoint {{ lookup('env','master_lb_ip_address') }}:6443 --upload-certs >> $HOME/log/init-cluster.log\n"", 'cgroup_manager = ""systemd""\n', 'modprobe overlay\nmodprobe br_netfilter\n\n# Setup required sysctl params, these persist across reboots.\ncat > /etc/sysctl.d/99-kubernetes-cri.conf <<EOF\nnet.bridge.bridge-nf-call-iptables  = 1\nnet.ipv4.ip_forward                 = 1\nnet.bridge.bridge-nf-call-ip6tables = 1\nEOF\n\nsysctl --system\n']"
1204,10765,2731,CC BY-SA 4.0,2020-02-10T20:56:11.603,"<p>If your company has nexus or a similar repository, they may already have set up nexus to pull in what you need. You could try adding your repo's host/ip in front of the relative docker hub path.</p>

<p>Examples:</p>

<pre><code>docker pull nexus.example.com:18443/nginx
docker pull nexus.example.com:18443/selenium/node-chrome
docker pull nexus.example.com:18443/postgres:9.4
</code></pre>
",19610,2020-02-10T20:56:11.603,['docker pull nexus.example.com:18443/nginx\ndocker pull nexus.example.com:18443/selenium/node-chrome\ndocker pull nexus.example.com:18443/postgres:9.4\n']
1205,10773,10695,CC BY-SA 4.0,2020-02-11T20:36:11.487,"<p>When running PowerShell as the <code>ENTRYPOINT</code> for the container PowerShell should be executed as:</p>

<pre><code>ENTRYPOINT [""pwsh"", ""-NoExit"", ""-File"", ""/app/Start-Test.ps1""]
</code></pre>

<p>The short form of each of those parameters can be used. Additionally, the <code>-NoExit</code> flag will help with debugging the issue in for your deployment. The reason the <code>-NoExit</code> flag helps is the deployment stays alive long enough for you to confirm the logs and the container health.</p>

<p>This answer along with answers from Alexey Skolyarov and John Humphreys to debug and solve my issue.</p>
",18178,2020-02-11T20:36:11.487,"['ENTRYPOINT [""pwsh"", ""-NoExit"", ""-File"", ""/app/Start-Test.ps1""]\n']"
1206,10774,10772,CC BY-SA 4.0,2020-02-11T22:38:45.850,"<p>OK, there seems to be two problems here.</p>

<hr>

<h3>SSH hanging after connection</h3>

<p>It's probably a problem on the client tty due to limitations of MinGW. In the past I've encountered that <code>ssh</code> was unable to <code>ioctl</code> the local <code>tty</code> because the lack of a control device (<code>pty</code>). I've used <a href=""https://github.com/rprichard/winpty"" rel=""nofollow noreferrer"">https://github.com/rprichard/winpty</a> at the time, but I think that newer versions of MinGW/MinGW64 (the Posix layer installed to run bash by Git) have that covered because I didn't see that problem anymore.</p>

<p>Summary:</p>

<ul>
<li>Try upgrading git in your Windows client to the latest version (best option).</li>
<li>Try using <code>GIT CMD</code> instead of <code>GIT BASH</code>.</li>
<li>If you're not using the GIT components on Windows, try invoking <code>ssh</code> from a Command window.</li>
</ul>

<hr>

<h3>SSH not using your key</h3>

<p>I suspect that this is your problem:</p>

<pre><code>
debug1: identity file C:\\Users\\alexa\\.ssh\\id_rsa type -1
</code></pre>

<p>In my PC, I get the following:</p>

<pre><code>debug1: Reading configuration data /c/Users/xxxx/.ssh/config
debug1: Reading configuration data /etc/ssh/ssh_config
debug1: Connecting to xxx [192.168.0.1] port 22.
debug1: Connection established.
debug1: identity file /c/Users/xxxx/.ssh/id_rsa type 0
</code></pre>

<p>As to why you're getting type <code>-1</code>, it <em>might</em> be a permissions problem. Make sure that all <code>C:\Users\alexa</code>, <code>C:\Users\alexa\.ssh</code> <em>and</em> <code>C:\Users\alexa\.ssh\id_rsa</code> have only permissions for <code>SYSTEM</code>, <code>alexa</code> and <code>Administrators</code>.</p>

<p>Also, please notice that you're getting double backslashes in your log (e.g. <code>C:\\Users\\alexa\\.ssh\\id_rsa</code> instead of <code>C:\Users\alexa\.ssh\id_rsa</code>). I don't get double backslashes in mine.</p>
",19627,2020-02-11T22:38:45.850,"['\ndebug1: identity file C:\\\\Users\\\\alexa\\\\.ssh\\\\id_rsa type -1\n', 'debug1: Reading configuration data /c/Users/xxxx/.ssh/config\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: Connecting to xxx [192.168.0.1] port 22.\ndebug1: Connection established.\ndebug1: identity file /c/Users/xxxx/.ssh/id_rsa type 0\n']"
1207,10779,10540,CC BY-SA 4.0,2020-02-12T09:51:19.843,"<p>Maybe it is strange solution, but I would like to provide it to you:</p>

<p>You can get actual kubeconfig file from your Kubernetes cluster or locally and change it to base64 format like in example below:</p>

<pre><code>- cat /root/.kube/config | base 64
</code></pre>

<p>Then use your base64 configuration file in pipeline:</p>

<pre><code>- echo $your_variable | base64 -d | tee /root/.kube/config
</code></pre>

<p>In such case you will be having actual kubeconfig file on runner machine.</p>

<p>In case of DNS problem - just need to specify IP address of your runner machine in /etc/resolv.conf file.</p>
",19136,2020-02-12T09:51:19.843,"['- cat /root/.kube/config | base 64\n', '- echo $your_variable | base64 -d | tee /root/.kube/config\n']"
1208,10783,10781,CC BY-SA 4.0,2020-02-12T12:47:56.393,"<blockquote>
  <p>What would be the best way to share ports among the containers? </p>
</blockquote>

<p>You don't really ""share"" ports between containers. Instead, you want to create network and attach each container to that network.  Each container gets a <strong>network alias</strong> (essentially a hostname) that you can use to hit the service. </p>

<pre><code>$ docker network create foo
$ docker run --network=foo --network-alias=mysql -p 3306:3306 my-mysql:latest
$ docker run --network=foo --network-alias=restapi -p 5000:5000 --link mysql my-restapi:latest
$ docker run --network=foo --network-alias=react -p 3000:3000 --link restapi my-reactapp:latest
</code></pre>

<p>So the <em>myrestapi</em> container can access the mysql container using the hostname <code>mysql</code> and port 3306 and your react app can hit the <em>myrestapi</em> container using the hostname <code>restapi</code>.  The containers will also be accessible from your localhost so you can hit your react app with a browser without additional setup</p>

<p>In docker-compose.yml (which I don't use a ton so someone may have a better solution), it would look something like this:</p>

<pre><code>networks: 
  foo:
services:
  mariadb:
    container_name: mysql # this works for your alias so long as you don't have another container called mysql
    image: mariadb:latest
    networks: [""foo""]
    ports:
    - 3306:3306
</code></pre>

<p>The other services would follow suit.</p>

<p>As for ""priming"" the database, that's a little trickier. If the DB has to be running, you would need to replace the docker container's entrypoint to start the server, run the mysql command to import the data, then your script would just spin forever.</p>

<p>Alternately, you could script your container start-up and after it starts, import the data that way.</p>
",17508,2020-02-12T16:48:32.093,"['$ docker network create foo\n$ docker run --network=foo --network-alias=mysql -p 3306:3306 my-mysql:latest\n$ docker run --network=foo --network-alias=restapi -p 5000:5000 --link mysql my-restapi:latest\n$ docker run --network=foo --network-alias=react -p 3000:3000 --link restapi my-reactapp:latest\n', 'networks: \n  foo:\nservices:\n  mariadb:\n    container_name: mysql # this works for your alias so long as you don\'t have another container called mysql\n    image: mariadb:latest\n    networks: [""foo""]\n    ports:\n    - 3306:3306\n']"
1209,10793,10676,CC BY-SA 4.0,2020-02-13T08:35:28.763,"<p>As @Vasiliy Shakhunov and @SheldonH have mentioned, there is no straight way to do what I asked in the question. In the end I ended up uploading the keys into AWS with its CLI like this: </p>

<pre><code>aws ec2 import-key-pair --key-name ""name_for_the_key"" --public-key-material file:///home/user/.ssh/name_for_the_key.pub
</code></pre>

<p>and then reference it like that:</p>

<pre><code>resource ""aws_instance"" ""test"" {

    ami = ""${var.ami_id}""

    ...

    key_name      = ""name_for_the_key""   

    ...

}
</code></pre>

<p><strong>Note</strong> Yes <code>file://</code> looks like the ""Windowsest"" syntax ever but you have to use it on linux too.</p>
",19440,2020-02-13T08:35:28.763,"['aws ec2 import-key-pair --key-name ""name_for_the_key"" --public-key-material file:///home/user/.ssh/name_for_the_key.pub\n', 'resource ""aws_instance"" ""test"" {\n\n    ami = ""${var.ami_id}""\n\n    ...\n\n    key_name      = ""name_for_the_key""   \n\n    ...\n\n}\n']"
1210,10795,5898,CC BY-SA 4.0,2020-02-13T09:14:01.837,"<p>There are a few options (combining the existing answers and adding option for Calico, including example ouput):</p>

<p><strong>Option 1</strong>: Run this command On the master node (also applicable when running for example microk8s on Ubuntu)</p>

<ul>
<li><strong>kubeadm config view | grep Subnet</strong></li>
</ul>

<p>example output from local 3 node cluster, master node</p>

<pre><code>podSubnet: 172.16.0.0/16
serviceSubnet: 10.96.0.0/12
</code></pre>

<p><strong>Option 2</strong>: Run this command on the master node:</p>

<ul>
<li><strong>ps -ef | grep cluster-cidr</strong></li>
</ul>

<p>example output from local machine running microk8s</p>

<pre><code>vincent   6841 27089  0 09:52 pts/7    00:00:00 grep --color=auto cluster-cidr
root      7053     1  0 feb12 ?        00:00:14 /snap/microk8s/1173/kube-proxy --kubeconfig=/var/snap/microk8s/1173/credentials/proxy.config --cluster-cidr=10.152.183.0/24 --healthz-bind-address=127.0.0.1
</code></pre>

<p><strong>Option 3</strong>: Run this command on the master node:</p>

<ul>
<li><strong>sudo grep cidr /etc/kubernetes/manifests/kube-*</strong></li>
</ul>

<p>Example output of same master node:</p>

<pre><code>/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --allocate-node-cidrs=true
/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --cluster-cidr=172.16.0.0/16
/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --node-cidr-mask-size=24
</code></pre>

<p>If you run Calico you have the option to use calicoctl:</p>

<p><a href=""https://docs.projectcalico.org/v3.5/usage/calicoctl/install"" rel=""nofollow noreferrer"">https://docs.projectcalico.org/v3.5/usage/calicoctl/install</a></p>

<p>This documentation shows how to show and also change the cidr:
<a href=""https://docs.projectcalico.org/v3.2/usage/changing-ip-pools"" rel=""nofollow noreferrer"">https://docs.projectcalico.org/v3.2/usage/changing-ip-pools</a></p>

<p><strong>Option 4</strong> (Calico): Run this command to view the cidr:</p>

<ul>
<li><strong>CALICO_KUBECONFIG=~/.kube/config DATASTORE_TYPE=kubernetes calicoctl get ippool -o wide</strong></li>
</ul>

<p>Example output for the same cluster (works from any place that has the proper kubectl config and connection to the cluster):</p>

<pre><code>NAME                  CIDR            NAT    IPIPMODE   DISABLED   SELECTOR   
default-ipv4-ippool   172.16.0.0/16   true   Always     false      all()
</code></pre>

<p>Depending on your network option, you may have other options which are hopefully documented in the respective documentation.</p>
",19664,2020-02-13T09:14:01.837,"['podSubnet: 172.16.0.0/16\nserviceSubnet: 10.96.0.0/12\n', 'vincent   6841 27089  0 09:52 pts/7    00:00:00 grep --color=auto cluster-cidr\nroot      7053     1  0 feb12 ?        00:00:14 /snap/microk8s/1173/kube-proxy --kubeconfig=/var/snap/microk8s/1173/credentials/proxy.config --cluster-cidr=10.152.183.0/24 --healthz-bind-address=127.0.0.1\n', '/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --allocate-node-cidrs=true\n/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --cluster-cidr=172.16.0.0/16\n/etc/kubernetes/manifests/kube-controller-manager.yaml:    - --node-cidr-mask-size=24\n', 'NAME                  CIDR            NAT    IPIPMODE   DISABLED   SELECTOR   \ndefault-ipv4-ippool   172.16.0.0/16   true   Always     false      all()\n']"
1211,10799,10421,CC BY-SA 4.0,2020-02-13T17:22:47.033,"<p>What we do is download and install miniconda in the first step in our (declarative) pipeline and create the environment(s) from a yaml file.</p>

<pre><code>sh '''#!/usr/bin/env bash
wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -nv -O miniconda.sh
bash miniconda.sh -b -p $WORKSPACE/miniconda
conda config --set always_yes yes --set changeps1 no
conda update -q conda

conda env create -f envs/ansible-env.yaml
'''
</code></pre>

<p>In each step we start the conda environment like so:</p>

<pre><code>sh '''#!/usr/bin/env bash
source $WORKSPACE/miniconda/etc/profile.d/conda.sh
conda activate miniconda/envs/ansible-env/

# do stuff
'''
</code></pre>
",19668,2020-02-13T17:22:47.033,"[""sh '''#!/usr/bin/env bash\nwget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -nv -O miniconda.sh\nbash miniconda.sh -b -p $WORKSPACE/miniconda\nconda config --set always_yes yes --set changeps1 no\nconda update -q conda\n\nconda env create -f envs/ansible-env.yaml\n'''\n"", ""sh '''#!/usr/bin/env bash\nsource $WORKSPACE/miniconda/etc/profile.d/conda.sh\nconda activate miniconda/envs/ansible-env/\n\n# do stuff\n'''\n""]"
1212,10804,10797,CC BY-SA 4.0,2020-02-14T15:32:03.947,"<p>Does the following work?</p>

<pre><code>docker-compose exec mariadb /usr/bin/mysql -u &lt;your_db_username&gt; --password=&lt;your_db_password&gt; &lt; your_db_backup.sql
</code></pre>

<p>Note: <code>mariadb</code> is the name of your container.</p>

<p>Edit: I realize I'm using docker-compose. So I'm not entirely sure if this would work with just a Dockerfile.</p>
",9148,2020-02-14T15:32:03.947,['docker-compose exec mariadb /usr/bin/mysql -u <your_db_username> --password=<your_db_password> < your_db_backup.sql\n']
1213,10805,10800,CC BY-SA 4.0,2020-02-14T15:48:07.700,"<p>You shouldn't need to statically link things to remove the <code>*-dev</code> packages and have everything still work. If you do, then that's a bug in the base package and the <code>-dev</code> package and should be reported upstream. So yes, you should in theory be able to, after installing your extensions and such, do the following and shrink the image significantly:</p>

<pre class=""lang-sh prettyprint-override""><code>apt-get install -y libghc-postgresql-simple &amp;&amp; apt-get remove libghc-postgresql-simple-dev
</code></pre>

<hr>

<p>There are two other things you can do to improve your image sizes:</p>

<ul>
<li>Use the <code>--no-install-recommends</code> switch for all of your <code>apt-get install</code> invocations, and explicitly list every package you depend on. Recommended dependencies are a type of optional dependency in Debian packages that are installed by default. They can often take up a <em>lot</em> of space, but you may not actually need most (or any) of them, so you can save space by not auto-installing them and only pulling in what you actually need. This can easily cut down image sizes multiple hundreds of MB.</li>
<li>Use the <code>--purge</code> option whenever removing packages. This will ensure that they leave nothing behind, instead of potentially leaving some config files and other similar stuff, which can also help cut down on your space usage.</li>
</ul>
",3930,2020-02-14T15:48:07.700,['apt-get install -y libghc-postgresql-simple && apt-get remove libghc-postgresql-simple-dev\n']
1214,10829,10819,CC BY-SA 4.0,2020-02-17T10:48:01.197,"<p>Add the following lines in <code>/var/lib/jenkins/config.xml</code> under <code>securityRealm</code> and then restart <code>jenkins</code> service to enable cache. Remove the below 4 line if you don't want to enable it.</p>

<pre><code>&lt;cache&gt;
  &lt;size&gt;500&lt;/size&gt;
  &lt;ttl&gt;3600&lt;/ttl&gt;
&lt;/cache&gt;
</code></pre>

<p>Please refer the below image</p>

<p><a href=""https://i.stack.imgur.com/UnULV.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UnULV.png"" alt=""Jenkins config file snippet""></a></p>
",18848,2020-02-17T10:54:54.570,['<cache>\n  <size>500</size>\n  <ttl>3600</ttl>\n</cache>\n']
1215,10830,9002,CC BY-SA 4.0,2020-02-17T13:50:05.847,"<p>I think my case may be related as I also tried to configure environment for both Windows and Linux. I only have to mention that I am using <code>docker-compose</code> on WSL1 (Windows Subsystem for Linux) configured following by: <a href=""https://nickjanetakis.com/blog/setting-up-docker-for-windows-and-wsl-to-work-flawlessly"" rel=""nofollow noreferrer"">this</a></p>

<p>I suggest you to try </p>

<p>My solution is (using the: <a href=""https://docs.docker.com/compose/compose-file/#long-syntax-3"" rel=""nofollow noreferrer"">long-syntax volumes definition</a> from official docs):</p>

<pre><code>version: '3.7'

services:
  web:
    build: ./DirectoryWithDockerfile
    volumes:
      - type: bind
        source: ./DirectoryIWantToMountInDockerContainer
        target: /path/where/mount/source
        volume:
          nocopy: true  # flag to disable copying of data from a container when a volume is created
    ports:
      - 8000:8000
</code></pre>

<p>I don't know why short syntax doesn't worked on Windows for me (and for you):</p>

<pre><code>   volumes:  # this doesn't work and I don't know why
     - ./DirectoryIWantToMountInDockerContainer/:/path/where/mount/source
</code></pre>

<p>My Docker version: 19.03.5</p>

<p>docker-compose version: 1.25.4</p>
",19719,2020-02-17T14:11:19.337,"[""version: '3.7'\n\nservices:\n  web:\n    build: ./DirectoryWithDockerfile\n    volumes:\n      - type: bind\n        source: ./DirectoryIWantToMountInDockerContainer\n        target: /path/where/mount/source\n        volume:\n          nocopy: true  # flag to disable copying of data from a container when a volume is created\n    ports:\n      - 8000:8000\n"", ""   volumes:  # this doesn't work and I don't know why\n     - ./DirectoryIWantToMountInDockerContainer/:/path/where/mount/source\n""]"
1216,10833,10832,CC BY-SA 4.0,2020-02-17T15:21:13.533,"<p>I don't think there's an ideal solution at all. However, there may be a preferred one, depending on circumstances.</p>

<p>There're several factors which I think one has to consider:</p>

<ul>
<li>How cheap/expensinve a dedicated instance is?</li>
<li>What are security concerns/considerations?</li>
<li>What is expected volume of data from every environment?</li>
</ul>

<p>This table can resume them :</p>

<pre><code> |    Factor \ |  Solution I  | Solution II  | Solution III |
 |____________\|______________|______________|______________|
 | Data Volume |     Low      |     High     |     High     |
 |-------------+--------------+--------------+--------------|
 |    Security |      No      |     Yes      |     Yes      |
 |-------------+--------------+--------------+--------------|
 |Instance Cost|     High     |     Low      |    Medium    |
 |_____________|______________|______________|______________|
</code></pre>

<p>Based on the analysis of one's particular circumstances a preferred solution may be selected.</p>

<p>I would love to know what others think about the subject, though</p>
",19143,2020-02-18T08:41:25.990,[' |    Factor \\ |  Solution I  | Solution II  | Solution III |\n |____________\\|______________|______________|______________|\n | Data Volume |     Low      |     High     |     High     |\n |-------------+--------------+--------------+--------------|\n |    Security |      No      |     Yes      |     Yes      |\n |-------------+--------------+--------------+--------------|\n |Instance Cost|     High     |     Low      |    Medium    |\n |_____________|______________|______________|______________|\n']
1217,10846,2191,CC BY-SA 4.0,2020-02-19T11:08:30.603,"<p>@kenorb example with <code>hudson.util.Secret</code> is good. Also answers listing all credentials are very useful (thanks @ymajoros for one-liner). </p>

<p>These do not handle secret files though where <code>secretBytes</code> are used and still an encrypted string is shown. In such case the <code>SecretBytes</code> class needs to be used. Assuming the file is UTF-8, one can do:</p>

<pre class=""lang-java prettyprint-override""><code>secret = ""{....}""
new String(com.cloudbees.plugins.credentials.SecretBytes.fromString(secret).getPlainData())
</code></pre>

<p>HTH</p>
",19764,2020-02-19T11:08:30.603,"['secret = ""{....}""\nnew String(com.cloudbees.plugins.credentials.SecretBytes.fromString(secret).getPlainData())\n']"
1218,10850,10837,CC BY-SA 4.0,2020-02-19T17:43:00.647,"<p>You can check out specific files or folders from a repo using <code>git archive</code>.  I've done this from a Jenkinsfile using a shell command like so:</p>

<pre><code>sh(""git archive --remote=${repo_url} ${ref} ${path} | tar x"")
</code></pre>

<p>You will, of course, need to set the variables <code>repo_url</code> (the url of the remote repository), <code>ref</code> (the ref/branch/commit/etc. to check out), and <code>path</code> (the path of the file or folder within the repo to check out).</p>
",4115,2020-02-19T17:43:00.647,"['sh(""git archive --remote=${repo_url} ${ref} ${path} | tar x"")\n']"
1219,10861,10860,CC BY-SA 4.0,2020-02-20T13:40:14.460,"<p>I'd go with what gitlab already offers, the <a href=""https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-advanced"" rel=""nofollow noreferrer"">only/except</a> keyword.</p>

<p>Something like:</p>

<pre><code>test:e2e:A:
  script:
    - whatever you do to test A part
  only:
   refs:
      - master
      - /^A-.*/

test:e2e:B:
  script:
    - whatever you do to test B part
  only:
   refs:
      - master
      - /^B-.*/
</code></pre>

<p>The only requirement is that work on A or B is done in branches prefixed with A- or B-.</p>

<p>the <code>refs</code> keyword accept regexes to match, more details on <a href=""https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-basic"" rel=""nofollow noreferrer"">gitlab-ci docs here</a></p>

<p>If your gitlab is pretty recent (>12.3) the rules method would be prefered and the example above for A would become:</p>

<pre><code>test:e2e:A:
  script:
    - whatever you do to test A part
  rules:
    - if: $CI_COMMIT_REF_NAME =~ /^A-.*$/
    when: always
    - if: $CI_COMMIT_REF_NAME =~ /^master$/
    when: always
</code></pre>

<p>Or with a single regex:</p>

<pre><code>test:e2e:A:
  script:
    - whatever you do to test A part
  rules:
    - if: $CI_COMMIT_REF_NAME =~ /^(A-.*|master)$/ 
    when: always
</code></pre>

<p>I didn't test those entries above, let me know if one fail</p>
",13,2020-02-20T13:40:14.460,"['test:e2e:A:\n  script:\n    - whatever you do to test A part\n  only:\n   refs:\n      - master\n      - /^A-.*/\n\ntest:e2e:B:\n  script:\n    - whatever you do to test B part\n  only:\n   refs:\n      - master\n      - /^B-.*/\n', 'test:e2e:A:\n  script:\n    - whatever you do to test A part\n  rules:\n    - if: $CI_COMMIT_REF_NAME =~ /^A-.*$/\n    when: always\n    - if: $CI_COMMIT_REF_NAME =~ /^master$/\n    when: always\n', 'test:e2e:A:\n  script:\n    - whatever you do to test A part\n  rules:\n    - if: $CI_COMMIT_REF_NAME =~ /^(A-.*|master)$/ \n    when: always\n']"
1220,10872,10871,CC BY-SA 4.0,2020-02-21T06:47:50.130,"<p>The <code>-name</code> parameter of the <code>Stop-Service</code> command is an [array strings][1]. You can pass multiple services to it.</p>

<pre><code>Stop-Service -name service1,service2,service3
</code></pre>

<p><strong>Edit</strong></p>

<pre><code>[string[]]$services = @('service1', 'service2')
Stop-Service -Name $services -NoWait
while ((Get-Service -Name $services | Where-Object { $_.status -ne 'Stopped'}).Count -ne 0)
{
    Start-Sleep -Seconds 5
}
</code></pre>
",8712,2020-02-21T09:50:10.770,"['Stop-Service -name service1,service2,service3\n', ""[string[]]$services = @('service1', 'service2')\nStop-Service -Name $services -NoWait\nwhile ((Get-Service -Name $services | Where-Object { $_.status -ne 'Stopped'}).Count -ne 0)\n{\n    Start-Sleep -Seconds 5\n}\n""]"
1221,10875,1671,CC BY-SA 4.0,2020-02-21T13:58:59.420,"<p>Windows also has a one-liner solution, just a bit uglier than the linux version. Any of the below lines will do the job:</p>

<pre><code>cmd /C ""SET GOOS=linux&amp;&amp; SET GOARCH=amd64&amp;&amp; go build main.go""
cmd /C ""SET ""GOOS=linux"" &amp;&amp; SET ""GOARCH=amd64"" &amp;&amp; go build main.go""
</code></pre>

<p>Be careful, if you just write <code>...SET GOOS=linux &amp;&amp; SET ...</code> then you will get an error message </p>

<pre><code>cmd/go: unsupported GOOS/GOARCH pair linux /amd64
</code></pre>

<p>because there will be an extra space after the value <code>linux</code>. In order to avoid this, use either the condensed form <code>linux&amp;&amp;</code> or the other version with quotation marks.</p>
",19821,2020-02-21T13:58:59.420,"['cmd /C ""SET GOOS=linux&& SET GOARCH=amd64&& go build main.go""\ncmd /C ""SET ""GOOS=linux"" && SET ""GOARCH=amd64"" && go build main.go""\n', 'cmd/go: unsupported GOOS/GOARCH pair linux /amd64\n']"
1222,10881,79,CC BY-SA 4.0,2020-02-22T19:42:05.477,"<p>You can utilize the <a href=""https://www.terraform.io/docs/providers/external/data_source.html"" rel=""nofollow noreferrer"">external data source</a> to import secrets to Terraform and encrypt the secret files with <code>gpg</code>.</p>

<p>For instance, this what a terraform file would like for creating an rds instance with password <code>foobarbaz</code></p>

<pre><code>data ""external"" ""rds"" {
  program  = [ ""cat"", "".secrets/rds.json""]
}


resource ""aws_db_instance"" ""default"" {
  allocated_storage    = 20
  storage_type         = ""gp2""
  engine               = ""mysql""
  engine_version       = ""5.7""
  instance_class       = ""db.t2.micro""
  name                 = ""mydb""
  username             = ""foo""
  password             = ""${data.external.rds.result.password}""
  parameter_group_name = ""default.mysql5.7""
}
</code></pre>

<p>You can check <a href=""http://issamben.com/how-to-encrypt-terraform-secrets/"" rel=""nofollow noreferrer"">this post</a> that explains in detail how to do this. </p>

<p><strong><a href=""http://issamben.com/how-to-encrypt-terraform-secrets/"" rel=""nofollow noreferrer"">How to encrypt terraform secrets</a></strong></p>
",19837,2020-02-22T19:42:05.477,"['data ""external"" ""rds"" {\n  program  = [ ""cat"", "".secrets/rds.json""]\n}\n\n\nresource ""aws_db_instance"" ""default"" {\n  allocated_storage    = 20\n  storage_type         = ""gp2""\n  engine               = ""mysql""\n  engine_version       = ""5.7""\n  instance_class       = ""db.t2.micro""\n  name                 = ""mydb""\n  username             = ""foo""\n  password             = ""${data.external.rds.result.password}""\n  parameter_group_name = ""default.mysql5.7""\n}\n']"
1223,10890,1551,CC BY-SA 4.0,2020-02-24T12:39:07.407,"<p>To error out the build, just add the following with your env variable in the docker-compose file.</p>

<pre><code>${ENV_VAR?Variable ENV_VAR not set}
</code></pre>

<p>example:</p>

<pre><code>image: consul:${TAG?Variable TAG not set}
</code></pre>
",19856,2020-02-24T12:39:07.407,"['${ENV_VAR?Variable ENV_VAR not set}\n', 'image: consul:${TAG?Variable TAG not set}\n']"
1224,10895,10894,CC BY-SA 4.0,2020-02-25T04:53:55.173,"<p>Robuster and more practical solution is an encrypted file. For example</p>

<pre><code>shell&gt; cat vault1.yml
my_email: admin@example.com
my_tag: tag123

shell&gt; ansible-vault encrypt vault1.yml
Encryption successful

shell&gt; cat vault1.yml
$ANSIBLE_VAULT;1.1;AES256
33376431383930313965356364356136306338383238303032363165633962636366663939373237
3433383262306631643431346236653534316331643466660a326562663633346662656233353733
63373561636432653535666437656537326635363935366261666237353136313939323535336665
3333666466656664610a633430313138393238653065623231393165383162656262646139353730
63653231363465643237666465613631646539366262656537323932346530386364353132326234
3230623232393630396361333462343862323231323733376665
</code></pre>

<p>Then the encryped file can be used in various <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable"" rel=""nofollow noreferrer"">places</a>. For example</p>

<pre><code>shell&gt; cat playbook.yml
- hosts: localhost
  tasks:
    - include_vars: vault1.yml
    - debug:
        msg: ""email: {{ my_email }} tag: {{ my_tag }}""
</code></pre>

<p>gives</p>

<pre><code>    ""msg"": ""email: admin@example.com tag: tag123""
</code></pre>

<p><strong>Including vault-encrypted variables in a task</strong></p>

<p>It's possible to limit the scope of the variables to a task. This limits the exposure of the sensitive variables and makes the solution safer. For example</p>

<pre><code>    - debug:
        msg: ""email: {{ my_vault.my_email }} tag: {{ my_vault.my_tag }}""
      vars:
        my_vault: ""{{ lookup('file', 'vault1.yml')|from_yaml }}""
</code></pre>

<p>gives the same result.</p>
",7715,2020-02-25T05:12:56.203,"['shell> cat vault1.yml\nmy_email: admin@example.com\nmy_tag: tag123\n\nshell> ansible-vault encrypt vault1.yml\nEncryption successful\n\nshell> cat vault1.yml\n$ANSIBLE_VAULT;1.1;AES256\n33376431383930313965356364356136306338383238303032363165633962636366663939373237\n3433383262306631643431346236653534316331643466660a326562663633346662656233353733\n63373561636432653535666437656537326635363935366261666237353136313939323535336665\n3333666466656664610a633430313138393238653065623231393165383162656262646139353730\n63653231363465643237666465613631646539366262656537323932346530386364353132326234\n3230623232393630396361333462343862323231323733376665\n', 'shell> cat playbook.yml\n- hosts: localhost\n  tasks:\n    - include_vars: vault1.yml\n    - debug:\n        msg: ""email: {{ my_email }} tag: {{ my_tag }}""\n', '    ""msg"": ""email: admin@example.com tag: tag123""\n', '    - debug:\n        msg: ""email: {{ my_vault.my_email }} tag: {{ my_vault.my_tag }}""\n      vars:\n        my_vault: ""{{ lookup(\'file\', \'vault1.yml\')|from_yaml }}""\n']"
1225,10902,10901,CC BY-SA 4.0,2020-02-25T16:56:38.460,"<p><code>azcopy</code> (v10) tries to use all available memory to buffer the blobs on transfer. It seems that the calculated memory size is incorrect and exceeds the pod memory limit. </p>

<p>This can be controlled with the option <code>AZCOPY_BUFFER_GB</code>, as described in the <code>azcopy env</code> output below. </p>

<blockquote>
  <p>INFO: Name: AZCOPY_BUFFER_GB</p>
  
  <p>Description: Max number of GB that AzCopy should use for buffering data between network and disk. May include decimal point, e.g. 0.5.
  The default is based on machine size.</p>
</blockquote>

<p>So for a pod limit of 2GiB, you can set the buffer a bit lower: </p>

<pre><code>export AZCOPY_BUFFER_GB=1.5
azcopy bench ...
</code></pre>
",19889,2020-02-25T16:56:38.460,['export AZCOPY_BUFFER_GB=1.5\nazcopy bench ...\n']
1226,10927,10919,CC BY-SA 4.0,2020-02-28T04:00:50.907,"<p>Generally speaking, you want to:</p>

<ul>
<li>Combine multiple <strong>related actions/files</strong> into a single layer so you don't have tons of layers.</li>
<li>Separate out unrelated actions/files which are likely to change independently. </li>
<li>Order layers such that those least likely to change occur first in the file.</li>
<li>Use multi stage builds to clean up if you have lots of garbage in your image/layers that does not need to be in the final image.</li>
</ul>

<p>If you have to make a change to anything in the docker file, everything below that point has to be redone; caching is useless at that point.  You want to avoid this.</p>

<p>So, rather than trying to combine everything into one layer or something odd like that, you should focus on understanding what is likely to change and how you can reduce the amount of layers you have to rebuild if and when that change happens.</p>

<p>The best explained example I've seen of this is <a href=""https://spring.io/blog/2018/11/08/spring-boot-in-a-container"" rel=""nofollow noreferrer"">here</a> for Spring Boot.</p>

<p>Details are below... but to summarize; they determined that a huge layer/size was the application dependencies from Maven.  They figured most app changes don't require new maven dependencies, so caching the maven dependencies in their own layer would generally make builds and image pulls faster by avoiding re-pulling dependencies.  Then when you change the application code itself, it just pulls the later/smaller layers for the app itself which is very efficient.</p>

<hr>

<h1>A Better Dockerfile</h1>

<p>A Spring Boot fat jar naturally has ""layers"" because of the way that the jar itself is packaged. If we unpack it first it will already be divided into external and internal dependencies. </p>

<h2>Dockerfile</h2>

<pre><code>FROM openjdk:8-jdk-alpine
VOLUME /tmp
ARG DEPENDENCY=target/dependency
COPY ${DEPENDENCY}/BOOT-INF/lib /app/lib
COPY ${DEPENDENCY}/META-INF /app/META-INF
COPY ${DEPENDENCY}/BOOT-INF/classes /app
ENTRYPOINT [""java"",""-cp"",""app:app/lib/*"",""hello.Application""]
</code></pre>

<p>There are now 3 layers, with all the application resources in the later 2 layers. If the application dependencies don’t change, then the first layer (from BOOT-INF/lib) will not change, so the build will be faster, and so will the startup of the container at runtime as long as the base layers are already cached.</p>

<hr>

<p>There really isn't a magic answer to this.  It really just depends on your application and its dependencies and what is likely to change in your development/deployment environment over time.</p>
",16059,2020-02-28T19:36:06.317,"['FROM openjdk:8-jdk-alpine\nVOLUME /tmp\nARG DEPENDENCY=target/dependency\nCOPY ${DEPENDENCY}/BOOT-INF/lib /app/lib\nCOPY ${DEPENDENCY}/META-INF /app/META-INF\nCOPY ${DEPENDENCY}/BOOT-INF/classes /app\nENTRYPOINT [""java"",""-cp"",""app:app/lib/*"",""hello.Application""]\n']"
1227,10935,8915,CC BY-SA 4.0,2020-02-28T15:01:31.340,"<ol>
<li><p>Yes, you are interpreting that correctly.</p></li>
<li><p>When you express your SLO as a percentage, you should express your error rate as a percentage too. So, in you example your error rate of 1 is 100%. That would make the equation:</p>

<pre><code>(100-95/100) * 1 hour * 1 = 0.05 hours = 3 minutes
</code></pre></li>
<li><p>The period in that equation is the reporting period that you have chosen for your SLO. You have not mentioned what time period you chose. The examples in the workbook are 30 days. If you use a 30 day (720 hour) period in your example, you would consume approximately 0.14% of your error budget in the 3 minutes it takes for the alert to fire:</p>

<pre><code>( 1 * 1 hour ) / 720 hours = 0.14%
</code></pre></li>
<li><p>The rates are different because they are measured over different time periods. (Note that the graph is using a logarithmic scale, so the actual error rate and the peak of the 5m measurement is 15%, not 10%.)</p>

<ul>
<li>Consider what you would measure one minute after the errors started:

<ul>
<li>The 5m measurement would see 4 minutes of no errors plus one minute of 15% errors, which gives an overall error rate of 3%.</li>
<li>The 60m measurement would see 59 minutes of no errors plus one minute of 15% errors, which is just an overall error rate of 0.25%.</li>
</ul></li>
<li>Then 5 minutes after the errors started:

<ul>
<li>The 5m measurement would see 5 minutes of 15% errors, so the overall rate would be 15%.</li>
<li>The 60m measurement would see 55 minutes of no errors plus 5 minutes of 15% errors, so the overall rate would be 1.25%. This is actually still too low to trigger the alert, so it will actually take more than 5 minutes to alert.</li>
</ul></li>
<li><p>Using the equation from before, the actual time taken to alert is 5.76 minutes:</p>

<pre><code>5.76 = (0.001/0.15) * 60 * 14.4
</code></pre></li>
</ul></li>
<li><p>Your PromQL seems to be looking at the good events instead of the bad events, as the le=""2"" selector is for the bucket counting latencies <em>less than or equal to</em> (le) 2 seconds. You may want to create a separate ""good_latency_rate1h"" recording rule for the good events, and then use something like ""(1-good_latency_rate1h) > (14.4*0.001)"" for your alerts.</p></li>
</ol>
",19952,2020-02-28T15:01:31.340,"['(100-95/100) * 1 hour * 1 = 0.05 hours = 3 minutes\n', '( 1 * 1 hour ) / 720 hours = 0.14%\n', '5.76 = (0.001/0.15) * 60 * 14.4\n']"
1228,10936,10918,CC BY-SA 4.0,2020-02-28T15:10:31.897,"<p>I've not used these plugins but I am using pipelines and pipeline libraries (<a href=""https://jenkins.io/doc/book/pipeline/shared-libraries/"" rel=""nofollow noreferrer"">https://jenkins.io/doc/book/pipeline/shared-libraries/</a>).</p>

<p>My Jenkinsfile is now dead simple basically made of an import, I define a map for project specific parameters and call the function from the import with the map : </p>

<pre><code>@Library('lib-pipeline')

def config = [""project_code"":""ProjA"",
          ""phase_code"":""prod"",
          ""build_NET"":""YES"",
          ""build_mono"":""NO"",
          ""run_tests"":""YES"",
          ""run_tests_coverage"":""YES"",
          ""p4_credential"":""MY_CREDENTIAL""
          ]

BuildWithMapConfig(config)
</code></pre>

<p>All the actual code is in a git repo where we can track changes properly.  you can set a branch in your import </p>

<pre><code>@Library('lib-pipeline@develop')
</code></pre>

<p>This coupled with the retry option in Jenkins where you can modify the Jenkinsfile just for that run makes it super easy to test variants in this pipeline.</p>

<p>Having it all in a separate library I imagine you could de-couple the groovy script in a way that makes them unit testable on their own.  You could add a pipeline to that project to run these tests and other validations too.</p>

<p>Since I've never used these plugins I'm not exactly sure this is what you are looking for, but if I had to add these functionalities in my pipeline that would be how I would do it.</p>
",1202,2020-02-28T15:10:31.897,"['@Library(\'lib-pipeline\')\n\ndef config = [""project_code"":""ProjA"",\n          ""phase_code"":""prod"",\n          ""build_NET"":""YES"",\n          ""build_mono"":""NO"",\n          ""run_tests"":""YES"",\n          ""run_tests_coverage"":""YES"",\n          ""p4_credential"":""MY_CREDENTIAL""\n          ]\n\nBuildWithMapConfig(config)\n', ""@Library('lib-pipeline@develop')\n""]"
1229,10937,9221,CC BY-SA 4.0,2020-02-28T15:17:26.267,"<p>I use this script in gitlab-ci.yml</p>

<pre><code>image: docker:19.03
services:
- docker:19.03.0-dind
before_script:
- $(aws ecr get-login --no-include-email --region eu-central-1)
</code></pre>

<p>... and provide AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY variables into Settings/CI-CD section. 
Ensure your region with images is the same where are you logging in. </p>
",12833,2020-02-28T15:17:26.267,['image: docker:19.03\nservices:\n- docker:19.03.0-dind\nbefore_script:\n- $(aws ecr get-login --no-include-email --region eu-central-1)\n']
1230,10938,10913,CC BY-SA 4.0,2020-02-28T15:18:46.407,"<p>The DevOps toolkit 2.3 book by Victor Farcic goes into some detail on this.</p>

<h1>What You Should Understand</h1>

<ul>
<li>You as a developer specify whatever requests/limits you like initially.</li>
<li>These values have no baring on reality.</li>
<li>In order to get ""real"" values, you must monitor your application's real resource usage.</li>
<li>This is best done through a monitoring tool like prometheus, instana, datadog etc.</li>
<li>E.g. in instana, I can see that I have 512MB set up for a pod's requests, 2G for its limits, but the pod only has one container currently taking 57MB.</li>
<li>But I can't just use 60MB as a value now... I need to load test my application and see how it behaves under real/stressed circumstances.</li>
<li>Then you review these values and you can adjust the requests/limits accordingly.</li>
</ul>

<h1>Determine Usage Without a Monitoring Tool</h1>

<p>You can use some kubectl commands to get these values as a one off (it's annoying at scale).  Here is an example of a different app I have running.</p>

<p>Notice that requests/limits are set to 1/4-2 CPUs and 4G-8G memory.  But the container is really using almost no CPU and 1.198G memory.  If I load tested this and those values did not move up, I would need to change them.  But I have load tested it and know that they would go up towards these realistic requests/limits, so it's okay.</p>

<pre><code>$ kubectl describe pod -n gazelle gazelle-ws-0-0-1-6d67cffcf-lvlhk

...
    Limits:
      cpu:     2
      memory:  8Gi
    Requests:
      cpu:      250m
      memory:   4Gi

$ kubectl top pod gazelle-ws-0-0-1-6d67cffcf-lvlhk -n gazelle --containers

POD                                NAME         CPU(cores)   MEMORY(bytes)   
gazelle-ws-0-0-1-6d67cffcf-lvlhk   gazelle-ws   5m           1198Mi 
</code></pre>
",16059,2020-02-28T15:18:46.407,['$ kubectl describe pod -n gazelle gazelle-ws-0-0-1-6d67cffcf-lvlhk\n\n...\n    Limits:\n      cpu:     2\n      memory:  8Gi\n    Requests:\n      cpu:      250m\n      memory:   4Gi\n\n$ kubectl top pod gazelle-ws-0-0-1-6d67cffcf-lvlhk -n gazelle --containers\n\nPOD                                NAME         CPU(cores)   MEMORY(bytes)   \ngazelle-ws-0-0-1-6d67cffcf-lvlhk   gazelle-ws   5m           1198Mi \n']
1231,10943,10941,CC BY-SA 4.0,2020-02-28T20:01:17.080,"<pre><code>label_values(kube_node_role, role)

sum(kube_pod_container_resource_requests_cpu_cores
  * on (node) group_left (role) kube_node_role{role=""$node_role""})
</code></pre>

<p>kube_node_role out of kube-state-metrics can give you a relationship to join</p>
",10354,2020-02-28T20:01:17.080,"['label_values(kube_node_role, role)\n\nsum(kube_pod_container_resource_requests_cpu_cores\n  * on (node) group_left (role) kube_node_role{role=""$node_role""})\n']"
1232,10944,10896,CC BY-SA 4.0,2020-02-28T20:53:49.137,"<p>When you download mariadb image, mysql client tool is only available inside container. It is not getting magically installed on your local - that is why you had to install mysql client app.</p>

<p>Alternative way to connect to db without installing mysql app is to use docker exec and through this get to mysql tool available on container. So you would do something like:</p>

<pre><code>docker exec -it your_maria_db_container_id mysql -h localhost -u root -p
</code></pre>

<p>Hope this helps.</p>
",19963,2020-02-29T01:13:46.117,['docker exec -it your_maria_db_container_id mysql -h localhost -u root -p\n']
1233,10946,8167,CC BY-SA 4.0,2020-02-28T22:09:28.563,"<p>I encountered the same error but with a different issue. The Service port needed a name added to it. <a href=""https://github.com/istio/istio/issues/19966"" rel=""noreferrer"">https://github.com/istio/istio/issues/19966</a>. And they need to follow the format (protocol-suffix) <a href=""https://istio.io/docs/ops/deployment/requirements/"" rel=""noreferrer"">https://istio.io/docs/ops/deployment/requirements/</a></p>

<pre><code>ports:
    - name: https # Use http or https
       protocol: TCP
       port: 8080
       targetPort: 8080
</code></pre>
",19966,2020-03-02T16:43:04.390,['ports:\n    - name: https # Use http or https\n       protocol: TCP\n       port: 8080\n       targetPort: 8080\n']
1234,10947,10912,CC BY-SA 4.0,2020-02-28T22:11:32.387,"<p>I encountered the same error. The Service port needed a name added to it. <a href=""https://github.com/istio/istio/issues/19966"" rel=""nofollow noreferrer"">https://github.com/istio/istio/issues/19966</a>. Make sure your <em>beta-optimus</em> service port has a name. </p>

<p><a href=""https://istio.io/docs/ops/deployment/requirements/"" rel=""nofollow noreferrer"">https://istio.io/docs/ops/deployment/requirements/</a></p>

<pre><code>ports:
    - name: https # Use http or https
       protocol: TCP
       port: 8080
       targetPort: 8080
</code></pre>
",19966,2020-03-02T16:42:25.910,['ports:\n    - name: https # Use http or https\n       protocol: TCP\n       port: 8080\n       targetPort: 8080\n']
1235,10950,10778,CC BY-SA 4.0,2020-02-29T05:00:45.897,"<p>While it's not clear what your trying to do (the script you have so far for the bit you are having trouble with would probably be handy), I <em>think</em> you are essentially just trying to parse your environment and manipulate the variables at the start of your script?</p>

<p>I don't see why add something like this to the first line of your script wouldn't work:</p>

<pre><code>eval $(typeset -p | grep -E 'declare -x VUE_APP_' | sed -e 's#declare -x VUE_APP_#export VUE_APP_#g')
</code></pre>

<p>But then I also don't know what shell you're running or anything else about the container, so I'm not sure..</p>
",677,2020-02-29T05:00:45.897,"[""eval $(typeset -p | grep -E 'declare -x VUE_APP_' | sed -e 's#declare -x VUE_APP_#export VUE_APP_#g')\n""]"
1236,10951,10718,CC BY-SA 4.0,2020-02-29T05:27:59.737,"<p>So there's something wild going on there with how that command is being called. It's not just being executed on each host (as one night expect) but it looks sus to me because the <code>ok</code> is from <code>10.240.22.44</code> but the contents of the variable indicates that the commands actually ran on <code>10.240.18.21</code> and <code>10.240.19.20</code>.</p>

<p>Which I can only imagine happening if you were to run the task something like this:</p>

<pre><code>- name: run command
  shell: /opt/confluent/bin/nodefirmware smm1
  loop:
    - 10.240.18.21
    - 10.240.19.20
  register: smm_output
</code></pre>

<p>I assume that's not what you're doing because the loop there is pointless, but if you were intending to run the command on each host then not looping and just using the variable would work.</p>

<p>In the likely scenario that you need to run the command on each host individually 1 at a time then you should be able to delegate the facts to those hosts and look it up in the <code>hostvars</code></p>

<p>Alternatively if the command really does need to run from that one host, registering results when looks are involved is a known PITA that <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html#registering-variables-with-a-loop"" rel=""nofollow noreferrer"" title=""Registering Variables With a Loop"">I believe the ansible docs cover what the result is</a> and it's pretty much universally going to be a pain to parse later.</p>

<p>However I suspect that there's something else going on here and this is an <a href=""https://en.wikipedia.org/wiki/XY_problem"" rel=""nofollow noreferrer"" title=""XY Problem"">XY Problem</a> type thing and you are trying to achieve something specific but are now <a href=""https://en.wiktionary.org/wiki/yak_shaving"" rel=""nofollow noreferrer"" title=""Yak Shaving"">Yak Shaving</a> other problems.</p>
",677,2020-02-29T05:27:59.737,['- name: run command\n  shell: /opt/confluent/bin/nodefirmware smm1\n  loop:\n    - 10.240.18.21\n    - 10.240.19.20\n  register: smm_output\n']
1237,10953,10897,CC BY-SA 4.0,2020-02-29T06:52:13.393,"<p>Well... you would need to know what IP address you actually want. Is it a public IP address? Is it a private subnet address? Do you only have 1 IP address? A few things you would need to figure out.</p>

<p>But, if we just assume that we want to have whatever ip address your VM thinks it's address is then:</p>

<p>Add the following to your .bashrc</p>

<pre><code>PS1=""\[$(tput setaf 33)\][\u@$(ip -4 -o addr show scope global $(ip -4 route | grep default | head -n1 | awk '{print$5}') | awk '{gsub(/\/.*/, """",$4); print $4}' | head -n 1) \w ]\[$(tput sgr0)\] \[$(tput setaf 34)\]\\$\[$(tput sgr0)\] ""
</code></pre>

<p>To throw an IP address into your prompt.</p>

<p>Now, because that's not really human friendly, let's break it down:</p>

<p>Make the prompt blue (honestly I can't remember why I always wrap with <code>\[ \]</code> I just remember someone telling me I needed to do that, so I guess see what works for you:</p>

<pre><code>\[$(tput setaf 33)\]
</code></pre>

<p>This bit you already had figured out:</p>

<pre><code>[\u@ 
</code></pre>

<p>This insanity to find the default IP address, it's a bit hard to break down without just reading through the <code>ip</code> man pages but basically we are searching for the interface marked as default then grabbing the IP address and stripping all the extra stuff out with awk/grep/head:</p>

<pre><code>$(ip -4 -o addr show scope global $(ip -4 route | grep default | head -n1 | awk '{print$5}') | awk '{gsub(/\/.*/, """",$4); print $4}' | head -n 1)
</code></pre>

<p>I tend to want to know my ${PWD}:</p>

<pre><code>\w ]
</code></pre>

<p>Reset our colour scheme just to be stafe (I've found weird stuff happens when you keep layering colours without resting:</p>

<pre><code>\[$(tput sgr0)\] 
</code></pre>

<p>Set some other colour:</p>

<pre><code>\[$(tput setaf 34)\]
</code></pre>

<p>Set the <code>$</code> or <code>#</code> prompt which is handy if you want it to be obvious if you are logged in as root:</p>

<pre><code>\\$
</code></pre>

<p>Then reset colour again:</p>

<pre><code>\[$(tput sgr0)\]
</code></pre>
",677,2020-02-29T06:52:13.393,"['PS1=""\\[$(tput setaf 33)\\][\\u@$(ip -4 -o addr show scope global $(ip -4 route | grep default | head -n1 | awk \'{print$5}\') | awk \'{gsub(/\\/.*/, """",$4); print $4}\' | head -n 1) \\w ]\\[$(tput sgr0)\\] \\[$(tput setaf 34)\\]\\\\$\\[$(tput sgr0)\\] ""\n', '\\[$(tput setaf 33)\\]\n', '[\\u@ \n', '$(ip -4 -o addr show scope global $(ip -4 route | grep default | head -n1 | awk \'{print$5}\') | awk \'{gsub(/\\/.*/, """",$4); print $4}\' | head -n 1)\n', '\\w ]\n', '\\[$(tput sgr0)\\] \n', '\\[$(tput setaf 34)\\]\n', '\\\\$\n', '\\[$(tput sgr0)\\]\n']"
1238,10960,10069,CC BY-SA 4.0,2020-03-01T07:47:11.497,"<p>If you want to create separate key pairs that are not dependent on your personal keys, the easiest way is to use a separate GPG home directory for each. For example, to create keys for ""projectB"", first create an empty directory, then tell gpg to use that dir as its home:</p>

<pre><code>mkdir projectB-gpg
gpg --homedir ./projectB-gpg --gen-key
</code></pre>

<p>That will do what you want, although you will now have the problem of distributing the private keys and passwords securely to each environment.</p>
",19952,2020-03-01T07:47:11.497,['mkdir projectB-gpg\ngpg --homedir ./projectB-gpg --gen-key\n']
1239,10976,10975,CC BY-SA 4.0,2020-03-03T07:15:33.063,"<p>There are a few ways to do this, but by far the easiest is to put your credentials (either username/password or ssh keypair) into the Jenkins built-in credentials store and then use the <a href=""https://jenkins.io/doc/pipeline/steps/ssh-agent/"" rel=""nofollow noreferrer"">sshagent</a> step in your Pipeline script:</p>

<pre><code>sshagent(credentials: ['my-credentials']) {
  sh('scp mynexus.com/my_artifact.zip ~/my_artifact.zip')
}
</code></pre>

<p>You may need to install the SSH Agent plugin to be able to use this step; I'm not sure if it's part of the default set of Pipeline plugins or not.</p>
",4115,2020-03-03T07:15:33.063,"[""sshagent(credentials: ['my-credentials']) {\n  sh('scp mynexus.com/my_artifact.zip ~/my_artifact.zip')\n}\n""]"
1240,10982,10977,CC BY-SA 4.0,2020-03-03T15:13:57.680,"<p>In Ruby you can use this function:</p>

<pre><code># return true if we are inside a docker container
def in_container?
  return File.file?('/.dockerenv')
end
</code></pre>
",16683,2020-03-03T15:13:57.680,"[""# return true if we are inside a docker container\ndef in_container?\n  return File.file?('/.dockerenv')\nend\n""]"
1241,10986,10903,CC BY-SA 4.0,2020-03-04T00:29:06.197,"<p>It sounds like your goal is to have a variable that takes a list and to validate each of the elements of that list. If that's true, then the approach would be to write an expression that returns true only if <em>all</em> of the elements are valid. For example:</p>

<pre><code>variable ""names"" {
  type = list(string)

  validation {
    condition     = can([for v in var.names : regex(""test$"", v)])
    error_message = ""All names must end with \""test\"".""
  }
}
</code></pre>

<p>The above relies on the fact that <a href=""https://www.terraform.io/docs/configuration/functions/regex.html"" rel=""nofollow noreferrer""><code>regex</code></a> will fail if the given string doesn't match the given pattern, and that the <code>for</code> expression will fail if the given expression fails for any <code>v</code>. <a href=""https://www.terraform.io/docs/configuration/functions/can.html"" rel=""nofollow noreferrer""><code>can</code></a> then captures the failure and returns <code>false</code>, making the validation fail.</p>
",2463,2020-03-04T00:29:06.197,"['variable ""names"" {\n  type = list(string)\n\n  validation {\n    condition     = can([for v in var.names : regex(""test$"", v)])\n    error_message = ""All names must end with \\""test\\"".""\n  }\n}\n']"
1242,10999,10811,CC BY-SA 4.0,2020-03-06T07:26:57.613,"<p>Define the volume in the following way </p>

<pre class=""lang-yaml prettyprint-override""><code>volumes:
  - ${local_path}:/data
</code></pre>

<p>or using docker volumes </p>

<pre class=""lang-yaml prettyprint-override""><code>version: '3.7'

volumes:
  db-data:

services:
  one:
    image: alpine
    command: sh -c 'echo one &gt;&gt; /data/db.txt &amp;&amp; cat /data/db.txt | wc -l'
    volumes:
      - db-data:/data
</code></pre>
",20020,2020-03-06T07:26:57.613,"['volumes:\n  - ${local_path}:/data\n', ""version: '3.7'\n\nvolumes:\n  db-data:\n\nservices:\n  one:\n    image: alpine\n    command: sh -c 'echo one >> /data/db.txt && cat /data/db.txt | wc -l'\n    volumes:\n      - db-data:/data\n""]"
1243,11007,10867,CC BY-SA 4.0,2020-03-06T17:42:41.857,"<pre><code>the idea is for each team member to have his/her own environment assigned, but deploy using a shared parametrized pipeline
</code></pre>

<ol>
<li>You could use definitions for the steps for each environment.</li>
</ol>

<pre class=""lang-yaml prettyprint-override""><code>definitions:
  steps:
    - step: deploy to staging1
        script:
          - echo ""Staging 1""
    - step: deploy to staging2
        script:
          - echo ""Staging 2""

</code></pre>

<ol start=""2"">
<li>Then just express each colleague branch and restrict his commits to just this branch.
For each of the branches you could call your needed definitions.</li>
</ol>

<pre class=""lang-yaml prettyprint-override""><code>branches:    #these will run on every push of the branch
    feature/john.b:
      - step:
          # call needed definition step/s
    feature/pavel.m:
          # call needed definition step/s

</code></pre>

<p>This gives u flexibility to express multiple definitions steps for one person if needed. </p>
",20101,2020-03-06T17:42:41.857,"['the idea is for each team member to have his/her own environment assigned, but deploy using a shared parametrized pipeline\n', 'definitions:\n  steps:\n    - step: deploy to staging1\n        script:\n          - echo ""Staging 1""\n    - step: deploy to staging2\n        script:\n          - echo ""Staging 2""\n\n', 'branches:    #these will run on every push of the branch\n    feature/john.b:\n      - step:\n          # call needed definition step/s\n    feature/pavel.m:\n          # call needed definition step/s\n\n']"
1244,11013,11010,CC BY-SA 4.0,2020-03-07T14:31:35.033,"<p>Just add <code>hosts</code> before every block of hosts.
I.e., under the group level, you should have <code>hosts</code> directive</p>

<p>See <a href=""https://github.com/ansible/ansible/blob/devel/examples/hosts.yaml#L8"" rel=""nofollow noreferrer"">ansible source code example</a>:</p>

<blockquote>
  <p><code>- Hosts must be specified in a group's hosts:</code></p>
</blockquote>

<p>Working inventory.yml:</p>

<pre><code>all:
  children:
    control:
      hosts:
        localhost
        127.0.0.1
    managed:
      hosts:
       localhost
</code></pre>
",20042,2020-03-07T14:31:35.033,['all:\n  children:\n    control:\n      hosts:\n        localhost\n        127.0.0.1\n    managed:\n      hosts:\n       localhost\n']
1245,11014,11010,CC BY-SA 4.0,2020-03-07T14:35:44.367,"<p>The keyword <code>hosts</code> is missing. Also colons <code>:</code> are needed after the hostnames. Fix the syntax, for example</p>
<pre class=""lang-yaml prettyprint-override""><code>all:
  children:
    control:
      hosts:
        moriarty.server.com:
        toby.server.com:
    managed:
      hosts:
        sherlock.server.com:
</code></pre>
<p>See <a href=""https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#how-to-build-your-inventory"" rel=""nofollow noreferrer"">How to build your inventory</a>.</p>
",7715,2021-01-14T10:53:40.167,['all:\n  children:\n    control:\n      hosts:\n        moriarty.server.com:\n        toby.server.com:\n    managed:\n      hosts:\n        sherlock.server.com:\n']
1246,11020,10959,CC BY-SA 4.0,2020-03-08T18:13:26.497,"<p>The easiest way I've found to properly set credentials for my local runs and remote terraform cloud runs is to use environment variables. Before running set the environment variables for </p>

<pre><code>AWS_ACCESS_KEY_ID
AWS_SECRET_KEY
AWS_DEFAULT_REGION
</code></pre>

<p>This should allow you to run in both Linux, PowerShell or even remote runs in Terraform cloud without issue.</p>

<p>I've gone between various approaches and this has provided me the easiest workflow. If you're doing this in AWS directly then of course you could use IAM instance role and avoid credentials altogether. This wouldn't allow you to keep the same workflow for local and remote though.</p>
",12831,2020-03-08T18:13:26.497,['AWS_ACCESS_KEY_ID\nAWS_SECRET_KEY\nAWS_DEFAULT_REGION\n']
1247,11035,4138,CC BY-SA 4.0,2020-03-10T00:17:30.073,"<p>The syntax is the below one:</p>

<pre><code>{% if backup_dest[0:1]  == ""/"" %}
</code></pre>

<p>=> this one tests if ""backup_dest"" first character is ""/""</p>

<pre><code>{% if variable == ""blabla"" %}
</code></pre>

<p>=> this one tests if ""variable"" equals to ""blabla""</p>

<p>Regards</p>
",20142,2020-03-10T00:17:30.073,"['{% if backup_dest[0:1]  == ""/"" %}\n', '{% if variable == ""blabla"" %}\n']"
1248,11040,11026,CC BY-SA 4.0,2020-03-10T16:05:11.540,"<p>There is <a href=""https://github.com/moby/moby/issues/37531"" rel=""nofollow noreferrer"">Docker's known issue #37531</a></p>

<p>To fix dependencies, you might try:</p>

<ol>
<li>Either upgrade <code>Docker</code> to 17.02</li>
</ol>

<pre><code>curl -sSL https://get.docker.com/ | sudo bash
</code></pre>

<ol start=""2"">
<li>or install lib inside of container.
Since your container based on Centos (<code>FROM centos</code>), so try <code>yum install</code></li>
</ol>

<pre><code>rpm -ql libXtst-devel-1.2.2-2.1.el6.x86_64
</code></pre>
",20042,2020-03-10T16:05:11.540,"['curl -sSL https://get.docker.com/ | sudo bash\n', 'rpm -ql libXtst-devel-1.2.2-2.1.el6.x86_64\n']"
1249,11053,1186,CC BY-SA 4.0,2020-03-11T20:41:43.603,"<p>This can be done using the AWS CLI:</p>

<pre><code>aws ec2 describe-volumes --query Volumes[*].VolumeId --filters Name=encrypted,Values=true
</code></pre>
",20172,2020-03-12T08:09:38.543,"['aws ec2 describe-volumes --query Volumes[*].VolumeId --filters Name=encrypted,Values=true\n']"
1250,11054,11050,CC BY-SA 4.0,2020-03-11T21:07:32.477,"<p>After resolving some syntax issues, I found the true cause of failing to throw the error.
In my prior usage I was doing this through Inspec provisioner, which handled the exit codes. </p>

<p>If you are using Pester and having to do the workaround I described above, then to ensure error's in a step are thrown you need to throw an exit code other than 0. </p>

<p>The two steps I took that seem to work fine (I like some emoji fire in my logs )</p>

<pre><code>$ErrorActionPreference = 'Stop'

try 
{
# Do code here
}
catch
{
   Write-Error "" Failed to do something important `$TestFile: $TestFile""
  exit 1  # packer will recognize failure at this point
}
</code></pre>

<p>Note that you will want to make sure your Azure DevOps Pipeline has the following settings to publish test results regardless of failing:</p>

<pre class=""lang-yaml prettyprint-override""><code># ℹ  Using Invoke-Build to call Packer. You can do this with a packer extension or any other way you prefer
- task: PowerShell@2
  displayName: Run Packer Configuration
  inputs:
      filePath: build/build.ps1
      arguments: '-Task PackerBuild -Configuration $(Configuration)'
      errorActionPreference: 'Continue'
      pwsh: true
  continueOnError: true #I want to publish the test results regardless

- task: PublishTestResults@2
  displayName: Publish Pester Tests
  inputs:
      testResultsFormat: 'NUnit'
      testResultsFiles: '**/TEST-*.xml'
  condition: succeededOrFailed()
</code></pre>
",12831,2020-03-11T21:07:32.477,"['$ErrorActionPreference = \'Stop\'\n\ntry \n{\n# Do code here\n}\ncatch\n{\n   Write-Error "" Failed to do something important `$TestFile: $TestFile""\n  exit 1  # packer will recognize failure at this point\n}\n', ""# ℹ  Using Invoke-Build to call Packer. You can do this with a packer extension or any other way you prefer\n- task: PowerShell@2\n  displayName: Run Packer Configuration\n  inputs:\n      filePath: build/build.ps1\n      arguments: '-Task PackerBuild -Configuration $(Configuration)'\n      errorActionPreference: 'Continue'\n      pwsh: true\n  continueOnError: true #I want to publish the test results regardless\n\n- task: PublishTestResults@2\n  displayName: Publish Pester Tests\n  inputs:\n      testResultsFormat: 'NUnit'\n      testResultsFiles: '**/TEST-*.xml'\n  condition: succeededOrFailed()\n""]"
1251,11057,11056,CC BY-SA 4.0,2020-03-12T07:01:56.513,"<p>Since <code>.gitlab-ci.yml</code> is a <code>Yaml</code> file, then just use it's syntax.</p>
<p>For example, you may use <code>&gt;</code>:</p>
<pre class=""lang-yaml prettyprint-override""><code>image: ubuntu
before_script:
  - 'which ssh-agent || ( apt-get update -y &amp;&amp; apt-get install openssh-client rsync git -y )'
  - mkdir -p ~/.ssh
  - chmod 700 ~/.ssh
  - echo -e &quot;$PRIVATE_KEY&quot; &gt; ~/.ssh/id_rsa
  - chmod 600 ~/.ssh/id_rsa
  - '[[ -f /.dockerenv ]] &amp;&amp; echo -e &quot;Host *\n\tStrictHostKeyChecking no\n\n&quot; &gt; ~/.ssh/config'


SSH:
  tags:
    - mytag
  script: &gt; 
  - ssh ubuntu@host &quot;which ssh-agent || 
    ( apt-get update -y &amp;&amp; apt-get install openssh-client rsync git -y ) &amp;&amp; 
    ssh ubuntu@192.168.1.2 &quot;mkdir -p /home/ubuntu/test&quot; &amp;&amp; 
    rsync /home/ubuntu/test/.gitlab-ci.yml ubuntu@192.168.1.2:/home/ubuntu/test/.gitlab-ci.yml&quot;
</code></pre>
<h1>Sample usage of <code>yaml</code> multilines</h1>
<p>There is a great resource about <code>yaml</code> multilines: <a href=""https://yaml-multiline.info/"" rel=""nofollow noreferrer"">YAML Multiline Strings</a>
Also, there is a <a href=""https://stackoverflow.com/a/21699210/5720818"">great SO answer</a> about <code>yaml</code> multilines.</p>
<p>So let's speculate about pipeline based on these materials.
Since we have specific context (script for <code>Gitlab CI</code>) then we don't need all of theese 63 cases:</p>
<pre><code>                      &gt;     |            &quot;     '     &gt;-     &gt;+     |-     |+
-------------------------|------|-----|-----|-----|------|------|------|------  
Trailing spaces   | Kept | Kept |     |     |     | Kept | Kept | Kept | Kept
Single newline =&gt; | _    | \n   | _   | _   | _   | _    |  _   | \n   | \n
Double newline =&gt; | \n   | \n\n | \n  | \n  | \n  | \n   |  \n  | \n\n | \n\n
Final newline  =&gt; | \n   | \n   |     |     |     |      |  \n  |      | \n
Final dbl nl's =&gt; |      |      |     |     |     |      | Kept |      | Kept  
In-line newlines  | No   | No   | No  | \n  | No  | No   | No   | No   | No
Spaceless newlines| No   | No   | No  | \   | No  | No   | No   | No   | No 
Single quote      | '    | '    | '   | '   | ''  | '    | '    | '    | '
Double quote      | &quot;    | &quot;    | &quot;   | \&quot;  | &quot;   | &quot;    | &quot;    | &quot;    | &quot;
Backslash         | \    | \    | \   | \\  | \   | \    | \    | \    | \
&quot; #&quot;, &quot;: &quot;        | Ok   | Ok   | No  | Ok  | Ok  | Ok   | Ok   | Ok   | Ok
Can start on same | No   | No   | Yes | Yes | Yes | No   | No   | No   | No
line as key       |
</code></pre>
<p>Assumptions are:</p>
<ul>
<li>we don't need trailing spaces at all</li>
<li>we don't need final newlines at all</li>
<li>we'll try to avoid quote escaping mess</li>
<li>Backslash is intended to combine multi-line scripts</li>
<li>almost doesn't matter how many spaces before the script</li>
</ul>
<p>P.s. I'd suggest to lint your <code>.gitlab-ci.yml</code> using GitLab UI</p>
",20042,2021-03-20T15:59:36.233,"['image: ubuntu\nbefore_script:\n  - \'which ssh-agent || ( apt-get update -y && apt-get install openssh-client rsync git -y )\'\n  - mkdir -p ~/.ssh\n  - chmod 700 ~/.ssh\n  - echo -e ""$PRIVATE_KEY"" > ~/.ssh/id_rsa\n  - chmod 600 ~/.ssh/id_rsa\n  - \'[[ -f /.dockerenv ]] && echo -e ""Host *\\n\\tStrictHostKeyChecking no\\n\\n"" > ~/.ssh/config\'\n\n\nSSH:\n  tags:\n    - mytag\n  script: > \n  - ssh ubuntu@host ""which ssh-agent || \n    ( apt-get update -y && apt-get install openssh-client rsync git -y ) && \n    ssh ubuntu@192.168.1.2 ""mkdir -p /home/ubuntu/test"" && \n    rsync /home/ubuntu/test/.gitlab-ci.yml ubuntu@192.168.1.2:/home/ubuntu/test/.gitlab-ci.yml""\n', '                      >     |            ""     \'     >-     >+     |-     |+\n-------------------------|------|-----|-----|-----|------|------|------|------  \nTrailing spaces   | Kept | Kept |     |     |     | Kept | Kept | Kept | Kept\nSingle newline => | _    | \\n   | _   | _   | _   | _    |  _   | \\n   | \\n\nDouble newline => | \\n   | \\n\\n | \\n  | \\n  | \\n  | \\n   |  \\n  | \\n\\n | \\n\\n\nFinal newline  => | \\n   | \\n   |     |     |     |      |  \\n  |      | \\n\nFinal dbl nl\'s => |      |      |     |     |     |      | Kept |      | Kept  \nIn-line newlines  | No   | No   | No  | \\n  | No  | No   | No   | No   | No\nSpaceless newlines| No   | No   | No  | \\   | No  | No   | No   | No   | No \nSingle quote      | \'    | \'    | \'   | \'   | \'\'  | \'    | \'    | \'    | \'\nDouble quote      | ""    | ""    | ""   | \\""  | ""   | ""    | ""    | ""    | ""\nBackslash         | \\    | \\    | \\   | \\\\  | \\   | \\    | \\    | \\    | \\\n"" #"", "": ""        | Ok   | Ok   | No  | Ok  | Ok  | Ok   | Ok   | Ok   | Ok\nCan start on same | No   | No   | Yes | Yes | Yes | No   | No   | No   | No\nline as key       |\n']"
1252,11059,11058,CC BY-SA 4.0,2020-03-12T10:31:26.320,"<p>Try this, to run an adhoc command with IP address</p>

<pre><code>ansible all -i 192.168.254.150, -m ping
192.168.254.150 | SUCCESS =&gt; {
    ""changed"": false, 
    ""ping"": ""pong""
}
</code></pre>

<p>From man:</p>

<blockquote>
  <p>-i INVENTORY, --inventory=INVENTORY, --inventory-file=INVENTORY
                         specify inventory host path or <strong>comma separated host</strong></p>
</blockquote>
",11440,2020-03-12T12:36:21.083,"['ansible all -i 192.168.254.150, -m ping\n192.168.254.150 | SUCCESS => {\n    ""changed"": false, \n    ""ping"": ""pong""\n}\n']"
1253,11061,3282,CC BY-SA 4.0,2020-03-12T13:31:23.687,"<p>I store them in my terminal session using <code>keyctl</code>. When I open a terminal session, I input my passwords once.</p>

<p><code>keyctl</code> allows you to store passwords at different levels, I have chosen session level  but you can store it at user or host level.</p>

<p>To perform that, define property <code>vault_identity_list</code> in file <em>ansible.cfg</em> :</p>

<pre><code>vault_identity_list = my_key@./scripts/my_key.py
</code></pre>

<p>Create a python script named <em>my_key.py</em> in directory <em>./scripts</em> with this content :</p>

<pre class=""lang-py prettyprint-override""><code>#!/usr/bin/python
# coding: utf8

import subprocess
import sys
import getpass

key_name = ""my_key""
try:
  keyid = int(subprocess.Popen(""keyctl request user {} @s"".format(key_name), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).stdout.read())
  print subprocess.Popen(""keyctl print {}"".format(str(keyid)), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).stdout.read().rstrip()
except ValueError:
  sys.stderr.write(""Password for '{}' : "".format(key_name))
  password = getpass.getpass("""").rstrip()
  subprocess.Popen(""keyctl add user {} '{}' @s"".format(key_name, password), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
  print password
</code></pre>

<p>Now, when you type <code>ansible-playbook -e @my_vault.vault ...</code>, it asks you password only once per sessions.</p>

<p>Whith this approach, you can use easily several vaults (each of them with a python script, I don't find a way to use the same script with all vaults).</p>
",20186,2020-03-12T13:31:23.687,"['vault_identity_list = my_key@./scripts/my_key.py\n', '#!/usr/bin/python\n# coding: utf8\n\nimport subprocess\nimport sys\nimport getpass\n\nkey_name = ""my_key""\ntry:\n  keyid = int(subprocess.Popen(""keyctl request user {} @s"".format(key_name), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).stdout.read())\n  print subprocess.Popen(""keyctl print {}"".format(str(keyid)), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE).stdout.read().rstrip()\nexcept ValueError:\n  sys.stderr.write(""Password for \'{}\' : "".format(key_name))\n  password = getpass.getpass("""").rstrip()\n  subprocess.Popen(""keyctl add user {} \'{}\' @s"".format(key_name, password), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n  print password\n']"
1254,11066,11065,CC BY-SA 4.0,2020-03-13T04:08:32.393,"<p>Solution that worked for me in the past: create a new image out of the existing one and let entrypoint script of that new image to modify permissions of your volume_mountpoint.</p>

<p>So in the case of your image (php:7.4-apache) you create entrypoint.sh file, something like</p>

<pre><code>chown www-data:www-data -R /path/to/volume_mountpoint
apache2-foreground
</code></pre>

<p>And then your Dockerfile should be something like</p>

<pre><code>FROM php:7.4-apache
COPY entrypoint.sh /entrypoint.sh
ENTRYPOINT [""/entrypoint.sh""]
</code></pre>

<p>This way it should correct the permissions when container starts. Note, that I haven't tested the above, might require some tweaks - but hopefully it shows the idea.</p>

<p>P.s. Maybe somebody has a better way of doing this - I would be very interested myself.</p>
",19963,2020-03-13T04:08:32.393,"['chown www-data:www-data -R /path/to/volume_mountpoint\napache2-foreground\n', 'FROM php:7.4-apache\nCOPY entrypoint.sh /entrypoint.sh\nENTRYPOINT [""/entrypoint.sh""]\n']"
1255,11071,11070,CC BY-SA 4.0,2020-03-13T18:24:15.017,"<p>You'll want to be sure your spec.tls section has the following two items to tell the router you want both secure and insecure traffic allowed in the edge. </p>

<pre><code>apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: my-app-ui
  namespace: my-namespace
spec:
  host: my-host
  port:
    targetPort: http
  tls:
    insecureEdgeTerminationPolicy: Allow
    termination: edge
  to:
    kind: Service
    name: my-app-ui
    weight: 100
  wildcardPolicy: None
</code></pre>
",20204,2020-03-13T18:24:15.017,['apiVersion: route.openshift.io/v1\nkind: Route\nmetadata:\n  name: my-app-ui\n  namespace: my-namespace\nspec:\n  host: my-host\n  port:\n    targetPort: http\n  tls:\n    insecureEdgeTerminationPolicy: Allow\n    termination: edge\n  to:\n    kind: Service\n    name: my-app-ui\n    weight: 100\n  wildcardPolicy: None\n']
1256,11082,8676,CC BY-SA 4.0,2020-03-16T09:37:47.697,"<p>I eventually found the solution :) </p>

<p>In an Azure Devops Release pipelines I've created a Command Line task that executes <code>SqlPackage.exe /Action:DeployReport /p:DoNotAlterReplicatedObjects=false ...</code> which creates an XML file that contains info on which tables etc would be changed by a deployment. It's important to note that <code>DoNotAlterReplicatedObjects</code> should be set to false, otherwise SqlPackage will fail.</p>

<p>In a second task in the Azure Release pipeline, I analyze the generated DeployReport (e.g. the XML file) using Powershell and XPath**. The Powershell task will create an boolean output variable that will indicate whether replication needs to be stopped or not. In my case, I analyze the XML and if a table is created/altered/dropped, the replication will be stopped.
The syntax for setting the output variable is</p>

<pre><code>Write-Host ""##vso[task.setvariable variable=haltReplication;isOutput=true]$haltReplication""`
</code></pre>

<p>Third step is yet another Powershell script that will stop the replication. This third script will only run if <code>$haltReplication</code> evaulates to true. In the Control Options, the custom condition is <code>and(succeeded(), eq(variables['haltReplication.haltReplication'],'1'))</code></p>

<p>**The XML file generated by SqlPackage.exe contains namespaces, which makes working with XPath a bit cumbersome. The following SO answer helped me a lot <a href=""https://stackoverflow.com/questions/36417189/ignore-namespace-in-xpath-as-this-can-be-dynamic?rq=1"">https://stackoverflow.com/questions/36417189/ignore-namespace-in-xpath-as-this-can-be-dynamic?rq=1</a> </p>
",16135,2020-03-16T09:37:47.697,"['Write-Host ""##vso[task.setvariable variable=haltReplication;isOutput=true]$haltReplication""`\n']"
1257,11091,11086,CC BY-SA 4.0,2020-03-17T15:24:49.927,"<p>You can use a ssh reverse proxy from any terminal (that has the ssh bin) to communicate with your applications.</p>

<p>For instance try this on the client side:  </p>

<pre><code> ssh -NL 3000:localhost:3000 root@10.10.10.1
</code></pre>

<p><em>This command won't print anything (except prompting for ssh key's password) and won't stop by itself. To kill the reverse proxy you can do ctrl + C</em></p>

<p>Now you should be able to curl your application the following way on the client:</p>

<pre><code>curl 127.0.0.1:3000
</code></pre>
",20255,2020-03-17T15:24:49.927,"[' ssh -NL 3000:localhost:3000 root@10.10.10.1\n', 'curl 127.0.0.1:3000\n']"
1258,11110,11078,CC BY-SA 4.0,2020-03-19T09:27:16.410,"<p>As @JSapkota mentioned the URL was wrong. It must be <code>https://keycloak-server/auth/admin/realms</code>.</p>

<pre><code>- name: ""Create Realm for service Keycloak""
  uri:
    url: ""https://keycloak-server/auth/admin/realms""
    method: POST
    src: ""realm.json""
    remote_src: ""no""
    status_code:
     - 201
    headers:
      Content-type: ""application/json""
      Accept: ""application/json""
      Authorization: ""Bearer {{ keycloak_token.json.access_token }}""
  register: keycloak_realm_create
</code></pre>

<p>Take care about the return status code. It is ""201 created"" and the <code>uri</code> module must know, that this is fine.</p>

<p>This works one time. Because in the next run the REST API responses with 409 the <code>uri</code> module fails. 
To be idempotent, you need to check first, if the realm exists. This can be done via <code>GET /auth/admin/realms/{{ keycloak_realm_name }}</code> and check the return code, if it is 404 or 200. If it is 404, then you make a ""POST"" otherwise a ""PUT"". So, this a complete example:</p>

<pre><code>- name: ""Set facts""
  set_fact:
    keycloak_admin_user: ""admin""
    keycloak_admin_pass: ""password""
    keycloak_base_url: ""https://keycloak.server""
    keycloak_realm_name: ""myrealm""
    keycloak_realm_data_file: ""realm.json""

- name: ""Create Token for service Keycloak""
  uri:
    url: ""{{ keycloak_base_url }}/auth/realms/master/protocol/openid-connect/token""
    method: POST
    body_format: form-urlencoded
    body:
      username: ""{{ keycloak_admin_user }}""
      password: ""{{ keycloak_admin_pass }}""
      grant_type: ""password""
      client_id: ""admin-cli""
  register: keycloak_token

- name: ""Find out, if Realm {{ keycloak_realm_name }} for service Keycloak exists""
  uri:
    url: ""{{ keycloak_base_url }}/auth/admin/realms/{{ keycloak_realm_name }}""
    method: GET
    status_code:
     - 200
     - 404
    headers:
      Accept: ""application/json""
      Authorization: ""Bearer {{ keycloak_token.json.access_token }}""
  register: keycloak_realm_exists

- name: ""Create Realm {{ keycloak_realm_name }} for service Keycloak""
  uri:
    url: ""{{ keycloak_base_url }}/auth/admin/realms""
    method: POST
    src: ""{{ keycloak_realm_data_file }}""
    remote_src: ""no""
    status_code:
     - 201
    headers:
      Content-type: ""application/json""
      Accept: ""application/json""
      Authorization: ""Bearer {{ keycloak_token.json.access_token }}""
  register: keycloak_realm_create
  when: ""keycloak_realm_exists.status == 404""

- name: ""Update Realm {{ keycloak_realm_name }} for service Keycloak""
  uri:
    url: ""{{ keycloak_base_url }}/auth/admin/realms/{{ keycloak_realm_name }}""
    method: PUT
    src: ""{{ keycloak_realm_data_file }}""
    remote_src: ""no""
    status_code:
     - 204
    headers:
      Content-type: ""application/json""
      Accept: ""application/json""
      Authorization: ""Bearer {{ keycloak_token.json.access_token }}""
  register: keycloak_realm_create
  when: ""keycloak_realm_exists.status == 200""
</code></pre>

<p>Also I had the problem, that after every request the Keycloak server responses with a 403 when I don't refresh the token before the next call to Keycloak. But I think, this depends on Realm token settings of the admin realm.</p>
",17486,2020-03-19T09:27:16.410,"['- name: ""Create Realm for service Keycloak""\n  uri:\n    url: ""https://keycloak-server/auth/admin/realms""\n    method: POST\n    src: ""realm.json""\n    remote_src: ""no""\n    status_code:\n     - 201\n    headers:\n      Content-type: ""application/json""\n      Accept: ""application/json""\n      Authorization: ""Bearer {{ keycloak_token.json.access_token }}""\n  register: keycloak_realm_create\n', '- name: ""Set facts""\n  set_fact:\n    keycloak_admin_user: ""admin""\n    keycloak_admin_pass: ""password""\n    keycloak_base_url: ""https://keycloak.server""\n    keycloak_realm_name: ""myrealm""\n    keycloak_realm_data_file: ""realm.json""\n\n- name: ""Create Token for service Keycloak""\n  uri:\n    url: ""{{ keycloak_base_url }}/auth/realms/master/protocol/openid-connect/token""\n    method: POST\n    body_format: form-urlencoded\n    body:\n      username: ""{{ keycloak_admin_user }}""\n      password: ""{{ keycloak_admin_pass }}""\n      grant_type: ""password""\n      client_id: ""admin-cli""\n  register: keycloak_token\n\n- name: ""Find out, if Realm {{ keycloak_realm_name }} for service Keycloak exists""\n  uri:\n    url: ""{{ keycloak_base_url }}/auth/admin/realms/{{ keycloak_realm_name }}""\n    method: GET\n    status_code:\n     - 200\n     - 404\n    headers:\n      Accept: ""application/json""\n      Authorization: ""Bearer {{ keycloak_token.json.access_token }}""\n  register: keycloak_realm_exists\n\n- name: ""Create Realm {{ keycloak_realm_name }} for service Keycloak""\n  uri:\n    url: ""{{ keycloak_base_url }}/auth/admin/realms""\n    method: POST\n    src: ""{{ keycloak_realm_data_file }}""\n    remote_src: ""no""\n    status_code:\n     - 201\n    headers:\n      Content-type: ""application/json""\n      Accept: ""application/json""\n      Authorization: ""Bearer {{ keycloak_token.json.access_token }}""\n  register: keycloak_realm_create\n  when: ""keycloak_realm_exists.status == 404""\n\n- name: ""Update Realm {{ keycloak_realm_name }} for service Keycloak""\n  uri:\n    url: ""{{ keycloak_base_url }}/auth/admin/realms/{{ keycloak_realm_name }}""\n    method: PUT\n    src: ""{{ keycloak_realm_data_file }}""\n    remote_src: ""no""\n    status_code:\n     - 204\n    headers:\n      Content-type: ""application/json""\n      Accept: ""application/json""\n      Authorization: ""Bearer {{ keycloak_token.json.access_token }}""\n  register: keycloak_realm_create\n  when: ""keycloak_realm_exists.status == 200""\n']"
1259,11115,11114,CC BY-SA 4.0,2020-03-19T15:03:45.620,"<p>When running an EKS cluster, the best way to configure your <code>~/.kube/config</code> is by using the <a href=""https://docs.aws.amazon.com/cli/latest/reference/eks/update-kubeconfig.html"" rel=""nofollow noreferrer"">SDK's update-kubeconfig</a>:</p>

<pre><code>aws eks update-kubeconfig --name your-cluster-name
</code></pre>

<p>Make sure to configure your credentials as <code>AWS_*</code> environment variables. Or even better use something like <a href=""https://github.com/99designs/aws-vault"" rel=""nofollow noreferrer"">aws-vault</a>.</p>
",19585,2020-03-19T15:03:45.620,['aws eks update-kubeconfig --name your-cluster-name\n']
1260,11118,11103,CC BY-SA 4.0,2020-03-20T13:37:18.400,"<p>Guys I discovered what happened.
It was necessary to apply these two resources that I informed (project_data and environment_data), but they were in the above directories and I was not aware.</p>

<p>Something like this:</p>

<pre><code>Application
|
|-Environment
  |-environment_data.tf
|
|- project_data.tf
</code></pre>
",18637,2020-03-20T13:37:18.400,['Application\n|\n|-Environment\n  |-environment_data.tf\n|\n|- project_data.tf\n']
1261,11119,11117,CC BY-SA 4.0,2020-03-20T13:55:39.543,"<p>Try something similar to the following:</p>

<pre><code>environment {
  GITLAB_API_TOKEN = credentials('gitlab_api_token').   
}
</code></pre>

<p>or</p>

<pre><code>withCredentials([[
  $class: 'com.dabsquared.gitlabjenkins.connection.GitLabApiTokenImpl',
  credentialsId: 'gitlab_api_token',
  variable: 'GITLAB_API_TOKEN'
]])
</code></pre>

<p>See <a href=""https://jenkins.io/doc/pipeline/steps/credentials-binding/"" rel=""nofollow noreferrer"">https://jenkins.io/doc/pipeline/steps/credentials-binding/</a>
and  <a href=""https://github.com/jenkinsci/gitlab-plugin/issues/536"" rel=""nofollow noreferrer"">https://github.com/jenkinsci/gitlab-plugin/issues/536</a> for more information.</p>
",12441,2020-03-20T13:55:39.543,"[""environment {\n  GITLAB_API_TOKEN = credentials('gitlab_api_token').   \n}\n"", ""withCredentials([[\n  $class: 'com.dabsquared.gitlabjenkins.connection.GitLabApiTokenImpl',\n  credentialsId: 'gitlab_api_token',\n  variable: 'GITLAB_API_TOKEN'\n]])\n""]"
1262,11120,11117,CC BY-SA 4.0,2020-03-20T13:57:41.150,"<p>You can do this using the <a href=""https://jenkins.io/doc/pipeline/steps/credentials-binding/"" rel=""nofollow noreferrer"">Credential Binding Plugin</a>. Open an existing pipeline job, scroll down to the text area where you enter the pipeline code, and click the Pipeline Syntax link to open the Snippet Generator.</p>

<p>From the Sample Step drop-down, select <code>withCredentials: Bind credentials to variables</code>. Under the Bindings section, select the ""Add"" button next to Credentials. Add a new credential of kind ""Secret text"". Enter the API token, give it an easy to remember ID (this is how we reference this secret) and a description.</p>

<p>When the token is added, select it from the <strong>Credentials</strong> drop-down selection. Enter the variable you want to use to reference the API key. Using your example, I named it <code>private_token</code>. When finished, click the <strong>Generate Pipeline Script</strong> button to generate a sample withCredentials() function. Using this function, any reference to the API key will be hidden from the user when called as <code>private_token</code></p>

<pre><code>withCredentials([string(credentialsId: 'Gitlab-API-Key', variable: 'private_token')]) 
{
    echo(""My private token is: ${private_token}"")
}
</code></pre>

<p><a href=""https://i.stack.imgur.com/IBPW8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/IBPW8.png"" alt=""Screenshot for reference""></a></p>
",9148,2020-03-20T13:57:41.150,"['withCredentials([string(credentialsId: \'Gitlab-API-Key\', variable: \'private_token\')]) \n{\n    echo(""My private token is: ${private_token}"")\n}\n']"
1263,11125,10923,CC BY-SA 4.0,2020-03-20T20:26:57.950,"<p>As @yang-shen-msft <a href=""https://stackoverflow.com/a/60541274/3025856"">notes on Stack Overflow</a>, there doesn't appear to be a way to honor the <code>MSDeploySkipRules</code> defined in the <code>csproj</code> file. Instead, files and folders can be skipped by defining the <em>Additional Arguments</em> (<code>AdditionalArguments</code>) parameter of the <em>Azure App Service Deploy</em> (<code>AzureRmWebAppDeployment</code>) task, <a href=""https://stackoverflow.com/a/46961055/3025856"">as discussed in another Stack Overflow answer</a>.</p>
<p>Since there doesn't appear to be any official documentation for the <code>-skip</code> rules, and <a href=""https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/dd569089(v=ws.10)?redirectedfrom=MSDN"" rel=""nofollow noreferrer"">the <code>MSDeploy.exe</code> documentation that Azure Pipelines references</a> is out-of-date, the following provides additional details.</p>
<p>First, it's useful to recognize that when you deploy a project via Visual Studio, it's simply taking the <code>MSDeploySkipRules</code> configured in the <code>csproj</code> file and adding them to it's internal call of <code>msdeploy.exe</code> as <code>-skip</code> rules. So, given the following rule defined in the <code>csproj</code>:</p>
<pre class=""lang-xml prettyprint-override""><code>&lt;Project Sdk=&quot;Microsoft.NET.Sdk.Web&quot;&gt;
  …
  &lt;ItemGroup&gt;
    &lt;MsDeploySkipRules Include=&quot;CustomSkipFolder&quot;&gt;
      &lt;ObjectName&gt;dirPath&lt;/ObjectName&gt;
      &lt;AbsolutePath&gt;wwwroot\\Uploads&lt;/AbsolutePath&gt;
    &lt;/MsDeploySkipRules&gt;
  &lt;/ItemGroup&gt;
&lt;/Project&gt;
</code></pre>
<p>The <code>-skip</code> rule is interpreted as:</p>
<pre><code>msdeploy.exe -skip:objectName=dirPath,absolutePath=wwwroot\\Uploads
</code></pre>
<p>Translating this to the <em>Azure App Service Deploy</em> (<code>AzureRmWebAppDeployment</code>) task, the resulting <code>yml</code> might look like:</p>
<pre><code>- task: AzureRmWebAppDeployment@4
  inputs:
    ConnectionType: 'AzureRM'
    azureSubscription: 'Azure Subscription'
    appType: 'webApp'
    WebAppName: 'MyStagingSite'
    packageForLinux: '$(Build.ArtifactStagingDirectory)/**/*.zip'
    enableCustomDeployment: true
    DeploymentType: 'webDeploy'
    enableXmlTransform: false
    enableXmlVariableSubstitution: true
    RemoveAdditionalFilesFlag: true
    AdditionalArguments: '-skip:objectName=dirPath,absolutePath=wwwroot\\Uploads'
</code></pre>
<blockquote>
<p><em>Note:</em> Multiple <code>-skip</code> rules can be defined on the same <code>msdeploy.exe</code> call.</p>
</blockquote>
<p>Unfortunately, as mentioned above, there doesn't <em>appear</em> to be any official, first-party documentation for the <code>-skip</code> rules on <code>msdeploy.exe</code>. The <a href=""https://docs.microsoft.com/en-us/previous-versions/windows/it-pro/windows-server-2008-R2-and-2008/dd569089(v=ws.10)?redirectedfrom=MSDN"" rel=""nofollow noreferrer"">2014 documentation</a> acknowledges them, and provides two examples, but doesn't expand on the options. That said, way back in 2012, @richard-szalay wrote a useful article, &quot;<a href=""https://blog.richardszalay.com/2012/12/17/demystifying-msdeploy-skip-rules/"" rel=""nofollow noreferrer"">Demystifying MSDeploy skip rules</a>&quot;, which provides useful direction here for anyone requiring additional control over their <code>-skip</code> rules.</p>
",19938,2020-08-18T19:10:12.463,"['<Project Sdk=""Microsoft.NET.Sdk.Web"">\n  …\n  <ItemGroup>\n    <MsDeploySkipRules Include=""CustomSkipFolder"">\n      <ObjectName>dirPath</ObjectName>\n      <AbsolutePath>wwwroot\\\\Uploads</AbsolutePath>\n    </MsDeploySkipRules>\n  </ItemGroup>\n</Project>\n', 'msdeploy.exe -skip:objectName=dirPath,absolutePath=wwwroot\\\\Uploads\n', ""- task: AzureRmWebAppDeployment@4\n  inputs:\n    ConnectionType: 'AzureRM'\n    azureSubscription: 'Azure Subscription'\n    appType: 'webApp'\n    WebAppName: 'MyStagingSite'\n    packageForLinux: '$(Build.ArtifactStagingDirectory)/**/*.zip'\n    enableCustomDeployment: true\n    DeploymentType: 'webDeploy'\n    enableXmlTransform: false\n    enableXmlVariableSubstitution: true\n    RemoveAdditionalFilesFlag: true\n    AdditionalArguments: '-skip:objectName=dirPath,absolutePath=wwwroot\\\\Uploads'\n""]"
1264,11126,10900,CC BY-SA 4.0,2020-03-20T22:24:38.287,"<p>This may be what you are doing already (in which case this sounds like a bug), yet it seems just based on the limited information in the question that you may be forgetting a step: Run <code>plan -destroy -target=... -target=...</code> first.  The <code>terraform destroy</code> command will try to operate on changes listed in the <code>.plan</code> file.</p>

<p>The following example assumes a Terraform module named <code>foo</code>, with 3 EBS volumes and attachments named as: <code>dev-sdb</code>, <code>dev-sdf</code>, <code>dev-sdg</code>.  All resources are assumed to have <code>count = local.enabled ? 1 : 0</code>.  So this is the more advanced case you may encounter where each resource would have to be targeted with the array syntax <code>[0]</code>.</p>

<ol>
<li><p>First create a targeted plan file with <code>terraform plan -destroy -target=...</code>. 
Do this before trying to run <code>terraform destroy</code></p>

<pre><code>terraform plan -destroy \
               -target=module.foo.aws_volume_attachment.dev-sdb-attachments[0] \
               -target=module.foo.aws_volume_attachment.dev-sdf-attachments[0] \
               -target=module.foo.aws_volume_attachment.dev-sdg-attachments[0] \
               -target=module.foo.aws_instance.foo[0]  \
               -target=module.foo.aws_iam_instance_profile.foo[0] \
               -out=intermediate.plan
</code></pre></li>
<li><p>Run <code>terraform destroy</code>, optionally also using <code>-target=...</code> for safety precautions if you wish:</p>

<pre><code>terraform destroy -target=module.foo.aws_volume_attachment.dev-sdb-attachments[0] \
                  -target=module.foo.aws_volume_attachment.dev-sdf-attachments[0] \
                  -target=module.foo.aws_volume_attachment.dev-sdg-attachments[0] \
                  -target=module.foo.aws_instance.foo[0]  \
                  -target=module.foo.aws_iam_instance_profile.foo[0] \
                  intermediate.plan
</code></pre></li>
</ol>

<p>If you need this to be unattended for automation, add <code>-auto-approve</code> flag to the <code>terraform destroy</code> command.  Otherwise, it assumes an interactive terminal session and will prompt before destroying any resources.</p>
",7668,2020-03-20T22:24:38.287,"['terraform plan -destroy \\\n               -target=module.foo.aws_volume_attachment.dev-sdb-attachments[0] \\\n               -target=module.foo.aws_volume_attachment.dev-sdf-attachments[0] \\\n               -target=module.foo.aws_volume_attachment.dev-sdg-attachments[0] \\\n               -target=module.foo.aws_instance.foo[0]  \\\n               -target=module.foo.aws_iam_instance_profile.foo[0] \\\n               -out=intermediate.plan\n', 'terraform destroy -target=module.foo.aws_volume_attachment.dev-sdb-attachments[0] \\\n                  -target=module.foo.aws_volume_attachment.dev-sdf-attachments[0] \\\n                  -target=module.foo.aws_volume_attachment.dev-sdg-attachments[0] \\\n                  -target=module.foo.aws_instance.foo[0]  \\\n                  -target=module.foo.aws_iam_instance_profile.foo[0] \\\n                  intermediate.plan\n']"
1265,11140,11138,CC BY-SA 4.0,2020-03-23T03:08:26.227,"<p>looks like your new to stack exchange. You need to form a clearer question to get a good answer.... </p>

<p>As far as your error goes.... <code>count</code> is a reserved name. It's only accessible when the block you're writing has a <code>count</code> set! </p>

<p>You have You just need to specify the <code>count</code> of <code>aws_internet_gateway</code> data resources you're trying to get. Your code implies there is more than one.</p>

<pre><code>data ""aws_internet_gateway"" ""zyz_igw"" {
   count = 1000000000
   ...
</code></pre>
",3328,2020-03-23T03:08:26.227,"['data ""aws_internet_gateway"" ""zyz_igw"" {\n   count = 1000000000\n   ...\n']"
1266,11146,11134,CC BY-SA 4.0,2020-03-24T07:16:04.943,"<p>You can mount a volume e.g. at <code>/app/artifacts</code> then set up your application to place the artifacts on that folder. </p>

<pre><code>docker run -d \
-v artifacts-vol:/app/artifacts \
artifact-creator:latest
</code></pre>

<p>then after that, you can mount the same volume to a separate container and specify on the new container to read the artifacts from the volume location</p>

<pre><code>docker run -d \
-v artifacts-vol:/app/artifacts \
artifact-reader:latest
</code></pre>
",20337,2020-03-24T07:16:04.943,"['docker run -d \\\n-v artifacts-vol:/app/artifacts \\\nartifact-creator:latest\n', 'docker run -d \\\n-v artifacts-vol:/app/artifacts \\\nartifact-reader:latest\n']"
1267,11147,11143,CC BY-SA 4.0,2020-03-24T09:04:00.313,"<p>There are three types of timeouts in <code>Gitlab CI</code>:</p>

<ul>
<li><code>Project</code> timeout</li>
<li><code>Runner</code> timeout</li>
<li><code>Jobs</code> timeout</li>
</ul>

<h2>Project <code>timeout</code></h2>

<p>According to <a href=""https://docs.gitlab.com/ee/ci/pipelines/settings.html#timeout"" rel=""nofollow noreferrer"">GitLab docs</a>:</p>

<blockquote>
  <p>Timeout defines the maximum amount of time in minutes that a job is able run. This is configurable under your project’s <strong>Settings &gt; CI/CD &gt; General pipelines settings</strong>. The default value is 60 minutes. Decrease the time limit if you want to impose a hard limit on your jobs’ running time or increase it otherwise. In any case, if the job surpasses the threshold, it is marked as failed</p>
</blockquote>

<h2>Runner <code>timeout</code></h2>

<p>According to <a href=""https://docs.gitlab.com/ee/ci/runners/#setting-maximum-job-timeout-for-a-runner"" rel=""nofollow noreferrer"">GitLab docs</a>:</p>

<blockquote>
  <p>For each <code>Runner</code> you can specify a <em>maximum job timeout</em>.</p>
</blockquote>

<p><code>Runner</code> timeout settings are defined in runner's edit page</p>

<h2><code>Jobs</code> timeout</h2>

<p><a href=""https://docs.gitlab.com/ce/ci/yaml/README.html#timeout"" rel=""nofollow noreferrer"">GitLab CI/CD Pipeline Configuration Reference | GitLab</a></p>

<p><code>Job</code>'s <code>timeout</code> allows you to configure a timeout for a specific job. For example:</p>

<pre><code>build:
  script: build.sh
  timeout: 3 hours 30 minutes

test:
  script: rspec
  timeout: 3h 30m
</code></pre>

<h1>Precedence of different types of timeout</h1>

<p>The <code>job</code>-level <code>timeout</code> can exceed the <a href=""https://docs.gitlab.com/ce/ci/pipelines/settings.html#timeout"" rel=""nofollow noreferrer""><code>project</code>-level timeout</a> but can not exceed the Runner-specific timeout.</p>

<p>If <code>runner</code> timeout smaller than <a href=""https://docs.gitlab.com/ee/ci/pipelines/settings.html#timeout"" rel=""nofollow noreferrer""><code>project</code> defined timeout</a>, will take the precedence.</p>

<h2>Examples of precedence of <code>timeout</code> directive</h2>

<p>See <a href=""https://docs.gitlab.com/ee/ci/runners/#setting-maximum-job-timeout-for-a-runner"" rel=""nofollow noreferrer"">Configuring GitLab Runners | GitLab</a></p>

<pre class=""lang-yaml prettyprint-override""><code>name: **Example 1 - Runner timeout bigger than project timeout**
  project_timeout: 2h
  runner_timeout: 24h
  job_timeout: 4h
  resulting_timeout: 4h

name: **Example 2 - Runner timeout not configured**
  project_timeout: 2h
  job_timeout: 4h
  resulting_timeout: 4h

name: **Example 3 - Runner AND job timeout are not configured**
  project_timeout: 24h
  resulting_timeout: 24h

name: **Example 4 - Runner timeout smaller than project timeout**
  project_timeout: 2h
  runner_timeout: 30m
  resulting_timeout: 30m

name: **Example 5 - Runner timeout smaller than Project timeout, Job timeout is bigger than Runner timeout**
  project_timeout: 2h
  runner_timeout: 30m
  job_timeout: 1h
  resulting_timeout: 30m
</code></pre>
",20042,2020-04-03T19:37:13.553,"['build:\n  script: build.sh\n  timeout: 3 hours 30 minutes\n\ntest:\n  script: rspec\n  timeout: 3h 30m\n', 'name: **Example 1 - Runner timeout bigger than project timeout**\n  project_timeout: 2h\n  runner_timeout: 24h\n  job_timeout: 4h\n  resulting_timeout: 4h\n\nname: **Example 2 - Runner timeout not configured**\n  project_timeout: 2h\n  job_timeout: 4h\n  resulting_timeout: 4h\n\nname: **Example 3 - Runner AND job timeout are not configured**\n  project_timeout: 24h\n  resulting_timeout: 24h\n\nname: **Example 4 - Runner timeout smaller than project timeout**\n  project_timeout: 2h\n  runner_timeout: 30m\n  resulting_timeout: 30m\n\nname: **Example 5 - Runner timeout smaller than Project timeout, Job timeout is bigger than Runner timeout**\n  project_timeout: 2h\n  runner_timeout: 30m\n  job_timeout: 1h\n  resulting_timeout: 30m\n']"
1268,11153,3102,CC BY-SA 4.0,2020-03-24T16:11:21.517,"<p>I hope you've figured it out yourself. In case you (or some other people) have that issue:</p>

<p>The user that needs to attach / detach the instance profile to an instance needs:</p>

<ul>
<li>EC2 actions to perform that. That includes:</li>
</ul>

<pre><code>{
    ""Sid"": ""InstanceProfileAccess"",
    ""Effect"": ""Allow"",
    ""Action"": [
        ""iam:GetInstanceProfile"",
        ""iam:ListInstanceProfiles"",
        ""iam:ListInstanceProfilesForRole"",
        ""iam:AddRoleToInstanceProfile"",
        ""iam:RemoveRoleFromInstanceProfile""
    ],
    ""Resource"": ""*""
}
</code></pre>

<ul>
<li>The <code>passRole</code> action to pass the role to the specific resource.</li>
</ul>

<pre><code>{
    ""Sid"": ""PassDefaultInstanceProfileToEC2"",
    ""Effect"":""Allow"",
    ""Action"":""iam:PassRole"",
    ""Resource"":""arn:aws:iam::&lt;ID&gt;:role/&lt;ROLE_NAME&gt;""
}
</code></pre>

<p>That user can gain access via policies or roles or group.
I hope this helps.</p>

<p>You can read more here:</p>

<ul>
<li><a href=""https://aws.amazon.com/blogs/security/granting-permission-to-launch-ec2-instances-with-iam-roles-passrole-permission/"" rel=""nofollow noreferrer"">Granting Permission to Launch EC2 Instances with IAM Roles</a>.</li>
<li><a href=""https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html"" rel=""nofollow noreferrer"">Using Instance Profiles</a>.</li>
<li><a href=""https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html"" rel=""nofollow noreferrer"">IAM Roles for Amazon EC2</a>.</li>
<li><a href=""https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_passrole.html"" rel=""nofollow noreferrer"">Granting a User Permissions to Pass a Role to an AWS Service</a>.</li>
</ul>
",20349,2020-03-24T16:11:21.517,"['{\n    ""Sid"": ""InstanceProfileAccess"",\n    ""Effect"": ""Allow"",\n    ""Action"": [\n        ""iam:GetInstanceProfile"",\n        ""iam:ListInstanceProfiles"",\n        ""iam:ListInstanceProfilesForRole"",\n        ""iam:AddRoleToInstanceProfile"",\n        ""iam:RemoveRoleFromInstanceProfile""\n    ],\n    ""Resource"": ""*""\n}\n', '{\n    ""Sid"": ""PassDefaultInstanceProfileToEC2"",\n    ""Effect"":""Allow"",\n    ""Action"":""iam:PassRole"",\n    ""Resource"":""arn:aws:iam::<ID>:role/<ROLE_NAME>""\n}\n']"
1269,11163,11112,CC BY-SA 4.0,2020-03-25T12:14:18.657,"<p>Could you wrap the assignment to value using the <a href=""https://www.terraform.io/docs/configuration/functions/try.html"" rel=""nofollow noreferrer"">try type conversion function</a>?</p>

<pre><code>output primary_LB_Subnet {
  value = try(aws_subnet.subnet_loadbalancer[0], null)
}
</code></pre>
",20362,2020-03-25T12:14:18.657,"['output primary_LB_Subnet {\n  value = try(aws_subnet.subnet_loadbalancer[0], null)\n}\n']"
1270,11171,11167,CC BY-SA 4.0,2020-03-26T12:06:56.340,"<p>Though it's not advised to have multiple processes inside a container, but you have 2 options:</p>

<p>Use a process manager like supervisord or wrapper script to use as CMD (meta code)</p>

<pre><code>start_first_process_in_bg
if START_FAILED
  exit
start_second_process_in_bg
if START_FAILED
  exit

while sleep 5; do
  check_first_process
  check_second_process

  if ANY_PROCESS_FAILED; then
    exit
</code></pre>
",3533,2020-03-26T12:06:56.340,['start_first_process_in_bg\nif START_FAILED\n  exit\nstart_second_process_in_bg\nif START_FAILED\n  exit\n\nwhile sleep 5; do\n  check_first_process\n  check_second_process\n\n  if ANY_PROCESS_FAILED; then\n    exit\n']
1271,11179,11175,CC BY-SA 4.0,2020-03-27T00:07:46.760,"<p>Caching of layers with buildkit in an external registry requires an extra step or two depending on how you want to cache your layers. The easy option is to include a build arg that enables the inline cache:</p>

<pre><code>docker build --build-arg BUILDKIT_INLINE_CACHE=1 --cache-from ${LATEST} -t ${LATEST} -t ${IMAGE_COMMIT_TAG} .
</code></pre>

<p>Note that the inline cache only caches layers for the target stage that was pushed in the image, so other states in a multi-stage build would need to be built and cached separately, or rebuilt without caching, neither of which is ideal.</p>

<p>You can also cache to a local file, or push the cache to a different registry image rather than inline with the image you pushed. Unfortunately the standard <code>docker build</code> CLI doesn't have access to all the buildkit flags to enable this. Instead, you can install buildkit directly or use buildx which is a CLI plugin for managing buildkit. You can install buildx separately but in current releases it's available with experimental CLI options that can be enabled with <code>export DOCKER_CLI_EXPERIMENTAL=enabled</code>. I believe you'd need to create a container based builder for all of the buildkit options, which can be done with:</p>

<pre><code>docker buildx create --use --driver docker-container --name local ${DOCKER_HOST:-unix:///var/run/docker.sock}
</code></pre>

<p>Then you should be able to run something like:</p>

<pre><code>docker buildx build --cache-from ${IMG_CACHE} --cache-to ${IMG_CACHE} -t ${LATEST} -t ${IMAGE_COMMIT_TAG} .
</code></pre>

<p>More documentation on the buildkit caching is available at: <a href=""https://github.com/moby/buildkit#export-cache"" rel=""nofollow noreferrer"">https://github.com/moby/buildkit#export-cache</a></p>

<p>More details on buildx is available at: <a href=""https://github.com/docker/buildx"" rel=""nofollow noreferrer"">https://github.com/docker/buildx</a></p>
",7730,2020-03-27T00:14:09.653,"['docker build --build-arg BUILDKIT_INLINE_CACHE=1 --cache-from ${LATEST} -t ${LATEST} -t ${IMAGE_COMMIT_TAG} .\n', 'docker buildx create --use --driver docker-container --name local ${DOCKER_HOST:-unix:///var/run/docker.sock}\n', 'docker buildx build --cache-from ${IMG_CACHE} --cache-to ${IMG_CACHE} -t ${LATEST} -t ${IMAGE_COMMIT_TAG} .\n']"
1272,11182,11180,CC BY-SA 4.0,2020-03-27T09:37:32.773,"<p>Well there are 2 possibble options.</p>

<p>One is to create a <strong>LoadBalancer</strong> type for each service you want to be exposed. In case you have just one service that's great. That's rarely the case of course :) </p>

<p>If you build your k8s cluster properly ( having Prometheus-Operator doing the monitoring for example ) most likely besides the business logic service/s, you would want to expose  internal cluster valuable services like Grafana.</p>

<p>That's why even if you have just 1 service, for future extension of such type of need the best would be to use an <strong>Ingress</strong> resource. It providees a way to expose multiple services through a single IP address —  HTTP level (network layer 7). </p>

<p>You could play with HTTP headers essentially and do some path/host routing.</p>

<p>You express the definition for your object and helm would do the installation. Another option is to use a tool like ArgoCD, basically sticking to GitOps policy.</p>

<p>A fundamnetal knowledge is to be aware that the Load Balancer/Ingress would forward the traffic to the service, not the pods. Services are abstracted entities by kube-proxy, by default kube-proxy uses a round-robin algorithm.</p>

<p><a href=""https://kubernetes.io/docs/concepts/services-networking/service/"" rel=""nofollow noreferrer"">https://kubernetes.io/docs/concepts/services-networking/service/</a></p>

<p>Regarding the definition, it follows the standart K8s scheme [ <strong>apiVersion</strong>, <strong>kind</strong>, <strong>metadata</strong>, <strong>spec</strong> fields]. Example would be an Ingress created from AWS-Ingress-Controller.</p>

<pre class=""lang-yaml prettyprint-override""><code>apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: ingress
  namespace: management
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
spec:
  rules:
  - host: grafana.com
    http:
      paths:
      - backend:
          serviceName: grafana
          servicePort: 80
        path: /*

</code></pre>
",20101,2020-03-27T10:04:37.937,['apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: ingress\n  namespace: management\n  annotations:\n    kubernetes.io/ingress.class: alb\n    alb.ingress.kubernetes.io/scheme: internet-facing\nspec:\n  rules:\n  - host: grafana.com\n    http:\n      paths:\n      - backend:\n          serviceName: grafana\n          servicePort: 80\n        path: /*\n\n']
1273,11189,11188,CC BY-SA 4.0,2020-03-29T17:18:42.000,"<p>Your very first role include does not have variables provided with it, so it will fail.</p>

<p>Here's an excerpt from above showing this.  Notice lines 1-2 have no variables after them (unlike the include following that which does correctly provide the variables).</p>

<pre><code>- include_role:
    name: gluster-node-partition

- name: Create data1 partition
  include_role:
    name: gluster-node-partition
  vars:
    device_name: '/dev/sdb'
    partition_name: 'data1'
</code></pre>

<p>As <code>roles/gluster-node-partition/tasks/main.yml</code> uses device_name twice, and it is not defined for that first call, it will fail. The two usages are noted on line 2 and on the last line below.</p>

<pre><code>  parted:
    device: '{{ device_name }}'
    number: 1
    label: gpt
    name: '{{ partition_name }}'
    state: present
  become: true

- name: 'Create filesystem on {{ partition_name }} partition'
  filesystem:
    fstype: btrfs
    dev: '{{ device_name }}1' #should expand to something like '/dev/sdb1'
</code></pre>
",16059,2020-03-29T17:30:41.053,"[""- include_role:\n    name: gluster-node-partition\n\n- name: Create data1 partition\n  include_role:\n    name: gluster-node-partition\n  vars:\n    device_name: '/dev/sdb'\n    partition_name: 'data1'\n"", ""  parted:\n    device: '{{ device_name }}'\n    number: 1\n    label: gpt\n    name: '{{ partition_name }}'\n    state: present\n  become: true\n\n- name: 'Create filesystem on {{ partition_name }} partition'\n  filesystem:\n    fstype: btrfs\n    dev: '{{ device_name }}1' #should expand to something like '/dev/sdb1'\n""]"
1274,11192,11188,CC BY-SA 4.0,2020-03-30T04:31:00.090,"<p>You might want to use the group vars feature, so that your playbooks stay clean and re-usable.
You define a <code>storageservers</code> group in your inventory; associated with this group, Ansible will look for <code>group_vars/storageservers.yml</code> for the vars to associate with this group. Here, you can set the variables:</p>

<pre><code># group_vars/storageservers.yml
---
partitions:
 - device_name: /dev/sdb
   partition_name: /data1
 - device_name: /dev/sdc
   partition_name: /data2
 - device_name: /dev/sdd
   partition_name: /data3
</code></pre>

<p>Now, you have a list of partitions which will be picked up when you target <code>hosts: storageservers</code>, which you can loop over with one statement instead of 3:</p>

<pre><code># playbook.yml
---
hosts: storage
become: true
roles:
  - gluster-node-partition
</code></pre>

<p>Updated tasks:</p>

<pre><code># roles/gluster-node-partition/tasks.yml
- name: ""Create {{ item['partition_name'] }} partition""
  parted:
    device: ""{{ item['device_name'] }}""
    number: 1
    label: gpt
    name: ""{{ item['partition_name' }}""
    state: present
  loop: ""{{ partitions }}""

- name: ""Create filesystem on {{ item['partition_name'] }} partition""
  filesystem:
    fstype: btrfs
    dev: ""{{ item['device_name'] }}1"" #should expand to something like '/dev/sdb1'
  item: ""{{ partitions }}""

- name: ""Create mount point for {{ item['partition_name'] }} partition""
  file:
    path: '/{{ item['partition_name'] }}'
    state: directory
  loop: ""{{ partitions }}""

- name: ""Mount {{ item['partition_name'] }} partition""
  mount:
    path: ""/{{ item['partition_name'] }}""
    src: ""LABEL={{ item['partition_name'] }}""
    fstype: btrfs
    state: present
  loop: ""{{ partitions }}""
</code></pre>

<p>Doing it this way separates variables from tasks. If you want to add or change a filesystem, you only need to change the <em>variable</em> and not the <em>playbook</em>.</p>

<p>You also have a much cleaner playbook -- just a few lines. It's clear that this <em>all</em> of the filesystem stuff is contained in the role.</p>

<p>If you have a different set of machines where you want different mounts, you only have to add a new group, give that group a new <code>partitions</code> variable, and target it in the same way by setting <code>hosts: other_storage_servers</code>.</p>

<p>For reference, see the Ansible docs on :</p>

<ul>
<li><a href=""https://docs.ansible.com/ansible/latest/user_guide/intro_patterns.html"" rel=""nofollow noreferrer"">Targetting groups</a></li>
<li><a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable"" rel=""nofollow noreferrer"">Variable precedence</a></li>
<li><a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html#iterating-over-a-list-of-hashes"" rel=""nofollow noreferrer"">Looping over hashes</a></li>
</ul>
",354,2020-03-30T04:31:00.090,"['# group_vars/storageservers.yml\n---\npartitions:\n - device_name: /dev/sdb\n   partition_name: /data1\n - device_name: /dev/sdc\n   partition_name: /data2\n - device_name: /dev/sdd\n   partition_name: /data3\n', '# playbook.yml\n---\nhosts: storage\nbecome: true\nroles:\n  - gluster-node-partition\n', '# roles/gluster-node-partition/tasks.yml\n- name: ""Create {{ item[\'partition_name\'] }} partition""\n  parted:\n    device: ""{{ item[\'device_name\'] }}""\n    number: 1\n    label: gpt\n    name: ""{{ item[\'partition_name\' }}""\n    state: present\n  loop: ""{{ partitions }}""\n\n- name: ""Create filesystem on {{ item[\'partition_name\'] }} partition""\n  filesystem:\n    fstype: btrfs\n    dev: ""{{ item[\'device_name\'] }}1"" #should expand to something like \'/dev/sdb1\'\n  item: ""{{ partitions }}""\n\n- name: ""Create mount point for {{ item[\'partition_name\'] }} partition""\n  file:\n    path: \'/{{ item[\'partition_name\'] }}\'\n    state: directory\n  loop: ""{{ partitions }}""\n\n- name: ""Mount {{ item[\'partition_name\'] }} partition""\n  mount:\n    path: ""/{{ item[\'partition_name\'] }}""\n    src: ""LABEL={{ item[\'partition_name\'] }}""\n    fstype: btrfs\n    state: present\n  loop: ""{{ partitions }}""\n']"
1275,11201,11200,CC BY-SA 4.0,2020-03-31T13:52:11.150,"<p>It would seem not - in the scripted pipeline, groovy needs to be used - see <a href=""https://jenkins.io/doc/book/pipeline/syntax/#flow-control"" rel=""nofollow noreferrer"">the docs</a></p>

<pre class=""lang-java prettyprint-override""><code>node {
    stage('Example') {
        if (env.BRANCH_NAME == 'master') {
            echo 'I only execute on the master branch'
        } else {
            echo 'I execute elsewhere'
        }
    }
}

</code></pre>

<p>(taken straight from the docs)</p>

<p>This would be the same as <code>when { branch 'master' }</code></p>
",354,2020-03-31T13:52:11.150,"[""node {\n    stage('Example') {\n        if (env.BRANCH_NAME == 'master') {\n            echo 'I only execute on the master branch'\n        } else {\n            echo 'I execute elsewhere'\n        }\n    }\n}\n\n""]"
1276,11205,11204,CC BY-SA 4.0,2020-03-31T23:43:00.580,"<p>You can use the count meta-parameter to achieve the effects of an if-else statement.  It is talked about in detail in the link below and I also pulled one relevant example out.</p>

<p>I'm not 100% sure if you can give both the data source and resource the same name without a conflict; but I assume it would work.  It may be dependent on the resource you're creating though, not sure.</p>

<p><a href=""https://blog.gruntwork.io/terraform-tips-tricks-loops-if-statements-and-gotchas-f739bbae55f9"" rel=""nofollow noreferrer"">https://blog.gruntwork.io/terraform-tips-tricks-loops-if-statements-and-gotchas-f739bbae55f9</a></p>

<h2>Excerpt:</h2>

<pre><code># This is just pseudo code. It won't actually work in Terraform.
if var.give_neo_cloudwatch_full_access {
  resource ""aws_iam_user_policy_attachment"" ""neo_cloudwatch_full"" {
    user       = aws_iam_user.example[0].name
    policy_arn = aws_iam_policy.cloudwatch_full_access.arn
  }
} else {
  resource ""aws_iam_user_policy_attachment"" ""neo_cloudwatch_read"" {
    user       = aws_iam_user.example[0].name
    policy_arn = aws_iam_policy.cloudwatch_read_only.arn
  }
}
</code></pre>

<p>To do this in Terraform, you can use the count parameter and a conditional expression on each of the resources:</p>

<pre><code>resource ""aws_iam_user_policy_attachment"" ""neo_cloudwatch_full"" {
  count = var.give_neo_cloudwatch_full_access ? 1 : 0
  user       = aws_iam_user.example[0].name
  policy_arn = aws_iam_policy.cloudwatch_full_access.arn
}
resource ""aws_iam_user_policy_attachment"" ""neo_cloudwatch_read"" {
  count = var.give_neo_cloudwatch_full_access ? 0 : 1
  user       = aws_iam_user.example[0].name
  policy_arn = aws_iam_policy.cloudwatch_read_only.arn
}
</code></pre>
",16059,2020-03-31T23:43:00.580,"['# This is just pseudo code. It won\'t actually work in Terraform.\nif var.give_neo_cloudwatch_full_access {\n  resource ""aws_iam_user_policy_attachment"" ""neo_cloudwatch_full"" {\n    user       = aws_iam_user.example[0].name\n    policy_arn = aws_iam_policy.cloudwatch_full_access.arn\n  }\n} else {\n  resource ""aws_iam_user_policy_attachment"" ""neo_cloudwatch_read"" {\n    user       = aws_iam_user.example[0].name\n    policy_arn = aws_iam_policy.cloudwatch_read_only.arn\n  }\n}\n', 'resource ""aws_iam_user_policy_attachment"" ""neo_cloudwatch_full"" {\n  count = var.give_neo_cloudwatch_full_access ? 1 : 0\n  user       = aws_iam_user.example[0].name\n  policy_arn = aws_iam_policy.cloudwatch_full_access.arn\n}\nresource ""aws_iam_user_policy_attachment"" ""neo_cloudwatch_read"" {\n  count = var.give_neo_cloudwatch_full_access ? 0 : 1\n  user       = aws_iam_user.example[0].name\n  policy_arn = aws_iam_policy.cloudwatch_read_only.arn\n}\n']"
1277,11207,11173,CC BY-SA 4.0,2020-04-01T10:58:09.840,"<p>As per Martin Flowers' <a href=""https://martinfowler.com/bliki/BlueGreenDeployment.html"" rel=""nofollow noreferrer"">definition</a> of Blue-Green deployment</p>

<blockquote>
  <p>The blue-green deployment approach does this by ensuring you have two production environments, as identical as possible. At any time one of them, let's say blue for the example, is live. As you prepare a new release of your software you do your final stage of testing in the green environment. Once the software is working in the green environment, you switch the router so that all incoming requests go to the green environment - the blue one is now idle.</p>
</blockquote>

<h1>Steps</h1>

<p>You've said that DBs are synced using <code>master-slave</code> topology.
So, to switch traffic from one instance to another, we have to make  steps:</p>

<ul>
<li>Switch web-traffic from <code>APP v1</code> to <code>APP v2</code></li>
<li>Shutdown deprecated <code>DB Blue</code></li>
<li>Promote <code>DB Green</code> to <code>master</code> mode</li>
<li>Start new <code>DB Blue v2</code> in <code>slave</code> mode
(you may ask - why shutdown <code>DB Blue</code> instead of using <code>master-master</code> replication or other ways to sync <code>DB Blue v1</code> with <code>DB Green</code> in <code>master</code> mode. See explanation in <code>DB replication</code>)</li>
</ul>

<h2>Graceful switch web-traffic</h2>

<p>To switch web-traffic from <code>APP v1</code> <code>APP v2</code> - just use <code>nginx reload</code> - it will graceful end all working connection and move traffic from <code>App v1</code> to <code>App v2</code>
There are many scripting solutions for switch <code>blue/green</code> using shell/python scripts</p>

<p>E.g.:</p>

<ul>
<li><p><a href=""https://github.com/meappy/docker-nginx-blue-green"" rel=""nofollow noreferrer"">meappy/docker-nginx-blue-green</a>: Docker blue green upstreams for nginx with ngx_http_perl_module</p></li>
<li><p><a href=""https://dan.bravender.net/2014/8/24/Simple_0-Downtime_Blue_Green_Deployments.html"" rel=""nofollow noreferrer"">Simple 0-Downtime Blue Green Deployments</a>: Python simple 0-Downtime Blue Green Deployments example</p></li>
</ul>

<p>The logic is simple: add <code>green</code> upstream in <code>nginx</code> config, use it as default and send <code>reload</code> to <code>nginx</code>:</p>

<p>Sample <code>nginx.conf</code> for <code>reverse proxy</code>/<code>load balancer</code></p>

<pre><code>http {

upstream appv1 {
    zone appv1 64K;
    server 10.10.0.1:80;
}

upstream appv2 {
    zone appv2 64K;
    server 10.10.0.3:80;
}

server {
...
location / {
    proxy_pass http://$appv1;
}
}

}
</code></pre>

<p>Replace <code>proxy_pass http://$appv1;</code> with <code>proxy_pass http://$appvv;</code></p>

<p>And then</p>

<pre><code>nginx -s reload
</code></pre>

<h2>Stop <code>DB Blue</code></h2>

<p><code>systemctl stop postgresql</code></p>

<h2>Promote <code>DB Green</code> to <code>master</code> mode</h2>

<ul>
<li>Trigger the promotion using your defined trigger in <code>$PGDATA/recovery.conf</code></li>
</ul>

<pre><code>touch $PGDATA/failover
</code></pre>

<ul>
<li>Remove <code>failover</code> trigger from <code>Green DB</code></li>
</ul>

<pre><code>cd $PRIMARY_DATA
rm -f recovery.* failover  
</code></pre>

<ul>
<li>Make sure that <code>hot stanby</code> mode is <code>on</code> on <code>Green DB</code> in <code>master</code> mode </li>
</ul>

<pre><code>cat postgresql.conf | grep '#hot_standby = on'
</code></pre>

<h1>DB replication</h1>

<h2>Make a backup of master Green DB</h2>

<pre><code>psql -c ""SELECT pg_start_backup('Streaming Replication', true)"" postgresql://postgres@GreenDB/postgres
</code></pre>

<h2>Send a backup to Blue DB</h2>

<pre><code>rsync -a $PG_DATA_Green_DB/ $BlueDB_IP:$PG_DATA_Blue_DB/ --exclude postmaster.pid --exclude postmaster.opts 
</code></pre>

<h2>See also</h2>

<ul>
<li><a href=""https://www.2ndquadrant.com/en/blog/evolution-of-fault-tolerance-in-postgresql/"" rel=""nofollow noreferrer"">Evolution of Fault Tolerance in PostgreSQL</a></li>
</ul>

<h1>DB Migration (More complex but more robust database migration scheme)</h1>

<p>You may use more complex scheme for migration using <code>Ansible</code> and `Pglupgrade tool:</p>

<p><img src=""https://www.2ndquadrant.com/wp-content/uploads/2018/04/Screen-Shot-2018-04-24-at-16.02.54.png"" alt=""""></p>

<p>See for details: </p>

<ul>
<li><p><a href=""https://www.2ndquadrant.com/blog/near-zero-downtime-automated-upgrades-postgresql-clusters-cloud/"" rel=""nofollow noreferrer"">Near-Zero Downtime Automated Upgrades of PostgreSQL Clusters in Cloud (Part I)</a></p></li>
<li><p><a href=""https://www.2ndquadrant.com/en/blog/near-zero-downtime-automated-upgrades-postgresql-clusters-cloud-part-ii/"" rel=""nofollow noreferrer"">Near-Zero Downtime Automated Upgrades of PostgreSQL Clusters in Cloud (Part II)</a></p></li>
</ul>

<h1>P.s some definitions.</h1>

<p>Just to...</p>

<blockquote>
  <p>... sort the buyers from the spyers, the needy from the greedy...</p>
</blockquote>

<p>And <code>blue/green deployment</code> vs <code>canary deployment</code> vs <code>A/B test</code></p>

<h1>Definitions, kinds of deployments and tests</h1>

<p>(see details in <a href=""https://stackoverflow.com/questions/23746038/canary-release-strategy-vs-blue-green"">these answers</a> )</p>

<ul>
<li><p><strong>Blue-Green Deployment</strong> - When deploying a new version of an application, a second environment is created. Once the new environment is tested, it takes over from the old version. The old environment can then be turned off.</p></li>
<li><p><strong>A/B Testing</strong> - Two versions of an application are running at the same time. A portion of requests go to each. Developers can then compare the versions.  </p></li>
<li><p><strong>Canary Release</strong> - A new version of a microservice is started along with the old versions. That new version can then take a portion of the requests and the team can test how this new version interacts with the overall system.</p></li>
<li><p><strong>Feature flagging</strong> - The action of ""configuring"" (cold, or even hot) which functionality is (not)available for which (group) of users. If you also do something like ""feature flagging"" you can deploy first, measure soundness of your release in backwards compatibility/bug perspective, and release new functionality gradually to different users, or vice versa (scale down or even rollback functionality and/or binaries). Feature flagging allows for splitting availability of functionality from deployment of binaries, and gives much more fine-grained decision making then only ""deploy/rollback""</p></li>
</ul>

<h1>P.P.S <code>Blue/Green</code> vs <code>Canary</code></h1>

<p><a href=""https://github.com/lerndevops/educka/blob/master/other/Canary-vs-Blue-Green-Deployments.md"" rel=""nofollow noreferrer"">source</a></p>

<ul>
<li><p>Both blue-green and canary releases solve the same purpose</p></li>
<li><p>Although both of these terms look quite close to each other, they have subtle differences. One put confidence in your functionality release and the other put confidence the way you release.</p></li>
</ul>

<h2>Blue-Green Deployment</h2>

<blockquote>
  <p>When deploying a new version of an application, a second environment is created. Once the new environment is tested, it takes over from the old version. The old environment can then be turned off.</p>
</blockquote>

<p><code>1. It is more about the predictable release with zero downtime deployment.</code></p>

<p><code>2. Easy rollbacks in case of failure.</code></p>

<p><code>3. Completely automated deployment process</code></p>

<p><code>4. In cloud environment where it is easier to script &amp; recreate infrastructure, blue/green deployment is preferred as it allows the infrastructure to be in sync with the automation</code></p>

<h2>Canary Release</h2>

<blockquote>
  <p>A new version of a microservice is started along with the old versions. That new version can then take a portion of the requests and the team can test how this new version interacts with the overall system.</p>
</blockquote>

<p><code>1. The canary release is a technique to reduce the risk of introducing a new software version in production by slowly rolling out the change to a small subset of users before rolling it out to the entire infrastructure.</code></p>

<p><code>2. It is about to get an idea of how new version will perform (integrate with other apps, CPU, memory, disk usage, etc).</code></p>

<p>See also illustration (<a href=""https://stackoverflow.com/a/47397219/5720818"">source</a>):</p>

<p>Blue/Green: <a href=""https://i.stack.imgur.com/RtQRg.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RtQRg.png"" alt=""enter image description here""></a></p>

<p>Canary: <a href=""https://i.stack.imgur.com/bA9Xi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bA9Xi.png"" alt=""enter image description here""></a></p>
",20042,2020-04-02T19:18:52.933,"['http {\n\nupstream appv1 {\n    zone appv1 64K;\n    server 10.10.0.1:80;\n}\n\nupstream appv2 {\n    zone appv2 64K;\n    server 10.10.0.3:80;\n}\n\nserver {\n...\nlocation / {\n    proxy_pass http://$appv1;\n}\n}\n\n}\n', 'nginx -s reload\n', 'touch $PGDATA/failover\n', 'cd $PRIMARY_DATA\nrm -f recovery.* failover  \n', ""cat postgresql.conf | grep '#hot_standby = on'\n"", 'psql -c ""SELECT pg_start_backup(\'Streaming Replication\', true)"" postgresql://postgres@GreenDB/postgres\n', 'rsync -a $PG_DATA_Green_DB/ $BlueDB_IP:$PG_DATA_Blue_DB/ --exclude postmaster.pid --exclude postmaster.opts \n']"
1278,11208,11199,CC BY-SA 4.0,2020-04-01T14:35:34.233,"<h1>It just works</h1>

<p>Your configuration is correct.</p>

<p>Provided <code>YAML</code> file generates <code>nginx</code> config like this:</p>

<pre><code>...
server {
 listen       80;
 server_name  example.com;
 ...
 location ~* ""^/service/test"" {
   root    /var/www/example.com/htdocs;
 }
}
</code></pre>

<p>Testing this config via <a href=""https://nginx.viraptor.info/"" rel=""nofollow noreferrer"">this cool tester</a> shows that location filter works:</p>

<ul>
<li><code>http://example.com/service/test1</code> -> <code>Location: ^/service/test</code></li>
<li><code>http://example.com/service/test</code> -> <code>Location: ^/service/test</code></li>
<li><code>http://example.com/login</code> -> <code>Errors: No locations matched</code></li>
</ul>

<p>For more details, see <a href=""https://github.com/kubernetes/ingress-nginx/blob/5f2f0e5db3c3defd34da943002fd6c96835efcbc/docs/user-guide/ingress-path-matching.md"" rel=""nofollow noreferrer"">this explanation of Ingress Path Matching</a> and examples from <a href=""https://docs.nginx.com/nginx-ingress-controller/configuration/configuration-examples/"" rel=""nofollow noreferrer"">NGINX Docs</a>:</p>

<blockquote>
  <ul>
  <li><a href=""https://github.com/nginxinc/kubernetes-ingress/tree/v1.6.3/examples"" rel=""nofollow noreferrer""><em>Examples</em></a> show how to use advanced NGINX features in Ingress resources with annotations.</li>
  <li><a href=""https://github.com/nginxinc/kubernetes-ingress/tree/v1.6.3/examples-of-custom-resources"" rel=""nofollow noreferrer""><em>Examples of Custom Resources</em></a> show how to use VirtualServer and VirtualServerResources for a few use cases.</li>
  </ul>
</blockquote>

<h1>Check your app</h1>

<p>Check your app, maybe it forward non-authorized requests to <code>/login</code> url.
You may use <code>curl -v</code> or <code>wget</code>, e.g:</p>

<pre><code>curl -v -L http://example.com/service/test1 | egrep ""^&gt; (Host:|GET)""
</code></pre>

<pre><code>wget  http://example.com/service/test1 2&gt;&amp;1 | grep Location
</code></pre>

<h1>Howto debug <code>nginx ingress</code></h1>

<p>There is an <a href=""http://nginx.org/en/docs/debugging_log.html"" rel=""nofollow noreferrer""><code>Nginx</code> debug mode</a> for debugging <code>nginx</code> <code>locations</code> and redirects.
To enable it, use <code>--v=5</code> in <code>kubectl edit deploy</code>.</p>

<p>See: <a href=""https://kubernetes.github.io/ingress-nginx/troubleshooting/#debug-logging"" rel=""nofollow noreferrer"">k8s debug logging</a>:</p>

<blockquote>
  <p>Using the flag <code>--v=XX</code> it is possible to increase the level of logging. This is performed by editing the deployment.</p>

<pre><code>$ kubectl get deploy -n &lt;namespace-of-ingress-controller&gt;
NAME                       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
default-http-backend       1         1         1            1           35m
nginx-ingress-controller   1         1         1            1           35m

$ kubectl edit deploy -n &lt;namespace-of-ingress-controller&gt; nginx-ingress-controller
# Add --v=X to ""- args"", where X is an integer
</code></pre>
  
  <blockquote>
    <ul>
    <li><code>--v=2</code> shows details using <code>diff</code> about the changes in the configuration in nginx</li>
    <li><code>--v=3</code> shows details about the service, Ingress rule, endpoint changes and it dumps the nginx configuration in JSON format</li>
    <li><code>--v=5</code> configures NGINX in <a href=""http://nginx.org/en/docs/debugging_log.html"" rel=""nofollow noreferrer"">debug mode</a></li>
    </ul>
  </blockquote>
</blockquote>
",20042,2020-04-03T19:34:35.227,"['...\nserver {\n listen       80;\n server_name  example.com;\n ...\n location ~* ""^/service/test"" {\n   root    /var/www/example.com/htdocs;\n }\n}\n', 'curl -v -L http://example.com/service/test1 | egrep ""^> (Host:|GET)""\n', 'wget  http://example.com/service/test1 2>&1 | grep Location\n', '$ kubectl get deploy -n <namespace-of-ingress-controller>\nNAME                       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\ndefault-http-backend       1         1         1            1           35m\nnginx-ingress-controller   1         1         1            1           35m\n\n$ kubectl edit deploy -n <namespace-of-ingress-controller> nginx-ingress-controller\n# Add --v=X to ""- args"", where X is an integer\n']"
1279,11216,11214,CC BY-SA 4.0,2020-04-02T14:36:33.793,"<p>The <a href=""https://docs.ansible.com/ansible/latest/modules/command_module.html#command-module"" rel=""nofollow noreferrer"">Ansible documentation</a> states that the command module doesn't get a shell </p>

<blockquote>
  <p>The command(s) will not be processed through the shell</p>
</blockquote>

<p>The <code>command</code> module takes the command as an argument, so you can't have  list as you've written there. You could do the same thing in a <code>loop:</code> with <code>command: {{ item }}</code> : </p>

<pre><code>- name: ""Run {{ item }}""
  command: ""{{ item }}""
  loop:
    - cmd2
    - cmd2 
    - cmd3
</code></pre>

<p>You could also have several <code>command:</code> tasks instead.</p>

<p>However, this is generally considered bad practice (E.g. E303 from <a href=""https://docs.ansible.com/ansible-lint/rules/default_rules.html"" rel=""nofollow noreferrer"">Ansible Lint rules</a>) because it tends to break idempotency. It would be better to decompose those commands into something that uses Ansible modules.</p>
",354,2020-04-02T14:36:33.793,"['- name: ""Run {{ item }}""\n  command: ""{{ item }}""\n  loop:\n    - cmd2\n    - cmd2 \n    - cmd3\n']"
1280,11221,11196,CC BY-SA 4.0,2020-04-02T18:59:25.937,"<p>Actually, there are two questions:</p>

<ul>
<li>Where default(100) value is declared?</li>
<li>How can I see <code>Stats target</code> value before applying <code>SET default_statistics_target=1000</code></li>
</ul>

<h2>Where default(100) value is declared?</h2>

<p>You can see it in the <a href=""https://github.com/postgres/postgres/blob/master/src/backend/utils/misc/guc.c#L2092"" rel=""nofollow noreferrer"">source code</a> </p>

<blockquote>
<pre><code>{
      {""default_statistics_target"", PGC_USERSET, QUERY_TUNING_OTHER,
          gettext_noop(""Sets the default statistics target.""),
          gettext_noop(""This applies to table columns that have not had a ""
                       ""column-specific target set via ALTER TABLE SET STATISTICS."")
      },
      &amp;default_statistics_target,
      100, 1, 10000,
      NULL, NULL, NULL
  },
</code></pre>
</blockquote>

<h2>How can I see <code>Stats target</code> value before applying <code>SET default_statistics_target=1000</code> ?</h2>

<p>Let's suppose that column <code>bar</code> of table <code>foo</code> has  <code>attstattarget=500</code>:</p>

<pre><code>alter table foo alter column bar set statistics 500;
</code></pre>

<p>So, there are two ways to show <code>attstattarget</code></p>

<ul>
<li>SQL_query:</li>
</ul>

<pre><code>SELECT attrelid::regclass, attname, attstattarget FROM pg_attribute WHERE attstattarget &gt; 0 order by attstattarget desc;

 attrelid | attname | attstattarget
----------+---------+---------------
 foo      | bar     |           500
</code></pre>

<ul>
<li><code>\d+</code> command:</li>
</ul>

<pre><code>\d+ foo

                                                            Table ""public.foo""
          Column           |            Type             |                  Modifiers                   | Storage  | Stats target | Description
---------------------------+-----------------------------+----------------------------------------------+----------+--------------+-------------
 bar                       | varchar                     | not null                                     | plain    | 500          |
</code></pre>

<p>** Note**: <code>Postgres</code> doesn't show <code>stats target</code> until it distinct from default value.</p>

<h2><code>300</code> - yet another magic number</h2>

<p>Thx to <a href=""https://dba.stackexchange.com/questions/200136/postgresql-what-the-default-statistics-target-value-really-means#comment450743_200177"">this comment</a>, you can read a <a href=""http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.53.1734&amp;rep=rep1&amp;type=pdf"" rel=""nofollow noreferrer"">paper</a> about another magic number and check it in the <a href=""https://github.com/postgres/postgres/blob/REL_11_STABLE/src/backend/commands/analyze.c#L1832"" rel=""nofollow noreferrer"">source code</a>:</p>

<blockquote>
<pre><code>/*
   * Determine which standard statistics algorithm to use
   */
  if (OidIsValid(eqopr) &amp;&amp; OidIsValid(ltopr))
  {
      /* Seems to be a scalar datatype */
      stats-&gt;compute_stats = compute_scalar_stats;
      /*--------------------
       * The following choice of minrows is based on the paper
       * ""Random sampling for histogram construction: how much is enough?""
       * by Surajit Chaudhuri, Rajeev Motwani and Vivek Narasayya, in
       * Proceedings of ACM SIGMOD International Conference on Management
       * of Data, 1998, Pages 436-447.  Their Corollary 1 to Theorem 5
       * says that for table size n, histogram size k, maximum relative
       * error in bin size f, and error probability gamma, the minimum
       * random sample size is
       *      r = 4 * k * ln(2*n/gamma) / f^2
       * Taking f = 0.5, gamma = 0.01, n = 10^6 rows, we obtain
       *      r = 305.82 * k
       * Note that because of the log function, the dependence on n is
       * quite weak; even at n = 10^12, a 300*k sample gives &lt;= 0.66
       * bin size error with probability 0.99.  So there's no real need to
       * scale for n, which is a good thing because we don't necessarily
       * know it at this point.
       *--------------------
       */
      stats-&gt;minrows = 300 * attr-&gt;attstattarget;
  }
  else if (OidIsValid(eqopr))
  {
      /* We can still recognize distinct values */
      stats-&gt;compute_stats = compute_distinct_stats;
      /* Might as well use the same minrows as above */
      stats-&gt;minrows = 300 * attr-&gt;attstattarget;
  }
  else
  {
      /* Can't do much but the trivial stuff */
      stats-&gt;compute_stats = compute_trivial_stats;
      /* Might as well use the same minrows as above */
      stats-&gt;minrows = 300 * attr-&gt;attstattarget;
  }
</code></pre>
</blockquote>
",20042,2020-04-02T18:59:25.937,"['{\n      {""default_statistics_target"", PGC_USERSET, QUERY_TUNING_OTHER,\n          gettext_noop(""Sets the default statistics target.""),\n          gettext_noop(""This applies to table columns that have not had a ""\n                       ""column-specific target set via ALTER TABLE SET STATISTICS."")\n      },\n      &default_statistics_target,\n      100, 1, 10000,\n      NULL, NULL, NULL\n  },\n', 'alter table foo alter column bar set statistics 500;\n', 'SELECT attrelid::regclass, attname, attstattarget FROM pg_attribute WHERE attstattarget > 0 order by attstattarget desc;\n\n attrelid | attname | attstattarget\n----------+---------+---------------\n foo      | bar     |           500\n', '\\d+ foo\n\n                                                            Table ""public.foo""\n          Column           |            Type             |                  Modifiers                   | Storage  | Stats target | Description\n---------------------------+-----------------------------+----------------------------------------------+----------+--------------+-------------\n bar                       | varchar                     | not null                                     | plain    | 500          |\n', '/*\n   * Determine which standard statistics algorithm to use\n   */\n  if (OidIsValid(eqopr) && OidIsValid(ltopr))\n  {\n      /* Seems to be a scalar datatype */\n      stats->compute_stats = compute_scalar_stats;\n      /*--------------------\n       * The following choice of minrows is based on the paper\n       * ""Random sampling for histogram construction: how much is enough?""\n       * by Surajit Chaudhuri, Rajeev Motwani and Vivek Narasayya, in\n       * Proceedings of ACM SIGMOD International Conference on Management\n       * of Data, 1998, Pages 436-447.  Their Corollary 1 to Theorem 5\n       * says that for table size n, histogram size k, maximum relative\n       * error in bin size f, and error probability gamma, the minimum\n       * random sample size is\n       *      r = 4 * k * ln(2*n/gamma) / f^2\n       * Taking f = 0.5, gamma = 0.01, n = 10^6 rows, we obtain\n       *      r = 305.82 * k\n       * Note that because of the log function, the dependence on n is\n       * quite weak; even at n = 10^12, a 300*k sample gives <= 0.66\n       * bin size error with probability 0.99.  So there\'s no real need to\n       * scale for n, which is a good thing because we don\'t necessarily\n       * know it at this point.\n       *--------------------\n       */\n      stats->minrows = 300 * attr->attstattarget;\n  }\n  else if (OidIsValid(eqopr))\n  {\n      /* We can still recognize distinct values */\n      stats->compute_stats = compute_distinct_stats;\n      /* Might as well use the same minrows as above */\n      stats->minrows = 300 * attr->attstattarget;\n  }\n  else\n  {\n      /* Can\'t do much but the trivial stuff */\n      stats->compute_stats = compute_trivial_stats;\n      /* Might as well use the same minrows as above */\n      stats->minrows = 300 * attr->attstattarget;\n  }\n']"
1281,11227,11223,CC BY-SA 4.0,2020-04-03T10:06:31.183,"<p>It works in dotted notation (Object.apiVersion.APIGroup), for e.g. deployments this way: <code>kubectl get deployments.v1.apps</code> In your case just try:</p>

<pre><code>kubectl get issuer.v1alpha2.cert-manager.io -n=default
</code></pre>
",21503,2020-04-03T10:06:31.183,['kubectl get issuer.v1alpha2.cert-manager.io -n=default\n']
1282,11235,11234,CC BY-SA 4.0,2020-04-03T22:09:57.057,"<p>Well of course its always the same - as soon as you actually do ask for help you figure it out...</p>

<pre><code>resource ""kubernetes_persistent_volume"" ""nodeconfig"" {
  metadata {
    name = ""nodeconfig""
    labels = {
      a = ""a""
    }
  }
  spec {
    capacity = {
      storage = ""25Gi""
    }
    storage_class_name               = ""nodeconfig""
    persistent_volume_reclaim_policy = ""Retain""
    access_modes                     = [""ReadOnlyMany""]
    persistent_volume_source {
      local {
        path = ""/mnt/nodeconfig""
      }
    }
    node_affinity {
      required {
        node_selector_term {
          match_expressions {
            key = ""kubernetes.io/hostname""
            operator = ""In""
            values = [var.config.RGs.Primary.clustervmhost]  # must mnanually put this one in
          }
        }
      }
    }
  }
}
</code></pre>

<p>So the docs were a bit off of the lists of lists, it was a map of maps of lists.</p>
",20251,2020-04-03T22:09:57.057,"['resource ""kubernetes_persistent_volume"" ""nodeconfig"" {\n  metadata {\n    name = ""nodeconfig""\n    labels = {\n      a = ""a""\n    }\n  }\n  spec {\n    capacity = {\n      storage = ""25Gi""\n    }\n    storage_class_name               = ""nodeconfig""\n    persistent_volume_reclaim_policy = ""Retain""\n    access_modes                     = [""ReadOnlyMany""]\n    persistent_volume_source {\n      local {\n        path = ""/mnt/nodeconfig""\n      }\n    }\n    node_affinity {\n      required {\n        node_selector_term {\n          match_expressions {\n            key = ""kubernetes.io/hostname""\n            operator = ""In""\n            values = [var.config.RGs.Primary.clustervmhost]  # must mnanually put this one in\n          }\n        }\n      }\n    }\n  }\n}\n']"
1283,11236,11228,CC BY-SA 4.0,2020-04-03T23:03:37.293,"<p>Without seeing the contents of your two modules I'm guessing a bit, but it looks like you have an AWS VPC declared in your <code>vpc</code> module and some subnets declared in your <code>prod_subnets</code> module and you are asking how the configuration of the subnets can get access to the VPC ID.</p>

<p>If so, the answer is that the <code>vpc</code> module must export the VPC ID as an <a href=""https://www.terraform.io/docs/configuration/outputs.html"" rel=""nofollow noreferrer"">output value</a> and then the <code>prod_subnets</code> module must accept the VPC ID as an <a href=""https://www.terraform.io/docs/configuration/variables.html"" rel=""nofollow noreferrer"">input variable</a>.</p>

<p>In your <code>vpc</code> module, you can declare a <code>vpc_id</code> output value like this, for example in a file <code>modules/vpc/outputs.tf</code>:</p>

<pre><code>output ""vpc_id"" {
  value = aws_vpc.production_vpc
}
</code></pre>

<p>In your <code>prod_subnets</code> module you can declare a <code>vpc_id</code> input variable, for example in a file <code>modules/vpc/modules/subnets/production/outputs.tf</code>:</p>

<pre><code>variable ""vpc_id"" {
  type = string
}
</code></pre>

<p>Then in your existing <code>modules/vpc/modules/subnets/production/production.tf</code> file, on line 162, change the <code>vpc_id</code> argument for the subnet to refer to that variable:</p>

<pre><code>  vpc_id = var.vpc_id
</code></pre>

<p>Finally, you must then edit the top-level file whose source code you shared in your question to pass the value between the two modules, like this:</p>

<pre><code>module ""vpc"" {
  source = ""./modules/vpc""
}

module ""prod_subnets"" {
  source = ""./modules/vpc/modules/subnets/production""

  vpc_id = module.vpc.vpc_id
}
</code></pre>

<p><code>module.vpc.vpc_id</code> means to take the value of the <code>vpc_id</code> output value from the <code>vpc</code> module.</p>
",2463,2020-04-03T23:03:37.293,"['output ""vpc_id"" {\n  value = aws_vpc.production_vpc\n}\n', 'variable ""vpc_id"" {\n  type = string\n}\n', '  vpc_id = var.vpc_id\n', 'module ""vpc"" {\n  source = ""./modules/vpc""\n}\n\nmodule ""prod_subnets"" {\n  source = ""./modules/vpc/modules/subnets/production""\n\n  vpc_id = module.vpc.vpc_id\n}\n']"
1284,11240,11173,CC BY-SA 4.0,2020-04-05T02:15:21.487,"<p>As promised, here is a solution using haproxy with sticky cookies. Note, that this approach requires support on the application side (as only your application layer may know once transactions are completed).</p>

<p>To achieve this, first - start with haproxy configuration of the following kind: </p>

<pre><code>    global
        daemon
        maxconn 256
    defaults
        mode http
        timeout connect 5000ms
        timeout client 50000ms
        timeout server 50000ms

    frontend http-in
        bind *:80
        default_backend servers

    backend servers
        balance roundrobin
        cookie SID insert indirect preserve
        server server1 blue-server-hostname:8000 cookie sblue
</code></pre>

<p>Note that this configuration is pretty generic and taken from haproxy documentation - from here: <a href=""https://cbonte.github.io/haproxy-dconv/2.2/configuration.html#2.5"" rel=""nofollow noreferrer"">https://cbonte.github.io/haproxy-dconv/2.2/configuration.html#2.5</a></p>

<p>The part that is used to achieve stickiness is cookie instruction that is added in the end, detailed documentation here: <a href=""https://cbonte.github.io/haproxy-dconv/2.2/configuration.html#4-cookie"" rel=""nofollow noreferrer"">https://cbonte.github.io/haproxy-dconv/2.2/configuration.html#4-cookie</a></p>

<p>So, with this line:</p>

<pre><code>cookie SID insert indirect preserve
</code></pre>

<p>we tell haproxy to insert cookie called <strong>SID</strong> which may only have value <strong>sblue</strong> for now (this value is defined in last line of configuration). And we also say that if this cookie is supplied by the back-end server, we don't want haproxy to overwrite it (achieved by <strong>insert</strong> and <strong>preserve</strong> keywords).</p>

<p>The next part is to add some application level logic to set <strong>SID</strong> cookie to client and make its value configurable on the application side. You want to set <strong>SID</strong> cookie to <strong>sblue</strong> for your old code and to <strong>sgreen</strong> for your new code.</p>

<p>Now, when you do deployment, at first you have only blue instance, all your <strong>SID</strong> cookies are set to <strong>sblue</strong> and haproxy directs all your traffic to the only blue instance.</p>

<p>Next, you add your green instance, and after that you add it to haproxy by adding the following line to the end of configuration above:</p>

<pre><code>server server2 green-server-hostname:8000 cookie sgreen
</code></pre>

<p>Now any request which gets to your new green instance would have its cookie set to sgreen and would stick to the new instance.</p>

<p>Finally, you want to engage your application-level configuration on the old blue instance to set cookie to <strong>sgreen</strong> to clients once their transaction is over (basically, at the point where application knows it's safe to do so). Then any new requests from such clients would be directed to green instance. At some point all your requests would be transitioned to green - and you can detach blue instance at that point.</p>

<p>This kind of approach (or its variations) would be the most graceful and controlled by your application-layer transaction logic.</p>
",19963,2020-04-05T02:15:21.487,"['    global\n        daemon\n        maxconn 256\n    defaults\n        mode http\n        timeout connect 5000ms\n        timeout client 50000ms\n        timeout server 50000ms\n\n    frontend http-in\n        bind *:80\n        default_backend servers\n\n    backend servers\n        balance roundrobin\n        cookie SID insert indirect preserve\n        server server1 blue-server-hostname:8000 cookie sblue\n', 'cookie SID insert indirect preserve\n', 'server server2 green-server-hostname:8000 cookie sgreen\n']"
1285,11254,1626,CC BY-SA 4.0,2020-04-06T06:22:46.017,"<p>Add the following policy if you want to access from FTP software like <strong>WinSCP</strong>, <strong>CyberDuck</strong>, etc.</p>

<pre><code>{
  ""Version"": ""2012-10-17"",
  ""Statement"": [
    {
      ""Effect"": ""Allow"",
      ""Action"": [
        ""s3:GetBucketLocation"",
        ""s3:ListAllMyBuckets""
      ],
      ""Resource"": ""*""
    },
    {
      ""Effect"": ""Allow"",
      ""Action"": [""s3:ListBucket""],
      ""Resource"": [
            ""arn:aws:s3:::test1"",
            ""arn:aws:s3:::test2""
        ]
    },
    {
      ""Effect"": ""Allow"",
      ""Action"": [
        ""s3:PutObject"",
        ""s3:GetObject"",
        ""s3:DeleteObject""
      ],
      ""Resource"": [
            ""arn:aws:s3:::test1/*"",
            ""arn:aws:s3:::test2/*""
        ]
    }
  ]
}
</code></pre>

<p>I learnt from <a href=""https://aws.amazon.com/blogs/security/writing-iam-policies-how-to-grant-access-to-an-amazon-s3-bucket/"" rel=""nofollow noreferrer"">Writing IAM Policies: How to Grant Access to an Amazon S3 Bucket</a></p>
",5454,2020-04-06T06:22:46.017,"['{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""s3:GetBucketLocation"",\n        ""s3:ListAllMyBuckets""\n      ],\n      ""Resource"": ""*""\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [""s3:ListBucket""],\n      ""Resource"": [\n            ""arn:aws:s3:::test1"",\n            ""arn:aws:s3:::test2""\n        ]\n    },\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": [\n        ""s3:PutObject"",\n        ""s3:GetObject"",\n        ""s3:DeleteObject""\n      ],\n      ""Resource"": [\n            ""arn:aws:s3:::test1/*"",\n            ""arn:aws:s3:::test2/*""\n        ]\n    }\n  ]\n}\n']"
1286,11260,9444,CC BY-SA 4.0,2020-04-06T18:01:05.363,"<p>You need the <code>--with-registry-auth</code> flag, e.g.:</p>

<pre><code>docker stack deploy -c myapp.yml --with-registry-auth myapp
</code></pre>

<p>From the <code>docker stack deploy --help</code> output:</p>

<pre><code>--with-registry-auth     Send registry authentication details to Swarm agents 
</code></pre>
",7730,2020-04-06T18:01:05.363,"['docker stack deploy -c myapp.yml --with-registry-auth myapp\n', '--with-registry-auth     Send registry authentication details to Swarm agents \n']"
1287,11265,4218,CC BY-SA 4.0,2020-04-07T09:50:50.930,"<p>I know that is not the clean solution everybody looks for and is a nasty workaround, but what worked for me was to squash all my deployment logic into a single Script Task (shell script) and then put the necessary conditions there, such as:</p>

<pre><code>if [ &lt;put condition for terminate here&gt; ] ; then 
   exit 0
fi 
&lt;Continue with other execution logic&gt;
</code></pre>

<p>In that way, you can exit with 0 (thus build shows as successful) , but of course that prevents you from reusing all of the out-of-the-box Bamboo Task types that are readily available and questions the benefits of using the bamboo framework as a wrapper.</p>
",21562,2020-04-07T09:50:50.930,['if [ <put condition for terminate here> ] ; then \n   exit 0\nfi \n<Continue with other execution logic>\n']
1288,11268,6787,CC BY-SA 4.0,2020-04-07T23:07:11.403,"<p>Supposing the scenario with two accounts A &amp; B the explanatory steps should be:</p>

<ol>
<li>In <strong>account A</strong>, I created a <strong>role</strong> (e.g <code>RoleForB</code>) to trust <strong>account B</strong>, and attach to the before created role a <strong>IAM policy</strong> to allow it to perform some read operations in <strong>account A</strong>. <code>e.g ReadOnlyAccess</code></li>
<li>In <strong>account B</strong>, I created a <strong>role</strong> (e.g <code>AssumeRoleInA</code>) and attach a <strong>policy</strong> to allow it to assume the role that is created in <strong>account A</strong>.</li>
<li>In <strong>account B</strong> Associate to your EC2 instance <code>ec2-profile</code> the IAM role (<code>AssumeRoleInA</code>) created in step 2.</li>
<li>In <strong>account B</strong> login into this EC2 instance to <strong>assume the role</strong> in <strong>Account A</strong> using the command <code>aws sts assume-role --role-arn ""arn:aws:iam::Account_A_ID:role/RoleForB"" --role-session-name ""EC2FromB""</code>.</li>
<li>In <strong>account B</strong> EC2 terminal when the command is <strong>step 4.</strong> finished, you can see the <strong>access key ID, secret access key, and session token</strong> from wherever you've routed it, in our case <code>stdout</code> either manually or by using a script. You can then assign these values to environment variables (<code>AWS_ACCESS_KEY_ID</code>, <code>AWS_SECRET_ACCESS_KEY</code>, <code>AWS_SESSION_TOKEN</code>)</li>
</ol>

<p>So Let’s check the configurations mentioned above step by step but with some mode detail:</p>

<ol>
<li>As before presented in <strong>account A</strong>, it builds the trust to <strong>account B</strong> by creating the role named <code>RoleForB</code> and attaching <code>ReadOnlyAccess</code> permission to it.</li>
</ol>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": {
        ""Effect"": ""Allow"",
        ""Principal"": {""AWS"": ""arn:aws:iam::Account_B_ID:root""},
        ""Action"": ""sts:AssumeRole""
    }
}
</code></pre>

<ol start=""2"">
<li>In <strong>account B</strong>, create a <strong>role</strong> named <code>AssumeRoleInA</code> then attach the corresponding <code>policy</code> to allow it to assume the role named <code>RoleForB</code> in <strong>account A</strong>.</li>
</ol>

<pre><code>{
  ""Version"": ""2012-10-17"",
  ""Statement"": [
    {
      ""Effect"": ""Allow"",
      ""Action"": ""sts:AssumeRole"",
      ""Resource"": [
        ""arn:aws:iam::Account_A_ID:role/RoleForB""
      ]
    }
  ]
}
</code></pre>

<ol start=""3"">
<li>In <strong>account B</strong>, create a new <strong>EC2 instance</strong> (if it does not exists yet), and associate it's <strong>ec2-profile</strong> with the <strong>IAM role</strong> named <code>AssumeRoleInA</code>.</li>
</ol>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": {
        ""Effect"": ""Allow"",
        ""Principal"": {""Service"": ""ec2.amazonaws.com""},
        ""Action"": ""sts:AssumeRole""
    }
}
</code></pre>

<ol start=""4"">
<li>In <strong>account B</strong> login into this EC2 instance to <strong>assume the role</strong> in <strong>Account A</strong> using the command: </li>
</ol>

<pre><code>aws sts assume-role --role-arn ""arn:aws:iam::Account_A_ID:role/RoleForB"" --role-session-name ""EC2FromB""`
</code></pre>

<p>eg:</p>

<pre><code>jenkins@bb-jenkins-vault:~$ aws sts assume-role --role-arn arn:aws:iam::521111111144:role/DeployMaster --role-session-name ""project-dev-jenkins-deploy""
{
    ""AssumedRoleUser"": {
        ""AssumedRoleId"": ""AROAJBXGEHOQBXGEHOQ:project-dev-jenkins-deploy"", 
        ""Arn"": ""arn:aws:sts::521111111144:assumed-role/DeployMaster/project-dev-jenkins-deploy""
    }, 
    ""Credentials"": {
        ""SecretAccessKey"": ""wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"", 
        ""SessionToken"": ""FQoGZXIvYXCUm8iG6/zLdQ7foognvCDpxKP7cRJiZgc...CUm8iG6/zLdQ7foognvCDpxKP7c+OQF"", 
        ""Expiration"": ""2019-03-29T15:41:02Z"", 
        ""AccessKeyId"": ""AKIAI44QH8DHBEXAMPLE""
    }
}
</code></pre>

<ol start=""5"">
<li>In <strong>account B</strong> EC2 terminal when the command is <strong>step 4.</strong> finished, you can see the <strong>access key ID, secret access key, and session token</strong> from wherever you've routed it, in our case <code>stdout</code> either manually or by using a script. You can then assign these values to environment variables</li>
</ol>

<pre><code>$ export AWS_ACCESS_KEY_ID=AKIAI44QH8DHBEXAMPLE
$ export AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
$ export AWS_SESSION_TOKEN=FQoGZXIvYXCUm8iG6/zLdQ...&lt;remainder of security token&gt;
$ aws ec2 describe-instances --region us-east-1
</code></pre>

<p><strong>credit:</strong> <a href=""https://stackoverflow.com/a/55420220/6657158"">https://stackoverflow.com/a/55420220/6657158</a></p>
",21575,2020-04-08T00:16:11.713,"['{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": {\n        ""Effect"": ""Allow"",\n        ""Principal"": {""AWS"": ""arn:aws:iam::Account_B_ID:root""},\n        ""Action"": ""sts:AssumeRole""\n    }\n}\n', '{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Action"": ""sts:AssumeRole"",\n      ""Resource"": [\n        ""arn:aws:iam::Account_A_ID:role/RoleForB""\n      ]\n    }\n  ]\n}\n', '{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": {\n        ""Effect"": ""Allow"",\n        ""Principal"": {""Service"": ""ec2.amazonaws.com""},\n        ""Action"": ""sts:AssumeRole""\n    }\n}\n', 'aws sts assume-role --role-arn ""arn:aws:iam::Account_A_ID:role/RoleForB"" --role-session-name ""EC2FromB""`\n', 'jenkins@bb-jenkins-vault:~$ aws sts assume-role --role-arn arn:aws:iam::521111111144:role/DeployMaster --role-session-name ""project-dev-jenkins-deploy""\n{\n    ""AssumedRoleUser"": {\n        ""AssumedRoleId"": ""AROAJBXGEHOQBXGEHOQ:project-dev-jenkins-deploy"", \n        ""Arn"": ""arn:aws:sts::521111111144:assumed-role/DeployMaster/project-dev-jenkins-deploy""\n    }, \n    ""Credentials"": {\n        ""SecretAccessKey"": ""wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY"", \n        ""SessionToken"": ""FQoGZXIvYXCUm8iG6/zLdQ7foognvCDpxKP7cRJiZgc...CUm8iG6/zLdQ7foognvCDpxKP7c+OQF"", \n        ""Expiration"": ""2019-03-29T15:41:02Z"", \n        ""AccessKeyId"": ""AKIAI44QH8DHBEXAMPLE""\n    }\n}\n', '$ export AWS_ACCESS_KEY_ID=AKIAI44QH8DHBEXAMPLE\n$ export AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n$ export AWS_SESSION_TOKEN=FQoGZXIvYXCUm8iG6/zLdQ...<remainder of security token>\n$ aws ec2 describe-instances --region us-east-1\n']"
1289,11275,6163,CC BY-SA 4.0,2020-04-08T17:16:42.510,"<p>The most popular answer is out of date with Terraform in version 0.12.24.</p>

<p><code>depends_on</code> is a protected variable, and cannot be used in a <code>module</code>.
In addition there are a few syntax differences.</p>

<p>I've updated the example below.</p>

<pre><code># ROOT level main.tf
# -------------------------------------------------------------------
# Create NAT Gateway - Associates EIP as well
# -------------------------------------------------------------------
module ""vpc_nat_gateway"" {
  source            = ""./vpc_nat_gateway""
  vpc_id            = module.vpc.id
  public_subnet_ids = module.vpc_subnets.public_subnet_ids
  private_cidr      = var.private_cidr
  common_tags       = local.common_tags
}

# -------------------------------------------------------------------
# Create Private Routes
# -------------------------------------------------------------------
module ""vpc_private_route"" {
  source         = ""./vpc_private_route""
  vpc_id.        = module.vpc.id
  nat_gateway_id = module.vpc_nat_gateway.nat_gateway_id
  common_tags    = local.common_tags

  # Depends is a custom variable, depends_on is a reserved keyword.
  depends = [module.vpc_nat_gateway.nat_gateway_id]
}
</code></pre>

<pre><code># vpc_private_route module - main.tf
variable ""depends"" {
  default = []
}

resource ""null_resource"" ""depends_on"" {
  triggers = {
    depends_on = ""${join("""", var.depends)}""
  }
}

data ""aws_nat_gateway"" ""az1"" {
  vpc_id = var.vpc_id

  depends_on = [
    null_resource.depends_on
  ]
}

data ""aws_nat_gateway"" ""az2"" {
  vpc_id = var.vpc_id

  depends_on = [
    null_resource.depends_on
  ]
}
</code></pre>
",21596,2020-04-08T17:35:13.973,"['# ROOT level main.tf\n# -------------------------------------------------------------------\n# Create NAT Gateway - Associates EIP as well\n# -------------------------------------------------------------------\nmodule ""vpc_nat_gateway"" {\n  source            = ""./vpc_nat_gateway""\n  vpc_id            = module.vpc.id\n  public_subnet_ids = module.vpc_subnets.public_subnet_ids\n  private_cidr      = var.private_cidr\n  common_tags       = local.common_tags\n}\n\n# -------------------------------------------------------------------\n# Create Private Routes\n# -------------------------------------------------------------------\nmodule ""vpc_private_route"" {\n  source         = ""./vpc_private_route""\n  vpc_id.        = module.vpc.id\n  nat_gateway_id = module.vpc_nat_gateway.nat_gateway_id\n  common_tags    = local.common_tags\n\n  # Depends is a custom variable, depends_on is a reserved keyword.\n  depends = [module.vpc_nat_gateway.nat_gateway_id]\n}\n', '# vpc_private_route module - main.tf\nvariable ""depends"" {\n  default = []\n}\n\nresource ""null_resource"" ""depends_on"" {\n  triggers = {\n    depends_on = ""${join("""", var.depends)}""\n  }\n}\n\ndata ""aws_nat_gateway"" ""az1"" {\n  vpc_id = var.vpc_id\n\n  depends_on = [\n    null_resource.depends_on\n  ]\n}\n\ndata ""aws_nat_gateway"" ""az2"" {\n  vpc_id = var.vpc_id\n\n  depends_on = [\n    null_resource.depends_on\n  ]\n}\n']"
1290,11287,11283,CC BY-SA 4.0,2020-04-09T14:17:12.373,"<p>I'd recommend a temporary container for this. It will work on just about any version of docker, and supports named volumes with non-default settings, e.g. that store data on remote systems (e.g. NFS) or modify the bind mound settings to use another folder.</p>

<p>A simple example is:</p>

<pre><code>$ docker container run --rm -v ""${volume_name}:/volume"" -w /volume busybox df -P .
Filesystem           1024-blocks    Used Available Capacity Mounted on
/dev/..........              898086280 350169736 502226484  41% /volume
</code></pre>

<p>You can parse that output or reformat with the <code>df</code> command as appropriate for your use case. The busybox version of <code>df</code> will have fewer options than you may be used to:</p>

<pre><code>$ df --help
BusyBox v1.31.1 (2019-12-23 19:20:27 UTC) multi-call binary.

Usage: df [-PkmhTai] [-B SIZE] [FILESYSTEM]...

Print filesystem usage statistics

        -P      POSIX output format
        -k      1024-byte blocks (default)
        -m      1M-byte blocks
        -h      Human readable (e.g. 1K 243M 2G)
        -T      Print filesystem type
        -a      Show all filesystems
        -i      Inodes
        -B SIZE Blocksize
</code></pre>
",7730,2020-04-09T14:17:12.373,"['$ docker container run --rm -v ""${volume_name}:/volume"" -w /volume busybox df -P .\nFilesystem           1024-blocks    Used Available Capacity Mounted on\n/dev/..........              898086280 350169736 502226484  41% /volume\n', '$ df --help\nBusyBox v1.31.1 (2019-12-23 19:20:27 UTC) multi-call binary.\n\nUsage: df [-PkmhTai] [-B SIZE] [FILESYSTEM]...\n\nPrint filesystem usage statistics\n\n        -P      POSIX output format\n        -k      1024-byte blocks (default)\n        -m      1M-byte blocks\n        -h      Human readable (e.g. 1K 243M 2G)\n        -T      Print filesystem type\n        -a      Show all filesystems\n        -i      Inodes\n        -B SIZE Blocksize\n']"
1291,11289,11284,CC BY-SA 4.0,2020-04-09T15:38:52.253,"<p>You should first <a href=""https://docs.ansible.com/ansible/latest/modules/stat_module.htm"" rel=""nofollow noreferrer"">stat</a> for the password file, and then set the fact depending on whether the <a href=""https://docs.ansible.com/ansible/latest/modules/stat_module.html#return-stat/exists"" rel=""nofollow noreferrer"">file.stat.exists</a> or not. And both those tasks need to be performed for each user.</p>

<p>As of Ansible 2.4 you can dynamically <a href=""https://docs.ansible.com/ansible/latest/modules/include_tasks_module.html"" rel=""nofollow noreferrer"">include_tasks</a> and perform a <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html"" rel=""nofollow noreferrer"">loop</a> on it. Meaning that you can group a few tasks in a file and loop those tasks for every value in your loop-variable.</p>

<p>I think this should be able to solve your problem by creating a separate tasks file containing these tasks that should be run for each user:</p>

<p>Stat for the password-file:</p>

<pre class=""lang-yaml prettyprint-override""><code>   - name: Check if password-file exists for user
     stat:
        path: ""credentials/{{ item.username }}/password.txt""
     register: password_file
</code></pre>

<p>Next you can define your tmp_user var when the password.txt-file exists:</p>

<pre class=""lang-yaml prettyprint-override""><code>   - name: Set fact for user
     set_fact:
       tmp_user:
        - username: ""{{ item.username }}""
          first_name: ""{{ item.first_name }}""
          last_name: ""{{ item.last_name }}""
          email: ""{{ item.email }}""
          password: ""{{ lookup('password', 'credentials/' + item.username + '/password.txt length=15 chars=ascii_letters') }}""
          roles: ""{{ item.roles }}""
      when: password_file.stat.exists
      register: set_tmp_user
</code></pre>

<p>Then, if previous task defined a new fact tmp_user, that fact should be added to the tmp_users list. </p>

<pre class=""lang-yaml prettyprint-override""><code>   - name: Add user to list
     set_fact:
       tmp_users: {{ tmp_users + [ tmp_user ] }}
     when: not set_tmp_user is skipped
</code></pre>

<p>(not sure by head if you can use <code>when: set_tmp_user is changed</code> but <code>not is skipped</code> should do the job)</p>

<p>Then in you main tasks-file, you create an empty tmp_users list and call an include_tasks in a loop to loop through the above tasks:</p>

<pre class=""lang-yaml prettyprint-override""><code>   - name: Include users.yaml and setup all vars for nexus
     include_vars:
       file: users.yaml
       name: users

   - name: Initialize tmp_users
     set_fact:
        tmp_users: []

   - name: Set user facts
     include_tasks: set_user_facts.yml
     loop: ""{{ users.nexus_local_users }}""
</code></pre>

<p>Disclaimer: I have not been able to test this out, or check its syntax, but I assume the general idea of which I try to accomplish here should be clear?</p>

<p>Also be aware that you currently can't perform a loop inside the included tasks file as that loop will by default overwrite the <code>item</code>-variable defined by the tasks-loop. See <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html#defining-inner-and-outer-variable-names-with-loop-var"" rel=""nofollow noreferrer"">defining inner and outer variable names with loop var</a> to solve this.</p>

<p>And an additional tip: add a debug task as first task to your included tasks file to output the current <code>item.username</code> in the loop.</p>
",14664,2020-04-09T15:38:52.253,"['   - name: Check if password-file exists for user\n     stat:\n        path: ""credentials/{{ item.username }}/password.txt""\n     register: password_file\n', '   - name: Set fact for user\n     set_fact:\n       tmp_user:\n        - username: ""{{ item.username }}""\n          first_name: ""{{ item.first_name }}""\n          last_name: ""{{ item.last_name }}""\n          email: ""{{ item.email }}""\n          password: ""{{ lookup(\'password\', \'credentials/\' + item.username + \'/password.txt length=15 chars=ascii_letters\') }}""\n          roles: ""{{ item.roles }}""\n      when: password_file.stat.exists\n      register: set_tmp_user\n', '   - name: Add user to list\n     set_fact:\n       tmp_users: {{ tmp_users + [ tmp_user ] }}\n     when: not set_tmp_user is skipped\n', '   - name: Include users.yaml and setup all vars for nexus\n     include_vars:\n       file: users.yaml\n       name: users\n\n   - name: Initialize tmp_users\n     set_fact:\n        tmp_users: []\n\n   - name: Set user facts\n     include_tasks: set_user_facts.yml\n     loop: ""{{ users.nexus_local_users }}""\n']"
1292,11292,11276,CC BY-SA 4.0,2020-04-09T16:07:22.087,"<p>Before giving the answer I'd like to clarify that S3 is meant for <em>object</em> storage, meaning that there's no file system involved and thus there are not ""directories"" per se.</p>

<p>So, an ""object"" with the name ""/avatars/user-123/xyz"" might give you the impression that it's stored in the ""/avatars/user-123"" directory, but there's no directory involved, that's just a name.</p>

<p>That being said, you can treat that portion of the name (/avatars/user-123) as a prefix, and then you can create IAM policies for your S3 buckets using said prefixes.</p>

<p>For futre reference, the following examples have been taken from:
<a href=""https://aws.amazon.com/premiumsupport/knowledge-center/s3-folder-user-access/"" rel=""nofollow noreferrer"">https://aws.amazon.com/premiumsupport/knowledge-center/s3-folder-user-access/</a></p>

<p>In case readers find out that link has been taken down I'll just copy and paste the examples here</p>

<p>AllowStatement1 allows the user to list the buckets that belong to their AWS account. The user needs this permission to be able to navigate to the bucket using the console.</p>

<p>AllowStatement2A allows the user to list the folders within awsexamplebucket, which the user needs to be able to navigate to the folder using the console. The statement also allows the user to search on the prefix media/ using the console.</p>

<p>AllowStatement3 allows the user to list the contents within awsexamplebucket/media.</p>

<p>AllowStatement4A allows the user to download objects (s3:GetObject) from the folder awsexamplebucket/media.</p>

<pre><code>{
 ""Version"":""2012-10-17"",
 ""Statement"": [
   {
     ""Sid"": ""AllowStatement1"",
     ""Action"": [""s3:ListAllMyBuckets"", ""s3:GetBucketLocation""],
     ""Effect"": ""Allow"",
     ""Resource"": [""arn:aws:s3:::*""]
   },
  {
     ""Sid"": ""AllowStatement2A"",
     ""Action"": [""s3:ListBucket""],
     ""Effect"": ""Allow"",
     ""Resource"": [""arn:aws:s3:::awsexamplebucket""],
     ""Condition"":{""StringEquals"":{""s3:prefix"":["""",""media""]}}
    },
  {
     ""Sid"": ""AllowStatement3"",
     ""Action"": [""s3:ListBucket""],
     ""Effect"": ""Allow"",
     ""Resource"": [""arn:aws:s3:::awsexamplebucket""],
     ""Condition"":{""StringLike"":{""s3:prefix"":[""media/*""]}}
    },    
   {
     ""Sid"": ""AllowStatement4A"",
     ""Effect"": ""Allow"",
     ""Action"": [""s3:GetObject""],
     ""Resource"": [""arn:aws:s3:::awsexamplebucket/media/*""]
   }
 ]
}



</code></pre>
",7498,2020-04-09T16:07:22.087,"['{\n ""Version"":""2012-10-17"",\n ""Statement"": [\n   {\n     ""Sid"": ""AllowStatement1"",\n     ""Action"": [""s3:ListAllMyBuckets"", ""s3:GetBucketLocation""],\n     ""Effect"": ""Allow"",\n     ""Resource"": [""arn:aws:s3:::*""]\n   },\n  {\n     ""Sid"": ""AllowStatement2A"",\n     ""Action"": [""s3:ListBucket""],\n     ""Effect"": ""Allow"",\n     ""Resource"": [""arn:aws:s3:::awsexamplebucket""],\n     ""Condition"":{""StringEquals"":{""s3:prefix"":["""",""media""]}}\n    },\n  {\n     ""Sid"": ""AllowStatement3"",\n     ""Action"": [""s3:ListBucket""],\n     ""Effect"": ""Allow"",\n     ""Resource"": [""arn:aws:s3:::awsexamplebucket""],\n     ""Condition"":{""StringLike"":{""s3:prefix"":[""media/*""]}}\n    },    \n   {\n     ""Sid"": ""AllowStatement4A"",\n     ""Effect"": ""Allow"",\n     ""Action"": [""s3:GetObject""],\n     ""Resource"": [""arn:aws:s3:::awsexamplebucket/media/*""]\n   }\n ]\n}\n\n\n\n']"
1293,11296,9002,CC BY-SA 4.0,2020-04-10T05:09:53.563,"<pre><code>volumes:
  - /usr/local/db-backup:/var/lib/mysql # On Linux, For backup data from the docker container to the host
  - D:/Docker_volumes/mysql/db-backup:/var/lib/mysql # On Windows, you need to config File Sharing with ""D:"" mounted when starting docker.
</code></pre>
",21624,2020-04-10T05:09:53.563,"['volumes:\n  - /usr/local/db-backup:/var/lib/mysql # On Linux, For backup data from the docker container to the host\n  - D:/Docker_volumes/mysql/db-backup:/var/lib/mysql # On Windows, you need to config File Sharing with ""D:"" mounted when starting docker.\n']"
1294,11298,11284,CC BY-SA 4.0,2020-04-10T10:00:39.637,"<p>I solved this with the Jinja test ""exists"" and the select filter to filter away the resulting 'AnsibleUndefined' values. The ""is exists"" test checks if the path exists on the ansible control host. This is the place the credentials are stored.</p>

<p>The solved code is below:</p>

<pre class=""lang-yaml prettyprint-override""><code>    ---
    - hosts: localhost
      tasks:
      - name: Include users.yaml and setup all vars for nexus
        include_vars:
          file: users.yaml
          name: users
      - set_fact:
          tmp_user:
          - username: ""{{ item.username }}""
            first_name: ""{{ item.first_name }}""
            last_name: ""{{ item.last_name }}""
            email: ""{{ item.email }}""
            password: ""{{ lookup('password', 'credentials/' + item.username + '/password.txt length=15 chars=ascii_letters') }}""
            roles: ""{{ item.roles }}""
        loop: ""{{ users.nexus_local_users }}""
        register: tmp_users
        when: ""not '{{ playbook_dir }}/credentials/{{ item.username }}/password.txt' is exists""
      - set_fact:
          tmp_user: ""{{ item.ansible_facts.tmp_user | combine(item.item) }}""
        with_items: ""{{ tmp_users.results }}""
        register: tmp_users_sorted
        when: ""not item is skipped""
      - set_fact:
          nexus_local_users: ""{{ tmp_users_sorted.results | map(attribute='item.ansible_facts.tmp_user') | list | select('defined') | list }}""
      - debug:
          msg: ""{{ nexus_local_users }}""
</code></pre>

<p>The following was added/changed:</p>

<pre class=""lang-yaml prettyprint-override""><code>        when: ""not '{{ playbook_dir }}/credentials/{{ item.username }}/password.txt' is exists""
</code></pre>

<pre class=""lang-yaml prettyprint-override""><code>        nexus_local_users: ""{{ tmp_users_sorted.results | map(attribute='item.ansible_facts.tmp_user') | list | select('defined') | list }}""
</code></pre>

<pre class=""lang-yaml prettyprint-override""><code>       when: ""not item is skipped""
</code></pre>

<p>This makes for a compact solution without adding more tasks/files.</p>

<p>For more information see: <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_tests.html"" rel=""nofollow noreferrer"">https://docs.ansible.com/ansible/latest/user_guide/playbooks_tests.html</a></p>
",21607,2020-04-10T11:48:56.230,"['    ---\n    - hosts: localhost\n      tasks:\n      - name: Include users.yaml and setup all vars for nexus\n        include_vars:\n          file: users.yaml\n          name: users\n      - set_fact:\n          tmp_user:\n          - username: ""{{ item.username }}""\n            first_name: ""{{ item.first_name }}""\n            last_name: ""{{ item.last_name }}""\n            email: ""{{ item.email }}""\n            password: ""{{ lookup(\'password\', \'credentials/\' + item.username + \'/password.txt length=15 chars=ascii_letters\') }}""\n            roles: ""{{ item.roles }}""\n        loop: ""{{ users.nexus_local_users }}""\n        register: tmp_users\n        when: ""not \'{{ playbook_dir }}/credentials/{{ item.username }}/password.txt\' is exists""\n      - set_fact:\n          tmp_user: ""{{ item.ansible_facts.tmp_user | combine(item.item) }}""\n        with_items: ""{{ tmp_users.results }}""\n        register: tmp_users_sorted\n        when: ""not item is skipped""\n      - set_fact:\n          nexus_local_users: ""{{ tmp_users_sorted.results | map(attribute=\'item.ansible_facts.tmp_user\') | list | select(\'defined\') | list }}""\n      - debug:\n          msg: ""{{ nexus_local_users }}""\n', '        when: ""not \'{{ playbook_dir }}/credentials/{{ item.username }}/password.txt\' is exists""\n', '        nexus_local_users: ""{{ tmp_users_sorted.results | map(attribute=\'item.ansible_facts.tmp_user\') | list | select(\'defined\') | list }}""\n', '       when: ""not item is skipped""\n']"
1295,11304,11062,CC BY-SA 4.0,2020-04-10T21:06:22.627,"<p>There are at least two ways to achieve this.</p>

<p>First is to go with transforming json output to proper object for PowerShell as described in this thread:</p>

<ul>
<li><a href=""https://stackoverflow.com/questions/58738011/how-do-you-select-just-one-property-from-an-array-of-results-from-the-azure-co"">how do you select just one property from an array of “results” from the Azure command 'az group list in powershell'?</a></li>
</ul>

<p>Second it to use <code>--query</code> global parameter for Azure CLI:</p>

<pre><code>az group list --query ""[?contains(name,'kafka')].name""
</code></pre>

<p>But remember to use at least PowerShell 6.2 as previous versions have an issue:</p>

<ul>
<li><a href=""https://github.com/Azure/azure-cli/issues/9047"" rel=""nofollow noreferrer"">powershell --query error #9047</a></li>
</ul>
",21634,2020-04-10T21:06:22.627,"['az group list --query ""[?contains(name,\'kafka\')].name""\n']"
1296,11307,3262,CC BY-SA 4.0,2020-04-11T03:09:18.593,"<p>Using Powershell's <code>Invoke-WebRequest</code> cmdlet:</p>

<pre><code>$Links=$(Invoke-WebRequest -Uri 'https://tomcat.apache.org/download-80.cgi' | Select-Object -ExpandProperty Links)
$($Links | Where-Object -Property href -Match '#8.5.[0-9]+').href.substring(1)
</code></pre>

<p>Returns:</p>

<pre><code>8.5.54
</code></pre>

<p>This command works on Windows/Linux/MACOS</p>
",21642,2020-04-11T03:51:20.103,"[""$Links=$(Invoke-WebRequest -Uri 'https://tomcat.apache.org/download-80.cgi' | Select-Object -ExpandProperty Links)\n$($Links | Where-Object -Property href -Match '#8.5.[0-9]+').href.substring(1)\n"", '8.5.54\n']"
1297,11321,11318,CC BY-SA 4.0,2020-04-12T12:20:05.320,"<p>Not in pure Docker Compose.  If you have a plain-text templating engine you like (Mustache, Jinja, m4, ...) you can ask it to do this for you.</p>

<p>You tagged this as <a href=""/questions/tagged/shell-script"" class=""post-tag"" title=""show questions tagged &#39;shell-script&#39;"" rel=""tag"">shell-script</a>, and <a href=""https://docs.docker.com/compose/reference/#specifying-multiple-compose-files"" rel=""nofollow noreferrer"">Compose can take the YAML configuration on stdin</a>, so in principle one option is to write a shell script, and then pipe that into <code>docker-compose</code>:</p>

<pre class=""lang-sh prettyprint-override""><code>#!/bin/sh

buildComposeYaml() {
  cat &lt;&lt;HEADER
version: '3'
services:
HEADER
  for i in $(seq 3); do
    cat &lt;&lt;BLOCK
  s$i:
    build: ../www$i
    ports:
      - ""500$i:9000""
BLOCK
  done
}

buildComposeYaml | docker-compose -f- ""$@""
</code></pre>

<p>(Note that YAML is indentation-sensitive, and the script is mixing indentation for the script itself, the YAML embedded in the script, and the end-of-heredoc markers; so this will work for a simple tool but it wouldn't be my long-term choice.)</p>
",17579,2020-04-12T12:20:05.320,"['#!/bin/sh\n\nbuildComposeYaml() {\n  cat <<HEADER\nversion: \'3\'\nservices:\nHEADER\n  for i in $(seq 3); do\n    cat <<BLOCK\n  s$i:\n    build: ../www$i\n    ports:\n      - ""500$i:9000""\nBLOCK\n  done\n}\n\nbuildComposeYaml | docker-compose -f- ""$@""\n']"
1298,11342,11341,CC BY-SA 4.0,2020-04-14T18:32:27.233,"<p>The <a href=""https://docs.ansible.com/ansible/latest/modules/copy_module.html"" rel=""nofollow noreferrer"">copy</a> module copies a file from the local or remote machine to a location on the remote machine. </p>

<p>In order to copy the file from the remote machine itself, set <code>remote_src</code> to <code>yes</code>.</p>

<pre><code>- name: Copy multiple Directories
          copy:
            src: ""{{ item.src }}""
            dest: ""{{ item.dest }}""
            mode: ""{{ item.mode }}""
            remote_src: yes
          with_items:
             - { src: '/home_old/',dest: '/home/',mode: preserve}
             - { src: '/var_old/',dest: '/var/',mode: preserve}
</code></pre>
",11440,2020-04-14T18:32:27.233,"['- name: Copy multiple Directories\n          copy:\n            src: ""{{ item.src }}""\n            dest: ""{{ item.dest }}""\n            mode: ""{{ item.mode }}""\n            remote_src: yes\n          with_items:\n             - { src: \'/home_old/\',dest: \'/home/\',mode: preserve}\n             - { src: \'/var_old/\',dest: \'/var/\',mode: preserve}\n']"
1299,11350,11341,CC BY-SA 4.0,2020-04-15T17:51:05.560,"<p>I have used below code to resolve the issue.</p>

<pre><code>    - name: Copy var directory
      shell: |
        cp -rpf /home_old/* /home
        cp -rpf /var_old/* /var
      args:
        executable: /bin/bash
</code></pre>

<p>Thanks.</p>
",20068,2020-04-15T17:51:05.560,['    - name: Copy var directory\n      shell: |\n        cp -rpf /home_old/* /home\n        cp -rpf /var_old/* /var\n      args:\n        executable: /bin/bash\n']
1300,11351,11214,CC BY-SA 4.0,2020-04-15T17:54:53.273,"<p>I have fixed updated error with the below module:</p>

<pre><code>- name: Join system to AD 
  expect:
    command: /bin/bash -c ""realm join --membership-software=adcli --user=username@EXAMPLE.COM --computer-ou=""OU={{ xxx }},OU={{ xxxx }},OU=xxxx,OU=xxxxx,DC=xxxxxxxx,DC=xxxx"" --os-name={{ ansible_distribution }} --os-version={{ ansible_distribution_version }} DCNAME""
    responses:
        Password for *: ""{{ join_user_pass | b64decode }}""
</code></pre>
",20068,2020-04-15T17:54:53.273,"['- name: Join system to AD \n  expect:\n    command: /bin/bash -c ""realm join --membership-software=adcli --user=username@EXAMPLE.COM --computer-ou=""OU={{ xxx }},OU={{ xxxx }},OU=xxxx,OU=xxxxx,DC=xxxxxxxx,DC=xxxx"" --os-name={{ ansible_distribution }} --os-version={{ ansible_distribution_version }} DCNAME""\n    responses:\n        Password for *: ""{{ join_user_pass | b64decode }}""\n']"
1301,11356,11355,CC BY-SA 4.0,2020-04-16T07:17:49.387,"<p><code>loop</code> requires a valid list. But we got here is,</p>

<pre>
[({'i_am': 'sam', 'eggs_ham': '456'}, <b>AnsibleUndefined</b>),
 ({'i_am': 'sam', 'eggs_ham': 'ham'}, {'transport': 'train'}),
 ({'i_am': 'eggs', 'eggs_ham': '456'}, <b>AnsibleUndefined</b>)]
</pre>

<p>Since no value is assigned to <code>transport_fact_results</code> when <code>common_thing_2</code> is not defined.</p>

<p>if you remove the <code>when</code> condition it will work.</p>

<p>CODE:</p>

<pre><code>- hosts: localhost
  vars:
    default_thing_1: 123
    default_thing_2: 456
    default_transport: train
    list_of_things:
      - name: foo
        common_thing_1: ""sam""
      - name: bar
        common_thing_1: ""sam""
        common_thing_2: ""ham""
      - name: biz
        common_thing_1: ""eggs""
  tasks:
    - name: Set the Things Facts
      set_fact:
        thing:
          i_am: ""{{ item.common_thing_1 | default(default_thing_1) }}""
          eggs_ham: ""{{ item.common_thing_2 | default(default_thing_2) }}""
      loop: ""{{ list_of_things }}""
      register: things_fact_results
    - name: Set Optional Things Facts
      set_fact:
        thing:
          transport: ""{{ item.transport | default(default_transport) }}""
      when: ""item.common_thing_2 is defined and item.common_thing_2 == 'ham'""
      loop: ""{{ list_of_things }}""
      register: transport_fact_results
    - name: Debug the Facts
      debug:
        msg: ""{{ item.0 | combine(item.1|default({})) }}""
      loop: ""{{
        things_fact_results.results |
        map(attribute='ansible_facts.thing') | list |
        zip(
          transport_fact_results.results |
          map(attribute='ansible_facts.thing') | list
        ) | list
      }}""
</code></pre>

<p>OUTPUT:</p>

<pre><code>PLAY [localhost] ************************************************************************************************************************************************************************************************

TASK [Gathering Facts] ******************************************************************************************************************************************************************************************
ok: [localhost]

TASK [Set the Things Facts] *************************************************************************************************************************************************************************************
ok: [localhost] =&gt; (item={u'common_thing_1': u'sam', u'name': u'foo'})
ok: [localhost] =&gt; (item={u'common_thing_1': u'sam', u'common_thing_2': u'ham', u'name': u'bar'})
ok: [localhost] =&gt; (item={u'common_thing_1': u'eggs', u'name': u'biz'})

TASK [Set Optional Things Facts] ********************************************************************************************************************************************************************************
ok: [localhost] =&gt; (item={u'common_thing_1': u'sam', u'name': u'foo'})
ok: [localhost] =&gt; (item={u'common_thing_1': u'sam', u'common_thing_2': u'ham', u'name': u'bar'})
ok: [localhost] =&gt; (item={u'common_thing_1': u'eggs', u'name': u'biz'})

TASK [Debug the Facts] ******************************************************************************************************************************************************************************************
ok: [localhost] =&gt; (item=[{u'eggs_ham': u'456', u'i_am': u'sam'}, {u'transport': u'train'}]) =&gt; {
    ""msg"": {
        ""eggs_ham"": ""456"", 
        ""i_am"": ""sam"", 
        ""transport"": ""train""
    }
}
ok: [localhost] =&gt; (item=[{u'eggs_ham': u'ham', u'i_am': u'sam'}, {u'transport': u'train'}]) =&gt; {
    ""msg"": {
        ""eggs_ham"": ""ham"", 
        ""i_am"": ""sam"", 
        ""transport"": ""train""
    }
}
ok: [localhost] =&gt; (item=[{u'eggs_ham': u'456', u'i_am': u'eggs'}, {u'transport': u'train'}]) =&gt; {
    ""msg"": {
        ""eggs_ham"": ""456"", 
        ""i_am"": ""eggs"", 
        ""transport"": ""train""
    }
}

PLAY RECAP ******************************************************************************************************************************************************************************************************
localhost                  : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0  
</code></pre>
",11440,2020-04-16T07:17:49.387,"[""\n[({'i_am': 'sam', 'eggs_ham': '456'}, AnsibleUndefined),\n ({'i_am': 'sam', 'eggs_ham': 'ham'}, {'transport': 'train'}),\n ({'i_am': 'eggs', 'eggs_ham': '456'}, AnsibleUndefined)]\n"", '- hosts: localhost\n  vars:\n    default_thing_1: 123\n    default_thing_2: 456\n    default_transport: train\n    list_of_things:\n      - name: foo\n        common_thing_1: ""sam""\n      - name: bar\n        common_thing_1: ""sam""\n        common_thing_2: ""ham""\n      - name: biz\n        common_thing_1: ""eggs""\n  tasks:\n    - name: Set the Things Facts\n      set_fact:\n        thing:\n          i_am: ""{{ item.common_thing_1 | default(default_thing_1) }}""\n          eggs_ham: ""{{ item.common_thing_2 | default(default_thing_2) }}""\n      loop: ""{{ list_of_things }}""\n      register: things_fact_results\n    - name: Set Optional Things Facts\n      set_fact:\n        thing:\n          transport: ""{{ item.transport | default(default_transport) }}""\n      when: ""item.common_thing_2 is defined and item.common_thing_2 == \'ham\'""\n      loop: ""{{ list_of_things }}""\n      register: transport_fact_results\n    - name: Debug the Facts\n      debug:\n        msg: ""{{ item.0 | combine(item.1|default({})) }}""\n      loop: ""{{\n        things_fact_results.results |\n        map(attribute=\'ansible_facts.thing\') | list |\n        zip(\n          transport_fact_results.results |\n          map(attribute=\'ansible_facts.thing\') | list\n        ) | list\n      }}""\n', 'PLAY [localhost] ************************************************************************************************************************************************************************************************\n\nTASK [Gathering Facts] ******************************************************************************************************************************************************************************************\nok: [localhost]\n\nTASK [Set the Things Facts] *************************************************************************************************************************************************************************************\nok: [localhost] => (item={u\'common_thing_1\': u\'sam\', u\'name\': u\'foo\'})\nok: [localhost] => (item={u\'common_thing_1\': u\'sam\', u\'common_thing_2\': u\'ham\', u\'name\': u\'bar\'})\nok: [localhost] => (item={u\'common_thing_1\': u\'eggs\', u\'name\': u\'biz\'})\n\nTASK [Set Optional Things Facts] ********************************************************************************************************************************************************************************\nok: [localhost] => (item={u\'common_thing_1\': u\'sam\', u\'name\': u\'foo\'})\nok: [localhost] => (item={u\'common_thing_1\': u\'sam\', u\'common_thing_2\': u\'ham\', u\'name\': u\'bar\'})\nok: [localhost] => (item={u\'common_thing_1\': u\'eggs\', u\'name\': u\'biz\'})\n\nTASK [Debug the Facts] ******************************************************************************************************************************************************************************************\nok: [localhost] => (item=[{u\'eggs_ham\': u\'456\', u\'i_am\': u\'sam\'}, {u\'transport\': u\'train\'}]) => {\n    ""msg"": {\n        ""eggs_ham"": ""456"", \n        ""i_am"": ""sam"", \n        ""transport"": ""train""\n    }\n}\nok: [localhost] => (item=[{u\'eggs_ham\': u\'ham\', u\'i_am\': u\'sam\'}, {u\'transport\': u\'train\'}]) => {\n    ""msg"": {\n        ""eggs_ham"": ""ham"", \n        ""i_am"": ""sam"", \n        ""transport"": ""train""\n    }\n}\nok: [localhost] => (item=[{u\'eggs_ham\': u\'456\', u\'i_am\': u\'eggs\'}, {u\'transport\': u\'train\'}]) => {\n    ""msg"": {\n        ""eggs_ham"": ""456"", \n        ""i_am"": ""eggs"", \n        ""transport"": ""train""\n    }\n}\n\nPLAY RECAP ******************************************************************************************************************************************************************************************************\nlocalhost                  : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0  \n']"
1302,11359,11358,CC BY-SA 4.0,2020-04-16T11:55:29.630,"<p><a href=""https://i.stack.imgur.com/QdcYr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QdcYr.png"" alt=""enter image description here""></a></p>

<p>main.tf</p>

<pre><code>module ""assets"" {
  source       = ""./modules""
}
</code></pre>

<p>modules/aws-assests.tf</p>

<pre><code>resource ""aws_s3_bucket"" ""machine-learning"" {
  # (resource arguments)
}
</code></pre>

<p>To install the aws_s3_bucket module run the below command</p>

<pre><code># terraform init
</code></pre>
",21739,2020-04-16T11:55:29.630,"['module ""assets"" {\n  source       = ""./modules""\n}\n', 'resource ""aws_s3_bucket"" ""machine-learning"" {\n  # (resource arguments)\n}\n', '# terraform init\n']"
1303,11360,11346,CC BY-SA 4.0,2020-04-16T13:05:02.483,"<p>I answered that question <a href=""https://stackoverflow.com/questions/44494238/mark-jenkins-build-as-success-in-case-of-timeout-on-input-declarative-pipelin/60383321#60383321"">stackoveflow</a> and I'll post the answer here:</p>

<p>For a Declarative pipeline (not a scripted) you would do something like this</p>

<pre><code>stage('Foo') {
      steps {
            script {
                env.PROCEED_TO_DEPLOY = 1
                try {
                    timeout(time: 2, unit: 'MINUTES') {
                        // ...
                    }
                } catch (err) {
                    env.PROCEED_TO_DEPLOY = 0
                }
            }
      }
  }
  stage('Bar') {
    when {
        expression {
            env.PROCEED_TO_DEPLOY == 1
        }
    }
    //rest of your pipeline
</code></pre>

<p>stage ""Bar"" would be skipped but as for the rest of the stages the job will be marked as passed (assuming nothing wrong happened before).</p>

<p>As for your particular use-case, the trick is to use a try/catch block.</p>
",7498,2020-04-16T13:05:02.483,"[""stage('Foo') {\n      steps {\n            script {\n                env.PROCEED_TO_DEPLOY = 1\n                try {\n                    timeout(time: 2, unit: 'MINUTES') {\n                        // ...\n                    }\n                } catch (err) {\n                    env.PROCEED_TO_DEPLOY = 0\n                }\n            }\n      }\n  }\n  stage('Bar') {\n    when {\n        expression {\n            env.PROCEED_TO_DEPLOY == 1\n        }\n    }\n    //rest of your pipeline\n""]"
1304,11371,11370,CC BY-SA 4.0,2020-04-17T03:58:15.513,"<p><strong><em>It is possible on the Linux(Unix) bastion host.</em></strong></p>

<p>Step-1: First ssh to the bastion host. <em>eg. 16.23.14.20 is the bastion host.</em></p>

<pre><code># ssh root@16.23.14.20
</code></pre>

<p>Step-2: Create port tunneling by using the below command. eg. <em>The RDS IP is 172.16.13.10</em></p>

<pre><code># ssh -L  3006:172.16.13.10:3006 localhost
</code></pre>

<p>Verify using netstat command.</p>

<pre><code>netstat -ntulp | grep 3006
</code></pre>

<p>Note: If netstat command not available. Using <code>sudo apt install -y net-tools</code> or <code>sudo yum install -y net-tools</code></p>
",21739,2020-04-17T03:58:15.513,"['# ssh root@16.23.14.20\n', '# ssh -L  3006:172.16.13.10:3006 localhost\n', 'netstat -ntulp | grep 3006\n']"
1305,11374,4365,CC BY-SA 4.0,2020-04-17T11:14:00.737,"<p>Ansible is case sensitive, hence a != A</p>

<p>Therefore, the correct code should look like this:</p>

<pre><code>- name: Configure NTP file
  template: src=ntp.conf.j2 dest=/etc/ntp.conf
  tags: ntp
  notify: Restart NTP
</code></pre>
",21770,2020-04-17T12:22:17.803,['- name: Configure NTP file\n  template: src=ntp.conf.j2 dest=/etc/ntp.conf\n  tags: ntp\n  notify: Restart NTP\n']
1306,11375,11358,CC BY-SA 4.0,2020-04-17T18:37:16.357,"<p>The <code>terraform import</code> command uses <a href=""https://www.terraform.io/docs/internals/resource-addressing.html"" rel=""noreferrer"">the ""Resource Address"" syntax</a>, which is a way to talk about objects in a configuration from outside of that configuration. (This is as opposed to <a href=""https://www.terraform.io/docs/configuration/expressions.html#references-to-named-values"" rel=""noreferrer"">references</a> in the main Terraform language, which are always resolved in the context of a particular module.)</p>

<p>To refer to a resource that is declared in a child module, you can add a module path to the beginning of the address:</p>

<pre><code>terraform import module.assets.aws_s3_bucket.machine-learning BUCKET-NAME
</code></pre>
",2463,2020-04-17T18:37:16.357,['terraform import module.assets.aws_s3_bucket.machine-learning BUCKET-NAME\n']
1307,11381,9348,CC BY-SA 4.0,2020-04-18T18:23:31.050,"<blockquote>
  <p>have anyone tried this scenario (gitlab runner + docker on Windows) before, and have some feedback if it works or not?</p>
</blockquote>

<p>I installed and registered a GitLab Runner on my Windows 10 laptop following the instructions from GitLab <a href=""https://docs.gitlab.com/runner/install/windows.html"" rel=""nofollow noreferrer"">Install GitLab Runner on Windows</a></p>

<p>At first, I had trouble pulling the Windows container image:</p>

<pre><code>PS C:\GitLab-Runner&gt; docker pull mcr.microsoft.com/windows/servercore
Using default tag: latest
Error response from daemon: manifest for mcr.microsoft.com/windows/servercore:latest not found: manifest unknown: manifest unknown
PS C:\GitLab-Runner&gt; docker pull mcr.microsoft.com/windows/servercore:1809
1809: Pulling from windows/servercore
no matching manifest for linux/amd64 in the manifest list entries
PS C:\GitLab-Runner&gt;
</code></pre>

<p>After selecting the ""Switch to Windows containers"" option in my Windows Docker (in the top-level menu that opens from the Docker icon in the toolbar), I was able to <code>docker pull</code> the Windows servercore image.  </p>

<p>However, I was unable to run GitLab Runner on my fully patched and updated Windows laptop:</p>

<pre><code> ERROR: Preparation failed: unsupported Windows version: Windows 10 Pro Version 1909 ...
</code></pre>

<p>It's too new!  As I read GitLab's <a href=""https://docs.gitlab.com/runner/install/windows.html#windows-version-support-policy"" rel=""nofollow noreferrer"">Windows version support policy</a>, GitLab should support 1909 for 18 months; but obviously that is not the case yet. 1903 is the most recent supported version.</p>

<p>However, as of January 2020, GitLab has <a href=""https://docs.gitlab.com/ee/user/gitlab_com/#windows-shared-runners-beta"" rel=""nofollow noreferrer"">Windows Shared Runners (beta)</a></p>

<p>I tried that and it works. Example <code>.gitlab-ci.yml</code>:</p>

<pre><code>my_job:
  script: systeminfo
  tags:
    - windows
</code></pre>

<blockquote>
  <p>Is my plan of decreasing Jenkins usage and using more Gitlab runner (for this project at least) feasible? </p>
</blockquote>

<p>Sounds good to  me.</p>

<blockquote>
  <p>Do you have a better approach on how can I improve to a scalable Windows project CI/CD process, other than using gitlab runner + docker?</p>
</blockquote>

<p>No.  I think you're on the right path.</p>
",21640,2020-04-18T19:44:12.873,"['PS C:\\GitLab-Runner> docker pull mcr.microsoft.com/windows/servercore\nUsing default tag: latest\nError response from daemon: manifest for mcr.microsoft.com/windows/servercore:latest not found: manifest unknown: manifest unknown\nPS C:\\GitLab-Runner> docker pull mcr.microsoft.com/windows/servercore:1809\n1809: Pulling from windows/servercore\nno matching manifest for linux/amd64 in the manifest list entries\nPS C:\\GitLab-Runner>\n', ' ERROR: Preparation failed: unsupported Windows version: Windows 10 Pro Version 1909 ...\n', 'my_job:\n  script: systeminfo\n  tags:\n    - windows\n']"
1308,11389,1116,CC BY-SA 4.0,2020-04-20T11:13:47.757,"<p>You have no problem at the first place. An image in Docker is not like a monolithic ISO. It has layers. And layers in Docker, when you run them, are immutable. </p>

<p>For example: </p>

<ul>
<li>Somebody built Alpine image with hash abc123</li>
<li>Then somebody build a Python image based on Alpine (FROM alpine:abc123) with hash def456.</li>
<li>Now you've build your image atop of Python (FROM python:def456) and result in hash ghi789.</li>
</ul>

<p>Now your customer is pulling the image: </p>

<pre><code>docker pull flask:ghi789
</code></pre>

<p>When he runs his container he gets three read-only layers in memory (abc123, def456 and ghi789) and one new read-write layer jkl357 that is initially empty. It will be filled later with some data during app activity, for example - logs, or external connections like ""docker exec ..."".
Thus, no matter what customer does in his new layers, all precommitted layers are safe.</p>

<p>The layer jkl357 become immutable (readonly) only upon commit. But this is already not your image SHA and not related to you app:</p>

<pre><code>docker commit -t my-altered-flask:tag
</code></pre>

<hr>

<p>All said is relevant unless your goal is to protect from modifying, not from read at all.</p>
",21715,2020-04-20T11:18:55.433,"['docker pull flask:ghi789\n', 'docker commit -t my-altered-flask:tag\n']"
1309,11394,4344,CC BY-SA 4.0,2020-04-21T06:49:11.313,"<p>You can download the latest stable or unstable version from the helm repo.
First, You need to verify the remote helm repo URL below command.</p>

<pre><code># helm repo list
</code></pre>

<p>For stable repo URL, you will get output like</p>

<pre><code>NAME            URL
stable          https://kubernetes-charts.storage.googleapis.com
</code></pre>

<p>It refers to <strong><code>https://github.com/helm/charts/tree/master/stable</code></strong></p>

<p>Now I will tell you to download the chart from the repo URL.</p>

<pre><code>helm fetch stable/wordpress --version 0.6.0
</code></pre>

<p>For the extracted copy of the chart</p>

<pre><code> helm fetch stable/wordpress --version 0.6.0 --untar
</code></pre>

<p><strong>The above command will download the chart in your current directory.</strong></p>
",21739,2020-04-21T06:49:11.313,"['# helm repo list\n', 'NAME            URL\nstable          https://kubernetes-charts.storage.googleapis.com\n', 'helm fetch stable/wordpress --version 0.6.0\n', ' helm fetch stable/wordpress --version 0.6.0 --untar\n']"
1310,11395,11393,CC BY-SA 4.0,2020-04-21T07:44:20.903,"<h2>Just unregister offline runners:</h2>
<p>As per <a href=""https://docs.gitlab.com/runner/commands/#gitlab-runner-verify"" rel=""nofollow noreferrer"">GitLab Runner commands</a> manual:</p>
<blockquote>
<p>To delete the old and removed from GitLab runners, execute the following command.</p>
</blockquote>
<pre><code>    gitlab-runner verify --delete
</code></pre>
<h2>You are not alone</h2>
<p>P.S. The problem is common: there <a href=""https://google.com/search?q=site%3A+https%3A%2F%2Fgitlab.com%2Fgitlab-org%2F+issue++intitle%3Arunner+intitle%3Aclean%7Cremove%7Cexpired"" rel=""nofollow noreferrer"">are many issues</a> with questions like yours.</p>
<p>Moreover, there are several custom recipes to unregister &quot;offline&quot; runners:</p>
<ul>
<li><a href=""https://gitlab.com/gitlab-org/gitlab-foss/issues/19828#note_54956232"" rel=""nofollow noreferrer""><code>bash</code> script</a></li>
<li><a href=""https://gitlab.com/gitlab-org/gitlab-foss/issues/19828#note_132438194"" rel=""nofollow noreferrer"">API oneliner with <code>curl</code></a></li>
<li><a href=""https://gitlab.com/gitlab-org/gitlab-foss/issues/19828#note_202265652"" rel=""nofollow noreferrer""><code>python</code> script</a></li>
</ul>
<h2>API for &quot;zombie&quot; runners</h2>
<p>As <a href=""https://devops.stackexchange.com/users/10807/rlandster"">rlandster</a> noted, sometimes you'll need an <a href=""https://gitlab.com/gitlab-org/gitlab-foss/-/issues/19828#note_132438194"" rel=""nofollow noreferrer"">API</a>
to unregister &quot;zombie&quot; runners.</p>
<pre><code>curl -S --header &quot;PRIVATE-TOKEN:&lt;token&gt;&quot; &quot;https://gitlab.example.com/api/v4/runners/all&quot; | jq '.[] | select(.status == &quot;offline&quot;) | .id' | xargs -I runner_id curl -S --request DELETE --header &quot;PRIVATE-TOKEN:&lt;token&gt;&quot; &quot;https://gitlab.example.com/api/v4/runners/runner_id&quot;`
</code></pre>
<p>This will list all runners, instead of the personal ones: <a href=""https://docs.gitlab.com/ee/api/runners.html#list-all-runners"" rel=""nofollow noreferrer"">https://docs.gitlab.com/ee/api/runners.html#list-all-runners</a></p>
<h2>P.S. note about runners</h2>
<p>Pls note that <code>Gitlab</code> itself doesn't manage runners. So, e.g. to restart or shutdown the runner, use appropriate commands on the runner's hosts.</p>
",20042,2020-04-30T08:23:41.330,"['    gitlab-runner verify --delete\n', 'curl -S --header ""PRIVATE-TOKEN:<token>"" ""https://gitlab.example.com/api/v4/runners/all"" | jq \'.[] | select(.status == ""offline"") | .id\' | xargs -I runner_id curl -S --request DELETE --header ""PRIVATE-TOKEN:<token>"" ""https://gitlab.example.com/api/v4/runners/runner_id""`\n']"
1311,11400,11398,CC BY-SA 4.0,2020-04-21T14:16:20.917,"<p>Found an easy solution using the <a href=""https://www.terraform.io/docs/configuration/functions/index.html"" rel=""nofollow noreferrer"">index</a> function:</p>

<pre><code>tags = { Name = ""Company0${index(var.vpc_cidrs, each.value) + 1}"" }
</code></pre>
",21846,2020-04-21T14:16:20.917,"['tags = { Name = ""Company0${index(var.vpc_cidrs, each.value) + 1}"" }\n']"
1312,11403,2967,CC BY-SA 4.0,2020-04-21T20:12:27.147,"<p>If anyone else is going down this rabbit hole.  Make sure you didn't accidentally define your volume with an <code>=</code> in your <code>Dockerfile</code></p>

<p><strong>Wrong:</strong> </p>

<pre><code>VOLUME = [""/logs"", ""/data""]
</code></pre>

<p><strong>Correct:</strong> </p>

<pre><code>VOLUME [""/logs"", ""/data""]
</code></pre>

<p>It took me a long time to dig into why the anonymous volumes were being added by <code>docker-compose</code></p>
",21855,2020-04-21T20:12:27.147,"['VOLUME = [""/logs"", ""/data""]\n', 'VOLUME [""/logs"", ""/data""]\n']"
1313,11407,11368,CC BY-SA 4.0,2020-04-22T10:56:05.320,"<p>The solution is to specify an <code>assume_role</code> statement:</p>

<pre><code>provider ""aws"" {
  profile = ""default""
  assume_role {
    role_arn = ""arn:aws:iam::[ACCOUNT_ID]:role/terraform-test-role""
  }
}
</code></pre>
",11598,2020-04-22T10:56:05.320,"['provider ""aws"" {\n  profile = ""default""\n  assume_role {\n    role_arn = ""arn:aws:iam::[ACCOUNT_ID]:role/terraform-test-role""\n  }\n}\n']"
1314,11414,11399,CC BY-SA 4.0,2020-04-22T22:10:31.777,"<p>The way I'm understanding your question is that you're writing a module that takes an optional <code>vpc_id</code> as an argument, and either uses it if specified or creates a new VPC itself if not specified. You then need to use the VPC id elsewhere in your configuration, regardless of whether it was provided by the caller directly or if it was created by the VPC module.</p>

<p>If I understood that correctly, here's one way to get that done.</p>

<p>First, we'll declare the <code>vpc_id</code> variable for your own module that the rest of this will use to make its decisions.</p>

<pre><code>variable ""vpc_id"" {
  type    = string
  default = null # optional with no default value
}
</code></pre>

<p>From this we will derive our decision about whether to create the VPC, which I'll write as a local value here mainly for exposition purposes but you might choose to inline it at the point of use in practice depending on what feels most readable for you:</p>

<pre><code>locals {
  create_vpc = var.vpc_id != null ? true : false
}
</code></pre>

<p>We can now use that value both with the module and with a <code>data</code> resource so that we'll either create a new VPC or retrieve data about the existing one:</p>

<pre><code>module ""vpc"" {
  source = ""terraform-aws-modules/vpc/aws""

  create_vpc = local.create_vpc
  # ...
}

data ""aws_vpc"" ""selected"" {
  count = local.create_vpc ? 0 : 1

  id = var.vpc_id
}
</code></pre>

<p>We can then write another local value that chooses which of those two locations to derive other VPC-related values, such as the <code>id</code> and <code>cidr_block</code> from:</p>

<pre><code>locals {
  vpc = (
    local.create_vpc ?
    {
      id         = module.vpc.vpc_id
      cidr_block = module.vpc.vpc_cidr_block
    } :
    {
      id         = data.aws_vpc.selected.id
      cidr_block = data.aws_vpc.selected.cidr_block
    }
  )
}
</code></pre>

<p>You can then use <code>local.vpc.id</code> and <code>local.vpc.cidr_block</code> elsewhere in the configuration to get the appropriate values to use regardless of whether this module created its own VPC or not.</p>

<hr>

<p>The above is the most direct answer to your question. I also wanted to share a different approach that is based on the patterns described in the <a href=""https://www.terraform.io/docs/modules/composition.html"" rel=""nofollow noreferrer"">Module Composition</a> section of Terraform's docs, which might be appropriate for you if you're building a shared module intended to be called by another Terraform module.</p>

<p>A different way to approach this problem using composition is to say that your module <em>never</em> creates its own VPC, and always expects one to be provided to it. This is an example of the <em>dependency inversion</em> principle. Here's how that might look for your particular use-case...</p>

<p>In your module, you can declare an input variable called <code>vpc</code> that has the same structure as the final <code>local.vpc</code> that we created in the previous approach:</p>

<pre><code>variable ""vpc"" {
  type = object({
    id         = string
    cidr_block = string
  })
  # This time the VPC is required. The caller decides how to obtain it.
}
</code></pre>

<p>Your own module's expressions would then get the VPC id as <code>var.vpc.id</code> instead of <code>local.vpc.id</code> as in the previous approach.</p>

<p>The calling module can then decide between several different ways of providing the value for that variable:</p>

<pre><code># Using the terraform-aws-modules/vpc/aws module
module ""vpc"" {
  source = ""terraform-aws-modules/vpc/aws""

  # ...
}

module ""your_module"" {
  source = ""./modules/your-module""

  vpc = {
    id         = module.vpc.vpc_id
    cidr_block = module.vpc.vpc_cidr_block
  }
}
</code></pre>

<pre><code># Directly using the aws_vpc resource type

resource ""aws_vpc"" ""example"" {
  # ...
}

module ""your_module"" {
  source = ""./modules/your-module""

  vpc = aws_vpc.example
}
</code></pre>

<pre><code># Using the aws_vpc data source to find an existing VPC

data ""aws_vpc"" ""example"" {
  tags = {
    Environment = ""STAGE""
  }
}

module ""your_module"" {
  source = ""./modules/your-module""

  vpc = data.aws_vpc.example
}
</code></pre>

<p>In other words, this lets your new module focus on whatever new problem it is trying to solve while being decoupled from the problem of creating a VPC, allowing the calling module to obtain that VPC information in whatever way is appropriate. The appropriate way to obtain the VPC might change over time, and this composition approach means that callers can have more control over how they manage the transition between different approaches, independent of the implementation of your new module.</p>

<p>Module composition isn't always the best option, but I wanted to point it out because the Terraform documentation specifically recommends considering this approach and recommends against having many levels of nested module calls.</p>
",2463,2020-04-22T22:10:31.777,"['variable ""vpc_id"" {\n  type    = string\n  default = null # optional with no default value\n}\n', 'locals {\n  create_vpc = var.vpc_id != null ? true : false\n}\n', 'module ""vpc"" {\n  source = ""terraform-aws-modules/vpc/aws""\n\n  create_vpc = local.create_vpc\n  # ...\n}\n\ndata ""aws_vpc"" ""selected"" {\n  count = local.create_vpc ? 0 : 1\n\n  id = var.vpc_id\n}\n', 'locals {\n  vpc = (\n    local.create_vpc ?\n    {\n      id         = module.vpc.vpc_id\n      cidr_block = module.vpc.vpc_cidr_block\n    } :\n    {\n      id         = data.aws_vpc.selected.id\n      cidr_block = data.aws_vpc.selected.cidr_block\n    }\n  )\n}\n', 'variable ""vpc"" {\n  type = object({\n    id         = string\n    cidr_block = string\n  })\n  # This time the VPC is required. The caller decides how to obtain it.\n}\n', '# Using the terraform-aws-modules/vpc/aws module\nmodule ""vpc"" {\n  source = ""terraform-aws-modules/vpc/aws""\n\n  # ...\n}\n\nmodule ""your_module"" {\n  source = ""./modules/your-module""\n\n  vpc = {\n    id         = module.vpc.vpc_id\n    cidr_block = module.vpc.vpc_cidr_block\n  }\n}\n', '# Directly using the aws_vpc resource type\n\nresource ""aws_vpc"" ""example"" {\n  # ...\n}\n\nmodule ""your_module"" {\n  source = ""./modules/your-module""\n\n  vpc = aws_vpc.example\n}\n', '# Using the aws_vpc data source to find an existing VPC\n\ndata ""aws_vpc"" ""example"" {\n  tags = {\n    Environment = ""STAGE""\n  }\n}\n\nmodule ""your_module"" {\n  source = ""./modules/your-module""\n\n  vpc = data.aws_vpc.example\n}\n']"
1315,11415,11398,CC BY-SA 4.0,2020-04-22T22:25:37.020,"<p>Terraform offers two resource repetition mechanisms: <a href=""https://www.terraform.io/docs/configuration/resources.html#count-multiple-resource-instances-by-count"" rel=""nofollow noreferrer""><code>count</code></a> and <a href=""https://www.terraform.io/docs/configuration/resources.html#for_each-multiple-resource-instances-defined-by-a-map-or-set-of-strings"" rel=""nofollow noreferrer""><code>for_each</code></a>. The main difference between these is how Terraform will track the multiple instances they create:</p>

<ul>
<li>When using <code>count</code>, each of the multiple instances is tracked by a number starting at 0, giving addresses like <code>aws_vpc.vpc[0]</code> and <code>aws_vpc.vpc[1]</code>.</li>
<li>When using <code>for_each</code>, each of the multiple instances is tracked by a string which could be obtained either from a key in a map or from an element in a set, giving addresses like <code>aws_vpc.vpc[""10.0.0.0/16""]</code> and <code>aws_vpc.vpc[""10.1.0.0/16""]</code>.</li>
</ul>

<p>The most common reason to choose <code>for_each</code> rather than <code>count</code> is to ensure that the order of whatever collection of values is driving the repetition is not significant. In your specific case, that would produce the same result regardless of whether <code>var.vpc_cidrs</code> is <code>[""10.0.0.0/16"", ""10.1.0.0/16""]</code> or <code>[""10.1.0.0/16"", ""10.0.0.0/16""]</code>, because the instances would be tracked by the CIDR block string and the index in the list is totally ignored.</p>

<p>With that all said, the reason why the index isn't directly available when using <code>for_each</code> is that this would defeat the main purpose of using <code>for_each</code>: it would make the order significant again. In your specific situation, if you used the index in the tag Name then changing the order of the list would cause Terraform to plan to swap the tagging on those two VPCs:</p>

<pre><code> # aws_vpc.vpc[""10.0.0.0/16""] will be updated in-place
 ~ resource ""aws_vpc"" ""vpc"" {
     ~ tags = {
         ~ Name = ""Company01"" -&gt; ""Company02""
       }
     # ...
   }

 # aws_vpc.vpc[""10.0.0.0/16""] will be updated in-place
 ~ resource ""aws_vpc"" ""vpc"" {
     ~ tags = {
         ~ Name = ""Company02"" -&gt; ""Company01""
       }
     # ...
   }
</code></pre>

<p>Perhaps that is fine for your case, if those numbers are just there to create some uniqueness and it doesn't matter if they get reassigned over time as CIDR blocks are added, removed and reordered in the input variable. If that's true, then we can derive a value that contains the original index and use that as part of <code>for_each</code> like this:</p>

<pre><code>resource ""aws_vpc"" ""vpc"" {
  for_each = { for i, b in var.vpc_cidrs : b =&gt; { index = i } }

  cidr_block           = each.key
  tags = {
    Name = format(""Company%02d"", each.value.index + 1)
  }
}
</code></pre>

<p>If you consider the position in the list to be truly significant though -- for example, if you'd want swapping two elements in the list to change the <code>cidr_block</code> values on the two existing objects rather than to re-tag them, it would be more appropriate to use <code>count</code> so that Terraform tracks them by the indices itself:</p>

<pre><code>resource ""aws_vpc"" ""vpc"" {
  count = length(var.vpc_cidrs)

  cidr_block           = var.vpc_cidrs[count.index]
  tags = {
    Name = format(""Company%02d"", count.index + 1)
  }
}
</code></pre>
",2463,2020-04-22T22:25:37.020,"[' # aws_vpc.vpc[""10.0.0.0/16""] will be updated in-place\n ~ resource ""aws_vpc"" ""vpc"" {\n     ~ tags = {\n         ~ Name = ""Company01"" -> ""Company02""\n       }\n     # ...\n   }\n\n # aws_vpc.vpc[""10.0.0.0/16""] will be updated in-place\n ~ resource ""aws_vpc"" ""vpc"" {\n     ~ tags = {\n         ~ Name = ""Company02"" -> ""Company01""\n       }\n     # ...\n   }\n', 'resource ""aws_vpc"" ""vpc"" {\n  for_each = { for i, b in var.vpc_cidrs : b => { index = i } }\n\n  cidr_block           = each.key\n  tags = {\n    Name = format(""Company%02d"", each.value.index + 1)\n  }\n}\n', 'resource ""aws_vpc"" ""vpc"" {\n  count = length(var.vpc_cidrs)\n\n  cidr_block           = var.vpc_cidrs[count.index]\n  tags = {\n    Name = format(""Company%02d"", count.index + 1)\n  }\n}\n']"
1316,11421,11417,CC BY-SA 4.0,2020-04-23T09:57:51.483,"<p>Use this instead:</p>

<pre class=""lang-java prettyprint-override""><code>script {
    sh ""`aws ecr get-login --region ap-southeast-1 --no-include-email`""
    docker.image('01234.dkr.ecr.ap-southeast-1.amazonaws.com/&lt;yourImage&gt;:&lt;yourTag&gt;')
}
</code></pre>
",9344,2020-04-23T09:57:51.483,"['script {\n    sh ""`aws ecr get-login --region ap-southeast-1 --no-include-email`""\n    docker.image(\'01234.dkr.ecr.ap-southeast-1.amazonaws.com/<yourImage>:<yourTag>\')\n}\n']"
1317,11424,11417,CC BY-SA 4.0,2020-04-23T13:40:43.323,"<p>I think what you are doing wrong is the way you specify the credentialID to be used. </p>

<p>Instead of <code>'awsId'</code> try to use <code>'ecr:ap-southeast-1:awsId'</code></p>

<pre><code>docker.withRegistry('https://01234.dkr.ecr.ap-southeast-1.amazonaws.com/', 'ecr:ap-southeast-1:awsId') {
    def image = docker.image(""01234.dkr.ecr.ap-southeast-1.amazonaws.com/tas/master-server:${env.BUILD_ID}"")
    image.push()                                        
}

</code></pre>

<p>EDIT: Check the <a href=""https://plugins.jenkins.io/amazon-ecr/"" rel=""nofollow noreferrer"">plugin doc</a></p>
",14930,2020-04-23T13:40:43.323,"['docker.withRegistry(\'https://01234.dkr.ecr.ap-southeast-1.amazonaws.com/\', \'ecr:ap-southeast-1:awsId\') {\n    def image = docker.image(""01234.dkr.ecr.ap-southeast-1.amazonaws.com/tas/master-server:${env.BUILD_ID}"")\n    image.push()                                        \n}\n\n']"
1318,11429,11291,CC BY-SA 4.0,2020-04-24T02:05:02.707,"<p>That can be achieved using another <code>gcloud</code> command:</p>

<pre><code>gcloud beta asset search-all-iam-policies --query policy:""roles/owner"" --project $your_project_id --flatten=""results[].policy[]"" --format=""csv(bindings.members[0])""
</code></pre>
",8125,2020-04-24T02:05:02.707,"['gcloud beta asset search-all-iam-policies --query policy:""roles/owner"" --project $your_project_id --flatten=""results[].policy[]"" --format=""csv(bindings.members[0])""\n']"
1319,11430,9953,CC BY-SA 4.0,2020-04-24T06:09:26.673,"<p>It may help to try it on another computer or inside a VM to isolate the cause.</p>
<p>I ran into the same issue on one computer (stable Manjaro with snap docker). Interestingly, I was able to build the same Dockerfile without issues on another computer (running KDE Neon with snap docker). I'm not sure what the actual cause of the issue is, but it seems, in my case, to be a problem with docker itself and not the Dockerfile.</p>
<a href=""https://github.com/mlaradji/redis-cluster-docker-swarm/blob/master/redis-sentinel/Dockerfile"" rel=""nofollow noreferrer"">Dockerfile</a>:
<pre><code>FROM redis:5.0.9-alpine

LABEL version=&quot;1.0.4&quot;

ENV SENTINEL_QUORUM=2 \
    SENTINEL_DOWN_AFTER=1000 \
    SENTINEL_FAILOVER=1000 \
    REDIS_MASTER_NAME=redismaster \
    REDIS_MASTER=redis-zero \
    REDIS_SENTINEL_NAME=redis-sentinel

RUN apk --no-cache add drill
[...]
</code></pre>
Output:
<pre class=""lang-sh prettyprint-override""><code>ERROR: Unable to read database state: No such file or directory
ERROR: Failed to open apk database: No such file or directory
The command '/bin/sh -c apk --no-cache add drill' returned a non-zero code: 99
</code></pre>
",21914,2020-04-24T06:09:26.673,"['FROM redis:5.0.9-alpine\n\nLABEL version=""1.0.4""\n\nENV SENTINEL_QUORUM=2 \\\n    SENTINEL_DOWN_AFTER=1000 \\\n    SENTINEL_FAILOVER=1000 \\\n    REDIS_MASTER_NAME=redismaster \\\n    REDIS_MASTER=redis-zero \\\n    REDIS_SENTINEL_NAME=redis-sentinel\n\nRUN apk --no-cache add drill\n[...]\n', ""ERROR: Unable to read database state: No such file or directory\nERROR: Failed to open apk database: No such file or directory\nThe command '/bin/sh -c apk --no-cache add drill' returned a non-zero code: 99\n""]"
1320,11433,11432,CC BY-SA 4.0,2020-04-24T12:24:20.103,"<p>Due to the fact that <code>build</code> had a branch filter... Even though no error message on additional info is shown...</p>

<p>Hence I needed to add the branch like so:</p>

<pre><code>workflows:
  version: 2
  build_deploy_test:
    jobs:
      - build:
          filters:
            branches:
              only:
                - develop
                - devops-docker-intial
      - christest:
          requires:
            - install
          filters:
            branches:
              only: devops-docker-intial
</code></pre>
",3599,2020-04-24T12:24:20.103,['workflows:\n  version: 2\n  build_deploy_test:\n    jobs:\n      - build:\n          filters:\n            branches:\n              only:\n                - develop\n                - devops-docker-intial\n      - christest:\n          requires:\n            - install\n          filters:\n            branches:\n              only: devops-docker-intial\n']
1321,11439,6317,CC BY-SA 4.0,2020-04-25T14:39:58.863,"<p>It is possible via network name:</p>

<pre><code>networks:
  mynetwork:
    name: ${STAGE_NAME}
</code></pre>

<p>where mynetwork - name ""inside"" stack</p>

<p>${STAGE_NAME} -name for other stacks/services/containers</p>

<p>See comment from docker capitan <a href=""https://github.com/moby/moby/issues/40819#issuecomment-618726892"" rel=""nofollow noreferrer"">https://github.com/moby/moby/issues/40819#issuecomment-618726892</a></p>
",14979,2020-04-25T14:39:58.863,['networks:\n  mynetwork:\n    name: ${STAGE_NAME}\n']
1322,11440,11420,CC BY-SA 4.0,2020-04-25T15:20:49.103,"<blockquote>
  <p>I though about putting the container on a not used port, like 8999 for example, and proxying the request to this port, and blocking these ports on the firewall, so no one outside can access them. If I go with this option, does the nginx configuration inside of the containers will need the server_name still?</p>
</blockquote>

<p>You're thinking along the right lines. You do need the <code>server_name</code> directives in the container, since it can be accessed both by <code>app2.com/example</code> and <code>app3.com</code>.</p>

<p>Here's an example setup. I'll emulate an nginx on the host machine with a docker container running on the host network.</p>

<p>Scroll down past the code and console log for some explanations.</p>

<p>Here is the listing of the files I used:</p>

<pre><code>lllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ tail -n +1 *
</code></pre>

<p><strong>==> app1.html &lt;==</strong></p>

<pre><code>I am app1!
</code></pre>

<p><strong>==> app2_example.html &lt;==</strong></p>

<pre><code>I am app2 in example subpath!
</code></pre>

<p><strong>==> app2.html &lt;==</strong></p>

<pre><code>I am app2!
</code></pre>

<p><strong>==> app3.html &lt;==</strong></p>

<pre><code>I am app3!
</code></pre>

<p><strong>==> container_nginx.conf &lt;==</strong></p>

<pre><code>server {
  server_name app2.com;
  location /example {
    root /var/www/app2/;
  }
}

server {
  server_name app3.com;
  location / {
    root /var/www/app3/;
  }
}
</code></pre>

<p><strong>==> host_nginx.conf &lt;==</strong></p>

<pre><code>server {
  server_name app1.com;
  location / { 
    root /var/www/app1/;
  }
}

server {
  server_name app2.com;
  location / { 
    root /var/www/app2/;
  }

  location /example {
    proxy_pass http://localhost:8999;
    proxy_set_header Host $http_host;
  }
}

server {
  server_name app3.com;
  location / {
    proxy_pass http://localhost:8999;
    proxy_set_header Host $http_host;
  }
}
</code></pre>

<p><strong>==> nginx.conf &lt;==</strong></p>

<pre><code>user  nginx;
worker_processes  1;

error_log  /var/log/nginx/error.log warn;
pid        /var/run/nginx.pid;


events {
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] ""$request"" ""$http_host"" '
                      '$status $body_bytes_sent ""$http_referer"" '
                      '""$http_user_agent"" ""$http_x_forwarded_for""';

    access_log  /var/log/nginx/access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    include /etc/nginx/conf.d/*.conf;
}
</code></pre>

<p><strong>==> run.sh &lt;==</strong></p>

<pre><code>docker run --name host_nginx --network=host --rm -d \
  -v `pwd`/nginx.conf:/etc/nginx/nginx.conf \
  -v `pwd`/host_nginx.conf:/etc/nginx/conf.d/default.conf \
  -v `pwd`/app1.html:/var/www/app1/index.html \
  -v `pwd`/app2.html:/var/www/app2/index.html \
  nginx

docker run --name container_nginx -p 8999:80 --rm -d \
  -v `pwd`/nginx.conf:/etc/nginx/nginx.conf \
  -v `pwd`/container_nginx.conf:/etc/nginx/conf.d/default.conf \
  -v `pwd`/app2_example.html:/var/www/app2/example/index.html \
  -v `pwd`/app3.html:/var/www/app3/index.html \
  nginx
</code></pre>

<p>Here is the log from my console, where I am testing things out.</p>

<pre><code>lllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ sudo ./run.sh 
73ebc99b8fae1d18bcbc571adbab6b65eaa49f861d66f11a7490d61b4e1beb0f
9f3761ab0619255d9bde08eee70e1fb9b686b645f38d976de7c39d4c8f0ad70d
lllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ curl app1.com
I am app1!
lllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ curl app2.com
I am app2!
lllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ curl app3.com
I am app3!
lllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ curl app2.com/example
&lt;html&gt;
&lt;head&gt;&lt;title&gt;301 Moved Permanently&lt;/title&gt;&lt;/head&gt;
&lt;body&gt;
&lt;center&gt;&lt;h1&gt;301 Moved Permanently&lt;/h1&gt;&lt;/center&gt;
&lt;hr&gt;&lt;center&gt;nginx/1.17.10&lt;/center&gt;
&lt;/body&gt;
&lt;/html&gt;
lllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ curl app2.com/example/
I am app2 in example subpath!
lllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ sudo docker logs host_nginx
127.0.0.1 - - [25/Apr/2020:15:11:15 +0000] ""GET / HTTP/1.1"" ""app1.com"" 200 11 ""-"" ""curl/7.68.0"" ""-""
127.0.0.1 - - [25/Apr/2020:15:11:17 +0000] ""GET / HTTP/1.1"" ""app2.com"" 200 11 ""-"" ""curl/7.68.0"" ""-""
127.0.0.1 - - [25/Apr/2020:15:11:20 +0000] ""GET / HTTP/1.1"" ""app3.com"" 200 11 ""-"" ""curl/7.68.0"" ""-""
127.0.0.1 - - [25/Apr/2020:15:11:25 +0000] ""GET /example HTTP/1.1"" ""app2.com"" 301 170 ""-"" ""curl/7.68.0"" ""-""
127.0.0.1 - - [25/Apr/2020:15:11:29 +0000] ""GET /example/ HTTP/1.1"" ""app2.com"" 200 30 ""-"" ""curl/7.68.0"" ""-""
lllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ sudo docker logs container_nginx
172.17.0.1 - - [25/Apr/2020:15:11:20 +0000] ""GET / HTTP/1.0"" ""app3.com"" 200 11 ""-"" ""curl/7.68.0"" ""-""
172.17.0.1 - - [25/Apr/2020:15:11:25 +0000] ""GET /example HTTP/1.0"" ""app2.com"" 301 170 ""-"" ""curl/7.68.0"" ""-""
172.17.0.1 - - [25/Apr/2020:15:11:29 +0000] ""GET /example/ HTTP/1.0"" ""app2.com"" 200 30 ""-"" ""curl/7.68.0"" ""-""
</code></pre>

<p>I corrected some errors in your config (missing semicolon here and there), changed the server roots to directories, rather than <code>index.html</code> and also the request for <code>app2.com/example</code> would request <code>/var/www/app2/example/index.html</code> so pay close attention to the way in which I mounted the files when starting up the containers in <code>./run.sh</code>. Finally, it was necessary to do <code>proxy_set_header Host $http_host;</code> in the host nginx config, so that the requested <code>Host</code> header gets correctly relayed to the containerized nginx and both app2 and app3 work correctly.</p>
",10718,2020-04-25T15:20:49.103,"['lllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ tail -n +1 *\n', 'I am app1!\n', 'I am app2 in example subpath!\n', 'I am app2!\n', 'I am app3!\n', 'server {\n  server_name app2.com;\n  location /example {\n    root /var/www/app2/;\n  }\n}\n\nserver {\n  server_name app3.com;\n  location / {\n    root /var/www/app3/;\n  }\n}\n', 'server {\n  server_name app1.com;\n  location / { \n    root /var/www/app1/;\n  }\n}\n\nserver {\n  server_name app2.com;\n  location / { \n    root /var/www/app2/;\n  }\n\n  location /example {\n    proxy_pass http://localhost:8999;\n    proxy_set_header Host $http_host;\n  }\n}\n\nserver {\n  server_name app3.com;\n  location / {\n    proxy_pass http://localhost:8999;\n    proxy_set_header Host $http_host;\n  }\n}\n', 'user  nginx;\nworker_processes  1;\n\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\n\n\nevents {\n    worker_connections  1024;\n}\n\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  \'$remote_addr - $remote_user [$time_local] ""$request"" ""$http_host"" \'\n                      \'$status $body_bytes_sent ""$http_referer"" \'\n                      \'""$http_user_agent"" ""$http_x_forwarded_for""\';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n', 'docker run --name host_nginx --network=host --rm -d \\\n  -v `pwd`/nginx.conf:/etc/nginx/nginx.conf \\\n  -v `pwd`/host_nginx.conf:/etc/nginx/conf.d/default.conf \\\n  -v `pwd`/app1.html:/var/www/app1/index.html \\\n  -v `pwd`/app2.html:/var/www/app2/index.html \\\n  nginx\n\ndocker run --name container_nginx -p 8999:80 --rm -d \\\n  -v `pwd`/nginx.conf:/etc/nginx/nginx.conf \\\n  -v `pwd`/container_nginx.conf:/etc/nginx/conf.d/default.conf \\\n  -v `pwd`/app2_example.html:/var/www/app2/example/index.html \\\n  -v `pwd`/app3.html:/var/www/app3/index.html \\\n  nginx\n', 'lllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ sudo ./run.sh \n73ebc99b8fae1d18bcbc571adbab6b65eaa49f861d66f11a7490d61b4e1beb0f\n9f3761ab0619255d9bde08eee70e1fb9b686b645f38d976de7c39d4c8f0ad70d\nlllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ curl app1.com\nI am app1!\nlllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ curl app2.com\nI am app2!\nlllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ curl app3.com\nI am app3!\nlllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ curl app2.com/example\n<html>\n<head><title>301 Moved Permanently</title></head>\n<body>\n<center><h1>301 Moved Permanently</h1></center>\n<hr><center>nginx/1.17.10</center>\n</body>\n</html>\nlllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ curl app2.com/example/\nI am app2 in example subpath!\nlllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ sudo docker logs host_nginx\n127.0.0.1 - - [25/Apr/2020:15:11:15 +0000] ""GET / HTTP/1.1"" ""app1.com"" 200 11 ""-"" ""curl/7.68.0"" ""-""\n127.0.0.1 - - [25/Apr/2020:15:11:17 +0000] ""GET / HTTP/1.1"" ""app2.com"" 200 11 ""-"" ""curl/7.68.0"" ""-""\n127.0.0.1 - - [25/Apr/2020:15:11:20 +0000] ""GET / HTTP/1.1"" ""app3.com"" 200 11 ""-"" ""curl/7.68.0"" ""-""\n127.0.0.1 - - [25/Apr/2020:15:11:25 +0000] ""GET /example HTTP/1.1"" ""app2.com"" 301 170 ""-"" ""curl/7.68.0"" ""-""\n127.0.0.1 - - [25/Apr/2020:15:11:29 +0000] ""GET /example/ HTTP/1.1"" ""app2.com"" 200 30 ""-"" ""curl/7.68.0"" ""-""\nlllamnyp@lllamnyp:~/Cloud/dev/stackexchange/devops/q11420$ sudo docker logs container_nginx\n172.17.0.1 - - [25/Apr/2020:15:11:20 +0000] ""GET / HTTP/1.0"" ""app3.com"" 200 11 ""-"" ""curl/7.68.0"" ""-""\n172.17.0.1 - - [25/Apr/2020:15:11:25 +0000] ""GET /example HTTP/1.0"" ""app2.com"" 301 170 ""-"" ""curl/7.68.0"" ""-""\n172.17.0.1 - - [25/Apr/2020:15:11:29 +0000] ""GET /example/ HTTP/1.0"" ""app2.com"" 200 30 ""-"" ""curl/7.68.0"" ""-""\n']"
1323,11466,11464,CC BY-SA 4.0,2020-04-29T13:43:48.827,"<p>From <a href=""https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.10/#-strong-api-overview-strong-"" rel=""nofollow noreferrer"">the kubernetes docs</a> I see this example:</p>

<pre><code>$ echo 'apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: deployment-example
spec:
  replicas: 3
  revisionHistoryLimit: 10
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.11
        ports:
        - containerPort: 80
' | kubectl replace -f -
</code></pre>

<p>So under your <code>containers</code> entry you should be able to add:</p>

<pre><code>        ports:
        - containerPort: 80
</code></pre>

<p>Is that what you had in mind or, at least, good enough?  You seem to want this as a command line option for the <code>kubectl</code> command and I don't see anything that indicates this is possible.</p>
",739,2020-04-29T13:43:48.827,"[""$ echo 'apiVersion: apps/v1beta1\nkind: Deployment\nmetadata:\n  name: deployment-example\nspec:\n  replicas: 3\n  revisionHistoryLimit: 10\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.11\n        ports:\n        - containerPort: 80\n' | kubectl replace -f -\n"", '        ports:\n        - containerPort: 80\n']"
1324,11467,11461,CC BY-SA 4.0,2020-04-29T19:13:34.630,"<p>In majority of circumstances I wouldn't recommend this in production, but to restart docker container from another container, you need to install docker in that container and then run that ""master"" container with</p>

<pre><code>docker run -v /var/run/docker.sock:/var/run/docker.sock 
</code></pre>

<p>as described here: <a href=""https://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/"" rel=""nofollow noreferrer"">https://jpetazzo.github.io/2015/09/03/do-not-use-docker-in-docker-for-ci/</a> (look for ""The solution"" part of the article).</p>

<p>But check your architecture and see if you really need to restart one container from another or if there is some other way.</p>
",19963,2020-04-29T19:13:34.630,['docker run -v /var/run/docker.sock:/var/run/docker.sock \n']
1325,11470,11469,CC BY-SA 4.0,2020-04-30T00:50:38.733,"<p>Here's an example of using them in a pipeline safely.  In this case, they are injected as environment variables and their value should never have to be shown unless you explicitly choose to print out the variable content for some reason or other.</p>

<p>Environment variables are generally seen as the best way to store secrets at this point and are heavily relied on by many modern deployments (e.g. often used in kubernetes apps).</p>

<p><a href=""https://www.jenkins.io/doc/book/pipeline/jenkinsfile/#handling-credentials"" rel=""noreferrer"">https://www.jenkins.io/doc/book/pipeline/jenkinsfile/#handling-credentials</a></p>

<pre><code>Jenkinsfile (Declarative Pipeline)
pipeline {
    agent {
        // Define agent details here
    }
    environment {
        AWS_ACCESS_KEY_ID     = credentials('jenkins-aws-secret-key-id')
        AWS_SECRET_ACCESS_KEY = credentials('jenkins-aws-secret-access-key')
    }
    stages {
        stage('Example stage 1') {
            steps {
                // 
            }
        }
        stage('Example stage 2') {
            steps {
                // 
            }
        }
    }
}
</code></pre>

<p>You can also avoid Jenkins altogether by having your pipeline/etc retrieve them from some other tool like HashiCorp Vault, AWS SSM, Azure Vault, etc.</p>
",16059,2020-04-30T00:50:38.733,"[""Jenkinsfile (Declarative Pipeline)\npipeline {\n    agent {\n        // Define agent details here\n    }\n    environment {\n        AWS_ACCESS_KEY_ID     = credentials('jenkins-aws-secret-key-id')\n        AWS_SECRET_ACCESS_KEY = credentials('jenkins-aws-secret-access-key')\n    }\n    stages {\n        stage('Example stage 1') {\n            steps {\n                // \n            }\n        }\n        stage('Example stage 2') {\n            steps {\n                // \n            }\n        }\n    }\n}\n""]"
1326,11472,11408,CC BY-SA 4.0,2020-04-30T12:24:31.207,"<p>Can't tell you why this does not work, I'm not using the Jenkins UI for build configuration anymore. I guess the Jenkins UI is blocking you because it does not recognize tha <code>$GIT_BRANCH</code> is a variable.</p>

<p>We do exactly what you are trying with a script-step in the pipeline, and that works:</p>

<pre><code>stage('Trigger downstream job') {
   steps {
      script {
         build(job: 'SomeJob/' + env.GIT_BRANCH.replaceAll('/', '%2F'),
               parameters: [...],
               propagate: true,
               wait: true)
      }
   }
}
</code></pre>

<p>Note that <code>/</code> in the branchname must be escaped.</p>

<p>So I recommend to rewrite your job with a Jenkinsfile :-)</p>
",7855,2020-04-30T12:24:31.207,"[""stage('Trigger downstream job') {\n   steps {\n      script {\n         build(job: 'SomeJob/' + env.GIT_BRANCH.replaceAll('/', '%2F'),\n               parameters: [...],\n               propagate: true,\n               wait: true)\n      }\n   }\n}\n""]"
1327,11477,11355,CC BY-SA 4.0,2020-04-30T22:27:34.697,"<p>So the way I figured it out was to put the <code>when</code> condition into Jinja.</p>

<pre><code>- hosts: localhost
  vars:
    default_thing_1: 123
    default_thing_2: 456
    default_transport: train
    list_of_things:
      - name: foo
        common_thing_1: ""sam""
      - name: bar
        common_thing_1: ""sam""
        common_thing_2: ""ham""
      - name: biz
        common_thing_1: ""eggs""
  tasks:
    - name: Set the Things Facts
      set_fact:
        thing:
          i_am: ""{{ item.common_thing_1 | default(default_thing_1) }}""
          eggs_ham: ""{{ item.common_thing_2 | default(default_thing_2) }}""
      loop: ""{{ list_of_things }}""
      register: things_fact_results
    - name: Set Optional Things Facts
      set_fact:
        thing: |
          {% if item.common_thing_2 is defined and item.common_thing_2 == 'ham' %}
          { ""transport"": ""{{ item.transport | default(default_transport) }}"" }
          {% else %}
          {}
          {% endif %}
      loop: ""{{ list_of_things }}""
      register: transport_fact_results
    - name: Debug the Facts
      debug:
        msg: ""{{ item.0 | combine(item.1) }}""
      loop: ""{{
        things_fact_results.results |
        map(attribute='ansible_facts.thing') | list |
        zip(
          transport_fact_results.results |
          map(attribute='ansible_facts.thing') | list
        ) | list
      }}""
</code></pre>

<p>This is kinda sloppy but does allow me to specify the else condition to set the result over every iteration to something instead of <code>AnsibleUndefined</code>.</p>

<p>I don't really like this solution but it works.</p>

<pre><code>$ ansible-playbook playbook.yml 
[WARNING]: No inventory was parsed, only implicit localhost is available
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'

PLAY [localhost] *******************************************************************************************************************************************************************

TASK [Gathering Facts] *************************************************************************************************************************************************************
ok: [localhost]

TASK [Set the Things Facts] ********************************************************************************************************************************************************
ok: [localhost] =&gt; (item={'name': 'foo', 'common_thing_1': 'sam'})
ok: [localhost] =&gt; (item={'name': 'bar', 'common_thing_1': 'sam', 'common_thing_2': 'ham'})
ok: [localhost] =&gt; (item={'name': 'biz', 'common_thing_1': 'eggs'})

TASK [Set Optional Things Facts] ***************************************************************************************************************************************************
ok: [localhost] =&gt; (item={'name': 'foo', 'common_thing_1': 'sam'})
ok: [localhost] =&gt; (item={'name': 'bar', 'common_thing_1': 'sam', 'common_thing_2': 'ham'})
ok: [localhost] =&gt; (item={'name': 'biz', 'common_thing_1': 'eggs'})

TASK [Debug the Facts] *************************************************************************************************************************************************************
ok: [localhost] =&gt; (item=[{'i_am': 'sam', 'eggs_ham': '456'}, {}]) =&gt; {
    ""msg"": {
        ""eggs_ham"": ""456"",
        ""i_am"": ""sam""
    }
}
ok: [localhost] =&gt; (item=[{'i_am': 'sam', 'eggs_ham': 'ham'}, {'transport': 'train'}]) =&gt; {
    ""msg"": {
        ""eggs_ham"": ""ham"",
        ""i_am"": ""sam"",
        ""transport"": ""train""
    }
}
ok: [localhost] =&gt; (item=[{'i_am': 'eggs', 'eggs_ham': '456'}, {}]) =&gt; {
    ""msg"": {
        ""eggs_ham"": ""456"",
        ""i_am"": ""eggs""
    }
}

PLAY RECAP *************************************************************************************************************************************************************************
localhost                  : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

</code></pre>

<p>Now the <code>transport</code> key is defined in the one object but not the other. So I can pass the item off to a complex object that's part of an API call.</p>
",21732,2020-04-30T22:27:34.697,"['- hosts: localhost\n  vars:\n    default_thing_1: 123\n    default_thing_2: 456\n    default_transport: train\n    list_of_things:\n      - name: foo\n        common_thing_1: ""sam""\n      - name: bar\n        common_thing_1: ""sam""\n        common_thing_2: ""ham""\n      - name: biz\n        common_thing_1: ""eggs""\n  tasks:\n    - name: Set the Things Facts\n      set_fact:\n        thing:\n          i_am: ""{{ item.common_thing_1 | default(default_thing_1) }}""\n          eggs_ham: ""{{ item.common_thing_2 | default(default_thing_2) }}""\n      loop: ""{{ list_of_things }}""\n      register: things_fact_results\n    - name: Set Optional Things Facts\n      set_fact:\n        thing: |\n          {% if item.common_thing_2 is defined and item.common_thing_2 == \'ham\' %}\n          { ""transport"": ""{{ item.transport | default(default_transport) }}"" }\n          {% else %}\n          {}\n          {% endif %}\n      loop: ""{{ list_of_things }}""\n      register: transport_fact_results\n    - name: Debug the Facts\n      debug:\n        msg: ""{{ item.0 | combine(item.1) }}""\n      loop: ""{{\n        things_fact_results.results |\n        map(attribute=\'ansible_facts.thing\') | list |\n        zip(\n          transport_fact_results.results |\n          map(attribute=\'ansible_facts.thing\') | list\n        ) | list\n      }}""\n', '$ ansible-playbook playbook.yml \n[WARNING]: No inventory was parsed, only implicit localhost is available\n[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match \'all\'\n\nPLAY [localhost] *******************************************************************************************************************************************************************\n\nTASK [Gathering Facts] *************************************************************************************************************************************************************\nok: [localhost]\n\nTASK [Set the Things Facts] ********************************************************************************************************************************************************\nok: [localhost] => (item={\'name\': \'foo\', \'common_thing_1\': \'sam\'})\nok: [localhost] => (item={\'name\': \'bar\', \'common_thing_1\': \'sam\', \'common_thing_2\': \'ham\'})\nok: [localhost] => (item={\'name\': \'biz\', \'common_thing_1\': \'eggs\'})\n\nTASK [Set Optional Things Facts] ***************************************************************************************************************************************************\nok: [localhost] => (item={\'name\': \'foo\', \'common_thing_1\': \'sam\'})\nok: [localhost] => (item={\'name\': \'bar\', \'common_thing_1\': \'sam\', \'common_thing_2\': \'ham\'})\nok: [localhost] => (item={\'name\': \'biz\', \'common_thing_1\': \'eggs\'})\n\nTASK [Debug the Facts] *************************************************************************************************************************************************************\nok: [localhost] => (item=[{\'i_am\': \'sam\', \'eggs_ham\': \'456\'}, {}]) => {\n    ""msg"": {\n        ""eggs_ham"": ""456"",\n        ""i_am"": ""sam""\n    }\n}\nok: [localhost] => (item=[{\'i_am\': \'sam\', \'eggs_ham\': \'ham\'}, {\'transport\': \'train\'}]) => {\n    ""msg"": {\n        ""eggs_ham"": ""ham"",\n        ""i_am"": ""sam"",\n        ""transport"": ""train""\n    }\n}\nok: [localhost] => (item=[{\'i_am\': \'eggs\', \'eggs_ham\': \'456\'}, {}]) => {\n    ""msg"": {\n        ""eggs_ham"": ""456"",\n        ""i_am"": ""eggs""\n    }\n}\n\nPLAY RECAP *************************************************************************************************************************************************************************\nlocalhost                  : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n\n']"
1328,11479,11476,CC BY-SA 4.0,2020-05-01T13:17:57.353,"<p>Figured it out!
The problem is that those DNS settings set in <code>aws_vpc_peering_connection_options</code> cannot be set until the peering connection is active (approved). It was only depending on <code>aws_vpc_peering_connection</code> existing, therefore was running at the same time or before <code>aws_vpc_peering_connection_accepter</code>.</p>

<p>This was simply fixed in <code>aws_vpc_peering_connection_options</code> by getting the <code>vpc_peering_connection_id</code> from <code>aws_vpc_peering_connection_accepter</code> instead of <code>aws_vpc_peering_connection</code>, so that the terraform dependency tree would automatically have the dependency work in the correct order.</p>

<p>Before:</p>

<pre><code>resource ""aws_vpc_peering_connection_options"" ""sb_vpc_peering_options"" {
  vpc_peering_connection_id = aws_vpc_peering_connection.sb_vpc_peering.id

  accepter {
    allow_remote_vpc_dns_resolution = var.accepter_dns_resolution
  }

  requester {
    allow_remote_vpc_dns_resolution = var.requester_dns_resolution
  }
}
</code></pre>

<p>After:</p>

<pre><code>resource ""aws_vpc_peering_connection_options"" ""sb_vpc_peering_options"" {
  vpc_peering_connection_id = aws_vpc_peering_connection_accepter.sb_vpc_peering_accepter.id

  accepter {
    allow_remote_vpc_dns_resolution = var.accepter_dns_resolution
  }

  requester {
    allow_remote_vpc_dns_resolution = var.requester_dns_resolution
  }
}
</code></pre>
",22035,2020-05-01T13:17:57.353,"['resource ""aws_vpc_peering_connection_options"" ""sb_vpc_peering_options"" {\n  vpc_peering_connection_id = aws_vpc_peering_connection.sb_vpc_peering.id\n\n  accepter {\n    allow_remote_vpc_dns_resolution = var.accepter_dns_resolution\n  }\n\n  requester {\n    allow_remote_vpc_dns_resolution = var.requester_dns_resolution\n  }\n}\n', 'resource ""aws_vpc_peering_connection_options"" ""sb_vpc_peering_options"" {\n  vpc_peering_connection_id = aws_vpc_peering_connection_accepter.sb_vpc_peering_accepter.id\n\n  accepter {\n    allow_remote_vpc_dns_resolution = var.accepter_dns_resolution\n  }\n\n  requester {\n    allow_remote_vpc_dns_resolution = var.requester_dns_resolution\n  }\n}\n']"
1329,11483,11482,CC BY-SA 4.0,2020-05-01T19:35:19.233,"<blockquote>
  <p>we'd prefer not to bake them into the actual Docker image itself (plus we want the ability to change the assets without having to recompile the application images).</p>
</blockquote>

<p>This is indeed good properties to have. You are on the right track.</p>

<blockquote>
  <p>The problem, however, comes with our read-only data assets (similar to a game's asset files).</p>
</blockquote>

<p>This can be solved with multiple solutions, it's hard to tell what is the best for you. Here are some alternatives.</p>

<p><strong>Persistent Volume - ReadOnlyMany</strong></p>

<blockquote>
  <p>I know that we're essentially looking for a persistent volume for Kubernetes, but the problem for us is bundling all of the data into a single package that has the same delivery convenience as a Docker image.</p>
</blockquote>

<p>Yes, you could create a <a href=""https://kubernetes.io/docs/concepts/storage/persistent-volumes/"" rel=""nofollow noreferrer"">Persistent Volume</a> with <a href=""https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes"" rel=""nofollow noreferrer"">access modes</a>:</p>

<pre><code>accessModes:
- ReadWriteOnce
- ReadOnlyMany
</code></pre>

<p>then (by an automatic process)</p>

<ol>
<li>Load your data onto the volume with a <a href=""https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/"" rel=""nofollow noreferrer"">Job</a> using access mode <code>ReadWriteOnce</code></li>
<li>Load the volumes to your pods/services using access mode <code>ReadOnlyMany</code></li>
</ol>

<p>and keep the volume immutable, you create a new when you need to change content. You can also use multiple volumes this way.</p>

<p><strong>CDN</strong></p>

<blockquote>
  <p>our read-only data assets (similar to a game's asset files).</p>
</blockquote>

<p>This inherently also sounds what typically is served by <a href=""https://en.wikipedia.org/wiki/Content_delivery_network"" rel=""nofollow noreferrer"">Content Deliver Networks</a>. But it depends on your use case if this is a good solution or not.</p>

<p><strong>Buckets</strong></p>

<p>Data for e.g. CDN is usually stored by ""buckets"" at cloud providers, that may also be an option, then your applications load data using HTTP typically. <a href=""https://min.io/"" rel=""nofollow noreferrer"">Minio</a> may be an alternative if you want to do this in your cluster.</p>
",6162,2020-05-01T19:35:19.233,['accessModes:\n- ReadWriteOnce\n- ReadOnlyMany\n']
1330,11493,11491,CC BY-SA 4.0,2020-05-02T20:56:00.190,"<p>These were made as <a href=""https://github.com/hashicorp/terraform/issues/19424"" rel=""nofollow noreferrer"">errors in 0.12</a>.  You need to put these into tfvars file in a <a href=""https://www.terraform.io/docs/configuration/locals.html"" rel=""nofollow noreferrer"">locals definition</a>. </p>

<pre><code>locals {
   secret_id = ""docker_secret.mysql_db_password.id""
   secret_name = ""docker_secret.mysql_db_password.name""
   file_name = ""/run/secrets/docker_secret.mysql_db_password.name""
</code></pre>

<p>}</p>

<p>Update:
Using a list:</p>

<pre><code>locals {
    secrets = [
        {
            secret_id = ""docker_secret.mysql_db_password.id""
            secret_name = ""docker_secret.mysql_db_password.name""
            file_name = ""/run/secrets/docker_secret.mysql_db_password.name""
        },
        {
            secret_id = ""docker_secret.mysql_root_password.id""
            secret_name = ""docker_secret.mysql_root_password.name""
            file_name = ""/run/secrets/docker_secret.mysql_root_password.name""
        }
    ]
}
</code></pre>

<p>Then to access an individual value, use indexing with variable evaluation: <code>${local.secrets[1].file_name}</code>.</p>
",21951,2020-05-04T00:38:20.310,"['locals {\n   secret_id = ""docker_secret.mysql_db_password.id""\n   secret_name = ""docker_secret.mysql_db_password.name""\n   file_name = ""/run/secrets/docker_secret.mysql_db_password.name""\n', 'locals {\n    secrets = [\n        {\n            secret_id = ""docker_secret.mysql_db_password.id""\n            secret_name = ""docker_secret.mysql_db_password.name""\n            file_name = ""/run/secrets/docker_secret.mysql_db_password.name""\n        },\n        {\n            secret_id = ""docker_secret.mysql_root_password.id""\n            secret_name = ""docker_secret.mysql_root_password.name""\n            file_name = ""/run/secrets/docker_secret.mysql_root_password.name""\n        }\n    ]\n}\n']"
1331,11494,11469,CC BY-SA 4.0,2020-05-02T21:11:03.813,"<p>John's answer works just fine.  An alternative is to use the <code>withCredentials</code> block, which is built right into core Jenkins.</p>

<p><strong>Example</strong></p>

<pre class=""lang-java prettyprint-override""><code>pipeline {
  agent any

  stages {
    ...
    stage('Publish') {
      steps {
        withCredentials([usernamePassword(credentialsId: 'sonar-publisher', usernameVariable: 'SONAR_USER', passwordVariable: 'SONAR_PASSWORD')]) {
          // maybe do stuff with variables, echoing them prints *****
          sh './gradlew sonar'
        }
      }
    }
  }
}
</code></pre>

<p>The only requirement in this scenario is that the credentials <code>sonar-publisher</code> exists on the Jenkins master and your job has access to them.</p>
",22059,2020-05-02T21:11:03.813,"[""pipeline {\n  agent any\n\n  stages {\n    ...\n    stage('Publish') {\n      steps {\n        withCredentials([usernamePassword(credentialsId: 'sonar-publisher', usernameVariable: 'SONAR_USER', passwordVariable: 'SONAR_PASSWORD')]) {\n          // maybe do stuff with variables, echoing them prints *****\n          sh './gradlew sonar'\n        }\n      }\n    }\n  }\n}\n""]"
1332,11495,11481,CC BY-SA 4.0,2020-05-03T00:16:14.040,"<p>There's a lot that you can do, but I'm not sure with the existing filters you easily augment a dict.</p>

<p>Creating a <a href=""https://docs.ansible.com/ansible/latest/dev_guide/developing_plugins.html#filter-plugins"" rel=""nofollow noreferrer"">new filter</a> to do it was easier.</p>

<pre><code>$ cat filter_plugins/addhomedir.py
class FilterModule:
    @staticmethod
    def add_home(_val):
        return [dict(user, home='/home/{0}/'.format(user['name'])) for user in
                _val if 'sudo' not in user]

    def filters(self):
        return {
            'add_homedir': self.add_home
        }
$ cat test1.yml
---
- hosts: localhost
  vars:
     users:
         - name: alice
           sudo: yes
         - name: bob
         - name: charlie
  tasks:
      - debug:
          msg: ""{{ users | add_homedir | list }}""
</code></pre>

<p>You can use set_facts and loop to get the values you want, but the question becomes what format and use of the data is really needed.  I'm not sure creating a new structure is the Right Way (TM).  It could be easier to just calculate the individual value for each item in the list when it is used.</p>

<pre><code>$ cat test2.yml
---
- hosts: localhost
  vars:
      users:
        - name: alice
          sudo: yes
        - name: bob
        - name: charlie
  tasks:
     - user:
         name: ""{{ item['name'] }}""
         create_home: true
         home: ""{{ '/home/{}/'.format(item['name'] }}""
       when: ""'sudo' not in item""
       loop: ""{{ users }}""
</code></pre>
",21951,2020-05-03T00:16:14.040,"['$ cat filter_plugins/addhomedir.py\nclass FilterModule:\n    @staticmethod\n    def add_home(_val):\n        return [dict(user, home=\'/home/{0}/\'.format(user[\'name\'])) for user in\n                _val if \'sudo\' not in user]\n\n    def filters(self):\n        return {\n            \'add_homedir\': self.add_home\n        }\n$ cat test1.yml\n---\n- hosts: localhost\n  vars:\n     users:\n         - name: alice\n           sudo: yes\n         - name: bob\n         - name: charlie\n  tasks:\n      - debug:\n          msg: ""{{ users | add_homedir | list }}""\n', '$ cat test2.yml\n---\n- hosts: localhost\n  vars:\n      users:\n        - name: alice\n          sudo: yes\n        - name: bob\n        - name: charlie\n  tasks:\n     - user:\n         name: ""{{ item[\'name\'] }}""\n         create_home: true\n         home: ""{{ \'/home/{}/\'.format(item[\'name\'] }}""\n       when: ""\'sudo\' not in item""\n       loop: ""{{ users }}""\n']"
1333,11507,11504,CC BY-SA 4.0,2020-05-04T09:01:30.123,"<p>If you run <code>docker run --rm -it alpine:3.7 /bin/sh</code>, created docker container will use default <code>bridge</code> network.</p>

<p>You can see the properties of this network using the following command: <code>docker network inspect bridge</code>. You can see there to which host interface (usually <code>docker0</code>) the network is associated and also what is the subnet for this network (usually <code>172.17.0.0/16</code>).</p>

<p>Additionally, if you run <code>docker run --rm -it alpine:3.7 ip addr</code> command, you should see the IP address of your container, which should be part of previously mentioned subnet.</p>

<p>Then, Docker by default creates NAT iptables rules, which allows the containers to communicate with outside world (as the container IP address is not known to the internet). You can see the rules using <code>sudo iptables -t nat -nvL POSTROUTING</code> command. It should look similar to:</p>

<pre><code>Chain POSTROUTING (policy ACCEPT 144K packets, 15M bytes)
 pkts bytes target     prot opt in     out     source               destination
  392 75916 MASQUERADE  all  --  *      !docker0  172.17.0.0/16        0.0.0.0/0
</code></pre>

<p>Finally, for your container, there is no difference, if you try to reach remote site of your VPN or the internet, as the container only knows how to reach Docker network. You can see that using <code>docker run --rm -it alpine:3.7 ip r</code> command:</p>

<pre><code>default via 172.17.0.1 dev eth0
172.17.0.0/16 dev eth0 scope link  src 172.17.0.2
</code></pre>

<p>So when traffic from the container goes via default route, it hits host routing table (I'm not 100% sure if this is right), it is being routed to your tunnel and then iptables NAT rule applies, changing the source IP of your traffic to IP of your end of the tunnel, so returning traffic will come back over the tunnel as well and then back to your container.</p>
",22084,2020-05-04T09:01:30.123,"['Chain POSTROUTING (policy ACCEPT 144K packets, 15M bytes)\n pkts bytes target     prot opt in     out     source               destination\n  392 75916 MASQUERADE  all  --  *      !docker0  172.17.0.0/16        0.0.0.0/0\n', 'default via 172.17.0.1 dev eth0\n172.17.0.0/16 dev eth0 scope link  src 172.17.0.2\n']"
1334,11510,11491,CC BY-SA 4.0,2020-05-04T09:43:28.923,"<p>According to the <a href=""https://www.terraform.io/docs/providers/docker/r/service.html#advanced"" rel=""nofollow noreferrer"">documentation</a>, you should change your secrets handling to following syntax: </p>

<pre><code>      secrets = [

        {
          secret_id   = docker_secret.mysql_db_password.id
          secret_name = docker_secret.mysql_db_password.name
          file_name   = ""/run/secrets/${docker_secret.mysql_db_password.name}""
        },

        {
          secret_id   = docker_secret.mysql_root_password.id
          secret_name = docker_secret.mysql_root_password.name
          file_name   = ""/run/secrets/${docker_secret.mysql_root_password.name}""
        }
      ]
</code></pre>

<p>So you pass the actual secret ID to the service object and not the Terraform resource reference as a string. The only difference between Terraform 0.11 and 0.12 code is, that in 0.12 you can remove the interpolation syntax (so <code>${}</code>), if you don't actually use it, as you only pass the attribute of other resource, with no additional formatting.</p>
",22084,2020-05-04T09:43:28.923,"['      secrets = [\n\n        {\n          secret_id   = docker_secret.mysql_db_password.id\n          secret_name = docker_secret.mysql_db_password.name\n          file_name   = ""/run/secrets/${docker_secret.mysql_db_password.name}""\n        },\n\n        {\n          secret_id   = docker_secret.mysql_root_password.id\n          secret_name = docker_secret.mysql_root_password.name\n          file_name   = ""/run/secrets/${docker_secret.mysql_root_password.name}""\n        }\n      ]\n']"
1335,11517,10945,CC BY-SA 4.0,2020-05-04T19:26:59.880,"<p>I would expect it to work like <code>az login</code> and open up a new tab in default browser. But somehow it doesn't work like that. I think the fix must come from azure CLI.</p>

<p>Temporarily, For <code>az aks browse</code> you can setup an environment variable on WSL.</p>

<pre><code>export BROWSER=""/mnt/c/Program Files (x86)/Google/Chrome/Application/chrome.exe""
</code></pre>

<p>In this case next when I run <code>az aks browse</code> it will open up the dashboard in new chrome tab.</p>

<p>You can use this variable to use your favorite browser. I would also add this variable to <code>.bashrc</code> or profile to be added on every session.</p>
",22093,2020-05-04T19:26:59.880,"['export BROWSER=""/mnt/c/Program Files (x86)/Google/Chrome/Application/chrome.exe""\n']"
1336,11519,8478,CC BY-SA 4.0,2020-05-04T21:24:37.547,"<p>My workaround looks like this:</p>

<pre class=""lang-java prettyprint-override""><code>pipeline {
    parameters {
        booleanParam(name: 'skip_all_steps', defaultValue: false, description: 'When changed parameters in pipeline, just update code from git')
    }
    stages {
        stage('Stage1'){
            when { not { expression { return params.skip_all_steps } } }
            steps {
                …
            }
        }
        stage('Install requirements') {
            when {
                allOf {
                    expression { return params.install_django_requirements }
                    not { expression { return params.skip_all_steps } }
                }
            }
            steps {
                sh 'pip3 install --upgrade --user -r src-django/requirements.txt'
                }
        }
        …
    }
    post {
        success {
            script {
                if (!params.skip_all_steps.toBoolean() &amp;&amp; params.workspace_cleanup.toBoolean()) {
                    cleanWs()
                }
            }

        }
    }
}
</code></pre>

<p>Be careful:</p>

<ul>
<li>parameters in Jenkins UI will be updated only after <strong>successful</strong> build,</li>
<li>maybe it is better idea to use <code>defaultValue: true</code> for <code>skip_all_steps</code> in your particular case (for example, to avoid running any step on first build)</li>
</ul>
",9938,2020-06-02T20:31:17.573,"[""pipeline {\n    parameters {\n        booleanParam(name: 'skip_all_steps', defaultValue: false, description: 'When changed parameters in pipeline, just update code from git')\n    }\n    stages {\n        stage('Stage1'){\n            when { not { expression { return params.skip_all_steps } } }\n            steps {\n                …\n            }\n        }\n        stage('Install requirements') {\n            when {\n                allOf {\n                    expression { return params.install_django_requirements }\n                    not { expression { return params.skip_all_steps } }\n                }\n            }\n            steps {\n                sh 'pip3 install --upgrade --user -r src-django/requirements.txt'\n                }\n        }\n        …\n    }\n    post {\n        success {\n            script {\n                if (!params.skip_all_steps.toBoolean() && params.workspace_cleanup.toBoolean()) {\n                    cleanWs()\n                }\n            }\n\n        }\n    }\n}\n""]"
1337,11522,8478,CC BY-SA 4.0,2020-05-05T10:51:24.523,"<p>A few years ago I used a similar approach:</p>

<pre><code> parameters {
        booleanParam(
                name: 'ABORT_JOB', defaultValue: false,
                description:    'Set this to true if you need to ""dry-run"" this job without doing any real work.\n' +
                        'The Jenkinsfile will be read and new parameters added. It will exit in the first stage.')
</code></pre>

<p>And in the first stage that runs:</p>

<pre><code>stage('Initialise') {
            steps {
                script {
                    if (params.ABORT_JOB) {
                        currentBuild.result = 'ABORTED'
                        error('Stopping early...')
                    }
</code></pre>

<p>I've since started using JobDSL to generate my jobs.  This simplifies the pipeline code and removes the need to code as above.</p>
",7385,2020-05-05T10:51:24.523,"[' parameters {\n        booleanParam(\n                name: \'ABORT_JOB\', defaultValue: false,\n                description:    \'Set this to true if you need to ""dry-run"" this job without doing any real work.\\n\' +\n                        \'The Jenkinsfile will be read and new parameters added. It will exit in the first stage.\')\n', ""stage('Initialise') {\n            steps {\n                script {\n                    if (params.ABORT_JOB) {\n                        currentBuild.result = 'ABORTED'\n                        error('Stopping early...')\n                    }\n""]"
1338,11527,11491,CC BY-SA 4.0,2020-05-05T18:21:57.377,"<p>It looks like there are two different problems here, so I'll answer them separately.</p>

<hr>

<p>First, we'll talk about the errors of this type:</p>

<pre><code>Error: Unsupported argument

  on main.tf line 8, in resource ""docker_service"" ""mysql-service"":
   8:       secrets = {

An argument named ""secrets"" is not expected here. Did you mean to define a
block of type ""secrets""?
</code></pre>

<p>This error is talking about the distinction described in the Terraform documentation section <a href=""https://www.terraform.io/docs/configuration/syntax.html#arguments-and-blocks"" rel=""nofollow noreferrer"">Arguments and Blocks</a>, and is telling you that <code>secrets</code> is defined in the provider's schema as using nested block syntax rather than argument syntax.</p>

<p>The syntax for nested blocks and the syntax for literal object values are both similar in that they use <code>{</code> <code>}</code> as delimiters, but the meaning of these and what is valid inside the braces in each case is distinct.</p>

<p>To fix this, you can use the block syntax to define these nested objects:</p>

<pre><code>  secrets {
    secret_id   = docker_secret.mysql_root_password.id
    secret_name = docker_secret.mysql_root_password.name
    file_name   = ""/run/secrets/${docker_secret.mysql_root_password.name}""
  }
  secrets {
    secret_id   = docker_secret.mysql_db_password.id
    secret_name = docker_secret.mysql_db_password.name
    file_name   = ""/run/secrets/${docker_secret.mysql_db_password.name}""
  }
</code></pre>

<p>The same is true for the <code>mounts</code> block type:</p>

<pre><code>  mounts {
    target = ""/var/lib/mysql""
    source = docker_volume.mysql_data_volume.name
    type   = ""volume""
  }
</code></pre>

<hr>

<p>The other error message you saw is an unrelated problem:</p>

<pre><code>Error: Incorrect attribute value type

  on main.tf line 34, in resource ""docker_service"" ""mysql-service"":
  34:     networks = ""docker_network.private_overlay_network.name""

Inappropriate value for attribute ""networks"": set of string required.
</code></pre>

<p>This error is saying that the <code>networks</code> argument requires a set of strings, but the value you gave here is a single string. This is happening because you've put the reference expression in quotes, and so Terraform assumes you are intending to give a literal string rather than a reference here. The first step to address this is to remove the quotes so to make this a <a href=""https://www.terraform.io/docs/configuration/expressions.html#references-to-named-values"" rel=""nofollow noreferrer"">reference expression</a> rather than a <a href=""https://www.terraform.io/docs/configuration/expressions.html#literal-expressions"" rel=""nofollow noreferrer"">literal expression</a>:</p>

<pre><code>  networks = docker_network.private_overlay_network.name
</code></pre>

<p>That's not sufficient for this particular situation though, because this <code>name</code> attribute is just a single string rather than a set of strings, and so the above change alone will not fully fix the problem. To address this secondary problem we can use brackets <code>[</code> <code>]</code> to construct a single-element sequence:</p>

<pre><code>  networks = [docker_network.private_overlay_network.name]
</code></pre>

<p>This argument expects a set of strings rather than a sequence of strings, but that's okay here because Terraform will automatically convert the sequence into a set. (A set is an unordered collection of distinct values, whereas a sequence is an ordered collection of values that may contain duplicates.)</p>
",2463,2020-05-05T18:21:57.377,"['Error: Unsupported argument\n\n  on main.tf line 8, in resource ""docker_service"" ""mysql-service"":\n   8:       secrets = {\n\nAn argument named ""secrets"" is not expected here. Did you mean to define a\nblock of type ""secrets""?\n', '  secrets {\n    secret_id   = docker_secret.mysql_root_password.id\n    secret_name = docker_secret.mysql_root_password.name\n    file_name   = ""/run/secrets/${docker_secret.mysql_root_password.name}""\n  }\n  secrets {\n    secret_id   = docker_secret.mysql_db_password.id\n    secret_name = docker_secret.mysql_db_password.name\n    file_name   = ""/run/secrets/${docker_secret.mysql_db_password.name}""\n  }\n', '  mounts {\n    target = ""/var/lib/mysql""\n    source = docker_volume.mysql_data_volume.name\n    type   = ""volume""\n  }\n', 'Error: Incorrect attribute value type\n\n  on main.tf line 34, in resource ""docker_service"" ""mysql-service"":\n  34:     networks = ""docker_network.private_overlay_network.name""\n\nInappropriate value for attribute ""networks"": set of string required.\n', '  networks = docker_network.private_overlay_network.name\n', '  networks = [docker_network.private_overlay_network.name]\n']"
1339,11529,11528,CC BY-SA 4.0,2020-05-05T20:19:38.323,"<p>Something needs to be different in other_job2 for tests['x'] and tests['y'].</p>

<p>Example(untested),</p>

<pre><code>for (f in [ 'x', 'y' ]) { {
    {some code}
    build job: ""other_job2"", parameters: [file_params, string(name:'dummy', value: ""${f}"")], wait: true, propagate: true
    // the dummy parameter is for preventing mutation
}
</code></pre>

<p>More info:
<a href=""https://www.jenkins.io/doc/pipeline/examples/#jobs-in-parallel"" rel=""nofollow noreferrer"">https://www.jenkins.io/doc/pipeline/examples/#jobs-in-parallel</a></p>
",1173,2020-05-05T20:33:23.797,"['for (f in [ \'x\', \'y\' ]) { {\n    {some code}\n    build job: ""other_job2"", parameters: [file_params, string(name:\'dummy\', value: ""${f}"")], wait: true, propagate: true\n    // the dummy parameter is for preventing mutation\n}\n']"
1340,11532,11282,CC BY-SA 4.0,2020-05-06T03:09:52.167,"<p>You can add this in inventory:</p>

<pre><code>ansible_ssh_common_args=""-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null""
</code></pre>

<p>It's ignoring check host and setting /dev/null as Known host file.</p>
",22072,2020-05-06T06:25:27.347,"['ansible_ssh_common_args=""-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null""\n']"
1341,11541,11539,CC BY-SA 4.0,2020-05-06T23:40:46.027,"<p>You can use Docker volume mounts at run time.  For example:</p>

<pre><code>$ mkdir -p app/src logs
$ touch app/src/foo.c logs/bar.txt
$ docker run --rm -v $PWD/app:/app -v $PWD/logs:/app/logs alpine ls -l /app /app/src /app/logs
/app:
total 8
drwxr-xr-x    2 1000     1000          4096 May  6 23:33 logs
drwxr-xr-x    2 1000     1000          4096 May  6 23:33 src

/app/logs:
total 0
-rw-r--r--    1 1000     1000             0 May  6 23:33 bar.txt

/app/src:
total 0
-rw-r--r--    1 1000     1000             0 May  6 23:33 foo.c
</code></pre>

<p>This mounts two directories on the host into the docker container.  Notice in this example that inside the container, they are mount on inside the other.</p>
",21951,2020-05-06T23:40:46.027,['$ mkdir -p app/src logs\n$ touch app/src/foo.c logs/bar.txt\n$ docker run --rm -v $PWD/app:/app -v $PWD/logs:/app/logs alpine ls -l /app /app/src /app/logs\n/app:\ntotal 8\ndrwxr-xr-x    2 1000     1000          4096 May  6 23:33 logs\ndrwxr-xr-x    2 1000     1000          4096 May  6 23:33 src\n\n/app/logs:\ntotal 0\n-rw-r--r--    1 1000     1000             0 May  6 23:33 bar.txt\n\n/app/src:\ntotal 0\n-rw-r--r--    1 1000     1000             0 May  6 23:33 foo.c\n']
1342,11542,885,CC BY-SA 4.0,2020-05-07T00:55:38.910,"<p>I was <em>almost</em> able to accomplish this with declarative pipeline. This allows you to exit the before the pipeline starts based on the outcome of a shell script. I was not able to get this working within the pipeline itself (either within or between stages).</p>

<pre><code>node('master'){
    env.status_code = sh(script: 'exit 0 # or 200 or other', returnStatus:true)
}
println 'status_code: ' + env.status_code
if(env.status_code == '200'){
    println 'Now is not the time to run the pipeline.'
    println 'Exiting without running subsequent stages.'
    currentBuild.result = 'SUCCESS'
    return
} else if(env.status_code == '0'){
    println 'Time to run. Let\'s go!'
} else {
    error 'Unable to check if it\'s time to run.'
}

pipeline {
  agent any
  stages {
      stage('Run only if exit status for was 0'){
          steps{
             sh 'echo hi'
          }
      }
  }
}
</code></pre>

<p><code>when</code> directive may help if you only want to skip certain stages, not exit entirely.</p>

<p><a href=""https://www.jenkins.io/doc/book/pipeline/syntax/#when"" rel=""nofollow noreferrer"">https://www.jenkins.io/doc/book/pipeline/syntax/#when</a></p>
",22154,2020-05-07T00:55:38.910,"[""node('master'){\n    env.status_code = sh(script: 'exit 0 # or 200 or other', returnStatus:true)\n}\nprintln 'status_code: ' + env.status_code\nif(env.status_code == '200'){\n    println 'Now is not the time to run the pipeline.'\n    println 'Exiting without running subsequent stages.'\n    currentBuild.result = 'SUCCESS'\n    return\n} else if(env.status_code == '0'){\n    println 'Time to run. Let\\'s go!'\n} else {\n    error 'Unable to check if it\\'s time to run.'\n}\n\npipeline {\n  agent any\n  stages {\n      stage('Run only if exit status for was 0'){\n          steps{\n             sh 'echo hi'\n          }\n      }\n  }\n}\n""]"
1343,11555,11318,CC BY-SA 4.0,2020-05-07T23:43:03.767,"<p>Using <code>docker-compose</code> version 3.3 extensions and with the long variants for <code>ports</code> &amp; <code>volumes</code>:</p>

<pre><code>version: '3.3'
services:
  s1: &amp;s
    build: .
    ports:
    - published: 5001
      target: 9000
    volumes:
    - source: ../www1
      target: /var/www
  s2:
    &lt;&lt;: *s
    ports:
    - published: 5002
    volumes:
    - source: ../www2
  s3:
    &lt;&lt;: *s
    ports:
    - published: 5003
    volumes:
    - source: ../www3
</code></pre>

<p>Not really more compact, but native :-)</p>

<p>Version 3.4 introduced <a href=""https://medium.com/@kinghuang/docker-compose-anchors-aliases-extensions-a1e4105d70bd"" rel=""nofollow noreferrer"">further improvements into making docker-compose.yml more DRY</a>. </p>

<p>Perhaps someone more experienced will point to even greater developments yet!</p>
",20393,2020-05-07T23:43:03.767,"[""version: '3.3'\nservices:\n  s1: &s\n    build: .\n    ports:\n    - published: 5001\n      target: 9000\n    volumes:\n    - source: ../www1\n      target: /var/www\n  s2:\n    <<: *s\n    ports:\n    - published: 5002\n    volumes:\n    - source: ../www2\n  s3:\n    <<: *s\n    ports:\n    - published: 5003\n    volumes:\n    - source: ../www3\n""]"
1344,11557,11548,CC BY-SA 4.0,2020-05-08T16:06:56.313,"<p>Your block expression doesn't return a value in all cases.</p>

<p>Try this instead:</p>

<pre><code>waitUntil { folder.exists() }
</code></pre>
",4115,2020-05-08T16:06:56.313,['waitUntil { folder.exists() }\n']
1345,11563,11534,CC BY-SA 4.0,2020-05-09T12:51:35.897,"<p>Honestly, I'm confused your question. It's meant to prevent git pull IAM user for specific repository or something else?</p>

<p>Here is example of how to deny policy for specific repository that can be attached to your IAM users.</p>

<pre><code>{
  ""Version"": ""2012-10-17"",
  ""Statement"" : [
    {
      ""Effect"" : ""Deny"",
      ""Action"" : [
        ""codecommit:*""
      ],
      ""Resource"" : [
        ""arn:aws:codecommit:us-east-2:111111111111:myrepo""
      ]
    }
  ]
}
</code></pre>
",16004,2020-05-09T12:51:35.897,"['{\n  ""Version"": ""2012-10-17"",\n  ""Statement"" : [\n    {\n      ""Effect"" : ""Deny"",\n      ""Action"" : [\n        ""codecommit:*""\n      ],\n      ""Resource"" : [\n        ""arn:aws:codecommit:us-east-2:111111111111:myrepo""\n      ]\n    }\n  ]\n}\n']"
1346,11567,5248,CC BY-SA 4.0,2020-05-09T22:18:08.140,"<p>If you have Jenkins user public key, on your target hosts authorized keys file, for the user you want to login as, ssh connection authorization should work. </p>

<p>This is an example of Jenkinsfile step. </p>

<pre><code>ansiblePlaybook colorized: true, installation: 'Ansible', inventory: 'inventory', playbook: 'playbook.yml',tags: """" , skippedTags: """", extras: ""--extra-vars ' hst=targetHost ""

</code></pre>

<p>This is Ansible Inventory example. You can define the args at the host level as well.</p>

<pre><code>[targetHost]
17.14.69.21 ansible_ssh_user=sshuser

[all:vars]
ansible_connection=ssh
ansible_ssh_common_args='-o StrictHostKeyChecking=no -oHostKeyAlgorithms=+ssh-dss'
</code></pre>
",14930,2020-05-09T22:18:08.140,"['ansiblePlaybook colorized: true, installation: \'Ansible\', inventory: \'inventory\', playbook: \'playbook.yml\',tags: """" , skippedTags: """", extras: ""--extra-vars \' hst=targetHost ""\n\n', ""[targetHost]\n17.14.69.21 ansible_ssh_user=sshuser\n\n[all:vars]\nansible_connection=ssh\nansible_ssh_common_args='-o StrictHostKeyChecking=no -oHostKeyAlgorithms=+ssh-dss'\n""]"
1347,11571,11553,CC BY-SA 4.0,2020-05-10T14:18:14.070,"<p>Got answer from StackOverflow and here is the <a href=""https://stackoverflow.com/questions/61702811/it-is-not-allowed-to-use-stages-more-than-once-jenkins-declarative-pipeline"">link</a> to the answer.</p>

<pre><code>stage('Test') {
    parallel {
        stage(""Test_A"") { 
            stages {
                stage(""Tests_A"") { steps { echo 'from A' } } 
                stage(""Archieve"") { steps { echo 'from Archieve' } }
            }
        }
        stage(""Test_B"") {
            ...
        }

        ... and so on
    }
}
</code></pre>
",20031,2020-05-10T14:18:14.070,"['stage(\'Test\') {\n    parallel {\n        stage(""Test_A"") { \n            stages {\n                stage(""Tests_A"") { steps { echo \'from A\' } } \n                stage(""Archieve"") { steps { echo \'from Archieve\' } }\n            }\n        }\n        stage(""Test_B"") {\n            ...\n        }\n\n        ... and so on\n    }\n}\n']"
1348,11586,11574,CC BY-SA 4.0,2020-05-11T19:19:01.013,"<blockquote>
  <p>2) App repo's CI commits into Configuration repo with newly built image tags.</p>
</blockquote>

<p>Yes, this makes sense. Instead of using <em>image tags</em> you can use <em>image digest</em>, since the digest is generated from content, it is immutable, while tags may be updated (intentionally or unintentionally).</p>

<p>This manifest update can be done with multiple tools:</p>

<p>Using <a href=""https://github.com/mikefarah/yq"" rel=""nofollow noreferrer"">yq</a></p>

<pre><code>yq write --inplace  deployment.yaml 'spec.template.spec.containers(name==myappname).image' gcr.io/my-image-repository/myappname:labelOrDigest
</code></pre>

<p>Or using a newer tool; <a href=""https://googlecontainertools.github.io/kpt/"" rel=""nofollow noreferrer"">kpt</a> with the <a href=""https://googlecontainertools.github.io/kpt/guides/consumer/set/"" rel=""nofollow noreferrer"">ktp set</a> command.</p>
",6162,2020-05-11T19:19:01.013,"[""yq write --inplace  deployment.yaml 'spec.template.spec.containers(name==myappname).image' gcr.io/my-image-repository/myappname:labelOrDigest\n""]"
1349,11589,11534,CC BY-SA 4.0,2020-05-12T06:35:17.110,"<p>I found what i needed to allow or the eqivalent StringNotEquals to deny useing the tag
aws:ResourceTag</p>

<pre><code>""Condition"": {
                ""StringEquals"": {
                    ""aws:ResourceTag/Key_-1"": ""Value_-1""
                }
            }
</code></pre>
",17276,2020-05-12T06:35:17.110,"['""Condition"": {\n                ""StringEquals"": {\n                    ""aws:ResourceTag/Key_-1"": ""Value_-1""\n                }\n            }\n']"
1350,11602,11592,CC BY-SA 4.0,2020-05-14T07:08:32.830,"<p>It looks like Groovy can't find your class at the path specified.</p>

<p>Try renaming the file common.groovy to match the class name and move it to the common folder:</p>

<pre><code>src/org/common/CommonFuncs.groovy
</code></pre>
",22231,2020-05-14T07:08:32.830,['src/org/common/CommonFuncs.groovy\n']
1351,11603,11596,CC BY-SA 4.0,2020-05-14T08:26:56.513,"<p>In the end solved it myself, I had to just define jira.summary and description respectively and copy/paste the contents from the slack integration in the given fields.</p>

<pre><code>{{ define ""jira.summary"" }}]
    {{ .Alerts.Firing | len }} {{ .CommonLabels.alertname }} for {{ .CommonLabels.job }}
    {{- if gt (len .CommonLabels) (len .GroupLabels) -}}
    {{"" ""}}(
    {{- with .CommonLabels.Remove .GroupLabels.Names }}
        {{- range $index, $label := .SortedPairs -}}
        {{ if $index }}, {{ end }}
        {{- $label.Name }}=""{{ $label.Value -}}""
        {{- end }}
    {{- end -}}
    )
    {{- end }}
{{- end }}
{{ define ""jira.description"" }}
    {{ with index .Alerts 0 -}}
    :chart_with_upwards_trend: *&lt;{{ .GeneratorURL }}|Graph&gt;*
    {{- if .Annotations.runbook }}   :notebook: *&lt;{{ .Annotations.runbook }}|Runbook&gt;*{{ end }}
    {{ end }}
    *Kubernetes Cluster:* `default`
    *Prometheus Alert Details*:
        {{ range .Alerts -}}
        *Prometheus Alert:* {{ .Annotations.title }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}
        *Prometheus Alert Description:* {{ .Annotations.message }}
        *Prometheus Alert Details:*
            {{ range .Labels.SortedPairs }}  *{{ .Name }}:* `{{ .Value }}`
            {{ end }}
    {{ end }}
{{- end }}
</code></pre>
",17329,2020-05-14T08:26:56.513,"['{{ define ""jira.summary"" }}]\n    {{ .Alerts.Firing | len }} {{ .CommonLabels.alertname }} for {{ .CommonLabels.job }}\n    {{- if gt (len .CommonLabels) (len .GroupLabels) -}}\n    {{"" ""}}(\n    {{- with .CommonLabels.Remove .GroupLabels.Names }}\n        {{- range $index, $label := .SortedPairs -}}\n        {{ if $index }}, {{ end }}\n        {{- $label.Name }}=""{{ $label.Value -}}""\n        {{- end }}\n    {{- end -}}\n    )\n    {{- end }}\n{{- end }}\n{{ define ""jira.description"" }}\n    {{ with index .Alerts 0 -}}\n    :chart_with_upwards_trend: *<{{ .GeneratorURL }}|Graph>*\n    {{- if .Annotations.runbook }}   :notebook: *<{{ .Annotations.runbook }}|Runbook>*{{ end }}\n    {{ end }}\n    *Kubernetes Cluster:* `default`\n    *Prometheus Alert Details*:\n        {{ range .Alerts -}}\n        *Prometheus Alert:* {{ .Annotations.title }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}\n        *Prometheus Alert Description:* {{ .Annotations.message }}\n        *Prometheus Alert Details:*\n            {{ range .Labels.SortedPairs }}  *{{ .Name }}:* `{{ .Value }}`\n            {{ end }}\n    {{ end }}\n{{- end }}\n']"
1352,11612,11598,CC BY-SA 4.0,2020-05-14T16:06:19.860,"<p>What you want is a <a href=""https://www.jenkins.io/doc/book/pipeline/shared-libraries/"" rel=""nofollow noreferrer"">Jenkins shared library</a> which will allow you to (among other things) define custom Pipeline DSL steps in a repository you own.  See the <a href=""https://www.jenkins.io/doc/book/pipeline/shared-libraries/#defining-custom-steps"" rel=""nofollow noreferrer"">""Defining custom steps"" section</a> in that document.</p>

<p>Here's the example custom step from that document:</p>

<pre><code>// vars/sayHello.groovy
def call(String name = 'human') {
    // Any valid steps can be called from this code, just like in other
    // Scripted Pipeline
    echo ""Hello, ${name}.""
}
</code></pre>
",4115,2020-05-14T16:06:19.860,"['// vars/sayHello.groovy\ndef call(String name = \'human\') {\n    // Any valid steps can be called from this code, just like in other\n    // Scripted Pipeline\n    echo ""Hello, ${name}.""\n}\n']"
1353,11620,11617,CC BY-SA 4.0,2020-05-15T13:00:13.360,"<p>The issue seems resolved, If I escape the backslash in the regex too:</p>

<pre><code>- name: Remove LE webroot definition
    lineinfile: 
      path: ""/etc/path/to/config/{{ inventory_hostname }}.conf""
      regexp: ""^{{ inventory_hostname | replace('.', '\\.') }} = /path/to/a/directory""
      state: absent
</code></pre>
",16778,2020-05-18T07:58:48.747,"['- name: Remove LE webroot definition\n    lineinfile: \n      path: ""/etc/path/to/config/{{ inventory_hostname }}.conf""\n      regexp: ""^{{ inventory_hostname | replace(\'.\', \'\\\\.\') }} = /path/to/a/directory""\n      state: absent\n']"
1354,11624,11623,CC BY-SA 4.0,2020-05-15T18:05:56.993,"<p>Turns out I was missing one very important line in my KMS key policy:</p>

<pre><code>    resources = [""*""]
</code></pre>

<p>Now it works fine, and my full policy looks like this:</p>

<pre><code>{
    ""Version"": ""2012-10-17"",
    ""Statement"": [
        {
            ""Sid"": ""Allow VPC Flow Logs to use the key"",
            ""Effect"": ""Allow"",
            ""Principal"": {
                ""Service"": ""delivery.logs.amazonaws.com""
            },
            ""Action"": [
                ""kms:ReEncrypt"",
                ""kms:GenerateDataKey"",
                ""kms:Encrypt"",
                ""kms:DescribeKey"",
                ""kms:Decrypt""
            ],
            ""Resource"": ""*""
        }
    ]
}
</code></pre>
",7770,2020-05-15T18:05:56.993,"['    resources = [""*""]\n', '{\n    ""Version"": ""2012-10-17"",\n    ""Statement"": [\n        {\n            ""Sid"": ""Allow VPC Flow Logs to use the key"",\n            ""Effect"": ""Allow"",\n            ""Principal"": {\n                ""Service"": ""delivery.logs.amazonaws.com""\n            },\n            ""Action"": [\n                ""kms:ReEncrypt"",\n                ""kms:GenerateDataKey"",\n                ""kms:Encrypt"",\n                ""kms:DescribeKey"",\n                ""kms:Decrypt""\n            ],\n            ""Resource"": ""*""\n        }\n    ]\n}\n']"
1355,11628,11627,CC BY-SA 4.0,2020-05-15T19:47:53.217,"<p>I forgot to add a MAVEN_OPTS variable in mavenOptions:<br>
    <code>mavenOptions: '-Xmx3072m $(MAVEN_OPTS)'</code></p>

<p>My pipeline.yml stayed like this:  </p>

<pre><code>trigger:
- master

pool:
  vmImage: 'ubuntu-latest'

variables:
  MAVEN_CACHE_FOLDER: $(Pipeline.Workspace)/.m2/repository
  MAVEN_OPTS: '-Dmaven.repo.local=$(MAVEN_CACHE_FOLDER)'


steps:

- task: Cache@2
  inputs:
    key: 'maven | ""$(Agent.OS)"" | **/pom.xml'
    restoreKeys: |
      maven | ""$(Agent.OS)""
      maven
    path: $(MAVEN_CACHE_FOLDER)
  displayName: Cache Maven local repo

- task: Maven@3
  inputs:
    mavenPomFile: 'pom.xml'
    mavenOptions: '-Xmx3072m $(MAVEN_OPTS)'
    javaHomeOption: 'JDKVersion'
    jdkVersionOption: '1.8'
    jdkArchitectureOption: 'x64'
    publishJUnitResults: true
    testResultsFiles: '**/surefire-reports/TEST-*.xml'
    goals: 'clean package'
    codeCoverageToolOption: JaCoCo
    sonarQubeRunAnalysis: false
- task: PublishPipelineArtifact@1
  inputs:
    targetPath: '$(Pipeline.Workspace)'
    publishLocation: 'pipeline'

- script: mvn install -B -e
</code></pre>
",22281,2020-05-15T19:47:53.217,"['trigger:\n- master\n\npool:\n  vmImage: \'ubuntu-latest\'\n\nvariables:\n  MAVEN_CACHE_FOLDER: $(Pipeline.Workspace)/.m2/repository\n  MAVEN_OPTS: \'-Dmaven.repo.local=$(MAVEN_CACHE_FOLDER)\'\n\n\nsteps:\n\n- task: Cache@2\n  inputs:\n    key: \'maven | ""$(Agent.OS)"" | **/pom.xml\'\n    restoreKeys: |\n      maven | ""$(Agent.OS)""\n      maven\n    path: $(MAVEN_CACHE_FOLDER)\n  displayName: Cache Maven local repo\n\n- task: Maven@3\n  inputs:\n    mavenPomFile: \'pom.xml\'\n    mavenOptions: \'-Xmx3072m $(MAVEN_OPTS)\'\n    javaHomeOption: \'JDKVersion\'\n    jdkVersionOption: \'1.8\'\n    jdkArchitectureOption: \'x64\'\n    publishJUnitResults: true\n    testResultsFiles: \'**/surefire-reports/TEST-*.xml\'\n    goals: \'clean package\'\n    codeCoverageToolOption: JaCoCo\n    sonarQubeRunAnalysis: false\n- task: PublishPipelineArtifact@1\n  inputs:\n    targetPath: \'$(Pipeline.Workspace)\'\n    publishLocation: \'pipeline\'\n\n- script: mvn install -B -e\n']"
1356,11636,11633,CC BY-SA 4.0,2020-05-17T19:44:41.360,"<p>There are 2 really major points for Docker containers. </p>

<ol>
<li>You make sure the app dependencies are versioned and encapsulated
inside the container. Container runs smoothly eveywhere, as long as you have the Docker daemon.</li>
<li>You have the capability to create/destroy a
container on any time, also known as ephemeral property. You could test easily, maintain N of them if needed ( Replica Sets in K8S for example are doing just that, Docker Swarm uses services to maintain this number as well ).</li>
</ol>

<p>The official Docker docs defines an image as</p>

<blockquote>
  <p>An image is a read-only template with instructions for creating a
  Docker container</p>
</blockquote>

<p>You can't remove an image, because the container relies on it. </p>

<pre><code>docker image rm ubuntu:20.04
Error response from daemon: conflict: unable to remove repository reference ""ubuntu:20.04"" (must force) - container ecd06b4eb4bf is using its referenced image
</code></pre>

<p>Then you might force the process</p>

<pre><code> docker image rm -f ubuntu:20.04
Untagged: ubuntu:20.04
Untagged: ubuntu@sha256:747d2dbbaaee995098c9792d99bd333c6783ce56150d1b11e333bbceed5c54d7
Untagged: ubuntu@sha256:8bce67040cd0ae39e0beb55bcb976a824d9966d2ac8d2e4bf6119b45505cee64
</code></pre>

<p>But that just untags the image, it's still here.</p>

<pre><code>docker image ls
REPOSITORY             TAG                                        IMAGE ID            CREATED             SIZE
&lt;none&gt;                 &lt;none&gt;                                     1d622ef86b13        3 weeks ago         73.9MB
</code></pre>

<p>So to your question, the best practice is to only remove images that are not being used by any containers. If you maintain 2-5 versions of your app, you could safely remove the others. Also you schould strive for minimum size of each image, even in total that schould not bother your available space that much. </p>
",20101,2020-05-17T19:44:41.360,"['docker image rm ubuntu:20.04\nError response from daemon: conflict: unable to remove repository reference ""ubuntu:20.04"" (must force) - container ecd06b4eb4bf is using its referenced image\n', ' docker image rm -f ubuntu:20.04\nUntagged: ubuntu:20.04\nUntagged: ubuntu@sha256:747d2dbbaaee995098c9792d99bd333c6783ce56150d1b11e333bbceed5c54d7\nUntagged: ubuntu@sha256:8bce67040cd0ae39e0beb55bcb976a824d9966d2ac8d2e4bf6119b45505cee64\n', 'docker image ls\nREPOSITORY             TAG                                        IMAGE ID            CREATED             SIZE\n<none>                 <none>                                     1d622ef86b13        3 weeks ago         73.9MB\n']"
1357,11640,11634,CC BY-SA 4.0,2020-05-18T18:28:37.817,"<p><strong>EDIT:</strong> Updating my answer to include steps on using the Declarative Directive Generator.</p>

<p>You can experiment with the different available configuration options, and sometimes gets hints as to what certain settings provide. For this specific case:</p>

<ol>
<li>Navigate to <code>&lt;$JENKINS_URL&gt;/directive-generator/</code></li>
<li>Select <code>parameters: Parameters</code> from the <strong>Sample Directive</strong> drop-down.</li>
<li>Click the <strong>Add</strong> button and select <code>extendedChoice: Extended Choice Parameter</code></li>
<li>Select <code>JSON Parameter Type</code> and then experiment with the available options.</li>
<li>When finished, click <strong>Generate Declarative Directive</strong> to generate the code block to paste into your pipeline.</li>
</ol>

<p><a href=""https://i.stack.imgur.com/HU20V.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HU20V.png"" alt=""Using the Declarative Directive Generator""></a></p>

<p>You can add the <code>javascriptFile</code> parameter and change the <code>type</code> to <code>PT_JSON</code>.</p>

<p>Using your example:</p>

<pre><code>properties([
    [$class: 'BuildDiscarderProperty', strategy: [$class: 'LogRotator', numToKeepStr: '500']],
    parameters([extendedChoice( 
    defaultValue: 'One,Two,Three,Four', 
    description: '', 
    javascriptFile: '/path/to/file.json',
    multiSelectDelimiter: ',', 
    name: 'SAMPLE_EXTENDED_CHOICE', 
    quoteValue: false, 
    saveJSONParameterToFile: false, 
    type: 'PT_JSON', 
    value:'One,Two,Three,Four,Five,Six,Seven,Eight,Nine,Ten', 
    visibleItemCount: 10)
</code></pre>
",9148,2020-05-21T21:12:17.027,"[""properties([\n    [$class: 'BuildDiscarderProperty', strategy: [$class: 'LogRotator', numToKeepStr: '500']],\n    parameters([extendedChoice( \n    defaultValue: 'One,Two,Three,Four', \n    description: '', \n    javascriptFile: '/path/to/file.json',\n    multiSelectDelimiter: ',', \n    name: 'SAMPLE_EXTENDED_CHOICE', \n    quoteValue: false, \n    saveJSONParameterToFile: false, \n    type: 'PT_JSON', \n    value:'One,Two,Three,Four,Five,Six,Seven,Eight,Nine,Ten', \n    visibleItemCount: 10)\n""]"
1358,11643,11625,CC BY-SA 4.0,2020-05-19T00:25:53.187,"<p>Use the <code>result</code> property of object returned from the <code>build</code> step.</p>

<p>This was already asked and <a href=""https://stackoverflow.com/a/52961436/1824868"">has an answer over on StackOverflow</a>.  Additionally, this is hinted at in the <a href=""https://www.jenkins.io/doc/pipeline/steps/pipeline-build-step/"" rel=""nofollow noreferrer"">official build step documentation</a> in the description for the <code>propagate</code> parameter (""use the <code>result</code> property of the return value as needed"").  I haven't tested it as I don't have a test Jenkins instance available right now, but based on those two pieces of information it looks like something like this should do the trick:</p>

<pre><code>def b = build('my-job-name', wait: true)

def r = b.result
</code></pre>
",4115,2020-05-19T00:25:53.187,"[""def b = build('my-job-name', wait: true)\n\ndef r = b.result\n""]"
1359,11645,11630,CC BY-SA 4.0,2020-05-19T07:08:25.803,"<p>I believe that the problem lies on your proxy environment variables.</p>

<pre><code>$ docker run \
    --name myjenkins \
    -p 7000:8080 \
    -p 50000:50000 \
    --env HTTP_PROXY=""http:// localhost:8080"" \
    --env HTTPS_PROXY=""https:// localhost:8080"" \
    -v /var/jenkins_home \
    jenkins
</code></pre>

<p>The values of <code>$HTTP_PROXY</code> and <code>$HTTP_PROXY</code> are not supposed to have space characters on them and the protocol should be <code>http</code>. Additionally, although setting <code>$HTTP_PROXY</code> is useful for compatibility with other applications running inside the container, <code>curl</code> expects the HTTP proxy environment variable to be written in lowercase, that is, <code>$http_proxy</code>. From <a href=""https://linux.die.net/man/1/curl"" rel=""nofollow noreferrer""><code>curl (1)</code> manual page</a>:</p>

<blockquote>
  <h2>Environment</h2>
  
  <p>The environment variables can be specified in lower case or upper case. The lower case version has precedence. <code>http_proxy</code> is an exception as it is only available in lower case.</p>
  
  <p><code>http_proxy [protocol://]&lt;host&gt;[:port]</code>
  Sets the proxy server to use for HTTP.</p>
  
  <p><code>HTTPS_PROXY [protocol://]&lt;host&gt;[:port]</code>
  Sets the proxy server to use for HTTPS.</p>
  
  <p><code>FTP_PROXY [protocol://]&lt;host&gt;[:port]</code>
  Sets the proxy server to use for FTP.</p>
  
  <p><code>ALL_PROXY [protocol://]&lt;host&gt;[:port]</code>
  Sets the proxy server to use if no protocol-specific proxy is set.</p>
  
  <p><code>NO_PROXY &lt;comma-separated list of hosts&gt;</code>
  list of host names that shouldn't go through any proxy. If set to a asterisk '*' only, it matches all hosts.</p>
</blockquote>

<p>Therefore the <code>docker run</code> command might be written as below:</p>

<pre><code>$ docker run \
    --name myjenkins \
    -p 7000:8080 \
    -p 50000:50000 \
    --env HTTP_PROXY=""http://localhost:8080"" \
    --env http_proxy=""http://localhost:8080"" \
    --env HTTPS_PROXY=""http://localhost:8080"" \
    --env https_proxy=""http://localhost:8080"" \
    -v /var/jenkins_home \
    jenkins
</code></pre>

<p>However, my solution will certainly not work because the port 8080 inside the container is being used by Jenkins and not by a HTTP proxy. Please, could you provide more information on how your work proxy is set up so I can edit my answer with more accurate details? Are you running a HTTP proxy such as <code>squid</code> or <code>cntlm</code> in your computer that receives requests from applications running in your workstation and forwards them to the corporate proxy after authentication? If so, you will need to adjust container's network configuration according to Stack Overflow question <a href=""https://stackoverflow.com/q/24319662"">From inside of a Docker container, how do I connect to the localhost of the machine?</a>.</p>

<hr>

<p><strong>EDIT:</strong> According to comments, a <code>cntlm</code> instance running locally on port <code>8080/tcp</code> provides a HTTP proxy service that local applications must use in order to access internet. I believe that the least complex way to expose it to Jenkins container is by specifying <code>--network=host</code> parameter and sharing <a href=""https://lwn.net/Articles/580893/"" rel=""nofollow noreferrer"">the root network namespace</a> with the Jenkins container. However, Jenkins is set to listen the port <code>8080/tcp</code> by default, therefore it must be instructed to listen to an alternative port, such as <code>7000/tcp</code>. That can be achieved by passing <a href=""https://stackoverflow.com/a/15265306""><code>--httpPort=#</code> command line argument</a> to Jenkins via <a href=""https://github.com/jenkinsci/docker/blob/master/README.md#passing-jenkins-launcher-parameters"" rel=""nofollow noreferrer""><code>JENKINS_OPTS</code> environment variable</a>.</p>

<p><strong>EDIT 2:</strong> While analyzing the <a href=""https://github.com/jenkinsci/docker/"" rel=""nofollow noreferrer"">repository code</a>, I've realized that Jenkins is a Java application and I am not sure that JVM recognizes <code>$http_proxy</code> and <code>$https_proxy</code> environment variables properly. So, to ensure that Jenkins will use <code>cntlm</code> as HTTP proxy, I also suggest passing <a href=""https://docs.oracle.com/javase/8/docs/api/java/net/doc-files/net-properties.html"" rel=""nofollow noreferrer"">proxy configuration properties</a> to the JVM via the <a href=""https://github.com/jenkinsci/docker/blob/master/README.md#passing-jvm-parameters"" rel=""nofollow noreferrer""><code>JAVA_OPTS</code> environment variable</a>.</p>

<p><strong>EDIT 3:</strong> The Docker image <a href=""https://hub.docker.com/_/jenkins"" rel=""nofollow noreferrer""><code>jenkins</code></a> is deprecated in favor of the <a href=""https://hub.docker.com/r/jenkins/jenkins"" rel=""nofollow noreferrer""><code>jenkins/jenkins:lts</code></a> one. The former image is currently unmaintained and seems to contain a version that is outdated and incompatible with plugins being downloaded.</p>

<p>To sum up, the <code>docker run</code> command have to be written as below for Jenkins to work in your environment:</p>

<pre><code>$ docker run \
    --name myjenkins \
    --network=host \
    --env HTTP_PROXY=""http://localhost:8080"" \
    --env http_proxy=""http://localhost:8080"" \
    --env HTTPS_PROXY=""http://localhost:8080"" \
    --env https_proxy=""http://localhost:8080"" \
    --env JAVA_OPTS=""-Dhttp.proxyHost=localhost -Dhttp.proxyPort=8080 -Dhttps.proxyHost=localhost -Dhttps.proxyPort=8080"" \
    --env JENKINS_OPTS=""--httpPort=7000"" \
    -v /var/jenkins_home \
    jenkins/jenkins:lts
</code></pre>

<p>Passing <code>--env JAVA_OPTS=""-Djava.net.useSystemProxies=true""</code> instead might work. I am not able to perform a try, though.</p>
",22312,2020-05-21T20:50:16.443,"['$ docker run \\\n    --name myjenkins \\\n    -p 7000:8080 \\\n    -p 50000:50000 \\\n    --env HTTP_PROXY=""http:// localhost:8080"" \\\n    --env HTTPS_PROXY=""https:// localhost:8080"" \\\n    -v /var/jenkins_home \\\n    jenkins\n', '$ docker run \\\n    --name myjenkins \\\n    -p 7000:8080 \\\n    -p 50000:50000 \\\n    --env HTTP_PROXY=""http://localhost:8080"" \\\n    --env http_proxy=""http://localhost:8080"" \\\n    --env HTTPS_PROXY=""http://localhost:8080"" \\\n    --env https_proxy=""http://localhost:8080"" \\\n    -v /var/jenkins_home \\\n    jenkins\n', '$ docker run \\\n    --name myjenkins \\\n    --network=host \\\n    --env HTTP_PROXY=""http://localhost:8080"" \\\n    --env http_proxy=""http://localhost:8080"" \\\n    --env HTTPS_PROXY=""http://localhost:8080"" \\\n    --env https_proxy=""http://localhost:8080"" \\\n    --env JAVA_OPTS=""-Dhttp.proxyHost=localhost -Dhttp.proxyPort=8080 -Dhttps.proxyHost=localhost -Dhttps.proxyPort=8080"" \\\n    --env JENKINS_OPTS=""--httpPort=7000"" \\\n    -v /var/jenkins_home \\\n    jenkins/jenkins:lts\n']"
1360,11652,11651,CC BY-SA 4.0,2020-05-19T17:40:06.573,"<p>If you want to ""add base_packages.yml to the title of the task"" you'll have to add it to the names of the tasks. For example</p>

<pre class=""lang-yaml prettyprint-override""><code>shell&gt; cat base_packages.yml
---
- name: ""base_packages: .... ""
</code></pre>

<p><code>sed</code> might help to automate it.</p>
",7715,2020-05-19T17:40:06.573,"['shell> cat base_packages.yml\n---\n- name: ""base_packages: .... ""\n']"
1361,11662,11660,CC BY-SA 4.0,2020-05-21T15:21:07.180,"<p>The issue was missing comma between <code>build job</code> and <code>parameters</code>. Below is the correct syntax:</p>

<pre><code>...
                    build job: 'run-on-single-repo',
                    parameters:

... 
</code></pre>
",22376,2020-05-21T15:21:07.180,"[""...\n                    build job: 'run-on-single-repo',\n                    parameters:\n\n... \n""]"
1362,11697,11678,CC BY-SA 4.0,2020-05-26T14:08:20.727,"<p>Assuming a docker file like this...</p>

<pre><code>FROM ubuntu:18.04

ARG TF_VERSION=0.12.25

RUN apt-get install wget -y

RUN wget -O terraform.zip https://releases.hashicorp.com/terraform/${TF_VERSION}/terraform_${TF_VERSION}_linux_amd64.zip
</code></pre>

<p>In your GitHub action you would need to get the current version from your Dockerfile.</p>

<pre><code>export CURRENT_TF_VERSION=$(grep -Eo '[[:digit:]]*\.[[:digit:]]*\.[[:digit:]]*' Dockerfile)
</code></pre>

<p>Then the latest version of terraform.</p>

<pre><code>export LATEST_TF_VERSION=$(curl -s 'https://checkpoint-api.hashicorp.com/v1/check/terraform' | jq -r .current_version)
</code></pre>

<p>Now in bash or using <code>if</code> and <code>outputs</code> in GitHub actions compare the two values. If they are not the same then find and replace the current version with the latest version in your Dockerfile.</p>

<pre><code>sed -i ""s/${CURRENT_TF_VERSION}/${LATEST_TF_VERSION}/"" Dockerfile 
</code></pre>

<p>Then you can use the <a href=""https://github.com/peter-evans/create-pull-request"" rel=""nofollow noreferrer"">create-pull-request</a> GitHub action to create a pull request.</p>

<p>The <a href=""https://github.com/peter-evans/create-pull-request"" rel=""nofollow noreferrer"">create-pull-request</a> documentation doesn't mention what happens if you don't have any changes but I asked <a href=""https://github.com/peter-evans/create-pull-request/issues/348"" rel=""nofollow noreferrer"">here</a>. If it doesn't throw an error when you don't have changes then you could simply get the latest value and run sed.</p>

<pre><code>sed ""s/[[:digit:]]*\.[[:digit:]]*\.[[:digit:]]*/${LATEST_TF_VERSION}/"" Dockerfile 
</code></pre>
",4427,2020-05-26T14:08:20.727,"['FROM ubuntu:18.04\n\nARG TF_VERSION=0.12.25\n\nRUN apt-get install wget -y\n\nRUN wget -O terraform.zip https://releases.hashicorp.com/terraform/${TF_VERSION}/terraform_${TF_VERSION}_linux_amd64.zip\n', ""export CURRENT_TF_VERSION=$(grep -Eo '[[:digit:]]*\\.[[:digit:]]*\\.[[:digit:]]*' Dockerfile)\n"", ""export LATEST_TF_VERSION=$(curl -s 'https://checkpoint-api.hashicorp.com/v1/check/terraform' | jq -r .current_version)\n"", 'sed -i ""s/${CURRENT_TF_VERSION}/${LATEST_TF_VERSION}/"" Dockerfile \n', 'sed ""s/[[:digit:]]*\\.[[:digit:]]*\\.[[:digit:]]*/${LATEST_TF_VERSION}/"" Dockerfile \n']"
1363,11698,11671,CC BY-SA 4.0,2020-05-26T14:43:41.233,"<p>I have managed to solve it myself later that day, I had to disable one of the apigroups within the specific crd that is responsible for the given object.
In that case it was editing:
kubectl edit crd virtualservices.networking.istio.io
And then change:</p>

<pre><code>  versions:
  - name: v1alpha3
    served: true
    storage: true
  - name: v1beta1
    served: true
    storage: false
</code></pre>

<p>to</p>

<pre><code>  versions:
  - name: v1alpha3
    served: true
    storage: true
  - name: v1beta1
    served: false
    storage: false
</code></pre>

<p>Then on redeploy I had the correct apigroup which I wanted.</p>
",17329,2020-05-26T14:43:41.233,"['  versions:\n  - name: v1alpha3\n    served: true\n    storage: true\n  - name: v1beta1\n    served: true\n    storage: false\n', '  versions:\n  - name: v1alpha3\n    served: true\n    storage: true\n  - name: v1beta1\n    served: false\n    storage: false\n']"
1364,11699,10703,CC BY-SA 4.0,2020-05-26T17:41:23.373,"<p>I understood with the help of the documentation above how to replace environment variables.</p>

<p>For example:</p>

<pre><code>- hosts: hostnames
  remote_user: root
  gather_facts: no
  vars:
    ansible_remote_tmp: /tmp
  tasks:
  ...
</code></pre>

<p>Also, it's possible to replace in the separate tasks.</p>

<p><a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_environment.html"" rel=""nofollow noreferrer"">Ansible documentation about playbook environment</a></p>
",18321,2020-05-26T17:41:23.373,['- hosts: hostnames\n  remote_user: root\n  gather_facts: no\n  vars:\n    ansible_remote_tmp: /tmp\n  tasks:\n  ...\n']
1365,11705,11668,CC BY-SA 4.0,2020-05-27T07:46:58.663,"<p>Just a quick follow-up on <a href=""https://github.com/alexei-led/pumba#stress-testing-docker-containers"" rel=""noreferrer"">pumba</a>. Installation (for Ubuntu):</p>

<pre><code>$ curl -SL https://github.com/alexei-led/pumba/releases/download/0.7.2/pumba_linux_amd64 -O
$ sudo mv pumba_linux_amd64 /usr/bin/pumba
$ sudo chmod +x /usr/bin/pumba
$ pumba --version
</code></pre>

<p>It uses <a href=""https://wiki.ubuntu.com/Kernel/Reference/stress-ng"" rel=""noreferrer"">stress-ng</a> under the hood, so same commands apply. Examples: </p>

<ol>
<li><pre><code>$ pumba stress -d 1m container_name
</code></pre>

<p><code>-d 1m</code> - duration of a stress test (1 minute)</p>

<p><code>container_name</code> - your target container (from <code>docker ps</code> output)</p></li>
<li><pre><code>$ pumba stress -d 30s --stressors ""--vm 10 --vm-bytes 512M --vm-hang 20"" container_name
</code></pre>

<p><code>-d 30</code> - duration 30 seconds</p>

<p><code>-stressors</code> - parameters passed to <em>stress-ng</em> app</p>

<p>In this particular example we create 10 workers spinning on <em>malloc()/free()</em> allocating <code>512MB</code> each and sleep 20 seconds before freeing the memory.</p></li>
</ol>

<p>Default stressor as in first example is <code>--cpu 4 --timeout 60s</code></p>
",19083,2020-05-27T07:46:58.663,"['$ curl -SL https://github.com/alexei-led/pumba/releases/download/0.7.2/pumba_linux_amd64 -O\n$ sudo mv pumba_linux_amd64 /usr/bin/pumba\n$ sudo chmod +x /usr/bin/pumba\n$ pumba --version\n', '$ pumba stress -d 1m container_name\n', '$ pumba stress -d 30s --stressors ""--vm 10 --vm-bytes 512M --vm-hang 20"" container_name\n']"
1366,11717,11661,CC BY-SA 4.0,2020-05-28T18:07:31.153,"<p>Assuming that deploy to DEV and QA steps look a lot like your deploy to production-staging environments, put the code that does that work into a <a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/process/templates?view=azure-devops"" rel=""nofollow noreferrer"">yaml template</a> and take advantage of <a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/process/templates?view=azure-devops#passing-parameters"" rel=""nofollow noreferrer"">parameters</a> to allow you to pass in differing environment settings for DEV, QA, and Staging-Production. </p>

<p>Then in one pipeline create a <code>stage</code> for each environment.  The <code>stage</code> should have a <code>job</code> which references your template.  You should use <a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/process/conditions?view=azure-devops&amp;tabs=yaml"" rel=""nofollow noreferrer"">conditions</a> on each stage to ensure your code goes to the environment when you want it.  Here's a pseudocode example:</p>

<pre><code>stages:
- stage: MyDevStage #No condition so this stage always runs
  jobs:
    - template: '../MyTemplate.Yaml
      parameters:
        ServerName: MyDevServer
- stage: MyProdStage
  condition: and(
    succeeded() # if my dev deploy doesn't go well don't deploy to PRD
    , eq(variables['Build.SourceBranch'], 'refs/heads/master') # confirm this is a commit to master
    )
  jobs:
    - template: '../MyTemplate.yaml'
      parameters:
        ServerName: MyProdServer
</code></pre>

<p>At the top of your pipeline yaml file you'll need to specify a trigger which may look something like this:</p>

<pre><code>trigger:
  batch: true
  branches:
    include:
    - master
</code></pre>
",22482,2020-05-28T18:07:31.153,"[""stages:\n- stage: MyDevStage #No condition so this stage always runs\n  jobs:\n    - template: '../MyTemplate.Yaml\n      parameters:\n        ServerName: MyDevServer\n- stage: MyProdStage\n  condition: and(\n    succeeded() # if my dev deploy doesn't go well don't deploy to PRD\n    , eq(variables['Build.SourceBranch'], 'refs/heads/master') # confirm this is a commit to master\n    )\n  jobs:\n    - template: '../MyTemplate.yaml'\n      parameters:\n        ServerName: MyProdServer\n"", 'trigger:\n  batch: true\n  branches:\n    include:\n    - master\n']"
1367,11727,11722,CC BY-SA 4.0,2020-05-29T21:48:16.560,"<p>This is actually pretty well described in the docs.</p>
<blockquote>
<p>Before you create worker nodes, you must create an IAM role with the
following IAM policies:</p>
<p>AmazonEKSWorkerNodePolicy</p>
<p>AmazonEKS_CNI_Policy</p>
<p>AmazonEC2ContainerRegistryReadOnly</p>
</blockquote>
<p>Also you need to make sure that this role could be assumed by EKS.</p>
<pre><code>{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Principal&quot;: {
        &quot;Service&quot;: &quot;ec2.amazonaws.com&quot;
      },
      &quot;Action&quot;: &quot;sts:AssumeRole&quot;
    }
  ]
}
</code></pre>
",20101,2020-11-20T12:41:43.530,"['{\n  ""Version"": ""2012-10-17"",\n  ""Statement"": [\n    {\n      ""Effect"": ""Allow"",\n      ""Principal"": {\n        ""Service"": ""ec2.amazonaws.com""\n      },\n      ""Action"": ""sts:AssumeRole""\n    }\n  ]\n}\n']"
1368,11731,11723,CC BY-SA 4.0,2020-05-30T12:59:59.430,"<p>You can specify that you want gitlab to execute your CI job on a windows machine using <a href=""http://%20*%20https://docs.gitlab.com/ee/ci/yaml/#tags"" rel=""nofollow noreferrer"">tags</a>.</p>

<p>Gitlab made Windows Shared Runners available as Beta in Jan 2020. <a href=""https://about.gitlab.com/blog/2020/01/21/windows-shared-runner-beta/"" rel=""nofollow noreferrer"">Their announcement</a> shows how to use the <code>tags</code> key in your <code>.gitlab-ci</code> file to specify Windows machines. You can also run in a docker container in windows:</p>

<ul>
<li><a href=""https://docs.gitlab.com/runner/executors/docker.html#using-windows-containers"" rel=""nofollow noreferrer"">https://docs.gitlab.com/runner/executors/docker.html#using-windows-containers</a></li>
</ul>

<p>For example, I was able to execute a simple ""hello world"" powershell script with the following job in <a href=""https://gitlab.com/maltfield/cross-platform-python-gui/-/blob/91f0d9e31ed5c5cfdcd073accc1b3cc86a00df0b/.gitlab-ci.yml"" rel=""nofollow noreferrer"">my <code>.gitlab-ci</code> file</a>:</p>

<pre><code>windows:
  script: ""build/windows/buildExe.ps1""
  tags:
    - shared-windows
    - windows
    - windows-1809
</code></pre>

<p>And here's the <a href=""https://gitlab.com/maltfield/cross-platform-python-gui/-/blob/91f0d9e31ed5c5cfdcd073accc1b3cc86a00df0b/build/windows/buildExe.ps1"" rel=""nofollow noreferrer""><code>buildExe.ps1</code> powershell script</a> reference above:</p>

<pre><code>Write-Host ""listing contents of C drive root""
Get-ChildItem -Path C:\ -Force

Write-Host ""listing contents of cwd""
Get-ChildItem -Force
</code></pre>

<p>The above config produced the following output <a href=""https://gitlab.com/maltfield/cross-platform-python-gui/-/jobs/574193500"" rel=""nofollow noreferrer"">in my CI job</a>:</p>

<pre><code>[0KRunning with gitlab-runner 12.9.0 (4c96e5ad)
[0;m[0K  on windows-shared-runners-manager 6QgxEPvR
[0;msection_start:1590842482:prepare_executor
[0K[0K[36;1mPreparing the ""custom"" executor[0;m
[0;m[0KUsing Custom executor with driver autoscaler dev (64a348d)...
[0;mCreating virtual machine for the job...
Virtual machine created!
section_end:1590842624:prepare_executor
[0Ksection_start:1590842624:prepare_script
[0K[0K[36;1mPreparing environment[0;m
[0;mRunning on PACKER-5E557E8E via 
runner-6qgxepvr-wsrm-87cf700a3349de62a18e...
section_end:1590842640:prepare_script
[0Ksection_start:1590842640:get_sources
[0K[0K[36;1mGetting source from Git repository[0;m
[0;m[32;1mFetching changes with git depth set to 50...[0;m
Initialized empty Git repository in C:/GitLab-Runner/builds/maltfield/cross-platform-python-gui/.git/
[32;1mCreated fresh repository.[0;m
[32;1mChecking out 91f0d9e3 as master...[0;m
From https://gitlab.com/maltfield/cross-platform-python-gui
 * [new ref]         refs/pipelines/151176370 -&gt; refs/pipelines/151176370
 * [new branch]      master                   -&gt; origin/master
git-lfs/2.8.0 (GitHub; windows amd64; go 1.12.2; git 30af66bb)

[32;1mUpdating/initializing submodules...[0;m
git-lfs/2.8.0 (GitHub; windows amd64; go 1.12.2; git 30af66bb)
section_end:1590842661:get_sources
[0Ksection_start:1590842661:restore_cache
[0K[0K[36;1mRestoring cache[0;m
[0;msection_end:1590842670:restore_cache
[0Ksection_start:1590842670:download_artifacts
[0K[0K[36;1mDownloading artifacts[0;m
[0;msection_end:1590842677:download_artifacts
[0Ksection_start:1590842677:build_script
[0K[0K[36;1mRunning before_script and script[0;m
[0;m[32;1m$ build/windows/buildExe.ps1[0;m
listing contents of C drive root


    Directory: C:\


Mode                LastWriteTime         Length Name                                                                  
----                -------------         ------ ----                                                                  
d--hs-       12/11/2019   2:47 AM                $RECYCLE.BIN                                                          
d--hs-        2/25/2020   8:52 PM                Boot                                                                  
d--hsl       12/11/2019  10:29 AM                Documents and Settings                                                
d-----        2/25/2020   8:16 PM                Git                                                                   
d-----        5/30/2020  12:44 PM                GitLab-Runner                                                         
d-----        2/25/2020   8:16 PM                GitLFS                                                                
d-----        2/25/2020   8:34 PM                Go                                                                    
d-----        9/15/2018   7:12 AM                PerfLogs                                                              
d-r---        2/25/2020   8:35 PM                Program Files                                                         
d-----        2/25/2020   8:27 PM                Program Files (x86)                                                   
d--h--        2/25/2020   8:51 PM                ProgramData                                                           
d--hs-        2/25/2020   8:10 PM                Recovery                                                              
d--hs-       12/11/2019  10:28 AM                System Volume Information                                             
d-----        2/25/2020   8:32 PM                tools                                                                 
d-r---        5/30/2020  12:43 PM                Users                                                                 
d-----        2/25/2020   8:38 PM                vcpkg                                                                 
d-----        2/25/2020   8:51 PM                Windows                                                               
-arhs-        2/25/2020   8:45 PM         408834 bootmgr                                                               
-a-hs-        9/15/2018   7:09 AM              1 BOOTNXT                                                               
-a-hs-        5/30/2020  12:41 PM     1073741824 pagefile.sys                                                          
listing contents of cwd


    Directory: C:\GitLab-Runner\builds\maltfield\cross-platform-python-gui


Mode                LastWriteTime         Length Name                                                                  
----                -------------         ------ ----                                                                  
d--h--        5/30/2020  12:44 PM                .git                                                                  
d-----        5/30/2020  12:44 PM                build                                                                 
d-----        5/30/2020  12:44 PM                src                                                                   
-a----        5/30/2020  12:44 PM            534 .gitlab-ci.yml                                                        
-a----        5/30/2020  12:44 PM          35787 LICENSE                                                               
-a----        5/30/2020  12:44 PM           1171 README.md                                                             
-a----        5/30/2020  12:44 PM              6 requirements.txt                                                      


section_end:1590842686:build_script
[0Ksection_start:1590842686:archive_cache
[0K[0K[36;1mSaving cache[0;m
[0;msection_end:1590842694:archive_cache
[0Ksection_start:1590842694:upload_artifacts_on_success
[0K[0K[36;1mUploading artifacts for successful job[0;m
[0;msection_end:1590842701:upload_artifacts_on_success
[0K[32;1mJob succeeded
[0;m
</code></pre>

<p>As for MacOS, gitlab currently doesn't support it natively. If this changes, updated answers are welcome.</p>

<p>Other answers showing how to run MacOS inside a VM (eg using vagrant and libvirt) on a gitlab shared runner are very welcome :)</p>
",22501,2020-05-30T12:59:59.430,"['windows:\n  script: ""build/windows/buildExe.ps1""\n  tags:\n    - shared-windows\n    - windows\n    - windows-1809\n', 'Write-Host ""listing contents of C drive root""\nGet-ChildItem -Path C:\\ -Force\n\nWrite-Host ""listing contents of cwd""\nGet-ChildItem -Force\n', '[0KRunning with gitlab-runner 12.9.0 (4c96e5ad)\n[0;m[0K  on windows-shared-runners-manager 6QgxEPvR\n[0;msection_start:1590842482:prepare_executor\n[0K[0K[36;1mPreparing the ""custom"" executor[0;m\n[0;m[0KUsing Custom executor with driver autoscaler dev (64a348d)...\n[0;mCreating virtual machine for the job...\nVirtual machine created!\nsection_end:1590842624:prepare_executor\n[0Ksection_start:1590842624:prepare_script\n[0K[0K[36;1mPreparing environment[0;m\n[0;mRunning on PACKER-5E557E8E via \nrunner-6qgxepvr-wsrm-87cf700a3349de62a18e...\nsection_end:1590842640:prepare_script\n[0Ksection_start:1590842640:get_sources\n[0K[0K[36;1mGetting source from Git repository[0;m\n[0;m[32;1mFetching changes with git depth set to 50...[0;m\nInitialized empty Git repository in C:/GitLab-Runner/builds/maltfield/cross-platform-python-gui/.git/\n[32;1mCreated fresh repository.[0;m\n[32;1mChecking out 91f0d9e3 as master...[0;m\nFrom https://gitlab.com/maltfield/cross-platform-python-gui\n * [new ref]         refs/pipelines/151176370 -> refs/pipelines/151176370\n * [new branch]      master                   -> origin/master\ngit-lfs/2.8.0 (GitHub; windows amd64; go 1.12.2; git 30af66bb)\n\n[32;1mUpdating/initializing submodules...[0;m\ngit-lfs/2.8.0 (GitHub; windows amd64; go 1.12.2; git 30af66bb)\nsection_end:1590842661:get_sources\n[0Ksection_start:1590842661:restore_cache\n[0K[0K[36;1mRestoring cache[0;m\n[0;msection_end:1590842670:restore_cache\n[0Ksection_start:1590842670:download_artifacts\n[0K[0K[36;1mDownloading artifacts[0;m\n[0;msection_end:1590842677:download_artifacts\n[0Ksection_start:1590842677:build_script\n[0K[0K[36;1mRunning before_script and script[0;m\n[0;m[32;1m$ build/windows/buildExe.ps1[0;m\nlisting contents of C drive root\n\n\n    Directory: C:\\\n\n\nMode                LastWriteTime         Length Name                                                                  \n----                -------------         ------ ----                                                                  \nd--hs-       12/11/2019   2:47 AM                $RECYCLE.BIN                                                          \nd--hs-        2/25/2020   8:52 PM                Boot                                                                  \nd--hsl       12/11/2019  10:29 AM                Documents and Settings                                                \nd-----        2/25/2020   8:16 PM                Git                                                                   \nd-----        5/30/2020  12:44 PM                GitLab-Runner                                                         \nd-----        2/25/2020   8:16 PM                GitLFS                                                                \nd-----        2/25/2020   8:34 PM                Go                                                                    \nd-----        9/15/2018   7:12 AM                PerfLogs                                                              \nd-r---        2/25/2020   8:35 PM                Program Files                                                         \nd-----        2/25/2020   8:27 PM                Program Files (x86)                                                   \nd--h--        2/25/2020   8:51 PM                ProgramData                                                           \nd--hs-        2/25/2020   8:10 PM                Recovery                                                              \nd--hs-       12/11/2019  10:28 AM                System Volume Information                                             \nd-----        2/25/2020   8:32 PM                tools                                                                 \nd-r---        5/30/2020  12:43 PM                Users                                                                 \nd-----        2/25/2020   8:38 PM                vcpkg                                                                 \nd-----        2/25/2020   8:51 PM                Windows                                                               \n-arhs-        2/25/2020   8:45 PM         408834 bootmgr                                                               \n-a-hs-        9/15/2018   7:09 AM              1 BOOTNXT                                                               \n-a-hs-        5/30/2020  12:41 PM     1073741824 pagefile.sys                                                          \nlisting contents of cwd\n\n\n    Directory: C:\\GitLab-Runner\\builds\\maltfield\\cross-platform-python-gui\n\n\nMode                LastWriteTime         Length Name                                                                  \n----                -------------         ------ ----                                                                  \nd--h--        5/30/2020  12:44 PM                .git                                                                  \nd-----        5/30/2020  12:44 PM                build                                                                 \nd-----        5/30/2020  12:44 PM                src                                                                   \n-a----        5/30/2020  12:44 PM            534 .gitlab-ci.yml                                                        \n-a----        5/30/2020  12:44 PM          35787 LICENSE                                                               \n-a----        5/30/2020  12:44 PM           1171 README.md                                                             \n-a----        5/30/2020  12:44 PM              6 requirements.txt                                                      \n\n\nsection_end:1590842686:build_script\n[0Ksection_start:1590842686:archive_cache\n[0K[0K[36;1mSaving cache[0;m\n[0;msection_end:1590842694:archive_cache\n[0Ksection_start:1590842694:upload_artifacts_on_success\n[0K[0K[36;1mUploading artifacts for successful job[0;m\n[0;msection_end:1590842701:upload_artifacts_on_success\n[0K[32;1mJob succeeded\n[0;m\n']"
1369,11755,11683,CC BY-SA 4.0,2020-06-02T16:51:09.810,"<p>You can add an entry in your ini file to set the sort_order for the callback plugin to none. </p>

<pre><code>[callback_profile_tasks]
sort_order = none
</code></pre>

<p>By default it is set to descending, which is why the tasks are displayed in decreasing order of time taken.</p>

<p>Refer: <a href=""https://docs.ansible.com/ansible/latest/plugins/callback/profile_tasks.html#parameter-sort_order"" rel=""nofollow noreferrer"">https://docs.ansible.com/ansible/latest/plugins/callback/profile_tasks.html#parameter-sort_order</a></p>
",22517,2020-06-02T16:51:09.810,['[callback_profile_tasks]\nsort_order = none\n']
1370,11761,11760,CC BY-SA 4.0,2020-06-03T07:14:56.473,"<p>You can run an ssh server in the container as the <code>ENTRYPOINT</code>. It can either be started in the foreground : </p>

<pre><code>ENTRYPOINT [""/usr/sbin/sshd"", ""-D"",""-p"",""22""]
</code></pre>

<p>Ensure that you have <code>openssh</code> installed and host keys setup.</p>

<p>Perhaps <a href=""https://github.com/AAROC/CODE-RADE-container"" rel=""nofollow noreferrer"">this Ansible role</a> would be illustrative</p>
",354,2020-06-03T07:14:56.473,"['ENTRYPOINT [""/usr/sbin/sshd"", ""-D"",""-p"",""22""]\n']"
1371,11766,11756,CC BY-SA 4.0,2020-06-04T11:33:14.187,"<p>eth0 is used by vagrant for nat configuration in order to establish portforwarding. eth1 private networks that you have configured should allow you to ping/nslookup from one node to another. You can use the following to customize the ip of the nat but I don't see why would you do that:</p>

<pre><code>config.vm.provider ""virtualbox"" do |vbx|
  vbx.customize ['modifyvm', :id, '--natnet1', '192.168.169.0/24']
end
</code></pre>

<p>Update: tested your setup it doesn't work, this is some CentOS 8 specifics.</p>
",17329,2020-06-07T12:55:12.730,"['config.vm.provider ""virtualbox"" do |vbx|\n  vbx.customize [\'modifyvm\', :id, \'--natnet1\', \'192.168.169.0/24\']\nend\n']"
1372,11778,11775,CC BY-SA 4.0,2020-06-05T14:28:40.787,"<p>Ultimately, as long as you have the disk space and RAM, you can run both in parallel with very few issues.</p>

<p>The biggest problem you may run into is that the default ports of the applications you run in a container may already be in use.  For example SQL server install runs on port 1433 by default.  If you try to run a SQL server container and do not map a different port on the host machine to 1433 on the container you will run into errors.  This is easy enough do though:</p>

<pre><code>docker run -e ""ACCEPT_EULA=Y"" -e ""SA_PASSWORD="" -p 1431:1433 -d mcr.microsoft.com/mssql/server:2019-CU3-ubuntu-18.04</code></pre>

<p>In the above example, MSSQL server will run on port 1431 and map to port 1433 in the container.  On your local machine you can access either your SQL server on port 1433 or the container SQL server on 1431.</p>
",15792,2020-06-05T14:28:40.787,"['docker run -e ""ACCEPT_EULA=Y"" -e ""SA_PASSWORD="" -p 1431:1433 -d mcr.microsoft.com/mssql/server:2019-CU3-ubuntu-18.04']"
1373,11779,11769,CC BY-SA 4.0,2020-06-05T18:35:13.127,"<p>You can't use <code>post</code> because post is part of the declarative DSL, not scripted, and you're defining your stages in a <code>script</code> block.  So I'm afraid that as long as you're using a <code>script</code> block to define your stages, you're going to have to stick with the scripted method, which is the groovy <code>try { ... } catch { ... } finally { ... }</code> construct.  For example:</p>

<pre><code>def createStage(String stageName) {
    stage(stageName) {
        try {
            echo ""Stage: ${stageName}""
            echo ""${stageName} &gt; this is executed only on success""
        finally {
            echo ""${stageName} &gt; this is always executed""
        }
    }
}
</code></pre>
",4115,2020-06-05T18:35:13.127,"['def createStage(String stageName) {\n    stage(stageName) {\n        try {\n            echo ""Stage: ${stageName}""\n            echo ""${stageName} > this is executed only on success""\n        finally {\n            echo ""${stageName} > this is always executed""\n        }\n    }\n}\n']"
1374,11800,11790,CC BY-SA 4.0,2020-06-10T18:19:17.390,"<p>Okay, it took time and help from someone else. I was going down the path of installing nginx, but that won't end up being necessary.</p>

<pre><code>apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    # &lt;string, required&gt; access mode. proxy or direct (Server or Browser in the UI). Required
    access: proxy
    orgId: 1
    url: http://localhost:9090
    isDefault: true
</code></pre>

<p>This is the end change. originally I had access: direct. As I understand it, that means access to the metrics is via the browser. Switching it to proxy means that Grafana will look up the data. Which means the URL doesn't need to be externally-useful.</p>

<p>To a newbie, none of this was obvious, so maybe my two days of pain will help someone out in the future.</p>
",22640,2020-06-10T18:19:17.390,"['apiVersion: 1\n\ndatasources:\n  - name: Prometheus\n    type: prometheus\n    # <string, required> access mode. proxy or direct (Server or Browser in the UI). Required\n    access: proxy\n    orgId: 1\n    url: http://localhost:9090\n    isDefault: true\n']"
1375,11813,11805,CC BY-SA 4.0,2020-06-11T17:31:14.447,"<p>From the <a href=""https://javadoc.jenkins-ci.org/hudson/model/User.html"" rel=""nofollow noreferrer"">Java API documentation for <code>hudson.model.User</code></a>:</p>

<blockquote>
  <p><code>String</code>  <code>getDisplayName()</code>
  Returns the user name.</p>
  
  <p><code>String</code>  <code>getFullName()</code>
  Gets the human readable name of this user.</p>
  
  <p><code>String</code>  <code>getId()</code></p>
</blockquote>

<p>It's not clear to me from your question what data you want (I think it's the user ID?), so I'm not sure which of these methods will get you that data (<code>getId()</code>?).  But in any case, you would call the method like:</p>

<pre><code>User.current().getId()
</code></pre>
",4115,2020-06-11T17:31:14.447,['User.current().getId()\n']
1376,11814,10499,CC BY-SA 4.0,2020-06-11T17:36:10.357,"<p>You do not need to include anything into your assembly to run your tests using GitHub Actions. Just create workflow file in .github/workflows folder with the following content (assuming that you have .NET Core project):</p>

<pre class=""lang-yaml prettyprint-override""><code>---
name: Tests

on: push

jobs:
  tests:
    name: Unit Testing
    runs-on: windows-latest
    steps:
      - uses: actions/checkout@v2.1.0
      - run: dotnet test
</code></pre>

<blockquote>
  <p>dotnet is pre-installed on windows machine but is not pre-installed on macos and ubuntu. So, you have to install dotnet by adding an extra step in case you want to run it on one of these machines. You can use <a href=""https://github.com/marketplace/actions/setup-net-core-sdk"" rel=""nofollow noreferrer"">actions/setup-dotnet</a> action for this purpose.</p>
</blockquote>
",19112,2020-06-11T17:36:10.357,['---\nname: Tests\n\non: push\n\njobs:\n  tests:\n    name: Unit Testing\n    runs-on: windows-latest\n    steps:\n      - uses: actions/checkout@v2.1.0\n      - run: dotnet test\n']
1377,11828,11824,CC BY-SA 4.0,2020-06-16T08:55:45.223,"<p>You might try installing the <a href=""https://plugins.jenkins.io/github-pullrequest/"" rel=""nofollow noreferrer"">GitHub Integration</a> plugin. Reading <a href=""https://github.com/KostyaSha/github-integration-plugin/blob/master/docs/Configuration.adoc"" rel=""nofollow noreferrer"">their documentation</a>, they provide a number of environment variables you can use for your purpose.</p>

<ol>
<li><code>GITHUB_PR_STATE</code> can be <code>OPEN</code>, <code>CLOSE</code></li>
<li><code>GITHUB_PR_SOURCE_BRANCH</code> for the source branch (e.g., <code>hotfix/foo</code>)</li>
<li><code>GITHUB_PR_TARGET_BRANCH</code> or <code>master</code></li>
</ol>

<p>Using the when condition, you can run a job/stage when it's a closed PR merging into the <code>master</code> branch using:</p>

<pre><code>when { 
  allOf { 
    expression { env.GITHUB_PR_STATE == ""CLOSE"" }
    expression { env.GITHUB_PR_TARGET_BRANCH == ""master"" }
    expression { env.GITHUB_PR_SOURCE_BRANCH == ""hotfix/foo"" }
  } 
}
</code></pre>
",9148,2020-06-16T08:55:45.223,"['when { \n  allOf { \n    expression { env.GITHUB_PR_STATE == ""CLOSE"" }\n    expression { env.GITHUB_PR_TARGET_BRANCH == ""master"" }\n    expression { env.GITHUB_PR_SOURCE_BRANCH == ""hotfix/foo"" }\n  } \n}\n']"
1378,11835,11834,CC BY-SA 4.0,2020-06-16T23:06:19.373,"<p>The best I have found so far for part 2 is to use the JSON output of <code>get pods</code>:</p>

<pre><code>kubectl get pods -o json | jq '.items[] | select(.metadata.labels.""app.kubernetes.io/name"") | { name: .metadata.labels.""app.kubernetes.io/name"", version: .metadata.labels.""app.kubernetes.io/version"" }'
</code></pre>

<p>produces</p>

<pre><code>{
  ""name"": ""db"",
  ""version"": ""0.0.1""
}
{
  ""name"": ""app"",
  ""version"": ""0.0.1""
}
</code></pre>
",22776,2020-06-16T23:06:19.373,"['kubectl get pods -o json | jq \'.items[] | select(.metadata.labels.""app.kubernetes.io/name"") | { name: .metadata.labels.""app.kubernetes.io/name"", version: .metadata.labels.""app.kubernetes.io/version"" }\'\n', '{\n  ""name"": ""db"",\n  ""version"": ""0.0.1""\n}\n{\n  ""name"": ""app"",\n  ""version"": ""0.0.1""\n}\n']"
1379,11837,11703,CC BY-SA 4.0,2020-06-17T07:31:18.923,"<p>I probably should use comment instead group the value in a dict who's value is a list</p>

<p>like</p>

<pre><code>packages:
  - apt-file
  - axel
  - ibus-rime
  - rofi
  - i3
  - ffmpeg
  - xclip
  - cargo
  - httpie
  - ttf-ubuntu-font-family
  - tldr-py
  - glances
  # browsers:
  - brave-browser
  - chromium
  # editors
  - emacs
</code></pre>
",22450,2020-06-17T07:31:18.923,['packages:\n  - apt-file\n  - axel\n  - ibus-rime\n  - rofi\n  - i3\n  - ffmpeg\n  - xclip\n  - cargo\n  - httpie\n  - ttf-ubuntu-font-family\n  - tldr-py\n  - glances\n  # browsers:\n  - brave-browser\n  - chromium\n  # editors\n  - emacs\n']
1380,11847,11836,CC BY-SA 4.0,2020-06-17T21:05:08.947,"<p>What I have done before goes on the same direction as Zeitounator commented; you can have one or more &quot;meta&quot; or master playbooks that import the ones you need to run your entire automation. To add to Zaito's comment; you can use the <code>when</code> clause on <code>import_playbook</code> or <code>include</code> to control the execution of those &quot;inner&quot; playbooks; something like this:</p>
<p>Say you want to execute PlatformB playbooks only for an stg or prod environment using a defined <code>env</code> ansible variable:</p>
<pre><code>- include: platformA/do_something_on_platformA.yml
- include: platformB/do_something_on_platformB.yml
  when: env == 'stg' or env == 'prod'
</code></pre>
<p>you could change the value of <code>env</code> using <code>--extra-vars</code> on execution time or something.</p>
<p>hope it helps, cheers.</p>
",22799,2020-06-18T12:07:48.533,"[""- include: platformA/do_something_on_platformA.yml\n- include: platformB/do_something_on_platformB.yml\n  when: env == 'stg' or env == 'prod'\n""]"
1381,11851,11818,CC BY-SA 4.0,2020-06-18T08:12:01.390,"<p>Is this what you are trying to do?</p>

<pre><code>$ docker run --add-host foo:127.0.0.42 alpine ping foo -c 3
PING foo (127.0.0.42): 56 data bytes
64 bytes from 127.0.0.42: seq=0 ttl=64 time=0.045 ms
64 bytes from 127.0.0.42: seq=1 ttl=64 time=0.061 ms
64 bytes from 127.0.0.42: seq=2 ttl=64 time=0.070 ms

--- foo ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 0.045/0.058/0.070 ms
</code></pre>

<p>Look for --add-host parameter for <a href=""https://docs.docker.com/engine/reference/commandline/run/"" rel=""nofollow noreferrer"">docker run</a> or <a href=""https://docs.docker.com/compose/compose-file/#extra_hosts"" rel=""nofollow noreferrer"">extra_hosts</a> for docker-compose.</p>
",22526,2020-06-18T08:12:01.390,"['$ docker run --add-host foo:127.0.0.42 alpine ping foo -c 3\nPING foo (127.0.0.42): 56 data bytes\n64 bytes from 127.0.0.42: seq=0 ttl=64 time=0.045 ms\n64 bytes from 127.0.0.42: seq=1 ttl=64 time=0.061 ms\n64 bytes from 127.0.0.42: seq=2 ttl=64 time=0.070 ms\n\n--- foo ping statistics ---\n3 packets transmitted, 3 packets received, 0% packet loss\nround-trip min/avg/max = 0.045/0.058/0.070 ms\n']"
1382,11861,11629,CC BY-SA 4.0,2020-06-19T09:33:42.050,"<p>This scenario remembers me how i used to test my ansible playbook with terraform. I would run &quot;remote exec&quot; in terraform to install python and other dependencies of ansible. After that I would retrieve the public ip of the instance and save in the inventory file of ansible in the local. And finally, I ran ansible from my local machine from terraform configuration using &quot;local exec&quot;. Of course, before everything you need to configure SSH from local to newly provisioned machine in terraform configuration.</p>
<pre><code>resource &quot;null_resource&quot; &quot;ConfigureAnsibleLabelVariable&quot; {
  provisioner &quot;local-exec&quot; {
    command = &quot;echo [${var.dev_host_label}:vars] &gt; hosts&quot;
  }
  provisioner &quot;local-exec&quot; {
    command = &quot;echo ansible_ssh_user=${var.ssh_user_name} &gt;&gt; hosts&quot;
  }
  provisioner &quot;local-exec&quot; {
    command = &quot;echo ansible_ssh_private_key_file=${var.ssh_key_path} &gt;&gt; hosts&quot;
  }
  provisioner &quot;local-exec&quot; {
    command = &quot;echo [${var.dev_host_label}] &gt;&gt; hosts&quot;
  }
}

resource &quot;null_resource&quot; &quot;ProvisionRemoteHostsIpToAnsibleHosts&quot; {
  count = &quot;${var.instance_count}&quot;
  connection {
    type = &quot;ssh&quot;
    user = &quot;${var.ssh_user_name}&quot;
    host = &quot;${element(aws_instance.DevInstanceAWS.*.public_ip, count.index)}&quot;
    private_key = &quot;${file(&quot;${var.ssh_key_path}&quot;)}&quot;
  }
  provisioner &quot;remote-exec&quot; {
    inline = [
      &quot;sudo yum update -y&quot;,
      &quot;sudo yum install python-setuptools python-pip -y&quot;,
      &quot;sudo pip install httplib2&quot;
    ]
  }
  provisioner &quot;local-exec&quot; {
    command = &quot;echo ${element(aws_instance.DevInstanceAWS.*.public_ip, count.index)} &gt;&gt; hosts&quot;
  }
}

resource &quot;null_resource&quot; &quot;ModifyApplyAnsiblePlayBook&quot; {
  provisioner &quot;local-exec&quot; {
    command = &quot;sed -i -e '/hosts:/ s/: .*/: ${var.dev_host_label}/' play.yml&quot;   #change host label in playbook dynamically
  }

  provisioner &quot;local-exec&quot; {
    command = &quot;sleep 10; ansible-playbook -i hosts play.yml&quot;
  }
  depends_on = [&quot;null_resource.ProvisionRemoteHostsIpToAnsibleHosts&quot;]
}
</code></pre>
",3564,2020-06-19T09:33:42.050,"['resource ""null_resource"" ""ConfigureAnsibleLabelVariable"" {\n  provisioner ""local-exec"" {\n    command = ""echo [${var.dev_host_label}:vars] > hosts""\n  }\n  provisioner ""local-exec"" {\n    command = ""echo ansible_ssh_user=${var.ssh_user_name} >> hosts""\n  }\n  provisioner ""local-exec"" {\n    command = ""echo ansible_ssh_private_key_file=${var.ssh_key_path} >> hosts""\n  }\n  provisioner ""local-exec"" {\n    command = ""echo [${var.dev_host_label}] >> hosts""\n  }\n}\n\nresource ""null_resource"" ""ProvisionRemoteHostsIpToAnsibleHosts"" {\n  count = ""${var.instance_count}""\n  connection {\n    type = ""ssh""\n    user = ""${var.ssh_user_name}""\n    host = ""${element(aws_instance.DevInstanceAWS.*.public_ip, count.index)}""\n    private_key = ""${file(""${var.ssh_key_path}"")}""\n  }\n  provisioner ""remote-exec"" {\n    inline = [\n      ""sudo yum update -y"",\n      ""sudo yum install python-setuptools python-pip -y"",\n      ""sudo pip install httplib2""\n    ]\n  }\n  provisioner ""local-exec"" {\n    command = ""echo ${element(aws_instance.DevInstanceAWS.*.public_ip, count.index)} >> hosts""\n  }\n}\n\nresource ""null_resource"" ""ModifyApplyAnsiblePlayBook"" {\n  provisioner ""local-exec"" {\n    command = ""sed -i -e \'/hosts:/ s/: .*/: ${var.dev_host_label}/\' play.yml""   #change host label in playbook dynamically\n  }\n\n  provisioner ""local-exec"" {\n    command = ""sleep 10; ansible-playbook -i hosts play.yml""\n  }\n  depends_on = [""null_resource.ProvisionRemoteHostsIpToAnsibleHosts""]\n}\n']"
1383,11862,11833,CC BY-SA 4.0,2020-06-19T09:43:23.723,"<p>Setup pipeline name and default version (e.g. master) in &quot;Global Pipeline Libraries&quot; settings. Then use them in your Jenkinsfile as following</p>
<pre><code>#!/usr/bin/env groovy
@Library('YourGlobalPipelineName@YourDefaultVersion') _

pipeline {

}
</code></pre>
",3564,2020-06-19T09:43:23.723,"[""#!/usr/bin/env groovy\n@Library('YourGlobalPipelineName@YourDefaultVersion') _\n\npipeline {\n\n}\n""]"
1384,11863,10263,CC BY-SA 4.0,2020-06-19T09:54:19.210,"<p>I faced the same problem while using different SSH key pairs for different deployment environment. Usually I used to create different ssm variables per environment and then changed the name of ssm per git branch in buildspec.yml. That worked perfectly for me. For example, for deploying to stage environment i used the git branch &quot;dev&quot; which had following buidlspec.yml config</p>
<pre><code>env:
  parameter-store:
    SECRET_KEY_BASE: &quot;DEV_SECRET_KEY_BASE&quot;
</code></pre>
<p>for &quot;release&quot; environment it was,</p>
<pre><code>env:
  parameter-store:
    SECRET_KEY_BASE: &quot;RELEASE_SECRET_KEY_BASE&quot;
</code></pre>
<p>make sure you resolve merge conflicts between inter git branches before you apply.</p>
",3564,2020-06-19T09:54:19.210,"['env:\n  parameter-store:\n    SECRET_KEY_BASE: ""DEV_SECRET_KEY_BASE""\n', 'env:\n  parameter-store:\n    SECRET_KEY_BASE: ""RELEASE_SECRET_KEY_BASE""\n']"
1385,11876,11875,CC BY-SA 4.0,2020-06-21T19:24:34.310,"<p>Could <a href=""https://www.jenkins.io/doc/pipeline/steps/credentials-binding/"" rel=""nofollow noreferrer"">credentials binding plugin</a> be the answer?</p>
<p>The idea is to add svn user and password to Jenkins credentials store and then use it in the pipeline.</p>
<pre><code>withCredentials([
    usernamePassword(
        credentialsId: 'mySvnLogin',
        usernameVariable: 'USER',
        passwordVariable: 'PASSWORD')]) {
    sh '''
      svn ls &lt;url&gt; --non-interactive --no-auth-cache --trust-server-cert --username $USER 
 --password $PASSWORD
    ''''
</code></pre>
",22526,2020-06-21T19:24:34.310,"[""withCredentials([\n    usernamePassword(\n        credentialsId: 'mySvnLogin',\n        usernameVariable: 'USER',\n        passwordVariable: 'PASSWORD')]) {\n    sh '''\n      svn ls <url> --non-interactive --no-auth-cache --trust-server-cert --username $USER \n --password $PASSWORD\n    ''''\n""]"
1386,11884,10665,CC BY-SA 4.0,2020-06-22T19:01:08.430,"<p><a href=""https://developer.github.com/v3/actions/workflow-runs/#list-workflow-runs"" rel=""nofollow noreferrer"">List workflow runs</a> would be the equivalent API endpoint in Github Actions:</p>
<pre><code>GET /repos/:owner/:repo/actions/workflows/:workflow_id/runs
</code></pre>
<p>You can use the <code>status</code> query parameter e.g. to filter for successful runs:</p>
<pre><code>GET /repos/:owner/:repo/actions/workflows/:workflow_id/runs?status=success
</code></pre>
",22762,2020-06-22T19:01:08.430,"['GET /repos/:owner/:repo/actions/workflows/:workflow_id/runs\n', 'GET /repos/:owner/:repo/actions/workflows/:workflow_id/runs?status=success\n']"
1387,11887,9118,CC BY-SA 4.0,2020-06-23T08:49:22.717,"<p>Not sure why this is required since Kubernetes is declarative and will not do anything is nothing has changed. Nonetheless, you can run it with the <code>--server-dry-run=true</code> flag. What attributes are going to be changed in the resource will not be mentioned but it does mention which resource(s) will be changed in the apply. You will need to parse the output message to identify if something changed or not since the exit code is always 1.
Sample outputs:</p>
<pre><code>$ kubectl apply --server-dry-run=true -f ./configmap.yaml # First run
secret/my-conf created
$ kubectl apply --server-dry-run=true -f ./configmap.yaml # Re-run without modifications
secret/my-conf unchanged
$ kubectl apply --server-dry-run=true -f ./configmap.yaml # Re-run with modifications
secret/my-conf configured
</code></pre>
",22743,2020-06-23T08:49:22.717,['$ kubectl apply --server-dry-run=true -f ./configmap.yaml # First run\nsecret/my-conf created\n$ kubectl apply --server-dry-run=true -f ./configmap.yaml # Re-run without modifications\nsecret/my-conf unchanged\n$ kubectl apply --server-dry-run=true -f ./configmap.yaml # Re-run with modifications\nsecret/my-conf configured\n']
1388,11892,11891,CC BY-SA 4.0,2020-06-23T17:10:47.867,"<p>Yes, you can start ECS Fargate tasks from Step Functions in the way you've described.</p>
<p>Step Functions allows you to pass <code>Parameters</code> to the underlying service API.</p>
<p><a href=""https://docs.aws.amazon.com/step-functions/latest/dg/connect-parameters.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/step-functions/latest/dg/connect-parameters.html</a></p>
<p><em>[sidebar: that doc also specifies how to pass state inputs, which you've stated is a requirement]</em></p>
<p>For ECS Fargate, a single state machine with no unique configuration could look something like this:</p>
<pre><code> &quot;States&quot;: {
    &quot;${name}&quot;: {
      &quot;Type&quot;: &quot;Task&quot;,
      &quot;Resource&quot;: &quot;arn:aws:states:::ecs:runTask.sync&quot;,
      &quot;Parameters&quot;: {
        &quot;LaunchType&quot;: &quot;FARGATE&quot;,
        &quot;Cluster&quot;: &quot;${cluster}&quot;,
        &quot;TaskDefinition&quot;: &quot;${task_definition}&quot;,
        &quot;NetworkConfiguration&quot;: {
          &quot;AwsvpcConfiguration&quot;: {
            &quot;Subnets&quot;: [&quot;${subnet_1}&quot;, &quot;${subnet_2}&quot;],
            &quot;SecurityGroups&quot;: [&quot;${security_group}&quot;],
            &quot;AssignPublicIp&quot;: &quot;DISABLED&quot;
          }
        }
      },
</code></pre>
<p>Now, you've asked about passing each task slightly different parameter values...</p>
<p>Thankfully, the ECS <code>RunTask</code> API has a helpful <code>overrides: { containerOverrides: [] }</code> parameter.</p>
<p><a href=""https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_RunTask.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/AmazonECS/latest/APIReference/API_RunTask.html</a></p>
<p>Overriding the <code>command</code> (for task execution) or <code>environment</code> (for OS variables) should provide the customization you require without needing multiple ECS Task Definitions.</p>
<p>So, add each distinct task to your state machine, each ingesting state inputs and with its own unique override, and that should do it!</p>
",132,2020-06-23T17:10:47.867,"[' ""States"": {\n    ""${name}"": {\n      ""Type"": ""Task"",\n      ""Resource"": ""arn:aws:states:::ecs:runTask.sync"",\n      ""Parameters"": {\n        ""LaunchType"": ""FARGATE"",\n        ""Cluster"": ""${cluster}"",\n        ""TaskDefinition"": ""${task_definition}"",\n        ""NetworkConfiguration"": {\n          ""AwsvpcConfiguration"": {\n            ""Subnets"": [""${subnet_1}"", ""${subnet_2}""],\n            ""SecurityGroups"": [""${security_group}""],\n            ""AssignPublicIp"": ""DISABLED""\n          }\n        }\n      },\n']"
1389,11894,3588,CC BY-SA 4.0,2020-06-24T09:23:50.440,"<p>What I did that worked for me :</p>
<pre><code>- name: launch pg_ctl start
  command: &quot;su &lt;USER&gt; -l -c '&lt;COMMAND&gt;'&quot;
  become: yes
  become_exe: sudo
</code></pre>
<p>PS : With <code>su -l</code>, it automatically load the <code>.bash_profile</code> and not the <code>.bashrc</code></p>
",22887,2020-06-24T09:23:50.440,"['- name: launch pg_ctl start\n  command: ""su <USER> -l -c \'<COMMAND>\'""\n  become: yes\n  become_exe: sudo\n']"
1390,11902,11900,CC BY-SA 4.0,2020-06-25T10:17:04.243,"<p>I believe your issue is the use of * * * * *.</p>
<p>The <a href=""https://github.com/jenkinsci/parameterized-scheduler-plugin/blob/master/README.md"" rel=""nofollow noreferrer"">parameterized-scheduler-plugin</a> example has two different times specified.</p>
<pre><code>#lets run against the integration environment at 15 past the hour
15 * * * * % env=int
#run QA too
30 * * * % env=qa
</code></pre>
<p>So one job runs <code>@15</code> and one <code>@30</code>.</p>
<p>Yours specify the same time, so only the first is executed.</p>
<p>You could try the random time parameter <code>&quot;H&quot;</code> or fix some different interval on each.</p>
<p>Or, it does say &quot;Leave a space. Put in a %. Then add the name=value pairs&quot;. So maybe it's <code>cronexp space percent space name=value</code> ?</p>
<p>OR you could just copy the job job and schedule two separate jobs w/fixed parameter.
But Jenkins does sound like the wrong tool for this.</p>
<p>The above will address why only the 1st line was executed.</p>
<p><strong>NOTE</strong> :There is a known issue attemptimg to to every minute, see <a href=""https://issues.jenkins-ci.org/browse/JENKINS-22129"" rel=""nofollow noreferrer"">JENKINS-22129</a> H/2 will run every 2 minutes, but H/1 will run every hour.</p>
",13379,2020-06-26T09:01:15.883,['#lets run against the integration environment at 15 past the hour\n15 * * * * % env=int\n#run QA too\n30 * * * % env=qa\n']
1391,11922,11905,CC BY-SA 4.0,2020-06-28T13:38:00.140,"<p>The answer is in environment variables. All builds should have the &quot;Environment Variables&quot; link, which shows all the environment variables, which you can easily compare.  In my case, the difference is in the <code>BUILD_CAUSE</code> and <code>review</code> variables:</p>
<p>Build 1 (started by the scheduler):</p>
<pre><code>BUILD_CAUSE = SCMTRIGGER
</code></pre>
<p>Build 2 (started by &quot;build review&quot;):</p>
<pre><code>BUILD_CAUSE = MANUALTRIGGER
review = 24564765
</code></pre>
<hr />
<p>This solution won't work in the general case, because I have some groovy script and/or some plugin which set these environment variables.</p>
",22372,2020-06-29T05:32:26.633,"['BUILD_CAUSE = SCMTRIGGER\n', 'BUILD_CAUSE = MANUALTRIGGER\nreview = 24564765\n']"
1392,11924,11920,CC BY-SA 4.0,2020-06-28T20:27:25.987,"<p>If you pass the listen address as the very first component of <code>-p</code>, Docker will only listen on that address:</p>
<pre><code>$ docker run -p 127.0.1.2:8080:80 -d nginx`
$ ss -ltp | grep 127.0.1.2
LISTEN  0       4096         127.0.1.2:http-alt          0.0.0.0:*
</code></pre>
",10750,2020-06-28T20:27:25.987,['$ docker run -p 127.0.1.2:8080:80 -d nginx`\n$ ss -ltp | grep 127.0.1.2\nLISTEN  0       4096         127.0.1.2:http-alt          0.0.0.0:*\n']
1393,11943,8415,CC BY-SA 4.0,2020-06-30T21:02:29.190,"<p>You can use the trim parameter:</p>
<pre><code>string(name: 'some parameter', trim: true)
</code></pre>
",22982,2020-06-30T21:02:29.190,"[""string(name: 'some parameter', trim: true)\n""]"
1394,11945,11936,CC BY-SA 4.0,2020-06-30T23:45:13.417,"<p>Yes, Terraform will detect drift in IAM policies.</p>
<p>Here is my starting point, a policy that allows full S3 and SQS access to specific resources.</p>
<pre><code>data &quot;aws_iam_policy_document&quot; &quot;task&quot; {
  statement {
    effect  = &quot;Allow&quot;
    actions = [&quot;sqs:*&quot;]
    resources = [
      aws_sqs_queue.my-queue.arn
    ]
  }

  statement {
    effect  = &quot;Allow&quot;
    actions = [&quot;s3:*&quot;]
    resources = [
      &quot;${aws_s3_bucket.my_bucket.arn}&quot;,
      &quot;${aws_s3_bucket.my_bucket.arn}/*&quot;,
    ]
  }
}

resource &quot;aws_iam_policy&quot; &quot;task_role&quot; {
  name   = &quot;my-task-policy&quot;
  policy = data.aws_iam_policy_document.task.json
}
</code></pre>
<p>I then manually added <code>ec2:DescribeInstances</code> to this policy via the AWS management console.</p>
<p>To test whether it was detected or not, I ran <code>terraform apply -target aws_iam_policy.task_role</code></p>
<pre><code>An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  ~ update in-place

Terraform will perform the following actions:

  # aws_iam_policy.task_role will be updated in-place
  ~ resource &quot;aws_iam_policy&quot; &quot;task_role&quot; {
        arn    = &quot;arn:aws:iam::111111111111:policy/my-task-policy&quot;
        id     = &quot;arn:aws:iam::111111111111:policy/my-task-policy&quot;
        name   = &quot;my-task-policy&quot;
        path   = &quot;/&quot;
      ~ policy = jsonencode(
          ~ {
              ~ Statement = [
                  ... REDACTED...
                  - {
                      - Action   = &quot;ec2:DescribeInstances&quot;
                      - Effect   = &quot;Allow&quot;
                      - Resource = &quot;*&quot;
                      - Sid      = &quot;VisualEditor0&quot;
                    },
                ]
                Version   = &quot;2012-10-17&quot;
            }
        )
    }

Plan: 0 to add, 1 to change, 0 to destroy.
</code></pre>
<p>So Terraform correctly detected the drift.</p>
",132,2020-06-30T23:45:13.417,"['data ""aws_iam_policy_document"" ""task"" {\n  statement {\n    effect  = ""Allow""\n    actions = [""sqs:*""]\n    resources = [\n      aws_sqs_queue.my-queue.arn\n    ]\n  }\n\n  statement {\n    effect  = ""Allow""\n    actions = [""s3:*""]\n    resources = [\n      ""${aws_s3_bucket.my_bucket.arn}"",\n      ""${aws_s3_bucket.my_bucket.arn}/*"",\n    ]\n  }\n}\n\nresource ""aws_iam_policy"" ""task_role"" {\n  name   = ""my-task-policy""\n  policy = data.aws_iam_policy_document.task.json\n}\n', 'An execution plan has been generated and is shown below.\nResource actions are indicated with the following symbols:\n  ~ update in-place\n\nTerraform will perform the following actions:\n\n  # aws_iam_policy.task_role will be updated in-place\n  ~ resource ""aws_iam_policy"" ""task_role"" {\n        arn    = ""arn:aws:iam::111111111111:policy/my-task-policy""\n        id     = ""arn:aws:iam::111111111111:policy/my-task-policy""\n        name   = ""my-task-policy""\n        path   = ""/""\n      ~ policy = jsonencode(\n          ~ {\n              ~ Statement = [\n                  ... REDACTED...\n                  - {\n                      - Action   = ""ec2:DescribeInstances""\n                      - Effect   = ""Allow""\n                      - Resource = ""*""\n                      - Sid      = ""VisualEditor0""\n                    },\n                ]\n                Version   = ""2012-10-17""\n            }\n        )\n    }\n\nPlan: 0 to add, 1 to change, 0 to destroy.\n']"
1395,11950,11949,CC BY-SA 4.0,2020-07-01T17:06:59.977,"<p>I've done this before, normally in the form of having a <code>/.well-known/info</code> endpoint available on every microservice that then returns a JSON payload with what's in it:</p>
<pre><code>{
    &quot;service_name&quot;: &quot;token_exchange&quot;,
    &quot;server_id&quot;: &quot;RD1717628373&quot;,
    &quot;commit_hash&quot;: &quot;f72a28&quot;,
    &quot;branch&quot;: &quot;feature/content-security-policy&quot;,
    &quot;version&quot;: &quot;v2.8.12-f72a28-prerelease1&quot;,
    &quot;dependencies&quot;: [
        {
            &quot;id&quot;: &quot;db&quot;,
            &quot;type&quot;: &quot;database&quot;,
            &quot;endpoint&quot;: &quot;db.mysite.com&quot;
        },
        {
            &quot;id&quot;: &quot;service&quot;,
            &quot;type&quot;: &quot;microservice&quot;,
            &quot;endpoint&quot;: &quot;RD661872834&quot;
        }
    ]
}
</code></pre>
<p>I then have a cron job and custom dashboard that queries all of the services that it knows about and then walks the dependency tree to add any newly added dependencies.</p>
<h1>Considerations</h1>
<ol>
<li><strong>Agree a Standard</strong> - The first step is to agree on a standard across services that you want to report on, then get them implemented.  It's hard to show the value of this kind of thing when only 1% of your estate implements it.</li>
<li><strong>Start Small</strong> - I created a command-line interface that went and queried it at first.</li>
<li><strong>Security</strong> - It could be an attack surface from an information security perspective, so test it and possibly add some authentication component to it and turn it off in production.</li>
</ol>
",397,2020-07-01T17:06:59.977,"['{\n    ""service_name"": ""token_exchange"",\n    ""server_id"": ""RD1717628373"",\n    ""commit_hash"": ""f72a28"",\n    ""branch"": ""feature/content-security-policy"",\n    ""version"": ""v2.8.12-f72a28-prerelease1"",\n    ""dependencies"": [\n        {\n            ""id"": ""db"",\n            ""type"": ""database"",\n            ""endpoint"": ""db.mysite.com""\n        },\n        {\n            ""id"": ""service"",\n            ""type"": ""microservice"",\n            ""endpoint"": ""RD661872834""\n        }\n    ]\n}\n']"
1396,11964,11956,CC BY-SA 4.0,2020-07-05T23:32:54.530,"<p>I'm not really sure I understand your question, but you can execute arbitrary Groovy inside of a <code>script</code> block, so you can do just about anything within <code>script</code>.</p>
<p>For example, here is my interpretation of what you are asking for:</p>
<pre><code>stage ('Execute jobs') {
    steps {
        node('node1') {
            script {
                parallel_jobs = [:]
                if (params.includeJob1 == &quot;true&quot;) {
                    parallel_jobs['ci'] = {
                        build job: job1, parameters: [], propagate: true
                    }
                }
                parallel_jobs['second'] = {
                    build job: job2, parameters: [], propagate: true
                }

                // ...
                // and more jobs dinamically added to the parallel_jobs list
                // ... parallel_jobs['etc'] = ...

                if (params.parallel) {
                    // execute jobs in parallel
                    parallel(parallel_jobs)
                } else {
                    // execute jobs in sequence
                    parallel_jobs.each { name, closure-&gt;
                        closure.call()
                    }
                }
            }
        }
    }
}
</code></pre>
<p>In Groovy, Maps (i.e. associative arrays) are ordered.  So if you use this to execute the builds serially rather than in parallel, the builds will be executed in the order they are defined.</p>
",4115,2020-07-05T23:32:54.530,"['stage (\'Execute jobs\') {\n    steps {\n        node(\'node1\') {\n            script {\n                parallel_jobs = [:]\n                if (params.includeJob1 == ""true"") {\n                    parallel_jobs[\'ci\'] = {\n                        build job: job1, parameters: [], propagate: true\n                    }\n                }\n                parallel_jobs[\'second\'] = {\n                    build job: job2, parameters: [], propagate: true\n                }\n\n                // ...\n                // and more jobs dinamically added to the parallel_jobs list\n                // ... parallel_jobs[\'etc\'] = ...\n\n                if (params.parallel) {\n                    // execute jobs in parallel\n                    parallel(parallel_jobs)\n                } else {\n                    // execute jobs in sequence\n                    parallel_jobs.each { name, closure->\n                        closure.call()\n                    }\n                }\n            }\n        }\n    }\n}\n']"
1397,11968,11967,CC BY-SA 4.0,2020-07-06T11:25:32.370,"<p>You need to use <code>set_fact</code> when setting a variable (instead of <code>register</code> the outcome of a task):</p>
<pre class=""lang-yaml prettyprint-override""><code>- name: Set myParam from ini
  set_fact:
    myParam: &quot;{{ lookup('ini', 'section=mySection, file=/path_to/ini_file') }}&quot;

</code></pre>
<p>In the lookup:</p>
<ul>
<li><code>ini</code> specifies what lookup plugin we are using</li>
<li><code>section</code> and <code>file</code> are arguments passed to the lookup, according to <a href=""https://docs.ansible.com/ansible/latest/plugins/lookup/ini.html"" rel=""nofollow noreferrer"">its documentation</a></li>
</ul>
",354,2020-07-06T11:25:32.370,"['- name: Set myParam from ini\n  set_fact:\n    myParam: ""{{ lookup(\'ini\', \'section=mySection, file=/path_to/ini_file\') }}""\n\n']"
1398,11976,11967,CC BY-SA 4.0,2020-07-08T10:20:16.223,"<p>Since the ini lookup plugin only reads files local to the controlling host, the remote file needs to be fetched locally before it can be read and set_fact has to be used to put its content into a variable, which results in the following:</p>
<pre><code>- block:
  - name: &quot;Retrieve remote ini file&quot;
    fetch:
      src: /path_to/ini_file
      dest: /tmp/ansible
  - name: &quot;Read and store my value&quot;
    set_fact:
      my_variable: &quot;{{ lookup( 'ini', 'myParam section=mySection file=/tmp/ansible/{{ inventory_hostname }}/path_to/ini_file' ) }}&quot;
</code></pre>
<p>Then the parameter is available as variable and can be used further in the playbook</p>
<pre><code>- debug:
    var: my_variable
</code></pre>
",23051,2020-07-08T10:20:16.223,"['- block:\n  - name: ""Retrieve remote ini file""\n    fetch:\n      src: /path_to/ini_file\n      dest: /tmp/ansible\n  - name: ""Read and store my value""\n    set_fact:\n      my_variable: ""{{ lookup( \'ini\', \'myParam section=mySection file=/tmp/ansible/{{ inventory_hostname }}/path_to/ini_file\' ) }}""\n', '- debug:\n    var: my_variable\n']"
1399,11983,11981,CC BY-SA 4.0,2020-07-09T16:48:16.563,"<p>Based on your output, all of your docker commands are running as root when in general they should be running as the jenkins user. You can try switching the user to jenkins and running the same docker login and pull commands.</p>
<p>I've used the following in my Jenkins pipeline scripts to log into a Nexus 3 Docker repository (<a href=""https://docs.cloudbees.com/docs/admin-resources/latest/plugins/docker-workflow"" rel=""nofollow noreferrer"">https://docs.cloudbees.com/docs/admin-resources/latest/plugins/docker-workflow</a>):</p>
<pre><code>docker.withRegistry('https://docker.mycorp.com/', 'docker-login') {
  git '…'
  docker.build('myapp').push('latest')
}
</code></pre>
",23100,2020-07-09T16:48:16.563,"[""docker.withRegistry('https://docker.mycorp.com/', 'docker-login') {\n  git '…'\n  docker.build('myapp').push('latest')\n}\n""]"
1400,11992,11991,CC BY-SA 4.0,2020-07-13T10:21:21.617,"<p>If you want to modify the configuration and rules, so you must save the current configuration to a file.
So step one is to save the rules configuration by typing the following commands:</p>
<pre><code>$ sudo iptables-save &gt; /root/my-iptables.rules
</code></pre>
<p>To restore it just use the command iptables-restore:</p>
<pre><code>$ sudo iptables-restore &lt; /root/my-iptables.rules
</code></pre>
<p>⚠️ When you changed the existing rules after saving the file, You should save it again or change the existing file and restore it from the file.</p>
",11759,2020-07-13T10:21:21.617,"['$ sudo iptables-save > /root/my-iptables.rules\n', '$ sudo iptables-restore < /root/my-iptables.rules\n']"
1401,11993,11981,CC BY-SA 4.0,2020-07-13T13:31:21.663,"<p>I was able to produce a correct behaviour starting from <code>centos:centos7</code> base image and installing Docker only (no Jenkins yet) via the steps provided in the official Docker docu:
<a href=""https://docs.docker.com/engine/install/centos/"" rel=""nofollow noreferrer"">https://docs.docker.com/engine/install/centos/</a></p>
<p>Seen here:</p>
<pre><code>[root@d8d441ae6a7a /]# history
    2  yum remove docker                   docker-client                   docker-client-latest                   docker-common                   docker-latest                   docker-latest-logrotate                   docker-logrotate                   docker-engine
    3  yum install -y yum-utils
    4  yum-config-manager     --add-repo     https://download.docker.com/linux/centos/docker-ce.repo
    5  yum install docker-ce docker-ce-cli containerd.io
    6  systemctl start docker
    7  docker ps
    8  docker run hello-world
    9  docker login https://nexus:port
10  docker login https://nexus:port
11  docker pull nexus:port/company/image:tag


# docker pull nexus:port/company/image:tag
...
Status: Downloaded newer image for nexus:port/company/image:tag
</code></pre>
<p>While I still have the faulty behaviour when I install docker via <code>yum install -y docker</code>. So it's pretty clear to assume that I'm not facing an issue with the Jenkins Docker images specifically but rather face centos problems with their Docker package.</p>
<p>I guess there is no need here for an answer. I will go on to talk to the centos people.</p>
<p>Cheers and thanks for your consideration everyone!</p>
",7646,2020-07-13T13:31:21.663,['[root@d8d441ae6a7a /]# history\n    2  yum remove docker                   docker-client                   docker-client-latest                   docker-common                   docker-latest                   docker-latest-logrotate                   docker-logrotate                   docker-engine\n    3  yum install -y yum-utils\n    4  yum-config-manager     --add-repo     https://download.docker.com/linux/centos/docker-ce.repo\n    5  yum install docker-ce docker-ce-cli containerd.io\n    6  systemctl start docker\n    7  docker ps\n    8  docker run hello-world\n    9  docker login https://nexus:port\n10  docker login https://nexus:port\n11  docker pull nexus:port/company/image:tag\n\n\n# docker pull nexus:port/company/image:tag\n...\nStatus: Downloaded newer image for nexus:port/company/image:tag\n']
1402,11996,11991,CC BY-SA 4.0,2020-07-14T06:09:58.253,"<p>The first thing to point out, is that you should already be writing IP tables rules to a file, and restoring them from that file at start up - otherwise you will lose all of the rules when the server reboots.</p>
<p>The standard commands to do this on Debian are:</p>
<pre><code>sudo iptables-save &gt; /etc/iptables.up.rules
sudo iptables-restore &lt; /etc/iptables.up.rules
</code></pre>
<p><strong>DO NOT EDIT THIS FILE</strong></p>
<blockquote>
<p>If you make a change that breaks your networking, killing your access
to the server, then you can only recover by walking to the computer's
console, and logging in there to fix the problem.  If thats a Cloud
server, or in a different city / country / continent you have a bigger
problem.</p>
</blockquote>
<p>The next issue that i want to cover, is if writing individual rules is hard, the config files just capture the same command that you would type into the terminal window. Using a configuration file does not reduce the complexity here.</p>
<p>Personally, I would use the existing file to help with the syntax (e.g. find something that already does something that i want to do), and then run that command manually in the shell, and verify that it does what i need it to do by testing the network connections carefully, and thoroughly.  I would then save rules, knowing that they are already working and tested.</p>
<p>If i messed up, a server reboot, using the management panel for the server would at least restore the previous IP table rules.</p>
",8049,2020-07-14T06:09:58.253,['sudo iptables-save > /etc/iptables.up.rules\nsudo iptables-restore < /etc/iptables.up.rules\n']
1403,11999,11973,CC BY-SA 4.0,2020-07-14T23:08:50.220,"<p>First, @Meir beat me to the punch on <code>awsvpc</code> network mode, so give him a +1 and read his linked document about task networking.</p>
<hr />
<p>I'm going to expand on that and include an description of how to route to your containers from both a public-facing ALB, as well as from another container.</p>
<p>To simplify things, we're going to pretend we're running on ECS Fargate to start, and at the end I'll point how that would be different for EC2.</p>
<p>You described two ECS services: one that is public-facing behind the ALB, which we'll call <strong>frontend</strong>, and the other, which communicates to other containers internally, we will call <strong>backend</strong>.</p>
<p>Here's what <strong>frontend</strong> that might look like in Terraform:</p>
<pre><code>resource &quot;aws_ecs_task_definition&quot; &quot;frontend&quot; {
  family                   = &quot;frontend&quot;
  network_mode             = &quot;awsvpc&quot;
  requires_compatibilities = [&quot;FARGATE&quot;]
  execution_role_arn       = &quot;&quot; # generic

  container_definitions = &quot;[]&quot; # not included in example
}

resource &quot;aws_ecs_service&quot; &quot;frontend&quot; {
  name            = &quot;frontend&quot;
  cluster         = &quot;my-ecs-cluster&quot;
  task_definition = aws_ecs_task_definition.frontend.arn
  desired_count   = 2 # high availability
  launch_type     = &quot;FARGATE&quot;

  network_configuration {
    security_groups = [] # SG allowing traffic from the loadbalancer to port 8080
    subnets = [] # list of private subnets
  }

  load_balancer {
    target_group_arn = &quot;&quot; # an aws_alb_target_group
    container_name   = &quot;frontend&quot;
    container_port   = 8080
  }
}
</code></pre>
<p><strong>backend</strong> would look similar, except instead of a <code>load_balancer</code> block it would have this:</p>
<pre><code>  service_registries {
    registry_arn = aws_service_discovery_service.internal.arn
  }
</code></pre>
<p>And these new resources:</p>
<pre><code>resource &quot;aws_service_discovery_private_dns_namespace&quot; &quot;internal&quot; {
  name = &quot;internal.dev&quot;
  vpc  = &quot;&quot; # a vpc id
}

resource &quot;aws_service_discovery_service&quot; &quot;backend&quot; {
  name = &quot;backend&quot;

  dns_config {
    namespace_id = aws_service_discovery_private_dns_namespace.internal.id
    dns_records {
      ttl  = 10
      type = &quot;A&quot;
    }
  }
}
</code></pre>
<p>Service Discovery creates and manages DNS records for the private IPs (ENIs) of your <strong>backend</strong> tasks automatically. That means <code>backend.internal.dev</code> now resolves to one of those IPs in your VPC CIDRs, something like <code>10.10.0.60</code>.</p>
<p>Now when <strong>frontend</strong> wants to connect to <strong>backend</strong>, it can do so via <code>backend.internal.dev</code>. No internal ALB required! Your entire VPC can resolve that domain.</p>
<hr />
<p><em>&quot;Okay, but how does this work on EC2?&quot;</em> you might ask. Well, that's the beauty of <code>awsvpc</code> network mode... it works the same way! These task ENIs are completely different network devices than your EC2 instance's ENI. You will need to modify the Terraform slightly, and perhaps review your security groups, but ultimately nothing has changed: the ALB still connects to the <strong>frontend</strong> task ENI, and the <strong>backend</strong> task ENI is still registered in service discovery. You can run multiples of the same container on a single EC2 instance without port collision because they are using different network interfaces.</p>
<hr />
<p>References:</p>
<p><a href=""https://aws.amazon.com/blogs/aws/amazon-ecs-service-discovery/"" rel=""nofollow noreferrer"">https://aws.amazon.com/blogs/aws/amazon-ecs-service-discovery/</a>
<a href=""https://aws.amazon.com/about-aws/whats-new/2019/06/Amazon-ECS-Improves-ENI-Density-Limits-for-awsvpc-Networking-Mode/"" rel=""nofollow noreferrer"">https://aws.amazon.com/about-aws/whats-new/2019/06/Amazon-ECS-Improves-ENI-Density-Limits-for-awsvpc-Networking-Mode/</a></p>
",132,2020-07-15T00:04:29.007,"['resource ""aws_ecs_task_definition"" ""frontend"" {\n  family                   = ""frontend""\n  network_mode             = ""awsvpc""\n  requires_compatibilities = [""FARGATE""]\n  execution_role_arn       = """" # generic\n\n  container_definitions = ""[]"" # not included in example\n}\n\nresource ""aws_ecs_service"" ""frontend"" {\n  name            = ""frontend""\n  cluster         = ""my-ecs-cluster""\n  task_definition = aws_ecs_task_definition.frontend.arn\n  desired_count   = 2 # high availability\n  launch_type     = ""FARGATE""\n\n  network_configuration {\n    security_groups = [] # SG allowing traffic from the loadbalancer to port 8080\n    subnets = [] # list of private subnets\n  }\n\n  load_balancer {\n    target_group_arn = """" # an aws_alb_target_group\n    container_name   = ""frontend""\n    container_port   = 8080\n  }\n}\n', '  service_registries {\n    registry_arn = aws_service_discovery_service.internal.arn\n  }\n', 'resource ""aws_service_discovery_private_dns_namespace"" ""internal"" {\n  name = ""internal.dev""\n  vpc  = """" # a vpc id\n}\n\nresource ""aws_service_discovery_service"" ""backend"" {\n  name = ""backend""\n\n  dns_config {\n    namespace_id = aws_service_discovery_private_dns_namespace.internal.id\n    dns_records {\n      ttl  = 10\n      type = ""A""\n    }\n  }\n}\n']"
1404,12001,4616,CC BY-SA 4.0,2020-07-15T09:30:45.030,"<p>For anyone came here to solve this problem without any workarounds - the solution is simple.</p>
<p>We need to add switch <code>--cache</code> to the kubeconfig for a user used to access a Kubernetes cluster.</p>
<pre><code>users:
- name: &lt;redacted&gt;
  user:
    exec:
      apiVersion: client.authentication.k8s.io/v1alpha1
      args:
      - token
      - --cache
      - -i
      - prod
</code></pre>
<p>Tested on:</p>
<pre><code>$ aws-iam-authenticator version
{&quot;Version&quot;:&quot;v0.5.1&quot;,&quot;Commit&quot;:&quot;d7c0b2e9131faabb2b09dd804a35ee03822f8447&quot;}
</code></pre>
<p>Hope this will help someone.</p>
",23163,2020-07-15T09:30:45.030,"['users:\n- name: <redacted>\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1alpha1\n      args:\n      - token\n      - --cache\n      - -i\n      - prod\n', '$ aws-iam-authenticator version\n{""Version"":""v0.5.1"",""Commit"":""d7c0b2e9131faabb2b09dd804a35ee03822f8447""}\n']"
1405,12005,11653,CC BY-SA 4.0,2020-07-15T16:20:29.503,"<p>Your CloudFormation template currently has the following resources:</p>
<ul>
<li>A Launch Configuration</li>
<li>An Auto Scaling Group</li>
<li>A Load Balancer</li>
</ul>
<p>Follow these steps in sequence to attach the auto scaling group to the load balancer:</p>
<ol>
<li><p>Add a listener resource to your CloudFormation template, as described <a href=""https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-listener.html"" rel=""noreferrer"">here</a>. Set its <code>LoadBalancerArn</code> property to the load balancer's ARN.</p>
</li>
<li><p>Add a target group resource to your CloudFormation template, as described <a href=""https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-targetgroup.html"" rel=""noreferrer"">here</a>.</p>
</li>
<li><p>Add a &quot;listener rule&quot; resource to your CloudFormation template, as described <a href=""https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-listenerrule.html"" rel=""noreferrer"">here</a>. Set its <code>ListenerArn</code> property to the listener's ARN. In its <code>Actions</code> property, add a <code>forward</code> action &amp; provide the target group's ARN like this:</p>
</li>
</ol>
<pre><code>Actions:
- Type: forward
  TargetGroupArn: !Ref MyTargetGroup
</code></pre>
<ol start=""4"">
<li>Add the target group's ARN to the <code>TargetGroupARNs</code> property of the auto scaling group, as described <a href=""https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-as-group.html#cfn-as-group-targetgrouparns"" rel=""noreferrer"">here</a>.</li>
</ol>
<p>If you prefer to visualize a chain of CloudFormation resources linking the load balancer to the auto scaling group, it'll look like this:</p>
<p><a href=""https://i.stack.imgur.com/OaeBH.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/OaeBH.png"" alt=""enter image description here"" /></a></p>
<p>Here's a complete example: <a href=""https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-elasticloadbalancingv2-listenerrule.html#aws-resource-elasticloadbalancingv2-listenerrule--examples--HTTP_Header_Rule_Example--yaml"" rel=""noreferrer"">LB to ASG Example</a>.</p>
",17435,2020-07-15T16:20:29.503,['Actions:\n- Type: forward\n  TargetGroupArn: !Ref MyTargetGroup\n']
1406,12024,12023,CC BY-SA 4.0,2020-07-18T10:31:43.133,"<p>Call Lambda's <a href=""https://docs.aws.amazon.com/lambda/latest/dg/API_UpdateEventSourceMapping.html"" rel=""nofollow noreferrer"">UpdateEventSourceMapping</a> API with the <code>{&quot;Enabled&quot;:true/false}</code> request body.</p>
<p>If, for some reason, you want your own API for this, you can create one in API Gateway as described below.</p>
<p>Before you begin, you need the UUID of the event source mapping you wish to enable/disable. Use the AWS CLI to get this (it isn’t shown on the UI):</p>
<pre><code>aws lambda list-event-source-mappings --function-name my-func
</code></pre>
<pre><code>{
    &quot;EventSourceMappings&quot;: [
        {
            &quot;UUID&quot;: &quot;b962dcee-173c-47r1-9600-5c6d81catf85&quot;,
            &quot;BatchSize&quot;: 1,
            &quot;EventSourceArn&quot;: &quot;arn:aws:sqs:us-east-1:123456789012:my-queue&quot;,
            &quot;FunctionArn&quot;: &quot;arn:aws:lambda:us-east-1:123456789012:function:my-func&quot;,
            &quot;LastModified&quot;: 1595058588.141,
            &quot;State&quot;: &quot;Enabled&quot;,
            &quot;StateTransitionReason&quot;: &quot;USER_INITIATED&quot;
        }
    ]
}
</code></pre>
<p>Next, either create a new API in API Gateway or add a resource &amp; a GET method to your existing API. Configure it as shown below. The UUID you got above is highlighted below:</p>
<p><a href=""https://i.stack.imgur.com/ifgvO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ifgvO.png"" alt=""enter image description here"" /></a></p>
<p>The execution role shown above must allow API Gateway to invoke Lambda APIs.</p>
<p>Scroll further down &amp; provide this mapping template:</p>
<pre><code>Content-Type: application/json
</code></pre>
<pre><code>{
    &quot;Enabled&quot; : $input.params(&quot;Enabled&quot;)
}
</code></pre>
<p>Save &amp; deploy to a stage. Now you can hit this API with the query param <code>Enabled=true</code> / <code>Enabled=false</code> to enable/disable your Lambda's SQS trigger. Here's a test done from the API Gateway console:</p>
<p><a href=""https://i.stack.imgur.com/CGilw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CGilw.png"" alt=""enter image description here"" /></a></p>
<p>For a detailed screenshot-guided walkthrough of this entire process, see <a href=""https://harishkm.in/2020/07/18/enable-disable-aws-lambda-triggers-programmatically-by-invoking-an-api/"" rel=""nofollow noreferrer"">my blog post</a>.</p>
",17435,2020-07-18T10:31:43.133,"['aws lambda list-event-source-mappings --function-name my-func\n', '{\n    ""EventSourceMappings"": [\n        {\n            ""UUID"": ""b962dcee-173c-47r1-9600-5c6d81catf85"",\n            ""BatchSize"": 1,\n            ""EventSourceArn"": ""arn:aws:sqs:us-east-1:123456789012:my-queue"",\n            ""FunctionArn"": ""arn:aws:lambda:us-east-1:123456789012:function:my-func"",\n            ""LastModified"": 1595058588.141,\n            ""State"": ""Enabled"",\n            ""StateTransitionReason"": ""USER_INITIATED""\n        }\n    ]\n}\n', 'Content-Type: application/json\n', '{\n    ""Enabled"" : $input.params(""Enabled"")\n}\n']"
1407,12052,12049,CC BY-SA 4.0,2020-07-22T09:04:32.790,"<p>Define the number of replicas in the <code>values.yaml</code> and pass it anywhere in resources (statefulset)</p>
<p><strong>Update 1:</strong> You can neither have a dynamic environment variable nor refer to the replicas field in STS. So the only way to get an updated count of STS in each pod is to redeploy with the new value of replicas in <code>values.yaml</code>:</p>
<pre class=""lang-yaml prettyprint-override""><code>replicas: 3
</code></pre>
<p><strong>Update 2:</strong></p>
<p>According to this <a href=""https://kubernetes.io/docs/concepts/configuration/secret/#mounted-secrets-are-updated-automatically"" rel=""nofollow noreferrer"">link</a>, you can mount a secret now to each pod and stay up to date about replicas count.</p>
",10769,2020-07-27T07:44:28.143,['replicas: 3\n']
1408,12055,10402,CC BY-SA 4.0,2020-07-22T20:41:25.573,"<p>I didn't find anything on AWS or boto3 docs that allows for that, but I was able to execute as a different user using the <code>runuser</code> command. In theory, you could do the same thing with a combination of <code>sudo</code> and <code>su</code> commands, but this one is pretty simpler.</p>
<p>For that, you can do as follows:</p>
<pre><code>runuser -l  userNameHere -c '/path/to/command arg1 arg2'
</code></pre>
<p>Since send-command executes as root, you don't have any issues.</p>
<p><strong>Note:</strong> I thought that send-command uses in some way a session managed by the <em>SSM Session Manager</em>, but I was wrong. I spent a good time configuring <em>SSM Session Manager</em> preferences and tagging IAM resources according to <a href=""https://docs.aws.amazon.com/systems-manager/latest/userguide/session-preferences-run-as.html"" rel=""nofollow noreferrer"">this doc</a> and <a href=""https://reinvent2019.aws-management.tools/mgt406/en/optional/step5.html"" rel=""nofollow noreferrer"">this one</a>, but send-command always execute as root as far I saw.</p>
<p>Sources:</p>
<ul>
<li><a href=""https://man7.org/linux/man-pages/man1/runuser.1.html"" rel=""nofollow noreferrer"">https://man7.org/linux/man-pages/man1/runuser.1.html</a></li>
<li><a href=""https://www.cyberciti.biz/open-source/command-line-hacks/linux-run-command-as-different-user/"" rel=""nofollow noreferrer"">https://www.cyberciti.biz/open-source/command-line-hacks/linux-run-command-as-different-user/</a></li>
</ul>
",23273,2020-07-22T20:50:44.047,"[""runuser -l  userNameHere -c '/path/to/command arg1 arg2'\n""]"
1409,12062,12060,CC BY-SA 4.0,2020-07-23T13:06:36.667,"<p>In 2 steps, you can first create your cartesian product in a variable:</p>
<pre><code>locals {
  datadog_gke_clusters_by_pov = flatten([
    for cluster in var.datadog_gke_clusters : [
      for pov in var.gke_slo_ : {
        cluster    = cluster
        pov        = pov
      }
    ]
  ])
}
</code></pre>
<p>And then use this new variable in your resource block:</p>
<pre><code>resource &quot;datadog_synthetics_test&quot; &quot;gke-monitoring&quot; {
  for_each = {
    for valuue in local.datadog_gke_clusters_by_pov : &quot;${valuue.cluster.name}-${valuue.pov.zone_name}&quot; =&gt; valuue
  }
...
# here you can use each.value.cluster.* and each.value.pov.*
}
</code></pre>
<p>Have a good day!</p>
",23282,2020-07-23T13:06:36.667,"['locals {\n  datadog_gke_clusters_by_pov = flatten([\n    for cluster in var.datadog_gke_clusters : [\n      for pov in var.gke_slo_ : {\n        cluster    = cluster\n        pov        = pov\n      }\n    ]\n  ])\n}\n', 'resource ""datadog_synthetics_test"" ""gke-monitoring"" {\n  for_each = {\n    for valuue in local.datadog_gke_clusters_by_pov : ""${valuue.cluster.name}-${valuue.pov.zone_name}"" => valuue\n  }\n...\n# here you can use each.value.cluster.* and each.value.pov.*\n}\n']"
1410,12064,12060,CC BY-SA 4.0,2020-07-23T15:07:59.000,"<p>As in Terraform, a loop &quot;products&quot; a result (a map, a list, an object...), in this case, you have to avoid nested loop:</p>
<pre><code># Clusters
variable &quot;datadog_gke_clusters&quot; {
  type = list(object({
    name        = string
    environment = string
    url = object({
      private = string
      public  = string
    })
  }))
  default = [
    # NPRD
    {
      name        = &quot;cluster01&quot;
      environment = &quot;nprd&quot;
      url = {
        private = &quot;https://private.domain-priv.com&quot;
        public  = &quot;https://public.domain.com&quot;
      }
    },
    # PROD
    {
      name        = &quot;cluster02&quot;
      environment = &quot;nprd&quot;
      url = {
        private = &quot;https://private.domain-priv.com&quot;
        public  = &quot;https://public.domain.com&quot;
      }
    }
  ]
}

# Point of views
variable &quot;gke_slo&quot; {
  type = list(object({
    zone              = string
    monitor_threshold = number
  }))
  description = &quot;Response time threshold in ms to respond to a request.&quot;
  default = [
    {
      zone              = &quot;private&quot;
      monitor_threshold = 50
    },
    {
      zone              = &quot;public&quot;
      monitor_threshold = 100
    },
  ]
}

locals {
  result = {
    for tuple in setproduct(var.datadog_gke_clusters, var.gke_slo): &quot;${tuple[0].name}_${tuple[1].zone}&quot; =&gt; {
      name              = tuple[0].name
      environment       = tuple[0].environment
      url               = tuple[0].url
      zone              = tuple[1].zone
      monitor_threshold = tuple[1].monitor_threshold
    }
  }
}

output &quot;result&quot; {
  value = local.result
}
</code></pre>
<p>Here we use <code>setproduct</code> to produce a <code>list(list(tuple(cluster,pov))</code> and then we can iterate on the first list to produce the expected result.</p>
",23283,2020-07-23T15:07:59.000,"['# Clusters\nvariable ""datadog_gke_clusters"" {\n  type = list(object({\n    name        = string\n    environment = string\n    url = object({\n      private = string\n      public  = string\n    })\n  }))\n  default = [\n    # NPRD\n    {\n      name        = ""cluster01""\n      environment = ""nprd""\n      url = {\n        private = ""https://private.domain-priv.com""\n        public  = ""https://public.domain.com""\n      }\n    },\n    # PROD\n    {\n      name        = ""cluster02""\n      environment = ""nprd""\n      url = {\n        private = ""https://private.domain-priv.com""\n        public  = ""https://public.domain.com""\n      }\n    }\n  ]\n}\n\n# Point of views\nvariable ""gke_slo"" {\n  type = list(object({\n    zone              = string\n    monitor_threshold = number\n  }))\n  description = ""Response time threshold in ms to respond to a request.""\n  default = [\n    {\n      zone              = ""private""\n      monitor_threshold = 50\n    },\n    {\n      zone              = ""public""\n      monitor_threshold = 100\n    },\n  ]\n}\n\nlocals {\n  result = {\n    for tuple in setproduct(var.datadog_gke_clusters, var.gke_slo): ""${tuple[0].name}_${tuple[1].zone}"" => {\n      name              = tuple[0].name\n      environment       = tuple[0].environment\n      url               = tuple[0].url\n      zone              = tuple[1].zone\n      monitor_threshold = tuple[1].monitor_threshold\n    }\n  }\n}\n\noutput ""result"" {\n  value = local.result\n}\n']"
1411,12072,12049,CC BY-SA 4.0,2020-07-24T16:00:13.997,"<p>If you launch the statefulset with the following key set</p>
<pre><code>{&quot;spec&quot;:{&quot;template&quot;:{&quot;spec&quot;:{&quot;serviceAccountName&quot;:&quot;myserviceaccount&quot;}}}}
</code></pre>
<p>you can run</p>
<pre><code>curl \
https://kubernetes/apis/apps/v1/namespaces/&lt;NAMESPACE&gt;/statefulsets/&lt;STATEFULSET&gt; \
-k -H &quot;Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)&quot; \
| jq '.spec.replicas'
</code></pre>
<p>to extract the replica count. This, of course, relies on the service account (myserviceaccount in this example) to have appropriate permissions to actually query the k8s API for this information, as well as having curl and jq available in the container.</p>
<p>You could then setup some kind of background job in the container to regularly make this request and update an env var or file or whatever.</p>
",10718,2020-07-24T16:00:13.997,"['{""spec"":{""template"":{""spec"":{""serviceAccountName"":""myserviceaccount""}}}}\n', 'curl \\\nhttps://kubernetes/apis/apps/v1/namespaces/<NAMESPACE>/statefulsets/<STATEFULSET> \\\n-k -H ""Authorization: Bearer $(cat /var/run/secrets/kubernetes.io/serviceaccount/token)"" \\\n| jq \'.spec.replicas\'\n']"
1412,12076,12049,CC BY-SA 4.0,2020-07-25T10:01:02.443,"<p>There are two ways either increase the number in your DeploymentConfig directly or use <code>oc scale statefulset &lt;name_of_statfulset&gt; --replicas=2</code></p>
<pre><code>apiVersion: apps.openshift.io/v1
kind: DeploymentConfig
metadata:
  labels:
  app: jekyll
  name: jekyll
  namespace: test
spec:
  replicas: 1 &lt;----------- here increase the number
 
</code></pre>
",15169,2020-08-05T11:18:29.967,['apiVersion: apps.openshift.io/v1\nkind: DeploymentConfig\nmetadata:\n  labels:\n  app: jekyll\n  name: jekyll\n  namespace: test\nspec:\n  replicas: 1 <----------- here increase the number\n \n']
1413,12080,12060,CC BY-SA 4.0,2020-07-26T11:58:08.097,"<p>Your loop is being nested.</p>
<p>Use this instead.</p>
<pre><code># Clusters
variable &quot;datadog_gke_clusters&quot; {
  type = list(object({
    name        = string
    environment = string
    url = object({
      private = string
      public  = string
    })
  }))
  default = [
    # NPRD
    {
      name        = &quot;cluster01&quot;
      environment = &quot;nprd&quot;
      url = {
        private = &quot;https://private.domain-priv.com&quot;
        public  = &quot;https://public.domain.com&quot;
      }
    },
    # PROD
    {
      name        = &quot;cluster02&quot;
      environment = &quot;nprd&quot;
      url = {
        private = &quot;https://private.domain-priv.com&quot;
        public  = &quot;https://public.domain.com&quot;
      }
    }
  ]
}

# Point of views
variable &quot;gke_slo&quot; {
  type = list(object({
    zone              = string
    monitor_threshold = number
  }))
  description = &quot;Response time threshold in ms to respond to a request.&quot;
  default = [
    {
      zone              = &quot;private&quot;
      monitor_threshold = 50
    },
    {
      zone              = &quot;public&quot;
      monitor_threshold = 100
    },
  ]
}

locals {
  result = {
    for tuple in setproduct(var.datadog_gke_clusters, var.gke_slo): &quot;${tuple[0].name}_${tuple[1].zone}&quot; =&gt; {
      name              = tuple[0].name
      environment       = tuple[0].environment
      url               = tuple[0].url
      zone              = tuple[1].zone
      monitor_threshold = tuple[1].monitor_threshold
    }
  }
}

output &quot;result&quot; {
  value = local.result
}
</code></pre>
",23308,2020-08-09T05:56:53.117,"['# Clusters\nvariable ""datadog_gke_clusters"" {\n  type = list(object({\n    name        = string\n    environment = string\n    url = object({\n      private = string\n      public  = string\n    })\n  }))\n  default = [\n    # NPRD\n    {\n      name        = ""cluster01""\n      environment = ""nprd""\n      url = {\n        private = ""https://private.domain-priv.com""\n        public  = ""https://public.domain.com""\n      }\n    },\n    # PROD\n    {\n      name        = ""cluster02""\n      environment = ""nprd""\n      url = {\n        private = ""https://private.domain-priv.com""\n        public  = ""https://public.domain.com""\n      }\n    }\n  ]\n}\n\n# Point of views\nvariable ""gke_slo"" {\n  type = list(object({\n    zone              = string\n    monitor_threshold = number\n  }))\n  description = ""Response time threshold in ms to respond to a request.""\n  default = [\n    {\n      zone              = ""private""\n      monitor_threshold = 50\n    },\n    {\n      zone              = ""public""\n      monitor_threshold = 100\n    },\n  ]\n}\n\nlocals {\n  result = {\n    for tuple in setproduct(var.datadog_gke_clusters, var.gke_slo): ""${tuple[0].name}_${tuple[1].zone}"" => {\n      name              = tuple[0].name\n      environment       = tuple[0].environment\n      url               = tuple[0].url\n      zone              = tuple[1].zone\n      monitor_threshold = tuple[1].monitor_threshold\n    }\n  }\n}\n\noutput ""result"" {\n  value = local.result\n}\n']"
1414,12094,12090,CC BY-SA 4.0,2020-07-29T16:41:20.333,"<p>The problem is that the date format isn't ideal.</p>
<blockquote>
<p>Supported formats for date formatted time stamps include RFC3339Nano, RFC3339, 2006-01-02T15:04:05, 2006-01-02T15:04:05.999999999, 2006-01-02Z07:00, and 2006-01-02</p>
</blockquote>
<p>Reference: <a href=""https://docs.docker.com/engine/reference/commandline/system_prune/#filtering"" rel=""nofollow noreferrer"">https://docs.docker.com/engine/reference/commandline/system_prune/#filtering</a></p>
<p>So this is really just a <em>half</em> answer, since it will use the date and the local timestamp.</p>
<blockquote>
<p>The local timezone on the daemon will be used if you do not provide either a Z or a +-00:00 timezone offset at the end of the timestamp.</p>
</blockquote>
<p>Thankfully, this comes sorted.</p>
<pre><code>~: docker images --format '{{.CreatedAt}}'
2020-06-09 12:44:57 -0700 PDT
2020-05-29 14:19:46 -0700 PDT
2020-05-05 13:40:47 -0700 PDT
2020-04-28 11:55:11 -0700 PDT
2020-03-09 10:35:34 -0700 PDT
2020-03-09 10:14:43 -0700 PDT
2020-03-09 10:14:43 -0700 PDT
2020-03-09 10:14:43 -0700 PDT
2020-02-26 07:10:58 -0800 PST
</code></pre>
<p>I don't know how to transform timestamps in bash off the top of my head, so let's just do this the quick and messy way... the whole date!</p>
<pre><code> ~: docker images --format '{{.CreatedAt}}' | sed -n '2p' | awk '{print $1;}'
2020-05-29
</code></pre>
<p>Now we can do command substitution.</p>
<pre><code>~: docker image prune --force --filter &quot;until=`docker images --format '{{.CreatedAt}}' | sed -n '2p' | awk '{print $1;}'`&quot;
Total reclaimed space: 1.344GB
</code></pre>
<p>I didn't put a heck of a lot of thought in to this answer, so there may be some edges cases I didn't consider. Also, if someone with better bash-fu can transform that timestamp, that would be awesome.</p>
",132,2020-07-29T16:41:20.333,"[""~: docker images --format '{{.CreatedAt}}'\n2020-06-09 12:44:57 -0700 PDT\n2020-05-29 14:19:46 -0700 PDT\n2020-05-05 13:40:47 -0700 PDT\n2020-04-28 11:55:11 -0700 PDT\n2020-03-09 10:35:34 -0700 PDT\n2020-03-09 10:14:43 -0700 PDT\n2020-03-09 10:14:43 -0700 PDT\n2020-03-09 10:14:43 -0700 PDT\n2020-02-26 07:10:58 -0800 PST\n"", "" ~: docker images --format '{{.CreatedAt}}' | sed -n '2p' | awk '{print $1;}'\n2020-05-29\n"", '~: docker image prune --force --filter ""until=`docker images --format \'{{.CreatedAt}}\' | sed -n \'2p\' | awk \'{print $1;}\'`""\nTotal reclaimed space: 1.344GB\n']"
1415,12095,4118,CC BY-SA 4.0,2020-07-29T17:56:12.833,"<p>This is how I did:</p>
<pre class=""lang-java prettyprint-override""><code>gitParameter {
            // The name of the parameter.
            name('SELECTED_BRANCH')
            // The type of the list of parameters: Tag - list of all commit tags in repository - returns Tag Name Branch - list of all branch in repository - returns Branch Name Revision - list of all revision sha1 in repository followed by its author and date - returns Tag SHA1
            type('PT_BRANCH')
            // In my case this is a variable pointing to the gitlab hook variable
            defaultValue('$gitlabAfter')
            // A description that will be shown to the user later.
            description('Select a git the configuration you want to deploy')
            // Name of branch to look in.
            branch('')
            // Regex used to filter displayed branches.
            // Whatever is captured in the group will be the name used as the value of the SELECTED_BRANCH
            branchFilter('origin/(config\\/.*)')
            // This parameter is used to get tag from git.
            tagFilter('*')
            // Select how to sort the downloaded parameters.
            sortMode('NONE')
            // Which value is selected, after loaded parameters.
            selectedValue('NONE')
            // If in the task are defined multiple repositories, this option specifies which the repository is taken into account on getting data.
            useRepository(&quot;&lt;my git url&gt;.*&quot;)
            // When this option is enabled will show a text field.
            quickFilterEnabled(false)
            // Specify the number of items the list will display.
            // listSize(String value)
        }

</code></pre>
<p>As strange as it seems, some parameters shouldn't really be necessary, but the plugin requires them anyway, so that's why the config is verbose.</p>
<p>Also, pay attention that this one is <code>gitParameter</code> and not <code>gitParam</code>, yes, both exist, and they take different parameters.</p>
<p>For more information about the properties you can go here:</p>
<p><a href=""https://plugins.jenkins.io/git-parameter/"" rel=""nofollow noreferrer"">https://plugins.jenkins.io/git-parameter/</a></p>
",23222,2020-07-29T17:56:12.833,"['gitParameter {\n            // The name of the parameter.\n            name(\'SELECTED_BRANCH\')\n            // The type of the list of parameters: Tag - list of all commit tags in repository - returns Tag Name Branch - list of all branch in repository - returns Branch Name Revision - list of all revision sha1 in repository followed by its author and date - returns Tag SHA1\n            type(\'PT_BRANCH\')\n            // In my case this is a variable pointing to the gitlab hook variable\n            defaultValue(\'$gitlabAfter\')\n            // A description that will be shown to the user later.\n            description(\'Select a git the configuration you want to deploy\')\n            // Name of branch to look in.\n            branch(\'\')\n            // Regex used to filter displayed branches.\n            // Whatever is captured in the group will be the name used as the value of the SELECTED_BRANCH\n            branchFilter(\'origin/(config\\\\/.*)\')\n            // This parameter is used to get tag from git.\n            tagFilter(\'*\')\n            // Select how to sort the downloaded parameters.\n            sortMode(\'NONE\')\n            // Which value is selected, after loaded parameters.\n            selectedValue(\'NONE\')\n            // If in the task are defined multiple repositories, this option specifies which the repository is taken into account on getting data.\n            useRepository(""<my git url>.*"")\n            // When this option is enabled will show a text field.\n            quickFilterEnabled(false)\n            // Specify the number of items the list will display.\n            // listSize(String value)\n        }\n\n']"
1416,12098,12074,CC BY-SA 4.0,2020-07-29T22:13:48.997,"<p>Your current shell environment variables, which are also including terraform-related ones can be listed by <code>env</code> command or you can do it in tf file:</p>
<pre><code>terraform {
  required_version = &quot;&gt;= 0.12.0&quot;
}

resource &quot;null_resource&quot; &quot;get_tf_env&quot; {
  provisioner &quot;local-exec&quot; {
    command = &quot;env&quot;
    interpreter = [&quot;bash&quot;, &quot;-c&quot;]
  }
}
</code></pre>
<p>According to <a href=""https://www.terraform.io/docs/commands/environment-variables.html"" rel=""nofollow noreferrer"">official docs</a> you can only feed terraform with the envs starting with <code>TF_*</code>.</p>
",10769,2020-07-29T22:13:48.997,"['terraform {\n  required_version = "">= 0.12.0""\n}\n\nresource ""null_resource"" ""get_tf_env"" {\n  provisioner ""local-exec"" {\n    command = ""env""\n    interpreter = [""bash"", ""-c""]\n  }\n}\n']"
1417,12111,676,CC BY-SA 4.0,2020-07-31T22:43:25.040,"<p>Docker-in-docker has gotten better over the years and the <a href=""https://hub.docker.com/_/docker"" rel=""nofollow noreferrer"">docker dind</a> image is getting more maturity. However there are still a number of caveats that make its use relatively difficult to get right.</p>
<h3>Storage driver</h3>
<p>The main challenge of getting docker-in-docker to work well is the storage driver of the docker installation. On your host you would have filesystems like <code>ext4</code>, which docker can run <code>overlayfs2</code> on top of. However, within a docker container, docker is unable to use <code>overlayfs2</code> as the backing filesystem of another <code>overlayfs2</code>. It doesn't work recursively. There are no easy setups to create a recursive docker-in-docker storage driver stack that works well.</p>
<p>The only storage driver that works on anything is <code>vfs</code>. However, <code>vfs</code> does not have copy-on-write capabilities, meaning that every docker build layer is actually a complete copy of the previous layers. In docker builds with many layers, high amounts of duplication cause performance issues as well as they quickly exhaust disk space. So it's usually not a real solution.</p>
<p>A possible workaround is to use a volume mount for the directory of the inner docker daemon's storage (<code>/var/lib/docker</code>). Then the inner docker daemon can use the host filesystem directly and can thus run <code>overlayfs2</code> on it.</p>
<p>Another workaround would be to create a loop device formatted as <code>ext4</code> which can then be used as the backing filesystem for the inner docker daemon. To avoid pre-allocating space on the disk, you can use a sparse file for the loop device. For example</p>
<pre><code>dd if=/dev/zero of=&quot;$image_file&quot; bs=1M count=0 seek=&quot;$sparse_loop_device_size_mb&quot;
mkfs.ext4 &quot;$image_file&quot;
mount -n -o loop,noatime,nodiratime,noexec,noauto &quot;$image_file&quot; /var/lib/docker
</code></pre>
<p>(The size of the loop device here is the maximum size, not the initial size)</p>
<p>Note however that docker recommends that write-heavy containers should not use the container's writeable layer due to performance reasons. So it is anyway advisable to use a volume mount for the docker daemon directory.</p>
<h3>Image cache</h3>
<p>Another typical issue is the cache of docker builds or of docker pulls within docker-in-docker. If you spin up docker-in-docker daemon for a build every time, it will have zero cache. Or if you spin up a docker-in-docker daemon for an integration test, you will have to pull down everything all over again. This is obvious when you think about it, but it can be a key performance issue if not taken into account. There is currently no easy way to share cache between the host docker daemon and the docker-in-docker.</p>
<p>However, you may be able to mount a volume for the docker dir (<code>/var/lib/docker</code>), to use it across multiple runs. Just make sure you never mount it to two docker daemons at the same time as that's an easy way to get unpredictable behavior due to corruption. The docker dir was not designed to be accessed by more than one daemon concurrently.</p>
<h3>Performance</h3>
<p>I have seen no evidence in the community of any significant performance impact of using docker-in-docker (aside from the storage driver and cache considerations mentioned above).</p>
<h3>Security</h3>
<p>Docker-in-docker requires privileged mode, which can be an additional attack vector. There is ongoing work to support docker-in-docker in rootless mode, including using a fuse variant of <code>overlayfs</code>. This is less mature however.</p>
<h3>Workaround: Mounting docker.sock</h3>
<p>There is, of course, the possibility of mounting <code>/var/run/docker.sock</code> within a container and you can use the docker CLI within that container. This is not a real docker-in-docker, as the container merely uses a client to connect to the host's docker daemon. It is however a popular, hassle-free option for certain use cases. This is far easier to achieve, if your circumstances permit.</p>
",23381,2020-07-31T22:43:25.040,"['dd if=/dev/zero of=""$image_file"" bs=1M count=0 seek=""$sparse_loop_device_size_mb""\nmkfs.ext4 ""$image_file""\nmount -n -o loop,noatime,nodiratime,noexec,noauto ""$image_file"" /var/lib/docker\n']"
1418,12132,12087,CC BY-SA 4.0,2020-08-03T22:44:21.240,"<p>Following the documentation a <code>map</code> is a collection of key/values with a constraint:</p>
<blockquote>
<p>&quot;...accepts any element type as long as every element is the same type&quot; <a href=""https://www.terraform.io/docs/configuration/types.html#map-"" rel=""nofollow noreferrer"">source</a></p>
</blockquote>
<p>So the input map you have declared, is already an invalid map for Terraform 0.12 (at least)</p>
<p>Below the example of the error produced:</p>
<pre><code>variable &quot;cidrs&quot; {
  description = &quot;&quot;
  type        = map
  default = [
    [&quot;1.1.1.1&quot;],
    [&quot;2.2.2.2&quot;, &quot;3.3.3.3&quot;],
    {
      C = [&quot;4.4.4.4&quot;]
      D = [&quot;5.5.5.5&quot;]
    }]
}
</code></pre>
<p>When validating an error is raised:</p>
<pre><code>$&gt; terraform validate

Error: Invalid default value for variable

  on vars.tf line 65, in variable &quot;cidrs&quot;:
  65:   default = [
  66:     [&quot;1.1.1.1&quot;],
  67:     [&quot;2.2.2.2&quot;, &quot;3.3.3.3&quot;],
  68:     {
  69:       C = [&quot;4.4.4.4&quot;]
  70:       D = [&quot;5.5.5.5&quot;]
  71:     }]

This default value is not compatible with the variable's type constraint: map
of any single type required.
</code></pre>
<p>Been that said, if we can generalize A and B as &quot;values which are lists&quot; and Group1 as &quot;values which are maps&quot; and the input is a fixed type ordered we can use a <em><a href=""https://www.terraform.io/docs/configuration/types.html#tuple-"" rel=""nofollow noreferrer"">tuple</a></em> or  an <em><a href=""https://www.terraform.io/docs/configuration/types.html#object-"" rel=""nofollow noreferrer"">object</a></em>, this can be solve in a more readable (and maintainable) way. If so, let us know so we can extend this answer.</p>
",23415,2020-08-06T16:08:01.087,"['variable ""cidrs"" {\n  description = """"\n  type        = map\n  default = [\n    [""1.1.1.1""],\n    [""2.2.2.2"", ""3.3.3.3""],\n    {\n      C = [""4.4.4.4""]\n      D = [""5.5.5.5""]\n    }]\n}\n', '$> terraform validate\n\nError: Invalid default value for variable\n\n  on vars.tf line 65, in variable ""cidrs"":\n  65:   default = [\n  66:     [""1.1.1.1""],\n  67:     [""2.2.2.2"", ""3.3.3.3""],\n  68:     {\n  69:       C = [""4.4.4.4""]\n  70:       D = [""5.5.5.5""]\n  71:     }]\n\nThis default value is not compatible with the variable\'s type constraint: map\nof any single type required.\n']"
1419,12135,12129,CC BY-SA 4.0,2020-08-04T06:57:47.753,"<p>It appears the issue is in the URL used to access the documents in the blog post excerpt. First of all, the URL should begin with a <code>/</code> since the <code>assets</code> folder is at the root of the site project. However (and most importantly), I also had to add the <code>baseurl</code> to the file URL as shown below:</p>
<p>blog post excerpt:</p>
<pre><code>&lt;ul style=&quot;list-style-type:none&quot;&gt;
    {% for duck in ducks %}
        &lt;h2&gt;{{ duck.name }}&lt;/h2&gt;
        &lt;li&gt;&lt;a href=&quot;/{{ baseurl }}/assets/v{{ version }}/{{ duck.url }}&quot;&gt;View&lt;/a&gt; | &lt;a href=&quot;/{{ baseurl }}/assets/v{{ version }}/{{ duck.url }}&quot; download&gt;Download&lt;/a&gt;&lt;/li&gt;
    {% endfor %}
&lt;/ul&gt;
</code></pre>
<p>If I weren't building my post entries from a template the link would actually be <code>/{{ site.baseurl }}/assets/v{{ version }}/{{ duck.url }}</code>, but Jinja does not understand the <code>site.baseurl</code> object when rendering the template. To bypass this, I read the value of the predefined GitLab <code>CI_PROJECT_PATH</code> variable and pass it to the template under the name <code>baseurl</code> when rendering.</p>
",11278,2020-08-04T06:57:47.753,"['<ul style=""list-style-type:none"">\n    {% for duck in ducks %}\n        <h2>{{ duck.name }}</h2>\n        <li><a href=""/{{ baseurl }}/assets/v{{ version }}/{{ duck.url }}"">View</a> | <a href=""/{{ baseurl }}/assets/v{{ version }}/{{ duck.url }}"" download>Download</a></li>\n    {% endfor %}\n</ul>\n']"
1420,12142,12130,CC BY-SA 4.0,2020-08-04T13:12:19.777,"<p>Since I do not currently have access to a server with Centos installed, I tested my soultion on Ubuntu 20.04. That being said, the whole point of using Docker is to make applications distribution-agnostic, so it should work on Centos as well.</p>
<p>You're getting an <code>image does not exist</code> error, because the image you specified does not, in fact, exist. There is a typo in one line of the README file provided on Docker Hub and you happened to use that line when writing your Compose file.</p>
<p>That being said, incorect image name is not your only issue. You have not specified a volume for your Bitbucket installation, meaning all of your data will be lost if the container is destroyed. Furthermore, the only way to backup a dockerized Bitbucket installation is to use method described <a href=""https://confluence.atlassian.com/display/BitbucketServer/Using+Bitbucket+Server+DIY+Backup"" rel=""nofollow noreferrer"">here</a>, which requires using external database.</p>
<p>With that in mind the minimal Compose file for Bitbucket is:</p>
<pre><code>version: '3.3'
services:
  bitbucket:
    hostname: bitbucket
    image: atlassian/bitbucket-server:latest
    environment:
     - JDBC_DRIVER=org.postgresql.Driver
     - JDBC_USER=bitbucketuser
     - JDBC_PASSWORD=jellyfish
     - JDBC_URL=jdbc:postgresql://db:5432/bitbucket
    volumes:
      - bitbucket_data:/var/atlassian/application-data/bitbucket
    ports:
      - 7990:7990
      - 7999:7999
    depends_on:
      - db
  db:
    hostname: db
    image: postgres:11.2-alpine
    command: -c 'max_prepared_transactions=64'
    environment:
     - POSTGRES_USER=bitbucketuser
     - POSTGRES_PASSWORD=jellyfish
     - POSTGRES_DB=bitbucket
    volumes:
     - db_data:/var/lib/postgresql/data  
volumes:
  bitbucket_data:
  db_data:
</code></pre>
<p>That can be further extended with httpd or nginx service used as a reverse proxy, which could also be used to enable HTTPS connections to your Bitbucket instance and an Elasticsearch service to replace the embedded one as well as an email server for Bitbucket to use to send various notifications to users.</p>
<p>I would definitely recommend the SSL-enabled reverse proxy and email server for production. Elasticsearch server is only necessary if you want to run Bitbucket cluster rather than a single instance.</p>
",12864,2020-08-04T13:25:10.080,"[""version: '3.3'\nservices:\n  bitbucket:\n    hostname: bitbucket\n    image: atlassian/bitbucket-server:latest\n    environment:\n     - JDBC_DRIVER=org.postgresql.Driver\n     - JDBC_USER=bitbucketuser\n     - JDBC_PASSWORD=jellyfish\n     - JDBC_URL=jdbc:postgresql://db:5432/bitbucket\n    volumes:\n      - bitbucket_data:/var/atlassian/application-data/bitbucket\n    ports:\n      - 7990:7990\n      - 7999:7999\n    depends_on:\n      - db\n  db:\n    hostname: db\n    image: postgres:11.2-alpine\n    command: -c 'max_prepared_transactions=64'\n    environment:\n     - POSTGRES_USER=bitbucketuser\n     - POSTGRES_PASSWORD=jellyfish\n     - POSTGRES_DB=bitbucket\n    volumes:\n     - db_data:/var/lib/postgresql/data  \nvolumes:\n  bitbucket_data:\n  db_data:\n""]"
1421,12143,12103,CC BY-SA 4.0,2020-08-04T14:41:02.283,"<p>I switched to using a production build for testing by use of a local webserver. I leveraging the <code>[jest-puppeteer][1]</code> library which allows you to start a webserver with your tests.</p>
<p><strong>jest-puppeteer.config.js</strong></p>
<pre><code>/**
 * find all flags at the following site @jkr
 * https://jestjs.io/docs/en/cli
 */

module.exports = {
    launch: {
        devtools: true, // allows for use of 'debugger;' in tests
        // executablePath: '/usr/bin/chromium-browser',
        headless: true,
        defaultViewport: {
            width: 1024,
            height: 768,
            //isMobile: true,
            //hasTouch: true,
        },
        ignoreDefaultArgs: ['--disable-extensions'],
        args: [
            '--enable-font-antialiasing',
            '--font-render-hinting=medium',
            '--disable-gpu',
            '--disable-dev-shm-usage',
            '--disable-setuid-sandbox',
            '--no-first-run',
            '--no-sandbox', // GOOD
            '--no-zygote',
            '--single-process', // GOOD

            &quot;--renderer&quot;,
            &quot;--no-service-autorun&quot;,
            &quot;--no-experiments&quot;,
            &quot;--no-default-browser-check&quot;,
            &quot;--disable-extensions&quot;,
        ]
    },
    server: { // launches webserver just for tests @jkr
        command: 'npm run test:webserver'
        // cd build &amp;&amp; ../node_modules/local-web-server/bin/cli.js --port 3000 --spa index.html
    },
    browser: 'chromium',
    browserContext: 'default'
};
</code></pre>
<p><strong>.gitlab-ci.yml</strong></p>
<pre><code>image: node:10.19.0 # https://hub.docker.com/_/node/
# image: node:latest

cache:
  # untracked: true
  key: my-project-name
  # key: ${CI_COMMIT_REF_SLUG} # per branch
  # key:
  #   files:
  #     - package-lock.json # only update cache when this file changes (not working) @jkr
  paths:
    - .npm/
    - node_modules
    - build

stages:
  - prepare # can install ci-deps here ? @jkr
  - test # uses test:build specifically @jkr
  - build
  - deploy

# before_install:

before_script:
  - npm ci --cache .npm --prefer-offline #
#   # - apt-get update &amp;&amp; apt-get install -y lftp gconf-service libasound2 libatk1.0-0 libatk-bridge2.0-0 libc6 libcairo2 libcups2 libdbus-1-3 libexpat1 libfontconfig1 libgcc1 libgconf-2-4 libgdk-pixbuf2.0-0 libglib2.0-0 libgtk-3-0 libnspr4 libpango-1.0-0 libpangocairo-1.0-0 libstdc++6 libx11-6 libx11-xcb1 libxcb1 libxcomposite1 libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 libxrandr2 libxrender1 libxss1 libxtst6 ca-certificates fonts-liberation libappindicator1 libnss3 lsb-release xdg-utils wget
#   - if [ ! -d &quot;node_modules&quot; ]; then set NODE_ENV=dev &amp;&amp; npm install; fi # make sure dev dependencies are installed todo: 'if' needs to be verified working @jkr
#   # - npm install
#   # - if [ ! -d &quot;build&quot; ]; then npm run build; fi

prepare: # could this job be in a before_script for test ? @jkr
  stage: prepare
  script:
    - npm install
    - npm run build:test
  # cache:
  #   paths:
  #     - node_modules
  #   policy: push

test:
  stage: test
  script:
    - npm run test:ci-deps
    - npm run test:e2e # runs puppeteer tests @jkr

build:
  stage: build
  script:
    - npm run build
  # artifacts:
  #   paths:
  #     - build

deploy-ftp:
  stage: deploy
  script:
    - lftp -e &quot;open ftp.my.domain.com; user $MJA_FTP_USER $MJA_FTP_PASS; mirror --reverse --verbose build/ /var/www/domains/dev/projects/my-project/build/; bye&quot;
  environment:
    name: staging
    url: http://my.domain.com/my-project/build
  when: manual
  only:
    - dev
</code></pre>
",23358,2020-08-06T20:47:05.343,"['/**\n * find all flags at the following site @jkr\n * https://jestjs.io/docs/en/cli\n */\n\nmodule.exports = {\n    launch: {\n        devtools: true, // allows for use of \'debugger;\' in tests\n        // executablePath: \'/usr/bin/chromium-browser\',\n        headless: true,\n        defaultViewport: {\n            width: 1024,\n            height: 768,\n            //isMobile: true,\n            //hasTouch: true,\n        },\n        ignoreDefaultArgs: [\'--disable-extensions\'],\n        args: [\n            \'--enable-font-antialiasing\',\n            \'--font-render-hinting=medium\',\n            \'--disable-gpu\',\n            \'--disable-dev-shm-usage\',\n            \'--disable-setuid-sandbox\',\n            \'--no-first-run\',\n            \'--no-sandbox\', // GOOD\n            \'--no-zygote\',\n            \'--single-process\', // GOOD\n\n            ""--renderer"",\n            ""--no-service-autorun"",\n            ""--no-experiments"",\n            ""--no-default-browser-check"",\n            ""--disable-extensions"",\n        ]\n    },\n    server: { // launches webserver just for tests @jkr\n        command: \'npm run test:webserver\'\n        // cd build && ../node_modules/local-web-server/bin/cli.js --port 3000 --spa index.html\n    },\n    browser: \'chromium\',\n    browserContext: \'default\'\n};\n', 'image: node:10.19.0 # https://hub.docker.com/_/node/\n# image: node:latest\n\ncache:\n  # untracked: true\n  key: my-project-name\n  # key: ${CI_COMMIT_REF_SLUG} # per branch\n  # key:\n  #   files:\n  #     - package-lock.json # only update cache when this file changes (not working) @jkr\n  paths:\n    - .npm/\n    - node_modules\n    - build\n\nstages:\n  - prepare # can install ci-deps here ? @jkr\n  - test # uses test:build specifically @jkr\n  - build\n  - deploy\n\n# before_install:\n\nbefore_script:\n  - npm ci --cache .npm --prefer-offline #\n#   # - apt-get update && apt-get install -y lftp gconf-service libasound2 libatk1.0-0 libatk-bridge2.0-0 libc6 libcairo2 libcups2 libdbus-1-3 libexpat1 libfontconfig1 libgcc1 libgconf-2-4 libgdk-pixbuf2.0-0 libglib2.0-0 libgtk-3-0 libnspr4 libpango-1.0-0 libpangocairo-1.0-0 libstdc++6 libx11-6 libx11-xcb1 libxcb1 libxcomposite1 libxcursor1 libxdamage1 libxext6 libxfixes3 libxi6 libxrandr2 libxrender1 libxss1 libxtst6 ca-certificates fonts-liberation libappindicator1 libnss3 lsb-release xdg-utils wget\n#   - if [ ! -d ""node_modules"" ]; then set NODE_ENV=dev && npm install; fi # make sure dev dependencies are installed todo: \'if\' needs to be verified working @jkr\n#   # - npm install\n#   # - if [ ! -d ""build"" ]; then npm run build; fi\n\nprepare: # could this job be in a before_script for test ? @jkr\n  stage: prepare\n  script:\n    - npm install\n    - npm run build:test\n  # cache:\n  #   paths:\n  #     - node_modules\n  #   policy: push\n\ntest:\n  stage: test\n  script:\n    - npm run test:ci-deps\n    - npm run test:e2e # runs puppeteer tests @jkr\n\nbuild:\n  stage: build\n  script:\n    - npm run build\n  # artifacts:\n  #   paths:\n  #     - build\n\ndeploy-ftp:\n  stage: deploy\n  script:\n    - lftp -e ""open ftp.my.domain.com; user $MJA_FTP_USER $MJA_FTP_PASS; mirror --reverse --verbose build/ /var/www/domains/dev/projects/my-project/build/; bye""\n  environment:\n    name: staging\n    url: http://my.domain.com/my-project/build\n  when: manual\n  only:\n    - dev\n']"
1422,12154,12136,CC BY-SA 4.0,2020-08-05T10:07:48.937,"<p>you should minimize the Layers of an Image for following Reasons:</p>
<ul>
<li>first, you can only have (afaik) 127 Layers in an Image.</li>
<li>second: yes, you should include severals Steps in a Single run because of the Copy-On-Write functionality:</li>
</ul>
<p>if you run:</p>
<pre><code>RUN dd if=/dev/zero of=output.dat  bs=1M  count=10
RUN rm -rf output.dat
</code></pre>
<p>your image is still 10MB (plus some bytes for the delete Marker)</p>
<p>instead, you should run:</p>
<pre><code>RUN dd if=/dev/zero of=output.dat  bs=1M  count=10 &amp;&amp;\
    rm -rf output.dat 
</code></pre>
<p>then, your image size is not increasing.</p>
<p>surely, this is not the Usual Use-Case, but, for example from a Real-World-Example:</p>
<pre><code># install terraform
ENV TF_VERSION=&quot;0.12.16&quot;
RUN curl -LO https://releases.hashicorp.com/terraform/${TF_VERSION}/terraform_${TF_VERSION}_linux_amd64.zip \
  &amp;&amp; unzip terraform_${TF_VERSION}_linux_amd64.zip \
  &amp;&amp; chmod +x ./terraform \
  &amp;&amp; mv ./terraform /usr/local/bin/terraform \
  &amp;&amp; rm terraform_${TF_VERSION}_linux_amd64.zip
</code></pre>
<p>more informations here: <a href=""https://docs.docker.com/storage/storagedriver/#the-copy-on-write-cow-strategy"" rel=""nofollow noreferrer"">https://docs.docker.com/storage/storagedriver/#the-copy-on-write-cow-strategy</a></p>
",23448,2020-08-05T10:07:48.937,"['RUN dd if=/dev/zero of=output.dat  bs=1M  count=10\nRUN rm -rf output.dat\n', 'RUN dd if=/dev/zero of=output.dat  bs=1M  count=10 &&\\\n    rm -rf output.dat \n', '# install terraform\nENV TF_VERSION=""0.12.16""\nRUN curl -LO https://releases.hashicorp.com/terraform/${TF_VERSION}/terraform_${TF_VERSION}_linux_amd64.zip \\\n  && unzip terraform_${TF_VERSION}_linux_amd64.zip \\\n  && chmod +x ./terraform \\\n  && mv ./terraform /usr/local/bin/terraform \\\n  && rm terraform_${TF_VERSION}_linux_amd64.zip\n']"
1423,12179,11685,CC BY-SA 4.0,2020-08-09T13:46:49.440,"<p>If the input string is failing due to folders with spaces not having quotes around them, try adding quotes around every object.</p>
<p>The InpFolderList already adds end quotes:</p>
<p><code>InpFoldersList=&quot;\&quot;$inpFoldersList&quot;\&quot;</code></p>
<p>Add the quotes around every object.</p>
<p><strong>groovy:</strong></p>
<pre><code>class Example { 
   static void main(String[] args) { 
        String FolderList = &quot;test1,test2,test3,Folder name1,Folder name2,Folder name3&quot;;
        println(FolderList.replaceAll(&quot;,&quot;,&quot;\&quot;,\&quot;&quot;));
   } 
}
</code></pre>
<p><strong>Output:</strong> (End quotes are left off)</p>
<p><code>test1&quot;,&quot;test2&quot;,&quot;test3&quot;,&quot;Folder name1&quot;,&quot;Folder name2&quot;,&quot;Folder name3</code></p>
<p><strong>Test Code:</strong> <a href=""https://www.jdoodle.com/execute-groovy-online/"" rel=""nofollow noreferrer"">https://www.jdoodle.com/execute-groovy-online/</a> (Copy / Paste Code and Execute)</p>
<p>Using above as an example, you could also add the end quotes and have a complete String variable to pass as $InpFoldersList, which would remove confusion if attempting to debug.</p>
<p><strong>Reference:</strong> <a href=""http://docs.groovy-lang.org/latest/html/api/org/codehaus/groovy/runtime/StringGroovyMethods.html#replaceAll(java.lang.CharSequence,java.util.regex.Pattern,java.lang.CharSequence)"" rel=""nofollow noreferrer"">http://docs.groovy-lang.org/latest/html/api/org/codehaus/groovy/runtime/StringGroovyMethods.html#replaceAll(java.lang.CharSequence,java.util.regex.Pattern,java.lang.CharSequence)</a></p>
",15016,2020-08-09T13:46:49.440,"['class Example { \n   static void main(String[] args) { \n        String FolderList = ""test1,test2,test3,Folder name1,Folder name2,Folder name3"";\n        println(FolderList.replaceAll("","",""\\"",\\""""));\n   } \n}\n']"
1424,12186,1473,CC BY-SA 4.0,2020-08-10T18:17:19.290,"<p>Alternative solution. Use the <code>parallel</code> pipeline step to run your foreground and background processes as equal partners in, well, parallel.</p>
<p>One advantage is that you have easy access to the stdout of the background process in the Blue Ocean UI.</p>
<pre><code>stage(&quot;Run&quot;) {
    parallel {
        stage('k3s') {
            steps {
                sh 'sudo /home/jenkins/k3s server --write-kubeconfig-mode 664 &amp; echo $! &gt; $WORKSPACE/k3s.pid; wait -n $(cat $WORKSPACE/k3s.pid) || true'
            }
        }
        stage('test') {
            steps {
                sh 'sleep 1; ps -p $(cat $WORKSPACE/k3s.pid)'
                sh 'while ! /home/jenkins/k3s kubectl get node; do sleep 1; done'
            }
            post {
                always {
                    sh 'while ps -p $(cat $WORKSPACE/k3s.pid); do sudo kill -9 $(cat $WORKSPACE/k3s.pid); sleep 5; done'
                }
            }
        }
    }
}
</code></pre>
",23214,2020-08-10T18:57:02.670,"['stage(""Run"") {\n    parallel {\n        stage(\'k3s\') {\n            steps {\n                sh \'sudo /home/jenkins/k3s server --write-kubeconfig-mode 664 & echo $! > $WORKSPACE/k3s.pid; wait -n $(cat $WORKSPACE/k3s.pid) || true\'\n            }\n        }\n        stage(\'test\') {\n            steps {\n                sh \'sleep 1; ps -p $(cat $WORKSPACE/k3s.pid)\'\n                sh \'while ! /home/jenkins/k3s kubectl get node; do sleep 1; done\'\n            }\n            post {\n                always {\n                    sh \'while ps -p $(cat $WORKSPACE/k3s.pid); do sudo kill -9 $(cat $WORKSPACE/k3s.pid); sleep 5; done\'\n                }\n            }\n        }\n    }\n}\n']"
1425,12188,8629,CC BY-SA 4.0,2020-08-11T04:13:11.830,"<p>More options like this.</p>
<pre><code>integration-testing:
  stage: test
  only:
    refs:
      - master
      - /release-.+/
</code></pre>
<p>Complete documentation can be found at <a href=""https://docs.gitlab.com/ee/ci/yaml/#onlyexcept-advanced"" rel=""nofollow noreferrer"">gitlab doc</a></p>
",22321,2020-08-11T04:13:11.830,['integration-testing:\n  stage: test\n  only:\n    refs:\n      - master\n      - /release-.+/\n']
1426,12195,12194,CC BY-SA 4.0,2020-08-12T06:08:21.977,"<p>You're using two different host names:</p>
<pre><code>$ rdcli -h dbbackupd.default.cluster.local
$ host dbbackupd.default.svc.cluster.local
</code></pre>
<p>The one used with <code>rdcli</code> is missing <code>.svc</code>.</p>
",349,2020-08-12T06:08:21.977,['$ rdcli -h dbbackupd.default.cluster.local\n$ host dbbackupd.default.svc.cluster.local\n']
1427,12200,12092,CC BY-SA 4.0,2020-08-12T18:13:15.080,"<p>You could use the command <code>rabbitmq-diagnostics -q ping</code> in case you just need a basic check.</p>
<pre><code>healthcheck:
  test: rabbitmq-diagnostics -q ping
  interval: 30s
  timeout: 30s
  retries: 3
</code></pre>
<p>More information on how to run more advanced health checks could be found <a href=""https://www.rabbitmq.com/monitoring.html#health-checks"" rel=""nofollow noreferrer"">here</a></p>
",23542,2020-08-12T18:13:15.080,['healthcheck:\n  test: rabbitmq-diagnostics -q ping\n  interval: 30s\n  timeout: 30s\n  retries: 3\n']
1428,12211,12209,CC BY-SA 4.0,2020-08-14T14:23:47.277,"<p>Found the issue, had:</p>
<pre><code>kubectl -n jenkins patch serviceaccount jenkins -p '{&quot;imagePullSecrets&quot;: [{&quot;name&quot;: &quot;gcr-json-key&quot;}]}' 
</code></pre>
<p>... applied on <code>default</code> serviceaccount instead of <code>jenkins</code>.</p>
",17329,2020-09-14T09:28:44.837,"['kubectl -n jenkins patch serviceaccount jenkins -p \'{""imagePullSecrets"": [{""name"": ""gcr-json-key""}]}\' \n']"
1429,12215,12213,CC BY-SA 4.0,2020-08-15T15:13:10.283,"<p>This is done using one of the configuration options. For a general overview of configuring Ansible, see <a href=""https://docs.ansible.com/ansible/latest/reference_appendices/config.html"" rel=""nofollow noreferrer"">the configuration documentation</a>, in particular the <a href=""https://docs.ansible.com/ansible/latest/plugins/callback.html"" rel=""nofollow noreferrer"">callback plugin configuration</a>.</p>
<p>Callback plugins change how Ansible provides feedback on the progress and state of tasks. There are several options for JSON output:</p>
<ol>
<li><a href=""https://docs.ansible.com/ansible/latest/plugins/callback/json.html"" rel=""nofollow noreferrer"">JSON output to stdout</a></li>
<li><a href=""https://docs.ansible.com/ansible/latest/plugins/callback/syslog_json.html"" rel=""nofollow noreferrer"">JSON to syslog</a></li>
</ol>
<p>Setting these configuration options can be done either in a configuration file (<code>ansible.cfg</code>) or with environment variables (<code>ANSIBLE_XXX</code>), depending on what you prefer.
To quote the current documentation:</p>
<blockquote>
<p>Changes can be made and used in a configuration file which will be searched for in the following order:</p>
</blockquote>
<blockquote>
<pre><code>   ANSIBLE_CONFIG (environment variable if set)
   ansible.cfg (in the current directory)
   ~/.ansible.cfg (in the home directory)
   /etc/ansible/ansible.cfg
</code></pre>
</blockquote>
<blockquote>
<p>Ansible will process the above list and use the first file found, all others are ignored.</p>
</blockquote>
<p>Assuming you want to send the output to stdout then, your <code>ansible.cfg</code> could look like:</p>
<pre><code>[defaults]
callback_whitelist=json
stdout_callback=json
</code></pre>
<p>Using environment variables:</p>
<pre><code> ANSIBLE_CALLBACK_WHITELIST=json ANSIBLE_STDOUT_CALLBACK=json ansible-playbook ...
</code></pre>
",354,2020-08-15T15:13:10.283,"['   ANSIBLE_CONFIG (environment variable if set)\n   ansible.cfg (in the current directory)\n   ~/.ansible.cfg (in the home directory)\n   /etc/ansible/ansible.cfg\n', '[defaults]\ncallback_whitelist=json\nstdout_callback=json\n', ' ANSIBLE_CALLBACK_WHITELIST=json ANSIBLE_STDOUT_CALLBACK=json ansible-playbook ...\n']"
1430,12218,12217,CC BY-SA 4.0,2020-08-16T09:21:27.037,"<p>A few initial comments for posterity:</p>
<ol>
<li>You can check exactly what the control is asserting by looking at <a href=""https://github.com/dev-sec/linux-baseline/blob/master/controls/os_spec.rb"" rel=""nofollow noreferrer"">the source code</a></li>
<li>You can see what the remediation should be, by checking Dev-Sec's <a href=""https://github.com/dev-sec/ansible-os-hardening"" rel=""nofollow noreferrer"">Ansible role</a></li>
<li>Most of your issues seem to be related to missing or incorrect input variables. See <a href=""https://docs.chef.io/inspec/inputs/"" rel=""nofollow noreferrer"">the Inspec documentation on that topic</a></li>
</ol>
<p>The specific issues you raise:</p>
<h2>Check login.defs (4 failed)</h2>
<p>This comes from the control <code>os-5</code>:</p>
<pre><code>control 'os-05' do
  impact 1.0
  title 'Check login.defs'
  desc 'Check owner and permissions for login.defs. Also check the configured PATH variable and umask in login.defs'
  describe file('/etc/login.defs') do
    it { should exist }
    it { should be_file }
    it { should be_owned_by 'root' }
    its('group') { should eq 'root' }
    it { should_not be_executable }
    it { should be_readable.by('owner') }
    it { should be_readable.by('group') }
    it { should be_readable.by('other') }
  end
  describe login_defs do
    its('ENV_SUPATH') { should include('/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin') }
    its('ENV_PATH') { should include('/usr/local/bin:/usr/bin:/bin') }
    its('UMASK') { should include(login_defs_umask) }
    its('PASS_MAX_DAYS') { should eq login_defs_passmaxdays }
    its('PASS_MIN_DAYS') { should eq login_defs_passmindays }
    its('PASS_WARN_AGE') { should eq login_defs_passwarnage }
    its('LOGIN_RETRIES') { should eq '5' }
    its('LOGIN_TIMEOUT') { should eq '60' }
    its('UID_MIN') { should eq '1000' }
    its('GID_MIN') { should eq '1000' }
  end
end
</code></pre>
<p>The specific assertions that are failing are related to:</p>
<ul>
<li>umask</li>
<li>password age (min/max days, warning)</li>
</ul>
<p>These use attributes (ie, Inspec input values), which are read <a href=""https://github.com/dev-sec/linux-baseline/blob/aa5adfa85966a9707aa03aef8a2ece0ce75dce04/controls/os_spec.rb#L20"" rel=""nofollow noreferrer"">higher up in the control</a>:</p>
<pre><code>login_defs_umask = attribute('login_defs_umask', value: os.redhat? ? '077' : '027', description: 'Default umask to set in login.defs')

login_defs_passmaxdays = attribute('login_defs_passmaxdays', value: '60', description: 'Default password maxdays to set in login.defs')
login_defs_passmindays = attribute('login_defs_passmindays', value: '7', description: 'Default password mindays to set in login.defs')
login_defs_passwarnage = attribute('login_defs_passwarnage', value: '7', description: 'Default password warnage (days) to set in login.defs')
</code></pre>
<p>The error you are getting:</p>
<pre><code>login.defs UMASK should include #&lt;Inspec::Attribute::DEFAULT_ATTRIBUTE:0x00000005a1ea00 @name=&quot;login_defs_umask&quot;&gt;
     can't convert Inspec::Attribute::DEFAULT_ATTRIBUTE to String (Inspec::Attribute::DEFAULT_ATTRIBUTE#to_str gives Inspec::Attribute::DEFAULT_ATTRIBUTE)
</code></pre>
<p>should be expected, given the previous warning Inspec told you:</p>
<pre><code>WARN: Attribute 'login_defs_umask' does not have a value. Use --attrs to provide a value for 'login_defs_umask' or specify a default  value with `attribute('login_defs_umask', default: 'somedefault', ...)`
</code></pre>
<p>Either you have an old version of Inspec where the default is not set, or you passed a set of input variables where these values are not set.</p>
<h2>os-06: Check for SUID/ SGID blacklist</h2>
<p>This <a href=""https://github.com/dev-sec/linux-baseline/blob/aa5adfa85966a9707aa03aef8a2ece0ce75dce04/controls/os_spec.rb#L165"" rel=""nofollow noreferrer"">control</a> checks the <code>suid</code> of a blacklist. It uses a <a href=""https://docs.chef.io/inspec/dsl_resource/"" rel=""nofollow noreferrer"">custom resource</a> <a href=""https://github.com/dev-sec/linux-baseline/blob/master/libraries/suid_check.rb"" rel=""nofollow noreferrer""><code>suid_check</code></a>. It essentially find's files with certain characteristics:</p>
<pre><code>def permissions
    output = inspec.command('find / -perm -4000 -o -perm -2000 -type f ! -path \'/proc/*\' ! -path \'/var/lib/lxd/containers/*\' -print 2&gt;/dev/null | grep -v \'^find:\'')
    output.stdout.split(/\r?\n/)
end
</code></pre>
<p>Your diff fails because some files match the blacklist, which is again set as an attribute:</p>
<pre><code>blacklist = attribute(
  'blacklist',
  value: suid_blacklist.default,
  description: 'blacklist of suid/sgid program on system'
)
</code></pre>
<p>It's <a href=""https://github.com/dev-sec/linux-baseline/blob/master/libraries/suid_blacklist.rb"" rel=""nofollow noreferrer"">default</a> has a method <code>default</code> with a big list of paths. You can pass your own blacklist by setting it in an input file.</p>
<h2>sysctl-29: Disable loading kernel modules</h2>
<blockquote>
<p>I accidentally set echo &quot;1&quot; &gt; /proc/sys/kernel/modules_disabled and now I'm unable to set it back</p>
</blockquote>
<p>The <a href=""https://www.kernel.org/doc/html/v5.4/admin-guide/sysctl/kernel.html#modules-disabled"" rel=""nofollow noreferrer"">kernel documentation</a> says:</p>
<blockquote>
<p>Once true, modules can be neither loaded nor unloaded, and the toggle cannot be set back to false.</p>
</blockquote>
<p>You probably have to reboot the machine.</p>
<h2>package-07: Install syslog server package</h2>
<p>The <a href=""https://github.com/dev-sec/linux-baseline/blob/master/controls/package_spec.rb#L77"" rel=""nofollow noreferrer"">control</a> makes an assertion on a package:</p>
<pre><code>describe package(val_syslog_pkg) do
</code></pre>
<p>where <code>val_syslog_pkg</code> is an attribute passed as an input variable:</p>
<p><code>val_syslog_pkg = attribute('syslog_pkg', value: 'rsyslog', description: 'syslog package to ensure present (default: rsyslog, alternative: syslog-ng...')</code></p>
<p>In Ubuntu, this package name is <code>syslog-ng</code>.</p>
",354,2020-08-16T09:21:27.037,"[""control 'os-05' do\n  impact 1.0\n  title 'Check login.defs'\n  desc 'Check owner and permissions for login.defs. Also check the configured PATH variable and umask in login.defs'\n  describe file('/etc/login.defs') do\n    it { should exist }\n    it { should be_file }\n    it { should be_owned_by 'root' }\n    its('group') { should eq 'root' }\n    it { should_not be_executable }\n    it { should be_readable.by('owner') }\n    it { should be_readable.by('group') }\n    it { should be_readable.by('other') }\n  end\n  describe login_defs do\n    its('ENV_SUPATH') { should include('/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin') }\n    its('ENV_PATH') { should include('/usr/local/bin:/usr/bin:/bin') }\n    its('UMASK') { should include(login_defs_umask) }\n    its('PASS_MAX_DAYS') { should eq login_defs_passmaxdays }\n    its('PASS_MIN_DAYS') { should eq login_defs_passmindays }\n    its('PASS_WARN_AGE') { should eq login_defs_passwarnage }\n    its('LOGIN_RETRIES') { should eq '5' }\n    its('LOGIN_TIMEOUT') { should eq '60' }\n    its('UID_MIN') { should eq '1000' }\n    its('GID_MIN') { should eq '1000' }\n  end\nend\n"", ""login_defs_umask = attribute('login_defs_umask', value: os.redhat? ? '077' : '027', description: 'Default umask to set in login.defs')\n\nlogin_defs_passmaxdays = attribute('login_defs_passmaxdays', value: '60', description: 'Default password maxdays to set in login.defs')\nlogin_defs_passmindays = attribute('login_defs_passmindays', value: '7', description: 'Default password mindays to set in login.defs')\nlogin_defs_passwarnage = attribute('login_defs_passwarnage', value: '7', description: 'Default password warnage (days) to set in login.defs')\n"", 'login.defs UMASK should include #<Inspec::Attribute::DEFAULT_ATTRIBUTE:0x00000005a1ea00 @name=""login_defs_umask"">\n     can\'t convert Inspec::Attribute::DEFAULT_ATTRIBUTE to String (Inspec::Attribute::DEFAULT_ATTRIBUTE#to_str gives Inspec::Attribute::DEFAULT_ATTRIBUTE)\n', ""WARN: Attribute 'login_defs_umask' does not have a value. Use --attrs to provide a value for 'login_defs_umask' or specify a default  value with `attribute('login_defs_umask', default: 'somedefault', ...)`\n"", ""def permissions\n    output = inspec.command('find / -perm -4000 -o -perm -2000 -type f ! -path \\'/proc/*\\' ! -path \\'/var/lib/lxd/containers/*\\' -print 2>/dev/null | grep -v \\'^find:\\'')\n    output.stdout.split(/\\r?\\n/)\nend\n"", ""blacklist = attribute(\n  'blacklist',\n  value: suid_blacklist.default,\n  description: 'blacklist of suid/sgid program on system'\n)\n"", 'describe package(val_syslog_pkg) do\n']"
1431,12222,12101,CC BY-SA 4.0,2020-08-17T17:00:01.233,"<p>You can use docker secrets a bit differently using <code>docker-compose</code> without having to use swarm. <a href=""https://docs.docker.com/compose/compose-file/#secrets"" rel=""nofollow noreferrer"">See this</a> for the official documentation.</p>
<h1>Example:</h1>
<ol>
<li>Create a simple compose file like so,</li>
</ol>
<pre><code>version: &quot;3.7&quot;

services:

  db:
    image: mariadb:10.5.2
    env_file:
      - ./db.env
    secrets:
      - rootpass
      - dbpass
      - mysqldb
      - mysqluser
    restart: always
</code></pre>
<ol start=""2"">
<li>Now add the following in the end</li>
</ol>
<pre><code>secrets:
  rootpass:
    file: /tmp/root_pass
  dbpass:
    file: /tmp/db_pass
  mysqldb:
    file: /tmp/mysql_db
  mysqluser:
    file: /tmp/mysql_user
</code></pre>
<ol start=""3"">
<li>Inside those files, keep your password, username, database name etc. in plain text. Then simply deploy the containers <code>docker-compose up -d</code>.</li>
</ol>
<p>It's similar to how you define volumes and networks in a compose file.</p>
<p>Keep in mind that this isn't true secret implementation. Here's <a href=""https://github.com/docker/compose/pull/4368"" rel=""nofollow noreferrer"">the github PR</a> that added this feature, along with the <a href=""https://www.github.com/dnephin/compose/tree/8c4fc4bc2ed82648f7a6ab7e14a492368f997415/compose%2Fconfig%2Fconfig.py"" rel=""nofollow noreferrer"">main file</a> if you're interested.</p>
",,2020-08-17T17:00:01.233,"['version: ""3.7""\n\nservices:\n\n  db:\n    image: mariadb:10.5.2\n    env_file:\n      - ./db.env\n    secrets:\n      - rootpass\n      - dbpass\n      - mysqldb\n      - mysqluser\n    restart: always\n', 'secrets:\n  rootpass:\n    file: /tmp/root_pass\n  dbpass:\n    file: /tmp/db_pass\n  mysqldb:\n    file: /tmp/mysql_db\n  mysqluser:\n    file: /tmp/mysql_user\n']"
1432,12231,12228,CC BY-SA 4.0,2020-08-18T13:11:02.230,"<p>Found this solution:</p>
<pre><code>static_configs:
  - targets: ['monitoring.api.endpoint.net']
metric_relabel_configs:
- source_labels: [__name__]
  regex: '(.*)'
  replacement: 'compute_${1}'
  target_label: __name__      
</code></pre>
",12833,2020-08-18T13:11:02.230,"[""static_configs:\n  - targets: ['monitoring.api.endpoint.net']\nmetric_relabel_configs:\n- source_labels: [__name__]\n  regex: '(.*)'\n  replacement: 'compute_${1}'\n  target_label: __name__      \n""]"
1433,12234,12134,CC BY-SA 4.0,2020-08-18T14:13:59.990,"<p>Use the register module and store the result in a variable.</p>
<pre><code> - hosts: all
   tasks:
     - name: Ansible register variable basic example
       shell: &quot;find *.txt&quot;
       args:
         chdir: &quot;/Users/mdtutorials2/Documents/Ansible&quot;
       register: find_output

     - debug:
         var: find_output
</code></pre>
",17679,2020-08-18T14:13:59.990,"[' - hosts: all\n   tasks:\n     - name: Ansible register variable basic example\n       shell: ""find *.txt""\n       args:\n         chdir: ""/Users/mdtutorials2/Documents/Ansible""\n       register: find_output\n\n     - debug:\n         var: find_output\n']"
1434,12235,12134,CC BY-SA 4.0,2020-08-18T15:53:09.930,"<p>Set the log file to use inline or <a href=""https://docs.ansible.com/ansible/latest/reference_appendices/logging.html"" rel=""nofollow noreferrer"">in Ansible config</a>, then run ansible-playbook with verbose option:</p>
<pre><code>ANSIBLE_LOG_PATH=&quot;ansible-$(date +%Y%m%d%H%M%S).log&quot; \
ansible-playbook -vvvv \
    --diff \
    -i inventory/myinventory \
    myplaybook.yml
</code></pre>
<ul>
<li><code>ANSIBLE_LOG_PATH</code> - is an environment variable that <a href=""https://docs.ansible.com/ansible/latest/reference_appendices/config.html#envvar-ANSIBLE_LOG_PATH"" rel=""nofollow noreferrer"">maps</a> to the <code>log_path</code> configuration item. Sets the file to log to. When using an environment variable you can use shell substitution to add the date and time to the file name so the next run doesn't overwrite the log file.</li>
<li><code>-vvvv</code> - be very very very verbose. Will show SSH commands executed.</li>
<li><code>--diff</code> - bonus, when making a change show what has been done.</li>
<li>the rest are standard options.</li>
</ul>
<p>The log will be in a file in the current directory named something like <code>ansible-20200818155322.log</code></p>
",12305,2020-08-18T15:53:09.930,"['ANSIBLE_LOG_PATH=""ansible-$(date +%Y%m%d%H%M%S).log"" \\\nansible-playbook -vvvv \\\n    --diff \\\n    -i inventory/myinventory \\\n    myplaybook.yml\n']"
1435,12237,12226,CC BY-SA 4.0,2020-08-18T21:41:10.630,"<p>I image you have used the dockerExecutor in gitlab-runner. This means you try to use docker-in-docker.
<a href=""https://docs.gitlab.com/ee/ci/docker/using_docker_build.html"" rel=""nofollow noreferrer"">https://docs.gitlab.com/ee/ci/docker/using_docker_build.html</a></p>
<p>I suggest to configure the docker socket binding which might be less secure but very easy to handle.</p>
<p>To register a runner with docker-in-docker support mount the <code>/var/run/docker.sock:/var/run/docker.sock</code>
e.g.</p>
<pre><code>sudo gitlab-runner register -n \
  --url https://gitlab.com/ \
  --registration-token REGISTRATION_TOKEN \
  --executor docker \
  --description &quot;My Docker Runner&quot; \
  --docker-image &quot;docker:19.03.12&quot; \
  --docker-volumes /var/run/docker.sock:/var/run/docker.sock
</code></pre>
",16282,2020-08-18T21:41:10.630,"['sudo gitlab-runner register -n \\\n  --url https://gitlab.com/ \\\n  --registration-token REGISTRATION_TOKEN \\\n  --executor docker \\\n  --description ""My Docker Runner"" \\\n  --docker-image ""docker:19.03.12"" \\\n  --docker-volumes /var/run/docker.sock:/var/run/docker.sock\n']"
1436,12244,12243,CC BY-SA 4.0,2020-08-19T13:34:51.560,"<p>At first, I misread your question, thinking you wanted to run more than one service together, so I had recommended <a href=""https://docs.docker.com/compose"" rel=""nofollow noreferrer"">Docker Compose</a> which makes it easy to run multiple services together, with networking, and can even specify the start up order.</p>
<p>But now I see you are just trying to run MySQL, and wondering do you need separate containers for the OS and MySQL: in short, no you don't need two containers. Instead, just get the MySQL image from DockerHub at <a href=""https://hub.docker.com/_/mysql?tab=description"" rel=""nofollow noreferrer"">https://hub.docker.com/_/mysql?tab=description</a></p>
<p>The reason you can just use that MySQL Docker image by itself is because it already is installed on a Debian image, which you can see in the Dockerfile at <a href=""https://github.com/docker-library/mysql/blob/master/8.0/Dockerfile"" rel=""nofollow noreferrer"">https://github.com/docker-library/mysql/blob/master/8.0/Dockerfile</a> where it shows:</p>
<pre><code>FROM debian:buster-slim
</code></pre>
<p>So, to solve the problem, do:</p>
<ol>
<li><code>docker pull mysql</code></li>
<li><code>docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag</code> as mentioned in the instructions on the Docker Hub page. Additional documentation at <a href=""https://github.com/docker-library/docs/tree/master/mysql"" rel=""nofollow noreferrer"">https://github.com/docker-library/docs/tree/master/mysql</a></li>
</ol>
<p>I do strongly recommend using Docker Compose (<code>docker-compose</code> command) to run containers, as it makes it easier to organise and run them.</p>
",124,2020-08-20T03:18:02.023,['FROM debian:buster-slim\n']
1437,12248,12247,CC BY-SA 4.0,2020-08-20T06:28:08.687,"<p>You can add an alias IP address to the loopback interface on the host to get a consistent address to use from your containers.</p>
<p>Any private address you won't see on the local or container networks, something like 10.8.8.8</p>
<p>Edit <code>/etc/network/interfaces.d/lo</code> for a permanent address after reboot</p>
<pre><code>auto lo
iface lo inet loopback
iface lo inet static
  address 10.8.8.8/32
</code></pre>
<p>or to temporarily test</p>
<pre><code>ip address add 10.8.8.8/32 dev lo
</code></pre>
",15151,2020-08-20T21:59:24.960,"['auto lo\niface lo inet loopback\niface lo inet static\n  address 10.8.8.8/32\n', 'ip address add 10.8.8.8/32 dev lo\n']"
1438,12249,8167,CC BY-SA 4.0,2020-08-20T08:12:45.890,"<p>sometimes it happens when you apply Istio mTLS so first try to disable mTLS in the relevant namespace. (especially if you are using some kind of gRPC in the pod)</p>
<pre><code>kubectl get peerauthentication --all-namespaces

</code></pre>
",23625,2020-08-20T11:37:43.123,['kubectl get peerauthentication --all-namespaces\n\n']
1439,12257,12193,CC BY-SA 4.0,2020-08-23T11:14:08.347,"<p>Have you looked at the <a href=""https://plugins.jenkins.io/matrix-project/"" rel=""nofollow noreferrer"">Matrix project plugin</a>?</p>
<blockquote>
<p><strong>Multi-Configuration Projects</strong></p>
<p>A multi-configuration project is useful for instances where your
builds will make many similar build steps, and you would otherwise be
duplicating steps.</p>
<p><strong>Configuration matrix</strong></p>
<p>The Configuration Matrix allows you to specify what steps to
duplicate, and create a multiple-axis graph of the type of builds to
create.</p>
</blockquote>
<p><a href=""https://www.jenkins.io/blog/2019/11/22/welcome-to-the-matrix/"" rel=""nofollow noreferrer"">Welcome to the Matrix</a> is an excellent reference doc.</p>
<p>Example (from <a href=""https://www.jenkins.io/blog/2019/11/22/welcome-to-the-matrix/"" rel=""nofollow noreferrer"">the blog</a>) - Pipeline for multiple platforms and browsers</p>
<blockquote>
<pre><code>Jenkinsfile

pipeline {
    agent none
    stages {
        stage('BuildAndTest') {
            matrix {
                agent any
                axes {
                    axis {
                        name 'PLATFORM'
                        values 'linux', 'windows', 'mac'
                    }
                    axis {
                        name 'BROWSER'
                        values 'firefox', 'chrome', 'safari', 'edge'
                    }
                }
                stages {
                    stage('Build') {
                        steps {
                            echo &quot;Do Build for ${PLATFORM} - ${BROWSER}&quot;
                        }
                    }
                    stage('Test') {
                        steps {
                            echo &quot;Do Test for ${PLATFORM} - ${BROWSER}&quot;
                        }
                    }
                }
            }
        }
    }
}
</code></pre>
</blockquote>
",13379,2020-08-23T23:51:23.853,"['Jenkinsfile\n\npipeline {\n    agent none\n    stages {\n        stage(\'BuildAndTest\') {\n            matrix {\n                agent any\n                axes {\n                    axis {\n                        name \'PLATFORM\'\n                        values \'linux\', \'windows\', \'mac\'\n                    }\n                    axis {\n                        name \'BROWSER\'\n                        values \'firefox\', \'chrome\', \'safari\', \'edge\'\n                    }\n                }\n                stages {\n                    stage(\'Build\') {\n                        steps {\n                            echo ""Do Build for ${PLATFORM} - ${BROWSER}""\n                        }\n                    }\n                    stage(\'Test\') {\n                        steps {\n                            echo ""Do Test for ${PLATFORM} - ${BROWSER}""\n                        }\n                    }\n                }\n            }\n        }\n    }\n}\n']"
1440,12264,12263,CC BY-SA 4.0,2020-08-25T09:05:45.070,"<p>Yes your understanding is correct. The <code>RUN &lt;commands&gt;</code> command in the Dockerfile is somewhat equivalent to</p>
<pre><code>container = $(docker run base-image) #1
docker exec base-image commands #2 
docker commit $container #3
</code></pre>
<p>Since images are static, we'll need a running instance/process to execute our command. this is why a container is created from the base image. #1</p>
<p>After the execution of the command in #2, the changes are committed back #3, which means a new layer is created on top of the previous layers. This layer will contain the changes introduced by the container in (#2).</p>
",23680,2020-08-25T09:05:45.070,['container = $(docker run base-image) #1\ndocker exec base-image commands #2 \ndocker commit $container #3\n']
1441,12266,12247,CC BY-SA 4.0,2020-08-25T09:26:38.190,"<p>You can run your flask container using the host networking mode. This way docker won't isolate the container and will run it the same network namespace as the host, and you container will be able to discover your database using <code>localhost</code> as mongodb hostname</p>
<pre><code>docker run --network host &lt;flask-image&gt;
</code></pre>
",23680,2020-08-25T10:52:49.390,['docker run --network host <flask-image>\n']
1442,12271,12268,CC BY-SA 4.0,2020-08-25T18:48:17.960,"<p>The final image will have all the layers from <code>diamol/base</code> as well as two additional layers - one for COPY and one for RUN command.</p>
<p>File <code>/build.txt</code> will have the following contents:</p>
<pre><code>Building...
Testing...
Done...
</code></pre>
",12864,2020-08-25T18:48:17.960,['Building...\nTesting...\nDone...\n']
1443,12278,12267,CC BY-SA 4.0,2020-08-26T10:44:16.857,"<p>First of all, you don't need the COPY instructions or multiple RUN instructions if you have only one stage:</p>
<pre><code>FROM diamol/base AS build-stage
RUN echo 'Building...' &gt; /build.txt &amp;&amp; echo 'Testing...' &gt;&gt; /build.txt
CMD cat /build.txt
</code></pre>
<p>Of course, the textbook example is just that - an example to illustrate the concept.</p>
<p>In reality multistage builds are used to create smaller final images, while keeping the entire build process inside the container.</p>
<p>Generally speaking one may install all development and runtime dependencies in a build stage, then copy just the final distribution package to the final stage, where only runtime dependencies are installed to reduce the final image size.</p>
<p>For example:</p>
<pre><code>FROM ubuntu:latest AS base
RUN apt -y install some-library

FROM base AS build
RUN apt -y install some-library-dev
COPY . /src
WORKDIR /src
RUN make &amp;&amp; make install

FROM base
COPY --from=build /usr/bin/app /usr/bin/app
CMD /usr/bin/app
</code></pre>
",12864,2020-08-26T10:44:16.857,"[""FROM diamol/base AS build-stage\nRUN echo 'Building...' > /build.txt && echo 'Testing...' >> /build.txt\nCMD cat /build.txt\n"", 'FROM ubuntu:latest AS base\nRUN apt -y install some-library\n\nFROM base AS build\nRUN apt -y install some-library-dev\nCOPY . /src\nWORKDIR /src\nRUN make && make install\n\nFROM base\nCOPY --from=build /usr/bin/app /usr/bin/app\nCMD /usr/bin/app\n']"
1444,12298,12295,CC BY-SA 4.0,2020-08-28T21:27:14.880,"<p>If HTTP/2 is not working try forcing HTTP 1.1:</p>
<pre><code>COPY plugins.txt /usr/share/jenkins/ref/

ENV CURL_OPTIONS -sSfL --http1.1
ENV CURL_CONNECTION_TIMEOUT 60
RUN /usr/local/bin/install-plugins.sh &lt; /usr/share/jenkins/ref/plugins.txt
</code></pre>
",12864,2020-08-28T21:27:14.880,['COPY plugins.txt /usr/share/jenkins/ref/\n\nENV CURL_OPTIONS -sSfL --http1.1\nENV CURL_CONNECTION_TIMEOUT 60\nRUN /usr/local/bin/install-plugins.sh < /usr/share/jenkins/ref/plugins.txt\n']
1445,12300,12299,CC BY-SA 4.0,2020-08-29T14:35:05.353,"<p>The &quot;D&quot; in CI/CD means different things to different people, either delivery or deployment. For both groups, it rarely means release everything immediately to production. For the delivery group, the output of CI/CD is an artifact that <em>can</em> be deployed. For the deployment group, there are typically gates in pipelines with either automatic or manual checks before deployment happens. Automatic gates include the unit tests, CI tests, but also things like canary releases with monitoring of key metrics.</p>
<p>Manual approvals in Jenkins involve adding an <a href=""https://www.jenkins.io/doc/pipeline/steps/pipeline-input-step/"" rel=""nofollow noreferrer"">input step</a> to your pipeline. E.g.</p>
<pre><code>input([message: &quot;Ready to continue?&quot;])
</code></pre>
<p>In my experience, having various stalled pipelines waiting for user approval is fairly common. I often include timeouts to clear out stale prompts, and sometimes I configure old prompts to automatically cancel with a more recent pipeline is approved to reduce the workload on users. If you do the latter, you may want to have a separate pipeline for backout/revert jobs since that would otherwise being a new job that gets promoted to production in an emergency and aborts all the other work in progress.</p>
<p>I still like to separate my builds from deploys with separate pipelines. It gives developers better feedback with their CI pipelines of what's working. Then the deployment team picks from a list of automatically queued up deployment jobs that were automatically triggered from those successful CI jobs.</p>
",7730,2020-08-29T14:35:05.353,"['input([message: ""Ready to continue?""])\n']"
1446,12304,12303,CC BY-SA 4.0,2020-08-30T05:50:15.330,"<p>it seems you’re trying to change the config by setting a context and you’re not providing the config to the change context command. So do this</p>
<pre><code>kubectl config --kubeconfig=infra_k8/config.yaml use-context test-sim
</code></pre>
<p>The setters are used when you want to add more entries to the config file, so you don’t need that command when changing context.</p>
",23699,2020-08-30T05:55:21.587,['kubectl config --kubeconfig=infra_k8/config.yaml use-context test-sim\n']
1447,12324,12320,CC BY-SA 4.0,2020-09-01T19:47:08.293,"<p>I have not tried it but I think if you change your deny to a list of elements it will work.</p>
<pre><code>{
  &quot;Effect&quot;: &quot;Deny&quot;,
  &quot;Principal&quot;: {
    &quot;AWS&quot;: &quot;arn:aws:iam::&lt;redacted&gt;:root&quot;
  },
  &quot;Action&quot;: &quot;sts:AssumeRole&quot;,
  &quot;Condition&quot;: {
    &quot;StringNotLike&quot;: {
      &quot;sts:RoleSessionName&quot;: [
        &quot;${aws:username}&quot;,
        &quot;AnotherAllowedName&quot;
      ]
    }
  }
}
</code></pre>
<p>This will allow an IAM user to assume the role if they use their username as the session name and it will also allow other Principals to assume the role if they use &quot;AnotherAllowedName&quot; as the session name but all other session names would be declined. I found this AWS <a href=""https://aws.amazon.com/blogs/security/easily-control-naming-individual-iam-role-sessions/"" rel=""nofollow noreferrer"">blog post</a> helpful when researching this answer</p>
",4427,2020-09-01T19:47:08.293,"['{\n  ""Effect"": ""Deny"",\n  ""Principal"": {\n    ""AWS"": ""arn:aws:iam::<redacted>:root""\n  },\n  ""Action"": ""sts:AssumeRole"",\n  ""Condition"": {\n    ""StringNotLike"": {\n      ""sts:RoleSessionName"": [\n        ""${aws:username}"",\n        ""AnotherAllowedName""\n      ]\n    }\n  }\n}\n']"
1448,12325,12317,CC BY-SA 4.0,2020-09-01T20:17:30.313,"<p>As the <a href=""https://docs.docker.com/engine/reference/run/"" rel=""nofollow noreferrer"">documentation</a> clearly states <code>docker run</code> command should be invoked as follows:</p>
<pre><code>docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]
</code></pre>
<p>so when you run</p>
<pre><code>docker run mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=password
</code></pre>
<p>Docker assumes <code>-p 3306:3306 -e MYSQL_ROOT_PASSWORD=password</code> is a command you want to run inside the container, not a list of options for <code>docker run</code> command.</p>
<p>The proper <code>docker run</code> invocation with the parameters you specified is:</p>
<pre><code>docker run -p 3306:3306 -e MYSQL_ROOT_PASSWORD=password mysql
</code></pre>
",12864,2020-09-01T20:17:30.313,"['docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]\n', 'docker run mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=password\n', 'docker run -p 3306:3306 -e MYSQL_ROOT_PASSWORD=password mysql\n']"
1449,12330,12328,CC BY-SA 4.0,2020-09-02T16:56:54.727,"<p>The scripted equivalent to the declarative</p>
<pre><code>steps {
  // pipeline steps here
post {
  failure {
    // failure handler here
  }
  success {
    // success handler here
  }
  always {
    // always handler here
  }
}
</code></pre>
<p>is the native Groovy <code>try { } catch { }</code>:</p>
<pre><code>try {
  // pipeline steps here

  // success handler here
} catch(Exception e) {
  // failure handler here
} finally {
  // always handler here
}
</code></pre>
<p>I'm not sure off the top of my head how to add an abort handler, but I think you might be able to do it by inspecting the <code>currentBuild.result</code> variable in the failure handler block.</p>
",4115,2020-09-02T16:56:54.727,"['steps {\n  // pipeline steps here\npost {\n  failure {\n    // failure handler here\n  }\n  success {\n    // success handler here\n  }\n  always {\n    // always handler here\n  }\n}\n', 'try {\n  // pipeline steps here\n\n  // success handler here\n} catch(Exception e) {\n  // failure handler here\n} finally {\n  // always handler here\n}\n']"
1450,12337,12336,CC BY-SA 4.0,2020-09-03T09:57:11.707,"<p>created with:</p>
<pre><code>docker run -d -p 80:8080 -p 443:8443 jetty
</code></pre>
<p>gives a start page as:</p>
<pre><code>Error 404 - Not Found.

   No context on this server matched or handled this request.

   Contexts known to this server are:

   Context Path Display Name Status LifeCycle
     __________________________________________________________________

   [1]icon  [2]Powered by Eclipse Jetty:// Server
     __________________________________________________________________

References

   1. http://eclipse.org/jetty
   2. http://eclipse.org/jetty
</code></pre>
",23443,2020-09-03T10:15:45.770,"['docker run -d -p 80:8080 -p 443:8443 jetty\n', 'Error 404 - Not Found.\n\n   No context on this server matched or handled this request.\n\n   Contexts known to this server are:\n\n   Context Path Display Name Status LifeCycle\n     __________________________________________________________________\n\n   [1]icon  [2]Powered by Eclipse Jetty:// Server\n     __________________________________________________________________\n\nReferences\n\n   1. http://eclipse.org/jetty\n   2. http://eclipse.org/jetty\n']"
1451,12343,12340,CC BY-SA 4.0,2020-09-03T16:54:53.437,"<p>Try something along these lines:</p>
<p><strong>First, create a network for the container:</strong></p>
<p><code>docker network create -d bridge basexhttpnetwork</code></p>
<p><strong>Then, run the container in that network:</strong></p>
<pre><code>docker run -ti --name basexhttp --network=basexhttpnetwork basex/basexhttp:latest basexclient -nbasexhttp
</code></pre>
",23808,2020-09-03T17:02:23.193,['docker run -ti --name basexhttp --network=basexhttpnetwork basex/basexhttp:latest basexclient -nbasexhttp\n']
1452,12347,12345,CC BY-SA 4.0,2020-09-04T08:28:23.713,"<p>Solution is to use <code>exec</code> as:</p>
<pre><code>root@doge:~# 
root@doge:~# docker run -ti     -d     --name basexhttp     --publish 1984:1984     --publish 8984:8984     --volume &quot;$(pwd)/basex/data&quot;:/srv/basex/data     basex/basexhttp:latest
5699af1dc04aa9c78066222e4b0b8e5621aa2ab9dd2bd46bcd87c6a0377c1960
root@doge:~# 
root@doge:~# docker container list
CONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS              PORTS                                                      NAMES
5699af1dc04a        basex/basexhttp:latest   &quot;/usr/local/bin/mvn-…&quot;   33 seconds ago      Up 30 seconds       0.0.0.0:1984-&gt;1984/tcp, 0.0.0.0:8984-&gt;8984/tcp, 8985/tcp   basexhttp
root@doge:~# 
root@doge:~# docker exec -ti --user root basexhttp bash
bash-4.4# 
bash-4.4# whoami
root
bash-4.4# 
bash-4.4# su basex
~ $ 
~ $ whoami
basex
~ $ 
~ $ exit
bash-4.4# exit
exit
root@doge:~# 
root@doge:~# docker container list
CONTAINER ID        IMAGE                    COMMAND                  CREATED              STATUS              PORTS                                                      NAMES
5699af1dc04a        basex/basexhttp:latest   &quot;/usr/local/bin/mvn-…&quot;   About a minute ago   Up About a minute   0.0.0.0:1984-&gt;1984/tcp, 0.0.0.0:8984-&gt;8984/tcp, 8985/tcp   basexhttp
root@doge:~# 
root@doge:~# docker ps -a
CONTAINER ID        IMAGE                    COMMAND                  CREATED              STATUS              PORTS                                                      NAMES
5699af1dc04a        basex/basexhttp:latest   &quot;/usr/local/bin/mvn-…&quot;   About a minute ago   Up About a minute   0.0.0.0:1984-&gt;1984/tcp, 0.0.0.0:8984-&gt;8984/tcp, 8985/tcp   basexhttp
root@doge:~# 
</code></pre>
",23443,2020-09-04T08:28:23.713,"['root@doge:~# \nroot@doge:~# docker run -ti     -d     --name basexhttp     --publish 1984:1984     --publish 8984:8984     --volume ""$(pwd)/basex/data"":/srv/basex/data     basex/basexhttp:latest\n5699af1dc04aa9c78066222e4b0b8e5621aa2ab9dd2bd46bcd87c6a0377c1960\nroot@doge:~# \nroot@doge:~# docker container list\nCONTAINER ID        IMAGE                    COMMAND                  CREATED             STATUS              PORTS                                                      NAMES\n5699af1dc04a        basex/basexhttp:latest   ""/usr/local/bin/mvn-…""   33 seconds ago      Up 30 seconds       0.0.0.0:1984->1984/tcp, 0.0.0.0:8984->8984/tcp, 8985/tcp   basexhttp\nroot@doge:~# \nroot@doge:~# docker exec -ti --user root basexhttp bash\nbash-4.4# \nbash-4.4# whoami\nroot\nbash-4.4# \nbash-4.4# su basex\n~ $ \n~ $ whoami\nbasex\n~ $ \n~ $ exit\nbash-4.4# exit\nexit\nroot@doge:~# \nroot@doge:~# docker container list\nCONTAINER ID        IMAGE                    COMMAND                  CREATED              STATUS              PORTS                                                      NAMES\n5699af1dc04a        basex/basexhttp:latest   ""/usr/local/bin/mvn-…""   About a minute ago   Up About a minute   0.0.0.0:1984->1984/tcp, 0.0.0.0:8984->8984/tcp, 8985/tcp   basexhttp\nroot@doge:~# \nroot@doge:~# docker ps -a\nCONTAINER ID        IMAGE                    COMMAND                  CREATED              STATUS              PORTS                                                      NAMES\n5699af1dc04a        basex/basexhttp:latest   ""/usr/local/bin/mvn-…""   About a minute ago   Up About a minute   0.0.0.0:1984->1984/tcp, 0.0.0.0:8984->8984/tcp, 8985/tcp   basexhttp\nroot@doge:~# \n']"
1453,12349,12344,CC BY-SA 4.0,2020-09-04T12:44:15.573,"<p>You're attempting to create two different containers, each with the same name. Each time you execute <code>docker run</code> it will create a container, and you've named the containers the same with <code>--name basexhttp</code>. These names must be unique, even among stopped containers. To delete an unneeded container, you can stop and remove it with:</p>
<pre><code>docker container stop basexhttp
docker container rm basexhttp
</code></pre>
<p>(Note that <code>docker stop</code> and <code>docker rm</code> also work, but it's easier to read and understand the more verbose syntax)</p>
",7730,2020-09-04T12:44:15.573,['docker container stop basexhttp\ndocker container rm basexhttp\n']
1454,12352,12340,CC BY-SA 4.0,2020-09-04T15:39:04.313,"<p>First of all, <code>--link</code> is deprecated.</p>
<p>Secondly, you don't need the daemon logs, instead you need to take a look at what the container's logs are saying</p>
<pre><code>docker logs &lt;container name/id&gt;
</code></pre>
<p>Once you have that, you'll need to work your way up in fixing whatever the issue there might be. This isn't <code>docker</code> related.</p>
<p>The first error message states that you're trying to link to a nonexistent container, and the second error pops up because even though the container isn't running (or failed), it's still there, and you can't use the same name for two containers. You need to remove the previous one using <code>docker rm &lt;container name/id&gt;</code>.</p>
<hr />
<blockquote>
<p>how do I now make it run something which doesn't immediately exit?</p>
</blockquote>
<p>You do that using the <code>--entrypoint</code> flag, like the following</p>
<pre><code>docker run -ti --entrypoint bash nginx:latest
</code></pre>
<p>This won't start the nginx daemon, instead you'll be put into a bash prompt.</p>
<p>Make sure you're using the <code>-ti</code> flag if you want to use something like bash/ash, i.e. an interactive tty.</p>
",,2020-09-04T15:44:05.607,"['docker logs <container name/id>\n', 'docker run -ti --entrypoint bash nginx:latest\n']"
1455,12354,12340,CC BY-SA 4.0,2020-09-04T19:29:48.203,"<p>The proper way to run this image, according to the README, is:</p>
<pre><code>docker run -d \
    --name basexhttp \
    --publish 1984:1984 \
    --publish 8984:8984 \
    --volume &quot;$HOME/basex/data&quot;:/srv/basex/data \
    --volume &quot;$HOME/basex/repo&quot;:/srv/basex/repo \
    --volume &quot;$HOME/basex/webapp&quot;:/srv/basex/webapp \
    basex/basexhttp:latest
</code></pre>
<p>No weird linking to itself is necessary.</p>
<p>If you wan to run a shell in an already running container (started as above) use:</p>
<pre><code>docker exec -it basexhttp sh
</code></pre>
<p>or you can try bash</p>
<pre><code>docker exec -it basexhttp bash
</code></pre>
<p>but the container is Alpine-based, so bash might not be installed.</p>
<p>If you want to run a new container and execute shell inside run</p>
<pre><code>docker run -it --rm basexhttp sh 
# or bash if it's installed
docker run -it --rm basexhttp bash
</code></pre>
<p>The above will remove the container once you exit bash (but the 3 volumes it creates
will remain, you need to find and remove those by yourself).</p>
<p>Edit:</p>
<p>It seems README is wrong about how to start the container. See my <a href=""https://devops.stackexchange.com/questions/12338/cannot-get-bash-prompt-error-response-from-daemon-container-foo-is-not-running"">answer</a> to this question for more details.</p>
",12864,2020-09-05T12:28:47.377,"['docker run -d \\\n    --name basexhttp \\\n    --publish 1984:1984 \\\n    --publish 8984:8984 \\\n    --volume ""$HOME/basex/data"":/srv/basex/data \\\n    --volume ""$HOME/basex/repo"":/srv/basex/repo \\\n    --volume ""$HOME/basex/webapp"":/srv/basex/webapp \\\n    basex/basexhttp:latest\n', 'docker exec -it basexhttp sh\n', 'docker exec -it basexhttp bash\n', ""docker run -it --rm basexhttp sh \n# or bash if it's installed\ndocker run -it --rm basexhttp bash\n""]"
1456,12355,12338,CC BY-SA 4.0,2020-09-04T20:40:32.733,"<p>Whoever created <code>basex/basexhttp:latest</code> does not seem to know Docker very well. They copied files necessary to a directory that was later configured as a volume, <strong>which means it can only be bound to an anonymous volume, otherwise files inside will be removed</strong>. They left source code inside the image, they used a single stage build with <code>maven:3-jdk-8-alpine</code> as base image, which means the final image has many unnecesary things installed. They left the entrypoint from the base image intact, which I guess is why they needed to create an empty <code>/srv/.m2</code> directory and set it as Maven config dir for the image to start. It switches user from <code>root</code> to <code>basex</code>, which causes permission problems with bind mounts. Generally it's a mess.</p>
<p>I see two ways to successfully run this image:</p>
<p>First:</p>
<pre><code>docker run -d \
    --name basexhttp \
    --publish 1984:1984 \
    --publish 8984:8984 \
    --entrypoint &quot;&quot; \
    basex/basexhttp:latest /usr/local/bin/basexhttp 
</code></pre>
<p>This uses only anonymous volumes and clears that unnecessary entrypoint.</p>
<p>You can stop it with <code>docker stop basexhttp</code> and then remove it with <code>docker rm -v basexhttp</code>. That <code>-v</code> is important - it removes the volumes - unless you memorize their very long IDs and which was mounted which you won't be able to reuse them anyway, so you may as well remove them from your system.</p>
<p>Second:</p>
<pre><code>mkdir -p $HOME/basex/data
mkdir -p $HOME/basex/repo
mkdir -p $HOME/basex/webapp
chmod a+w basex
sudo chown -R 1984:1984 $HOME/basex
docker run -d \
    --name basexhttp \
    --publish 1984:1984 \
    --publish 8984:8984 \
    --volume &quot;$HOME/basex/data&quot;:/srv/basex/data \
    --volume &quot;$HOME/basex/repo&quot;:/srv/basex/repo \
    --volume &quot;$HOME/basex/webapp&quot;:/srv/basex/webapp \
    --entrypoint &quot;&quot; \
    basex/basexhttp:latest bash -c &quot;cp -r /usr/src/basex/basex-api/src/main/webapp/WEB-INF /srv/basex/webapp &amp;&amp; exec /usr/local/bin/basexhttp&quot;
</code></pre>
<p>This creates the necessary directories and sets their permissions so that both your user on the host and user.</p>
<p>You can stop it as in the previous example and remove with <code>docker rm basexhttp</code>. This time <code>-v</code> is not necessary, as there are no anonymous volumes.</p>
<p>You can verify that the contaienr is running correctly by executing:</p>
<pre><code>docker exec -ti basexhttp basexclient
</code></pre>
<p>Username and password are both admin.</p>
",12864,2020-09-04T20:40:32.733,"['docker run -d \\\n    --name basexhttp \\\n    --publish 1984:1984 \\\n    --publish 8984:8984 \\\n    --entrypoint """" \\\n    basex/basexhttp:latest /usr/local/bin/basexhttp \n', 'mkdir -p $HOME/basex/data\nmkdir -p $HOME/basex/repo\nmkdir -p $HOME/basex/webapp\nchmod a+w basex\nsudo chown -R 1984:1984 $HOME/basex\ndocker run -d \\\n    --name basexhttp \\\n    --publish 1984:1984 \\\n    --publish 8984:8984 \\\n    --volume ""$HOME/basex/data"":/srv/basex/data \\\n    --volume ""$HOME/basex/repo"":/srv/basex/repo \\\n    --volume ""$HOME/basex/webapp"":/srv/basex/webapp \\\n    --entrypoint """" \\\n    basex/basexhttp:latest bash -c ""cp -r /usr/src/basex/basex-api/src/main/webapp/WEB-INF /srv/basex/webapp && exec /usr/local/bin/basexhttp""\n', 'docker exec -ti basexhttp basexclient\n']"
1457,12356,12340,CC BY-SA 4.0,2020-09-05T00:47:16.520,"<p>After random stumbling, this works:</p>
<pre><code>root $ 
root $ docker run -ti -d \
&gt;     --name basexhttp \
&gt;     --publish 1984:1984 \
&gt;     --publish 8984:8984 \
&gt;     --volume &quot;$(pwd)/basex/data&quot;:/srv/basex/data \
&gt;     basex/basexhttp:latest
0cbd60aa6261c7e43646f675765e2dbf38fbfd57f641ca87dc6f6b8cd4fd36e0
root $ 
root $ docker exec -ti \
&gt; --user root \
&gt; basexhttp \
&gt; bash
bash-4.4# 
bash-4.4# whoami
root
bash-4.4# 
bash-4.4# pwd
/srv
bash-4.4# 
bash-4.4# ls
basex
bash-4.4# 
bash-4.4# exit
exit
root $ 
</code></pre>
<p>I'll go through the answers more thoroughly, but thanks to all.</p>
",23443,2020-09-05T00:47:16.520,"['root $ \nroot $ docker run -ti -d \\\n>     --name basexhttp \\\n>     --publish 1984:1984 \\\n>     --publish 8984:8984 \\\n>     --volume ""$(pwd)/basex/data"":/srv/basex/data \\\n>     basex/basexhttp:latest\n0cbd60aa6261c7e43646f675765e2dbf38fbfd57f641ca87dc6f6b8cd4fd36e0\nroot $ \nroot $ docker exec -ti \\\n> --user root \\\n> basexhttp \\\n> bash\nbash-4.4# \nbash-4.4# whoami\nroot\nbash-4.4# \nbash-4.4# pwd\n/srv\nbash-4.4# \nbash-4.4# ls\nbasex\nbash-4.4# \nbash-4.4# exit\nexit\nroot $ \n']"
1458,12365,10945,CC BY-SA 4.0,2020-09-08T12:38:18.773,"<p>This is a combination of two things. You need the <code>BROWSER</code> variable and there is a bug (as of Sep-2020) where <code>az-cli</code> doesn't detect interactive session correctly (<a href=""https://github.com/microsoft/WSL2-Linux-Kernel/issues/55"" rel=""nofollow noreferrer"">https://github.com/microsoft/WSL2-Linux-Kernel/issues/55</a>)</p>
<p>So you need to modify <code>~/.bashrc</code>:</p>
<pre><code>export BROWSER=&quot;/c/Program Files (x86)/Google/Chrome/Application/chrome.exe&quot;
</code></pre>
<p>end then you can run your browser spawning commands with prefix <code>DISPLAY=:0</code> (sets that environment variable for duration of command; in this case az uses it to determine if the session is interactive and a browser should/could be spawned). So for you:</p>
<pre><code>DISPLAY=:0 az aks browse -g &lt;groupname&gt; -n &lt;clustername&gt;
</code></pre>
",23854,2020-09-08T12:38:18.773,"['export BROWSER=""/c/Program Files (x86)/Google/Chrome/Application/chrome.exe""\n', 'DISPLAY=:0 az aks browse -g <groupname> -n <clustername>\n']"
1459,12371,12370,CC BY-SA 4.0,2020-09-09T07:04:16.730,"<p>If you're using the declarative DSL, you can use <a href=""https://www.jenkins.io/doc/book/pipeline/syntax/#when"" rel=""nofollow noreferrer""><code>when</code></a></p>
<p>Suppose the branch you're interested in is <code>main</code>, have a stage like:</p>
<pre><code>.
.
.
stages {
  stage('Specific Branch'}
  when { branch 'main' }
  steps {
    // only executed when the main branch is changed
  }
}
.
.
.
</code></pre>
<p>From the Jenkins docs:</p>
<blockquote>
<p>Built-in Conditions</p>
</blockquote>
<blockquote>
<p>branch</p>
</blockquote>
<blockquote>
<p>Execute the stage when the branch being built matches the branch pattern (ANT style path glob) given, for example: when { branch 'master' }. Note that this only works on a multibranch Pipeline.</p>
</blockquote>
<blockquote>
<p>The optional parameter comparator may be added after an attribute to specify how any patterns are evaluated for a match: EQUALS for a simple string comparison, GLOB (the default) for an ANT style path glob (same as for example changeset), or REGEXP for regular expression matching. For example: when { branch pattern: &quot;release-\d+&quot;, comparator: &quot;REGEXP&quot;}</p>
</blockquote>
<p>While this will only execute changes to the <code>main</code> branch, you still need to configure the job to be executed when changes to that branch are made. This can be done with the <a href=""https://github.com/jenkinsci/job-dsl-plugin"" rel=""nofollow noreferrer"">job dsl</a>:</p>
<p>This slightly modified example is taken from the DSL plugin repo:</p>
<pre><code>pipelineJob('job-dsl-plugin') {
  definition {
    cpsScm {
      scm {
        git {
          remote {
            url('https://github.com/your/repo')
          }
          branch('*/main')
        }
      }
      lightweight()
    }
  }
}
</code></pre>
",354,2020-09-09T07:04:16.730,"["".\n.\n.\nstages {\n  stage('Specific Branch'}\n  when { branch 'main' }\n  steps {\n    // only executed when the main branch is changed\n  }\n}\n.\n.\n.\n"", ""pipelineJob('job-dsl-plugin') {\n  definition {\n    cpsScm {\n      scm {\n        git {\n          remote {\n            url('https://github.com/your/repo')\n          }\n          branch('*/main')\n        }\n      }\n      lightweight()\n    }\n  }\n}\n""]"
1460,12376,12374,CC BY-SA 4.0,2020-09-10T07:06:43.803,"<p>@Mkash, don't you know in advance what services you have in your <code>services.yaml</code> file?</p>
<p>Maintain a list in groovy, and see whether the input is in that list or not.</p>
<p>Something like:</p>
<pre><code>availableServices = [&quot;ew_ws_gateway&quot;, &quot;ingress&quot;]

services = [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;ew_ws_gateway&quot;]

services.each { svc -&gt;
    if (svc in availableServices) {
        println(&quot;Service exist&quot; + svc)
    }
}
</code></pre>
<p>The other option is to change the parameter from type of <code>text</code> to multiple-choice possibly using <a href=""https://plugins.jenkins.io/extended-choice-parameter/"" rel=""nofollow noreferrer"">https://plugins.jenkins.io/extended-choice-parameter/</a></p>
",8065,2020-09-10T07:06:43.803,"['availableServices = [""ew_ws_gateway"", ""ingress""]\n\nservices = [""a"", ""b"", ""c"", ""ew_ws_gateway""]\n\nservices.each { svc ->\n    if (svc in availableServices) {\n        println(""Service exist"" + svc)\n    }\n}\n']"
1461,12383,12382,CC BY-SA 4.0,2020-09-11T05:34:43.783,"<p>The condition works as expected. For example, the inventory and the playbook below</p>
<pre class=""lang-yaml prettyprint-override""><code>shell&gt; cat hosts
[managers]
k8s01
k8s02
k8s03

[workers]
worker1
worker2

shell&gt; cat playbook.yml 
- hosts: all
  gather_facts: false
  tasks:
    - debug:
        var: inventory_hostname
      when:
        - inventory_hostname != groups.managers.0
        - inventory_hostname in groups.managers
</code></pre>
<p>give</p>
<pre class=""lang-yaml prettyprint-override""><code>shell&gt; ansible-playbook -i hosts playbook.yml 

PLAY [all] ****

TASK [debug] ****
skipping: [worker1]
ok: [k8s02] =&gt; {
    &quot;inventory_hostname&quot;: &quot;k8s02&quot;
}
skipping: [k8s01]
skipping: [worker2]
ok: [k8s03] =&gt; {
    &quot;inventory_hostname&quot;: &quot;k8s03&quot;
}
</code></pre>
",7715,2020-09-11T05:43:10.313,"['shell> cat hosts\n[managers]\nk8s01\nk8s02\nk8s03\n\n[workers]\nworker1\nworker2\n\nshell> cat playbook.yml \n- hosts: all\n  gather_facts: false\n  tasks:\n    - debug:\n        var: inventory_hostname\n      when:\n        - inventory_hostname != groups.managers.0\n        - inventory_hostname in groups.managers\n', 'shell> ansible-playbook -i hosts playbook.yml \n\nPLAY [all] ****\n\nTASK [debug] ****\nskipping: [worker1]\nok: [k8s02] => {\n    ""inventory_hostname"": ""k8s02""\n}\nskipping: [k8s01]\nskipping: [worker2]\nok: [k8s03] => {\n    ""inventory_hostname"": ""k8s03""\n}\n']"
1462,12385,3264,CC BY-SA 4.0,2020-09-11T09:52:09.933,"<p>If you need to execute more than just one command, because let's say you are investigating an issue, you can start a session:</p>
<pre><code>aws ssm start-session --target i-0123456789abcdef0
</code></pre>
<p>You will need to <a href=""https://docs.aws.amazon.com/systems-manager/latest/userguide/session-manager-working-with-install-plugin.html"" rel=""nofollow noreferrer"">install Session Manager Plugin</a> for that.</p>
",23902,2020-09-11T09:52:09.933,['aws ssm start-session --target i-0123456789abcdef0\n']
1463,12387,10349,CC BY-SA 4.0,2020-09-11T13:45:19.013,"<p>It seems your private DNS is misconfigured. Check your host or make sure that <code>docker-registry.default</code> is the a valid hostname.</p>
<p>You can run a temporary Ubuntu pod to check if that hostname is resolving correctly from your cluster, e.g.</p>
<pre><code>$ kubectl run ubuntu -it --image ubuntu --rm=true -- bash
root@shell:/# apt update &amp;&amp; DEBIAN_FRONTEND=noninteractive apt --yes install dnsutils
root@shell:/# dig docker-registry.default
docker-registry.default.    IN  A D0.y0u.h4ve.1P?
</code></pre>
<p>Additional suggestions:</p>
<ul>
<li>If you're using a cloud provider (such as Azure), make sure your Private DNS zone is linked with your cluster's virtual network. Read: <a href=""https://docs.microsoft.com/en-us/azure/container-registry/container-registry-private-link#create-a-docker-enabled-virtual-machine"" rel=""nofollow noreferrer"">Connect privately to an Azure container registry using Azure Private Link</a></li>
<li>If your container registry endpoint isn't correct, edit the deployment manifest and fix the image path.</li>
<li>Test pulling the image from another VM within the same private network.</li>
</ul>
",3,2020-09-11T13:50:29.507,['$ kubectl run ubuntu -it --image ubuntu --rm=true -- bash\nroot@shell:/# apt update && DEBIAN_FRONTEND=noninteractive apt --yes install dnsutils\nroot@shell:/# dig docker-registry.default\ndocker-registry.default.    IN  A D0.y0u.h4ve.1P?\n']
1464,12389,12386,CC BY-SA 4.0,2020-09-11T15:24:19.200,"<p>Ansible <strong>facts</strong> are data collected about the (target) systems on which Ansible takes actions. They are variables, but set by Ansible (in a way like <em><strong>system defined variables</strong></em>). They are collected during <code>Gathering Facts</code> stage of a playbook run, and it is controlled by the <code>gather_facts</code> setting. Ansible calls this <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#id26"" rel=""nofollow noreferrer"">variables discovered from systems</a>. That said, it is possible to set custom facts also.</p>
<p>Some examples are:</p>
<ul>
<li><code>ansible_hostname</code> - the FQDN of the target system</li>
<li><code>ansible_os_family</code> - the Operating System family of target system (RedHat, Debian, etc.)</li>
</ul>
<p>The other <strong>variables</strong> are the ones we can set as per our requirement (in a way like <em><strong>user defined variables</strong></em>).</p>
<p>Some examples are:</p>
<ul>
<li><code>my_fav_fruits: [ 'orange', 'apple', 'banana' ]</code> - yours might differ.</li>
<li><code>config_dir: '/etc/my_app/conf.d'</code> - for my application configuration files.</li>
</ul>
<hr />
<p><strong>Update:</strong></p>
<p><em>Updating answer to make it relevant to the edit(s) made in question.</em></p>
<p>As <a href=""https://devops.stackexchange.com/a/12393/23904"">@Bruce Becker's answer</a> rightly pointed out, there is a difference in the precedence of variables set with <code>set_fact</code>. Also variables that need to be set at &quot;run time&quot; can be set this way. Without further explanation, taking your example variables, if I create a play like below:</p>
<pre class=""lang-yaml prettyprint-override""><code>- hosts: localhost
  vars:
    nginx_ssl: '/etc/nginx/ssl'
    nginx_conf_file: '/etc/nginx/nginx.conf'

  tasks:
  - name: set nginx path to /opt when running on Debian
    set_fact:
      nginx_ssl: '/opt/nginx/ssl'
      nginx_conf_file: '/opt/nginx/nginx.conf'
    when: ansible_distribution == 'Debian'
  - debug:
      msg: 'ssl: {{ nginx_ssl }} and conf: {{ nginx_conf_file }}'
</code></pre>
<p>Then the <code>set_fact</code> variables will take precedence (on Debian) and output will be:</p>
<pre><code>&quot;msg&quot;: &quot;ssl: /opt/nginx/ssl and conf: /opt/nginx/nginx.conf&quot;
</code></pre>
<p>On other distributions, it will be what was declared in <code>vars:</code>.</p>
",23904,2020-09-12T17:42:51.410,"[""- hosts: localhost\n  vars:\n    nginx_ssl: '/etc/nginx/ssl'\n    nginx_conf_file: '/etc/nginx/nginx.conf'\n\n  tasks:\n  - name: set nginx path to /opt when running on Debian\n    set_fact:\n      nginx_ssl: '/opt/nginx/ssl'\n      nginx_conf_file: '/opt/nginx/nginx.conf'\n    when: ansible_distribution == 'Debian'\n  - debug:\n      msg: 'ssl: {{ nginx_ssl }} and conf: {{ nginx_conf_file }}'\n"", '""msg"": ""ssl: /opt/nginx/ssl and conf: /opt/nginx/nginx.conf""\n']"
1465,12399,12382,CC BY-SA 4.0,2020-09-14T03:15:51.913,"<p>I believe your <code>hosts</code> is set to <code>k8s01</code> or other group not containing k8s02 and
k8s03.<br />
That's why they are not run.</p>
<p>You shall add <code>with_items: &quot;{{ groups['managers'] }}&quot;</code> and delegate as you done in the second task <code>-name: Set join command for managers</code>.</p>
<pre><code>- name: Join managers into cluster      
  shell: &quot;{{ kubernetes_join_command_controlplane.stdout }}&quot;
  args:
    warn: no
  when: inventory_hostname != groups['managers'][0] and inventory_hostname in groups['managers']
  delegate_to: &quot;{{ item }}&quot;
  delegate_facts: true
  with_items: &quot;{{ groups['managers'] }}&quot; 
</code></pre>
<p>Alternatively, depending on your design and scope.
Do as answer from Botka and set the hosts as:<br />
<code>hosts: all</code><br />
or<br />
<code>hosts: managers</code></p>
",23898,2020-09-14T03:22:19.393,"['- name: Join managers into cluster      \n  shell: ""{{ kubernetes_join_command_controlplane.stdout }}""\n  args:\n    warn: no\n  when: inventory_hostname != groups[\'managers\'][0] and inventory_hostname in groups[\'managers\']\n  delegate_to: ""{{ item }}""\n  delegate_facts: true\n  with_items: ""{{ groups[\'managers\'] }}"" \n']"
1466,12401,12392,CC BY-SA 4.0,2020-09-14T07:04:51.120,"<p>Try to read logs as follows:</p>
<pre><code>docker logs -f &lt;container-name or container-ID&gt; 2&gt;&amp;1
</code></pre>
<hr />
<p>[<strong>NOTE</strong>]:</p>
<ul>
<li><code>-f</code> option follows live logs.</li>
<li><code>2&gt;&amp;1</code> makes output as <code>stdout</code> and <code>stderr</code> which is useful for grepping and standardizing.</li>
</ul>
",7953,2020-09-22T07:12:25.113,['docker logs -f <container-name or container-ID> 2>&1\n']
1467,12410,12409,CC BY-SA 4.0,2020-09-15T06:58:21.797,"<pre><code>nicholas $ 
nicholas $ cat ansible.cfg 
[defaults]
inventory = hosts
ask_vault_pass = True

[privilege_escalation]
become_ask_pass = True


nicholas $ 
nicholas $ sudo ansible-playbook first_playbook.yml --connection=local
BECOME password: 
Vault password: 
[WARNING]: Unable to parse /home/nicholas/ansible/hosts as an inventory source
[WARNING]: No inventory was parsed, only implicit localhost is available
[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'

PLAY [Network Getting Started First Playbook] **************************************************************************************
skipping: no hosts matched

PLAY RECAP *************************************************************************************************************************

nicholas $ 
</code></pre>
<p>As a <a href=""https://devops.stackexchange.com/q/4365/23443"">workaround to using</a> a remote, although it requires some additional configuration apparently.</p>
",23443,2020-09-15T06:58:21.797,"[""nicholas $ \nnicholas $ cat ansible.cfg \n[defaults]\ninventory = hosts\nask_vault_pass = True\n\n[privilege_escalation]\nbecome_ask_pass = True\n\n\nnicholas $ \nnicholas $ sudo ansible-playbook first_playbook.yml --connection=local\nBECOME password: \nVault password: \n[WARNING]: Unable to parse /home/nicholas/ansible/hosts as an inventory source\n[WARNING]: No inventory was parsed, only implicit localhost is available\n[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'\n\nPLAY [Network Getting Started First Playbook] **************************************************************************************\nskipping: no hosts matched\n\nPLAY RECAP *************************************************************************************************************************\n\nnicholas $ \n""]"
1468,12414,12409,CC BY-SA 4.0,2020-09-15T13:35:26.147,"<p>This error is due to invalid value of <code>ansible_network_os:</code></p>
<p>The playbook you try setup is meant for network devices.<br />
And since centos is not a network device OS the playbook will fail.<br />
Here you can find supported network OS.<br />
<a href=""https://docs.ansible.com/ansible/latest/network/user_guide/platform_index.html#settings-by-platform"" rel=""nofollow noreferrer"">Ansible Documentation: ansible_network_os values</a></p>
<p>If you don't have any device running a supported network OS I recommend you to follow the regular user guide.<br />
<a href=""https://docs.ansible.com/ansible/latest/user_guide/index.html"" rel=""nofollow noreferrer"">Ansible User Guide</a></p>
<p>My suggestion is to setup a easy playbook that will run on the environment you have.<br />
Get the understanding of following concepts.<br />
<code>Control node</code><br />
<code>Managed nodes</code><br />
<code>Inventory</code><br />
<code>Modules</code><br />
<code>Tasks</code><br />
<code>Playbooks</code></p>
<p>Here is a short example.<br />
This will only execute <code>hostname</code> do confirm it execute on expected host.<br />
Let's say <code>nicholas</code> is your control node and <code>rolly</code> is the managed node.</p>
<p>On <code>nicholas</code>:<br />
Create a inventory as before with your control node and managed node.<br />
inventory.txt:</p>
<pre class=""lang-yaml prettyprint-override""><code>[local]
localhost ansible_connection=local

[managed_node]
rolly ansible_host=&lt;rolly ip&gt; ansible_user=&lt;rolly user&gt; ansible_ssh_pass=&lt;rolly user password&gt;
</code></pre>
<p>myplaybook.yml:</p>
<pre class=""lang-yaml prettyprint-override""><code>---
- name: This will get hostname localy on control node
  hosts: localhost
  tasks:
    - name: get hostname
      command: hostname
      register: result

    - name: print hostname
      debug:
          var: result

- name: This will get hostname remote on manged node
  hosts: rolly
  tasks:
    - name: get hostname
      command: hostname
      register: result

    - name: print hostname
      debug:
          var: result
</code></pre>
<p>And then execute on the control node:<br />
<code>ansible-playbook -i inventory.txt myplaybook.yml</code></p>
",23898,2020-09-15T13:35:26.147,"['[local]\nlocalhost ansible_connection=local\n\n[managed_node]\nrolly ansible_host=<rolly ip> ansible_user=<rolly user> ansible_ssh_pass=<rolly user password>\n', '---\n- name: This will get hostname localy on control node\n  hosts: localhost\n  tasks:\n    - name: get hostname\n      command: hostname\n      register: result\n\n    - name: print hostname\n      debug:\n          var: result\n\n- name: This will get hostname remote on manged node\n  hosts: rolly\n  tasks:\n    - name: get hostname\n      command: hostname\n      register: result\n\n    - name: print hostname\n      debug:\n          var: result\n']"
1469,12420,12411,CC BY-SA 4.0,2020-09-16T08:17:17.257,"<p>The answer is in the warning you get:</p>
<pre><code>[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'
</code></pre>
<p>When you use <code>hosts: all</code> in your playbook, <code>localhost</code> is not matched.</p>
<p>If you want to run the playbook on localhost, you can do one of the following:</p>
<ul>
<li>Change your playbook to <code>hosts: localhost</code>.</li>
<li>Explicitly provide an inventory file that has <code>localhost</code>.</li>
</ul>
<p>You can create an inventory file - <code>inventory.yml</code> with the contents:</p>
<pre><code>all:
  hosts:
    localhost
</code></pre>
<p>and then pass this inventory file to ansible explicitly like this:</p>
<p><code>$ ansible-playbook --connection=local -i inventory.yml playbook.yml</code></p>
<p>You can find more information about inventory in the <a href=""https://docs.ansible.com/ansible/2.7/user_guide/intro_inventory.html"" rel=""nofollow noreferrer"">Ansible documentation</a>.</p>
",20015,2020-09-16T08:17:17.257,"[""[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit localhost does not match 'all'\n"", 'all:\n  hosts:\n    localhost\n']"
1470,12423,12422,CC BY-SA 4.0,2020-09-16T16:26:19.543,"<p>You can use a proxy to forward traffic between the two services, I typically do something like this which includes automated SSL with certbot. In the example below I have two services listening on port 80/443 (Sonarqube and Jenkins). You can also see I can reference container hosts by name (https://jenkins:8080)</p>
<pre><code>nginx:
container_name: nginx-certbot
restart: unless-stopped
image: staticfloat/nginx-certbot
networks:
  - local
ports:
  - &quot;0.0.0.0:80:80&quot;
  - &quot;0.0.0.0:443:443&quot;
environment:
  CERTBOT_EMAIL: &lt;insert_email&gt;
volumes:
  - ./conf.d:/etc/nginx/user.conf.d:ro
  - letsencrypt:/etc/letsencrypt
</code></pre>
<p>And this is what my nginx config looks like</p>
<pre><code>server {
listen              443 ssl;
server_name jenkins.hauntedmansion.io;
ssl_certificate     /etc/letsencrypt/live/jenkins.hauntedmansion.io/fullchain.pem;
ssl_certificate_key /etc/letsencrypt/live/jenkins.hauntedmansion.io/privkey.pem;

client_max_body_size 20M;

  location / {
    proxy_set_header   Host $host;
    proxy_set_header   X-Real-IP $remote_addr;
    proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header   X-Forwarded-Proto $scheme;
    proxy_pass         http://jenkins:8080;
    proxy_read_timeout 90;
    proxy_redirect     http://127.0.0.1:8080 https://jenkins.hauntedmansion.io;
  }
}
</code></pre>
<p>If you want to see the full docker compose example check it out here:</p>
<p><a href=""https://gist.github.com/cvega/66e0e5a2815e9b923da2c616f74dea7e"" rel=""nofollow noreferrer"">https://gist.github.com/cvega/66e0e5a2815e9b923da2c616f74dea7e</a></p>
",6579,2020-09-16T16:26:19.543,"['nginx:\ncontainer_name: nginx-certbot\nrestart: unless-stopped\nimage: staticfloat/nginx-certbot\nnetworks:\n  - local\nports:\n  - ""0.0.0.0:80:80""\n  - ""0.0.0.0:443:443""\nenvironment:\n  CERTBOT_EMAIL: <insert_email>\nvolumes:\n  - ./conf.d:/etc/nginx/user.conf.d:ro\n  - letsencrypt:/etc/letsencrypt\n', 'server {\nlisten              443 ssl;\nserver_name jenkins.hauntedmansion.io;\nssl_certificate     /etc/letsencrypt/live/jenkins.hauntedmansion.io/fullchain.pem;\nssl_certificate_key /etc/letsencrypt/live/jenkins.hauntedmansion.io/privkey.pem;\n\nclient_max_body_size 20M;\n\n  location / {\n    proxy_set_header   Host $host;\n    proxy_set_header   X-Real-IP $remote_addr;\n    proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header   X-Forwarded-Proto $scheme;\n    proxy_pass         http://jenkins:8080;\n    proxy_read_timeout 90;\n    proxy_redirect     http://127.0.0.1:8080 https://jenkins.hauntedmansion.io;\n  }\n}\n']"
1471,12431,12427,CC BY-SA 4.0,2020-09-17T12:57:03.247,"<p>You should look at <a href=""https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/"" rel=""nofollow noreferrer"">DaemonSets</a>. You can configure it so that the Pods runs on each node of your Kubernetes cluster. Each individual Pod (running your Linux machine) can be exposed to outside network using the IP address of the node on which it is running.</p>
<blockquote>
<p>My need is more targeted to expose an entire machine on a precise static IP and not just a port.</p>
</blockquote>
<p><em>Before getting into further explanation, I should point out that there is nothing like exposing entire machines.</em></p>
<p>Access to any machine is always through a combination of IP address and Port. So you should decide based on which port you would like to access on the container.</p>
<p><strong>Example:</strong></p>
<p>Let's say I have a 3 node Kubernetes cluster, I can create a DaemonSet with the application/image of my choice. Below names/details are imaginary, but should give an idea on the mapping.</p>
<pre><code>ubuntu-daemonset-pod-xyz    k8s-node-1    192.168.2.1
ubuntu-daemonset-pod-abc    k8s-node-2    192.168.2.2
ubuntu-daemonset-pod-hij    k8s-node-3    192.168.2.3
</code></pre>
<p>The Pods above can be &quot;exposed&quot; on the IP address of the node on which it is running. That is: <code>ubuntu-daemonset-pod-xyz</code> on <code>192.168.2.1</code>.</p>
",23904,2020-09-17T12:57:03.247,['ubuntu-daemonset-pod-xyz    k8s-node-1    192.168.2.1\nubuntu-daemonset-pod-abc    k8s-node-2    192.168.2.2\nubuntu-daemonset-pod-hij    k8s-node-3    192.168.2.3\n']
1472,12434,11282,CC BY-SA 4.0,2020-09-17T18:33:17.567,"<p>An alternative sintax to <code>Dilson Rainov</code>'s answer, more ansible 2.x style (I think).</p>
<p>In your inventory define the host as:</p>
<pre class=""lang-yml prettyprint-override""><code>vagrant-local:
      ansible_host: 192.168.33.10
      ansible_user: vagrant
      ansible_ssh_private_key_file: .vagrant/machines/default/virtualbox/private_key
      UserKnownHostsFile: /dev/null
      StrictHostKeyChecking: no
      ansible_python_interpreter: /usr/bin/python3
</code></pre>
<ul>
<li><code>UserKnownHostsFile</code> causes the check of the host fingerprint on an always empty file (replacing the check inside <code>~/.ssh/known_hosts</code>)</li>
<li><code>StrictHostKeyChecking</code> allows ssh to connect without the user confirming the detected fingerprint from the vagrant host</li>
</ul>
",24000,2020-09-17T18:33:17.567,['vagrant-local:\n      ansible_host: 192.168.33.10\n      ansible_user: vagrant\n      ansible_ssh_private_key_file: .vagrant/machines/default/virtualbox/private_key\n      UserKnownHostsFile: /dev/null\n      StrictHostKeyChecking: no\n      ansible_python_interpreter: /usr/bin/python3\n']
1473,12435,12433,CC BY-SA 4.0,2020-09-18T01:41:56.757,"<p>The Dockerfile specifies how a container image is <em>built</em>.  The Dockerfile’s <code>RUN</code> command is trying to ping the <code>db</code> container, which is not yet running during the build phase.</p>
<p>Once the container images have been created, compose will start the containers and they will be able to address each other via their service names (<code>db</code> and <code>web</code>).</p>
<p>To accomplish what you want, an adjustment to your Dockerfile will need to be made.  Replace <code>RUN</code> with <code>CMD</code>.  This will allow the container to execute your ping command when it launches.</p>
<pre><code>FROM alpine
CMD ping -c 1 db
</code></pre>
<p>Now your <code>docker-compose up</code> will build the web image, launch the <code>db</code> container and then launch your <code>web</code> container which will successfully execute a ping:</p>
<pre><code>&gt; docker-compose up
Creating network &quot;simple_default&quot; with the default driver
Building web
Step 1/2 : FROM alpine
 ---&gt; a24bb4013296
Step 2/2 : CMD ping -c 1 db
 ---&gt; Running in 0c210f0936fd
Removing intermediate container 0c210f0936fd
 ---&gt; 7c0ed50ad4e8
Successfully built 7c0ed50ad4e8
Successfully tagged simple_web:latest
WARNING: Image for service web was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Creating simple_db_1 ... done
Creating simple_web_1 ... done
Attaching to simple_db_1, simple_web_1

... output omitted

web_1  | PING db (172.19.0.2): 56 data bytes
web_1  | 64 bytes from 172.19.0.2: seq=0 ttl=64 time=0.218 ms
web_1  |
web_1  | --- db ping statistics ---
web_1  | 1 packets transmitted, 1 packets received, 0% packet loss
web_1  | round-trip min/avg/max = 0.218/0.218/0.218 ms
db_1   |
db_1   | Data page checksums are disabled.
db_1   |
db_1   | fixing permissions on existing directory /var/lib/postgresql/data ... ok
db_1   | creating subdirectories ... ok
db_1   | selecting dynamic shared memory implementation ... posix
db_1   | selecting default max_connections ... 100
db_1   | selecting default shared_buffers ... 128MB
db_1   | selecting default time zone ... Etc/UTC
db_1   | creating configuration files ... ok
db_1   | running bootstrap script ... ok
db_1   | performing post-bootstrap initialization ... ok
simple_web_1 exited with code 0
</code></pre>
",6258,2020-09-22T19:44:49.707,"['FROM alpine\nCMD ping -c 1 db\n', '> docker-compose up\nCreating network ""simple_default"" with the default driver\nBuilding web\nStep 1/2 : FROM alpine\n ---> a24bb4013296\nStep 2/2 : CMD ping -c 1 db\n ---> Running in 0c210f0936fd\nRemoving intermediate container 0c210f0936fd\n ---> 7c0ed50ad4e8\nSuccessfully built 7c0ed50ad4e8\nSuccessfully tagged simple_web:latest\nWARNING: Image for service web was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.\nCreating simple_db_1 ... done\nCreating simple_web_1 ... done\nAttaching to simple_db_1, simple_web_1\n\n... output omitted\n\nweb_1  | PING db (172.19.0.2): 56 data bytes\nweb_1  | 64 bytes from 172.19.0.2: seq=0 ttl=64 time=0.218 ms\nweb_1  |\nweb_1  | --- db ping statistics ---\nweb_1  | 1 packets transmitted, 1 packets received, 0% packet loss\nweb_1  | round-trip min/avg/max = 0.218/0.218/0.218 ms\ndb_1   |\ndb_1   | Data page checksums are disabled.\ndb_1   |\ndb_1   | fixing permissions on existing directory /var/lib/postgresql/data ... ok\ndb_1   | creating subdirectories ... ok\ndb_1   | selecting dynamic shared memory implementation ... posix\ndb_1   | selecting default max_connections ... 100\ndb_1   | selecting default shared_buffers ... 128MB\ndb_1   | selecting default time zone ... Etc/UTC\ndb_1   | creating configuration files ... ok\ndb_1   | running bootstrap script ... ok\ndb_1   | performing post-bootstrap initialization ... ok\nsimple_web_1 exited with code 0\n']"
1474,12438,8329,CC BY-SA 4.0,2020-09-18T16:55:37.713,"<p>Adjust Jenkins job &quot;Build Environment&quot;
<a href=""https://i.stack.imgur.com/m83pi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/m83pi.png"" alt=""enter image description here"" /></a>
see <a href=""https://stackoverflow.com/questions/39829229/how-to-use-exclude-folder-option-in-delete-workspace-before-build-starts-secti/41728663"">https://stackoverflow.com/questions/39829229/how-to-use-exclude-folder-option-in-delete-workspace-before-build-starts-secti/41728663</a></p>
<p>also add build step with shell/windows script with</p>
<pre><code>npm install -D
</code></pre>
",24017,2020-09-18T20:26:26.087,['npm install -D\n']
1475,12445,3794,CC BY-SA 4.0,2020-09-21T04:47:10.360,"<p>Combining the answer of <a href=""https://devops.stackexchange.com/a/3854/10932"">https://devops.stackexchange.com/a/3854/10932</a> and the comment of Overbryd along with a slight modification worked for me. Here, instead of using using <strong>git remote set-url</strong> command, I used <strong>git remote add</strong>.</p>
<p>The code will look like this:</p>
<pre><code>image: maven

stages:
- build
- deploy
- tag

maven_build:
stage: build

  script:
   - mvn clean package
   artifacts:
  paths:
   - target/*.jar

  after_script:
   - ls -a
   - cd target &amp;&amp; ls -a
   - git --version
   - git remote remove origin
   - git remote add origin https://&quot;username:passwd&quot;@gitlab.com/accountname/projectname.git
   - git config user.email &quot;${GITLAB_USER_EMAIL}&quot;
   - git config user.name &quot;${GITLAB_USER_NAME}&quot;
   - git tag -a 1.0.15 -m &quot;Version created by gitlab-ci Build&quot;
   - git push origin 1.0.15
  only:
    - master
</code></pre>
<p>Thanks to both.</p>
",10932,2020-09-21T04:47:10.360,"['image: maven\n\nstages:\n- build\n- deploy\n- tag\n\nmaven_build:\nstage: build\n\n  script:\n   - mvn clean package\n   artifacts:\n  paths:\n   - target/*.jar\n\n  after_script:\n   - ls -a\n   - cd target && ls -a\n   - git --version\n   - git remote remove origin\n   - git remote add origin https://""username:passwd""@gitlab.com/accountname/projectname.git\n   - git config user.email ""${GITLAB_USER_EMAIL}""\n   - git config user.name ""${GITLAB_USER_NAME}""\n   - git tag -a 1.0.15 -m ""Version created by gitlab-ci Build""\n   - git push origin 1.0.15\n  only:\n    - master\n']"
1476,12451,12449,CC BY-SA 4.0,2020-09-21T14:02:18.863,"<p>Solution:</p>
<pre><code>root $ 
root $ mysql -h localhost -P 3306 --protocol=tcp -u user -p
Enter password: 
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 17
Server version: 8.0.21 MySQL Community Server - GPL

Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql&gt; 
mysql&gt; SELECT host, user FROM mysql.user;
+-----------+------------------+
| host      | user             |
+-----------+------------------+
| %         | user             |
| localhost | healthchecker    |
| localhost | mysql.infoschema |
| localhost | mysql.session    |
| localhost | mysql.sys        |
| localhost | root             |
+-----------+------------------+
6 rows in set (0.00 sec)

mysql&gt; 
</code></pre>
<p>per:</p>
<p><a href=""https://stackoverflow.com/q/33001750/4531180"">https://stackoverflow.com/q/33001750/4531180</a></p>
",23443,2020-09-21T14:08:01.893,"[""root $ \nroot $ mysql -h localhost -P 3306 --protocol=tcp -u user -p\nEnter password: \nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 17\nServer version: 8.0.21 MySQL Community Server - GPL\n\nCopyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nmysql> \nmysql> SELECT host, user FROM mysql.user;\n+-----------+------------------+\n| host      | user             |\n+-----------+------------------+\n| %         | user             |\n| localhost | healthchecker    |\n| localhost | mysql.infoschema |\n| localhost | mysql.session    |\n| localhost | mysql.sys        |\n| localhost | root             |\n+-----------+------------------+\n6 rows in set (0.00 sec)\n\nmysql> \n""]"
1477,12461,10669,CC BY-SA 4.0,2020-09-22T16:27:58.790,"<p>The following setup works for me.  When using the <code>subPath</code> in <code>volumeMounts</code>, the permission issue is automatically addressed, as the user <code>postgres</code> owns the folder corresponding to the <code>subPath</code>.</p>
<pre><code>    spec:
      ...
      containers:
        - ...
          volumeMounts:
            # need a subpath as postgres wants an empty folder (the mounted folder `/var/lib/postgresql/data` has a `lost+found` directory)
            # see https://stackoverflow.com/questions/51168558/how-to-mount-a-postgresql-volume-using-aws-ebs-in-kubernete
            # this is used together with the env var PGDATA = /var/lib/postgresql/data/pgdata (below)
            # the owner:group of this folder is 70:70 (postgres:postgres), done by this step in the docker image:
            # https://github.com/docker-library/postgres/blob/master/Dockerfile-alpine.template#L146
            - mountPath: /var/lib/postgresql/data
              subPath: pgdata
              name: my-postgres-pv
          ...
          env:
            # need to define PGDATA env var because not using the default /var/lib/postgresql/data, but a subpath under it.
            - name: PGDATA
              value: /var/lib/postgresql/data/pgdata
            ...
</code></pre>
",24042,2020-09-22T16:27:58.790,"['    spec:\n      ...\n      containers:\n        - ...\n          volumeMounts:\n            # need a subpath as postgres wants an empty folder (the mounted folder `/var/lib/postgresql/data` has a `lost+found` directory)\n            # see https://stackoverflow.com/questions/51168558/how-to-mount-a-postgresql-volume-using-aws-ebs-in-kubernete\n            # this is used together with the env var PGDATA = /var/lib/postgresql/data/pgdata (below)\n            # the owner:group of this folder is 70:70 (postgres:postgres), done by this step in the docker image:\n            # https://github.com/docker-library/postgres/blob/master/Dockerfile-alpine.template#L146\n            - mountPath: /var/lib/postgresql/data\n              subPath: pgdata\n              name: my-postgres-pv\n          ...\n          env:\n            # need to define PGDATA env var because not using the default /var/lib/postgresql/data, but a subpath under it.\n            - name: PGDATA\n              value: /var/lib/postgresql/data/pgdata\n            ...\n']"
1478,12468,12467,CC BY-SA 4.0,2020-09-23T03:01:30.953,"<p>I'm still fairly new to the Docker game, too, but I've got a few little projects that I do exactly what you are asking about. Through my own experience with trial &amp; error (mostly error...) I would suggest using a docker-compose.yml with your network set to static internal IPs so each container will have predictable, repeatable results and IPs that you can configure your containers to communicate across.</p>
<p>I'm not familiar with <code>BaseX</code> but I have a sample situation using docker-compose <code>version: &quot;3.7&quot;</code> here that could easily run multiple apps and/or be added to or repurposed to fit your hypothetical.</p>
<p>This example docker-compose has the following:</p>
<ul>
<li><p>A separate container for populating my <code>app-volume</code> volume with the contents of a public GitHub repo.</p>
</li>
<li><p>An Apache Web Server container with PHP-FPM enabled for a &quot;selective backend&quot; that gets built from a Dockerfile in the ~/dockerbuild directory.</p>
</li>
<li><p>An nginx web server container used as a reverse proxy for all things PHP to be passed to Apache (but serves &amp; caches pretty much everything else).</p>
</li>
<li><p>A MariaDB container in the mix for the app DB that I populate with a mysqldump file after the app gets built.</p>
</li>
</ul>
<p>This is a slimmed down version of my docker-compose.yml, so note that you can add a variety of things like <code>healthcheck:</code> and <code>command:</code> to fit your needs.</p>
<p>You execute with <code>docker-compose up -d --build</code> to both build and start your app in one command (but you'll probably want to create your own ba(.sh) file that you execute afterwards, too for those important finishing touches).</p>
<p>Take notice of <code>static-network</code>. And while I am using named volumes in the example, that's just a preference of mine.</p>
<pre><code>version: &quot;3.7&quot;

services:

  github_repo_clone:
    image: debian:latest
    container_name: github_repo_clone
    networks: 
      static-network:
        ipv4_address: 172.20.0.254

    command: bash -c &quot;
        apt-get update &amp;&amp; 
        apt-get install git -y &amp;&amp;
        rm -rf examplerepo &amp;&amp;
        git clone https://github.com/exampleuser/examplerepo.git &amp;&amp;
        rm -rf /var/www/vhosts/exampleuser/examplerepo &amp;&amp;
        mkdir -p /var/www/vhosts/exampleuser/examplerepo &amp;&amp;
        cp -rapv examplerepo/* /var/www/vhosts/exampleuser/examplerepo &amp;&amp;
        rm -rf examplerepo &amp;&amp;
        tail -f /dev/null
      &quot;
    volumes:
     - app-volume:/var/www/vhosts

  apache_php-fpm_backend:
    container_name: debian-build-demo0
    build: ~/dockerbuild
    ports:
     - &quot;8080:8080&quot;
    networks:
      static-network:
        ipv4_address: 172.20.0.2
    volumes:
     - app-volume:/var/www/vhosts


  nginx_rp:
    image: nginx:latest
    container_name: nginx-build-demo0
    ports:
     - &quot;80:80&quot;
     - &quot;443:443&quot;
    networks:
      static-network:
        ipv4_address: 172.20.0.3
    volumes:
     - app-volume:/var/www/vhosts

  mariadb:
    restart: always
    image: mariadb:latest
    container_name: mariadb-build-demo0
    ports:
     - &quot;3306:3306&quot;
    networks:
      static-network:
        ipv4_address: 172.20.0.10
    environment:
     - MYSQL_ROOT_PASSWORD=4007p@$$w04d
     - MYSQL_USER=dbusernamegoeshere
     - MYSQL_PASSWORD=@p@$$w04d
     - MYSQL_DATABASE=dbnamegoeshere
    volumes:
     - app-volume:/var/www/vhosts
    healthcheck:
      test: [&quot;CMD&quot;, &quot;mysqladmin&quot; ,&quot;ping&quot;, &quot;-h&quot;, &quot;localhost&quot;]
      timeout: 10s
      retries: 5

volumes:
  app-volume:
#    external: true

networks:
  static-network:
    driver: bridge
    ipam:
      driver: default
      config:
       - subnet: 172.20.0.0/16

</code></pre>
<p>My clean up command when I take the app down is kind of ugly, but not terribly difficult to read and goes something like this:
<code>docker-compose down -v ; docker rmi -f dockerbuild_apache_php-fpm_backend:latest mariadb:latest nginx:latest debian:latest ; docker rmi -f $(docker images -q --filter &quot;dangling=true&quot;) ; docker rmi -f $(docker images -q --filter label=stage=intermediate) ; docker volume prune -f; </code></p>
<p>I think each &quot;independent app&quot; could (and probably should) have its own docker-compose and/or Dockerfiles, but you may find synergies with certain Dockerfiles that you can create custom <code>command:</code> instructions for (such as the git_repo_clone example) to be used &amp; shared across multiple &quot;apps&quot;.</p>
",9877,2020-09-25T16:21:02.590,"['version: ""3.7""\n\nservices:\n\n  github_repo_clone:\n    image: debian:latest\n    container_name: github_repo_clone\n    networks: \n      static-network:\n        ipv4_address: 172.20.0.254\n\n    command: bash -c ""\n        apt-get update && \n        apt-get install git -y &&\n        rm -rf examplerepo &&\n        git clone https://github.com/exampleuser/examplerepo.git &&\n        rm -rf /var/www/vhosts/exampleuser/examplerepo &&\n        mkdir -p /var/www/vhosts/exampleuser/examplerepo &&\n        cp -rapv examplerepo/* /var/www/vhosts/exampleuser/examplerepo &&\n        rm -rf examplerepo &&\n        tail -f /dev/null\n      ""\n    volumes:\n     - app-volume:/var/www/vhosts\n\n  apache_php-fpm_backend:\n    container_name: debian-build-demo0\n    build: ~/dockerbuild\n    ports:\n     - ""8080:8080""\n    networks:\n      static-network:\n        ipv4_address: 172.20.0.2\n    volumes:\n     - app-volume:/var/www/vhosts\n\n\n  nginx_rp:\n    image: nginx:latest\n    container_name: nginx-build-demo0\n    ports:\n     - ""80:80""\n     - ""443:443""\n    networks:\n      static-network:\n        ipv4_address: 172.20.0.3\n    volumes:\n     - app-volume:/var/www/vhosts\n\n  mariadb:\n    restart: always\n    image: mariadb:latest\n    container_name: mariadb-build-demo0\n    ports:\n     - ""3306:3306""\n    networks:\n      static-network:\n        ipv4_address: 172.20.0.10\n    environment:\n     - MYSQL_ROOT_PASSWORD=4007p@$$w04d\n     - MYSQL_USER=dbusernamegoeshere\n     - MYSQL_PASSWORD=@p@$$w04d\n     - MYSQL_DATABASE=dbnamegoeshere\n    volumes:\n     - app-volume:/var/www/vhosts\n    healthcheck:\n      test: [""CMD"", ""mysqladmin"" ,""ping"", ""-h"", ""localhost""]\n      timeout: 10s\n      retries: 5\n\nvolumes:\n  app-volume:\n#    external: true\n\nnetworks:\n  static-network:\n    driver: bridge\n    ipam:\n      driver: default\n      config:\n       - subnet: 172.20.0.0/16\n\n']"
1479,12473,12469,CC BY-SA 4.0,2020-09-23T15:25:13.213,"<p>The Compose syntax <a href=""https://docs.docker.com/compose/compose-file/#domainname-hostname-ipc-mac_address-privileged-read_only-shm_size-stdin_open-tty-user-working_dir"" rel=""nofollow noreferrer"">allows you to specify</a> <code>user: &lt;uid&gt;:&lt;gid&gt;</code> in the service's configuration block.</p>
<p>For example:</p>
<pre><code>version: &quot;3&quot;
services:
  node-service:
    image: node
    user: 1001:1001
</code></pre>
<p>This will run the container as UID 1001 and GID 1001.</p>
",6258,2020-09-23T15:25:13.213,"['version: ""3""\nservices:\n  node-service:\n    image: node\n    user: 1001:1001\n']"
1480,12480,12469,CC BY-SA 4.0,2020-09-24T00:46:35.223,"<p>In your Dockerfile:</p>
<pre><code>ARG UID=1000
ARG GID=1000

RUN usermod -u $UID node &amp;&amp; groupmod -g $GID node
</code></pre>
<p>Then using <code>docker build</code>:</p>
<pre><code>docker build --build-arg UID=$(id -u) --build-arg GID=$(id -g) .
</code></pre>
<p>The <code>ARG</code> lines provide defaults. If you leave off the <code>--build-arg</code> flags, they will be used. If you do use the <code>--build-arg</code> flags values those will be used instead.</p>
",349,2020-09-24T00:46:35.223,"['ARG UID=1000\nARG GID=1000\n\nRUN usermod -u $UID node && groupmod -g $GID node\n', 'docker build --build-arg UID=$(id -u) --build-arg GID=$(id -g) .\n']"
1481,12483,12482,CC BY-SA 4.0,2020-09-24T06:28:36.590,"<p>horribly insecure:</p>
<pre><code>root $ 
root $ docker login
Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.
Username: nicksaunders
Password: 
WARNING! Your password will be stored unencrypted in /root/snap/docker/471/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded
root $ 
root $ docker images
REPOSITORY                   TAG                 IMAGE ID            CREATED             SIZE
helloworld_web               latest              3118807ab0e0        13 minutes ago      196MB
frappe/erpnext-nginx         latest              e417869e11ba        39 hours ago        414MB
frappe/erpnext-worker        latest              96559438dfec        40 hours ago        1.22GB
frappe/frappe-nginx          latest              3d006c375c6e        40 hours ago        410MB
frappe/frappe-worker         latest              961988528953        40 hours ago        1GB
frappe/frappe-socketio       latest              bca49f1b4a04        40 hours ago        180MB
frappe/bench                 latest              8c1bc9d3a572        40 hours ago        1.4GB
frappe/erpnext-docs-nginx    latest              7d117e2bd798        42 hours ago        428MB
frappe/erpnext-docs-worker   latest              a1c0b0511e92        42 hours ago        2.88GB
frappe/erpnext-worker        &lt;none&gt;              09be9dde8f8f        2 days ago          1.21GB
frappe/bench                 &lt;none&gt;              c775a49dee59        2 days ago          1.4GB
redis                        alpine              bd71e6db4a54        13 days ago         32.2MB
python                       3.7-alpine          295b051ee125        2 weeks ago         41.7MB
basex/basexhttp              latest              3339bf6bc898        3 weeks ago         226MB
twilio/twilio-java           latest              611ab7ece1cf        5 weeks ago         993MB
mysql                        latest              0d64f46acfd1        7 weeks ago         544MB
jetty                        latest              5f997007f18d        7 weeks ago         522MB
jitsi/web                    latest              1fad75476320        2 months ago        483MB
mysql/mysql-server           latest              8a3a24ad33be        2 months ago        366MB
hello-world                  latest              bf756fb1ae65        8 months ago        13.3kB
lukptr/erpnext7              latest              130f3d9f222f        14 months ago       3.59GB
root $ 
root $ docker tag helloworld_web nicksaunders/helloworld:firsttry
root $ 
root $ docker push nicksaunders/helloworld
The push refers to repository [docker.io/nicksaunders/helloworld]
fca41575e369: Pushed 
40f0977ea685: Pushing [==================================================&gt;]  12.08MB
f8b013a4d861: Pushed 
1d6d0bace1b8: Pushing [====&gt;                                              ]  13.03MB/143MB
aabee2d268fc: Pushed 
22ee430ae506: Waiting 
60faa6c61cf9: Waiting 
cfd52085ef94: Waiting 
408e53c5e3b2: Waiting 
50644c29ef5a: Waiting 
</code></pre>
<p>but <a href=""https://ropenscilabs.github.io/r-docker-tutorial/04-Dockerhub.html"" rel=""nofollow noreferrer"">seems</a> to work.</p>
",23443,2020-09-24T06:28:36.590,"[""root $ \nroot $ docker login\nLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.\nUsername: nicksaunders\nPassword: \nWARNING! Your password will be stored unencrypted in /root/snap/docker/471/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\nroot $ \nroot $ docker images\nREPOSITORY                   TAG                 IMAGE ID            CREATED             SIZE\nhelloworld_web               latest              3118807ab0e0        13 minutes ago      196MB\nfrappe/erpnext-nginx         latest              e417869e11ba        39 hours ago        414MB\nfrappe/erpnext-worker        latest              96559438dfec        40 hours ago        1.22GB\nfrappe/frappe-nginx          latest              3d006c375c6e        40 hours ago        410MB\nfrappe/frappe-worker         latest              961988528953        40 hours ago        1GB\nfrappe/frappe-socketio       latest              bca49f1b4a04        40 hours ago        180MB\nfrappe/bench                 latest              8c1bc9d3a572        40 hours ago        1.4GB\nfrappe/erpnext-docs-nginx    latest              7d117e2bd798        42 hours ago        428MB\nfrappe/erpnext-docs-worker   latest              a1c0b0511e92        42 hours ago        2.88GB\nfrappe/erpnext-worker        <none>              09be9dde8f8f        2 days ago          1.21GB\nfrappe/bench                 <none>              c775a49dee59        2 days ago          1.4GB\nredis                        alpine              bd71e6db4a54        13 days ago         32.2MB\npython                       3.7-alpine          295b051ee125        2 weeks ago         41.7MB\nbasex/basexhttp              latest              3339bf6bc898        3 weeks ago         226MB\ntwilio/twilio-java           latest              611ab7ece1cf        5 weeks ago         993MB\nmysql                        latest              0d64f46acfd1        7 weeks ago         544MB\njetty                        latest              5f997007f18d        7 weeks ago         522MB\njitsi/web                    latest              1fad75476320        2 months ago        483MB\nmysql/mysql-server           latest              8a3a24ad33be        2 months ago        366MB\nhello-world                  latest              bf756fb1ae65        8 months ago        13.3kB\nlukptr/erpnext7              latest              130f3d9f222f        14 months ago       3.59GB\nroot $ \nroot $ docker tag helloworld_web nicksaunders/helloworld:firsttry\nroot $ \nroot $ docker push nicksaunders/helloworld\nThe push refers to repository [docker.io/nicksaunders/helloworld]\nfca41575e369: Pushed \n40f0977ea685: Pushing [==================================================>]  12.08MB\nf8b013a4d861: Pushed \n1d6d0bace1b8: Pushing [====>                                              ]  13.03MB/143MB\naabee2d268fc: Pushed \n22ee430ae506: Waiting \n60faa6c61cf9: Waiting \ncfd52085ef94: Waiting \n408e53c5e3b2: Waiting \n50644c29ef5a: Waiting \n""]"
1482,12489,12487,CC BY-SA 4.0,2020-09-24T21:38:49.973,"<p>thought it was working because <code>docker-compose build</code> returned without errors.</p>
<p>I've tried a few URL's, but can't quite tell what happened:</p>
<pre><code>root $ 
root $ docker-compose up
Starting frappe_docker_erpnext-nginx_1 ... 
frappe_docker_mariadb_1 is up-to-date
frappe_docker_redis-cache_1 is up-to-date
Starting frappe_docker_traefik_1       ... 
frappe_docker_erpnext-python_1 is up-to-date
frappe_docker_redis-socketio_1 is up-to-date
frappe_docker_redis-queue_1 is up-to-date
Starting frappe_docker_site-creator_1  ... 
frappe_docker_frappe-socketio_1 is up-to-date
frappe_docker_erpnext-schedule_1 is up-to-date
Starting frappe_docker_erpnext-nginx_1 ... done
Starting frappe_docker_traefik_1       ... done
Starting frappe_docker_site-creator_1  ... done
Attaching to frappe_docker_mariadb_1, frappe_docker_redis-cache_1, frappe_docker_erpnext-python_1, frappe_docker_redis-socketio_1, frappe_docker_redis-queue_1, frappe_docker_frappe-socketio_1, frappe_docker_erpnext-schedule_1, frappe_docker_erpnext-worker-default_1, frappe_docker_erpnext-worker-short_1, frappe_docker_erpnext-worker-long_1, frappe_docker_site-creator_1, frappe_docker_erpnext-nginx_1, frappe_docker_traefik_1
erpnext-python_1          | Attempt 1 to connect to mariadb:3306
erpnext-python_1          | Attempt 2 to connect to mariadb:3306
erpnext-python_1          | Attempt 3 to connect to mariadb:3306
erpnext-python_1          | Attempt 4 to connect to mariadb:3306
erpnext-python_1          | Attempt 5 to connect to mariadb:3306
erpnext-python_1          | Attempt 1 to connect to redis-queue:6379
erpnext-python_1          | Attempt 1 to connect to redis-cache:6379
erpnext-python_1          | Attempt 1 to connect to redis-socketio:6379
erpnext-python_1          | Connections OK
erpnext-python_1          | [2020-09-24 21:42:51 +0000] [20] [INFO] Starting gunicorn 19.10.0
erpnext-python_1          | [2020-09-24 21:42:51 +0000] [20] [INFO] Listening at: http://0.0.0.0:8000 (20)
erpnext-python_1          | [2020-09-24 21:42:51 +0000] [20] [INFO] Using worker: gthread
erpnext-python_1          | [2020-09-24 21:42:51 +0000] [23] [INFO] Booting worker with pid: 23
erpnext-python_1          | [2020-09-24 21:42:51 +0000] [24] [INFO] Booting worker with pid: 24
erpnext-schedule_1        | Attempt 1 to connect to mariadb:3306
erpnext-schedule_1        | Attempt 1 to connect to redis-queue:6379
erpnext-schedule_1        | Attempt 1 to connect to redis-cache:6379
erpnext-schedule_1        | Attempt 1 to connect to redis-socketio:6379
erpnext-schedule_1        | Connections OK
erpnext-schedule_1        | Starting background scheduler . . .
erpnext-worker-long_1     | Attempt 1 to connect to mariadb:3306
erpnext-worker-long_1     | Attempt 1 to connect to redis-queue:6379
erpnext-worker-long_1     | Attempt 1 to connect to redis-cache:6379
erpnext-worker-long_1     | Attempt 1 to connect to redis-socketio:6379
erpnext-worker-long_1     | Connections OK
erpnext-worker-long_1     | 21:42:50 Worker rq:worker:9e230e83f0a54f2c9e23cf8c05803a5b.d7c672c3b8e4.13.long: started, version 1.5.2
erpnext-worker-long_1     | 21:42:50 *** Listening on long...
erpnext-worker-long_1     | 21:42:50 Cleaning registries for queue: long
erpnext-worker-short_1    | Attempt 1 to connect to mariadb:3306
erpnext-worker-short_1    | Attempt 1 to connect to redis-queue:6379
erpnext-worker-short_1    | Attempt 1 to connect to redis-cache:6379
erpnext-worker-short_1    | Attempt 1 to connect to redis-socketio:6379
erpnext-worker-short_1    | Connections OK
erpnext-worker-short_1    | 21:42:50 Worker rq:worker:2b7b866af6af496fa729c4ad20e78978.7da607a8d5a8.13.short: started, version 1.5.2
erpnext-worker-short_1    | 21:42:50 *** Listening on short...
erpnext-worker-short_1    | 21:42:50 Cleaning registries for queue: short
redis-queue_1             | 1:C 24 Sep 2020 21:42:20.656 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
redis-queue_1             | 1:C 24 Sep 2020 21:42:20.656 # Redis version=6.0.8, bits=64, commit=00000000, modified=0, pid=1, just started
redis-queue_1             | 1:C 24 Sep 2020 21:42:20.656 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf
redis-queue_1             | 1:M 24 Sep 2020 21:42:20.657 * Increased maximum number of open files to 10032 (it was originally set to 1024).
redis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * Running mode=standalone, port=6379.
redis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 # Server initialized
redis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
redis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * Loading RDB produced by version 6.0.8
redis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * RDB age 37 seconds
redis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * RDB memory usage when created 0.83 Mb
redis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * DB loaded from disk: 0.000 seconds
redis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * Ready to accept connections
mariadb_1                 | 2020-09-24 21:42:14+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 1:10.3.24+maria~focal started.
mariadb_1                 | 2020-09-24 21:42:15+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'
mariadb_1                 | 2020-09-24 21:42:15+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 1:10.3.24+maria~focal started.
mariadb_1                 | 2020-09-24 21:42:16 0 [Note] mysqld (mysqld 10.3.24-MariaDB-1:10.3.24+maria~focal) starting as process 1 ...
mariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Using Linux native AIO
mariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
mariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Uses event mutexes
mariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Compressed tables use zlib 1.2.11
mariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Number of pools: 1
mariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Using generic crc32 instructions
mariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Initializing buffer pool, total size = 256M, instances = 1, chunk size = 128M
mariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Completed initialization of buffer pool
mariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority().
mariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: 128 out of 128 rollback segments are active.
mariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: Creating shared tablespace for temporary tables
mariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ...
mariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: File './ibtmp1' size is now 12 MB.
mariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: 10.3.24 started; log sequence number 39389994; transaction id 12198
mariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool
mariadb_1                 | 2020-09-24 21:42:31 0 [Note] Plugin 'FEEDBACK' is disabled.
mariadb_1                 | 2020-09-24 21:42:32 0 [Note] Server socket created on IP: '::'.
mariadb_1                 | 2020-09-24 21:42:32 0 [Warning] 'proxies_priv' entry '@% root@ae9b03a0d7ee' ignored in --skip-name-resolve mode.
mariadb_1                 | 2020-09-24 21:42:32 0 [Note] Reading of all Master_info entries succeeded
mariadb_1                 | 2020-09-24 21:42:32 0 [Note] Added new Master_info '' to hash table
mariadb_1                 | 2020-09-24 21:42:32 0 [Note] mysqld: ready for connections.
mariadb_1                 | Version: '10.3.24-MariaDB-1:10.3.24+maria~focal'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  mariadb.org binary distribution
mariadb_1                 | 2020-09-24 21:43:04 0 [Note] InnoDB: Buffer pool(s) load completed at 200924 21:43:04
erpnext-worker-default_1  | Attempt 1 to connect to mariadb:3306
erpnext-worker-default_1  | Attempt 1 to connect to redis-queue:6379
erpnext-worker-default_1  | Attempt 1 to connect to redis-cache:6379
erpnext-worker-default_1  | Attempt 1 to connect to redis-socketio:6379
erpnext-worker-default_1  | Connections OK
erpnext-worker-default_1  | 21:42:50 Worker rq:worker:1c434d0c9d5d4d61874e73a1eab8cad6.f18a505e3d01.14.default: started, version 1.5.2
erpnext-worker-default_1  | 21:42:50 *** Listening on default...
erpnext-worker-default_1  | 21:42:50 Cleaning registries for queue: default
redis-cache_1             | 1:C 24 Sep 2020 21:42:19.998 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
redis-cache_1             | 1:C 24 Sep 2020 21:42:19.998 # Redis version=6.0.8, bits=64, commit=00000000, modified=0, pid=1, just started
redis-cache_1             | 1:C 24 Sep 2020 21:42:19.998 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf
redis-cache_1             | 1:M 24 Sep 2020 21:42:20.000 * Increased maximum number of open files to 10032 (it was originally set to 1024).
redis-cache_1             | 1:M 24 Sep 2020 21:42:20.266 * Running mode=standalone, port=6379.
redis-cache_1             | 1:M 24 Sep 2020 21:42:20.266 # Server initialized
redis-cache_1             | 1:M 24 Sep 2020 21:42:20.266 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
redis-cache_1             | 1:M 24 Sep 2020 21:42:20.267 * Loading RDB produced by version 6.0.8
redis-cache_1             | 1:M 24 Sep 2020 21:42:20.267 * RDB age 37 seconds
redis-cache_1             | 1:M 24 Sep 2020 21:42:20.267 * RDB memory usage when created 1.33 Mb
redis-cache_1             | 1:M 24 Sep 2020 21:42:20.269 * DB loaded from disk: 0.003 seconds
redis-cache_1             | 1:M 24 Sep 2020 21:42:20.269 * Ready to accept connections
frappe-socketio_1         | listening on *: 9000
redis-socketio_1          | 1:C 24 Sep 2020 21:42:24.894 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
redis-socketio_1          | 1:C 24 Sep 2020 21:42:24.894 # Redis version=6.0.8, bits=64, commit=00000000, modified=0, pid=1, just started
redis-socketio_1          | 1:C 24 Sep 2020 21:42:24.894 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf
redis-socketio_1          | 1:M 24 Sep 2020 21:42:24.895 * Increased maximum number of open files to 10032 (it was originally set to 1024).
redis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * Running mode=standalone, port=6379.
redis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 # Server initialized
redis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
redis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * Loading RDB produced by version 6.0.8
redis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * RDB age 41 seconds
redis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * RDB memory usage when created 0.79 Mb
redis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * DB loaded from disk: 0.000 seconds
redis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * Ready to accept connections
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=info msg=&quot;Configuration loaded from flags.&quot;
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=info msg=&quot;Traefik version 2.2.11 built on 2020-09-07T14:12:48Z&quot;
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Static configuration loaded {\&quot;global\&quot;:{\&quot;checkNewVersion\&quot;:true},\&quot;serversTransport\&quot;:{\&quot;maxIdleConnsPerHost\&quot;:200},\&quot;entryPoints\&quot;:{\&quot;web\&quot;:{\&quot;address\&quot;:\&quot;:80\&quot;,\&quot;transport\&quot;:{\&quot;lifeCycle\&quot;:{\&quot;graceTimeOut\&quot;:10000000000},\&quot;respondingTimeouts\&quot;:{\&quot;idleTimeout\&quot;:180000000000}},\&quot;forwardedHeaders\&quot;:{},\&quot;http\&quot;:{}},\&quot;websecure\&quot;:{\&quot;address\&quot;:\&quot;:443\&quot;,\&quot;transport\&quot;:{\&quot;lifeCycle\&quot;:{\&quot;graceTimeOut\&quot;:10000000000},\&quot;respondingTimeouts\&quot;:{\&quot;idleTimeout\&quot;:180000000000}},\&quot;forwardedHeaders\&quot;:{},\&quot;http\&quot;:{}}},\&quot;providers\&quot;:{\&quot;providersThrottleDuration\&quot;:2000000000,\&quot;docker\&quot;:{\&quot;watch\&quot;:true,\&quot;endpoint\&quot;:\&quot;unix:///var/run/docker.sock\&quot;,\&quot;defaultRule\&quot;:\&quot;Host(`{{ normalize .Name }}`)\&quot;,\&quot;swarmModeRefreshSeconds\&quot;:15000000000}},\&quot;log\&quot;:{\&quot;level\&quot;:\&quot;DEBUG\&quot;,\&quot;format\&quot;:\&quot;common\&quot;},\&quot;certificatesResolvers\&quot;:{\&quot;myresolver\&quot;:{\&quot;acme\&quot;:{\&quot;email\&quot;:\&quot;saunders.nicholas@gmail.com\&quot;,\&quot;caServer\&quot;:\&quot;https://acme-v02.api.letsencrypt.org/directory\&quot;,\&quot;storage\&quot;:\&quot;/letsencrypt/acme.json\&quot;,\&quot;keyType\&quot;:\&quot;RSA4096\&quot;,\&quot;httpChallenge\&quot;:{\&quot;entryPoint\&quot;:\&quot;web\&quot;}}}}}&quot;
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=info msg=&quot;\nStats collection is disabled.\nHelp us improve Traefik by turning this feature on :)\nMore details on: https://docs.traefik.io/contributing/data-collection/\n&quot;
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=info msg=&quot;Starting provider aggregator.ProviderAggregator {}&quot;
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Start TCP Server&quot; entryPointName=web
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Start TCP Server&quot; entryPointName=websecure
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=info msg=&quot;Starting provider *acme.Provider {\&quot;email\&quot;:\&quot;saunders.nicholas@gmail.com\&quot;,\&quot;caServer\&quot;:\&quot;https://acme-v02.api.letsencrypt.org/directory\&quot;,\&quot;storage\&quot;:\&quot;/letsencrypt/acme.json\&quot;,\&quot;keyType\&quot;:\&quot;RSA4096\&quot;,\&quot;httpChallenge\&quot;:{\&quot;entryPoint\&quot;:\&quot;web\&quot;},\&quot;ResolverName\&quot;:\&quot;myresolver\&quot;,\&quot;store\&quot;:{},\&quot;ChallengeStore\&quot;:{}}&quot;
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=info msg=&quot;Testing certificate renew...&quot; providerName=myresolver.acme
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=info msg=&quot;Starting provider *docker.Provider {\&quot;watch\&quot;:true,\&quot;endpoint\&quot;:\&quot;unix:///var/run/docker.sock\&quot;,\&quot;defaultRule\&quot;:\&quot;Host(`{{ normalize .Name }}`)\&quot;,\&quot;swarmModeRefreshSeconds\&quot;:15000000000}&quot;
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Configuration received from provider myresolver.acme: {\&quot;http\&quot;:{},\&quot;tls\&quot;:{}}&quot; providerName=myresolver.acme
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=info msg=&quot;Starting provider *traefik.Provider {}&quot;
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;No default certificate, generating one&quot;
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Configuration received from provider internal: {\&quot;http\&quot;:{\&quot;services\&quot;:{\&quot;noop\&quot;:{}}},\&quot;tcp\&quot;:{},\&quot;tls\&quot;:{}}&quot; providerName=internal
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Provider connection established with docker 19.03.11 (API 1.40)&quot; providerName=docker
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Filtering disabled container&quot; providerName=docker container=frappe-socketio-frappe-docker-547893b784969e960c010590b90d256a5844d4eda6bef53402117f25fd6cd835
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Filtering disabled container&quot; providerName=docker container=erpnext-worker-long-frappe-docker-d7c672c3b8e46b1ddbdea4540aaae117852a22cdc04cbddb6a4c9aa5f678849b
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Filtering disabled container&quot; providerName=docker container=erpnext-schedule-frappe-docker-16916a30304b6f542c219ed353f1c924fcd6d9142f4ab17e101eab8adc3b2f4f
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Filtering disabled container&quot; providerName=docker container=erpnext-worker-default-frappe-docker-f18a505e3d01d1fc0741cfdc15ff33d0188e9e4de5852e3c760eb22a066749b9
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Filtering disabled container&quot; providerName=docker container=erpnext-worker-short-frappe-docker-7da607a8d5a81077d1dd500f9ed6888f84cfbcbd7dd2efab11565611a66f2e2a
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Filtering disabled container&quot; providerName=docker container=site-creator-frappe-docker-6ea0246bf12dbaf11c684dbecc9dd449b30f38930610b3a6bdd6fcc31a416b92
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Filtering disabled container&quot; providerName=docker container=mariadb-frappe-docker-70879517dbbf4ed9c84627f8b312709a56832e423df82715ad0db82c1ed5321b
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Filtering disabled container&quot; providerName=docker container=redis-socketio-frappe-docker-e1b06e870f32304b7dcc863a2fef341d0642a929cd721a9220af1c9f845cdf9c
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Filtering disabled container&quot; providerName=docker container=erpnext-python-frappe-docker-b8ef2a1cd6858a6a7aa2517928dddffc2dfde713090a6d160847a641288521c6
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Filtering disabled container&quot; providerName=docker container=redis-cache-frappe-docker-d7cbac8c826b3c00cb5a699d89d8dd261b6efecdcf75e0e5117459b3a2b1ac57
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Filtering disabled container&quot; providerName=docker container=redis-queue-frappe-docker-4d6c6ed96e2a4da4d7efa21299e6ea9fb74f09bdc466fd878598f5cd288090ad
traefik_1                 | time=&quot;2020-09-24T21:46:16Z&quot; level=debug msg=&quot;Configuration received from provider docker: {\&quot;http\&quot;:{\&quot;routers\&quot;:{\&quot;erpnext-nginx\&quot;:{\&quot;entryPoints\&quot;:[\&quot;websecure\&quot;],\&quot;service\&quot;:\&quot;erpnext-nginx\&quot;,\&quot;rule\&quot;:\&quot;Host(`erp.saundersconsulting.tech)\&quot;,\&quot;tls\&quot;:{\&quot;certResolver\&quot;:\&quot;myresolver\&quot;}},\&quot;http-catchall\&quot;:{\&quot;entryPoints\&quot;:[\&quot;web\&quot;],\&quot;middlewares\&quot;:[\&quot;redirect-to-https\&quot;],\&quot;service\&quot;:\&quot;traefik-frappe-docker\&quot;,\&quot;rule\&quot;:\&quot;hostregexp(`{host:.+}`)\&quot;}},\&quot;services\&quot;:{\&quot;erpnext-nginx\&quot;:{\&quot;loadBalancer\&quot;:{\&quot;servers\&quot;:[{\&quot;url\&quot;:\&quot;http://172.20.0.4:80\&quot;}],\&quot;passHostHeader\&quot;:true}},\&quot;traefik-frappe-docker\&quot;:{\&quot;loadBalancer\&quot;:{\&quot;servers\&quot;:[{\&quot;url\&quot;:\&quot;http://172.20.0.14:80\&quot;}],\&quot;passHostHeader\&quot;:true}}},\&quot;middlewares\&quot;:{\&quot;redirect-to-https\&quot;:{\&quot;redirectScheme\&quot;:{\&quot;scheme\&quot;:\&quot;https\&quot;}}}},\&quot;tcp\&quot;:{},\&quot;udp\&quot;:{}}&quot; providerName=docker
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;No default certificate, generating one&quot;
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Creating middleware&quot; middlewareName=pipelining middlewareType=Pipelining entryPointName=web routerName=http-catchall@docker serviceName=traefik-frappe-docker
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Creating load-balancer&quot; entryPointName=web routerName=http-catchall@docker serviceName=traefik-frappe-docker
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Creating server 0 http://172.20.0.14:80&quot; entryPointName=web routerName=http-catchall@docker serverName=0 serviceName=traefik-frappe-docker
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Added outgoing tracing middleware traefik-frappe-docker&quot; middlewareName=tracing middlewareType=TracingForwarder entryPointName=web routerName=http-catchall@docker
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Creating middleware&quot; middlewareType=RedirectScheme entryPointName=web routerName=http-catchall@docker middlewareName=redirect-to-https@docker
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Setting up redirection to https &quot; middlewareType=RedirectScheme entryPointName=web routerName=http-catchall@docker middlewareName=redirect-to-https@docker
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Adding tracing to middleware&quot; entryPointName=web routerName=http-catchall@docker middlewareName=redirect-to-https@docker
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Creating middleware&quot; entryPointName=web middlewareType=Recovery middlewareName=traefik-internal-recovery
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Creating middleware&quot; routerName=erpnext-nginx@docker serviceName=erpnext-nginx middlewareName=pipelining middlewareType=Pipelining entryPointName=websecure
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Creating load-balancer&quot; entryPointName=websecure routerName=erpnext-nginx@docker serviceName=erpnext-nginx
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Creating server 0 http://172.20.0.4:80&quot; entryPointName=websecure routerName=erpnext-nginx@docker serviceName=erpnext-nginx serverName=0
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Added outgoing tracing middleware erpnext-nginx&quot; middlewareName=tracing middlewareType=TracingForwarder routerName=erpnext-nginx@docker entryPointName=websecure
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=error msg=&quot;error while parsing rule Host(`erp.saundersconsulting.tech): 1:6: raw string literal not terminated&quot; routerName=erpnext-nginx@docker entryPointName=websecure
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;Creating middleware&quot; entryPointName=websecure middlewareName=traefik-internal-recovery middlewareType=Recovery
traefik_1                 | time=&quot;2020-09-24T21:46:17Z&quot; level=debug msg=&quot;No default certificate, generating one&quot;
traefik_1                 | time=&quot;2020-09-24T21:46:18Z&quot; level=error msg=&quot;Error parsing domains in provider ACME: 1:6: raw string literal not terminated&quot; providerName=myresolver.acme routerName=erpnext-nginx@docker rule=&quot;Host(`erp.saundersconsulting.tech)&quot;
site-creator_1            | Attempt 1 to connect to mariadb:3306
site-creator_1            | Attempt 1 to connect to redis-queue:6379
site-creator_1            | Attempt 1 to connect to redis-cache:6379
site-creator_1            | Attempt 1 to connect to redis-socketio:6379
site-creator_1            | Connections OK
site-creator_1            | Site erp.saundersconsulting.tech already exists
traefik_1                 | time=&quot;2020-09-24T21:46:26Z&quot; level=debug msg=&quot;Provider event received {Status:die ID:6ea0246bf12dbaf11c684dbecc9dd449b30f38930610b3a6bdd6fcc31a416b92 From:frappe/erpnext-worker:edge Type:container Action:die Actor:{ID:6ea0246bf12dbaf11c684dbecc9dd449b30f38930610b3a6bdd6fcc31a416b92 Attributes:map[com.docker.compose.config-
</code></pre>
<p>...</p>
<pre><code>traefik_1                 | time=&quot;2020-09-24T21:46:30Z&quot; level=debug msg=&quot;Filtering disabled container&quot; container=redis-queue-frappe-docker-4d6c6ed96e2a4da4d7efa21299e6ea9fb74f09bdc466fd878598f5cd288090ad providerName=docker
traefik_1                 | time=&quot;2020-09-24T21:46:30Z&quot; level=debug msg=&quot;Configuration received from provider docker: {\&quot;http\&quot;:{\&quot;routers\&quot;:{\&quot;erpnext-nginx\&quot;:{\&quot;entryPoints\&quot;:[\&quot;websecure\&quot;],\&quot;service\&quot;:\&quot;erpnext-nginx\&quot;,\&quot;rule\&quot;:\&quot;Host(`erp.saundersconsulting.tech)\&quot;,\&quot;tls\&quot;:{\&quot;certResolver\&quot;:\&quot;myresolver\&quot;}},\&quot;http-catchall\&quot;:{\&quot;entryPoints\&quot;:[\&quot;web\&quot;],\&quot;middlewares\&quot;:[\&quot;redirect-to-https\&quot;],\&quot;service\&quot;:\&quot;traefik-frappe-docker\&quot;,\&quot;rule\&quot;:\&quot;hostregexp(`{host:.+}`)\&quot;}},\&quot;services\&quot;:{\&quot;erpnext-nginx\&quot;:{\&quot;loadBalancer\&quot;:{\&quot;servers\&quot;:[{\&quot;url\&quot;:\&quot;http://172.20.0.4:80\&quot;}],\&quot;passHostHeader\&quot;:true}},\&quot;traefik-frappe-docker\&quot;:{\&quot;loadBalancer\&quot;:{\&quot;servers\&quot;:[{\&quot;url\&quot;:\&quot;http://172.20.0.14:80\&quot;}],\&quot;passHostHeader\&quot;:true}}},\&quot;middlewares\&quot;:{\&quot;redirect-to-https\&quot;:{\&quot;redirectScheme\&quot;:{\&quot;scheme\&quot;:\&quot;https\&quot;}}}},\&quot;tcp\&quot;:{},\&quot;udp\&quot;:{}}&quot; providerName=docker
traefik_1                 | time=&quot;2020-09-24T21:46:30Z&quot; level=info msg=&quot;Skipping same configuration&quot; providerName=docker
erpnext-nginx_1           | Waiting for frappe-python to be available on erpnext-python port 8000
erpnext-nginx_1           | Frappe-python available on erpnext-python port 8000
erpnext-nginx_1           | Waiting for frappe-socketio to be available on frappe-socketio port 9000
erpnext-nginx_1           | Frappe-socketio available on frappe-socketio port 9000
redis-cache_1             | 1:M 24 Sep 2020 21:47:21.055 * 100 changes in 300 seconds. Saving...
redis-cache_1             | 1:M 24 Sep 2020 21:47:21.056 * Background saving started by pid 18
redis-cache_1             | 18:C 24 Sep 2020 21:47:21.107 * DB saved on disk
redis-cache_1             | 18:C 24 Sep 2020 21:47:21.108 * RDB: 0 MB of memory used by copy-on-write
redis-cache_1             | 1:M 24 Sep 2020 21:47:21.156 * Background saving terminated with success
traefik_1                 | time=&quot;2020-09-24T21:50:09Z&quot; level=debug msg=&quot;Serving default certificate for request: \&quot;localhost\&quot;&quot;
traefik_1                 | time=&quot;2020-09-24T21:50:09Z&quot; level=debug msg=&quot;http: TLS handshake error from 172.20.0.1:40102: remote error: tls: bad certificate&quot;
traefik_1                 | time=&quot;2020-09-24T21:50:14Z&quot; level=debug msg=&quot;Serving default certificate for request: \&quot;localhost\&quot;&quot;
 
</code></pre>
<p>Looking at the below <code>entrypoint</code>:</p>
<pre><code>root $ 
root $ docker container ls
CONTAINER ID        IMAGE                         COMMAND                  CREATED             STATUS              PORTS                                      NAMES
547893b78496        frappe/frappe-socketio:edge   &quot;docker-entrypoint.s…&quot;   11 minutes ago      Up 11 minutes                                                  frappe_docker_frappe-socketio_1
d7c672c3b8e4        frappe/erpnext-worker:edge    &quot;docker-entrypoint.s…&quot;   11 minutes ago      Up 11 minutes       8000/tcp                                   frappe_docker_erpnext-worker-long_1
16916a30304b        frappe/erpnext-worker:edge    &quot;docker-entrypoint.s…&quot;   11 minutes ago      Up 11 minutes       8000/tcp                                   frappe_docker_erpnext-schedule_1
f18a505e3d01        frappe/erpnext-worker:edge    &quot;docker-entrypoint.s…&quot;   11 minutes ago      Up 11 minutes       8000/tcp                                   frappe_docker_erpnext-worker-default_1
7da607a8d5a8        frappe/erpnext-worker:edge    &quot;docker-entrypoint.s…&quot;   11 minutes ago      Up 11 minutes       8000/tcp                                   frappe_docker_erpnext-worker-short_1
70879517dbbf        mariadb:10.3                  &quot;docker-entrypoint.s…&quot;   11 minutes ago      Up 11 minutes       3306/tcp                                   frappe_docker_mariadb_1
e1b06e870f32        redis:latest                  &quot;docker-entrypoint.s…&quot;   11 minutes ago      Up 11 minutes       6379/tcp                                   frappe_docker_redis-socketio_1
b8ef2a1cd685        frappe/erpnext-worker:edge    &quot;docker-entrypoint.s…&quot;   11 minutes ago      Up 11 minutes       8000/tcp                                   frappe_docker_erpnext-python_1
d6555ff0f12f        traefik:v2.2                  &quot;/entrypoint.sh --lo…&quot;   11 minutes ago      Up 7 minutes        0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp   frappe_docker_traefik_1
d7cbac8c826b        redis:latest                  &quot;docker-entrypoint.s…&quot;   11 minutes ago      Up 11 minutes       6379/tcp                                   frappe_docker_redis-cache_1
55b3a31ee25c        frappe/erpnext-nginx:edge     &quot;/docker-entrypoint.…&quot;   11 minutes ago      Up 7 minutes        80/tcp                                     frappe_docker_erpnext-nginx_1
4d6c6ed96e2a        redis:latest                  &quot;docker-entrypoint.s…&quot;   11 minutes ago      Up 11 minutes       6379/tcp                                   frappe_docker_redis-queue_1
root $ 
</code></pre>
<p>I tried a few of those ports, best result was a <code>404</code> from <code>localhost</code> on Firefox which I <em>think</em> was from this unconfigured app.</p>
<p>Quite possibly everything's working as intended, but simply needs configuration.</p>
",23443,2020-09-24T22:06:54.947,"['root $ \nroot $ docker-compose up\nStarting frappe_docker_erpnext-nginx_1 ... \nfrappe_docker_mariadb_1 is up-to-date\nfrappe_docker_redis-cache_1 is up-to-date\nStarting frappe_docker_traefik_1       ... \nfrappe_docker_erpnext-python_1 is up-to-date\nfrappe_docker_redis-socketio_1 is up-to-date\nfrappe_docker_redis-queue_1 is up-to-date\nStarting frappe_docker_site-creator_1  ... \nfrappe_docker_frappe-socketio_1 is up-to-date\nfrappe_docker_erpnext-schedule_1 is up-to-date\nStarting frappe_docker_erpnext-nginx_1 ... done\nStarting frappe_docker_traefik_1       ... done\nStarting frappe_docker_site-creator_1  ... done\nAttaching to frappe_docker_mariadb_1, frappe_docker_redis-cache_1, frappe_docker_erpnext-python_1, frappe_docker_redis-socketio_1, frappe_docker_redis-queue_1, frappe_docker_frappe-socketio_1, frappe_docker_erpnext-schedule_1, frappe_docker_erpnext-worker-default_1, frappe_docker_erpnext-worker-short_1, frappe_docker_erpnext-worker-long_1, frappe_docker_site-creator_1, frappe_docker_erpnext-nginx_1, frappe_docker_traefik_1\nerpnext-python_1          | Attempt 1 to connect to mariadb:3306\nerpnext-python_1          | Attempt 2 to connect to mariadb:3306\nerpnext-python_1          | Attempt 3 to connect to mariadb:3306\nerpnext-python_1          | Attempt 4 to connect to mariadb:3306\nerpnext-python_1          | Attempt 5 to connect to mariadb:3306\nerpnext-python_1          | Attempt 1 to connect to redis-queue:6379\nerpnext-python_1          | Attempt 1 to connect to redis-cache:6379\nerpnext-python_1          | Attempt 1 to connect to redis-socketio:6379\nerpnext-python_1          | Connections OK\nerpnext-python_1          | [2020-09-24 21:42:51 +0000] [20] [INFO] Starting gunicorn 19.10.0\nerpnext-python_1          | [2020-09-24 21:42:51 +0000] [20] [INFO] Listening at: http://0.0.0.0:8000 (20)\nerpnext-python_1          | [2020-09-24 21:42:51 +0000] [20] [INFO] Using worker: gthread\nerpnext-python_1          | [2020-09-24 21:42:51 +0000] [23] [INFO] Booting worker with pid: 23\nerpnext-python_1          | [2020-09-24 21:42:51 +0000] [24] [INFO] Booting worker with pid: 24\nerpnext-schedule_1        | Attempt 1 to connect to mariadb:3306\nerpnext-schedule_1        | Attempt 1 to connect to redis-queue:6379\nerpnext-schedule_1        | Attempt 1 to connect to redis-cache:6379\nerpnext-schedule_1        | Attempt 1 to connect to redis-socketio:6379\nerpnext-schedule_1        | Connections OK\nerpnext-schedule_1        | Starting background scheduler . . .\nerpnext-worker-long_1     | Attempt 1 to connect to mariadb:3306\nerpnext-worker-long_1     | Attempt 1 to connect to redis-queue:6379\nerpnext-worker-long_1     | Attempt 1 to connect to redis-cache:6379\nerpnext-worker-long_1     | Attempt 1 to connect to redis-socketio:6379\nerpnext-worker-long_1     | Connections OK\nerpnext-worker-long_1     | 21:42:50 Worker rq:worker:9e230e83f0a54f2c9e23cf8c05803a5b.d7c672c3b8e4.13.long: started, version 1.5.2\nerpnext-worker-long_1     | 21:42:50 *** Listening on long...\nerpnext-worker-long_1     | 21:42:50 Cleaning registries for queue: long\nerpnext-worker-short_1    | Attempt 1 to connect to mariadb:3306\nerpnext-worker-short_1    | Attempt 1 to connect to redis-queue:6379\nerpnext-worker-short_1    | Attempt 1 to connect to redis-cache:6379\nerpnext-worker-short_1    | Attempt 1 to connect to redis-socketio:6379\nerpnext-worker-short_1    | Connections OK\nerpnext-worker-short_1    | 21:42:50 Worker rq:worker:2b7b866af6af496fa729c4ad20e78978.7da607a8d5a8.13.short: started, version 1.5.2\nerpnext-worker-short_1    | 21:42:50 *** Listening on short...\nerpnext-worker-short_1    | 21:42:50 Cleaning registries for queue: short\nredis-queue_1             | 1:C 24 Sep 2020 21:42:20.656 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\nredis-queue_1             | 1:C 24 Sep 2020 21:42:20.656 # Redis version=6.0.8, bits=64, commit=00000000, modified=0, pid=1, just started\nredis-queue_1             | 1:C 24 Sep 2020 21:42:20.656 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\nredis-queue_1             | 1:M 24 Sep 2020 21:42:20.657 * Increased maximum number of open files to 10032 (it was originally set to 1024).\nredis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * Running mode=standalone, port=6379.\nredis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 # Server initialized\nredis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \'vm.overcommit_memory = 1\' to /etc/sysctl.conf and then reboot or run the command \'sysctl vm.overcommit_memory=1\' for this to take effect.\nredis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * Loading RDB produced by version 6.0.8\nredis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * RDB age 37 seconds\nredis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * RDB memory usage when created 0.83 Mb\nredis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * DB loaded from disk: 0.000 seconds\nredis-queue_1             | 1:M 24 Sep 2020 21:42:20.658 * Ready to accept connections\nmariadb_1                 | 2020-09-24 21:42:14+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 1:10.3.24+maria~focal started.\nmariadb_1                 | 2020-09-24 21:42:15+00:00 [Note] [Entrypoint]: Switching to dedicated user \'mysql\'\nmariadb_1                 | 2020-09-24 21:42:15+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 1:10.3.24+maria~focal started.\nmariadb_1                 | 2020-09-24 21:42:16 0 [Note] mysqld (mysqld 10.3.24-MariaDB-1:10.3.24+maria~focal) starting as process 1 ...\nmariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Using Linux native AIO\nmariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins\nmariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Uses event mutexes\nmariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Compressed tables use zlib 1.2.11\nmariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Number of pools: 1\nmariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Using generic crc32 instructions\nmariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Initializing buffer pool, total size = 256M, instances = 1, chunk size = 128M\nmariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: Completed initialization of buffer pool\nmariadb_1                 | 2020-09-24 21:42:16 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority().\nmariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: 128 out of 128 rollback segments are active.\nmariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: Creating shared tablespace for temporary tables\nmariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: Setting file \'./ibtmp1\' size to 12 MB. Physically writing the file full; Please wait ...\nmariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: File \'./ibtmp1\' size is now 12 MB.\nmariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: 10.3.24 started; log sequence number 39389994; transaction id 12198\nmariadb_1                 | 2020-09-24 21:42:31 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool\nmariadb_1                 | 2020-09-24 21:42:31 0 [Note] Plugin \'FEEDBACK\' is disabled.\nmariadb_1                 | 2020-09-24 21:42:32 0 [Note] Server socket created on IP: \'::\'.\nmariadb_1                 | 2020-09-24 21:42:32 0 [Warning] \'proxies_priv\' entry \'@% root@ae9b03a0d7ee\' ignored in --skip-name-resolve mode.\nmariadb_1                 | 2020-09-24 21:42:32 0 [Note] Reading of all Master_info entries succeeded\nmariadb_1                 | 2020-09-24 21:42:32 0 [Note] Added new Master_info \'\' to hash table\nmariadb_1                 | 2020-09-24 21:42:32 0 [Note] mysqld: ready for connections.\nmariadb_1                 | Version: \'10.3.24-MariaDB-1:10.3.24+maria~focal\'  socket: \'/var/run/mysqld/mysqld.sock\'  port: 3306  mariadb.org binary distribution\nmariadb_1                 | 2020-09-24 21:43:04 0 [Note] InnoDB: Buffer pool(s) load completed at 200924 21:43:04\nerpnext-worker-default_1  | Attempt 1 to connect to mariadb:3306\nerpnext-worker-default_1  | Attempt 1 to connect to redis-queue:6379\nerpnext-worker-default_1  | Attempt 1 to connect to redis-cache:6379\nerpnext-worker-default_1  | Attempt 1 to connect to redis-socketio:6379\nerpnext-worker-default_1  | Connections OK\nerpnext-worker-default_1  | 21:42:50 Worker rq:worker:1c434d0c9d5d4d61874e73a1eab8cad6.f18a505e3d01.14.default: started, version 1.5.2\nerpnext-worker-default_1  | 21:42:50 *** Listening on default...\nerpnext-worker-default_1  | 21:42:50 Cleaning registries for queue: default\nredis-cache_1             | 1:C 24 Sep 2020 21:42:19.998 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\nredis-cache_1             | 1:C 24 Sep 2020 21:42:19.998 # Redis version=6.0.8, bits=64, commit=00000000, modified=0, pid=1, just started\nredis-cache_1             | 1:C 24 Sep 2020 21:42:19.998 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\nredis-cache_1             | 1:M 24 Sep 2020 21:42:20.000 * Increased maximum number of open files to 10032 (it was originally set to 1024).\nredis-cache_1             | 1:M 24 Sep 2020 21:42:20.266 * Running mode=standalone, port=6379.\nredis-cache_1             | 1:M 24 Sep 2020 21:42:20.266 # Server initialized\nredis-cache_1             | 1:M 24 Sep 2020 21:42:20.266 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \'vm.overcommit_memory = 1\' to /etc/sysctl.conf and then reboot or run the command \'sysctl vm.overcommit_memory=1\' for this to take effect.\nredis-cache_1             | 1:M 24 Sep 2020 21:42:20.267 * Loading RDB produced by version 6.0.8\nredis-cache_1             | 1:M 24 Sep 2020 21:42:20.267 * RDB age 37 seconds\nredis-cache_1             | 1:M 24 Sep 2020 21:42:20.267 * RDB memory usage when created 1.33 Mb\nredis-cache_1             | 1:M 24 Sep 2020 21:42:20.269 * DB loaded from disk: 0.003 seconds\nredis-cache_1             | 1:M 24 Sep 2020 21:42:20.269 * Ready to accept connections\nfrappe-socketio_1         | listening on *: 9000\nredis-socketio_1          | 1:C 24 Sep 2020 21:42:24.894 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\nredis-socketio_1          | 1:C 24 Sep 2020 21:42:24.894 # Redis version=6.0.8, bits=64, commit=00000000, modified=0, pid=1, just started\nredis-socketio_1          | 1:C 24 Sep 2020 21:42:24.894 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\nredis-socketio_1          | 1:M 24 Sep 2020 21:42:24.895 * Increased maximum number of open files to 10032 (it was originally set to 1024).\nredis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * Running mode=standalone, port=6379.\nredis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 # Server initialized\nredis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add \'vm.overcommit_memory = 1\' to /etc/sysctl.conf and then reboot or run the command \'sysctl vm.overcommit_memory=1\' for this to take effect.\nredis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * Loading RDB produced by version 6.0.8\nredis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * RDB age 41 seconds\nredis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * RDB memory usage when created 0.79 Mb\nredis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * DB loaded from disk: 0.000 seconds\nredis-socketio_1          | 1:M 24 Sep 2020 21:42:24.896 * Ready to accept connections\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=info msg=""Configuration loaded from flags.""\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=info msg=""Traefik version 2.2.11 built on 2020-09-07T14:12:48Z""\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Static configuration loaded {\\""global\\"":{\\""checkNewVersion\\"":true},\\""serversTransport\\"":{\\""maxIdleConnsPerHost\\"":200},\\""entryPoints\\"":{\\""web\\"":{\\""address\\"":\\"":80\\"",\\""transport\\"":{\\""lifeCycle\\"":{\\""graceTimeOut\\"":10000000000},\\""respondingTimeouts\\"":{\\""idleTimeout\\"":180000000000}},\\""forwardedHeaders\\"":{},\\""http\\"":{}},\\""websecure\\"":{\\""address\\"":\\"":443\\"",\\""transport\\"":{\\""lifeCycle\\"":{\\""graceTimeOut\\"":10000000000},\\""respondingTimeouts\\"":{\\""idleTimeout\\"":180000000000}},\\""forwardedHeaders\\"":{},\\""http\\"":{}}},\\""providers\\"":{\\""providersThrottleDuration\\"":2000000000,\\""docker\\"":{\\""watch\\"":true,\\""endpoint\\"":\\""unix:///var/run/docker.sock\\"",\\""defaultRule\\"":\\""Host(`{{ normalize .Name }}`)\\"",\\""swarmModeRefreshSeconds\\"":15000000000}},\\""log\\"":{\\""level\\"":\\""DEBUG\\"",\\""format\\"":\\""common\\""},\\""certificatesResolvers\\"":{\\""myresolver\\"":{\\""acme\\"":{\\""email\\"":\\""saunders.nicholas@gmail.com\\"",\\""caServer\\"":\\""https://acme-v02.api.letsencrypt.org/directory\\"",\\""storage\\"":\\""/letsencrypt/acme.json\\"",\\""keyType\\"":\\""RSA4096\\"",\\""httpChallenge\\"":{\\""entryPoint\\"":\\""web\\""}}}}}""\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=info msg=""\\nStats collection is disabled.\\nHelp us improve Traefik by turning this feature on :)\\nMore details on: https://docs.traefik.io/contributing/data-collection/\\n""\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=info msg=""Starting provider aggregator.ProviderAggregator {}""\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Start TCP Server"" entryPointName=web\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Start TCP Server"" entryPointName=websecure\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=info msg=""Starting provider *acme.Provider {\\""email\\"":\\""saunders.nicholas@gmail.com\\"",\\""caServer\\"":\\""https://acme-v02.api.letsencrypt.org/directory\\"",\\""storage\\"":\\""/letsencrypt/acme.json\\"",\\""keyType\\"":\\""RSA4096\\"",\\""httpChallenge\\"":{\\""entryPoint\\"":\\""web\\""},\\""ResolverName\\"":\\""myresolver\\"",\\""store\\"":{},\\""ChallengeStore\\"":{}}""\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=info msg=""Testing certificate renew..."" providerName=myresolver.acme\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=info msg=""Starting provider *docker.Provider {\\""watch\\"":true,\\""endpoint\\"":\\""unix:///var/run/docker.sock\\"",\\""defaultRule\\"":\\""Host(`{{ normalize .Name }}`)\\"",\\""swarmModeRefreshSeconds\\"":15000000000}""\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Configuration received from provider myresolver.acme: {\\""http\\"":{},\\""tls\\"":{}}"" providerName=myresolver.acme\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=info msg=""Starting provider *traefik.Provider {}""\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""No default certificate, generating one""\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Configuration received from provider internal: {\\""http\\"":{\\""services\\"":{\\""noop\\"":{}}},\\""tcp\\"":{},\\""tls\\"":{}}"" providerName=internal\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Provider connection established with docker 19.03.11 (API 1.40)"" providerName=docker\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Filtering disabled container"" providerName=docker container=frappe-socketio-frappe-docker-547893b784969e960c010590b90d256a5844d4eda6bef53402117f25fd6cd835\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Filtering disabled container"" providerName=docker container=erpnext-worker-long-frappe-docker-d7c672c3b8e46b1ddbdea4540aaae117852a22cdc04cbddb6a4c9aa5f678849b\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Filtering disabled container"" providerName=docker container=erpnext-schedule-frappe-docker-16916a30304b6f542c219ed353f1c924fcd6d9142f4ab17e101eab8adc3b2f4f\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Filtering disabled container"" providerName=docker container=erpnext-worker-default-frappe-docker-f18a505e3d01d1fc0741cfdc15ff33d0188e9e4de5852e3c760eb22a066749b9\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Filtering disabled container"" providerName=docker container=erpnext-worker-short-frappe-docker-7da607a8d5a81077d1dd500f9ed6888f84cfbcbd7dd2efab11565611a66f2e2a\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Filtering disabled container"" providerName=docker container=site-creator-frappe-docker-6ea0246bf12dbaf11c684dbecc9dd449b30f38930610b3a6bdd6fcc31a416b92\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Filtering disabled container"" providerName=docker container=mariadb-frappe-docker-70879517dbbf4ed9c84627f8b312709a56832e423df82715ad0db82c1ed5321b\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Filtering disabled container"" providerName=docker container=redis-socketio-frappe-docker-e1b06e870f32304b7dcc863a2fef341d0642a929cd721a9220af1c9f845cdf9c\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Filtering disabled container"" providerName=docker container=erpnext-python-frappe-docker-b8ef2a1cd6858a6a7aa2517928dddffc2dfde713090a6d160847a641288521c6\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Filtering disabled container"" providerName=docker container=redis-cache-frappe-docker-d7cbac8c826b3c00cb5a699d89d8dd261b6efecdcf75e0e5117459b3a2b1ac57\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Filtering disabled container"" providerName=docker container=redis-queue-frappe-docker-4d6c6ed96e2a4da4d7efa21299e6ea9fb74f09bdc466fd878598f5cd288090ad\ntraefik_1                 | time=""2020-09-24T21:46:16Z"" level=debug msg=""Configuration received from provider docker: {\\""http\\"":{\\""routers\\"":{\\""erpnext-nginx\\"":{\\""entryPoints\\"":[\\""websecure\\""],\\""service\\"":\\""erpnext-nginx\\"",\\""rule\\"":\\""Host(`erp.saundersconsulting.tech)\\"",\\""tls\\"":{\\""certResolver\\"":\\""myresolver\\""}},\\""http-catchall\\"":{\\""entryPoints\\"":[\\""web\\""],\\""middlewares\\"":[\\""redirect-to-https\\""],\\""service\\"":\\""traefik-frappe-docker\\"",\\""rule\\"":\\""hostregexp(`{host:.+}`)\\""}},\\""services\\"":{\\""erpnext-nginx\\"":{\\""loadBalancer\\"":{\\""servers\\"":[{\\""url\\"":\\""http://172.20.0.4:80\\""}],\\""passHostHeader\\"":true}},\\""traefik-frappe-docker\\"":{\\""loadBalancer\\"":{\\""servers\\"":[{\\""url\\"":\\""http://172.20.0.14:80\\""}],\\""passHostHeader\\"":true}}},\\""middlewares\\"":{\\""redirect-to-https\\"":{\\""redirectScheme\\"":{\\""scheme\\"":\\""https\\""}}}},\\""tcp\\"":{},\\""udp\\"":{}}"" providerName=docker\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""No default certificate, generating one""\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Creating middleware"" middlewareName=pipelining middlewareType=Pipelining entryPointName=web routerName=http-catchall@docker serviceName=traefik-frappe-docker\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Creating load-balancer"" entryPointName=web routerName=http-catchall@docker serviceName=traefik-frappe-docker\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Creating server 0 http://172.20.0.14:80"" entryPointName=web routerName=http-catchall@docker serverName=0 serviceName=traefik-frappe-docker\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Added outgoing tracing middleware traefik-frappe-docker"" middlewareName=tracing middlewareType=TracingForwarder entryPointName=web routerName=http-catchall@docker\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Creating middleware"" middlewareType=RedirectScheme entryPointName=web routerName=http-catchall@docker middlewareName=redirect-to-https@docker\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Setting up redirection to https "" middlewareType=RedirectScheme entryPointName=web routerName=http-catchall@docker middlewareName=redirect-to-https@docker\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Adding tracing to middleware"" entryPointName=web routerName=http-catchall@docker middlewareName=redirect-to-https@docker\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Creating middleware"" entryPointName=web middlewareType=Recovery middlewareName=traefik-internal-recovery\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Creating middleware"" routerName=erpnext-nginx@docker serviceName=erpnext-nginx middlewareName=pipelining middlewareType=Pipelining entryPointName=websecure\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Creating load-balancer"" entryPointName=websecure routerName=erpnext-nginx@docker serviceName=erpnext-nginx\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Creating server 0 http://172.20.0.4:80"" entryPointName=websecure routerName=erpnext-nginx@docker serviceName=erpnext-nginx serverName=0\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Added outgoing tracing middleware erpnext-nginx"" middlewareName=tracing middlewareType=TracingForwarder routerName=erpnext-nginx@docker entryPointName=websecure\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=error msg=""error while parsing rule Host(`erp.saundersconsulting.tech): 1:6: raw string literal not terminated"" routerName=erpnext-nginx@docker entryPointName=websecure\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""Creating middleware"" entryPointName=websecure middlewareName=traefik-internal-recovery middlewareType=Recovery\ntraefik_1                 | time=""2020-09-24T21:46:17Z"" level=debug msg=""No default certificate, generating one""\ntraefik_1                 | time=""2020-09-24T21:46:18Z"" level=error msg=""Error parsing domains in provider ACME: 1:6: raw string literal not terminated"" providerName=myresolver.acme routerName=erpnext-nginx@docker rule=""Host(`erp.saundersconsulting.tech)""\nsite-creator_1            | Attempt 1 to connect to mariadb:3306\nsite-creator_1            | Attempt 1 to connect to redis-queue:6379\nsite-creator_1            | Attempt 1 to connect to redis-cache:6379\nsite-creator_1            | Attempt 1 to connect to redis-socketio:6379\nsite-creator_1            | Connections OK\nsite-creator_1            | Site erp.saundersconsulting.tech already exists\ntraefik_1                 | time=""2020-09-24T21:46:26Z"" level=debug msg=""Provider event received {Status:die ID:6ea0246bf12dbaf11c684dbecc9dd449b30f38930610b3a6bdd6fcc31a416b92 From:frappe/erpnext-worker:edge Type:container Action:die Actor:{ID:6ea0246bf12dbaf11c684dbecc9dd449b30f38930610b3a6bdd6fcc31a416b92 Attributes:map[com.docker.compose.config-\n', 'traefik_1                 | time=""2020-09-24T21:46:30Z"" level=debug msg=""Filtering disabled container"" container=redis-queue-frappe-docker-4d6c6ed96e2a4da4d7efa21299e6ea9fb74f09bdc466fd878598f5cd288090ad providerName=docker\ntraefik_1                 | time=""2020-09-24T21:46:30Z"" level=debug msg=""Configuration received from provider docker: {\\""http\\"":{\\""routers\\"":{\\""erpnext-nginx\\"":{\\""entryPoints\\"":[\\""websecure\\""],\\""service\\"":\\""erpnext-nginx\\"",\\""rule\\"":\\""Host(`erp.saundersconsulting.tech)\\"",\\""tls\\"":{\\""certResolver\\"":\\""myresolver\\""}},\\""http-catchall\\"":{\\""entryPoints\\"":[\\""web\\""],\\""middlewares\\"":[\\""redirect-to-https\\""],\\""service\\"":\\""traefik-frappe-docker\\"",\\""rule\\"":\\""hostregexp(`{host:.+}`)\\""}},\\""services\\"":{\\""erpnext-nginx\\"":{\\""loadBalancer\\"":{\\""servers\\"":[{\\""url\\"":\\""http://172.20.0.4:80\\""}],\\""passHostHeader\\"":true}},\\""traefik-frappe-docker\\"":{\\""loadBalancer\\"":{\\""servers\\"":[{\\""url\\"":\\""http://172.20.0.14:80\\""}],\\""passHostHeader\\"":true}}},\\""middlewares\\"":{\\""redirect-to-https\\"":{\\""redirectScheme\\"":{\\""scheme\\"":\\""https\\""}}}},\\""tcp\\"":{},\\""udp\\"":{}}"" providerName=docker\ntraefik_1                 | time=""2020-09-24T21:46:30Z"" level=info msg=""Skipping same configuration"" providerName=docker\nerpnext-nginx_1           | Waiting for frappe-python to be available on erpnext-python port 8000\nerpnext-nginx_1           | Frappe-python available on erpnext-python port 8000\nerpnext-nginx_1           | Waiting for frappe-socketio to be available on frappe-socketio port 9000\nerpnext-nginx_1           | Frappe-socketio available on frappe-socketio port 9000\nredis-cache_1             | 1:M 24 Sep 2020 21:47:21.055 * 100 changes in 300 seconds. Saving...\nredis-cache_1             | 1:M 24 Sep 2020 21:47:21.056 * Background saving started by pid 18\nredis-cache_1             | 18:C 24 Sep 2020 21:47:21.107 * DB saved on disk\nredis-cache_1             | 18:C 24 Sep 2020 21:47:21.108 * RDB: 0 MB of memory used by copy-on-write\nredis-cache_1             | 1:M 24 Sep 2020 21:47:21.156 * Background saving terminated with success\ntraefik_1                 | time=""2020-09-24T21:50:09Z"" level=debug msg=""Serving default certificate for request: \\""localhost\\""""\ntraefik_1                 | time=""2020-09-24T21:50:09Z"" level=debug msg=""http: TLS handshake error from 172.20.0.1:40102: remote error: tls: bad certificate""\ntraefik_1                 | time=""2020-09-24T21:50:14Z"" level=debug msg=""Serving default certificate for request: \\""localhost\\""""\n \n', 'root $ \nroot $ docker container ls\nCONTAINER ID        IMAGE                         COMMAND                  CREATED             STATUS              PORTS                                      NAMES\n547893b78496        frappe/frappe-socketio:edge   ""docker-entrypoint.s…""   11 minutes ago      Up 11 minutes                                                  frappe_docker_frappe-socketio_1\nd7c672c3b8e4        frappe/erpnext-worker:edge    ""docker-entrypoint.s…""   11 minutes ago      Up 11 minutes       8000/tcp                                   frappe_docker_erpnext-worker-long_1\n16916a30304b        frappe/erpnext-worker:edge    ""docker-entrypoint.s…""   11 minutes ago      Up 11 minutes       8000/tcp                                   frappe_docker_erpnext-schedule_1\nf18a505e3d01        frappe/erpnext-worker:edge    ""docker-entrypoint.s…""   11 minutes ago      Up 11 minutes       8000/tcp                                   frappe_docker_erpnext-worker-default_1\n7da607a8d5a8        frappe/erpnext-worker:edge    ""docker-entrypoint.s…""   11 minutes ago      Up 11 minutes       8000/tcp                                   frappe_docker_erpnext-worker-short_1\n70879517dbbf        mariadb:10.3                  ""docker-entrypoint.s…""   11 minutes ago      Up 11 minutes       3306/tcp                                   frappe_docker_mariadb_1\ne1b06e870f32        redis:latest                  ""docker-entrypoint.s…""   11 minutes ago      Up 11 minutes       6379/tcp                                   frappe_docker_redis-socketio_1\nb8ef2a1cd685        frappe/erpnext-worker:edge    ""docker-entrypoint.s…""   11 minutes ago      Up 11 minutes       8000/tcp                                   frappe_docker_erpnext-python_1\nd6555ff0f12f        traefik:v2.2                  ""/entrypoint.sh --lo…""   11 minutes ago      Up 7 minutes        0.0.0.0:80->80/tcp, 0.0.0.0:443->443/tcp   frappe_docker_traefik_1\nd7cbac8c826b        redis:latest                  ""docker-entrypoint.s…""   11 minutes ago      Up 11 minutes       6379/tcp                                   frappe_docker_redis-cache_1\n55b3a31ee25c        frappe/erpnext-nginx:edge     ""/docker-entrypoint.…""   11 minutes ago      Up 7 minutes        80/tcp                                     frappe_docker_erpnext-nginx_1\n4d6c6ed96e2a        redis:latest                  ""docker-entrypoint.s…""   11 minutes ago      Up 11 minutes       6379/tcp                                   frappe_docker_redis-queue_1\nroot $ \n']"
1483,12494,12493,CC BY-SA 4.0,2020-09-25T05:37:11.067,"<p>One way to achieve this is by using the MySQL socket to connect instead of port. For this you would have bind a mount to your container. You would anyway need a host directory bound to container to persist Database data.</p>
<ul>
<li>First create a directory on host to mount container <code>/var/lib/mysql</code></li>
<li>Use <code>-v</code> option in <code>docker run</code> to attach host path to container</li>
<li>Connect from client using <code>-S</code> and point to <code>mysql.sock</code> socket file</li>
</ul>
<p>Example:</p>
<pre><code>mkdir /home/user/mysql-1
</code></pre>
<p>Then start the container so that <code>/home/user/mysql-1</code> will attach to container's <code>/var/lib/mysql</code>:</p>
<pre><code>docker run --name mysql -d \
-v /home/user/mysql-1:/var/lib/mysql \
-e MYSQL_ROOT_PASSWORD=password \
mysql/mysql-server 
</code></pre>
<p>Once the container is started, you can connect to it with:</p>
<pre><code>mysql -h localhost -u user -p -S /home/user/mysql-1/mysql.sock
</code></pre>
",23904,2020-09-25T05:37:11.067,"['mkdir /home/user/mysql-1\n', 'docker run --name mysql -d \\\n-v /home/user/mysql-1:/var/lib/mysql \\\n-e MYSQL_ROOT_PASSWORD=password \\\nmysql/mysql-server \n', 'mysql -h localhost -u user -p -S /home/user/mysql-1/mysql.sock\n']"
1484,12495,12491,CC BY-SA 4.0,2020-09-25T06:31:29.117,"<p>Let's test the use-case with 10 remote hosts (test_01 - test_10) in the group <em>test</em> and user <em>my-user</em> in the hosts test_03 and test_07. To test the existence of the user, use the shell command</p>
<pre class=""lang-sh prettyprint-override""><code>shell&gt; cat /etc/passwd|grep my-user
</code></pre>
<p>For example the playbook</p>
<pre class=""lang-yaml prettyprint-override""><code>shell&gt; cat playbook.yml
- hosts: test
  tasks:
    - shell: cat /etc/passwd|grep my-user
      register: result
      ignore_errors: true
    - set_fact:
        results: &quot;{{ results|default({})|
                     combine({item: hostvars[item].result.rc}) }}&quot;
      loop: &quot;{{ ansible_play_hosts }}&quot;
      run_once: true
    - debug:
        var: results
      run_once: true
</code></pre>
<p>gives</p>
<pre class=""lang-yaml prettyprint-override""><code>ok: [test_01] =&gt; 
  results:
    test_01: 1
    test_02: 1
    test_03: 0
    test_04: 1
    test_05: 1
    test_06: 1
    test_07: 0
    test_08: 1
    test_09: 1
    test_10: 1
</code></pre>
<hr>
<p>To skip the rest of the hosts, when the first host is found, iterate the list of the hosts and test <em>rc</em>. Then add the host to a new group and run the next play with this group. For example,</p>
<pre class=""lang-yaml prettyprint-override""><code>shell&gt; cat playbook.yml
- hosts: test
  vars:
    dresult:
      rc: 1
  tasks:
    - block:
        - shell: cat /etc/passwd|grep my-user
          register: result
          loop: &quot;{{ ansible_play_hosts }}&quot;
          delegate_to: &quot;{{ item }}&quot;
          ignore_errors: true
          when: (result|default(dresult)).rc == 1
        - set_fact:
            my_host: &quot;{{ result.results|json_query('[?rc == `0`].item')|first }}&quot;
        - debug:
            var: my_host
        - add_host:
            name: &quot;{{ my_host }}&quot;
            groups: my_group
      run_once: true


- hosts: my_group
  tasks:
    - debug:
        var: inventory_hostname
</code></pre>
<p>gives</p>
<pre class=""lang-yaml prettyprint-override""><code>shell&gt; ansible-playbook playbook.yml 

PLAY [test] ****

TASK [shell] ****
failed: [test_01 -&gt; test_01] (item=test_01) =&gt; changed=true 
  ansible_loop_var: item
  cmd: cat /etc/passwd|grep my-user
  delta: '0:00:00.023271'
  end: '2020-09-25 08:20:31.823168'
  item: test_01
  msg: non-zero return code
  rc: 1
  start: '2020-09-25 08:20:31.799897'
  stderr: ''
  stderr_lines: &lt;omitted&gt;
  stdout: ''
  stdout_lines: &lt;omitted&gt;
failed: [test_01 -&gt; test_02] (item=test_02) =&gt; changed=true 
  ansible_loop_var: item
  cmd: cat /etc/passwd|grep my-user
  delta: '0:00:00.017642'
  end: '2020-09-25 08:20:33.386657'
  item: test_02
  msg: non-zero return code
  rc: 1
  start: '2020-09-25 08:20:33.369015'
  stderr: ''
  stderr_lines: &lt;omitted&gt;
  stdout: ''
  stdout_lines: &lt;omitted&gt;
changed: [test_01 -&gt; test_03] =&gt; (item=test_03)
skipping: [test_01] =&gt; (item=test_04) 
skipping: [test_01] =&gt; (item=test_05) 
skipping: [test_01] =&gt; (item=test_06) 
skipping: [test_01] =&gt; (item=test_07) 
skipping: [test_01] =&gt; (item=test_08) 
skipping: [test_01] =&gt; (item=test_09) 
skipping: [test_01] =&gt; (item=test_10) 
...ignoring

TASK [set_fact] ****
ok: [test_01]

TASK [debug] ****
ok: [test_01] =&gt; 
  my_host: test_03

TASK [add_host] ****
changed: [test_01]

PLAY [my_group] ****

TASK [debug] ****
ok: [test_03] =&gt; 
  inventory_hostname: test_03

PLAY RECAP *****
test_01: ok=4 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=1   
test_03: ok=1 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0
</code></pre>
",7715,2020-09-25T07:26:36.810,"['shell> cat /etc/passwd|grep my-user\n', 'shell> cat playbook.yml\n- hosts: test\n  tasks:\n    - shell: cat /etc/passwd|grep my-user\n      register: result\n      ignore_errors: true\n    - set_fact:\n        results: ""{{ results|default({})|\n                     combine({item: hostvars[item].result.rc}) }}""\n      loop: ""{{ ansible_play_hosts }}""\n      run_once: true\n    - debug:\n        var: results\n      run_once: true\n', 'ok: [test_01] => \n  results:\n    test_01: 1\n    test_02: 1\n    test_03: 0\n    test_04: 1\n    test_05: 1\n    test_06: 1\n    test_07: 0\n    test_08: 1\n    test_09: 1\n    test_10: 1\n', 'shell> cat playbook.yml\n- hosts: test\n  vars:\n    dresult:\n      rc: 1\n  tasks:\n    - block:\n        - shell: cat /etc/passwd|grep my-user\n          register: result\n          loop: ""{{ ansible_play_hosts }}""\n          delegate_to: ""{{ item }}""\n          ignore_errors: true\n          when: (result|default(dresult)).rc == 1\n        - set_fact:\n            my_host: ""{{ result.results|json_query(\'[?rc == `0`].item\')|first }}""\n        - debug:\n            var: my_host\n        - add_host:\n            name: ""{{ my_host }}""\n            groups: my_group\n      run_once: true\n\n\n- hosts: my_group\n  tasks:\n    - debug:\n        var: inventory_hostname\n', ""shell> ansible-playbook playbook.yml \n\nPLAY [test] ****\n\nTASK [shell] ****\nfailed: [test_01 -> test_01] (item=test_01) => changed=true \n  ansible_loop_var: item\n  cmd: cat /etc/passwd|grep my-user\n  delta: '0:00:00.023271'\n  end: '2020-09-25 08:20:31.823168'\n  item: test_01\n  msg: non-zero return code\n  rc: 1\n  start: '2020-09-25 08:20:31.799897'\n  stderr: ''\n  stderr_lines: <omitted>\n  stdout: ''\n  stdout_lines: <omitted>\nfailed: [test_01 -> test_02] (item=test_02) => changed=true \n  ansible_loop_var: item\n  cmd: cat /etc/passwd|grep my-user\n  delta: '0:00:00.017642'\n  end: '2020-09-25 08:20:33.386657'\n  item: test_02\n  msg: non-zero return code\n  rc: 1\n  start: '2020-09-25 08:20:33.369015'\n  stderr: ''\n  stderr_lines: <omitted>\n  stdout: ''\n  stdout_lines: <omitted>\nchanged: [test_01 -> test_03] => (item=test_03)\nskipping: [test_01] => (item=test_04) \nskipping: [test_01] => (item=test_05) \nskipping: [test_01] => (item=test_06) \nskipping: [test_01] => (item=test_07) \nskipping: [test_01] => (item=test_08) \nskipping: [test_01] => (item=test_09) \nskipping: [test_01] => (item=test_10) \n...ignoring\n\nTASK [set_fact] ****\nok: [test_01]\n\nTASK [debug] ****\nok: [test_01] => \n  my_host: test_03\n\nTASK [add_host] ****\nchanged: [test_01]\n\nPLAY [my_group] ****\n\nTASK [debug] ****\nok: [test_03] => \n  inventory_hostname: test_03\n\nPLAY RECAP *****\ntest_01: ok=4 changed=2 unreachable=0 failed=0 skipped=0 rescued=0 ignored=1   \ntest_03: ok=1 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0\n""]"
1485,12498,12488,CC BY-SA 4.0,2020-09-25T08:58:12.443,"<p>Yes, it's absolutely reasonable and this is how real apps work. This is the microservice approach which allows to independently scale instances of a service and a DB.</p>
<p>What you have to do is to run your Flask and Redis services in a way so the first one can achieve the second one. If they are on the same machine, you just have to open Redis port used by your Flask app (probably 6379):</p>
<pre><code>docker run -d -p 192.168.10.20:6379:6379 your_redis_image
</code></pre>
<p>And specify IP address and port of the Redis container in your Flask app. This is better to be done with a config file like the following <code>yaml</code>:</p>
<pre class=""lang-yaml prettyprint-override""><code>redis:
  host: '172.16.10.20'
  pw: 'YourPassWord'
  port: 6379
  db: 0
</code></pre>
<p>And use it in the code:</p>
<pre class=""lang-py prettyprint-override""><code>import yaml, redis

cfg_file open('config.yaml', 'r')
cfg = yaml.load(cfg_file)
redcfg = cfg['redis']

r = redis.Redis(
    host=redcfg['host'], port=redcfg['port'],
    db=redcfg['db'], password=redcfg['pw'],
)
</code></pre>
<p>Don't forget to copy this file into container to be accessible from the inside.</p>
",23212,2020-09-25T08:58:12.443,"['docker run -d -p 192.168.10.20:6379:6379 your_redis_image\n', ""redis:\n  host: '172.16.10.20'\n  pw: 'YourPassWord'\n  port: 6379\n  db: 0\n"", ""import yaml, redis\n\ncfg_file open('config.yaml', 'r')\ncfg = yaml.load(cfg_file)\nredcfg = cfg['redis']\n\nr = redis.Redis(\n    host=redcfg['host'], port=redcfg['port'],\n    db=redcfg['db'], password=redcfg['pw'],\n)\n""]"
1486,12499,12490,CC BY-SA 4.0,2020-09-25T13:27:45.520,"<p>By default Docker uses the <code>bridge</code> network.</p>
<p>On a default Docker installation you can simply map a port to the container's service port.  The Redis Docker image exposes its service on port <code>6379</code> so you can do:</p>
<p><code>$ docker run --name rd -d -p 6379:6379 redis:latest</code></p>
<p>From your host you can now run use the <code>redis-cli</code> utility:</p>
<pre><code>$ redis-cli
127.0.0.1:6379&gt; ping
PONG
127.0.0.1:6379&gt;
</code></pre>
",6258,2020-09-25T13:27:45.520,['$ redis-cli\n127.0.0.1:6379> ping\nPONG\n127.0.0.1:6379>\n']
1487,12502,12169,CC BY-SA 4.0,2020-09-25T18:26:57.487,"<p><strong>Thanks to <a href=""https://stackoverflow.com/a/54104353/332578"">this answer</a></strong></p>
<p>I fixed this by adding the following to my lftp command</p>
<pre><code>set ftp:use-allo false; set ftp:passive-mode true; set ftp:prefer-epsv false;
</code></pre>
<p>which made my finished command the following</p>
<pre><code>lftp -e &quot;set ftp:use-allo false; set ftp:passive-mode true; set ftp:prefer-epsv false; set ssl:verify-certificate no; open mediajackagency.com; user $LFTP_USERNAME $LFTP_PASSWORD; mirror --reverse --verbose --delete-first build/ /var/www/domains/dev/clients/jhm/cornerstone-mvp/build/; bye&quot;
</code></pre>
",23358,2020-09-25T18:26:57.487,"['set ftp:use-allo false; set ftp:passive-mode true; set ftp:prefer-epsv false;\n', 'lftp -e ""set ftp:use-allo false; set ftp:passive-mode true; set ftp:prefer-epsv false; set ssl:verify-certificate no; open mediajackagency.com; user $LFTP_USERNAME $LFTP_PASSWORD; mirror --reverse --verbose --delete-first build/ /var/www/domains/dev/clients/jhm/cornerstone-mvp/build/; bye""\n']"
1488,12503,12486,CC BY-SA 4.0,2020-09-25T20:17:49.113,"<p>Yes--absolutely you can skip Kubernetes. Suggest that you still use Docker, but you could even just install the components separately.</p>
<p>I think it's easiest using Docker Compose (need to have package <code>docker-compose</code> installed on your host) to manage the containers.</p>
<p>Here is a <code>docker-compose.yml</code> that might be helpful:</p>
<pre><code>version: '3'

services:
    prometheus:
        image: prom/prometheus:latest
        restart: unless-stopped
        ports:
            - &quot;9090:9090&quot;
        volumes:
            - /home/${USER}/opt/prometheus/data:/opt/prometheus/data:rw
            - /home/${USER}/opt/prometheus/config:/opt/prometheus/config:rw
        environment:
            SERVER_KEY: ${SERVER_KEY}
            SERVER_CERT: ${SERVER_CERT}

    grafana:
        image: grafana/grafana:latest
        restart: unless-stopped
        ports:
            - &quot;3000:3000&quot;
        volumes:
            - /home/${USER}/var/lib/grafana:/var/lib/grafana:rw
            - /home/${USER}/var/log/grafana:/var/log/grafana:rw
            - /home/${USER}/etc/grafana/grafana.ini:/etc/grafana/grafana.ini:rw
            - /home/${USER}/etc/grafana/ldap.toml:/etc/grafana/ldap.toml:rw
        environment:
            SERVER_KEY: ${SERVER_KEY}
            SERVER_CERT: ${SERVER_CERT}
            GF_SECURITY_ADMIN_USER: ${GF_SECURITY_ADMIN_USER}
            GF_SECURITY_ADMIN_PASSWORD: ${GF_SECURITY_ADMIN_PASSWORD}
        depends_on:
            - &quot;prometheus&quot;
</code></pre>
<p>Can also use Docker Compose for Loki and Promtail.</p>
<p>Docker Compose reference: <a href=""https://docs.docker.com/compose/compose-file"" rel=""nofollow noreferrer"">https://docs.docker.com/compose/compose-file</a></p>
",124,2020-09-25T20:17:49.113,"['version: \'3\'\n\nservices:\n    prometheus:\n        image: prom/prometheus:latest\n        restart: unless-stopped\n        ports:\n            - ""9090:9090""\n        volumes:\n            - /home/${USER}/opt/prometheus/data:/opt/prometheus/data:rw\n            - /home/${USER}/opt/prometheus/config:/opt/prometheus/config:rw\n        environment:\n            SERVER_KEY: ${SERVER_KEY}\n            SERVER_CERT: ${SERVER_CERT}\n\n    grafana:\n        image: grafana/grafana:latest\n        restart: unless-stopped\n        ports:\n            - ""3000:3000""\n        volumes:\n            - /home/${USER}/var/lib/grafana:/var/lib/grafana:rw\n            - /home/${USER}/var/log/grafana:/var/log/grafana:rw\n            - /home/${USER}/etc/grafana/grafana.ini:/etc/grafana/grafana.ini:rw\n            - /home/${USER}/etc/grafana/ldap.toml:/etc/grafana/ldap.toml:rw\n        environment:\n            SERVER_KEY: ${SERVER_KEY}\n            SERVER_CERT: ${SERVER_CERT}\n            GF_SECURITY_ADMIN_USER: ${GF_SECURITY_ADMIN_USER}\n            GF_SECURITY_ADMIN_PASSWORD: ${GF_SECURITY_ADMIN_PASSWORD}\n        depends_on:\n            - ""prometheus""\n']"
1489,12504,12490,CC BY-SA 4.0,2020-09-25T21:19:06.077,"<p>tentative answer:</p>
<pre><code>root $ 
root $ docker run --name rds -d redis redis-server --appendonly yes
d85ce8736fc33f81edc7e63972391f6eb34586d562b4066f57395f9ea2bafe58
root $ 
root $ docker container ls
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
d85ce8736fc3        redis               &quot;docker-entrypoint.s…&quot;   9 seconds ago       Up 6 seconds        6379/tcp            rds
root $ 
root $ docker exec -it rds redis-cli
127.0.0.1:6379&gt; 
127.0.0.1:6379&gt; keys *
(empty array)
127.0.0.1:6379&gt; 
127.0.0.1:6379&gt; set foo bar
OK
127.0.0.1:6379&gt; 
127.0.0.1:6379&gt; keys *
1) &quot;foo&quot;
127.0.0.1:6379&gt; 
127.0.0.1:6379&gt; get foo
&quot;bar&quot;
127.0.0.1:6379&gt; 
</code></pre>
<p>should work as persistence in a microservice architecture.  To my understanding.</p>
<pre><code>root $ 
root $ docker network ls
NETWORK ID          NAME                DRIVER              SCOPE
e57e2c862b19        bridge              bridge              local
25aba55a5413        host                host                local
ad5c1c2fa1e1        none                null                local
root $ 
root $ docker inspect rds | grep bridge
                &quot;bridge&quot;: {
root $ 
root $ docker network inspect bridge
[
    {
        &quot;Name&quot;: &quot;bridge&quot;,
        &quot;Id&quot;: &quot;e57e2c862b19e68b470adf5bbd4719b675c15a399e3bd01380a9d7ad35c7ea26&quot;,
        &quot;Created&quot;: &quot;2020-09-24T17:43:14.098411476-07:00&quot;,
        &quot;Scope&quot;: &quot;local&quot;,
        &quot;Driver&quot;: &quot;bridge&quot;,
        &quot;EnableIPv6&quot;: false,
        &quot;IPAM&quot;: {
            &quot;Driver&quot;: &quot;default&quot;,
            &quot;Options&quot;: null,
            &quot;Config&quot;: [
                {
                    &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;,
                    &quot;Gateway&quot;: &quot;172.17.0.1&quot;
                }
            ]
        },
        &quot;Internal&quot;: false,
        &quot;Attachable&quot;: false,
        &quot;Ingress&quot;: false,
        &quot;ConfigFrom&quot;: {
            &quot;Network&quot;: &quot;&quot;
        },
        &quot;ConfigOnly&quot;: false,
        &quot;Containers&quot;: {
            &quot;d85ce8736fc33f81edc7e63972391f6eb34586d562b4066f57395f9ea2bafe58&quot;: {
                &quot;Name&quot;: &quot;rds&quot;,
                &quot;EndpointID&quot;: &quot;b0afddd9a063d8051021db490342e6627bdf9694b8f526ad5bbd5a665eeafefd&quot;,
                &quot;MacAddress&quot;: &quot;02:42:ac:11:00:02&quot;,
                &quot;IPv4Address&quot;: &quot;172.17.0.2/16&quot;,
                &quot;IPv6Address&quot;: &quot;&quot;
            }
        },
        &quot;Options&quot;: {
            &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;,
            &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;,
            &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,
            &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;,
            &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;,
            &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot;
        },
        &quot;Labels&quot;: {}
    }
]
root $ 
</code></pre>
<p>So a <code>flask</code> container also on the bridge network should be able to access this container.</p>
",23443,2020-09-25T21:19:06.077,"['root $ \nroot $ docker run --name rds -d redis redis-server --appendonly yes\nd85ce8736fc33f81edc7e63972391f6eb34586d562b4066f57395f9ea2bafe58\nroot $ \nroot $ docker container ls\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES\nd85ce8736fc3        redis               ""docker-entrypoint.s…""   9 seconds ago       Up 6 seconds        6379/tcp            rds\nroot $ \nroot $ docker exec -it rds redis-cli\n127.0.0.1:6379> \n127.0.0.1:6379> keys *\n(empty array)\n127.0.0.1:6379> \n127.0.0.1:6379> set foo bar\nOK\n127.0.0.1:6379> \n127.0.0.1:6379> keys *\n1) ""foo""\n127.0.0.1:6379> \n127.0.0.1:6379> get foo\n""bar""\n127.0.0.1:6379> \n', 'root $ \nroot $ docker network ls\nNETWORK ID          NAME                DRIVER              SCOPE\ne57e2c862b19        bridge              bridge              local\n25aba55a5413        host                host                local\nad5c1c2fa1e1        none                null                local\nroot $ \nroot $ docker inspect rds | grep bridge\n                ""bridge"": {\nroot $ \nroot $ docker network inspect bridge\n[\n    {\n        ""Name"": ""bridge"",\n        ""Id"": ""e57e2c862b19e68b470adf5bbd4719b675c15a399e3bd01380a9d7ad35c7ea26"",\n        ""Created"": ""2020-09-24T17:43:14.098411476-07:00"",\n        ""Scope"": ""local"",\n        ""Driver"": ""bridge"",\n        ""EnableIPv6"": false,\n        ""IPAM"": {\n            ""Driver"": ""default"",\n            ""Options"": null,\n            ""Config"": [\n                {\n                    ""Subnet"": ""172.17.0.0/16"",\n                    ""Gateway"": ""172.17.0.1""\n                }\n            ]\n        },\n        ""Internal"": false,\n        ""Attachable"": false,\n        ""Ingress"": false,\n        ""ConfigFrom"": {\n            ""Network"": """"\n        },\n        ""ConfigOnly"": false,\n        ""Containers"": {\n            ""d85ce8736fc33f81edc7e63972391f6eb34586d562b4066f57395f9ea2bafe58"": {\n                ""Name"": ""rds"",\n                ""EndpointID"": ""b0afddd9a063d8051021db490342e6627bdf9694b8f526ad5bbd5a665eeafefd"",\n                ""MacAddress"": ""02:42:ac:11:00:02"",\n                ""IPv4Address"": ""172.17.0.2/16"",\n                ""IPv6Address"": """"\n            }\n        },\n        ""Options"": {\n            ""com.docker.network.bridge.default_bridge"": ""true"",\n            ""com.docker.network.bridge.enable_icc"": ""true"",\n            ""com.docker.network.bridge.enable_ip_masquerade"": ""true"",\n            ""com.docker.network.bridge.host_binding_ipv4"": ""0.0.0.0"",\n            ""com.docker.network.bridge.name"": ""docker0"",\n            ""com.docker.network.driver.mtu"": ""1500""\n        },\n        ""Labels"": {}\n    }\n]\nroot $ \n']"
1490,12505,12497,CC BY-SA 4.0,2020-09-26T02:37:45.747,"<p>A little more information is needed about specific operations you are doing, but generally your options are:</p>
<ol>
<li><p>For one-time operations: use <a href=""https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/"" rel=""nofollow noreferrer"">kubectl exec</a> to get into containers and do commands (works similar to <code>docker exec</code>).</p>
</li>
<li><p>Also for one-time operations, spawn separate pods with shell access to interact with existing pods, something along the lines:</p>
</li>
</ol>
<pre><code>kubectl run -it --rm --restart=Never --image busybox tempbusybox -- sh
</code></pre>
<ol start=""3"">
<li><p>For reproducible (not one-time) operations, you may use <a href=""https://kubernetes.io/docs/concepts/workloads/controllers/job/"" rel=""nofollow noreferrer"">kubernetes jobs</a>.</p>
</li>
<li><p>In some cases you may use <a href=""https://kubernetes.io/docs/concepts/workloads/pods/init-containers/"" rel=""nofollow noreferrer"">init containers</a> for setup tasks.</p>
</li>
</ol>
",19963,2020-09-26T02:37:45.747,['kubectl run -it --rm --restart=Never --image busybox tempbusybox -- sh\n']
1491,12514,12138,CC BY-SA 4.0,2020-09-28T21:39:36.010,"<p>Not tested this, but is <a href=""https://docs.ansible.com/ansible/latest/collections/ansible/builtin/include_role_module.html"" rel=""nofollow noreferrer"">include_role</a> any help? so instead of a playbook like this,</p>
<pre><code> ---
 - name: Example
   hosts: all
   roles:
    - first_role
    - second_role
    - third_role
</code></pre>
<p>maybe this,</p>
<pre><code> ---
 - name: Example
   hosts: all
   tasks:
    - etckeeper_task
    - include_role:
        name: first_role
    - etckeeper_task
    - include_role:
        name: second_role
    - etckeeper_task
    - include_role:
        name: third_role
    - etckeeper_task
</code></pre>
<p>alternatively (also untested) you could build a role, let's call it <code>wrap_role</code> with <code>tasks/main.yml</code> containing,</p>
<pre><code>---
# Replace this task with your actual before-role etckeeper task,
- name: etckeeper pre-actions
  meta: noop

- include_role:
  name: {{role_name}}

# Replace this task with your actual after-role etckeeper task,
- name: etckeeper post-actions
  meta: noop
</code></pre>
<p>Now your top-level playbook can be something like,</p>
<pre><code> ---
 - name: Example
   hosts: all
   roles:
     - { role: wrap_role, role_name: first_role }
     - { role: wrap_role, role_name: second_role }
     - { role: wrap_role, role_name: third_role }
</code></pre>
<p>not ideal based on your question, but at least it leaves the roles untouched, even if you have to alter top-level playbooks. If I get the time I'll test the above suggestions and update this answer accordingly.</p>
",21779,2020-09-28T21:39:36.010,"[' ---\n - name: Example\n   hosts: all\n   roles:\n    - first_role\n    - second_role\n    - third_role\n', ' ---\n - name: Example\n   hosts: all\n   tasks:\n    - etckeeper_task\n    - include_role:\n        name: first_role\n    - etckeeper_task\n    - include_role:\n        name: second_role\n    - etckeeper_task\n    - include_role:\n        name: third_role\n    - etckeeper_task\n', '---\n# Replace this task with your actual before-role etckeeper task,\n- name: etckeeper pre-actions\n  meta: noop\n\n- include_role:\n  name: {{role_name}}\n\n# Replace this task with your actual after-role etckeeper task,\n- name: etckeeper post-actions\n  meta: noop\n', ' ---\n - name: Example\n   hosts: all\n   roles:\n     - { role: wrap_role, role_name: first_role }\n     - { role: wrap_role, role_name: second_role }\n     - { role: wrap_role, role_name: third_role }\n']"
1492,12519,12518,CC BY-SA 4.0,2020-09-29T09:30:52.273,"<p>Put the following setting in <code>/etc/elasticsearch.yml</code> and it will work.</p>
<pre><code>network.host: 0.0.0.0
discovery.type: single-node
</code></pre>
",11598,2020-09-29T09:30:52.273,['network.host: 0.0.0.0\ndiscovery.type: single-node\n']
1493,12521,79,CC BY-SA 4.0,2020-09-29T14:48:06.227,"<p>you can store values in the parameter store and use them in terraform resources by fetching values using data resources.</p>
<pre><code>data &quot;aws_ssm_parameter&quot; &quot;rds_password&quot; {
  name = &quot;/${var.project_name}/DB_PASSWORD&quot;
}

resource &quot;aws_db_instance&quot; &quot;rds&quot; {
  ...
  password = data.aws_ssm_parameter.rds_password.value
  ...
}
</code></pre>
",19373,2020-09-29T14:48:06.227,"['data ""aws_ssm_parameter"" ""rds_password"" {\n  name = ""/${var.project_name}/DB_PASSWORD""\n}\n\nresource ""aws_db_instance"" ""rds"" {\n  ...\n  password = data.aws_ssm_parameter.rds_password.value\n  ...\n}\n']"
1494,12541,12540,CC BY-SA 4.0,2020-10-04T11:44:39.230,"<p>This can be achieved by running your build script in a docker container and applying your iptables rules inside that container, which won't affect the host <code>runner</code>'s connectivity.</p>
<p>For example, if the below script is executed in a GitHub Actions job (in the Ubuntu 18.04 GitHub shared runner), it will run the build script (<code>docker_script.sh</code>) in a debian docker container that has no internet connectivity, except from the <code>_apt</code> user.</p>
<pre><code>#!/bin/bash
set -x

###################
# INSTALL DEPENDS #
###################

apt-get -y install docker.io

##################
# DOWNLOAD IMAGE #
##################

# At the time of writing, Docker Content Trust is 100% security theater without
# explicitly adding the root public keys to the $HOME/.docker/trust/ directory
#
#  * https://github.com/BusKill/buskill-app/issues/6#issuecomment-700050760
#  * https://security.stackexchange.com/questions/238529/how-to-list-all-of-the-known-root-keys-in-docker-docker-content-trust
#  * https://github.com/docker/cli/issues/2752

docker -D pull debian:stable-slim

#################
# CREATE SCRIPT #
#################

tmpDir=`mktemp -d`
pushd &quot;${tmpDir}&quot;

cat &lt;&lt; EOF &gt; docker_script.sh
#!/bin/bash
set -x

# SETTINGS #
SUDO=/usr/bin/sudo

# DEPENDS #
${SUDO} apt-get update
${SUDO} apt-get install iptables curl

# IPTABLES #

# We setup iptables so that only the apt user (and therefore the apt command)
# can access the internet. We don't want insecure tools like `pip` to download
# unsafe code from the internet.

${SUDO} iptables-save &gt; /tmp/iptables-save.`date &quot;+%Y%m%d_%H%M%S&quot;`
${SUDO} iptables -A INPUT -i lo -j ACCEPT
${SUDO} iptables -A INPUT -s 127.0.0.1/32 -j DROP
${SUDO} iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
${SUDO} iptables -A INPUT -j DROP
${SUDO} iptables -A OUTPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -j ACCEPT
${SUDO} iptables -A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
${SUDO} iptables -A OUTPUT -m owner --uid-owner 100 -j ACCEPT # apt uid = 100
${SUDO} iptables -A OUTPUT -j DROP

${SUDO} ip6tables-save &gt; /tmp/ip6tables-save.`date &quot;+%Y%m%d_%H%M%S&quot;`
${SUDO} ip6tables -A INPUT -i lo -j ACCEPT
${SUDO} ip6tables -A INPUT -s ::1/128 -j DROP
${SUDO} ip6tables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
${SUDO} ip6tables -A INPUT -j DROP
${SUDO} ip6tables -A OUTPUT -s ::1/128 -d ::1/128 -j ACCEPT
${SUDO} ip6tables -A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT
${SUDO} ip6tables -A OUTPUT -m owner --uid-owner 100 -j ACCEPT
${SUDO} ip6tables -A OUTPUT -j DROP

# attempt to access the internet as root. If it works, exit 1
curl 1.1.1.1
if [ $? -eq 0 ]; then
        echo &quot;ERROR: iptables isn't blocking internet access to unsafe tools. You may need to run this as root (and you should do it inside a VM)&quot;
        exit 1
fi

# BUILD #

# ...
# &lt;DO BUILD HERE&gt;
# ...

exit 0
EOF
chmod +x docker_script.sh

##############
# DOCKER RUN #
##############

docker run --rm --cap-add &quot;NET_ADMIN&quot; -v &quot;${tmpDir}:/root/shared_volume&quot; debian:stable-slim /bin/bash -c &quot;cd /root/shared_volume &amp;&amp; docker_script.sh&quot;

# exit cleanly
exit 0
</code></pre>
<p>Note that:</p>
<ol>
<li><p>You have to execute the <code>docker run</code> command manually rather than just specify the <code>container:</code> in the GitHub Actions yaml file in order to add the <code>NET_ADMIN</code> capability. See Also <a href=""https://stackoverflow.com/questions/63959783/how-to-run-script-in-docker-container-with-additional-capabilities-docker-exec/64045054#64045054"">https://stackoverflow.com/questions/63959783/how-to-run-script-in-docker-container-with-additional-capabilities-docker-exec/64045054#64045054</a></p>
</li>
<li><p>This is a security risk unless you pin the root signing keys before calling <code>docker pull</code>. See also <a href=""https://security.stackexchange.com/questions/238529/how-to-list-all-of-the-known-root-keys-in-docker-docker-content-trust"">https://security.stackexchange.com/questions/238529/how-to-list-all-of-the-known-root-keys-in-docker-docker-content-trust</a></p>
</li>
<li><p>The above script should be executed as root. For example, prepend <code>sudo</code> to it in the <code>run:</code> key for the step in the GitHub Actions workflow.</p>
</li>
</ol>
",22501,2020-10-04T11:44:39.230,"['#!/bin/bash\nset -x\n\n###################\n# INSTALL DEPENDS #\n###################\n\napt-get -y install docker.io\n\n##################\n# DOWNLOAD IMAGE #\n##################\n\n# At the time of writing, Docker Content Trust is 100% security theater without\n# explicitly adding the root public keys to the $HOME/.docker/trust/ directory\n#\n#  * https://github.com/BusKill/buskill-app/issues/6#issuecomment-700050760\n#  * https://security.stackexchange.com/questions/238529/how-to-list-all-of-the-known-root-keys-in-docker-docker-content-trust\n#  * https://github.com/docker/cli/issues/2752\n\ndocker -D pull debian:stable-slim\n\n#################\n# CREATE SCRIPT #\n#################\n\ntmpDir=`mktemp -d`\npushd ""${tmpDir}""\n\ncat << EOF > docker_script.sh\n#!/bin/bash\nset -x\n\n# SETTINGS #\nSUDO=/usr/bin/sudo\n\n# DEPENDS #\n${SUDO} apt-get update\n${SUDO} apt-get install iptables curl\n\n# IPTABLES #\n\n# We setup iptables so that only the apt user (and therefore the apt command)\n# can access the internet. We don\'t want insecure tools like `pip` to download\n# unsafe code from the internet.\n\n${SUDO} iptables-save > /tmp/iptables-save.`date ""+%Y%m%d_%H%M%S""`\n${SUDO} iptables -A INPUT -i lo -j ACCEPT\n${SUDO} iptables -A INPUT -s 127.0.0.1/32 -j DROP\n${SUDO} iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\n${SUDO} iptables -A INPUT -j DROP\n${SUDO} iptables -A OUTPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -j ACCEPT\n${SUDO} iptables -A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\n${SUDO} iptables -A OUTPUT -m owner --uid-owner 100 -j ACCEPT # apt uid = 100\n${SUDO} iptables -A OUTPUT -j DROP\n\n${SUDO} ip6tables-save > /tmp/ip6tables-save.`date ""+%Y%m%d_%H%M%S""`\n${SUDO} ip6tables -A INPUT -i lo -j ACCEPT\n${SUDO} ip6tables -A INPUT -s ::1/128 -j DROP\n${SUDO} ip6tables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\n${SUDO} ip6tables -A INPUT -j DROP\n${SUDO} ip6tables -A OUTPUT -s ::1/128 -d ::1/128 -j ACCEPT\n${SUDO} ip6tables -A OUTPUT -m state --state RELATED,ESTABLISHED -j ACCEPT\n${SUDO} ip6tables -A OUTPUT -m owner --uid-owner 100 -j ACCEPT\n${SUDO} ip6tables -A OUTPUT -j DROP\n\n# attempt to access the internet as root. If it works, exit 1\ncurl 1.1.1.1\nif [ $? -eq 0 ]; then\n        echo ""ERROR: iptables isn\'t blocking internet access to unsafe tools. You may need to run this as root (and you should do it inside a VM)""\n        exit 1\nfi\n\n# BUILD #\n\n# ...\n# <DO BUILD HERE>\n# ...\n\nexit 0\nEOF\nchmod +x docker_script.sh\n\n##############\n# DOCKER RUN #\n##############\n\ndocker run --rm --cap-add ""NET_ADMIN"" -v ""${tmpDir}:/root/shared_volume"" debian:stable-slim /bin/bash -c ""cd /root/shared_volume && docker_script.sh""\n\n# exit cleanly\nexit 0\n']"
1495,12550,12548,CC BY-SA 4.0,2020-10-07T20:41:14.413,"<p>It sounds to me like you're already aware of this, but there are a couple easy ways to do this, and a couple hard ways to do this.</p>
<p>The easy ways:</p>
<ul>
<li>Make your repo available for checkout without SSH keys or authentication credentials.</li>
<li>Manually add an SSH keypair for repo checkout to the Jenkins user on your Jenkins master node (since Active Choice Groovy scripts run on the master node) (i.e. don't use the Credentials store).</li>
</ul>
<p>The hard ways:</p>
<ul>
<li>Use the Jenkins Java API in your Active Choices code to extract credentials from the credentials store.  API docs are available for <a href=""https://javadoc.jenkins.io/plugin/credentials/"" rel=""nofollow noreferrer"">the credentials store</a> and the <a href=""https://javadoc.jenkins.io/plugin/ssh-credentials/"" rel=""nofollow noreferrer"">ssh credentials type</a>.  There is no documentation on how to use the Java classes available in these plugins, so it's up to you to figure it out yourself.</li>
<li>Create a secondary &quot;meta&quot; job to update the parameters in the original Jenkins job (including Active Choices scripts) - I describe this a bit below.</li>
</ul>
<hr />
<p>If you can't do any of the easy solutions for security reasons, there isn't an easy, straightforward way to update Active Choice parameters based on the contents of a git repo.  This is because:</p>
<ol>
<li>Like you said, &quot;during pre-pipeline stage (i.e. Active Choices parameter) Hudson extensions such as withCredentials or sshAgent are not accessible&quot;.</li>
<li>The configuration for parameters, including Active Choice parameters, is taken from the <em>previous</em> run of that Pipeline, not the current one.  Meaning that, to update your parameters from within your Pipeline code, you'll need to run your Pipeline, which defeats the point of what you want to do.</li>
</ol>
<p>There is a solution for 1., which is to use Scripted Pipelines instead of Declarative, but that won't get around the problems of 2.</p>
<p>The solution that I came up with when I ran into this issue is to create a second Jenkins job (I call it a &quot;meta&quot; job) which updates the parameters of the original job, including Active Choices scripts.  This second meta job is triggered by a git hook on the repository that I use to fill the options in my Active Choices parameters.  This has the advantage that you do not need to run the original job's Pipeline in order to update its parameters, solving the issues in 2.  Also, because it's still a Pipeline job, you can use normal Pipeline steps, thus allowing you to access the credentials store.</p>
<p>My job looks (roughly) like this - I simplified it a lot to make it fit here, so you'll need to do a bunch of tweaking to get it working the way you want.  There are probably a ton of errors and bugs in this because I ripped apart an existing script to make this.  A few things to note:</p>
<ul>
<li>This makes heavy use of Jenkins APIs, so you'll need to either disable the script sandbox or whitelist a ton of functions in the Jenkins security manager in order to get this to run</li>
<li>This is still technically a Scripted Pipeline even though it looks much more like a normal Groovy script than a Pipeline file</li>
<li>Because this is a Pipeline, you can use steps like <code>withCredentials</code> to check out repositories using the credentials store.</li>
</ul>
<pre><code>import groovy.json.JsonOutput

import org.jenkinsci.plugins.scriptsecurity.sandbox.groovy.SecureGroovyScript 

import org.biouno.unochoice.*
import org.biouno.unochoice.model.*

def metadataUrl = 'ssh://git@**************/metadata.git'
def metadataBranch = 'master'

def metadata = [:]

node('master') {
  git(
    url: metadataUrl,
    branch: metadataBranch,
    credentialsId: 'jenkins',
    changelog: false,
  )

  def dataDir = &quot;${pwd()}/myJsonFiles&quot;

  // can't use File.eachFileMatch() due to:
  // https://wiki.jenkins.io/display/JENKINS/Pipeline+CPS+method+mismatches
  def files = new File(dataDir).list().findAll() { f-&gt;
    FilenameUtils.getExtension(f) == 'json'
  }

  files.each() { f-&gt;
    // TODO: nice error messages if files are misformatted
    def name = FilenameUtils.removeExtension(f)
    def data = readJson(file: &quot;${dataDir}/${f}&quot;)
    metadata[name] = data
  }
}


// ChoiceParameterDefinition is the class name for the built-in static choice parameter.
// CascadeChoiceParameter is the class name for the Active Choices dynamic choice parameter.


// begin first parameter
def fileParam = new ChoiceParameterDefinition(
  'file',
  'The JSON file to use',
)
fileParam.setChoices(metadata.keySet())
// end first parameter


// begin second parameter
def metadataJson = JsonOutput.toJson(metadata)

def scriptText = &quot;&quot;&quot;
import groovy.json.JsonSlurper

def slurper = new JsonSlurper()
def metadata = slurper.parseText('${metadataJson}')

return metadata[file]['versions']
&quot;&quot;&quot;
def mainScript = new SecureGroovyScript(scriptText, true)
def fallbackScript = new SecureGroovyScript('return [&quot;Error encountered - see logs&quot;]', true)
def activeChoiceScript = new GroovyScript(mainScript, fallbackScript)

def versionParam = new CascadeChoiceParameter(
  'version', 
  'The version to use',
  activeChoiceScript,
  'PT_SINGLE_SELECT',
  'file',
  false,
)
// end second parameter


def paramProp = new ParametersDefinitionProperty(fileParam, versionParam)


// this is the full name of the actual job which needs dynamic parameters
def job = Jenkins.instance.getItemByFullName('UNIX/deploy_to_environment/master')


// There is no &quot;setProperty&quot; - we need to remove and replace.
// removeProperty is safe to run even if no matching properties are set on the job.
// However, this method only removes one property per method call.
// Theoretically, this means the job could accumulate multiple conflicting
// ParametersDefinitionProperty properties.
// TODO: run removeProperty in a while loop to eliminate all matching properties for extra safety.
job.removeProperty(ParametersDefinitionProperty)

job.addProperty(paramProp)
</code></pre>
",4115,2020-10-07T20:53:31.867,"['import groovy.json.JsonOutput\n\nimport org.jenkinsci.plugins.scriptsecurity.sandbox.groovy.SecureGroovyScript \n\nimport org.biouno.unochoice.*\nimport org.biouno.unochoice.model.*\n\ndef metadataUrl = \'ssh://git@**************/metadata.git\'\ndef metadataBranch = \'master\'\n\ndef metadata = [:]\n\nnode(\'master\') {\n  git(\n    url: metadataUrl,\n    branch: metadataBranch,\n    credentialsId: \'jenkins\',\n    changelog: false,\n  )\n\n  def dataDir = ""${pwd()}/myJsonFiles""\n\n  // can\'t use File.eachFileMatch() due to:\n  // https://wiki.jenkins.io/display/JENKINS/Pipeline+CPS+method+mismatches\n  def files = new File(dataDir).list().findAll() { f->\n    FilenameUtils.getExtension(f) == \'json\'\n  }\n\n  files.each() { f->\n    // TODO: nice error messages if files are misformatted\n    def name = FilenameUtils.removeExtension(f)\n    def data = readJson(file: ""${dataDir}/${f}"")\n    metadata[name] = data\n  }\n}\n\n\n// ChoiceParameterDefinition is the class name for the built-in static choice parameter.\n// CascadeChoiceParameter is the class name for the Active Choices dynamic choice parameter.\n\n\n// begin first parameter\ndef fileParam = new ChoiceParameterDefinition(\n  \'file\',\n  \'The JSON file to use\',\n)\nfileParam.setChoices(metadata.keySet())\n// end first parameter\n\n\n// begin second parameter\ndef metadataJson = JsonOutput.toJson(metadata)\n\ndef scriptText = """"""\nimport groovy.json.JsonSlurper\n\ndef slurper = new JsonSlurper()\ndef metadata = slurper.parseText(\'${metadataJson}\')\n\nreturn metadata[file][\'versions\']\n""""""\ndef mainScript = new SecureGroovyScript(scriptText, true)\ndef fallbackScript = new SecureGroovyScript(\'return [""Error encountered - see logs""]\', true)\ndef activeChoiceScript = new GroovyScript(mainScript, fallbackScript)\n\ndef versionParam = new CascadeChoiceParameter(\n  \'version\', \n  \'The version to use\',\n  activeChoiceScript,\n  \'PT_SINGLE_SELECT\',\n  \'file\',\n  false,\n)\n// end second parameter\n\n\ndef paramProp = new ParametersDefinitionProperty(fileParam, versionParam)\n\n\n// this is the full name of the actual job which needs dynamic parameters\ndef job = Jenkins.instance.getItemByFullName(\'UNIX/deploy_to_environment/master\')\n\n\n// There is no ""setProperty"" - we need to remove and replace.\n// removeProperty is safe to run even if no matching properties are set on the job.\n// However, this method only removes one property per method call.\n// Theoretically, this means the job could accumulate multiple conflicting\n// ParametersDefinitionProperty properties.\n// TODO: run removeProperty in a while loop to eliminate all matching properties for extra safety.\njob.removeProperty(ParametersDefinitionProperty)\n\njob.addProperty(paramProp)\n']"
1496,12551,9243,CC BY-SA 4.0,2020-10-07T20:41:36.993,"<p>There may not be a way to make your idea work with submodules. When a Jenkins multibranch pipeline polls SCM for changes, it has no visibility into submodules. I verified this recently. The result in &quot;Scan Multibranch Pipeline Log&quot; was a <code>Communication error for url</code> response. The Jenkinsfile was not found, and so no build was triggered.</p>
<p>The good news is that I discovered a straightforward way to achieve what we're after <em>without</em> using submodules. Have a look at the <a href=""https://plugins.jenkins.io/remote-file/"" rel=""nofollow noreferrer"">Remote Jenkinsfile Provider Plugin</a>.</p>
<p>When a pipeline is polling a repository to trigger new builds, it looks for two things for each branch:</p>
<ol>
<li>The polled branch has new SCM changes since the last build (HEAD is different).</li>
<li>A Jenkinsfile exists in repository X on branch Y at path Z.</li>
</ol>
<p>In a multibranch pipeline's Build Configuration section, normally only one Mode is available to tell Jenkins where to find the Jenkinsfile: &quot;by Jenkinsfile&quot;. This mode allows us to specify Z (path) only; X and Y are <em>implicitly</em> set to the repository and branch being polled.</p>
<p>What the Remote Jenkinsfile Provider Plugin gives us is a new Build Configuration Mode: &quot;by Remote Jenkins File Plugin&quot;. This mode allows us to <em>explicitly</em> set the repository, branch, and path for the Jenkinsfile - X, Y, <em>and</em> Z. In your example, X would be <code>ci-repo</code>, but <em>any</em> Jenkinsfile in <em>any</em> repository is fair game. You could have <code>ci-repo</code> be a submodule of <code>dev-repo</code> if it's convenient, but no such relationship is required to make this work.</p>
<p>If desired, a &quot;Match branches&quot; option uses the <em>polled branch name</em> for Y, looking for a <em>remote</em> Jenkinsfile on a branch of the same name. For example, while polling <code>dev-repo/feature-123</code>, it would look for a Jenkinsfile on <code>ci-repo/feature-123</code>.</p>
<p>As long as the Jenkinsfile exists at the specified location, the second criteria for triggering new builds will be satisfied. You'll see something like this in the pipeline's polling logs:</p>
<pre><code>Looking up DR/dev-repo for branches
Checking branch master from DR/dev-repo
No local file defined. Skipping Source Code SCM probe, since Jenkinsfile will be provided by Remote Jenkins File Plugin
    Met criteria
Scheduled build for branch: master
</code></pre>
<p>Instructions for how to set this up, with screenshots, can be found on <a href=""https://plugins.jenkins.io/remote-file/"" rel=""nofollow noreferrer"">the plugin's page</a>.</p>
<p><strong>Caveat:</strong> Pushing changes to a <em>remote</em> Jenkinsfile (<code>ci-repo</code>) will <em>not</em> trigger any builds of the polling repository (<code>dev-repo</code>). If this behavior is desired, one solution would be to use webhooks. Another would be to create a pipeline that polls the <em>remote</em> Jenkinsfile's repository and builds other pipeline jobs as desired using the <a href=""https://www.jenkins.io/doc/pipeline/steps/pipeline-build-step/"" rel=""nofollow noreferrer"">build step</a>, like so:</p>
<pre><code>build(job: &quot;dev-repo/${BRANCH_NAME}&quot;, wait: false)
</code></pre>
",17761,2020-10-07T20:41:36.993,"['Looking up DR/dev-repo for branches\nChecking branch master from DR/dev-repo\nNo local file defined. Skipping Source Code SCM probe, since Jenkinsfile will be provided by Remote Jenkins File Plugin\n    Met criteria\nScheduled build for branch: master\n', 'build(job: ""dev-repo/${BRANCH_NAME}"", wait: false)\n']"
1497,12556,12553,CC BY-SA 4.0,2020-10-09T20:31:40.660,"<p>In my case it ended up that Jenkins was running docker agent with specific UID and GID. To get that fixed it required to rebuild that docker image with creating internal Jenkins user with the same UID and GID</p>
<p>For that purpose on top of the Jenkinsfile to crate that docker image I have added:</p>
<pre><code>def user_id
def group_id
node {
   user_id = sh(returnStdout: true, script: 'id -u').trim()
   group_id = sh(returnStdout: true, script: 'id -g').trim()
}

</code></pre>
<p>and then during the build stage I have passed additional arguments to the docker as</p>
<pre><code>--build-arg JenkinsUserId=${user_id} --build-arg JenkinsGroupId=${group_id}
</code></pre>
<p>then in the Dockerfile for that build:</p>
<pre><code>FROM alpine:latest

#pick up provided ARGs for the bild

ARG JenkinsUserId
ARG JenkinsGroupId

//do your stuff here

#create Ansible config directory
RUN set -xe \
    &amp;&amp; mkdir -p /etc/ansible

#create Ansible tmp directory
RUN set -xe \
    &amp;&amp; mkdir -p /.ansible/tmp

#set ANSIBLE_LOCAL_TEMP
ENV ANSIBLE_LOCAL_TEMP /.ansible/tmp

#create Ansible cp directory
RUN set -xe \
    &amp;&amp; mkdir -p /.ansible/cp

#set ANSIBLE_SSH_CONTROL_PATH_DIR
ENV ANSIBLE_SSH_CONTROL_PATH_DIR /.ansible/cp

# Create Jenkins group and user
RUN if ! id $JenkinsUserId; then \
    groupadd -g ${JenkinsGroupId} jenkins; \
    useradd jenkins -u ${JenkinsUserId} -g jenkins --shell /bin/bash --create-home; \
  else \
    addgroup --gid 1000 -S jenkins &amp;&amp; adduser --uid 1000 -S jenkins -G jenkins; \
  fi

RUN addgroup jenkins root

# Tell docker that all future commands should run as the appuser user
USER jenkins
</code></pre>
<p>and finally update <code>docker</code> <code>agent</code> for the main pipeline which had issue:</p>
<pre><code>   agent {
      docker {
         image 'artifactory.devbox.local/docker-local/myrepo/jdk8:latest'
         args '-v $HOME/.m2:/root/.m2 -v $HOME/.ssh:/home/jenkins/.ssh  -v /etc/ansible:/etc/ansible -v $HOME/.ansible/tmp:/.ansible/tmp -v $HOME/.ansible/cp:/.ansible/cp'
      }
   }
</code></pre>
",23745,2020-10-09T20:31:40.660,"[""def user_id\ndef group_id\nnode {\n   user_id = sh(returnStdout: true, script: 'id -u').trim()\n   group_id = sh(returnStdout: true, script: 'id -g').trim()\n}\n\n"", '--build-arg JenkinsUserId=${user_id} --build-arg JenkinsGroupId=${group_id}\n', 'FROM alpine:latest\n\n#pick up provided ARGs for the bild\n\nARG JenkinsUserId\nARG JenkinsGroupId\n\n//do your stuff here\n\n#create Ansible config directory\nRUN set -xe \\\n    && mkdir -p /etc/ansible\n\n#create Ansible tmp directory\nRUN set -xe \\\n    && mkdir -p /.ansible/tmp\n\n#set ANSIBLE_LOCAL_TEMP\nENV ANSIBLE_LOCAL_TEMP /.ansible/tmp\n\n#create Ansible cp directory\nRUN set -xe \\\n    && mkdir -p /.ansible/cp\n\n#set ANSIBLE_SSH_CONTROL_PATH_DIR\nENV ANSIBLE_SSH_CONTROL_PATH_DIR /.ansible/cp\n\n# Create Jenkins group and user\nRUN if ! id $JenkinsUserId; then \\\n    groupadd -g ${JenkinsGroupId} jenkins; \\\n    useradd jenkins -u ${JenkinsUserId} -g jenkins --shell /bin/bash --create-home; \\\n  else \\\n    addgroup --gid 1000 -S jenkins && adduser --uid 1000 -S jenkins -G jenkins; \\\n  fi\n\nRUN addgroup jenkins root\n\n# Tell docker that all future commands should run as the appuser user\nUSER jenkins\n', ""   agent {\n      docker {\n         image 'artifactory.devbox.local/docker-local/myrepo/jdk8:latest'\n         args '-v $HOME/.m2:/root/.m2 -v $HOME/.ssh:/home/jenkins/.ssh  -v /etc/ansible:/etc/ansible -v $HOME/.ansible/tmp:/.ansible/tmp -v $HOME/.ansible/cp:/.ansible/cp'\n      }\n   }\n""]"
1498,12557,12555,CC BY-SA 4.0,2020-10-10T00:16:09.580,"<p>I believe this is due to non existing variable attribute.<br />
Most likely <code>chain_from_certificate1</code> and <code>chain_from_certificate2</code> don't have <code>stdout</code></p>
<p>Did you try debug by printing the variables?<br />
With <code>stdout</code>:<br />
Did this throw similar failure?</p>
<pre><code>    - name: print variable
      debug:
        msg: &quot;{{ chain_from_certificate1.stdout }}&quot;
</code></pre>
<p>Without <code>stdout</code>:<br />
What is output of this?<br />
Will this print same output as of manually execute <code>openssl x509 -issuer -noout -in Certiticate1</code>?</p>
<pre><code>    - name: print variable
      debug:
        msg: &quot;{{ chain_from_certificate1 }}&quot;
</code></pre>
<p>My assumption is that the script set the value of <code>stdout</code> in <code>chain_from_certificate1</code> and <code>chain_from_certificate2</code> rather than the <code>stdout: &lt;value&gt;</code>. Therefor <code>stdout</code> do not exist as attribute.<br />
Or <code>chain_from_certificate1</code> and <code>chain_from_certificate2</code> contain another data structure.</p>
<p>The key is to print them out.</p>
",23898,2020-10-10T00:33:44.063,"['    - name: print variable\n      debug:\n        msg: ""{{ chain_from_certificate1.stdout }}""\n', '    - name: print variable\n      debug:\n        msg: ""{{ chain_from_certificate1 }}""\n']"
1499,12559,12558,CC BY-SA 4.0,2020-10-10T01:59:21.130,"<p>Ok, found it <a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=azure-devops&amp;tabs=yaml#build-variables-devops-services"" rel=""nofollow noreferrer"">here</a>:</p>
<pre><code>Build.SourceBranch  

The branch of the triggering repo the build was queued for. Some examples:

 - Git repo branch: refs/heads/master 
 - Git repo pull request: refs/pull/1/merge 
 - TFVC repo branch: $/teamproject/main 
 - TFVC repo gated check-in: Gated_2016-06-06_05.20.51.4369;username@live.com 
 - TFVC repo shelveset build: myshelveset;username@live.com

When your pipeline is triggered by a tag: refs/tags/your-tag-name
When you use this variable in your build number format, the forward slash characters (/) are replaced with underscore characters _).

Note: In TFVC, if you are running a gated check-in build or manually building a shelveset, you cannot use this variable in your build number format.
</code></pre>
",11490,2020-10-10T01:59:21.130,"['Build.SourceBranch  \n\nThe branch of the triggering repo the build was queued for. Some examples:\n\n - Git repo branch: refs/heads/master \n - Git repo pull request: refs/pull/1/merge \n - TFVC repo branch: $/teamproject/main \n - TFVC repo gated check-in: Gated_2016-06-06_05.20.51.4369;username@live.com \n - TFVC repo shelveset build: myshelveset;username@live.com\n\nWhen your pipeline is triggered by a tag: refs/tags/your-tag-name\nWhen you use this variable in your build number format, the forward slash characters (/) are replaced with underscore characters _).\n\nNote: In TFVC, if you are running a gated check-in build or manually building a shelveset, you cannot use this variable in your build number format.\n']"
1500,12561,12547,CC BY-SA 4.0,2020-10-10T07:09:34.933,"<p>I'm pretty sure this <a href=""https://www.jenkins.io/doc/book/managing/system-properties/#hudson-util-ringbufferloghandler-defaultsize"" rel=""nofollow noreferrer"">Jenkins system property</a> will do the trick:</p>
<blockquote>
<pre><code>hudson.util.RingBufferLogHandler.defaultSize
</code></pre>
<p>tuning</p>
<p>Since: 1.563</p>
<p>Default:  256</p>
<p><strong>Description:</strong> Number of log entries in loggers available on the UI at /log/</p>
</blockquote>
<p>You can also custom <a href=""https://support.cloudbees.com/hc/en-us/articles/115002626172-Configure-Loggers-for-Jenkins"" rel=""nofollow noreferrer"">Configure Loggers for Jenkins</a> or <a href=""https://support.cloudbees.com/hc/en-us/articles/204880580-How-do-I-create-a-logger-in-Jenkins-for-troubleshooting-and-diagnostic-information-"" rel=""nofollow noreferrer"">create a logger in Jenkins for troubleshooting and diagnostic information</a> that capture specifics you are looking for.</p>
<p>Additional references:<br>
<a href=""https://wiki.jenkins.io/display/JENKINS/Logging"" rel=""nofollow noreferrer"">JENKINS - Logging</a><br>
<a href=""https://wiki.jenkins.io/display/JENKINS/Logger+Configuration"" rel=""nofollow noreferrer"">JENKINS - Logger Configuration</a></p>
<p>Or, if you are the admin, you should be able simply to scan the logs on the filesystem. Review what log rotation options and retention you may have.</p>
",13379,2020-10-10T07:35:23.503,['hudson.util.RingBufferLogHandler.defaultSize\n']
1501,12567,5762,CC BY-SA 4.0,2020-10-12T18:51:12.620,"<p>I am not entirely sure what configs you were using, but here is a process using CLI (gcloud and gsutil). The end product is a new custom role replacing the current standard roles/storage.objectViewer on allUsers for a GCP Bucket.</p>
<p>Recommend using GCP Cloud Cloud Shell in your Project: <a href=""https://cloud.google.com/shell"" rel=""nofollow noreferrer"">https://cloud.google.com/shell</a></p>
<ol>
<li>Create a new Role with the Custom Permissions you would like.</li>
</ol>
<p>Create yaml file to hold the new config:</p>
<pre><code>vi custom_role.yaml
</code></pre>
<p>Add role configurations to new custom_role.yaml:</p>
<pre><code>title: &quot;storageobjectviewer.nolist&quot;
description: &quot;Storage Object Viewer Role without source objects list&quot;
stage: &quot;ALPHA&quot;
includedPermissions:
- resourcemanager.projects.get
- storage.objects.get
</code></pre>
<p>Create new Role in GCP:</p>
<pre><code>gcloud iam roles create storageobjectviewer.nolist --project=[YOUR PROJECT] --file=custom_role.yaml
</code></pre>
<ol start=""2"">
<li>Pull current permissions for [YOUR BUCKET] locally:</li>
</ol>
<blockquote>
<p>gsutil iam get gs://[YOUR BUCKET] &gt; perms.txt</p>
</blockquote>
<ol start=""3"">
<li>Update Permissions with the new role.</li>
</ol>
<p>Should only be this section:</p>
<blockquote>
<pre><code>{
  &quot;members&quot;: [
    &quot;allUsers&quot;
  ],
  &quot;role&quot;: &quot;projects/[YOUR PROJECT]/roles/storageobjectviewer.nolist&quot;
}
</code></pre>
</blockquote>
<ol start=""4"">
<li>Update the allUsers to the new role on [YOUR BUCKET]</li>
</ol>
<blockquote>
<p>gsutil iam set perms.txt  gs://[YOUR BUCKET]</p>
</blockquote>
<p>The new configuration should be viewable in CLI:</p>
<pre><code>gsutil iam get gs://[YOUR BUCKET]
</code></pre>
<p>Also in the UI:
Bucket Details -&gt; Permissions
<a href=""https://i.stack.imgur.com/Y2IE3.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Y2IE3.jpg"" alt=""enter image description here"" /></a></p>
<p>and IAM -&gt; Roles
<a href=""https://i.stack.imgur.com/wO4QG.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wO4QG.jpg"" alt=""enter image description here"" /></a>
Hopefully this helps!</p>
<p>Additional Info:</p>
<ul>
<li><a href=""https://cloud.google.com/iam/docs/creating-custom-roles#iam-custom-roles-create-gcloud"" rel=""nofollow noreferrer"">https://cloud.google.com/iam/docs/creating-custom-roles#iam-custom-roles-create-gcloud</a></li>
<li><a href=""https://cloud.google.com/storage/docs/gsutil/commands/iam"" rel=""nofollow noreferrer"">https://cloud.google.com/storage/docs/gsutil/commands/iam</a></li>
<li><a href=""https://cloud.google.com/storage/docs/access-control/making-data-public#gsutil"" rel=""nofollow noreferrer"">https://cloud.google.com/storage/docs/access-control/making-data-public#gsutil</a></li>
<li><a href=""https://cloud.google.com/storage/docs/access-control/iam-roles"" rel=""nofollow noreferrer"">https://cloud.google.com/storage/docs/access-control/iam-roles</a></li>
</ul>
",15016,2020-10-12T18:51:12.620,"['vi custom_role.yaml\n', 'title: ""storageobjectviewer.nolist""\ndescription: ""Storage Object Viewer Role without source objects list""\nstage: ""ALPHA""\nincludedPermissions:\n- resourcemanager.projects.get\n- storage.objects.get\n', 'gcloud iam roles create storageobjectviewer.nolist --project=[YOUR PROJECT] --file=custom_role.yaml\n', '{\n  ""members"": [\n    ""allUsers""\n  ],\n  ""role"": ""projects/[YOUR PROJECT]/roles/storageobjectviewer.nolist""\n}\n', 'gsutil iam get gs://[YOUR BUCKET]\n']"
1502,12575,12534,CC BY-SA 4.0,2020-10-14T14:53:40.757,"<p>Technically I guess something like this would print out any branchs between any particular branch and your master branch:</p>
<pre><code>for hash in $(git log --format=%h master..); do if git branch --contains=$hash | grep -qv $(git name-rev HEAD | sed -e 's#HEAD ##g'); then git branch --contains=$hash | grep -v $(git name-rev HEAD | sed -e 's#HEAD ##g'); fi; done
</code></pre>
<p>But fundamentally there is probably an underlying problem here, I'm not intimate with your work flow or the teams you work with, but it seems unlikely to me that developers would accidentally create a new feature branch rooted on another feature branch unless they actually wanted some of the code in that other feature branch, perhaps to reuse in delivering whatever the new feature might be.</p>
<p>It seems that you might make a lot of improvement to your process quite quickly and easily by simply ensuring that the all features that are currently being worked on to completion are included in the next release and thus cN be merged into a pre-release branch as soon as they are approved. From there any branch taken from that pre-release branch should only contain features intended to be released,but it would mean that if a developer wrote code they thought was applicable to more than one problem,then they would almost immediately be able to reuse it once merged.</p>
<p>Although I'm not entirely sure that I've understood the issue you are facing, it seems to me that the existence of code in two branches isn't actually a problem, it's just code reuse. If one of those branches is pulled from the release then that's fine, the code that is being reused would still need to stay?</p>
",677,2020-10-14T14:53:40.757,"[""for hash in $(git log --format=%h master..); do if git branch --contains=$hash | grep -qv $(git name-rev HEAD | sed -e 's#HEAD ##g'); then git branch --contains=$hash | grep -v $(git name-rev HEAD | sed -e 's#HEAD ##g'); fi; done\n""]"
1503,12588,12254,CC BY-SA 4.0,2020-10-16T15:59:55.117,"<p>I ended up using the <code>cyrilgdn/postgresql</code> provider which allowed be to create/destroy db as needed</p>
<pre><code>terraform {
  required_providers {
    hashiaws = {
      source  = &quot;hashicorp/aws&quot;
      version = &quot;~&gt; 3.4.0&quot;
    }
    postgresql = {
      source  = &quot;cyrilgdn/postgresql&quot;
      version = &quot;1.7.2&quot;
    }
  }
  required_version = &quot;&gt;= 0.13&quot;
}

provider &quot;postgresql&quot; {
  host             = local.db_url
  port             = local.db_port
  database         = local.db_name
  username         = local.db_usr
  password         = local.db_pwd
  sslmode          = &quot;disable&quot;
  connect_timeout  = 15
  expected_version = local.db_eng_ver
}
</code></pre>
<p>The only downside to this solution is that the server you are running TF on will need to have access to the RDS manage instance</p>
",6374,2020-10-16T15:59:55.117,"['terraform {\n  required_providers {\n    hashiaws = {\n      source  = ""hashicorp/aws""\n      version = ""~> 3.4.0""\n    }\n    postgresql = {\n      source  = ""cyrilgdn/postgresql""\n      version = ""1.7.2""\n    }\n  }\n  required_version = "">= 0.13""\n}\n\nprovider ""postgresql"" {\n  host             = local.db_url\n  port             = local.db_port\n  database         = local.db_name\n  username         = local.db_usr\n  password         = local.db_pwd\n  sslmode          = ""disable""\n  connect_timeout  = 15\n  expected_version = local.db_eng_ver\n}\n']"
1504,12590,12586,CC BY-SA 4.0,2020-10-17T20:42:00.153,"<p>The problem seems to be that the ubuntu:latest image is stale.
Changing to ubuntu:bionic fixes the issue:</p>
<pre><code>FROM ubuntu:bionic AS toolchain
ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update &amp;&amp; apt-get install -y \
  build-essential \
  g++-5
</code></pre>
<p>I don't know why an old image is being used, but that seems like a separate question.</p>
",16456,2020-10-17T20:42:00.153,['FROM ubuntu:bionic AS toolchain\nENV DEBIAN_FRONTEND=noninteractive\nRUN apt-get update && apt-get install -y \\\n  build-essential \\\n  g++-5\n']
1505,12606,12597,CC BY-SA 4.0,2020-10-20T12:19:15.967,"<p>Use a combination of <a href=""https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-readiness-probes"" rel=""nofollow noreferrer"">Readiness Probes</a> and a proper deployment strategy.</p>
<ol>
<li>Configure your Deployment spec like so:
<pre><code>spec:
  replicas: 4    # or as many as you need to have
  strategy:
    rollingUpdate:
  maxUnavailable: 0
  maxSurge: 1
</code></pre>
<code>maxUnavailable</code> = 0 means that there should always be a number of pods available equal to the <code>replicas</code> count. <code>maxSurge</code> = 1 means that kubernetes will create the new pods one at a time, and destroy the old ones one-at-a-time as well.</li>
<li>Implement a <code>readinessProbe</code> which should return a successful response when the database migration has completed. You'd have to write the logic for that yourself, but if you do it right, kubernetes will create a pod with the new Deployment and wait for it to complete and only after that, evict 1 of the old ones.</li>
</ol>
<p>PS: It's worth noting that this approach will cause your node to temporarily contain more pods than your <code>replicas</code> config implies, namely <code>replicas + 1</code> for a short period of time while deploying. You need to make sure that your node can handle the little extra load untill the rollout is complete.</p>
",24391,2020-10-20T15:30:42.303,['spec:\n  replicas: 4    # or as many as you need to have\n  strategy:\n    rollingUpdate:\n  maxUnavailable: 0\n  maxSurge: 1\n']
1506,12610,12607,CC BY-SA 4.0,2020-10-20T21:04:53.150,"<p>You can use <code>kubectl get -o json</code> and parse the output using <a href=""https://github.com/stedolan/jq"" rel=""nofollow noreferrer""><code>jq</code></a> to iterate over the deployments, matching any desired <code>configMapKeyRef.name</code> and returning a <code>uniq</code> list of deployments.</p>
<p>This should work:</p>
<pre><code>kubectl get deployments --all-namespaces -o json | jq -r '.items | map(select(.spec.template.spec.containers[]?.env[]?.valueFrom.configMapKeyRef.name == &quot;london-tz-config&quot; ) | .metadata.name) | .[]' | uniq
</code></pre>
",13139,2020-10-20T21:04:53.150,"['kubectl get deployments --all-namespaces -o json | jq -r \'.items | map(select(.spec.template.spec.containers[]?.env[]?.valueFrom.configMapKeyRef.name == ""london-tz-config"" ) | .metadata.name) | .[]\' | uniq\n']"
1507,12612,12609,CC BY-SA 4.0,2020-10-20T23:16:35.823,"<p>Q: <strong>&quot;<em>Override certain parameters that pass them into the include_role task.</em>&quot;</strong></p>
<p>A: The parameter <a href=""https://docs.ansible.com/ansible/latest/collections/ansible/builtin/include_role_module.html#parameter-tasks_from"" rel=""nofollow noreferrer""><em>tasks_from</em></a> serves this use-case. For example, create the task file</p>
<pre class=""lang-yaml prettyprint-override""><code>shell&gt; cat roles/git_cached/tasks/git.yml
- git:
    repo: &quot;{{ params.repo }}&quot;
    dest: &quot;{{ params.dest }}&quot;
    recursive: &quot;{{ params.recursive|default(ommit) }}&quot;
    depth: &quot;{{ params.depth|default('1') }}&quot;
</code></pre>
<p>Then &quot;call&quot; this task</p>
<pre class=""lang-yaml prettyprint-override""><code>    - name: Download something via Git
      include_role:
        name: git_cached
        tasks_from: git.yml
      vars:
        params:
          repo: https://somerepo
          dest: /some/path
</code></pre>
<p>You might want to complete the task with all <a href=""https://docs.ansible.com/ansible/latest/collections/ansible/builtin/git_module.html#ansible-builtin-git-deploy-software-or-files-from-git-checkouts"" rel=""nofollow noreferrer"">git</a> parameters:</p>
<ul>
<li><p>The parameters <em>repo</em> and <em>dest</em> are required.</p>
</li>
<li><p>In some parameters, like <em>recursive</em>, the default values are defined. You can either omit the parameter, in which case the default value will be used, or define your own default.</p>
</li>
<li><p>Some parameters, like <em>depth</em>, don't have defaults.  Also here you can either omit the parameter, in which case the parameter won't be used or define your own default.</p>
</li>
<li><p>It's a good idea to &quot;namespace&quot; the variables.</p>
</li>
<li><p>It's a good idea to put the default variables into roles/git_cached/defaults/main.yml</p>
</li>
</ul>
",7715,2020-10-20T23:16:35.823,"['shell> cat roles/git_cached/tasks/git.yml\n- git:\n    repo: ""{{ params.repo }}""\n    dest: ""{{ params.dest }}""\n    recursive: ""{{ params.recursive|default(ommit) }}""\n    depth: ""{{ params.depth|default(\'1\') }}""\n', '    - name: Download something via Git\n      include_role:\n        name: git_cached\n        tasks_from: git.yml\n      vars:\n        params:\n          repo: https://somerepo\n          dest: /some/path\n']"
1508,12641,12629,CC BY-SA 4.0,2020-10-25T21:16:23.107,"<p>Notice that what you're trying to do is not merging inventories.  Merging inventories happens when you have two fully defined inventories and you try to, well, merge them.  So, you have an inventory with a set of defined hosts, groups and variables and you combine that with another inventory with its own hosts, groups and variables.</p>
<p>In your example, what you're trying to do is to split the definition of a single inventory.  The <code>aws_ec2</code> plugin requires some information so it goes to Amazon and say, 'hey take this info and give me back my inventory'.  You want part of that information in one file, part in another one.</p>
<p>Once you're using a plugin, the inventory's parsing will be controlled by the plugin, so I don't think there are any guarantees that stuff that works elsewhere (like variables) will work here.</p>
<p>You can test that; run <code>ansible-playbook</code> without secrets.yaml and set each of the variables as extra vars using <code>-e</code>:</p>
<pre><code>ansible-playbook \
 -i /opt/ansible/inventories/aws_ec2.yaml  \
 -e aws_access_key=xxx \
 -e aws_secret_key=xxx \
 -e aws_security_token=xxx \
 /opt/ansible/playbooks/test.yaml
</code></pre>
<p>If that works, then you have validated that you can use Ansible variables in that place, and you just need to find a proper place to put them.  I'm not sure where exactly to put that, though.</p>
<p>If you don't mind to put that data elsewhere, the plugin accepts those values you're trying to separate as environment variables:</p>
<pre><code>ansible-doc -t inventory aws_ec2

- aws_access_key
    The AWS access key to use.
    (Aliases: aws_access_key_id)[Default: (null)]
    set_via:
      env:
      - name: EC2_ACCESS_KEY
      - name: AWS_ACCESS_KEY
      - name: AWS_ACCESS_KEY_ID
    
    type: str
</code></pre>
",16819,2020-10-25T21:16:23.107,"['ansible-playbook \\\n -i /opt/ansible/inventories/aws_ec2.yaml  \\\n -e aws_access_key=xxx \\\n -e aws_secret_key=xxx \\\n -e aws_security_token=xxx \\\n /opt/ansible/playbooks/test.yaml\n', 'ansible-doc -t inventory aws_ec2\n\n- aws_access_key\n    The AWS access key to use.\n    (Aliases: aws_access_key_id)[Default: (null)]\n    set_via:\n      env:\n      - name: EC2_ACCESS_KEY\n      - name: AWS_ACCESS_KEY\n      - name: AWS_ACCESS_KEY_ID\n    \n    type: str\n']"
1509,12643,1353,CC BY-SA 4.0,2020-10-26T11:18:20.550,"<p>Ansible usually takes relative path according to <code>inventory_dir</code> &amp; <code>playbook_dir</code>:</p>
<pre class=""lang-yaml prettyprint-override""><code>- debug: var=inventory_dir
- debug: var=playbook_dir
</code></pre>
",5337,2020-10-26T11:18:20.550,['- debug: var=inventory_dir\n- debug: var=playbook_dir\n']
1510,12663,12662,CC BY-SA 4.0,2020-10-30T01:43:48.190,"<p>Got it! <code>reuseNode</code> needs to be set true for each docker agent:</p>
<pre><code>       agent { docker { 
            image 'golang:latest' 
            reuseNode true
        } }
</code></pre>
<p>Wish that didn't take a couple hours to learn but que sera sera</p>
",24255,2020-10-30T01:43:48.190,"[""       agent { docker { \n            image 'golang:latest' \n            reuseNode true\n        } }\n""]"
1511,12675,12659,CC BY-SA 4.0,2020-10-30T20:53:57.777,"<p>Docker itself does not provide such rolling update feature. You have to do it by hand which is not an easy task. Even if you want to use a one node Swarm cluster, the scheduler does have downtime.</p>
<pre><code>The scheduler applies rolling updates as follows by default:

Stop the first task.
Schedule update for the stopped task.
Start the container for the updated task.
</code></pre>
<p>If you only have one machine, you can try something like <a href=""https://k3s.io"" rel=""nofollow noreferrer"">k3s</a>, which is a lightweight Kubernetes distribution. You'll be able to use a Deployment, a Kubernetes object, which provide zero downtime rolling update feature.</p>
",16683,2020-10-30T20:53:57.777,['The scheduler applies rolling updates as follows by default:\n\nStop the first task.\nSchedule update for the stopped task.\nStart the container for the updated task.\n']
1512,12676,12668,CC BY-SA 4.0,2020-10-31T03:04:26.717,"<p>Problem solved:</p>
<p>It's because of endianess of output.</p>
<p>There is an option <code>--endian</code> which by default is <code>little</code>.</p>
<p>The example string was <code>cá</code>, which translates to <code>63 C3 A1</code> <code>utf-8</code> encoded:</p>
<pre><code>~ $ echo -n cá | od --endian=big -x
0000000 63c3 a100
0000003
</code></pre>
<p>(The <code>-n</code> prevents <code>\n</code> in the end of string, making last byte <code>00</code>)</p>
<p>So it's exactly the same output, but with bytes inverted:</p>
<pre><code>~ $ echo -n cá | od --endian=little -x
0000000 c363 00a1
0000003
</code></pre>
<p>(<code>c363</code> instead of <code>63c3</code> and so forth).</p>
",24523,2020-10-31T03:04:26.717,"['~ $ echo -n cá | od --endian=big -x\n0000000 63c3 a100\n0000003\n', '~ $ echo -n cá | od --endian=little -x\n0000000 c363 00a1\n0000003\n']"
1513,12680,12677,CC BY-SA 4.0,2020-11-01T11:07:32.153,"<p>In short, it's not practically possible. This <a href=""https://stackoverflow.com/a/12472740/598141"">S/O answer</a> is quite detailed.</p>
<blockquote>
<p>Jenkins used a <a href=""https://en.m.wikipedia.org/wiki/Cron#CRON_expression"" rel=""nofollow noreferrer"">cron
expression</a>, and
the different fields are:</p>
<pre><code>MINUTES Minutes in one hour (0-59)
HOURS Hours in one day (0-23)
DAYMONTH Day in a month (1-31)
MONTH Month in a year (1-12)
DAYWEEK Day of the week (0-7) where 0 and 7 are sunday
</code></pre>
</blockquote>
<p>cron syntax simply does not support every <code>n days</code>.</p>
<p>An impractical option wuld be to have a daily job with a <a href=""https://plugins.jenkins.io/conditional-buildstep/"" rel=""nofollow noreferrer"">Conditional BuildStep</a> to calculate if this day is n × 30 days from a given fixed day and abort if not..</p>
<p>But every 30 days doesn't really align w/calendar anyways, so is that really the intent?</p>
",13379,2020-11-01T11:07:32.153,['MINUTES Minutes in one hour (0-59)\nHOURS Hours in one day (0-23)\nDAYMONTH Day in a month (1-31)\nMONTH Month in a year (1-12)\nDAYWEEK Day of the week (0-7) where 0 and 7 are sunday\n']
1514,12682,12668,CC BY-SA 4.0,2020-11-01T16:09:07.090,"<p>Because of endianess and other things I've settled on these two aliases I use all the time.  The important thing is <code>-t x1</code></p>
<pre><code>alias od1='od -Ax -t x1'
alias od2='od -Ax -t x1 -c'
</code></pre>
",3529,2020-11-01T16:09:07.090,"[""alias od1='od -Ax -t x1'\nalias od2='od -Ax -t x1 -c'\n""]"
1515,12691,5848,CC BY-SA 4.0,2020-11-03T15:10:33.360,"<p><strong>This is possible using AWS SDKs.</strong></p>
<p>I was cleaning my tabs after finishing this task and decided I would write an answer to help other people.</p>
<p><strong>Versions:</strong></p>
<ul>
<li><p>aws-cli/2.0.61</p>
</li>
<li><p>go1.15.3 linux/amd64</p>
</li>
</ul>
<hr />
<p>Let's do this in Golang with the right imports.</p>
<pre><code> import (
     &quot;fmt&quot;
     &quot;github.com/aws/aws-sdk-go/aws&quot;
     &quot;context&quot;
     &quot;github.com/aws/aws-sdk-go-v2/config&quot;
     &quot;github.com/aws/aws-sdk-go-v2/service/iam&quot;
)
</code></pre>
<p>First, you want to init a session and a client:</p>
<pre><code>cfg, err := config.LoadDefaultConfig() 
svc := iam.NewFromConfig(cfg)
</code></pre>
<p>Then you want to get a list of roles, to iterate through all role names. You can also use a specific role name because that's the only thing you will need to get the LastUsedDate:</p>
<pre><code>roles_iam, err := svc.ListRoles(context.Background(), &amp;iam.ListRolesInput{
PathPrefix: aws.String(&quot;/&quot;)})
if err != nil {
    fmt.Println(&quot;Error&quot;, err)
    return  
}

/** For simplicity and less dereferencing: more execution speed **/
roles_list := roles_iam.Roles    
</code></pre>
<p>Finally, iterate through a loop if you need to get LastUsedDate for all roles. Just set input with the right GetRoleInput arguments then call svc.GetRole to get a structure with your info.</p>
<pre><code>/** Declare slice 'unused_roles' containing string unused role names **/
var unused_roles []string 

for i := range roles_list {
    role_name := *roles_list[i].RoleName
    input := &amp;iam.GetRoleInput{
        RoleName: aws.String(*roles_list[i].RoleName),
    }
    role_info, err := svc.GetRole(context.Background(), input)
    if err != nil {
        fmt.Println(&quot;Error&quot;, err)
    }    
      
/** Check if role has never been used **/           
    if (role_info.Role.RoleLastUsed.LastUsedDate) == nil {
        fmt.Printf(&quot;Role %s has never been used\n&quot;, role_name)
        unused_roles = append(unused_roles, role_name)
        continue
    }
    last_used_date := *role_info.Role.RoleLastUsed.LastUsedDate
}
</code></pre>
<p>More info:</p>
<p><a href=""https://docs.aws.amazon.com/IAM/latest/APIReference/API_Role.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/IAM/latest/APIReference/API_Role.html</a></p>
<p><a href=""https://docs.aws.amazon.com/IAM/latest/APIReference/API_RoleLastUsed.html"" rel=""nofollow noreferrer"">https://docs.aws.amazon.com/IAM/latest/APIReference/API_RoleLastUsed.html</a></p>
",24571,2020-11-03T15:24:31.900,"[' import (\n     ""fmt""\n     ""github.com/aws/aws-sdk-go/aws""\n     ""context""\n     ""github.com/aws/aws-sdk-go-v2/config""\n     ""github.com/aws/aws-sdk-go-v2/service/iam""\n)\n', 'cfg, err := config.LoadDefaultConfig() \nsvc := iam.NewFromConfig(cfg)\n', 'roles_iam, err := svc.ListRoles(context.Background(), &iam.ListRolesInput{\nPathPrefix: aws.String(""/"")})\nif err != nil {\n    fmt.Println(""Error"", err)\n    return  \n}\n\n/** For simplicity and less dereferencing: more execution speed **/\nroles_list := roles_iam.Roles    \n', '/** Declare slice \'unused_roles\' containing string unused role names **/\nvar unused_roles []string \n\nfor i := range roles_list {\n    role_name := *roles_list[i].RoleName\n    input := &iam.GetRoleInput{\n        RoleName: aws.String(*roles_list[i].RoleName),\n    }\n    role_info, err := svc.GetRole(context.Background(), input)\n    if err != nil {\n        fmt.Println(""Error"", err)\n    }    \n      \n/** Check if role has never been used **/           \n    if (role_info.Role.RoleLastUsed.LastUsedDate) == nil {\n        fmt.Printf(""Role %s has never been used\\n"", role_name)\n        unused_roles = append(unused_roles, role_name)\n        continue\n    }\n    last_used_date := *role_info.Role.RoleLastUsed.LastUsedDate\n}\n']"
1516,12699,12660,CC BY-SA 4.0,2020-11-04T13:14:57.463,"<p>So basically I've ended up turning these flags off (<code>/app/management/kibana/settings</code>)</p>
<pre><code>filterEditor:suggestValues
discover:searchOnPageLoad
doc_table:highlight
visualize:enableLabs
telemetry:enabled
</code></pre>
<p>Other ideas I had in mind:</p>
<ul>
<li>adding nginx as a proxy caching all the static files (js for plugins / images)</li>
<li>warmup script (periodically makes requests to predefined hot pages for Kibana to internally cache these pages) if that would work</li>
<li>migrate to hosted cloud solution which might be optimized better for the loading time</li>
</ul>
",19083,2020-11-04T13:14:57.463,['filterEditor:suggestValues\ndiscover:searchOnPageLoad\ndoc_table:highlight\nvisualize:enableLabs\ntelemetry:enabled\n']
1517,12715,12673,CC BY-SA 4.0,2020-11-05T20:37:41.333,"<p>I'm resolved my question like bellow:</p>
<ul>
<li>I discovered that some arguments that I used before not was used when you use the <strong>s3_origin</strong> and them are used with <strong>custom_orogin</strong></li>
</ul>
<p>Was necessary used too variables <code>type=list(object({foo=bar})</code> for my dynamic blocks lists.</p>
<p>Part of my module bellow:</p>
<p><strong>main.tf</strong></p>
<pre><code> dynamic &quot;origin&quot; {
    for_each = var.origin
    content {

      domain_name = origin.value.domain_name
      origin_id   = origin.value.origin_id

      s3_origin_config {
        origin_access_identity = origin.value.origin_access_identity
      }
    }
  }
</code></pre>
<p><strong>vars.tf</strong></p>
<pre><code>variable &quot;origin&quot; {
  type        = list(object({ domain_name = any, origin_id = string, origin_access_identity = string }))
  description = &quot;One or more origins for this distribution (multiples allowed).&quot;
}
</code></pre>
<p>Another thing that I learned it's when you set a <code>default=value</code> onto variable <code>type</code> same this <em>var</em> is (optional) you turn them (required).</p>
",18637,2020-11-05T20:37:41.333,"[' dynamic ""origin"" {\n    for_each = var.origin\n    content {\n\n      domain_name = origin.value.domain_name\n      origin_id   = origin.value.origin_id\n\n      s3_origin_config {\n        origin_access_identity = origin.value.origin_access_identity\n      }\n    }\n  }\n', 'variable ""origin"" {\n  type        = list(object({ domain_name = any, origin_id = string, origin_access_identity = string }))\n  description = ""One or more origins for this distribution (multiples allowed).""\n}\n']"
1518,12722,12703,CC BY-SA 4.0,2020-11-06T19:02:23.493,"<p>That is not good design to have docker or any lib update after logging into the container. As mentioned by Andrea Giaime Bodei , you need to update the base image in the Dockerfile and rebuild the image. The docker images are immutable.</p>
<pre><code># Download base image ubuntu 20.04
FROM ubuntu:20.04

# LABEL about the custom image
LABEL maintainer=&quot;abcd@me.com&quot;
LABEL version=&quot;0.1&quot;
LABEL description=&quot;This is custom Docker Image for \
the test&quot;
</code></pre>
",22070,2020-11-06T19:02:23.493,"['# Download base image ubuntu 20.04\nFROM ubuntu:20.04\n\n# LABEL about the custom image\nLABEL maintainer=""abcd@me.com""\nLABEL version=""0.1""\nLABEL description=""This is custom Docker Image for \\\nthe test""\n']"
1519,12723,12713,CC BY-SA 4.0,2020-11-06T19:25:04.247,"<p>Ideally dont run docker as superuser(root). You should create a user within dockerfile and chown the file system with that user. You can create a user and then add access to that user on the file system. In the below example there is appuser , with ownership to src</p>
<pre><code>FROM ubuntu:latest
RUN useradd -r -u 1001 -g appuser appuser
RUN chown -R appuser.appuser /src
USER appuser
CMD [&quot;appuser&quot;, &quot;/src/index.js&quot;] 
</code></pre>
<p>Its not recommended to run as root
You could also run as any user (Say root id = 0) if needed from externally</p>
<pre><code>docker run -d --user 0 ubuntu:latest
</code></pre>
<p>You should never relay on gid/uid  of the linux user outside the container.</p>
",22070,2020-11-06T19:25:04.247,"['FROM ubuntu:latest\nRUN useradd -r -u 1001 -g appuser appuser\nRUN chown -R appuser.appuser /src\nUSER appuser\nCMD [""appuser"", ""/src/index.js""] \n', 'docker run -d --user 0 ubuntu:latest\n']"
1520,12735,12733,CC BY-SA 4.0,2020-11-10T01:12:31.237,"<pre><code>git show -s --format=&quot;%H&quot; &lt;HEAD or Branch Name&gt;
</code></pre>
<p><code>-s</code> supressess the diff output</p>
<p><code>--format=&quot;%H&quot;</code> specifies that only the hash should be shown.</p>
<p>See <code>man git-show</code> for more details.</p>
",24668,2020-11-10T01:12:31.237,"['git show -s --format=""%H"" <HEAD or Branch Name>\n']"
1521,12736,12711,CC BY-SA 4.0,2020-11-10T08:09:43.330,"<p>You do not need to use <code>rewrite</code> for your case, since you want to append <code>_plugin/kibana</code> to <strong>any routes</strong>.</p>
<p>Assuming the nginx config is for <code>http://origin.com/</code>:</p>
<pre><code>server {
    listen 80;
    server_name origin.com;
    location / {
        proxy_set_header X-Forwared-Proto $scheme;

        # http://origin.com/req/1/2 will go to http://target.com/_plugin/kibana/req/1/2
        proxy_pass http://target.com/_plugin/kibana;

    }
}
</code></pre>
",12821,2020-11-10T08:09:43.330,['server {\n    listen 80;\n    server_name origin.com;\n    location / {\n        proxy_set_header X-Forwared-Proto $scheme;\n\n        # http://origin.com/req/1/2 will go to http://target.com/_plugin/kibana/req/1/2\n        proxy_pass http://target.com/_plugin/kibana;\n\n    }\n}\n']
1522,12753,12752,CC BY-SA 4.0,2020-11-14T01:24:56.197,"<p>This at least builds and runs:</p>
<pre><code>root@mordor:/home/nicholas/docker/nginx# 
root@mordor:/home/nicholas/docker/nginx# ls -al
total 16
drwxrwxr-x 2 nicholas nicholas 4096 Nov 13 17:18 .
drwxrwxr-x 3 nicholas nicholas 4096 Nov 13 16:12 ..
-rw-rw-r-- 1 nicholas nicholas   49 Nov 13 17:18 dockerfile
-rw-rw-r-- 1 nicholas nicholas   56 Nov 13 17:18 index.html
root@mordor:/home/nicholas/docker/nginx# 
root@mordor:/home/nicholas/docker/nginx# cat dockerfile 
FROM nginx
COPY index.html /usr/share/nginx/html
root@mordor:/home/nicholas/docker/nginx# 
root@mordor:/home/nicholas/docker/nginx# cat index.html 



hello world

how do I put this file in a diff dir?


root@mordor:/home/nicholas/docker/nginx# 
root@mordor:/home/nicholas/docker/nginx# docker build -t some-content-nginx .
Sending build context to Docker daemon  3.072kB
Step 1/2 : FROM nginx
 ---&gt; c39a868aad02
Step 2/2 : COPY index.html /usr/share/nginx/html
 ---&gt; Using cache
 ---&gt; 07a94375fb55
Successfully built 07a94375fb55
Successfully tagged some-content-nginx:latest
root@mordor:/home/nicholas/docker/nginx# 
root@mordor:/home/nicholas/docker/nginx# docker run --name some-nginx -d -p 8080:80 some-content-nginx
2c912aa5ce5c8b864a6fe79a18ee8e833874f85a75fed1c7020163ca7b90bedb
root@mordor:/home/nicholas/docker/nginx# 
</code></pre>
<p>although I can't seem to get anything from navigating to <code>localhost</code> so I'll have to look closer at the <code>container</code> which is built.</p>
",23443,2020-11-14T01:24:56.197,['root@mordor:/home/nicholas/docker/nginx# \nroot@mordor:/home/nicholas/docker/nginx# ls -al\ntotal 16\ndrwxrwxr-x 2 nicholas nicholas 4096 Nov 13 17:18 .\ndrwxrwxr-x 3 nicholas nicholas 4096 Nov 13 16:12 ..\n-rw-rw-r-- 1 nicholas nicholas   49 Nov 13 17:18 dockerfile\n-rw-rw-r-- 1 nicholas nicholas   56 Nov 13 17:18 index.html\nroot@mordor:/home/nicholas/docker/nginx# \nroot@mordor:/home/nicholas/docker/nginx# cat dockerfile \nFROM nginx\nCOPY index.html /usr/share/nginx/html\nroot@mordor:/home/nicholas/docker/nginx# \nroot@mordor:/home/nicholas/docker/nginx# cat index.html \n\n\n\nhello world\n\nhow do I put this file in a diff dir?\n\n\nroot@mordor:/home/nicholas/docker/nginx# \nroot@mordor:/home/nicholas/docker/nginx# docker build -t some-content-nginx .\nSending build context to Docker daemon  3.072kB\nStep 1/2 : FROM nginx\n ---> c39a868aad02\nStep 2/2 : COPY index.html /usr/share/nginx/html\n ---> Using cache\n ---> 07a94375fb55\nSuccessfully built 07a94375fb55\nSuccessfully tagged some-content-nginx:latest\nroot@mordor:/home/nicholas/docker/nginx# \nroot@mordor:/home/nicholas/docker/nginx# docker run --name some-nginx -d -p 8080:80 some-content-nginx\n2c912aa5ce5c8b864a6fe79a18ee8e833874f85a75fed1c7020163ca7b90bedb\nroot@mordor:/home/nicholas/docker/nginx# \n']
1523,12758,12757,CC BY-SA 4.0,2020-11-14T04:36:41.913,"<p>running and copying files into the container:</p>
<pre><code>root@mordor:~# 
root@mordor:~# sudo docker run --name docker-nginx -p 80:80 -d nginx
29b4280504c2d46c10b8459de0844ba30bce0c1bc97b70521c3f812f29d17c27
root@mordor:~# 
root@mordor:~# docker cp index.html docker-nginx:/indx.html
root@mordor:~# 
root@mordor:~# docker exec -it docker-nginx bash
root@29b4280504c2:/# 
root@29b4280504c2:/# ls
bin   dev          docker-entrypoint.sh  home       lib    media  opt   root  sbin  sys  usr
boot  docker-entrypoint.d  etc           indx.html  lib64  mnt    proc  run   srv   tmp  var
root@29b4280504c2:/# 
root@29b4280504c2:/# cd /usr/share/nginx/html/
root@29b4280504c2:/usr/share/nginx/html# 
root@29b4280504c2:/usr/share/nginx/html# ls
50x.html  index.html
root@29b4280504c2:/usr/share/nginx/html# 
root@29b4280504c2:/usr/share/nginx/html# mv index.html index.html.bkup
root@29b4280504c2:/usr/share/nginx/html# 
root@29b4280504c2:/usr/share/nginx/html# cp /indx.html ./index.html
root@29b4280504c2:/usr/share/nginx/html# 
root@29b4280504c2:/usr/share/nginx/html# exit
exit
root@mordor:~# 
root@mordor:~# docker container list
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                NAMES
29b4280504c2        nginx               &quot;/docker-entrypoint.…&quot;   2 minutes ago       Up 2 minutes        0.0.0.0:80-&gt;80/tcp   docker-nginx
root@mordor:~# 
root@mordor:~# docker stop docker-nginx
docker-nginx
root@mordor:~# 
root@mordor:~# docker start docker-nginx
docker-nginx
root@mordor:~# 
</code></pre>
<p>so that:</p>
<pre><code>nicholas@mordor:~$ 
nicholas@mordor:~$ lynx http://localhost/ --dump
   hello nginx docker world
nicholas@mordor:~$ 
</code></pre>
",23443,2020-11-14T04:36:41.913,"['root@mordor:~# \nroot@mordor:~# sudo docker run --name docker-nginx -p 80:80 -d nginx\n29b4280504c2d46c10b8459de0844ba30bce0c1bc97b70521c3f812f29d17c27\nroot@mordor:~# \nroot@mordor:~# docker cp index.html docker-nginx:/indx.html\nroot@mordor:~# \nroot@mordor:~# docker exec -it docker-nginx bash\nroot@29b4280504c2:/# \nroot@29b4280504c2:/# ls\nbin   dev          docker-entrypoint.sh  home       lib    media  opt   root  sbin  sys  usr\nboot  docker-entrypoint.d  etc           indx.html  lib64  mnt    proc  run   srv   tmp  var\nroot@29b4280504c2:/# \nroot@29b4280504c2:/# cd /usr/share/nginx/html/\nroot@29b4280504c2:/usr/share/nginx/html# \nroot@29b4280504c2:/usr/share/nginx/html# ls\n50x.html  index.html\nroot@29b4280504c2:/usr/share/nginx/html# \nroot@29b4280504c2:/usr/share/nginx/html# mv index.html index.html.bkup\nroot@29b4280504c2:/usr/share/nginx/html# \nroot@29b4280504c2:/usr/share/nginx/html# cp /indx.html ./index.html\nroot@29b4280504c2:/usr/share/nginx/html# \nroot@29b4280504c2:/usr/share/nginx/html# exit\nexit\nroot@mordor:~# \nroot@mordor:~# docker container list\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                NAMES\n29b4280504c2        nginx               ""/docker-entrypoint.…""   2 minutes ago       Up 2 minutes        0.0.0.0:80->80/tcp   docker-nginx\nroot@mordor:~# \nroot@mordor:~# docker stop docker-nginx\ndocker-nginx\nroot@mordor:~# \nroot@mordor:~# docker start docker-nginx\ndocker-nginx\nroot@mordor:~# \n', 'nicholas@mordor:~$ \nnicholas@mordor:~$ lynx http://localhost/ --dump\n   hello nginx docker world\nnicholas@mordor:~$ \n']"
1524,12759,12757,CC BY-SA 4.0,2020-11-14T06:59:03.547,"<p>The &quot;official&quot; nginx image has a specific path where it looks for files. You can either copy a file into the image by creating a new image from it or mount your files into this path as a volume.</p>
<p>To copy files, have a folder with your <code>index.html</code> and a <code>Dockerfile</code> that looks like this:</p>
<pre><code>FROM nginx
COPY index.html /usr/share/nginx/html
</code></pre>
<p>Then build a new image with <code>docker build -t my-nginx .</code></p>
<p>To start a container with your own files as a volume, you can run the container like this:</p>
<pre><code>docker run -p 8080:80 -v ${PWD}:/usr/share/nginx/html nginx
</code></pre>
<p>All the files in your current folder (including the <code>index.html</code>) will now be available via <code>http://localhost:8080/index.html</code>.</p>
<p>Most of this information is covered in the documentation for the image at <a href=""https://hub.docker.com/_/nginx"" rel=""nofollow noreferrer"">https://hub.docker.com/_/nginx</a></p>
",6,2021-03-10T18:58:36.333,"['FROM nginx\nCOPY index.html /usr/share/nginx/html\n', 'docker run -p 8080:80 -v ${PWD}:/usr/share/nginx/html nginx\n']"
1525,12760,12751,CC BY-SA 4.0,2020-11-14T07:07:11.473,"<p>According to your screen dump you have your port 80 mapped to the Traefik container</p>
<p><code>58cd5b59579c        traefik:v2.2                  &quot;/entrypoint.sh --lo…&quot;   16 minutes ago      Up 15 minutes       0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp   frappe_docker_traefik_1</code></p>
<p>The listen address of this mapping is <code>0.0.0.0</code> on both port <code>80 HTTP</code>, and <code>443 HTTPS</code> which means it listens on all your computer interfaces. Including the local-loopback interface which has the address of <code>127.0.0.1</code>.</p>
<p>Most operating systems have a file called <code>hosts</code> which is located at <code>/etc/hosts</code> for Linux, MacOS, BSD and at <code>C:\Windows\System32\drivers\etc\hosts</code> for Windows 10.</p>
<p>This file maps the DNS names (such as <code>localhost</code>) to their IP addresses, like <code>127.0.0.1</code>.</p>
<p>For you to have a working <code>FQDN</code>, you can temporarily create a new mapping in this file to map your desired name to the local-loopback address of 127.0.0.1.</p>
<p>Edit the <code>hosts</code> file and add a line saying:</p>
<pre><code>127.0.0.1 erp.mordor.bounceme.net
</code></pre>
<p>The applications that lookup that name later, such as <code>lynx</code>, will now know that <code>erp.mordor.bounceme.net</code> is located at <code>127.0.0.1</code> IP address. And your Docker Traefik container is listening there (as well) on ports <code>80</code> and <code>443</code>.</p>
",6,2020-11-14T07:07:11.473,['127.0.0.1 erp.mordor.bounceme.net\n']
1526,12774,12771,CC BY-SA 4.0,2020-11-16T13:14:40.693,"<p>This is the output from buildkit. You can run buildkit based builds with a different output syntax:</p>
<pre><code>$ docker build --help
...
  --progress string         Set type of progress output (auto, plain, tty). Use plain to show container output
                            (default &quot;auto&quot;)
</code></pre>
<p>In your command, that would be:</p>
<pre><code>docker build --progress=plain .
</code></pre>
<p>Or you can disable buildkit by setting <code>DOCKER_BUILDKIT=0</code> in your shell:</p>
<pre><code>DOCKER_BUILDKIT=0 docker build .
</code></pre>
",7730,2020-11-16T13:14:40.693,"['$ docker build --help\n...\n  --progress string         Set type of progress output (auto, plain, tty). Use plain to show container output\n                            (default ""auto"")\n', 'docker build --progress=plain .\n', 'DOCKER_BUILDKIT=0 docker build .\n']"
1527,12775,12768,CC BY-SA 4.0,2020-11-16T13:35:38.887,"<p>I've seen it done before but wouldn't call it common. There are other artifact servers, and many git repositories have the concept of a release with artifacts that makes more sense.</p>
<p>I suspect Docker Hub is one of many artifact servers to introduce rate limits and other usage caps, so if you do this, make sure you control (or pay for) the registry server. Otherwise the risk is you'll exceed limits and lose access to your artifacts.</p>
<p>If you only want to copy binaries, then I'd skip the base image and use <code>FROM scratch</code>.</p>
<p>It's also possible to bypass the docker engine entirely and pull the artifacts from the registry server directly to the filesystem. I have a <a href=""https://github.com/regclient/regclient"" rel=""nofollow noreferrer"">regclient</a> project that ships a <code>regctl</code> command with <code>regctl image manifest</code> and <code>regctl layer pull</code> commands. E.g.:</p>
<pre><code>$ regctl image manifest regclient/regctl
{
  &quot;schemaVersion&quot;: 2,
  &quot;mediaType&quot;: &quot;application/vnd.docker.distribution.manifest.v2+json&quot;,
  &quot;config&quot;: {
    &quot;mediaType&quot;: &quot;application/vnd.docker.container.image.v1+json&quot;,
    &quot;size&quot;: 3019,
    &quot;digest&quot;: &quot;sha256:e3abac7c7ce78aaa5efddb5abedd54f8ed3077d9d5b03b5a66ecf9f4c3502454&quot;
  },
  &quot;layers&quot;: [
    {
      &quot;mediaType&quot;: &quot;application/vnd.docker.image.rootfs.diff.tar.gzip&quot;,
      &quot;size&quot;: 930,
      &quot;digest&quot;: &quot;sha256:41437cd6a6e3d3098329474c62ccc5bd01fcf6b41bf35f0e8c89db96110b23ac&quot;
    },
    {
      &quot;mediaType&quot;: &quot;application/vnd.docker.image.rootfs.diff.tar.gzip&quot;,
      &quot;size&quot;: 122413,
      &quot;digest&quot;: &quot;sha256:69d6afda22ccf4f223c016bfd3a108fe0a1ddd15c72978bd238b19201e0e1973&quot;
    },
    {
      &quot;mediaType&quot;: &quot;application/vnd.docker.image.rootfs.diff.tar.gzip&quot;,
      &quot;size&quot;: 161,
      &quot;digest&quot;: &quot;sha256:57dd9736a25ab0b55d9d364dc20ee0946a844a8ac72d7f986ef902826f933e89&quot;
    },
    {
      &quot;mediaType&quot;: &quot;application/vnd.docker.image.rootfs.diff.tar.gzip&quot;,
      &quot;size&quot;: 3963283,
      &quot;digest&quot;: &quot;sha256:282c5a3b4b6c8bf0b7038204919bbfc26c8b120cd87f4a1f573c12c808774c1c&quot;
    }
  ]
}

$ regctl layer pull regclient/regctl sha256:282c5a3b4b6c8bf0b7038204919bbfc26c8b120cd87f4a1f573c12c808774c1c | tar -tzvf -
-rwxr-xr-x root/root  10235904 2020-11-05 20:52 regctl
</code></pre>
<p>Note that the sha's are unique and persistent, so if that hash is unchanged there's no need to pull the binary again. And the above example has a few extra layers since the command is expected to run in the image as a non-root user (/etc/passwd, ca-certificates, and a home directory). For a non-running image, that could be a single layer. E.g.:</p>
<pre><code># change image to your scratch-based source
image=regclient/regctl
store=/tmp
sha=$(regctl image manifest $image --format '{{ (index .Layers 0).Digest}}')
if [ ! -d &quot;$store/$sha&quot; ]; then
  mkdir -p &quot;$store/$sha&quot;
  regctl layer pull $image $sha | tar -xzvf - -C &quot;$store/$sha&quot;
fi
echo &quot;result in $store/$sha&quot;
</code></pre>
",7730,2020-11-16T13:35:38.887,"['$ regctl image manifest regclient/regctl\n{\n  ""schemaVersion"": 2,\n  ""mediaType"": ""application/vnd.docker.distribution.manifest.v2+json"",\n  ""config"": {\n    ""mediaType"": ""application/vnd.docker.container.image.v1+json"",\n    ""size"": 3019,\n    ""digest"": ""sha256:e3abac7c7ce78aaa5efddb5abedd54f8ed3077d9d5b03b5a66ecf9f4c3502454""\n  },\n  ""layers"": [\n    {\n      ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",\n      ""size"": 930,\n      ""digest"": ""sha256:41437cd6a6e3d3098329474c62ccc5bd01fcf6b41bf35f0e8c89db96110b23ac""\n    },\n    {\n      ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",\n      ""size"": 122413,\n      ""digest"": ""sha256:69d6afda22ccf4f223c016bfd3a108fe0a1ddd15c72978bd238b19201e0e1973""\n    },\n    {\n      ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",\n      ""size"": 161,\n      ""digest"": ""sha256:57dd9736a25ab0b55d9d364dc20ee0946a844a8ac72d7f986ef902826f933e89""\n    },\n    {\n      ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",\n      ""size"": 3963283,\n      ""digest"": ""sha256:282c5a3b4b6c8bf0b7038204919bbfc26c8b120cd87f4a1f573c12c808774c1c""\n    }\n  ]\n}\n\n$ regctl layer pull regclient/regctl sha256:282c5a3b4b6c8bf0b7038204919bbfc26c8b120cd87f4a1f573c12c808774c1c | tar -tzvf -\n-rwxr-xr-x root/root  10235904 2020-11-05 20:52 regctl\n', '# change image to your scratch-based source\nimage=regclient/regctl\nstore=/tmp\nsha=$(regctl image manifest $image --format \'{{ (index .Layers 0).Digest}}\')\nif [ ! -d ""$store/$sha"" ]; then\n  mkdir -p ""$store/$sha""\n  regctl layer pull $image $sha | tar -xzvf - -C ""$store/$sha""\nfi\necho ""result in $store/$sha""\n']"
1528,12776,885,CC BY-SA 4.0,2020-11-16T23:02:59.800,"<p>If it is acceptable to set the build status to <code>ABORTED</code> instead of <code>SUCCESS</code>, the following snippet may be used within a pipeline stage to short-circuit the job:</p>
<pre class=""lang-java prettyprint-override""><code>steps {
    script {
        currentBuild.result = 'ABORTED'
        error(&quot;Aborting the job.&quot;)
    }
}
</code></pre>
<p>I tested setting the result to <code>SUCCESS</code>, but doing so resulted in a failed build (using Jenkins 2.235.5). It seems that <code>ABORTED</code> is respected by the <code>error</code> step, while <code>SUCCESS</code> is overridden.</p>
",24759,2020-11-16T23:02:59.800,"['steps {\n    script {\n        currentBuild.result = \'ABORTED\'\n        error(""Aborting the job."")\n    }\n}\n']"
1529,12783,12782,CC BY-SA 4.0,2020-11-17T18:42:59.973,"<p>Okay, found it.</p>
<p>It seems the .gitlab-ci.yml hidden job needs to have a &quot;script:&quot; to solve the problem. See below:</p>
<pre><code>.gitlab-tf-backend: &amp;gitlab-tf-backend
      script:
       - export TF_ADDRESS=${GITLAB_API_ENDPOINT}/projects/${CI_PROJECT_ID}/terraform/state/${STATE_NAME}
       - export TF_HTTP_ADDRESS=${TF_ADDRESS}
       - export TF_HTTP_LOCK_ADDRESS=${TF_ADDRESS}/lock
       - export TF_HTTP_LOCK_METHOD=POST
       - export TF_HTTP_UNLOCK_ADDRESS=${TF_ADDRESS}/lock
       - export TF_HTTP_UNLOCK_METHOD=DELETE
       - export TF_HTTP_USERNAME=${USERNAME}
       - export TF_HTTP_PASSWORD=${GITLAB_TOKEN}
       - export TF_HTTP_RETRY_WAIT_MIN=5
       - echo &quot;Using HTTP Backend at $TF_HTTP_ADDRESS&quot;
       - terraform --version
       - terraform init
</code></pre>
",24571,2020-11-17T18:42:59.973,"['.gitlab-tf-backend: &gitlab-tf-backend\n      script:\n       - export TF_ADDRESS=${GITLAB_API_ENDPOINT}/projects/${CI_PROJECT_ID}/terraform/state/${STATE_NAME}\n       - export TF_HTTP_ADDRESS=${TF_ADDRESS}\n       - export TF_HTTP_LOCK_ADDRESS=${TF_ADDRESS}/lock\n       - export TF_HTTP_LOCK_METHOD=POST\n       - export TF_HTTP_UNLOCK_ADDRESS=${TF_ADDRESS}/lock\n       - export TF_HTTP_UNLOCK_METHOD=DELETE\n       - export TF_HTTP_USERNAME=${USERNAME}\n       - export TF_HTTP_PASSWORD=${GITLAB_TOKEN}\n       - export TF_HTTP_RETRY_WAIT_MIN=5\n       - echo ""Using HTTP Backend at $TF_HTTP_ADDRESS""\n       - terraform --version\n       - terraform init\n']"
1530,12784,12705,CC BY-SA 4.0,2020-11-17T21:46:48.757,"<p>I had the same issue, I downloaded the Template from Azure which effectively had my Load Balancer's Backend Address Pool as a &quot;dependsOn&quot; and as a &quot;property&quot;.</p>
<p>This is under the load balancer's &quot;dependsOn&quot; list :</p>
<pre><code>    &quot;[resourceId('Microsoft.Network/loadBalancers/backendAddressPools', 'LB-db-phi-dbphipri', 'LoadBalancerBEAddressPool')]&quot;
</code></pre>
<p>And the property under the Load Balancer's property list:</p>
<pre><code>    &quot;backendAddressPools&quot;: [
      {
        &quot;name&quot;: &quot;LoadBalancerBEAddressPool&quot;,            
        &quot;properties&quot;: {}
      }
    ]
</code></pre>
<p>Lastly, I had a child definition of the backendAddressPool as well</p>
<pre><code>{
  &quot;type&quot;: &quot;Microsoft.Network/loadBalancers/backendAddressPools&quot;,
  &quot;apiVersion&quot;: &quot;2020-05-01&quot;,
  &quot;name&quot;: &quot;LB-db-phi-dbphipri/LoadBalancerBEAddressPool&quot;,
  &quot;properties&quot;: {}
}
</code></pre>
<p>You don't need both. In my case I removed the &quot;child&quot; and the &quot;dependsOn&quot; and just have the property defined under the load balancer.</p>
",24778,2020-11-17T21:46:48.757,"['    ""[resourceId(\'Microsoft.Network/loadBalancers/backendAddressPools\', \'LB-db-phi-dbphipri\', \'LoadBalancerBEAddressPool\')]""\n', '    ""backendAddressPools"": [\n      {\n        ""name"": ""LoadBalancerBEAddressPool"",            \n        ""properties"": {}\n      }\n    ]\n', '{\n  ""type"": ""Microsoft.Network/loadBalancers/backendAddressPools"",\n  ""apiVersion"": ""2020-05-01"",\n  ""name"": ""LB-db-phi-dbphipri/LoadBalancerBEAddressPool"",\n  ""properties"": {}\n}\n']"
1531,12800,12744,CC BY-SA 4.0,2020-11-19T09:10:03.717,"<p>Finally managed to generate the docker image for Angular. Here are is the screnshot.</p>
<p><a href=""https://i.stack.imgur.com/C7SLR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/C7SLR.png"" alt=""enter image description here"" /></a></p>
<p>I am listing the contents of the Docker File along with the comments that explain the reasoning and my learnings.</p>
<pre><code># Created by Sridhar Pandurangiah - 29 October 2020
# This Docker file helps create the containers for the Angular User Interface
#1 We would like to create from the node image and then add the layers. I had initially started from a base image and proceeded to add Ubuntu, it did not work out as creating a ubuntu from the base involves a lot of work and its rather baseless to start from a base image. Then switched to starting from the Ubuntu image and the problems I faced is documented in this question. So had to start from the node image. Also remember that docker containers have to address a single concern.

FROM node:15.1.0 as ab-suite-image

#Add Information about this image
LABEL maintainer=&quot;sridhar@st.in&quot;
LABEL version=&quot;1.0&quot;
LABEL decsription=&quot;This is a docker image built from the node image and includes angular9 and metronic theme&quot;

#2 Add Angular and other peer dependencies that do not get installed by default to avoid the build from exiting with errors
RUN npm install -g @angular/cli@9.1.12 @angular/core @angular/common eslint chokidar jquery popper.js tslib --save

# Set environment variables for file locations if required

#3 Set the environment Variable to determine the environment where the application is deployed development | testing | staging | production
ENV AB_COMPLIANCE_ENV=development

#4 Set the working directory to copy the angular dependencies
WORKDIR /opt/ng

#5 We don't pull the code from GIT as it would mean storing the private ssh keys on a docker image that can be publicly accessed. This is is not advisable.
COPY package.json ./

#6 Update project dependencies using package.json. This stage is where we encountered a lot of issues with build failing as the shell scripts were returing errors. the flag --legacy-peer-deps ensures that the npm doesn't throw errors so the docker build continues
RUN npm install --legacy-peer-deps

#7 Copy all the other project files and build
COPY . ./
RUN ng build


#8 Configure Volumes if required

#9 Copy start Script if required
#COPY start.sh /start.sh
#CMD [&quot;./start.sh&quot;]

#10 Expose Port for the application
EXPOSE 4200 443
</code></pre>
<p>This docker image can be used to for running unit and E2E tests.</p>
<p>Some literature on the web ask you to install nginx but not advisable. Run nginx on a seperate dedicated container. On production you can build the angular application with the &quot;prod&quot; flag and copy the files so that nginx can serve them.</p>
",6733,2020-11-19T09:10:03.717,"['# Created by Sridhar Pandurangiah - 29 October 2020\n# This Docker file helps create the containers for the Angular User Interface\n#1 We would like to create from the node image and then add the layers. I had initially started from a base image and proceeded to add Ubuntu, it did not work out as creating a ubuntu from the base involves a lot of work and its rather baseless to start from a base image. Then switched to starting from the Ubuntu image and the problems I faced is documented in this question. So had to start from the node image. Also remember that docker containers have to address a single concern.\n\nFROM node:15.1.0 as ab-suite-image\n\n#Add Information about this image\nLABEL maintainer=""sridhar@st.in""\nLABEL version=""1.0""\nLABEL decsription=""This is a docker image built from the node image and includes angular9 and metronic theme""\n\n#2 Add Angular and other peer dependencies that do not get installed by default to avoid the build from exiting with errors\nRUN npm install -g @angular/cli@9.1.12 @angular/core @angular/common eslint chokidar jquery popper.js tslib --save\n\n# Set environment variables for file locations if required\n\n#3 Set the environment Variable to determine the environment where the application is deployed development | testing | staging | production\nENV AB_COMPLIANCE_ENV=development\n\n#4 Set the working directory to copy the angular dependencies\nWORKDIR /opt/ng\n\n#5 We don\'t pull the code from GIT as it would mean storing the private ssh keys on a docker image that can be publicly accessed. This is is not advisable.\nCOPY package.json ./\n\n#6 Update project dependencies using package.json. This stage is where we encountered a lot of issues with build failing as the shell scripts were returing errors. the flag --legacy-peer-deps ensures that the npm doesn\'t throw errors so the docker build continues\nRUN npm install --legacy-peer-deps\n\n#7 Copy all the other project files and build\nCOPY . ./\nRUN ng build\n\n\n#8 Configure Volumes if required\n\n#9 Copy start Script if required\n#COPY start.sh /start.sh\n#CMD [""./start.sh""]\n\n#10 Expose Port for the application\nEXPOSE 4200 443\n']"
1532,12810,12809,CC BY-SA 4.0,2020-11-20T18:07:35.770,"<p>AWS Chatbot uses CloudWatch Logs Insights, so the IAM policy for Chatbot must include these two statements:</p>
<pre><code>{
    &quot;Sid&quot;: &quot;QueryLogs&quot;,
    &quot;Effect&quot;: &quot;Allow&quot;,
    &quot;Action&quot;: [
        &quot;logs:StopQuery&quot;,
        &quot;logs:StartQuery&quot;,
        &quot;logs:DescribeQueries&quot;
    ],
    &quot;Resource&quot;: &quot;arn:aws:logs:::log-group:/aws/lambda/*&quot;
},
{
    &quot;Sid&quot;: &quot;GetQueryResults&quot;,
    &quot;Effect&quot;: &quot;Allow&quot;,
    &quot;Action&quot;: &quot;logs:GetQueryResults&quot;,
    &quot;Resource&quot;: &quot;*&quot;
}
</code></pre>
<p>With these statements in place, pressing the logs button will yield an initial message from Chatbot like this:</p>
<blockquote>
<p>I ran this CloudWatch Logs Insights query to fetch logs from <strong>2020-11-18T09:02 UTC</strong> to <strong>2020-11-18T09:07 UTC</strong>.</p>
</blockquote>
<p>... as well as several follow-up messages containing a plaintext dump of the logs.</p>
",7770,2020-11-20T18:07:35.770,"['{\n    ""Sid"": ""QueryLogs"",\n    ""Effect"": ""Allow"",\n    ""Action"": [\n        ""logs:StopQuery"",\n        ""logs:StartQuery"",\n        ""logs:DescribeQueries""\n    ],\n    ""Resource"": ""arn:aws:logs:::log-group:/aws/lambda/*""\n},\n{\n    ""Sid"": ""GetQueryResults"",\n    ""Effect"": ""Allow"",\n    ""Action"": ""logs:GetQueryResults"",\n    ""Resource"": ""*""\n}\n']"
1533,12811,12808,CC BY-SA 4.0,2020-11-20T19:43:10.713,"<p>I found out what was happening in my graphs. All the Pods mentioned above have one thing in common: they use the host's network namespace, so their network metrics are <em>all identical</em>, and equal to the global <em>host's metric</em> (just with a slightly different precision).</p>
<pre><code>$ kubectl - monitoring get pod -o jsonpath='{.spec.hostNetwork}' \
    prometheus-stack-prometheus-node-exporter-jnhw7

true
</code></pre>
<pre><code>$ kubectl -n kube-system get pod -o jsonpath='{.items[*].spec.hostNetwork}' \
    kube-proxy-gke-triggermesh-product-control-plane-7fc0ad24-z586 \
    gke-metrics-agent-5cv4m \
    prometheus-to-sd-tk8jv \
    fluentbit-gke-xh879

true true true true 
</code></pre>
<p>One way to see it is to compare the host's metric to <em>one</em> of the above Pods:</p>
<p><a href=""https://i.stack.imgur.com/RHQiT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RHQiT.png"" alt=""Comparison of eth0 and a Pod with hostNetwork"" /></a></p>
",24826,2020-11-20T19:43:10.713,"[""$ kubectl - monitoring get pod -o jsonpath='{.spec.hostNetwork}' \\\n    prometheus-stack-prometheus-node-exporter-jnhw7\n\ntrue\n"", ""$ kubectl -n kube-system get pod -o jsonpath='{.items[*].spec.hostNetwork}' \\\n    kube-proxy-gke-triggermesh-product-control-plane-7fc0ad24-z586 \\\n    gke-metrics-agent-5cv4m \\\n    prometheus-to-sd-tk8jv \\\n    fluentbit-gke-xh879\n\ntrue true true true \n""]"
1534,12820,12613,CC BY-SA 4.0,2020-11-22T16:11:06.727,"<p>In case anyone ever finds this question: I didn't find a satisfying answer. My workaround was to write my variables to a text file in the build and then publish it, download it in the deployment and publish the values as output variables to a bash task. Looks something like this:</p>
<pre><code>source file_containing_your_vars.txt
echo &quot;##vso[task.setvariable variable=var1;isoutput=true]$var1&quot;
</code></pre>
<p>the output variables parameters of this bash would need some reference name, for example job_out and you would then be able to reference the variables from other jobs in that stage like this:</p>
<pre><code>variables['job_out.var1']
</code></pre>
<p>If you are running a yaml deployment pipeline (instead of one made in the portal) you can even use job output variable between stages.</p>
<p>For portal pipelines that want to share variables between stages this exists and seems to have helped some people but I didn't get it to work:
<a href=""https://stackoverflow.com/questions/53042605/how-to-modify-azure-devops-release-definition-variable-from-a-release-task/53060141#53060141"">https://stackoverflow.com/questions/53042605/how-to-modify-azure-devops-release-definition-variable-from-a-release-task/53060141#53060141</a></p>
",24402,2020-11-22T16:11:06.727,"['source file_containing_your_vars.txt\necho ""##vso[task.setvariable variable=var1;isoutput=true]$var1""\n', ""variables['job_out.var1']\n""]"
1535,12831,12830,CC BY-SA 4.0,2020-11-23T16:38:11.900,"<p>I have a little script for my MariaDb database inside a docker container.
The setup is comparable. I have a database container with a mounted volume. Furthermore I have a second volume for backups mounted under <code>/backup</code>.</p>
<p>The script is run on the host via cron and uses the database instance inside the container, so only one database accesses the data. That is the docker exec part.
I'm sure, you can adopt it to mysql. You only have to configure the CONTAINER_NAME and change the command inside the container.</p>
<pre class=""lang-bash prettyprint-override""><code>#!/bin/bash
DATE_TIME=`date +&quot;%Y_%m_%d_%H_%M&quot;`
CONTAINER_NAME=&quot;mariadb&quot;
CONTAINER=`docker ps -q -f name=${CONTAINER_NAME}`
PASSWORD=`docker exec ${CONTAINER} sh -c 'echo $MYSQL_ROOT_PASSWORD'`
BACKUPFILE=${DATE_TIME}_${CONTAINER_NAME}.backup.gz

echo &quot;Backup of MariaDb&quot;
echo &quot;&quot;
echo &quot;Old backps will be deleted.&quot;
echo &quot;Datenbank Container Name: $CONTAINER_NAME&quot;
echo &quot;Datenbank Container:  $CONTAINER&quot;

echo &quot;Writing backup to ${BACKUPFILE}&quot;
echo &quot;&quot;
docker exec ${CONTAINER} sh -c &quot;find /backup/ -mindepth 1 -mtime +8 -delete; /usr/bin/mariabackup --backup --user root --password=${PASSWORD} --stream=xbstream | gzip &gt; /backup/${BACKUPFILE}&quot;
echo &quot;&quot;
echo &quot;Backup finished&quot;
</code></pre>
",24816,2020-11-23T16:38:11.900,"['#!/bin/bash\nDATE_TIME=`date +""%Y_%m_%d_%H_%M""`\nCONTAINER_NAME=""mariadb""\nCONTAINER=`docker ps -q -f name=${CONTAINER_NAME}`\nPASSWORD=`docker exec ${CONTAINER} sh -c \'echo $MYSQL_ROOT_PASSWORD\'`\nBACKUPFILE=${DATE_TIME}_${CONTAINER_NAME}.backup.gz\n\necho ""Backup of MariaDb""\necho """"\necho ""Old backps will be deleted.""\necho ""Datenbank Container Name: $CONTAINER_NAME""\necho ""Datenbank Container:  $CONTAINER""\n\necho ""Writing backup to ${BACKUPFILE}""\necho """"\ndocker exec ${CONTAINER} sh -c ""find /backup/ -mindepth 1 -mtime +8 -delete; /usr/bin/mariabackup --backup --user root --password=${PASSWORD} --stream=xbstream | gzip > /backup/${BACKUPFILE}""\necho """"\necho ""Backup finished""\n']"
1536,12834,12250,CC BY-SA 4.0,2020-11-23T22:09:14.570,"<p><a href=""https://github.com/ansible/ansible/pull/67435"" rel=""nofollow noreferrer"">this feature</a> was recently merged to ansible devel branch. It would be posible using:</p>
<pre><code>- import_playbook: testns.testcoll.default_collection_playbook
</code></pre>
",24855,2020-11-23T22:09:14.570,['- import_playbook: testns.testcoll.default_collection_playbook\n']
1537,12835,12819,CC BY-SA 4.0,2020-11-23T22:38:38.323,"<p>The <code>cloudinit</code> provider only knows how to <em>encode</em> multipart MIME documents to pass to cloud init; there is no mechanism for <em>parsing</em> to modify and then re-encode.</p>
<p>However, a different way to frame your problem is of constructing a sequence of part objects in a local value and then passing them all together to the <code>cloudinit_config</code> data source, like this:</p>
<pre><code>locals {
  core_config = tolist([
    {
      content_type = &quot;text/x-shellscript&quot;
      content      = file(&quot;${path.module}/scripts/core_script1.sh&quot;)
    },
    {
      content_type = &quot;text/x-shellscript&quot;
      content      = file(&quot;${path.module}/scripts/core_script2.sh&quot;)
    },
  ])
  custom_config = tolist([
    {
      content_type = &quot;text/x-shellscript&quot;
      content      = file(&quot;${path.module}/scripts/custom_script.sh&quot;)
    },
  ])
}

data &quot;cloudinit_config&quot; &quot;core&quot; {
  dynamic &quot;part&quot; {
    for_each = local.core_config
    content {
      content_type = part.value.content_type
      content      = part.value.content
    }
  }
}

data &quot;cloudinit_config&quot; &quot;custom&quot; {
  dynamic &quot;part&quot; {
    for_each = concat(
      local.core_config,
      local.custom_config,
    )
    content {
      content_type = part.value.content_type
      content      = part.value.content
    }
  }
}

resource &quot;aws_instance&quot; &quot;vm1&quot; {
  instance_type = &quot;t2.small&quot;
  ami           = data.aws_ami.ubuntu_ami.image_id
  
  # ...

  user_data = data.cloudinit_config.core.rendered
}

resource &quot;aws_instance&quot; &quot;vm2&quot; {
  instance_type = &quot;t2.small&quot;
  ami           = data.aws_ami.ubuntu_ami.image_id
  
  # ...

  user_data = data.cloudinit_config.custom.rendered
}
</code></pre>
<p>The above is using <a href=""https://www.terraform.io/docs/configuration/expressions.html#dynamic-blocks"" rel=""nofollow noreferrer""><code>dynamic</code> blocks</a> to generate a dynamic number of <code>part</code> blocks based on the number of elements in a list, which means you can focus on making sure the lists have the necessary items, using whatever dynamic expressions you need to decide that, and have Terraform project that into zero or more <code>part</code> blocks automatically.</p>
<p><strong>Note:</strong> the <code>hashicorp/template</code> provider has been deprecated and continues to be available only for backward-compatibility. For that reason, I wrote the above to use <a href=""https://registry.terraform.io/providers/hashicorp/cloudinit/latest"" rel=""nofollow noreferrer"">the <code>hashicorp/cloudinit</code> provider</a> instead. Its <a href=""https://registry.terraform.io/providers/hashicorp/cloudinit/latest/docs/data-sources/cloudinit_config"" rel=""nofollow noreferrer""><code>cloudinit_config</code> data source</a> is based on what was formerly <code>template_cloudinit_config</code>.</p>
",2463,2020-11-23T22:38:38.323,"['locals {\n  core_config = tolist([\n    {\n      content_type = ""text/x-shellscript""\n      content      = file(""${path.module}/scripts/core_script1.sh"")\n    },\n    {\n      content_type = ""text/x-shellscript""\n      content      = file(""${path.module}/scripts/core_script2.sh"")\n    },\n  ])\n  custom_config = tolist([\n    {\n      content_type = ""text/x-shellscript""\n      content      = file(""${path.module}/scripts/custom_script.sh"")\n    },\n  ])\n}\n\ndata ""cloudinit_config"" ""core"" {\n  dynamic ""part"" {\n    for_each = local.core_config\n    content {\n      content_type = part.value.content_type\n      content      = part.value.content\n    }\n  }\n}\n\ndata ""cloudinit_config"" ""custom"" {\n  dynamic ""part"" {\n    for_each = concat(\n      local.core_config,\n      local.custom_config,\n    )\n    content {\n      content_type = part.value.content_type\n      content      = part.value.content\n    }\n  }\n}\n\nresource ""aws_instance"" ""vm1"" {\n  instance_type = ""t2.small""\n  ami           = data.aws_ami.ubuntu_ami.image_id\n  \n  # ...\n\n  user_data = data.cloudinit_config.core.rendered\n}\n\nresource ""aws_instance"" ""vm2"" {\n  instance_type = ""t2.small""\n  ami           = data.aws_ami.ubuntu_ami.image_id\n  \n  # ...\n\n  user_data = data.cloudinit_config.custom.rendered\n}\n']"
1538,12841,12830,CC BY-SA 4.0,2020-11-24T16:52:40.900,"<p>based on @ulrich answer, but with <strong>mysqldump</strong> :</p>
<pre class=""lang-bash prettyprint-override""><code>DATE_TIME=`date +&quot;%Y%m%d_%H%M&quot;
CONTAINER_NAME=&quot;mysql_server&quot;
CONTAINER=`docker ps -q -f name=${CONTAINER_NAME}`
PASSWORD=`docker exec ${CONTAINER} sh -c 'echo $MYSQL_ROOT_PASSWORD'`
BACKUP_FILE=${DATE_TIME}_${CONTAINER_NAME}.backup.sql.gz
CONTAINER_BACKUP_DIR=&quot;/var/lib/mysql/&quot;
HOST_DATA_DIR=&quot;/path/on/my/VM/correspond/to/docker/volume/&quot;
HOST_BACKUP_DIR=&quot;/other/path/on/VM/&quot;
## run backup in container
docker exec ${CONTAINER} sh -c &quot;/usr/bin/mysqldump -h localhost -u root -p${PASSWORD} --all-databases | gzip -9 -c &gt; ${CONTAINER_BACKUP_DIR}${BACKUP_FILE}&quot;
## move to final folder 
mv ${HOST_DATA_DIR}${BACKUP_FILE} ${HOST_BACKUP_DIR}
</code></pre>
<p>HOST_DATA_DIR and HOST_BACKUP_DIR are differents because I have an other daemon to save backup to a data center, and because in HOST_DATA_DIR, root can only read and execute (r_x).<br />
For all folder paths, be careful to have a final '/', otherwise you should be surprised!</p>
<p>and if you run it automatically with a CRON job, it should be helpfull to manage rotate to delete old backup:</p>
<pre class=""lang-bash prettyprint-override""><code>## rotate save management to keep only last MAX_BACKUP files
MAX_BACKUP=3
${HOST_DATA_DIR}rotate-databases-backup.log
echo ${HOST_BACKUP_DIR}${BACKUP_FILE} &gt;&gt; ${HOST_DATA_DIR}rotate-databases-backup.log
BACKUPED_NB=$(ls ${HOST_BACKUP_DIR}*${CONTAINER_NAME}.backup.sql.gz | wc --lines)
TOTAL=$(wc --lines &lt; ${HOST_DATA_DIR}rotate-databases-backup.log)
FILES_NB_TO_DELETE=$(expr $TOTAL - $MAX_BACKUP)
if [[ $FILES_NB_TO_DELETE -gt 0 ]]; then
    head --lines=$FILES_NB_TO_DELETE ${HOST_DATA_DIR}rotate-databases-backup.log | xargs rm
    ls ${HOST_BACKUP_DIR}*${CONTAINER_NAME}.backup.sql.gz &gt; ${HOST_DATA_DIR}rotate-databases-backup.log
fi
</code></pre>
",19257,2020-11-24T17:41:04.183,"['DATE_TIME=`date +""%Y%m%d_%H%M""\nCONTAINER_NAME=""mysql_server""\nCONTAINER=`docker ps -q -f name=${CONTAINER_NAME}`\nPASSWORD=`docker exec ${CONTAINER} sh -c \'echo $MYSQL_ROOT_PASSWORD\'`\nBACKUP_FILE=${DATE_TIME}_${CONTAINER_NAME}.backup.sql.gz\nCONTAINER_BACKUP_DIR=""/var/lib/mysql/""\nHOST_DATA_DIR=""/path/on/my/VM/correspond/to/docker/volume/""\nHOST_BACKUP_DIR=""/other/path/on/VM/""\n## run backup in container\ndocker exec ${CONTAINER} sh -c ""/usr/bin/mysqldump -h localhost -u root -p${PASSWORD} --all-databases | gzip -9 -c > ${CONTAINER_BACKUP_DIR}${BACKUP_FILE}""\n## move to final folder \nmv ${HOST_DATA_DIR}${BACKUP_FILE} ${HOST_BACKUP_DIR}\n', '## rotate save management to keep only last MAX_BACKUP files\nMAX_BACKUP=3\n${HOST_DATA_DIR}rotate-databases-backup.log\necho ${HOST_BACKUP_DIR}${BACKUP_FILE} >> ${HOST_DATA_DIR}rotate-databases-backup.log\nBACKUPED_NB=$(ls ${HOST_BACKUP_DIR}*${CONTAINER_NAME}.backup.sql.gz | wc --lines)\nTOTAL=$(wc --lines < ${HOST_DATA_DIR}rotate-databases-backup.log)\nFILES_NB_TO_DELETE=$(expr $TOTAL - $MAX_BACKUP)\nif [[ $FILES_NB_TO_DELETE -gt 0 ]]; then\n    head --lines=$FILES_NB_TO_DELETE ${HOST_DATA_DIR}rotate-databases-backup.log | xargs rm\n    ls ${HOST_BACKUP_DIR}*${CONTAINER_NAME}.backup.sql.gz > ${HOST_DATA_DIR}rotate-databases-backup.log\nfi\n']"
1539,12843,9895,CC BY-SA 4.0,2020-11-24T20:23:37.123,"<p>For me, I cannot resolve these conflicts.</p>
<p><strong>To PREVENT THEM:</strong></p>
<pre><code>  i) Make backups outside the folder system for the repository

 ii) Totally delete your 'local' folder for the repository.  (Seems
     counterintuitive, but it is all that works for me).  

iii) Re-load 'local' folder from the web-repository.

 iv) Eventually, check-in, then it will work.

  v) Repeat step i for next time.
</code></pre>
",9710,2020-11-24T20:23:37.123,"[""  i) Make backups outside the folder system for the repository\n\n ii) Totally delete your 'local' folder for the repository.  (Seems\n     counterintuitive, but it is all that works for me).  \n\niii) Re-load 'local' folder from the web-repository.\n\n iv) Eventually, check-in, then it will work.\n\n  v) Repeat step i for next time.\n""]"
1540,12845,12842,CC BY-SA 4.0,2020-11-24T21:57:01.490,"<p>Coincidentally I had to do something very similar yesterday. This is the script I used:</p>
<pre class=""lang-sh prettyprint-override""><code>#!/bin/bash -e

VAULT_NAME=...   # put your Backup Vault name here

for ARN in $(aws backup list-recovery-points-by-backup-vault --backup-vault-name &quot;${​​​​​​​VAULT_NAME}​​​​​​​&quot; --query 'RecoveryPoints[].RecoveryPointArn' --output text); do
  echo &quot;deleting ${​​​​​​​ARN}​​​​​​​ ...&quot;
  aws backup delete-recovery-point --backup-vault-name &quot;${​​​​​​​VAULT_NAME}​​​​​​​&quot; --recovery-point-arn &quot;${​​​​​​​ARN}​​​​​​​&quot;
done
</code></pre>
<p>You can also add <code>--by-created-before</code> to delete the old backups only.</p>
<p>Hope that helps :)</p>
",8800,2020-11-24T21:57:01.490,"['#!/bin/bash -e\n\nVAULT_NAME=...   # put your Backup Vault name here\n\nfor ARN in $(aws backup list-recovery-points-by-backup-vault --backup-vault-name ""${\u200b\u200b\u200b\u200b\u200b\u200b\u200bVAULT_NAME}\u200b\u200b\u200b\u200b\u200b\u200b\u200b"" --query \'RecoveryPoints[].RecoveryPointArn\' --output text); do\n  echo ""deleting ${\u200b\u200b\u200b\u200b\u200b\u200b\u200bARN}\u200b\u200b\u200b\u200b\u200b\u200b\u200b ...""\n  aws backup delete-recovery-point --backup-vault-name ""${\u200b\u200b\u200b\u200b\u200b\u200b\u200bVAULT_NAME}\u200b\u200b\u200b\u200b\u200b\u200b\u200b"" --recovery-point-arn ""${\u200b\u200b\u200b\u200b\u200b\u200b\u200bARN}\u200b\u200b\u200b\u200b\u200b\u200b\u200b""\ndone\n']"
1541,12855,1551,CC BY-SA 4.0,2020-11-25T17:40:52.583,"<p>If the <code>if</code> command construct is very complex for you, you can always simply it like</p>
<pre><code>RUN [ -n &quot;$VAR&quot; ]
</code></pre>
<p>This asserts the variable value length is nonzero. If it's empty or not set it'll exit with 1. This is also same as running <code>RUN test -n &quot;$VAR&quot;</code></p>
<p>I see this error message on my machine</p>
<pre><code>The command '/bin/sh -c [ -n &quot;$VAR&quot; ]' returned a non-zero code: 1
</code></pre>
",16143,2020-11-25T17:40:52.583,"['RUN [ -n ""$VAR"" ]\n', 'The command \'/bin/sh -c [ -n ""$VAR"" ]\' returned a non-zero code: 1\n']"
1542,12857,12851,CC BY-SA 4.0,2020-11-25T19:39:25.530,"<p>Judging by the <a href=""https://docs.ansible.com/ansible/2.3/ios_command_module.html"" rel=""nofollow noreferrer"">documentation</a>, the result of your <code>run multiple commands on remote nodes</code> block is an array. You're writing only the first item of that array with <code>{{ print_output.stdout[0] }}</code>. The <code>[0]</code> here is the pointer to the first element of the array. Try removing it and see if the result fits your needs.</p>
<p><strong>UPD</strong>: Use this to write several strings into a file:</p>
<pre class=""lang-yaml prettyprint-override""><code>- name: save output to a file
  lineinfile:
    create: yes
    line: &quot;{{item}}&quot;
    path: ./output/{{ inventory_hostname }}.txt
  with_items: &quot;{{ print_output.stdout }}&quot;
</code></pre>
",24539,2020-11-26T19:31:41.557,"['- name: save output to a file\n  lineinfile:\n    create: yes\n    line: ""{{item}}""\n    path: ./output/{{ inventory_hostname }}.txt\n  with_items: ""{{ print_output.stdout }}""\n']"
1543,12864,12837,CC BY-SA 4.0,2020-11-26T13:05:13.023,"<p>YAML anchors are supported, but only for the same YAML file. You can't create the anchor (<code>&amp;</code>) on a deployment file and reference (<code>*</code>) the value on another one.</p>
<p>If you want to share ENVs values across multiple Deployments, you can create a ConfigMap with the ENVs and use the <a href=""https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables"" rel=""nofollow noreferrer""><code>envFrom</code></a> spec. Example:</p>
<pre><code>apiVersion: v1
kind: ConfigMap
metadata:
  name: my-configmap
data:
  FIRST_ENV: my-value
  SECOND_ENV: another-value
---  
apiVersion: apps/v1
kind: Deployment
metadata:
  name: beat
spec:
  selector:
    matchLabels:
      app: beat
  template:
    metadata:
      labels:
        app: beat
    spec:
      containers:
      - name: beat
        image: myimage
        command: [&quot;celery&quot;, &quot;-A&quot;, &quot;wsgi.celery&quot;, &quot;beat&quot;]
        envFrom:
        - configMapRef:
            name: my-configmap
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flower
spec:
  selector:
    matchLabels:
      app: flower
  template:
    metadata:
      labels:
        app: flower
    spec:
      containers:
      - name: flower
        image: myimage
        command: [&quot;celery&quot;, &quot;flower&quot;, &quot;-A&quot;, &quot;wsgi.celery&quot;]
        envFrom:
        - configMapRef:
            name: my-configmap
</code></pre>
",13139,2020-11-26T13:05:13.023,"['apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: my-configmap\ndata:\n  FIRST_ENV: my-value\n  SECOND_ENV: another-value\n---  \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: beat\nspec:\n  selector:\n    matchLabels:\n      app: beat\n  template:\n    metadata:\n      labels:\n        app: beat\n    spec:\n      containers:\n      - name: beat\n        image: myimage\n        command: [""celery"", ""-A"", ""wsgi.celery"", ""beat""]\n        envFrom:\n        - configMapRef:\n            name: my-configmap\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: flower\nspec:\n  selector:\n    matchLabels:\n      app: flower\n  template:\n    metadata:\n      labels:\n        app: flower\n    spec:\n      containers:\n      - name: flower\n        image: myimage\n        command: [""celery"", ""flower"", ""-A"", ""wsgi.celery""]\n        envFrom:\n        - configMapRef:\n            name: my-configmap\n']"
1544,12867,12850,CC BY-SA 4.0,2020-11-27T07:03:37.173,"<p>You can utilize watchtower to restart the specified containers each time new image of that container is avaialble.</p>
<blockquote>
<p><a href=""https://github.com/containrrr/watchtower"" rel=""nofollow noreferrer"">Watchtower</a> : with watchtower you can update the running version
of your containerized app simply by pushing a new image to the Docker
Hub or your own image registry. Watchtower will pull down your new
image, gracefully shut down your existing container and restart it
with the same options that were used when it was deployed initially.
Run the watchtower container with the following command:</p>
<pre><code>$ docker run -d \
    --name watchtower \
    -v /var/run/docker.sock:/var/run/docker.sock \
    containrrr/watchtower
</code></pre>
</blockquote>
<p>docker-compose integration example:</p>
<pre><code>services:
  watchtower:
    command: --label-enable --cleanup --interval 300
    image: containrrr/watchtower
    labels:
      - &quot;com.centurylinklabs.watchtower.enable=true&quot;
    network_mode: none
    restart: always
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  mariadb:
      depends_on:
        - watchtower
      env_file: .mariadb.env
      image: mariadb:10
      labels:
        - &quot;com.centurylinklabs.watchtower.enable=true&quot;
      networks:
        - default
      ports:
        - 3306:3306
      restart: always
      volumes:
        - ./data/volumes/mariadb:/var/lib/mysql
</code></pre>
<p>To check the logs of the updation you can execute <code>docker-compose logs watchtower</code></p>
<p>docker-compose integration reference: <a href=""https://chriswiegman.com/2019/12/keeping-docker-containers-updated/"" rel=""nofollow noreferrer"">https://chriswiegman.com/2019/12/keeping-docker-containers-updated/</a></p>
",19767,2020-11-27T07:03:37.173,"['$ docker run -d \\\n    --name watchtower \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    containrrr/watchtower\n', 'services:\n  watchtower:\n    command: --label-enable --cleanup --interval 300\n    image: containrrr/watchtower\n    labels:\n      - ""com.centurylinklabs.watchtower.enable=true""\n    network_mode: none\n    restart: always\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n\n  mariadb:\n      depends_on:\n        - watchtower\n      env_file: .mariadb.env\n      image: mariadb:10\n      labels:\n        - ""com.centurylinklabs.watchtower.enable=true""\n      networks:\n        - default\n      ports:\n        - 3306:3306\n      restart: always\n      volumes:\n        - ./data/volumes/mariadb:/var/lib/mysql\n']"
1545,12870,12856,CC BY-SA 4.0,2020-11-27T22:08:34.497,"<p>This should be fairly straightforward to do in a script block.  I don't think there's a declarative-native way to do this.</p>
<p>I use this script block to cancel builds for earlier (i.e. outdated) revisions of PRs:</p>
<pre><code>script {
  // currentBuild is a Pipeline-builtin variable for accessing the Build object
  // https://www.jenkins.io/doc/book/pipeline/getting-started/#global-variable-reference
  def build = currentBuild

  while(true) {
    build = build.getPreviousBuild()

    // exit the loop if we have finished iterating over builds
    // (groovy doesn't have a do...while feature)
    if (build == null) break

    def rawBuild = build.rawBuild

    if (rawBuild.isBuilding()) {
      // abort the build
      rawBuild.doTerm()
    }
  }
}
</code></pre>
<p>As you can hopefully see, this iterates over <strong>all</strong> previous builds and uses the <code>isBuilding()</code> method to find ones that are currently running.</p>
<p>If you want to check later builds instead of previous ones, you can use <code>getNextBuild()</code> instead (I believe the API doc is <a href=""https://javadoc.jenkins-ci.org/hudson/model/Run.html"" rel=""nofollow noreferrer"">here</a>, it's been a while since I wrote this so this might be the wrong class).</p>
<p>And if you want to check only one directly adjacent build instead of all earlier/later builds, you can just omit the loop and only call <code>getPreviousBuild()</code>/<code>getNextBuild()</code> once.</p>
",4115,2020-11-27T22:08:34.497,"[""script {\n  // currentBuild is a Pipeline-builtin variable for accessing the Build object\n  // https://www.jenkins.io/doc/book/pipeline/getting-started/#global-variable-reference\n  def build = currentBuild\n\n  while(true) {\n    build = build.getPreviousBuild()\n\n    // exit the loop if we have finished iterating over builds\n    // (groovy doesn't have a do...while feature)\n    if (build == null) break\n\n    def rawBuild = build.rawBuild\n\n    if (rawBuild.isBuilding()) {\n      // abort the build\n      rawBuild.doTerm()\n    }\n  }\n}\n""]"
1546,12876,12692,CC BY-SA 4.0,2020-11-28T22:26:18.220,"<p>Do you have 2 different jenkins jobs configured for master and release branches? Since github webhook event is sent to Jenkins irrespective of branch, both your jenkins jobs may be getting triggered by this github webhook event. And since both jobs are configured with separate branches, they may be checking out those branches during jenkins job execution which is why you may be seeing respective branches being printed in both jenkins jobs.</p>
<p>Checkout <a href=""https://www.jenkins.io/doc/book/pipeline/multibranch/"" rel=""nofollow noreferrer"">jenkins multibranch pipeline</a> if you haven't already so you don't have to maintain multiple jenkins jobs for branches.</p>
<p>Now coming back to your Jenkinsfile code, you can try following:</p>
<ol>
<li><p>Replace <code>env.GIT_BRANCH</code> with <code>env.BRANCH_NAME</code></p>
</li>
<li><p>Use <code>allOf</code> inside when condition instead of <code>&amp;&amp;</code>  -</p>
<pre><code>stage(&quot;Step 3: Production Deployment&quot;){
    when {
        allOf {
            expression { env.BRANCH_NAME == &quot;origin/master&quot; }
            expression { params.merged == true }
            expression { params.current_status == &quot;closed&quot; }
        }
    }
    steps{
        -----
        sh 'kubectl apply -f **.yaml'
    } 
}
</code></pre>
</li>
</ol>
<p>Note that github webhook will trigger the jenkins job for every branch push or PR merge event (irrespective of branch), so your jenkins job would have to handle multi-branch scenarios like explained in this <a href=""https://www.jenkins.io/doc/tutorials/build-a-multibranch-pipeline-project/#add-deliver-and-deploy-stages-to-your-pipeline"" rel=""nofollow noreferrer"">official doc example</a>.</p>
",24917,2020-11-28T22:26:18.220,"['stage(""Step 3: Production Deployment""){\n    when {\n        allOf {\n            expression { env.BRANCH_NAME == ""origin/master"" }\n            expression { params.merged == true }\n            expression { params.current_status == ""closed"" }\n        }\n    }\n    steps{\n        -----\n        sh \'kubectl apply -f **.yaml\'\n    } \n}\n']"
1547,12893,12891,CC BY-SA 4.0,2020-12-01T14:29:08.883,"<p>I made it work by changing the way <code>labels</code> argument is passed into <code>requestBody</code>.</p>
<p>Turns out the list representation while interpolated into string is missing quotation marks around each list element.</p>
<pre><code>def setLabels (String repository, List label) {
    try {
        String labelsAsString = &quot;[\&quot;${label.join('&quot;, &quot;')}\&quot;]&quot;
        def response = httpRequest httpMode: 'POST',
                        url: &quot;[REPO_URL]/${repository}/issues/${CHANGE_ID}/labels&quot;,
                        authentication: 'ors_git_service_account',
                        requestBody: &quot;&quot;&quot;{
                            &quot;labels&quot;: ${labelsAsString}
                        }&quot;&quot;&quot;
    } catch (e) {
        wrap([$class: 'AnsiColorBuildWrapper', 'colorMapName': 'XTerm']) {
            echo &quot;\u001B[31magdSlack.setLabels: '&quot; + e.toString() + &quot;'\u001B[0m&quot;
        }
        throw e
    }
}
</code></pre>
",24953,2020-12-01T14:29:08.883,"['def setLabels (String repository, List label) {\n    try {\n        String labelsAsString = ""[\\""${label.join(\'"", ""\')}\\""]""\n        def response = httpRequest httpMode: \'POST\',\n                        url: ""[REPO_URL]/${repository}/issues/${CHANGE_ID}/labels"",\n                        authentication: \'ors_git_service_account\',\n                        requestBody: """"""{\n                            ""labels"": ${labelsAsString}\n                        }""""""\n    } catch (e) {\n        wrap([$class: \'AnsiColorBuildWrapper\', \'colorMapName\': \'XTerm\']) {\n            echo ""\\u001B[31magdSlack.setLabels: \'"" + e.toString() + ""\'\\u001B[0m""\n        }\n        throw e\n    }\n}\n']"
1548,12912,11232,CC BY-SA 4.0,2020-12-04T04:11:53.617,"<p>Re „<em>How long should feature branches last?</em>“</p>
<p>Just as short as possible. Just as long as needed. &quot;Old feature branch&quot; is a contradiction in itself.</p>
<p>We use Scrum with JIRA as ticketing tool. No feature branch lasts more than the 2 weeks sprint period, ever. Our tickets' planned times go from, often, 2 (net working) hour to, almost never, 40 (net working) hours (that's 2 weeks at 50 % net developing time).</p>
<p>Set <em>Blocked by</em> in a task if advised. Tasks with no blocker can be done in parallel, by different persons. With such a fine-granular process any dev can easily continue on a ticket (in case of a day-off, sick leave, burndown of an office at another location, etc.) or begin to work on a new one without having to care about prerequisites.</p>
<p>If a task's estimated fulfilment time tends to be longer than two days, it's splitted into smaller tasks.</p>
<h3>Example: Project using Java, JUnit, GitLab, Eclipse, Maven, Jenkins</h3>
<p><strong>Dev Tasks</strong></p>
<ul>
<li>Create Jenkins projects for the branches main, develop, feature, hotfix, release</li>
<li>Create Git repo(s) (including configuring access right etc.)</li>
<li>Create Maven project(s) (from within Eclipse), adapt POM declarations accordingly (properties, dependencies, plugins, ...)</li>
<li>Implement the framework: create packages, interfaces, test classes and classes/enums with empty methods, resources and test resources for a start (this task can also be split into more than one depending on the size of the project)</li>
<li>Implement functionality (can be split depending on...see above)</li>
</ul>
<p><strong>Git tasks (for each of the dev tasks above)</strong></p>
<ul>
<li>If a ticket's status changes from <em>New</em> to <em>In implementation</em> a feature branch is created.</li>
<li>If a ticket's status changes from <em>In implementation</em> to <em>Implemented</em> a review is done.</li>
<li>If a ticket's status changes from <em>Implemented</em> to <em>Closed</em> the feature branch is merged and deleted.</li>
</ul>
<hr />
<p>Re „<em>Are there considerations and maintenance commands that developers need to execute every so often to have working, efficient, and responsive git ?</em>“</p>
<p>See <a href=""https://stackoverflow.com/q/2116778/1744774"">SO for <code>git gc</code></a>.</p>
<p>In a <a href=""https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow"" rel=""nofollow noreferrer""><code>git flow init</code>ialized repo</a> there are basically two of them:</p>
<ul>
<li><code>git flow feature start &lt;name&gt; [&lt;base&gt;]</code></li>
<li><code>git flow feature finish [&lt;name&gt;]</code></li>
</ul>
<pre class=""lang-bash prettyprint-override""><code>(main) $ git flow init
... 6 times &lt;Enter&gt; to accept the defaults ...
(develop) $ git branch
* develop
  main
$ git flow feature start my-cool-feature
Switched to a new branch 'feature/my-cool-feature'

Summary of actions:
- A new branch 'feature/my-cool-feature' was created, based on 'develop'
- You are now on branch 'feature/my-cool-feature'

Now, start committing on your feature. When done, use:

     git flow feature finish my-cool-feature

(feature/my-cool-feature) $ git branch
  develop
* feature/my-cool-feature
  main
...
(feature/my-cool-feature) $ git status | add | commit | pull | push | gc | ...  # whatever
...
(feature/my-cool-feature) $ git flow feature finish  # without a feature name it finishes the current
Switched to branch 'develop'
Already up to date.
Deleted branch feature/my-cool-feature (was a57868f).

Summary of actions:
- The feature branch 'feature/my-cool-feature' was merged into 'develop'
- Feature branch 'feature/my-cool-feature' has been locally deleted
- You are now on branch 'develop'

(develop) $ git push  # if there's a remote repo
(develop) $ git branch
 1. develop
  main
(develop) $ git flow feature start my-even-cooler-feature
...
(feature/my-even-cooler-feature) $
</code></pre>
<p>Long story short from the bottom of the page <a href=""https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow"" rel=""nofollow noreferrer"">Gitflow Workflow</a>:</p>
<blockquote>
<p>The overall flow of Gitflow is:</p>
<ol>
<li>A <code>develop</code> branch is created from <code>master</code> [now <code>main</code>]</li>
<li>A <code>release</code> branch is created from <code>develop</code></li>
<li><code>Feature</code> branches are created from <code>develop</code></li>
<li>When a <code>feature</code> is complete it is merged into the <code>develop</code> branch</li>
<li>When the release branch is done it is merged into <code>develop</code> and <code>master</code> [or <code>main</code>]</li>
<li>If an issue in <code>master</code> is detected a <code>hotfix</code> branch is created from <code>master</code></li>
<li>Once the <code>hotfix</code> is complete it is merged to both <code>develop</code> and <code>master</code> [or <code>main</code>]</li>
</ol>
</blockquote>
",24991,2020-12-04T18:51:14.927,"[""(main) $ git flow init\n... 6 times <Enter> to accept the defaults ...\n(develop) $ git branch\n* develop\n  main\n$ git flow feature start my-cool-feature\nSwitched to a new branch 'feature/my-cool-feature'\n\nSummary of actions:\n- A new branch 'feature/my-cool-feature' was created, based on 'develop'\n- You are now on branch 'feature/my-cool-feature'\n\nNow, start committing on your feature. When done, use:\n\n     git flow feature finish my-cool-feature\n\n(feature/my-cool-feature) $ git branch\n  develop\n* feature/my-cool-feature\n  main\n...\n(feature/my-cool-feature) $ git status | add | commit | pull | push | gc | ...  # whatever\n...\n(feature/my-cool-feature) $ git flow feature finish  # without a feature name it finishes the current\nSwitched to branch 'develop'\nAlready up to date.\nDeleted branch feature/my-cool-feature (was a57868f).\n\nSummary of actions:\n- The feature branch 'feature/my-cool-feature' was merged into 'develop'\n- Feature branch 'feature/my-cool-feature' has been locally deleted\n- You are now on branch 'develop'\n\n(develop) $ git push  # if there's a remote repo\n(develop) $ git branch\n 1. develop\n  main\n(develop) $ git flow feature start my-even-cooler-feature\n...\n(feature/my-even-cooler-feature) $\n""]"
1549,12915,12910,CC BY-SA 4.0,2020-12-04T15:32:30.880,"<p>You seem to be passing <code>force_basic_auth: yes</code> but no <code>user</code>, nor <code>password</code>.</p>
<p>Example from the Ansible docs:</p>
<pre><code>- name: Create a JIRA issue
  uri:
    url: https://your.jira.example.com/rest/api/2/issue/
    method: POST
    user: your_username
    password: your_pass
    body: &quot;{{ lookup('file','issue.json') }}&quot;
    force_basic_auth: yes
    status_code: 201
    body_format: json
</code></pre>
<p>The 403 is usually Basic Auth failing. If it's not, it could be the API server you're running requiring some sort of authentication.</p>
<p>If the <code>curl -k</code> command includes something like <code>https://user:password@dev-box.local/api/</code> or the <code>--user &lt;user:password&gt;</code>, it should work. Or maybe it's using data from <code>.netrc</code>?</p>
<p>I hope this helps.</p>
",24996,2020-12-04T15:32:30.880,"['- name: Create a JIRA issue\n  uri:\n    url: https://your.jira.example.com/rest/api/2/issue/\n    method: POST\n    user: your_username\n    password: your_pass\n    body: ""{{ lookup(\'file\',\'issue.json\') }}""\n    force_basic_auth: yes\n    status_code: 201\n    body_format: json\n']"
1550,12936,12927,CC BY-SA 4.0,2020-12-07T12:06:51.930,"<p>I totally misunderstood you. Here is a new attempt to actually answer your question. :)</p>
<ol>
<li>Create a passwords file:</li>
</ol>
<pre><code>root@2ca77340d571:/# cat .passvaults
dev my_dev_pass
test my_test_pass
prod my_prod_pas
</code></pre>
<ol start=""2"">
<li>Create a file to encrypt:</li>
</ol>
<pre><code>root@2ca77340d571:/# cat extravaulty.yml
chocolate:banana
</code></pre>
<ol start=""3"">
<li>Encrypt the file:</li>
</ol>
<pre><code>root@2ca77340d571:/# ansible-vault encrypt --vault-id=dev@.passvaults extravaulty.yml
Encryption successful
</code></pre>
<ol start=""4"">
<li>View the raw file:</li>
</ol>
<pre><code>root@2ca77340d571:/# cat extravaulty.yml
$ANSIBLE_VAULT;1.2;AES256;dev
33336336336238326137393764316333623231336238323931306166626434653164326330656566
3561356333343435663538623661363661373461356461300a663361666331323031623530343930
62633230636566643339663637386438336539383162346634393031633165333033396238363163
6134383233346538330a326266626261346638303738313862656337396237343231326231656139
34376334663664343164303462356431306539316232323761386164643735376330
</code></pre>
<p>and the decrypted file:</p>
<pre><code>root@2ca77340d571:/# ansible-vault view --vault-id=dev@.passvaults extravaulty.yml
chocolate:banana
</code></pre>
<p>As I understand it, when you use <code>--vault-id=dev@.passvaults</code> you are telling it to use <code>dev</code> as a hint (not the vault password) and <code>.passvaults</code> as the file where the encrypt/decrypt password is.</p>
<p>This means that you can also do this:</p>
<pre><code>root@2ca77340d571:/# ansible-vault view --vault-id=prod@.passvaults extravaulty.yml
chocolate:banana
</code></pre>
<p>Or this</p>
<pre><code>root@2ca77340d571:/# ansible-vault view --vault-id=.passvaults extravaulty.yml
chocolate:banana
</code></pre>
<p>Which is not intuitive to me.
Does this help?</p>
",24996,2020-12-07T12:06:51.930,"['root@2ca77340d571:/# cat .passvaults\ndev my_dev_pass\ntest my_test_pass\nprod my_prod_pas\n', 'root@2ca77340d571:/# cat extravaulty.yml\nchocolate:banana\n', 'root@2ca77340d571:/# ansible-vault encrypt --vault-id=dev@.passvaults extravaulty.yml\nEncryption successful\n', 'root@2ca77340d571:/# cat extravaulty.yml\n$ANSIBLE_VAULT;1.2;AES256;dev\n33336336336238326137393764316333623231336238323931306166626434653164326330656566\n3561356333343435663538623661363661373461356461300a663361666331323031623530343930\n62633230636566643339663637386438336539383162346634393031633165333033396238363163\n6134383233346538330a326266626261346638303738313862656337396237343231326231656139\n34376334663664343164303462356431306539316232323761386164643735376330\n', 'root@2ca77340d571:/# ansible-vault view --vault-id=dev@.passvaults extravaulty.yml\nchocolate:banana\n', 'root@2ca77340d571:/# ansible-vault view --vault-id=prod@.passvaults extravaulty.yml\nchocolate:banana\n', 'root@2ca77340d571:/# ansible-vault view --vault-id=.passvaults extravaulty.yml\nchocolate:banana\n']"
1551,12939,12924,CC BY-SA 4.0,2020-12-08T01:12:45.353,"<p>Answering my own question &amp; accepting it because it works - this is the solution:</p>
<p><strong>Step 1:</strong>
So I start by finding the Docker Service I recognise as my Drupal site &quot;that's the site&quot;</p>
<pre><code>node1 $ docker service ls
</code></pre>
<p>As before, shown in the question, the output of that command is:</p>
<pre><code>ID                  NAME                       MODE                REPLICAS            IMAGE                      PORTS
sr2w12kl8bg1        site1_db                    replicated          1/1                 animage2/mariadb:latest        *:13306-&gt;3306/tcp
e083ij8abje1        site1_drupal                replicated          1/1                 animage2/drupal:d7             *:7150-&gt;80/tcp
sejb0f2mfo22        site1_drush                 replicated          0/1                 drush/drush:latest         
kbae02doa8rs        site1_haproxy               replicated          2/2                 haproxy:alpine             
khgmnu1566rb        site2_db                    replicated          1/1                 mariadb:latest             
notoc1fam1gk        site3_drupal                replicated          1/1                 animage1/drupal:d8             *:7160-&gt;80/tcp
0xtxx4jmmwa3        site4_db                    replicated          1/1                 mariadb:latest

        
</code></pre>
<p>I pick out the site <code>animage1/drupal:d8</code>, second from bottom in the list above and find the corresponding Service ID, <code>notoc1fam1gk</code></p>
<p><strong>Step 2:</strong></p>
<p>I use this, Service ID, <code>notoc1fam1gk</code>, to list all the tasks for that Service, by doing this command</p>
<pre><code>node1 $ docker service ps notoc1fam1gk
</code></pre>
<p>The output of that command is:</p>
<pre><code>ID                  NAME                 IMAGE                      NODE                DESIRED STATE       CURRENT STATE          ERROR               PORTS
yiofs723gc89        site3_drupal.1       animage1/drupal:d8         node2               Running             Running 6 days ago                         
pgdgf783ff9v         \_ site3_drupal.1   animage1/drupal:d8         node2               Shutdown            Shutdown 2 weeks ago                       
1gfdsgcb0p2q         \_ site3_drupal.1   animage1/drupal:d8         node2               Shutdown            Shutdown 2 weeks ago                       
175lfds2jbjy         \_ site3_drupal.1   animage1/drupal:d8         node2               Shutdown            Shutdown 2 weeks ago                       
qo312e143p1q         \_ site3_drupal.1   animage1/drupal:d8         node2               Shutdown            Shutdown 3 weeks ago    

               
</code></pre>
<p><strong>Step 3:</strong></p>
<p>Now for the crucial bit - I still don't have a Container ID to be able to ssh into.</p>
<p>So This command will do it for me:</p>
<pre><code>docker inspect -f &quot;{{.Status.ContainerStatus.ContainerID}}&quot; &lt;task_id&gt;
</code></pre>
<p>( Credit: <a href=""https://stackoverflow.com/a/42465558/227926"">https://stackoverflow.com/a/42465558/227926</a> )</p>
<p>In my example, this looks like:</p>
<pre><code>node1 $ docker inspect -f &quot;{{.Status.ContainerStatus.ContainerID}}&quot; yiofs723gc89
</code></pre>
<p>The output of the above command is just:</p>
<pre><code>72d6a20c3d15dd9f0db4b1a60d93a91c0514946881f2dc00ca62d6a7a9ef1290
</code></pre>
<p>This is the container ID in the format of the 64 character SHA-256 ID.</p>
<p>But I'm familiar with the 12 character length Container IDs that docker ps shows.</p>
<p>The explaination is that the 12 character Container ID is just a truncated version of the full length 64 character ID  - it takes the first 12 characters.</p>
<p>So in my case, <code>72d6a20c3d15dd9f0db4b1a60d93a91c0514946881f2dc00ca62d6a7a9ef1290</code> will be <code>72d6a20c3d15</code> in the 12 character format.</p>
<p><strong>Step 4:</strong></p>
<p>So now, when I docker ps on node1 to go looking for that container ID I can use the 12 character format for the ID, <code>72d6a20c3d15</code></p>
<p>I'm on my Docker Swarm Node node1 and I do a docker ps:</p>
<pre><code>node1 $ docker ps
CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                    NAMES
d5d45a94d45e        haproxy:alpine         &quot;/docker-entrypoint.…&quot;   3 days ago          Up 3 days                                    db_proxy_haproxy.2.91aw0apofd3iw537d249pyi62
6a4676df2b3a        22dbb7890585           &quot;docker-entrypoint.s…&quot;   3 days ago          Up 3 days           3306/tcp                 site2_db.1.xxizdccg9a2hgf83tcgg1tkaej
538172a86a57        site1/drupal:asite     &quot;docker-php-entrypoi…&quot;   3 days ago          Up 3 days           80/tcp                   site3.1.uofsfssl72aj867r0hfs86i7m24linae8
2d487ea3788e        22dbb7890585           &quot;docker-entrypoint.s…&quot;   3 days ago          Up 3 days           3306/tcp                 site4_db.1.3lnd0f9sl027f0skgza3kq373c0
d671069584d7        mariadb:latest         &quot;docker-entrypoint.s…&quot;   3 days ago          Up 3 days           3306/tcp                 site5.1.xoy0r6720362hlkhksu2qd
beb6bcb66f43        mariadb:latest         &quot;docker-entrypoint.s…&quot;   3 days ago          Up 3 days           3306/tcp                 site2.1.kobk423624kljfs1uhpflfs3
</code></pre>
<p>But <code>72d6a20c3d15</code> isn't in the list. Why is that?</p>
<p>Well, in my case it is on the node2 of my Docker Swarm.  How do I know this?</p>
<p>I know because the earlier command <code>docker service ps</code> <code>notoc1fam1gk</code> listed the task as node2, so I know that this task's corresponding container will be on node2.</p>
<p><strong>Step 5:</strong></p>
<p>So I connect to node2 where my container is located</p>
<pre><code>node1$ ssh node2
</code></pre>
<p>Then list the Docker Containers, by ID.  And I can see <code>72d6a20c3d15</code> in this list, bottom entry:</p>
<pre><code>node2$ docker ps

CONTAINER ID        IMAGE                      COMMAND                  CREATED             STATUS              PORTS               NAMES
2e3bc7158d61        89up/drupal:unity          &quot;docker-php-entrypoi…&quot;   7 days ago          Up 7 days           80/tcp              someothersite_drupal.1.tg33od888aj6krqqhdx0tp8ta
53122123d035        haproxy:alpine             &quot;/docker-entrypoint.…&quot;   7 days ago          Up 7 days                               someothersite_haproxy.1.t1x7exq98huu8q3aaok57d22
9348345f84cb        haproxy:alpine             &quot;/docker-entrypoint.…&quot;   10 days ago         Up 10 days                              something-m_haproxy.2.02haarnwe1ssfo0x9rypx2yud
72d6a20c3d15        animage1/drupal:d8         &quot;docker-entrypoint.s…&quot;   2 weeks ago         Up 2 weeks          80/tcp              site3_drupal.1.5fqfizaxt0plh1tzt6caq0zon
</code></pre>
<p><strong>Step 6:</strong></p>
<p>I can now ssh into that container:</p>
<pre><code>node2$ docker exec -it 72d6a20c3d15 /bin/bash
</code></pre>
<p>Triumph!</p>
<p>(In your case, your Container ID may be on your node1, or whatever.  I've only added this extra step for node2 to illustrate the point that one should be aware of the node that the task (and corresponding container is running on))</p>
",8489,2020-12-14T10:00:43.937,"['node1 $ docker service ls\n', 'ID                  NAME                       MODE                REPLICAS            IMAGE                      PORTS\nsr2w12kl8bg1        site1_db                    replicated          1/1                 animage2/mariadb:latest        *:13306->3306/tcp\ne083ij8abje1        site1_drupal                replicated          1/1                 animage2/drupal:d7             *:7150->80/tcp\nsejb0f2mfo22        site1_drush                 replicated          0/1                 drush/drush:latest         \nkbae02doa8rs        site1_haproxy               replicated          2/2                 haproxy:alpine             \nkhgmnu1566rb        site2_db                    replicated          1/1                 mariadb:latest             \nnotoc1fam1gk        site3_drupal                replicated          1/1                 animage1/drupal:d8             *:7160->80/tcp\n0xtxx4jmmwa3        site4_db                    replicated          1/1                 mariadb:latest\n\n        \n', 'node1 $ docker service ps notoc1fam1gk\n', 'ID                  NAME                 IMAGE                      NODE                DESIRED STATE       CURRENT STATE          ERROR               PORTS\nyiofs723gc89        site3_drupal.1       animage1/drupal:d8         node2               Running             Running 6 days ago                         \npgdgf783ff9v         \\_ site3_drupal.1   animage1/drupal:d8         node2               Shutdown            Shutdown 2 weeks ago                       \n1gfdsgcb0p2q         \\_ site3_drupal.1   animage1/drupal:d8         node2               Shutdown            Shutdown 2 weeks ago                       \n175lfds2jbjy         \\_ site3_drupal.1   animage1/drupal:d8         node2               Shutdown            Shutdown 2 weeks ago                       \nqo312e143p1q         \\_ site3_drupal.1   animage1/drupal:d8         node2               Shutdown            Shutdown 3 weeks ago    \n\n               \n', 'docker inspect -f ""{{.Status.ContainerStatus.ContainerID}}"" <task_id>\n', 'node1 $ docker inspect -f ""{{.Status.ContainerStatus.ContainerID}}"" yiofs723gc89\n', '72d6a20c3d15dd9f0db4b1a60d93a91c0514946881f2dc00ca62d6a7a9ef1290\n', 'node1 $ docker ps\nCONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS                    NAMES\nd5d45a94d45e        haproxy:alpine         ""/docker-entrypoint.…""   3 days ago          Up 3 days                                    db_proxy_haproxy.2.91aw0apofd3iw537d249pyi62\n6a4676df2b3a        22dbb7890585           ""docker-entrypoint.s…""   3 days ago          Up 3 days           3306/tcp                 site2_db.1.xxizdccg9a2hgf83tcgg1tkaej\n538172a86a57        site1/drupal:asite     ""docker-php-entrypoi…""   3 days ago          Up 3 days           80/tcp                   site3.1.uofsfssl72aj867r0hfs86i7m24linae8\n2d487ea3788e        22dbb7890585           ""docker-entrypoint.s…""   3 days ago          Up 3 days           3306/tcp                 site4_db.1.3lnd0f9sl027f0skgza3kq373c0\nd671069584d7        mariadb:latest         ""docker-entrypoint.s…""   3 days ago          Up 3 days           3306/tcp                 site5.1.xoy0r6720362hlkhksu2qd\nbeb6bcb66f43        mariadb:latest         ""docker-entrypoint.s…""   3 days ago          Up 3 days           3306/tcp                 site2.1.kobk423624kljfs1uhpflfs3\n', 'node1$ ssh node2\n', 'node2$ docker ps\n\nCONTAINER ID        IMAGE                      COMMAND                  CREATED             STATUS              PORTS               NAMES\n2e3bc7158d61        89up/drupal:unity          ""docker-php-entrypoi…""   7 days ago          Up 7 days           80/tcp              someothersite_drupal.1.tg33od888aj6krqqhdx0tp8ta\n53122123d035        haproxy:alpine             ""/docker-entrypoint.…""   7 days ago          Up 7 days                               someothersite_haproxy.1.t1x7exq98huu8q3aaok57d22\n9348345f84cb        haproxy:alpine             ""/docker-entrypoint.…""   10 days ago         Up 10 days                              something-m_haproxy.2.02haarnwe1ssfo0x9rypx2yud\n72d6a20c3d15        animage1/drupal:d8         ""docker-entrypoint.s…""   2 weeks ago         Up 2 weeks          80/tcp              site3_drupal.1.5fqfizaxt0plh1tzt6caq0zon\n', 'node2$ docker exec -it 72d6a20c3d15 /bin/bash\n']"
1552,12955,12954,CC BY-SA 4.0,2020-12-10T14:08:43.220,"<blockquote>
<p>does Docker actually clone the image</p>
</blockquote>
<p>Typically no, it uses a layered filesystem, by default that's overlay2 on my systems. A decent example of this comes from the <a href=""https://wiki.archlinux.org/index.php/Overlay_filesystem"" rel=""nofollow noreferrer"">arch wiki</a>:</p>
<blockquote>
<ul>
<li>The lower directory can be read-only or could be an overlay itself.</li>
<li>The upper directory is normally writable.</li>
<li>The workdir is used to prepare files as they are switched between the layers.</li>
</ul>
<p>The lower directory can actually be a list of directories separated by
:, all changes in the merged directory are still reflected in upper.</p>
<p>Example:</p>
<pre><code># mount -t overlay overlay -o lowerdir=/lower1:/lower2:/lower3,upperdir=/upper,workdir=/work /merged
</code></pre>
</blockquote>
<hr />
<blockquote>
<p>how can I see the actual disk space used by a container?</p>
</blockquote>
<p>Docker will show you the disk used by all containers in a <code>docker system df</code>.</p>
<pre><code>$ docker system df
TYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLE
Images          183       4         37.59GB   37.34GB (99%)
Containers      7         3         2.23kB    1.114kB (49%)
Local Volumes   10        1         4.816GB   305.8MB (6%)
Build Cache     511       0         20.49GB   20.49GB
</code></pre>
<p>For a container, this number is not static (unlike images that are read only), so I don't think this shows in any of the inspect commands. But you can see the underlying filesystems used:</p>
<pre><code>$ docker container inspect 056 --format '{{json .GraphDriver}}' | jq .
{
  &quot;Data&quot;: {
    &quot;LowerDir&quot;: &quot;/home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6-init/diff:/home/docker/overlay2/22281f31287edf3342709add6123436540bd04dea60e474c961421e47b2dd58f/diff:/home/docker/overlay2/6a7a1eee38c2496928dff4741c2f9a1365f177a3e620ef7cf8adb816bba69b55/diff:/home/docker/overlay2/fcf371f07f06a42d328027281afb52c8044000cb51c4bb01a1f0dca2701062ec/diff:/home/docker/overlay2/89f8b12195e051bc439ac66d2bb299975884cdb229146dd570b1cac4011a08e6/diff:/home/docker/overlay2/d5a7a5c1c11746080d802b4dd076fd4d775099cb16b73d82c06db71e93b4e0c5/diff&quot;,
    &quot;MergedDir&quot;: &quot;/home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6/merged&quot;,
    &quot;UpperDir&quot;: &quot;/home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6/diff&quot;,
    &quot;WorkDir&quot;: &quot;/home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6/work&quot;
  },
  &quot;Name&quot;: &quot;overlay2&quot;
}
</code></pre>
<p>In this case, I can look at the disk usage of UpperDir to see how much space is used by that container:</p>
<pre><code>$ sudo du -sh /home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6/diff
80K     /home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6/diff
</code></pre>
<hr />
<p>The actual disk space used by a container includes the filesystem changes made by the container, since overlay is a copy-on-write filesystem. Each file changed is first copied to the container specific filesystem, even for a timestamp, permission, or owner change to the file metadata. This allows multiple containers to use the same immutable image layers without seeing changes made by the other containers.</p>
<p>Docker also keeps container logs, stdout and stderr, for each container. These logs are by default unlimited.</p>
<p>What you won't see is a full copy of the image filesystem, <strong>unless</strong> the overlay and similar graph drivers are unavailable to the docker engine. The fallback on an unsupported host filesystem, or kernel missing the needed features, is to use the <code>vfs</code> graph driver in docker, which I believe is the same as the <code>native</code> snapshotter in containerd. I see this happen occasionally with a docker-in-docker build environment where you cannot run an overlay filesystem on top of the overlay container filesystem (the fix there is typically to mount a volume that is on a supported filesystem outside of the container's overlay filesystem).</p>
",7730,2020-12-15T15:36:17.013,"['# mount -t overlay overlay -o lowerdir=/lower1:/lower2:/lower3,upperdir=/upper,workdir=/work /merged\n', '$ docker system df\nTYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLE\nImages          183       4         37.59GB   37.34GB (99%)\nContainers      7         3         2.23kB    1.114kB (49%)\nLocal Volumes   10        1         4.816GB   305.8MB (6%)\nBuild Cache     511       0         20.49GB   20.49GB\n', '$ docker container inspect 056 --format \'{{json .GraphDriver}}\' | jq .\n{\n  ""Data"": {\n    ""LowerDir"": ""/home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6-init/diff:/home/docker/overlay2/22281f31287edf3342709add6123436540bd04dea60e474c961421e47b2dd58f/diff:/home/docker/overlay2/6a7a1eee38c2496928dff4741c2f9a1365f177a3e620ef7cf8adb816bba69b55/diff:/home/docker/overlay2/fcf371f07f06a42d328027281afb52c8044000cb51c4bb01a1f0dca2701062ec/diff:/home/docker/overlay2/89f8b12195e051bc439ac66d2bb299975884cdb229146dd570b1cac4011a08e6/diff:/home/docker/overlay2/d5a7a5c1c11746080d802b4dd076fd4d775099cb16b73d82c06db71e93b4e0c5/diff"",\n    ""MergedDir"": ""/home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6/merged"",\n    ""UpperDir"": ""/home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6/diff"",\n    ""WorkDir"": ""/home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6/work""\n  },\n  ""Name"": ""overlay2""\n}\n', '$ sudo du -sh /home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6/diff\n80K     /home/docker/overlay2/ba813e6876186f8792d263ced7dc912921870393a085644188a8adadcf73d3e6/diff\n']"
1553,12958,12956,CC BY-SA 4.0,2020-12-10T18:17:23.210,"<p>When creating an image using a Dockerfile, docker layers are created for each step. The description of layers can be found on the official docker <a href=""https://docs.docker.com/storage/storagedriver/#images-and-layers"" rel=""nofollow noreferrer"">page</a>.</p>
<p>Accordingly, when using Multistage to create an image, it introduces a new build step that can be named using an alias in the FROM statement, and all layers except the image layer created via the last FROM statement are deleted.</p>
<p>After build your image, check if the layer that contains WORKDIR whether exists or not using docker image inspect. I think you probably know the unique layer value for each step.</p>
<p>You can see the image consists with which layers.
e.g.,</p>
<pre><code>$docker image inspect [OPTIONS] 464503b73bfe # IMAGE
[
    {
        &quot;Id&quot;: &quot;sha256:464bf1...46c&quot;,
        ...

        &quot;RootFS&quot;: {
            &quot;Type&quot;: &quot;layers&quot;,
            &quot;Layers&quot;: [
                &quot;sha256:26711...8fcf&quot;,
                &quot;sha256:6c5a51...56e0&quot;
            ]
        },
        ...
</code></pre>
",13461,2020-12-10T19:11:23.243,"['$docker image inspect [OPTIONS] 464503b73bfe # IMAGE\n[\n    {\n        ""Id"": ""sha256:464bf1...46c"",\n        ...\n\n        ""RootFS"": {\n            ""Type"": ""layers"",\n            ""Layers"": [\n                ""sha256:26711...8fcf"",\n                ""sha256:6c5a51...56e0""\n            ]\n        },\n        ...\n']"
1554,12959,12957,CC BY-SA 4.0,2020-12-10T20:49:39.893,"<p>This was so simple I've been kicking myself ever since I figured out what was wrong.</p>
<p>In the WP stack docker compose file this line was correct, but missing the 'www'.</p>
<pre><code>extra_hosts:
      - &quot;www.my-domain-name.com:192.168.80.2&quot;
</code></pre>
<p>In my WordPress setup the site URL included the www. So I was right to point the domain name to the IP of the Nginx container, but not including the full URL as specified in WP was causing the issue.</p>
<p>For anybody experiencing WP Site Health issues when using Docker, Nginx the solution is to use the &quot;extra_hosts&quot; directive in the wordpress container setup and point the IP of the Nginx container to the WordPress site URL.</p>
",25097,2020-12-10T22:42:46.187,"['extra_hosts:\n      - ""www.my-domain-name.com:192.168.80.2""\n']"
1555,12960,12954,CC BY-SA 4.0,2020-12-10T21:20:38.997,"<p>Docker containers are processes, does a process use disk space ? nope (at least not in itself).</p>
<p>The space used is the space when you put the program on disk first (the container image here).</p>
<p>Starting a container multiple times behave as starting bash/zsh/ multiple times when you login/ssh on different terminals/sessions.</p>
<p>One particularity of containers, more precisely of overlayfs, is the layers, if you pull two images for services based on the same base image, the initial layer won't be downloaded twice.</p>
<p>A rought illustration:</p>
<pre><code>- Ubuntu 20.04
|- redis (FROM ubuntu 20.04)
|- apache2 (FROM ubuntu 20.04)
</code></pre>
<p>You can get image for apache2 and redis and get only 3 layers on disk, the base ubuntu 20.04 will be reused.</p>
<p>Refer to <a href=""https://devops.stackexchange.com/a/12955/13"">BMitch</a>'s answer for details</p>
",13,2020-12-10T21:20:38.997,['- Ubuntu 20.04\n|- redis (FROM ubuntu 20.04)\n|- apache2 (FROM ubuntu 20.04)\n']
1556,12963,12924,CC BY-SA 4.0,2020-12-11T08:01:14.030,"<p>As a little addition to such extensive answer, with <code>docker ps</code> you can <code>--filter</code> containers by label. One of the labels in swarm is a service name, so:</p>
<pre><code>docker ps --filter &quot;label=com.docker.swarm.service.name=&lt;service_name&gt;&quot;
</code></pre>
<p>Should give you service containers on current node. To find more labels for possible filters hit</p>
<pre><code>docker  ps --format &quot;table {{.Names}}\t{{ .Labels }}&quot;
</code></pre>
",24539,2020-12-11T08:01:14.030,"['docker ps --filter ""label=com.docker.swarm.service.name=<service_name>""\n', 'docker  ps --format ""table {{.Names}}\\t{{ .Labels }}""\n']"
1557,12970,12944,CC BY-SA 4.0,2020-12-13T09:23:25.853,"<p>One way to limit docker logs is to specify limits in docker daemon's config file.</p>
<p>You can put this in <code>/etc/docker/daemon.json</code></p>
<pre><code>{
  &quot;log-driver&quot;: &quot;json-file&quot;,
  &quot;log-opts&quot;: {
    &quot;max-size&quot;: &quot;10m&quot;,
    &quot;max-file&quot;: &quot;3&quot; 
  }
}
</code></pre>
<p>and then restart your docker daemon.</p>
",8727,2020-12-13T09:23:25.853,"['{\n  ""log-driver"": ""json-file"",\n  ""log-opts"": {\n    ""max-size"": ""10m"",\n    ""max-file"": ""3"" \n  }\n}\n']"
1558,12992,10421,CC BY-SA 4.0,2020-12-17T14:05:49.657,"<p>I've encountered the same issue when trying to use conda environments in CI builds and Docker images. The <a href=""https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/use-conda-with-travis-ci.html"" rel=""nofollow noreferrer"">conda documentation</a> does provide an example when using Travis CI, but it does not work for me.</p>
<p>However, via <a href=""https://pythonspeed.com/articles/activate-conda-dockerfile/"" rel=""nofollow noreferrer"">this blog</a> I found a working solution! Instead of activating your environment, you can use it by calling <code>conda run -n my_env python my_file.py</code>. So, keep everything like it was until you activate your environment.</p>
<p>These build specs worked for me when using AWS CodeBuild:</p>
<pre class=""lang-json prettyprint-override""><code>{
  &quot;version&quot;: &quot;0.2&quot;,
  &quot;phases&quot;: {
    &quot;pre_build&quot;: {
      &quot;commands&quot;: [
        &quot;wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh -q&quot;,
        &quot;bash miniconda.sh -b -p $HOME/miniconda&quot;,
        &quot;. \&quot;$HOME/miniconda/etc/profile.d/conda.sh\&quot;&quot;,
        &quot;hash -r&quot;,
        &quot;conda config --set always_yes yes --set changeps1 no&quot;,
        &quot;conda update -q conda&quot;,
        &quot;conda info -a&quot;,
        &quot;conda env create -q -p ./py_env -f environment.yml&quot;
      ]
    },
    &quot;build&quot;: {
      &quot;commands&quot;: [
        &quot;conda run -p ./py_env python app.py&quot;
      ]
    }
  }
}

</code></pre>
",25215,2020-12-18T18:51:21.780,"['{\n  ""version"": ""0.2"",\n  ""phases"": {\n    ""pre_build"": {\n      ""commands"": [\n        ""wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh -q"",\n        ""bash miniconda.sh -b -p $HOME/miniconda"",\n        "". \\""$HOME/miniconda/etc/profile.d/conda.sh\\"""",\n        ""hash -r"",\n        ""conda config --set always_yes yes --set changeps1 no"",\n        ""conda update -q conda"",\n        ""conda info -a"",\n        ""conda env create -q -p ./py_env -f environment.yml""\n      ]\n    },\n    ""build"": {\n      ""commands"": [\n        ""conda run -p ./py_env python app.py""\n      ]\n    }\n  }\n}\n\n']"
1559,13003,6267,CC BY-SA 4.0,2020-12-20T01:20:06.647,"<p>For those searching, I found this post while experiencing the same issue.  I was able to resolve this by adding the array index to my loop:</p>
<pre><code>  copy:
    content: &quot;{{ acme_challenge_your_domain['results'][ansible_loop.index0]['challenge_data'][item.hostname]['http-01']['resource_value'] }}&quot;
    dest: &quot;/var/www/{{ item.hostname }}/{{ acme_challenge_your_domain['results'][ansible_loop.index0]['challenge_data'][item.hostname]['http-01']['resource'] }}&quot;
    owner: root
    group: root
    mode: u=rw,g=r,o=r
  loop: &quot;{{ hosted_sites }}&quot;
  loop_control:
    loop_var: item
    extended: yes
</code></pre>
<p>The specific changes here being converting with_items to a loop and adding the loop_control parameter extended.  This allows for usage of ansible_loop.index0.</p>
",25247,2020-12-20T01:20:06.647,"['  copy:\n    content: ""{{ acme_challenge_your_domain[\'results\'][ansible_loop.index0][\'challenge_data\'][item.hostname][\'http-01\'][\'resource_value\'] }}""\n    dest: ""/var/www/{{ item.hostname }}/{{ acme_challenge_your_domain[\'results\'][ansible_loop.index0][\'challenge_data\'][item.hostname][\'http-01\'][\'resource\'] }}""\n    owner: root\n    group: root\n    mode: u=rw,g=r,o=r\n  loop: ""{{ hosted_sites }}""\n  loop_control:\n    loop_var: item\n    extended: yes\n']"
1560,13005,13004,CC BY-SA 4.0,2020-12-20T16:33:15.100,"<p>Q: <strong>&quot;<em>Check if all items are own by root.</em>&quot;</strong></p>
<p>A: Put the list of the tools into the variable <em>audit_tools</em>. Compare the length of the lists. For example</p>
<pre class=""lang-yaml prettyprint-override""><code>- hosts: localhost
  vars:
    audit_tools:
      - auditctl
      - aureport
      - ausearch
      - autrace
      - auditd
      - audispd
      - augenrules
  tasks:
    - block:
        - stat:
            path: &quot;/sbin/{{ item }}&quot;
          loop: &quot;{{ audit_tools }}&quot;
          register: result
        - assert:
            that: no_audit_tools == no_owner_root
            fail_msg: &quot;One or more tools are not own by root.&quot;
          vars:
            no_audit_tools: &quot;{{ audit_tools|length }}&quot;
            no_owner_root: &quot;{{ result.results|
                               json_query('[?stat.pw_name==`root`]')|
                               length }}&quot;
      rescue:
        - debug:
            msg: &quot;Rescue: audit tools not owned by root.&quot;
</code></pre>
<p>If not all items are owned by root <em>assert</em> will fail and the <em>block</em> will proceed to the <em>rescue</em> section</p>
<pre class=""lang-yaml prettyprint-override""><code>TASK [assert] ****
fatal: [localhost]: FAILED! =&gt; changed=false 
  assertion: no_audit_tools == no_owner_root
  evaluated_to: false
  msg: One or more tools are not own by root.

TASK [debug] ****
ok: [localhost] =&gt; 
  msg: 'Rescue: audit tools not owned by root.'
</code></pre>
<hr>
<p>Q: <strong>&quot;<em>This solution requires <a href=""https://jmespath.org/"" rel=""nofollow noreferrer"">JMESPath</a> to be installed. Is there an alternative solution?</em>&quot;</strong></p>
<p>A: Yes. It is. Use Jinja filter <a href=""https://jinja.palletsprojects.com/en/master/templates/#selectattr"" rel=""nofollow noreferrer"">selectattr</a></p>
<pre class=""lang-yaml prettyprint-override""><code>            no_owner_root: &quot;{{ result.results|
                               selectattr('stat.pw_name', 'eq', 'root')|
                               list|length }}&quot;
</code></pre>
",7715,2020-12-21T07:09:04.480,"['- hosts: localhost\n  vars:\n    audit_tools:\n      - auditctl\n      - aureport\n      - ausearch\n      - autrace\n      - auditd\n      - audispd\n      - augenrules\n  tasks:\n    - block:\n        - stat:\n            path: ""/sbin/{{ item }}""\n          loop: ""{{ audit_tools }}""\n          register: result\n        - assert:\n            that: no_audit_tools == no_owner_root\n            fail_msg: ""One or more tools are not own by root.""\n          vars:\n            no_audit_tools: ""{{ audit_tools|length }}""\n            no_owner_root: ""{{ result.results|\n                               json_query(\'[?stat.pw_name==`root`]\')|\n                               length }}""\n      rescue:\n        - debug:\n            msg: ""Rescue: audit tools not owned by root.""\n', ""TASK [assert] ****\nfatal: [localhost]: FAILED! => changed=false \n  assertion: no_audit_tools == no_owner_root\n  evaluated_to: false\n  msg: One or more tools are not own by root.\n\nTASK [debug] ****\nok: [localhost] => \n  msg: 'Rescue: audit tools not owned by root.'\n"", '            no_owner_root: ""{{ result.results|\n                               selectattr(\'stat.pw_name\', \'eq\', \'root\')|\n                               list|length }}""\n']"
1561,13007,12942,CC BY-SA 4.0,2020-12-21T11:16:27.297,"<p>Standard practice in non-development environments is to <code>COPY</code> the application code into the image, and to set the standard <code>CMD</code> there too.</p>
<pre class=""lang-sh prettyprint-override""><code>...
COPY . .
RUN composer install
# php:fpm-alpine image already provides the correct CMD
</code></pre>
<p>There are a couple of important advantages to doing this:</p>
<ul>
<li>You can just run the Docker image directly on the target system; you don't have to copy the Docker image, and also the application code separately.</li>
<li><code>RUN composer install</code> happens only once during the build sequence.  <code>command: composer install ...</code> runs on every restart, which is slower, uses network bandwidth, and can fail.</li>
<li>If you give a unique tag to each image, you can easily roll back to an earlier image by changing the tag back.  It's hard to do this with a volume mount.</li>
<li>You'll <code>docker run</code> an identical image in all environments; you don't need to worry that the host-directory copy of the application is slightly different on that one system.</li>
</ul>
<p>There's no specific rule that a Docker image needs to be very small; the only practical issue I've encountered is that multi-gigabyte images don't transfer across the network well.  Indeed, I'd recommend the opposite choice around <code>COPY</code> vs. volumes that you've suggested: <code>COPY</code> the application code in, and use volumes for config files and other things that aren't &quot;your code&quot;, and that need to be directly accessed from the host.  (You do want to rebuild your application when the application changes; you don't want to rebuild your application when the database URL changes.)</p>
",17579,2020-12-21T11:16:27.297,['...\nCOPY . .\nRUN composer install\n# php:fpm-alpine image already provides the correct CMD\n']
1562,13036,12824,CC BY-SA 4.0,2020-12-28T20:49:36.023,"<p>Is something like the below what you are looking for?</p>
<pre><code>locals {
  apps = keys(var.app_config)
}

resource &quot;azurerm_key_vault_secret&quot; &quot;app_id&quot; {
  for_each = toset(local.apps)

  name         = each.key
  value        = var.keyvault_secrets[var.environment][each.key][&quot;application_id&quot;]
  key_vault_id = data.azurerm_key_vault.mykv.id
}
</code></pre>
",22743,2020-12-28T20:49:36.023,"['locals {\n  apps = keys(var.app_config)\n}\n\nresource ""azurerm_key_vault_secret"" ""app_id"" {\n  for_each = toset(local.apps)\n\n  name         = each.key\n  value        = var.keyvault_secrets[var.environment][each.key][""application_id""]\n  key_vault_id = data.azurerm_key_vault.mykv.id\n}\n']"
1563,13055,10495,CC BY-SA 4.0,2020-12-31T05:07:06.160,"<p>I recently made myself a small script that seems to do the work. It certainly can be done better but maybe you can get some inspiration:</p>
<pre><code>#!/bin/bash

set -e

if [ -z &quot;$1&quot; ]
 then
    echo &quot;No host patter supplied. Please provide a host pattern that would match only one host form the inventory.&quot;
    echo &quot;Usage: ansible-ssh &lt;host_pattern&gt;&quot;
    echo &quot;Example: ./ansible-ssh services[0]&quot;
    exit 1
fi

USER=sysadm
HOST_PATTERN=$1
HOST=`ansible -m shell -a &quot;echo {{ groups.$HOST_PATTERN }}&quot; localhost  | sed 1d`

if grep -q &quot;\[.*\]&quot; &lt;&lt;&lt; &quot;$HOST&quot;; then
  echo &quot;Host pattern $HOST_PATTERN matches more than one host: $HOST&quot;
  exit 1
fi

echo &quot;Connecting to $USER@$HOST...&quot;
ssh $USER@$HOST
</code></pre>
<p>Just edit your default USER (in my case sysadm) and execute in the following way:</p>
<pre><code>./ansible-ssh services[0]
</code></pre>
<p>Where <code>services</code> is your inventory entry holding one or more IPs.</p>
",25387,2020-12-31T05:07:06.160,"['#!/bin/bash\n\nset -e\n\nif [ -z ""$1"" ]\n then\n    echo ""No host patter supplied. Please provide a host pattern that would match only one host form the inventory.""\n    echo ""Usage: ansible-ssh <host_pattern>""\n    echo ""Example: ./ansible-ssh services[0]""\n    exit 1\nfi\n\nUSER=sysadm\nHOST_PATTERN=$1\nHOST=`ansible -m shell -a ""echo {{ groups.$HOST_PATTERN }}"" localhost  | sed 1d`\n\nif grep -q ""\\[.*\\]"" <<< ""$HOST""; then\n  echo ""Host pattern $HOST_PATTERN matches more than one host: $HOST""\n  exit 1\nfi\n\necho ""Connecting to $USER@$HOST...""\nssh $USER@$HOST\n', './ansible-ssh services[0]\n']"
1564,13060,13033,CC BY-SA 4.0,2021-01-01T13:59:08.490,"<p>This is something I have implemented recently.</p>
<p><em><strong>NOTE: I'm assuming you are aware ho to add users. or users in group in this case.</strong></em></p>
<p>here is what I have applied:</p>
<pre><code>apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: readonly_role
rules: 
- apiGroups:
  - &quot;&quot;
  resourceNames:
  - &quot;&quot;
  resources:
  - &quot;pods&quot;
  - &quot;pods/logs&quot;
  - &quot;deployments&quot;
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - authorization.k8s.io
  resources:
  - selfsubjectaccessreviews
  - selfsubjectrulesreviews
  verbs:
  - watch
  - get
  - list

---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: bind_readonly_dev_role
subjects:
- kind: Group
  name: myorg:readonly 
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: readonly_role
  apiGroup: rbac.authorization.k8s.io

</code></pre>
<p>You can use either <code>ClusterRole</code> &amp; <code>ClusterRoleBinding</code> or else just <code>Role</code> &amp; <code>Rolebinding</code>, depending on your requirement. In case you are not looking for cluster scoped access, instead just a namespace, I would strongly suggest going with the <code>Role</code> &amp; <code>Rolebinding</code> kind of object.</p>
<p><strong>What I'm doing/creating in the above?</strong></p>
<p>I'm creating one RBAC Role (<code>readonly_role</code>) scoped to Cluster.
and in that I'm specifying I want to let access <code>pods</code>, <code>logs</code> (i.e <code>pods/logs</code>), and <code>deployments</code>. additionally you. can also add things like <code>services</code> or else if you just want to give access to all specify <code>&quot;&quot;</code> instead.</p>
<p>in the 2nd part, I'm creating a ClusterRoleBinding Object named <code>bind_readonly_dev_role </code> which ensures only users in group <code>myorg:readonly</code> are having this role or privileges in the role we just created (<code>readonly_role </code>).</p>
<p>NOTE: Incase you want to allow proxy access to certain applications, like <code>kubectl proxy</code>.
you might have to specify them separately in the <code>ClusterRole</code> rules.</p>
<p>I do like this for one of my svc:</p>
<pre><code>- apiGroups:
  - &quot;&quot;
  resourceNames:
  - dashboard:5000
  resources:
  - services/proxy
  verbs:
  - '*'

</code></pre>
<p>at last but not least, you have to test if the user has those privileges correct,
you can test like this:</p>
<pre><code>kubectl auth  can-i get pods --as myorg:readonly
</code></pre>
<p>in the above replace the pods with the object you want the users of the group to have access to.</p>
<p>Hope this helps!</p>
",21684,2021-01-01T13:59:08.490,"['apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: readonly_role\nrules: \n- apiGroups:\n  - """"\n  resourceNames:\n  - """"\n  resources:\n  - ""pods""\n  - ""pods/logs""\n  - ""deployments""\n  verbs:\n  - get\n  - list\n  - watch\n- apiGroups:\n  - authorization.k8s.io\n  resources:\n  - selfsubjectaccessreviews\n  - selfsubjectrulesreviews\n  verbs:\n  - watch\n  - get\n  - list\n\n---\n\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: bind_readonly_dev_role\nsubjects:\n- kind: Group\n  name: myorg:readonly \n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: readonly_role\n  apiGroup: rbac.authorization.k8s.io\n\n', '- apiGroups:\n  - """"\n  resourceNames:\n  - dashboard:5000\n  resources:\n  - services/proxy\n  verbs:\n  - \'*\'\n\n', 'kubectl auth  can-i get pods --as myorg:readonly\n']"
1565,13077,13073,CC BY-SA 4.0,2021-01-04T13:13:51.607,"<p>CORS is applied at the application layer, not the infrastructure (docker) layer. So, this has nothing to do with docker. It also has nothing to do with the axios client. Rather, your server needs to allow requests from your client by returning the correct headers via the OPTIONS method.</p>
<p>If you're using nodejs and express, you can add something like this to your service:</p>
<pre class=""lang-javascript prettyprint-override""><code>app.use((req, res, next) =&gt; {
  res.header(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;);
  res.header(&quot;Access-Control-Allow-Headers&quot;, &quot;Origin, X-Requested-With, Content-Type, Accept, Authorization&quot;);
  res.header(&quot;Access-Control-Allow-Methods&quot;, &quot;GET&quot;);

  if (req.method === &quot;OPTIONS&quot;) return res.status(200).json({});

  next();
});
</code></pre>
<p>Or, there are plenty of CORS libraries that can help you out.</p>
",7513,2021-01-04T13:13:51.607,"['app.use((req, res, next) => {\n  res.header(""Access-Control-Allow-Origin"", ""*"");\n  res.header(""Access-Control-Allow-Headers"", ""Origin, X-Requested-With, Content-Type, Accept, Authorization"");\n  res.header(""Access-Control-Allow-Methods"", ""GET"");\n\n  if (req.method === ""OPTIONS"") return res.status(200).json({});\n\n  next();\n});\n']"
1566,13083,12809,CC BY-SA 4.0,2021-01-05T04:59:49.120,"<p>I solved this issue with these IAM permissions,</p>
<pre><code>{
    &quot;Sid&quot;: &quot;query&quot;,
    &quot;Effect&quot;: &quot;Allow&quot;,
    &quot;Action&quot;: [
        &quot;logs:StopQuery&quot;,
        &quot;logs:StartQuery&quot;
    ],
    &quot;Resource&quot;: &quot;arn:aws:logs:us-east-1:*:log-group:/aws/lambda/my-lambda-function-name*:*&quot;
},
{
    &quot;Sid&quot;: &quot;logstream&quot;,
    &quot;Effect&quot;: &quot;Allow&quot;,
    &quot;Action&quot;: [
        &quot;logs:GetQueryResults&quot;,
        &quot;logs:DescribeLogGroups&quot;
    ],
    &quot;Resource&quot;: &quot;arn:aws:logs:us-east-1:*:log-group::log-stream:*&quot;
}
</code></pre>
<p>(you need to change the region <code>us-east-1</code> and <code>my-lambda-function-name</code> to your lambda function name)</p>
",25483,2021-01-05T04:59:49.120,"['{\n    ""Sid"": ""query"",\n    ""Effect"": ""Allow"",\n    ""Action"": [\n        ""logs:StopQuery"",\n        ""logs:StartQuery""\n    ],\n    ""Resource"": ""arn:aws:logs:us-east-1:*:log-group:/aws/lambda/my-lambda-function-name*:*""\n},\n{\n    ""Sid"": ""logstream"",\n    ""Effect"": ""Allow"",\n    ""Action"": [\n        ""logs:GetQueryResults"",\n        ""logs:DescribeLogGroups""\n    ],\n    ""Resource"": ""arn:aws:logs:us-east-1:*:log-group::log-stream:*""\n}\n']"
1567,13090,13085,CC BY-SA 4.0,2021-01-05T19:32:21.080,"<p>You can store secret file at Jenkins and use it for deployment.
It can be achieved by using <a href=""https://plugins.jenkins.io/credentials/"" rel=""nofollow noreferrer"">Credentials</a> and <a href=""https://plugins.jenkins.io/credentials-binding/"" rel=""nofollow noreferrer"">Credentials Binding</a> plugins.</p>
<ol>
<li>Install Credentials Binding and Credentials plugins</li>
<li>Select your user name in the top navigation bar.</li>
<li>Select Credentials in the left pane.</li>
<li>Under Stores from parent, select (global) in the Domains column.</li>
<li>Select Add Credentials in the left pane.
<a href=""https://i.stack.imgur.com/wCUk4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wCUk4.png"" alt=""enter image description here"" /></a></li>
<li>insert into your pipeline script</li>
</ol>
<pre>  
withCredentials([file(credentialsId: 'env', variable: 'mySecretEnvFile')]){
    sh 'cp $mySecretEnvFile $WORKSPACE'
}
</pre>
",6060,2021-01-05T19:32:21.080,"[""  \nwithCredentials([file(credentialsId: 'env', variable: 'mySecretEnvFile')]){\n    sh 'cp $mySecretEnvFile $WORKSPACE'\n}\n""]"
1568,13094,13092,CC BY-SA 4.0,2021-01-06T00:55:15.363,"<p>When validating an input variable of a collection type, we typically want to write a validation rule that tests if something is true for each value within the collection, rather than true of the collection as a whole.</p>
<p>You can write a &quot;for each&quot; sort of condition using Terraform's <a href=""https://www.terraform.io/docs/configuration/expressions/for.html"" rel=""nofollow noreferrer""><code>for</code> expressions</a>. If you are using Terraform v0.14 or later then you can write it concisely using <a href=""https://www.terraform.io/docs/configuration/functions/alltrue.html"" rel=""nofollow noreferrer"">the <code>alltrue</code> function</a> along with a <code>for</code> expression that produces a true or false result for each of the items, like this:</p>
<pre><code>  validation {
    condition = alltrue([
      for id in var.security_groups : can(regex(&quot;^sg-&quot;, id))
    ])
    error_message = &quot;All security group ids must start with \&quot;sg-\&quot;.&quot;
  }
</code></pre>
<hr />
<p>If you are using Terraform v0.13 then you won't have the <code>alltrue</code> function available to you yet, but you can get a similar result in a clunkier way by using the optional <code>if</code> clause of a <code>for</code> expression to filter out all of the valid ids and then checking whether the resulting list is empty -- that is, whether there are any remaining items that were <em>not</em> valid:</p>
<pre><code>  validation {
    condition = length([
      for id in var.security_groups : id
      if !can(regex(&quot;^sg-&quot;, id))
    ]) == 0
    error_message = &quot;All security group ids must start with \&quot;sg-\&quot;.&quot;
  }
</code></pre>
<p>This second example is a bit more cryptic to understand because it's using some language features in an atypical way, so I'll break it down into smaller parts to explain:</p>
<ul>
<li><code>[for id in var.security_groups : id if !can(regex(&quot;^sg-&quot;, id))]</code> filters the elements of <code>var.security_groups</code> to keep only the ones where the expression is true.</li>
<li><code>!can(regex(&quot;^sg-&quot;, id))</code> uses the <code>!</code> operator to turn your original expression that decides if the value is <em>valid</em> into an expression which decides if the value is <em>invalid</em>. Consequently the result of the <code>for</code> expression will be empty unless there's at least one invalid value.</li>
<li>Finally, the <code>length( ... ) == 0</code> around the <code>for</code> expression says that the value is only valid if filtering out all of the valid values produces an empty list, which conversely means that the list didn't contain any invalid values.</li>
</ul>
",2463,2021-01-06T17:27:23.473,"['  validation {\n    condition = alltrue([\n      for id in var.security_groups : can(regex(""^sg-"", id))\n    ])\n    error_message = ""All security group ids must start with \\""sg-\\"".""\n  }\n', '  validation {\n    condition = length([\n      for id in var.security_groups : id\n      if !can(regex(""^sg-"", id))\n    ]) == 0\n    error_message = ""All security group ids must start with \\""sg-\\"".""\n  }\n']"
1569,13100,13034,CC BY-SA 4.0,2021-01-07T10:58:58.137,"<p>you need just to install <code>ca-certificates</code> so update your apt-get command to :</p>
<pre><code>RUN set -ex; \
    apt-get -y install --no-install-recommends \
        ca-certificates \
        curl=7.64.0-4+deb10u1 \
        unzip=6.0-23+deb10u1 \
        coreutils=8.30-3 \
        lsb-release build-essential ssh-client apt-transport-https \
        python gnupg
</code></pre>
",15739,2021-01-07T10:58:58.137,['RUN set -ex; \\\n    apt-get -y install --no-install-recommends \\\n        ca-certificates \\\n        curl=7.64.0-4+deb10u1 \\\n        unzip=6.0-23+deb10u1 \\\n        coreutils=8.30-3 \\\n        lsb-release build-essential ssh-client apt-transport-https \\\n        python gnupg\n']
1570,13108,9298,CC BY-SA 4.0,2021-01-08T19:52:13.900,"<p>To calculate disk space required by Prometheus v2.20 <strong>in bytes</strong>, use the query:</p>
<pre><code>retention_time_seconds *
rate(prometheus_tsdb_head_samples_appended_total[2h]) *
(rate(prometheus_tsdb_compaction_chunk_size_bytes_sum[2h]) / rate(prometheus_tsdb_compaction_chunk_samples_sum[2h]))
</code></pre>
<p>Where <code>retention_time_seconds</code> is the value you've configured for <code>--storage.tsdb.retention.time</code>, which defaults to <code>15d</code> = <code>1296000</code> seconds.</p>
",25540,2021-01-08T19:52:13.900,['retention_time_seconds *\nrate(prometheus_tsdb_head_samples_appended_total[2h]) *\n(rate(prometheus_tsdb_compaction_chunk_size_bytes_sum[2h]) / rate(prometheus_tsdb_compaction_chunk_samples_sum[2h]))\n']
1571,13119,13088,CC BY-SA 4.0,2021-01-11T18:13:43.707,"<p>Since I'm using Jenkins official helm chart which contains <a href=""https://www.jenkins.io/projects/jcasc/"" rel=""nofollow noreferrer"">JCasC plugin (Jenkins Configuration as Code)</a>, I was able to configure the static slave attachment using it including the creation of relevant credentials.</p>
<p>Here's the relevant section of the values.yaml file I use to install/upgrade the Jenkins helm chart:</p>
<pre><code>JCasC:
    defaultConfig: true
    configScripts:
      credentials: |
        credentials:
          system:
            domainCredentials:
              - credentials:
                  - usernamePassword:
                      scope: GLOBAL
                      id: &quot;CentOS_7.1_k4.14.11_ssh_password&quot;
                      username: 'jenkins'
                      password: ${decodeBase64:BASE64ENCODEDPASSWD}
                      description: &quot;Username/Password Credentials for CentOS_7.1_k4.14.11&quot;
      permanent-nodes: |
        jenkins:
          nodes:
            - permanent:
                name: &quot;CentOS 7.1 k4.14.11&quot;
                remoteFS: &quot;/home/jenkins&quot;
                numExecutors: 2
                labelString: &quot;CentOS_7.1_k4.14.11&quot;
                mode: EXCLUSIVE
                retentionStrategy: &quot;always&quot;
                launcher:
                  SSH:
                    jvmOptions: &quot;-Xms256m -Xmx1024m -XX:MaxPermSize=1024m&quot;
                    credentialsId: &quot;CentOS_7.1_k4.14.11_ssh_password&quot;
                    host: &quot;10.1.66.120&quot;
                    port: 22
                    sshHostKeyVerificationStrategy:
                      manuallyTrustedKeyVerificationStrategy:
                        requireInitialManualTrust: false
</code></pre>
<p>Now whenever I re-deploy or upgrade Jenkins helm chart, it automatically configures these credentials and add the static slave.</p>
",12614,2021-01-11T18:13:43.707,"['JCasC:\n    defaultConfig: true\n    configScripts:\n      credentials: |\n        credentials:\n          system:\n            domainCredentials:\n              - credentials:\n                  - usernamePassword:\n                      scope: GLOBAL\n                      id: ""CentOS_7.1_k4.14.11_ssh_password""\n                      username: \'jenkins\'\n                      password: ${decodeBase64:BASE64ENCODEDPASSWD}\n                      description: ""Username/Password Credentials for CentOS_7.1_k4.14.11""\n      permanent-nodes: |\n        jenkins:\n          nodes:\n            - permanent:\n                name: ""CentOS 7.1 k4.14.11""\n                remoteFS: ""/home/jenkins""\n                numExecutors: 2\n                labelString: ""CentOS_7.1_k4.14.11""\n                mode: EXCLUSIVE\n                retentionStrategy: ""always""\n                launcher:\n                  SSH:\n                    jvmOptions: ""-Xms256m -Xmx1024m -XX:MaxPermSize=1024m""\n                    credentialsId: ""CentOS_7.1_k4.14.11_ssh_password""\n                    host: ""10.1.66.120""\n                    port: 22\n                    sshHostKeyVerificationStrategy:\n                      manuallyTrustedKeyVerificationStrategy:\n                        requireInitialManualTrust: false\n']"
1572,13127,6227,CC BY-SA 4.0,2021-01-12T16:36:41.950,"<h3>Containers have to expose ports</h3>
<p>A container will not listen to outside traffic unless the Dockerfile has an <code>EXPOSE 5000</code> command. This tells the container to listen for external traffic on that port.</p>
<p>That being said, the Docker engine will only listen to external ports that you tell it to. By default that is none. Setting <code>EXPOSE 5000</code> means that the container will listen to external traffic that the docker engine routes to it. By default this means only internal docker engine traffic will be able to access that port.</p>
<h3>Expose the port to the host</h3>
<p>Depending on how you are starting the container (either cli or docker-compose), you will need to expose the port to the host. From CLI, this will be done with the <code>-p</code> flag in the format <code>-p hostPort:containerPort</code>. You can then map the port as you wish, like <code>-p 50000:5000</code> with 5000 being the same port in your <code>EXPOSE</code> command in the Docker file and 50000 being the <code>localhost</code> port you want to use.</p>
<h3>Putting it together</h3>
<p>Update your docker file to something like this:</p>
<pre><code># Specify a base image
FROM node:alpine
...

EXPOSE 5000

# Default command
CMD [&quot;npm&quot;, &quot;start&quot;]
</code></pre>
<p>Then run it with:</p>
<pre class=""lang-sh prettyprint-override""><code>docker run --rm imageName -p 5000:5000
</code></pre>
<p>From there you should be able to <code>curl http://localhost:5000</code> and get the expected response.</p>
",25586,2021-01-12T16:36:41.950,"['# Specify a base image\nFROM node:alpine\n...\n\nEXPOSE 5000\n\n# Default command\nCMD [""npm"", ""start""]\n', 'docker run --rm imageName -p 5000:5000\n']"
1573,13134,8512,CC BY-SA 4.0,2021-01-13T12:41:12.200,"<p>In the google_compute_instance_template resource, the email property of the service_account block should not start with &quot;serviceAccount:&quot;. Change from:</p>
<pre><code>service_account {
  email  = &quot;serviceAccount:${google_service_account.frontend_service_account.email}&quot;
  scopes = [&quot;default&quot;]
}
</code></pre>
<p>To this:</p>
<pre><code>service_account {
  email  = &quot;${google_service_account.frontend_service_account.email}&quot;
  scopes = [&quot;default&quot;]
}
</code></pre>
",25604,2021-01-13T12:41:12.200,"['service_account {\n  email  = ""serviceAccount:${google_service_account.frontend_service_account.email}""\n  scopes = [""default""]\n}\n', 'service_account {\n  email  = ""${google_service_account.frontend_service_account.email}""\n  scopes = [""default""]\n}\n']"
1574,13137,13135,CC BY-SA 4.0,2021-01-14T07:35:04.043,"<p>This can be done with two tasks with loops:</p>
<pre class=""lang-yaml prettyprint-override""><code># tasks/packages.yml
- name: pkgs | Ensure Good 
  package:
    name: &quot;{{ item }}&quot;
    state: present
  loop: &quot;{{ packages['present'] }}&quot;

- name: pkgs | Ensure Bad
  package:
    name: &quot;{{ item }}&quot;
    state: absent
  loop: &quot;{{ packages['absent'] }}&quot;
</code></pre>
<p>This will loop over all of the items in the list that you define and ensure that they are either <code>present</code> or <code>absent</code>.</p>
<p>You could also use a shorthand:</p>
<pre class=""lang-yaml prettyprint-override""><code># tasks/packages.yml
- name: pkgs | Ensure Good 
  package:
    name: &quot;{{ packages['present'] }}&quot;
    state: present

- name: pkgs | Ensure Bad
  package:
    name: &quot;{{ packages['absent'] }}&quot;
    state: absent
</code></pre>
<p>This would run faster, since you don't have a list of tasks, but a task with a list, but you would lose some visibility into which packages you're actually ensuring the state of.</p>
<p>Caveats:</p>
<p>Ensure that there is no overlap between the two lists. One way would be to make an assertion on the lists before you run the task:</p>
<pre class=""lang-yaml prettyprint-override""><code>- name: ensure no overlap between good and bad
  assert:
    that: &quot;{{ packages['present'] | intersect(packages['absent'] }} == [] }}&quot;
</code></pre>
<p>Also ensure that the lists are not empty.</p>
<p>To answer your final question:</p>
<blockquote>
<p>Q: are there best practices about managing the state of &quot;entities&quot; on the configured infrastructure?</p>
</blockquote>
<p>It is usually <em>my</em> practice (I wouldn't call it &quot;best&quot;, but take it for what it's worth) to declare the explicit state of a resource. It's quite difficult to do this exhaustively for packages that should be <code>absent</code> - this is something akin to maintaining a &quot;blacklist&quot;. One approach might to be start from a policy and implement specific controls in it. <em>IE</em> for ssh config ensure that protocol v1 is absent, <em>etc</em>.</p>
",354,2021-01-14T08:31:43.983,"['# tasks/packages.yml\n- name: pkgs | Ensure Good \n  package:\n    name: ""{{ item }}""\n    state: present\n  loop: ""{{ packages[\'present\'] }}""\n\n- name: pkgs | Ensure Bad\n  package:\n    name: ""{{ item }}""\n    state: absent\n  loop: ""{{ packages[\'absent\'] }}""\n', '# tasks/packages.yml\n- name: pkgs | Ensure Good \n  package:\n    name: ""{{ packages[\'present\'] }}""\n    state: present\n\n- name: pkgs | Ensure Bad\n  package:\n    name: ""{{ packages[\'absent\'] }}""\n    state: absent\n', '- name: ensure no overlap between good and bad\n  assert:\n    that: ""{{ packages[\'present\'] | intersect(packages[\'absent\'] }} == [] }}""\n']"
1575,13138,9156,CC BY-SA 4.0,2021-01-14T08:37:50.973,"<p>I managed to get Erik's approach working which is great.</p>
<p>I then wondered if I could simplify it so instead of deleting the content how about put each artifact in a sub folder of the <strong>$(Build.ArtifactStagingDirectory)</strong> So by just appending /Api or /App I could create specific publish folders that I could then push onto the azure pipeline.</p>
<p>You can then have as many artifacts as you need :)</p>
<p>The important parts to take from this are that <strong>publishWebProjects</strong> needs to be set to <strong>false</strong> or it defaults to true and then ignores the projects line below, and the <strong>output</strong> path puts the content in a sub folder.</p>
<pre><code> # This need to be false in order for the specific project to be published
 publishWebProjects: False
 projects: '**/DevOpsApp.csproj'
 arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)/App'
</code></pre>
<p>and <strong>pathtoPublish</strong> need to then point to the sub folder</p>
<pre><code>pathtoPublish: '$(Build.ArtifactStagingDirectory)/App'
</code></pre>
<p>Full example file below</p>
<pre><code># ASP.NET Core
# Build and test ASP.NET Core projects targeting .NET Core.
# Add steps that run tests, create a NuGet package, deploy, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/dotnet-core

trigger:
- develop

pool:
  vmImage: 'ubuntu-latest'

variables:
    buildConfiguration: 'Release'
    versionNumber: 1.0.0

name: $(versionNumber)-wip-$(Rev:r)

#----------------------------------------------------------
# Web API Build and Artifact
#----------------------------------------------------------

steps:
- task: DotNetCoreCLI@2
  displayName: 'Build'
  inputs:
    command: 'build'
    projects: '**/DevOpsApi.csproj'
    arguments: '--configuration $(buildConfiguration)'

- task: DotNetCoreCLI@2
  inputs:
    command: 'test'
    projects: '**/*Tests.csproj'
    arguments: '--configuration $(buildConfiguration)'
    testRunTitle: 'Unit Tests'

# Publish the artifact
- task: DotNetCoreCLI@2
  inputs:
    command: 'publish'
    # This need to be false in order for the specific project to be published
    publishWebProjects: False
    projects: '**/DevOpsApi.csproj'
    arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)/Api'
    zipAfterPublish: True

# Publish the artifact for the pipelines to use
- task: PublishBuildArtifacts@1
  displayName: 'Publishing WebAPI Artifact'
  inputs:
    pathtoPublish: '$(Build.ArtifactStagingDirectory)/Api' 
    artifactName: 'TestWebApi-Wip'

#----------------------------------------------------------
# Web APP Build and Artifact
#----------------------------------------------------------

- task: DotNetCoreCLI@2
  displayName: 'Build'
  inputs:
    command: 'build'
    projects: '**/DevOpsApp.csproj'
    arguments: '--configuration $(buildConfiguration)'

# Publish the artifact
- task: DotNetCoreCLI@2
  inputs:
    command: 'publish'
    # This need to be false in order for the specific project to be published
    publishWebProjects: False
    projects: '**/DevOpsApp.csproj'
    arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)/App'
    zipAfterPublish: True

# Publish the artifact for the pipelines to use
- task: PublishBuildArtifacts@1
  displayName: 'Publishing WebAPP Artifact'
  inputs:
    pathtoPublish: '$(Build.ArtifactStagingDirectory)/App' 
    artifactName: 'TestWebApp-Wip'
</code></pre>
",25625,2021-01-14T08:37:50.973,"["" # This need to be false in order for the specific project to be published\n publishWebProjects: False\n projects: '**/DevOpsApp.csproj'\n arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)/App'\n"", ""pathtoPublish: '$(Build.ArtifactStagingDirectory)/App'\n"", ""# ASP.NET Core\n# Build and test ASP.NET Core projects targeting .NET Core.\n# Add steps that run tests, create a NuGet package, deploy, and more:\n# https://docs.microsoft.com/azure/devops/pipelines/languages/dotnet-core\n\ntrigger:\n- develop\n\npool:\n  vmImage: 'ubuntu-latest'\n\nvariables:\n    buildConfiguration: 'Release'\n    versionNumber: 1.0.0\n\nname: $(versionNumber)-wip-$(Rev:r)\n\n#----------------------------------------------------------\n# Web API Build and Artifact\n#----------------------------------------------------------\n\nsteps:\n- task: DotNetCoreCLI@2\n  displayName: 'Build'\n  inputs:\n    command: 'build'\n    projects: '**/DevOpsApi.csproj'\n    arguments: '--configuration $(buildConfiguration)'\n\n- task: DotNetCoreCLI@2\n  inputs:\n    command: 'test'\n    projects: '**/*Tests.csproj'\n    arguments: '--configuration $(buildConfiguration)'\n    testRunTitle: 'Unit Tests'\n\n# Publish the artifact\n- task: DotNetCoreCLI@2\n  inputs:\n    command: 'publish'\n    # This need to be false in order for the specific project to be published\n    publishWebProjects: False\n    projects: '**/DevOpsApi.csproj'\n    arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)/Api'\n    zipAfterPublish: True\n\n# Publish the artifact for the pipelines to use\n- task: PublishBuildArtifacts@1\n  displayName: 'Publishing WebAPI Artifact'\n  inputs:\n    pathtoPublish: '$(Build.ArtifactStagingDirectory)/Api' \n    artifactName: 'TestWebApi-Wip'\n\n#----------------------------------------------------------\n# Web APP Build and Artifact\n#----------------------------------------------------------\n\n- task: DotNetCoreCLI@2\n  displayName: 'Build'\n  inputs:\n    command: 'build'\n    projects: '**/DevOpsApp.csproj'\n    arguments: '--configuration $(buildConfiguration)'\n\n# Publish the artifact\n- task: DotNetCoreCLI@2\n  inputs:\n    command: 'publish'\n    # This need to be false in order for the specific project to be published\n    publishWebProjects: False\n    projects: '**/DevOpsApp.csproj'\n    arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)/App'\n    zipAfterPublish: True\n\n# Publish the artifact for the pipelines to use\n- task: PublishBuildArtifacts@1\n  displayName: 'Publishing WebAPP Artifact'\n  inputs:\n    pathtoPublish: '$(Build.ArtifactStagingDirectory)/App' \n    artifactName: 'TestWebApp-Wip'\n""]"
1576,13144,13117,CC BY-SA 4.0,2021-01-15T08:41:55.247,"<p><a href=""https://support.cloudbees.com/hc/en-us/articles/226520788-Control-environment-variables-inside-a-Docker-container"" rel=""nofollow noreferrer"">This post explains that/why environment variables don't propagate to Docker agent</a>.</p>
<p>If you need a custom container, you could define path and whatever else as layers on top of base image in a Dockerfile. Then using that image in pipeline would be what I think is usual way of doing it. You can build that image outside of Jenkins, but it's also possible to <a href=""https://www.jenkins.io/doc/book/pipeline/docker/#building-containers"" rel=""nofollow noreferrer"">build container from within pipeline too</a> if you want (get Dockerfile from SCM or some other use case).</p>
<p>In the context of your question, I think you can still use base image, and if you know full path you'd like to set, do that at container (agent) startup with args. But <code>$PATH</code> variable won't be available at host to be resolved within container at startup. If you must dynamically set path in container, could adjust it in shells.</p>
<pre><code>pipeline {
    agent {
        docker { 
            image 'python:3.9'
            // cannot resolve $PATH var in container (becasue HOST does not know what it is).
            args '-e PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/i/know/my/full/path/ahead/of/time'
        }
    }
    stages {
        stage('Test') {
            steps {
                
                // as set by args above. Applies to all shells
                sh 'echo $PATH'
                
                // You can also adjust it within container in each shell
                sh '''
                    export PATH=/even/more/path:$PATH
                    echo $PATH
                   '''

                // But this is back to what's in args in a new shell instance
                sh 'echo $PATH'
            }
        }
    }
}
</code></pre>
",25529,2021-01-15T11:28:07.320,"[""pipeline {\n    agent {\n        docker { \n            image 'python:3.9'\n            // cannot resolve $PATH var in container (becasue HOST does not know what it is).\n            args '-e PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/i/know/my/full/path/ahead/of/time'\n        }\n    }\n    stages {\n        stage('Test') {\n            steps {\n                \n                // as set by args above. Applies to all shells\n                sh 'echo $PATH'\n                \n                // You can also adjust it within container in each shell\n                sh '''\n                    export PATH=/even/more/path:$PATH\n                    echo $PATH\n                   '''\n\n                // But this is back to what's in args in a new shell instance\n                sh 'echo $PATH'\n            }\n        }\n    }\n}\n""]"
1577,13149,12902,CC BY-SA 4.0,2021-01-16T17:45:03.893,"<p>First - <a href=""https://devops.stackexchange.com/users/16819/caxcaxcoatl"">@caxcaxcoatl</a> is completly right - your playbook is not Ansible, it is a bash script inside Ansible and that isn't Ansible.</p>
<p>Your error doesn't have something to do with your playbook, but with that, what the playbook is doing. You're redeploying an application and then the proxy in front of the Tomcat cannot read the response from your Tomcat. So your deployment is wrong, has some failures, what ever. You should have a look at your Tomcat HTTP response (without the Proxy in front) direct on the machine (with <code>curl</code>, <code>telnet</code> or whatever). Maybe you should also check the logs of Tomcat to get the error. The proxy sends the error, because the Tomcat is answering with a 500 HTTP error code, when the proxy hits <code>/portal-client/cm/misalud/</code>.</p>
<p>To give you a hint, how a playbook could look like (of course this wasn't the question, and it could be done much better then this with includes for a unspecific WAR and just call include_tasks on all available WARs in the main playbook, or with a Ansible module written in Python just giving the params of the new WAR etc.):</p>
<pre><code>- name: Deploy war
  hosts: grupo1
  vars:
    webapps_cur &quot;/opt/tomcat/catalina_base/webapps&quot;
    webapps_old: &quot;/opt/tomcat/catalina_base/webapps.old&quot;
  tasks:
    - name: &quot;Stop Tomcat&quot;
      systemd:
        name: tomcat
        state: stopped

    - name: &quot;Delete old Backup WARs&quot;
      file:
        path: &quot;{{ webapps_old }}/{{ item }}&quot;
        state: absent
      with_items:
        - &quot;portal-admin&quot;
        - &quot;portal-client&quot;

    - name: &quot;Backup the current WARs&quot;
      copy:
        src: &quot;{{ webapps_cur }}/{{ item }}&quot;
        dest: &quot;{{ webapps_old }}/{{ item }}&quot;
        remote_src: true
      with_items:
        - &quot;portal-admin&quot;
        - &quot;portal-client&quot;

    - name: &quot;Delete the current WARs&quot;
      file:
        path: &quot;{{ webapps_cur }}/{{ item }}&quot;
        state: absent
      with_items:
        - &quot;portal-admin&quot;
        - &quot;portal-client&quot;

    - name: &quot;Deploy new WARs&quot;
      unarchive:
        src: &quot;/tmp/{{ item }}.war&quot;
        dest: &quot;{{ webapps_cur }}/{{ item }}&quot;
        user: &quot;tomcat&quot;
        group: &quot;tomcat&quot;
      with_items:
        - &quot;portal-admin&quot;
        - &quot;portal-client&quot;

    - name: &quot;Start Tomcat&quot;
      systemd:
        name: tomcat
        state: started
</code></pre>
",17486,2021-01-16T17:45:03.893,"['- name: Deploy war\n  hosts: grupo1\n  vars:\n    webapps_cur ""/opt/tomcat/catalina_base/webapps""\n    webapps_old: ""/opt/tomcat/catalina_base/webapps.old""\n  tasks:\n    - name: ""Stop Tomcat""\n      systemd:\n        name: tomcat\n        state: stopped\n\n    - name: ""Delete old Backup WARs""\n      file:\n        path: ""{{ webapps_old }}/{{ item }}""\n        state: absent\n      with_items:\n        - ""portal-admin""\n        - ""portal-client""\n\n    - name: ""Backup the current WARs""\n      copy:\n        src: ""{{ webapps_cur }}/{{ item }}""\n        dest: ""{{ webapps_old }}/{{ item }}""\n        remote_src: true\n      with_items:\n        - ""portal-admin""\n        - ""portal-client""\n\n    - name: ""Delete the current WARs""\n      file:\n        path: ""{{ webapps_cur }}/{{ item }}""\n        state: absent\n      with_items:\n        - ""portal-admin""\n        - ""portal-client""\n\n    - name: ""Deploy new WARs""\n      unarchive:\n        src: ""/tmp/{{ item }}.war""\n        dest: ""{{ webapps_cur }}/{{ item }}""\n        user: ""tomcat""\n        group: ""tomcat""\n      with_items:\n        - ""portal-admin""\n        - ""portal-client""\n\n    - name: ""Start Tomcat""\n      systemd:\n        name: tomcat\n        state: started\n']"
1578,13150,12832,CC BY-SA 4.0,2021-01-16T18:37:30.730,"<p>When I have a look at your posted output and compare it to mine, there is something wrong:</p>
<pre><code>ok: [localhost] =&gt; {
    &quot;msg&quot;: &quot;357&quot;
}
</code></pre>
<p>That output comes from the debug message. But only with <code>debug msg={{ value }}</code> and not with <code>debug var={{ value }}</code>. When I do it with var= then I get (in my case) <code>&quot;32&quot;: &quot;32&quot;</code> as a response.</p>
<p>But that's not the problem. The problem is:</p>
<pre><code>- name: Show diff variable
  debug:
    var: diff
</code></pre>
<p>The name <code>diff</code> for the variable is somehow reserved. You need to set the diff as Jinja</p>
<pre><code>- name: Show diff variable
  debug:
    var: &quot;{{ diff }}&quot;
</code></pre>
<p>And then I see</p>
<pre><code>ok: [localhost] =&gt; {
    &quot;32&quot;: &quot;32&quot;
}
</code></pre>
<p>When I rename the variable to <code>diffa</code> everything is normal. I can't find any documentation for it.</p>
<pre><code>- name: Show mount of days with dedug module
  set_fact:
    diffa: &quot;{{ (( x2 | to_datetime('%d-%m-%Y')) - ( x1  | to_datetime('%d-%m-%Y'))).days }}&quot;

- name: Show mount of days with dedug module
  debug:
    var: diffa
</code></pre>
<p>output:</p>
<pre><code>TASK [Show mount of days with dedug module] *********************************************
ok: [localhost] =&gt; {
    &quot;diffa&quot;: &quot;32&quot;
}
</code></pre>
",17486,2021-01-16T18:37:30.730,"['ok: [localhost] => {\n    ""msg"": ""357""\n}\n', '- name: Show diff variable\n  debug:\n    var: diff\n', '- name: Show diff variable\n  debug:\n    var: ""{{ diff }}""\n', 'ok: [localhost] => {\n    ""32"": ""32""\n}\n', '- name: Show mount of days with dedug module\n  set_fact:\n    diffa: ""{{ (( x2 | to_datetime(\'%d-%m-%Y\')) - ( x1  | to_datetime(\'%d-%m-%Y\'))).days }}""\n\n- name: Show mount of days with dedug module\n  debug:\n    var: diffa\n', 'TASK [Show mount of days with dedug module] *********************************************\nok: [localhost] => {\n    ""diffa"": ""32""\n}\n']"
1579,13157,13147,CC BY-SA 4.0,2021-01-18T16:56:06.833,"<p>One option for doing this is to create a database trigger.</p>
<h2>In Mysql</h2>
<p>In MySQL and MariaDB, you can do this with mysql-udf-http. <a href=""https://stackoverflow.com/a/57937476/3127174"">From perodriguezl answer</a> from Stack Overflow:</p>
<blockquote>
<p>You can use a mysql-udf-http and then create a trigger like this:</p>
</blockquote>
<pre><code>delimiter $$
CREATE TRIGGER upd_check BEFORE UPDATE ON account 
FOR EACH ROW 
  BEGIN 
    IF NEW.amount &gt; 0 THEN 
      set @json = select json_object(account_id,amount) 
      select http_post('http://restservice.example.com/account/post',@json); 
    END IF; 
  END;$$ 

delimiter;
</code></pre>
<h2>In Postgres</h2>
<p>In Postgres, you can write a stored procedure and use <code>plperlu</code> with <code>REST::Client</code></p>
<p>From <a href=""https://stackoverflow.com/a/46543582"">JustMe's Answer</a> on Stack Overflow:</p>
<blockquote>
<p>...the fastest way is to use <code>plperlu</code> with <code>REST::Client</code> package, e.g.:</p>
</blockquote>
<pre><code>CREATE OR REPLACE FUNCTION restful.put(auri character varying, ajson_text text)
 RETURNS text
 LANGUAGE plperlu
 SECURITY DEFINER
AS $function$
  use REST::Client;  
  use Encode qw(encode);
  my $client = REST::Client-&gt;new();    
  $client-&gt;getUseragent()-&gt;proxy( 'https', 'http://some-proxy/' ); # use for proxy authentication
  $client-&gt;addHeader('Content-Type', 'application/json');          # headers
  $client-&gt;POST( $_[0], encode('UTF-8', $_[1]));                   # encoding
  return $client-&gt;responseContent();  
$function$
</code></pre>
<h2>Using Oracle</h2>
<p>On an Oracle database, You will need to use <code>UTL_HTTP</code> - <a href=""https://technology.amis.nl/database/invoke-a-rest-service-from-plsql-make-an-http-post-request-using-utl_http-in-oracle-database-11g-xe/"" rel=""nofollow noreferrer"">Lucas Jellema's blog has a good example.</a> There are also several others available.</p>
<h2>Conclusion</h2>
<p>In each case, You would then presumably want to tweak your trigger to watch for an <code>update</code> statement on the table and check for the status you want to trigger off of (eg, you probably don't want to trigger off of new/closed) as well as make sure it is for the right project (Not quite sure how JIRA's schema is laid out - it might do one table per project. Eg, you probably don't want to trigger builds off of IT's tickets, but only off of dev or QA's JIRA project if you have multiple.)</p>
",2845,2021-01-19T02:41:34.363,"[""delimiter $$\nCREATE TRIGGER upd_check BEFORE UPDATE ON account \nFOR EACH ROW \n  BEGIN \n    IF NEW.amount > 0 THEN \n      set @json = select json_object(account_id,amount) \n      select http_post('http://restservice.example.com/account/post',@json); \n    END IF; \n  END;$$ \n\ndelimiter;\n"", ""CREATE OR REPLACE FUNCTION restful.put(auri character varying, ajson_text text)\n RETURNS text\n LANGUAGE plperlu\n SECURITY DEFINER\nAS $function$\n  use REST::Client;  \n  use Encode qw(encode);\n  my $client = REST::Client->new();    \n  $client->getUseragent()->proxy( 'https', 'http://some-proxy/' ); # use for proxy authentication\n  $client->addHeader('Content-Type', 'application/json');          # headers\n  $client->POST( $_[0], encode('UTF-8', $_[1]));                   # encoding\n  return $client->responseContent();  \n$function$\n""]"
1580,13173,13172,CC BY-SA 4.0,2021-01-20T07:24:48.393,"<p>For the daemon's version (meaning the engine's version) that's running on your server:</p>
<pre><code>$ dockerd --version
Docker version 20.10.2, build 8891c58
</code></pre>
<p>For your client's version that's running on your local computer and with which you send commands to the daemon on the remote server:</p>
<pre><code>$ docker --version
Docker version 19.03.13, build 4484c46d9d
</code></pre>
",7646,2021-01-20T07:24:48.393,"['$ dockerd --version\nDocker version 20.10.2, build 8891c58\n', '$ docker --version\nDocker version 19.03.13, build 4484c46d9d\n']"
1581,13175,13147,CC BY-SA 4.0,2021-01-20T08:14:41.617,"<p>I didn't get what's wrong with <a href=""https://developer.atlassian.com/server/jira/platform/webhooks/"" rel=""nofollow noreferrer"">webhooks</a>
You just create a webhook on Gitlab CI side and provide this URL to your Jira account.</p>
<pre><code>https://gitlab.com/api/v4/projects/PROJECT_ID/ref/REF_NAME/trigger/pipeline?token=TOKEN
</code></pre>
<p><code>PROJECT_ID</code> - unique project id on Gitlab</p>
<p><code>REF_NAME</code> - your <code>qa</code> / <code>stage</code> / <code>beta</code> branches within repository</p>
<p><code>TOKEN</code> - uniquely generated access token (gitlab provided)</p>
<p><a href=""https://docs.gitlab.com/ee/ci/triggers/"" rel=""nofollow noreferrer"">Look here</a> for more details how to trigger build on Gitlab via this call</p>
",19083,2021-01-20T08:14:41.617,['https://gitlab.com/api/v4/projects/PROJECT_ID/ref/REF_NAME/trigger/pipeline?token=TOKEN\n']
1582,13187,4823,CC BY-SA 4.0,2021-01-21T13:40:53.997,"<p>I also tried to make something more &quot;practical&quot; so i just search a bit around and found the task: &quot;include_role&quot; which allows loops. So i decided to loop that task with my target roles and use a when. Here the snippet:</p>
<pre><code>- name: &quot;Redhat&quot;
  hosts: all
  become: yes
  tasks:
    - name: ADD Roles
      include_role:
        name: &quot;{{role}}&quot;
        apply:
          ignore_errors: yes
      with_items:
        - role1
        - role2
      loop_control:
        loop_var: role
      when: ansible_os_family==&quot;RedHat&quot;
</code></pre>
",25735,2021-01-21T13:40:53.997,"['- name: ""Redhat""\n  hosts: all\n  become: yes\n  tasks:\n    - name: ADD Roles\n      include_role:\n        name: ""{{role}}""\n        apply:\n          ignore_errors: yes\n      with_items:\n        - role1\n        - role2\n      loop_control:\n        loop_var: role\n      when: ansible_os_family==""RedHat""\n']"
1583,13223,13220,CC BY-SA 4.0,2021-01-25T19:00:21.173,"<p>Try and add a Stage condition to only run that stage for a specific branch.</p>
<pre><code>condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/master'))


stages:
- stage: A
             .....

- stage: B
  **condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/master'))**
  jobs:
  - job: B1
    steps:
      - script: echo Hello Stage B!
      - script: echo $(isMain)
</code></pre>
<p>Reference : <a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/process/conditions?view=azure-devops&amp;tabs=yaml"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/azure/devops/pipelines/process/conditions?view=azure-devops&amp;tabs=yaml</a></p>
<p>PS : Will refine the answer in future, currently we are still using GUI for releases and we are using this branch filter to control this scenario.</p>
<p><a href=""https://i.stack.imgur.com/GZWfa.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GZWfa.png"" alt=""enter image description here"" /></a></p>
",14940,2021-01-25T19:00:21.173,"[""condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/master'))\n\n\nstages:\n- stage: A\n             .....\n\n- stage: B\n  **condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/master'))**\n  jobs:\n  - job: B1\n    steps:\n      - script: echo Hello Stage B!\n      - script: echo $(isMain)\n""]"
1584,13225,12996,CC BY-SA 4.0,2021-01-25T19:56:47.570,"<p>I got a work around to this case. basically, My root volume is 100GB and I created a separate partition out of it as 70GB and I set it to a new device sda3 and mounted it to /var/lib.</p>
<p>now, all docker container logs are written in same path but in backend they are mounted to a different drive. with this setup, even if there is disk pressure, the node does not become unavailable.</p>
<p>so my drive now looks liek below</p>
<pre><code>sda1
sda2 / 30GB
sda3 /var/lib 70GB.  &lt;&lt; new device
</code></pre>
",24120,2021-01-25T19:56:47.570,['sda1\nsda2 / 30GB\nsda3 /var/lib 70GB.  << new device\n']
1585,13233,13203,CC BY-SA 4.0,2021-01-27T01:47:44.453,"<p>This is possible, but you'll have to use scripted Pipelines, not declarative, disable the Groovy sandbox for pipelines, and dig deep into the Jenkins API.</p>
<p>For instance, I wrote a Pipeline job that edits the parameters of a second job which has a full name of &quot;SCA/deploy_to_environment/master&quot;.  Here's a snippet of that code - I'm eliding how to create the &quot;Param&quot; objects in the first line for brevity, this snippet is just to give you an idea of what a similar use case looks like:</p>
<pre><code>def paramProp = new ParametersDefinitionProperty(envParam, pgParam, infoParam)

def job = Jenkins.instance.getItemByFullName('SCA/deploy_to_environment/master')

// There is no &quot;setProperty&quot; - we need to remove and replace.
// removeProperty is safe to run even if no matching properties are set on the job.
// However, this method only removes one property per method call.
// Theoretically, this means the job could accumulate multiple conflicting
// ParametersDefinitionProperty properties.
// TODO: run removeProperty in a while loop to eliminate all matching properties for extra safety.
job.removeProperty(ParametersDefinitionProperty)

job.addProperty(paramProp)
</code></pre>
<p>So to fetch the values instead of simply editing them, you would need to instead call <code>getProperty</code> (<a href=""https://javadoc.jenkins.io/hudson/model/Job.html#getProperty-java.lang.Class-"" rel=""nofollow noreferrer"">API doc here</a>), passing the class name of the GitLab Project parameter classes. I suspect the class name you'll need is available somewhere in the source code or the <a href=""https://javadoc.jenkins.io/plugin/gitlab-branch-source/io/jenkins/plugins/gitlabbranchsource/package-summary.html"" rel=""nofollow noreferrer"">API docs for that plugin</a>, but I'm not sure.</p>
<hr />
<p>However, I have to ask, why do you want to do this?  What's the big picture here?</p>
<p>It sounds kind of like you want to share a single Jenkinsfile or build pipeline among multiple repositories.  I also have this use case at my job - we need to have one Jenkinsfile shared across nearly 200 repositories.  If this is similar to your need, then consider using <a href=""https://www.jenkins.io/doc/book/pipeline/shared-libraries/"" rel=""nofollow noreferrer"">Jenkins Shared Libraries</a>.  You can put all of your build pipeline code into a single shared library, then call the shared library in a single line from the Jenkinsfile in your individual repositories.</p>
",4115,2021-01-27T01:47:44.453,"['def paramProp = new ParametersDefinitionProperty(envParam, pgParam, infoParam)\n\ndef job = Jenkins.instance.getItemByFullName(\'SCA/deploy_to_environment/master\')\n\n// There is no ""setProperty"" - we need to remove and replace.\n// removeProperty is safe to run even if no matching properties are set on the job.\n// However, this method only removes one property per method call.\n// Theoretically, this means the job could accumulate multiple conflicting\n// ParametersDefinitionProperty properties.\n// TODO: run removeProperty in a while loop to eliminate all matching properties for extra safety.\njob.removeProperty(ParametersDefinitionProperty)\n\njob.addProperty(paramProp)\n']"
1586,13237,13232,CC BY-SA 4.0,2021-01-27T09:16:59.897,"<p>They quick and dirty answer is to &quot;<a href=""https://wiki.jenkins.io/display/JENKINS/Display+jobs+group+by+the+build+steps+they+use"" rel=""nofollow noreferrer"">Display jobs group by the build steps they use</a>&quot; as updated below.</p>
<pre><code>import hudson.model.*
import hudson.tasks.*

//All the projects on which we can apply the getBuilders method
def allProjects = Jenkins.instance.allItems.findAll{ it instanceof Project }

//All the registered build steps in the current Jenkins Instance
def allSteps = Builder.all()

//Group the projects by the build steps used
def projectsGroupBySteps = allSteps.inject([:]){
   map, step -&gt;
   map[step.clazz.name] = allProjects.findAll{it.builders.any{ 
        it.class.name.contains(step.clazz.name)}}.collect{it.fullName}
   map
}

//Presentation
projectsGroupBySteps.sort().each{
    println &quot;--- ($it.value.size) $it.key ---&quot;
}
println ''

println 'Occcurences:'
projectsGroupBySteps.sort().each{
println &quot;--- ($it.value.size) $it.key ---&quot;
    it.value.each {
        println it }
    println ''
}
return
</code></pre>
<p>Note that a job has multiple sections: <strong>builders</strong>, <strong>publishers</strong> and <strong>buildWrappers</strong>.
Depending on what you are looking for, replace</p>
<pre><code>[allSteps = Builder.all(), allProjects.findAll{it.builders.any ]
[allSteps = Publisher.all(), allProjects.findAll{it.publishers.any ]
[allSteps = BuildWrapper.all(), allProjects.findAll{it.buildWrappers.any ]
</code></pre>
<p>Plugins may also be involved in the <strong>SCM</strong> section and as <strong>properties</strong> (eg: <code>hudson.plugins.buildblocker.BuildBlockerProperty</code>, <code>com.sonyericsson.jenkins.plugins.bfa.model.ScannerJobProperty</code>)</p>
<p>Obviously, same limitations of plugin-usage apply: does not scan pipeline steps plugin usage or build steps nested within an <code>org.jenkinsci.plugins.conditionalbuildstep</code></p>
",13379,2021-01-27T10:18:01.190,"['import hudson.model.*\nimport hudson.tasks.*\n\n//All the projects on which we can apply the getBuilders method\ndef allProjects = Jenkins.instance.allItems.findAll{ it instanceof Project }\n\n//All the registered build steps in the current Jenkins Instance\ndef allSteps = Builder.all()\n\n//Group the projects by the build steps used\ndef projectsGroupBySteps = allSteps.inject([:]){\n   map, step ->\n   map[step.clazz.name] = allProjects.findAll{it.builders.any{ \n        it.class.name.contains(step.clazz.name)}}.collect{it.fullName}\n   map\n}\n\n//Presentation\nprojectsGroupBySteps.sort().each{\n    println ""--- ($it.value.size) $it.key ---""\n}\nprintln \'\'\n\nprintln \'Occcurences:\'\nprojectsGroupBySteps.sort().each{\nprintln ""--- ($it.value.size) $it.key ---""\n    it.value.each {\n        println it }\n    println \'\'\n}\nreturn\n', '[allSteps = Builder.all(), allProjects.findAll{it.builders.any ]\n[allSteps = Publisher.all(), allProjects.findAll{it.publishers.any ]\n[allSteps = BuildWrapper.all(), allProjects.findAll{it.buildWrappers.any ]\n']"
1587,13245,13242,CC BY-SA 4.0,2021-01-28T07:36:09.110,"<p>Helm isn't made to be used this way.  If you'd prefer to use a static deployment, you're better off using a plain Kubernetes manifest.  Then, people changing the image field won't break your release.</p>
<p>You can easily convert it to one simply by running <a href=""https://helm.sh/docs/helm/helm_get_manifest/"" rel=""nofollow noreferrer"">helm get manifest</a> command</p>
<p>Helm is used to manage release versions.  I.e. every new release (and a docker image change definitely qualifies as one), you would push a change to your helm chart.</p>
<p>The other alternative you have is defining docker image as a value.  Then you can pass a command-line argument to replace the image tag with a new one and re-run helm from Jenkins any time you have a new deploy.</p>
<p>Example:</p>
<p>in values.yaml:</p>
<pre><code>image: 
  repo: foo
  tag: bar
</code></pre>
<p>On command line when running helm:</p>
<pre><code>helm upgrade --install my-app --set image.tag=newtag
</code></pre>
<p>Final, and least recommended way is to use a mutable tag (i.e. &quot;master&quot;) and set your <code>ImagePullPolicy</code> to <code>Always</code>.  This way, when you have a deploy, you just need to bounce all the pods in your deployment/daemonset/statefulset object.</p>
",3175,2021-01-28T07:36:09.110,"['image: \n  repo: foo\n  tag: bar\n', 'helm upgrade --install my-app --set image.tag=newtag\n']"
1588,13250,13238,CC BY-SA 4.0,2021-01-28T15:06:48.503,"<p>Simplest answer is to just revert the commit.  AWS Code Commit is standard Git and will support everything Git allows you to do.</p>
<p>I.e. find commit hash:</p>
<pre><code>git log -n1
commit 444c954e458cc446e2a7a1f2659adf71bdf55580 (HEAD -&gt; my-branch, origin/my-branch)
</code></pre>
<p>Then do the revert:</p>
<pre><code>git revert 444c954e458cc446e2a7a1f2659adf71bdf55580
git push
</code></pre>
<p>It'll revert your repo to whatever state it would be without that specific commit.  Note that if you have other commits that modified the same files afterward, you will have a merge conflict and will have to fix them manually.</p>
",3175,2021-01-28T15:06:48.503,"['git log -n1\ncommit 444c954e458cc446e2a7a1f2659adf71bdf55580 (HEAD -> my-branch, origin/my-branch)\n', 'git revert 444c954e458cc446e2a7a1f2659adf71bdf55580\ngit push\n']"
1589,13258,11833,CC BY-SA 4.0,2021-01-31T02:24:18.730,"<p>It's possible to use jobDSL from Pipeline. (Im using multibranch pipeline as it allows to configure pipelineTriggers)
You can configure your seed job to be a pipeline like this:</p>
<pre><code>def gitCredentialsId      = 'github-jenkins'
def jobsRepoName          = 'https://github.com/my-jobs-repo.git'
def sharedLibraryRepoName = 'https://github.com/shared-library-repo.git'

properties([    
   pipelineTriggers([githubPush()])
])

pipeline {
    agent any
    stages{
        stage('Seed Job') {
            agent any
            steps {

                checkout([
                    $class: 'GitSCM', 
                    branches: [[name: '*/main']], 
                    doGenerateSubmoduleConfigurations: false,
                    extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'shared-library']], 
                    submoduleCfg: [],
                    userRemoteConfigs: [[credentialsId:  gitCredentialsId, url: sharedLibraryRepoName ]]
                    ])

                git url: jobsRepoName, changelog: false, credentialsId: gitCredentialsId, poll: false, branch: 'main'
                jobDsl targets: 'jobs/**/*_job.groovy', additionalClasspath: 'shared-library/src'
            }
        }
    }
}
</code></pre>
<p>This way we can configure our seed job to checkout shared libraries repo into workspace subdirectory <em>shared-library</em> and specify <strong>additionalClasspath</strong> for jobDSL groovy scripts</p>
<p>So in your groovy scripts you can simply use import without @Library annotation</p>
",25862,2021-01-31T02:24:18.730,"[""def gitCredentialsId      = 'github-jenkins'\ndef jobsRepoName          = 'https://github.com/my-jobs-repo.git'\ndef sharedLibraryRepoName = 'https://github.com/shared-library-repo.git'\n\nproperties([    \n   pipelineTriggers([githubPush()])\n])\n\npipeline {\n    agent any\n    stages{\n        stage('Seed Job') {\n            agent any\n            steps {\n\n                checkout([\n                    $class: 'GitSCM', \n                    branches: [[name: '*/main']], \n                    doGenerateSubmoduleConfigurations: false,\n                    extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'shared-library']], \n                    submoduleCfg: [],\n                    userRemoteConfigs: [[credentialsId:  gitCredentialsId, url: sharedLibraryRepoName ]]\n                    ])\n\n                git url: jobsRepoName, changelog: false, credentialsId: gitCredentialsId, poll: false, branch: 'main'\n                jobDsl targets: 'jobs/**/*_job.groovy', additionalClasspath: 'shared-library/src'\n            }\n        }\n    }\n}\n""]"
1590,13259,11833,CC BY-SA 4.0,2021-01-31T16:05:29.877,"<p>There are two option</p>
<ol>
<li><p>Using jenkins global shared lib setting in gui see documation  <a href=""https://www.jenkins.io/doc/book/pipeline/shared-libraries/"" rel=""nofollow noreferrer"">https://www.jenkins.io/doc/book/pipeline/shared-libraries/</a></p>
</li>
<li><p>Importing shared library inside jenkins file similart like this follow this blog
<a href=""https://tomd.xyz/jenkins-shared-library/"" rel=""nofollow noreferrer"">https://tomd.xyz/jenkins-shared-library/</a></p>
<pre><code>library identifier: 'mylibraryname@master',
     //'master' refers to a valid git-ref
     //'mylibraryname' can be any name you like
     retriever: modernSCM([
       $class: 'GitSCMSource',
       credentialsId: 'your-credentials-id',
       remote: 'https://git.yourcompany.com/yourrepo/private-library.git'
 ])

 pipeline {
     agent any
     stages {
         stage('Demo') {
             steps {
                 echo 'Hello world'
                 yourCustomStep 'your_arg'
             }
         }
     }
</code></pre>
</li>
</ol>
<p>P.S.
When using &quot;@Library _&quot; the this means importing all libraries</p>
",22892,2021-01-31T16:10:43.373,"[""library identifier: 'mylibraryname@master',\n     //'master' refers to a valid git-ref\n     //'mylibraryname' can be any name you like\n     retriever: modernSCM([\n       $class: 'GitSCMSource',\n       credentialsId: 'your-credentials-id',\n       remote: 'https://git.yourcompany.com/yourrepo/private-library.git'\n ])\n\n pipeline {\n     agent any\n     stages {\n         stage('Demo') {\n             steps {\n                 echo 'Hello world'\n                 yourCustomStep 'your_arg'\n             }\n         }\n     }\n""]"
1591,13270,12625,CC BY-SA 4.0,2021-02-01T10:30:24.003,"<p>You defined multiple <code>ansible_ssh_common_args</code> vars per host. That does'nt work. Ansible will use only one of it (I asume the last). Also you try to reach the bastion host via 10.1.0.49 (but you do not mention that in your question). I think, the second <code>ansible_ssh_common_args</code> in the hostvars of <code>bastion</code> is wrong.</p>
<p>You could have this vars...</p>
<pre><code>[bastions:vars]
ansible_ssh_common_args='-o StrictHostKeyChecking=no'
...

[jenkins:vars]
ansible_ssh_common_args: '-o StrictHostKeyChecking=no -o ProxyCommand=&quot;ssh -o StrictHostKeyChecking=no -W [%h]:%p -q ubuntu@10.1.0.49&quot;'
</code></pre>
<p>Also - just a notice - ignoring the host key is not very &quot;secure&quot; - especially when you use a bastion host (which is more or less a man-in-the-middle which you need to trust).</p>
",17486,2021-02-01T10:30:24.003,"['[bastions:vars]\nansible_ssh_common_args=\'-o StrictHostKeyChecking=no\'\n...\n\n[jenkins:vars]\nansible_ssh_common_args: \'-o StrictHostKeyChecking=no -o ProxyCommand=""ssh -o StrictHostKeyChecking=no -W [%h]:%p -q ubuntu@10.1.0.49""\'\n']"
1592,13277,13262,CC BY-SA 4.0,2021-02-02T19:46:11.830,"<p>If you want to use a database, you can always shell out to a database:</p>
<pre><code>sh &quot;mysql -u my_username -p my_password -h my_hostname -P 3306 -e \'INSERT INTO my_table (column1, column2, ...) VALUES (value1, value3, ...);\'  my_database&quot;
</code></pre>
<p>You can also write out your data to a JSON or YAML or whatever type of file and then store it in Jenkins' built-in artifact storage with <a href=""https://www.jenkins.io/doc/pipeline/steps/core/#archiveartifacts-archive-the-artifacts"" rel=""nofollow noreferrer"">archiveArtifacts</a>.</p>
",4115,2021-02-02T19:46:11.830,"['sh ""mysql -u my_username -p my_password -h my_hostname -P 3306 -e \\\'INSERT INTO my_table (column1, column2, ...) VALUES (value1, value3, ...);\\\'  my_database""\n']"
1593,13297,13269,CC BY-SA 4.0,2021-02-05T14:22:17.880,"<p>I think it should be:</p>
<pre><code>children:
    docker:
      hosts:
        01-dev:
        02-dev:
</code></pre>
<p>(The colon)</p>
",25953,2021-02-05T14:22:17.880,['children:\n    docker:\n      hosts:\n        01-dev:\n        02-dev:\n']
1594,13309,13301,CC BY-SA 4.0,2021-02-06T03:57:51.697,"<p>If you just want to print a subset of the results of your commands on your terminal without using one or more <code>-v</code> flags, you can refactor your playbook to show just the standard output from each of the commands using a JSON query. For example:</p>
<pre class=""lang-yaml prettyprint-override""><code>---
- name: display info
  hosts: localhost
  tasks:
  - name: Display uptime and kernel info
    shell: &quot;{{ item }}&quot;
    with_items:
      - uptime
      - uname -n
      - uname -r
    register: output

  - debug: msg=&quot;{{ output.results | json_query('[].stdout[]') }}&quot;
</code></pre>
<p>This will yield output similar to the following:</p>
<pre><code>PLAY [display info] **********************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [localhost]

TASK [Display uptime and kernel info] ****************************************************************
changed: [localhost] =&gt; (item=uptime)
changed: [localhost] =&gt; (item=uname -n)
changed: [localhost] =&gt; (item=uname -r)

TASK [debug] *****************************************************************************************
ok: [localhost] =&gt; {
    &quot;msg&quot;: [
        &quot;22:48  up 4 days,  3:41, 2 users, load averages: 1.26 1.39 1.42&quot;,
        &quot;localhost.local&quot;,
        &quot;20.3.0&quot;
    ]
}

PLAY RECAP *******************************************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
</code></pre>
",549,2021-02-06T03:57:51.697,"['---\n- name: display info\n  hosts: localhost\n  tasks:\n  - name: Display uptime and kernel info\n    shell: ""{{ item }}""\n    with_items:\n      - uptime\n      - uname -n\n      - uname -r\n    register: output\n\n  - debug: msg=""{{ output.results | json_query(\'[].stdout[]\') }}""\n', 'PLAY [display info] **********************************************************************************\n\nTASK [Gathering Facts] *******************************************************************************\nok: [localhost]\n\nTASK [Display uptime and kernel info] ****************************************************************\nchanged: [localhost] => (item=uptime)\nchanged: [localhost] => (item=uname -n)\nchanged: [localhost] => (item=uname -r)\n\nTASK [debug] *****************************************************************************************\nok: [localhost] => {\n    ""msg"": [\n        ""22:48  up 4 days,  3:41, 2 users, load averages: 1.26 1.39 1.42"",\n        ""localhost.local"",\n        ""20.3.0""\n    ]\n}\n\nPLAY RECAP *******************************************************************************************\nlocalhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n']"
1595,13322,4312,CC BY-SA 4.0,2021-02-06T19:38:59.417,"<p>Utilizing the <a href=""https://www.packer.io/docs/from-1.5"" rel=""nofollow noreferrer"">HCL2</a> syntax is definitely the correct approach here. You can use the different building <a href=""https://www.packer.io/docs/from-1.5/blocks"" rel=""nofollow noreferrer"">blocks</a> to define different source blocks and then assign sources to the builders and even conditionally execute the provisioners and <a href=""https://www.packer.io/docs/from-1.5/blocks/build/post-processors"" rel=""nofollow noreferrer"">post processors</a> on specific sources using <a href=""https://www.packer.io/docs/from-1.5/onlyexcept"" rel=""nofollow noreferrer"">only/except</a>.</p>
<p>Using this approach you can easily accomplish what you are looking for. Here is a rough example adapted from the hashicorp documentation with multiple sources and ansible:</p>
<pre><code>source &quot;amazon-ebs&quot; &quot;first-example&quot; {
    ...
}
source &quot;amazon-ebs&quot; &quot;second-example&quot; {
    ...
}
build {
  name = &quot;my_build&quot;
  sources [
    &quot;source.amazon-ebs.first-example&quot;,&quot;source.amazon-ebs.second-example&quot;
  ]

# I run on both sources 
provisioner &quot;ansible&quot; {
        playbook_file = &quot;common.yml&quot;
  }

# Only runs on first example
provisioner &quot;ansible&quot; {
    only = [&quot;source.amazon-ebs.first-example&quot;]
    playbook_file = &quot;playbook-a.yml&quot;
  }

# Never runs on second example
provisioner &quot;ansible&quot; {
    except = [&quot;source.amazon-ebs.second-example&quot;]
    playbook_file = &quot;playbook-b.yml&quot;
  }
}
</code></pre>
<p>Depending on your source blocks and the builder being used, this opens up the ability to template multi-cloud, arch, distribution and purposed images from the same packer build command.</p>
",25974,2021-02-06T19:38:59.417,"['source ""amazon-ebs"" ""first-example"" {\n    ...\n}\nsource ""amazon-ebs"" ""second-example"" {\n    ...\n}\nbuild {\n  name = ""my_build""\n  sources [\n    ""source.amazon-ebs.first-example"",""source.amazon-ebs.second-example""\n  ]\n\n# I run on both sources \nprovisioner ""ansible"" {\n        playbook_file = ""common.yml""\n  }\n\n# Only runs on first example\nprovisioner ""ansible"" {\n    only = [""source.amazon-ebs.first-example""]\n    playbook_file = ""playbook-a.yml""\n  }\n\n# Never runs on second example\nprovisioner ""ansible"" {\n    except = [""source.amazon-ebs.second-example""]\n    playbook_file = ""playbook-b.yml""\n  }\n}\n']"
1596,13323,11719,CC BY-SA 4.0,2021-02-06T22:38:03.393,"<p>It looks like you are configuring two services, mysql and mysql-nodeport to use the same port. Without information to indicate otherwise im assuming this is a 1 node setup with rasbian. I personally dont have raspbian installed to test, but try something like this:</p>
<pre><code>---
apiVersion: v1
kind: Service
metadata:
  name: mysql
  labels:
    app: mysql
spec:
  type: NodePort
  selector:
    app: mysql
  ports:
  - port: 3306
    name: mysql
    targetPort: 3306
    nodePort: 30036
</code></pre>
<p>Per the kubernetes <a href=""https://kubernetes.io/docs/concepts/services-networking/service/"" rel=""nofollow noreferrer"">service</a> documentation:
<em>NodePort: Exposes the Service on each Node's IP at a static port (the NodePort). A ClusterIP Service, to which the NodePort Service routes, is automatically created. You'll be able to contact the NodePort Service, from outside the cluster, by requesting :</em></p>
<p>If you want your service available on the node port, try updating your service and deleting the other service definition.</p>
",25974,2021-02-06T22:38:03.393,['---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mysql\n  labels:\n    app: mysql\nspec:\n  type: NodePort\n  selector:\n    app: mysql\n  ports:\n  - port: 3306\n    name: mysql\n    targetPort: 3306\n    nodePort: 30036\n']
1597,13331,13330,CC BY-SA 4.0,2021-02-08T20:49:54.167,"<p>There are two main reasons for this issue to happen:</p>
<ol>
<li>Your dns are not exposed.</li>
<li>Your code is redirecting to a https address (and since you are working in your local machine, most likely you don't have a secure certificate)</li>
</ol>
<h2>CASE 1 - Exposing DNS</h2>
<p>On linux you can solve it like:</p>
<ul>
<li><p>minikube ip</p>
</li>
<li><p>vim /etc/hosts</p>
</li>
<li><p>Add the ip from the first step and the hostname you want to expose, and save the file.</p>
<pre><code># For example
192.168.39.70   elasticsearch-es-http
</code></pre>
</li>
</ul>
<p>No need to restart any service, it should work just like that. Add all the hostnames you need.</p>
<h2>CASE 2 - HTTPS on minikube</h2>
<p>If your problem is 2, then you have to find a way for you application to not use HTTPS while you are using minikube.</p>
",26006,2021-02-24T15:14:00.050,['# For example\n192.168.39.70   elasticsearch-es-http\n']
1598,13332,12927,CC BY-SA 4.0,2021-02-09T00:51:27.677,"<p>This afternoon I also struggled on this. I think I've understood it a little bit more so I'd like to share it. But I'm also new to Ansible Vault so what I say here may not be completely correct. I used [1] as my main source of learning.</p>
<h2>What May Have Confused You</h2>
<p>[1] says a <code>vault ID</code> has the pattern <code>label@source</code>. But the symbol <code>@</code> delivers the meaning of &quot;inside&quot;, &quot;at&quot;, or &quot;of&quot; which makes people think a vault ID <code>test@password_file</code> means a line inside the file <code>password_file</code> with the label <code>test</code>.</p>
<p><strong>But this is the gotcha</strong>: according to my test, the <strong>entire content</strong> in <code>password_file</code> is used as the password. In your example above, the password <strong>you think</strong> is &quot;my_test_pass&quot;; but the password <strong>Ansible Vault sees</strong> is <code>dev my_dev_pass\ntest my_test_pass\nprod my_prod_pass</code> (note the white spaces and the End-of-Lines).</p>
<p>Therefore, <code>test@file_path</code> does not select the line &quot;my_test_pass&quot;. It actually means the following:</p>
<ul>
<li>At <strong>encryption</strong>, it means &quot;use the entire content in <code>file_path</code> as the password to encrypt the given message and marks the result with the label <code>test</code>&quot;.</li>
<li>At <strong>decryption</strong>, it means &quot;use the entire content in <code>file_path</code> as the password to decrypt everything that is marked with the label <code>test</code>&quot;.</li>
</ul>
<h2>Using Multiple Password Files</h2>
<p>Therefore, if you want to use different password files, you need to do it this way:</p>
<ul>
<li>Create three files (I put them at different folders intentionally for demo): <code>~/pass_dev.txt</code>, <code>/tmp/pass_test.txt</code>, <code>./pass_prod.txt</code>.</li>
<li>Put the passwords into the correct files. Example: <code>my_dev_pass</code> into <code>pass_dev.txt</code>.</li>
<li>When you encrypt the file <code>my_dev_file.yml</code>, you have two options:
<ul>
<li>You can specify just one vault ID: <code>ansible-vault encrypt --vault-id dev@~/pass_dev.txt my_dev_file.yml</code></li>
<li>You can specify multiple vault IDs but must also use <code>--encrypt-valut-id</code> to tell <code>ansible-vault</code> which one should actually be used to encrypt the file: <code>ansible-vault encrypt --vault-id dev@~/pass_dev.txt test@/tmp/pass_test.txt prod@./pass_prod.txt --encrypt-vault-id dev my_dev_file.yml</code></li>
</ul>
</li>
</ul>
<p>When you need to decrypt some content, you may or may not know what password the content was encrypted with. In this case, you can pass in all the possible vault IDs: <code>ansible-vault decrypt dev@~/pass_dev.txt test@/tmp/pass_test.txt prod@./pass_prod.txt some_encrypted_file.yml</code>. And vault will automatically figure out which password to use. This is talked about <a href=""https://docs.ansible.com/ansible/latest/user_guide/vault.html#passing-multiple-vault-passwords"" rel=""nofollow noreferrer"">in this section of [1]</a>.</p>
<p>This also explains why the <code>label</code> part is only used as a hint. In fact, you can pass in the vault IDs with completely wrong labels:</p>
<pre><code>ansible-vault decrypt prod@~/pass_dev.txt dev@/tmp/pass_test.txt test@./pass_prod.txt some_encrypted_file.yml
</code></pre>
<p>And <code>ansible-vault</code> is still able to decrypt the file, because, essentially, <code>ansible-vault</code> uses the <code>label</code> as the hint to see which password should be tried first. If it doesn't succeed, it tries the other passwords.</p>
<p>But if you define the environment variable <code>ANSIBLE_VAULT_ID_MATCH</code>, <code>ansible-vault</code> will take the labels seriously and only try the passwords with matching labels, so the following will fail:</p>
<pre><code>ANSIBLE_VAULT_ID_MATCH=1 ansible-vault decrypt prod@~/pass_dev.txt dev@/tmp/pass_test.txt test@./pass_prod.txt some_encrypted_file.yml
</code></pre>
<h2>Other Things in Your Question</h2>
<p>I may not be completely correct in this part: I guess <code>ansible-vault</code> maintains an internal list of &quot;currently available vault IDs&quot;. If no <code>--vault-id</code> is present on the command line, the only available vault ID is <code>default</code>. When <code>--vault-id</code> arguments are given, the <code>default</code> is overridden by whatever is provided.</p>
<p>Therefore, when you encrypted the target file using a <code>--vault-password-file</code>, without any other <code>--vault-id</code>, the only available vault ID was <code>default</code>. But by providing <code>--encrypt-vault-id=test</code> you were asking <code>ansible-vault</code> to encrypt the target file using a vault ID of &quot;test&quot; which was not available, hence the error &quot;Did not find a match&quot;.</p>
<p>Later, when you provided <code>ansible-vault</code> with only <code>--vault-id abc@file_path</code> but asked it to encrypt the target file using <code>test</code>, <code>ansible-vault</code> still couldn't find the required vault ID, hence the error &quot;Did not find a match&quot; again.</p>
<p>You made the mistake because you thought <code>test@file_path</code> selects one password from all the available passwords in <code>file_path</code>, so by providing one password file, you thought you had provided multiple passwords. But that doesn't seem to be how <code>ansible-vault</code> works. You need to provide multiple password files (or, technically, multiple password sources which could also be prompts and scripts).</p>
<h2>References</h2>
<ul>
<li>[1] Ansible 2.10 (latest as of 2021-02-08) <a href=""https://docs.ansible.com/ansible/latest/user_guide/vault.html"" rel=""nofollow noreferrer"">Encrypting content with Ansible Vault</a></li>
</ul>
",23543,2021-02-09T00:51:27.677,"['ansible-vault decrypt prod@~/pass_dev.txt dev@/tmp/pass_test.txt test@./pass_prod.txt some_encrypted_file.yml\n', 'ANSIBLE_VAULT_ID_MATCH=1 ansible-vault decrypt prod@~/pass_dev.txt dev@/tmp/pass_test.txt test@./pass_prod.txt some_encrypted_file.yml\n']"
1599,13333,5620,CC BY-SA 4.0,2021-02-09T11:35:56.463,"<p>An elegant way is to use <strong>IFS environment variable</strong> (Internal Field Separator) to define a <em>delimiter</em> when assigning a string list to array.</p>
<pre class=""lang-bash prettyprint-override""><code>IFS=&quot;,&quot; SERVERS=($SERVERS) #BTW, no need to declare a new variable, just reassign

for SERVER in ${SERVERS[@]} 
do 
   echo $SERVER
done
</code></pre>
",23509,2021-02-09T11:42:28.840,"['IFS="","" SERVERS=($SERVERS) #BTW, no need to declare a new variable, just reassign\n\nfor SERVER in ${SERVERS[@]} \ndo \n   echo $SERVER\ndone\n']"
1600,13351,13334,CC BY-SA 4.0,2021-02-11T16:45:05.107,"<p>The thing I was looking for was <a href=""https://kubernetes.github.io/ingress-nginx/examples/auth/external-auth/"" rel=""nofollow noreferrer"">external-auth</a> in ingress-nginx. I created a simple service with nodejs which took over all the basic-auth logic. Then I used an external link to this service in k8s annotations for restricted resources.</p>
<p>annotation snippet:</p>
<pre><code>  annotations:
    nginx.ingress.kubernetes.io/auth-url: http://service-name.default.svc.cluster.local:3000/auth 
</code></pre>
",25822,2021-02-11T16:45:05.107,['  annotations:\n    nginx.ingress.kubernetes.io/auth-url: http://service-name.default.svc.cluster.local:3000/auth \n']
1601,13354,13353,CC BY-SA 4.0,2021-02-12T11:44:44.453,"<p>Your script works, just update the last content type to <code>application/json</code>:</p>
<pre><code>Invoke-RestMethod -Uri $adoTaskUri -ContentType &quot;application/json&quot; -Body $body -headers $adoHeader -Method POST
</code></pre>
<p>PATCH is used to update a team project: <a href=""https://docs.microsoft.com/en-us/rest/api/azure/devops/core/projects/update?view=azure-devops-rest-6.1"" rel=""nofollow noreferrer"">https://docs.microsoft.com/en-us/rest/api/azure/devops/core/projects/update?view=azure-devops-rest-6.1</a></p>
",6341,2021-02-12T11:44:44.453,"['Invoke-RestMethod -Uri $adoTaskUri -ContentType ""application/json"" -Body $body -headers $adoHeader -Method POST\n']"
1602,13362,13356,CC BY-SA 4.0,2021-02-13T14:26:34.273,"<p>Your listen 443 need to have ssl parameter to tell Nginx that all connections accepted on this port should work in SSL mode.</p>
<p>See example at <a href=""https://nginx.org/en/docs/http/configuring_https_servers.html#single_http_https_server"" rel=""nofollow noreferrer"">https://nginx.org/en/docs/http/configuring_https_servers.html#single_http_https_server</a></p>
<p>Shown here for convenience:</p>
<pre><code>server {
    listen              80;
    listen              443 ssl;
    server_name         www.example.com;
    ssl_certificate     www.example.com.crt;
    ssl_certificate_key www.example.com.key;
    ...
}
</code></pre>
",14815,2021-02-13T14:26:34.273,['server {\n    listen              80;\n    listen              443 ssl;\n    server_name         www.example.com;\n    ssl_certificate     www.example.com.crt;\n    ssl_certificate_key www.example.com.key;\n    ...\n}\n']
1603,13365,13357,CC BY-SA 4.0,2021-02-13T18:52:17.217,"<p>Yes, you can use the <a href=""https://docs.gitlab.com/ee/ci/yaml/#rules"" rel=""nofollow noreferrer"">rules</a> syntax. You can use this in combination with regex for commit message, <a href=""https://docs.gitlab.com/ee/ci/yaml/#common-if-clauses-for-rules"" rel=""nofollow noreferrer"">ci_pipeline_source</a> or any other available CI variables.</p>
<pre><code>
job1:
  script: 
    - do something on schedule only
  rules:
    - if: '&quot;$CI_PIPELINE_SOURCE&quot; == &quot;schedule&quot;'
      when: always

job2:
  script: 
    - runs on Merge request pipeline
  rules:
    - if: $CI_MERGE_REQUEST_ID
      when: always
    when: never

job2:
  script: 
    - runs on changes to anything in src directory or Dockerfile
  rules:
    - changes:
        - src/*
        - Dockerfile

</code></pre>
<p>Note you can also <a href=""https://docs.gitlab.com/ee/ci/yaml/includes.html"" rel=""nofollow noreferrer"">include</a> multiple CI templates in your gitlab-ci.yml. Additonally, you can include a CI template with <a href=""https://docs.gitlab.com/ee/ci/yaml/#hide-jobs"" rel=""nofollow noreferrer"">&quot;hidden&quot;</a> job templates that you can reference with <a href=""https://docs.gitlab.com/ee/ci/yaml/#extends"" rel=""nofollow noreferrer"">extends</a>:</p>
<pre><code># Include ci files 
include:
 - local: '/templates/.scheduled-job-template.yml' # CI template with hidden job (.scheduled_job) that runs on schedule
 - local: '/templates/.lint-and-validate.yml' # contains jobs for linting and validating project

job1:
  extends:
    - .scheduled_job
  rules:
    - if: '&quot;$CI_PIPELINE_SOURCE&quot; == &quot;schedule&quot;'
      when: always

job2:
  script: 
    - runs on Merge request pipeline
  rules:
    - if: $CI_MERGE_REQUEST_ID
      when: always
    when: never
</code></pre>
<p>In doing this you can compose the jobs/pipelines you want in its own yml file and then define the jobs using those templates in the gitlab-ci.yml, which will help keep things maintainable and clear if you are running numerous different pipeline/pipeline configurations from the same project.</p>
",25974,2021-02-13T18:57:48.467,"['\njob1:\n  script: \n    - do something on schedule only\n  rules:\n    - if: \'""$CI_PIPELINE_SOURCE"" == ""schedule""\'\n      when: always\n\njob2:\n  script: \n    - runs on Merge request pipeline\n  rules:\n    - if: $CI_MERGE_REQUEST_ID\n      when: always\n    when: never\n\njob2:\n  script: \n    - runs on changes to anything in src directory or Dockerfile\n  rules:\n    - changes:\n        - src/*\n        - Dockerfile\n\n', '# Include ci files \ninclude:\n - local: \'/templates/.scheduled-job-template.yml\' # CI template with hidden job (.scheduled_job) that runs on schedule\n - local: \'/templates/.lint-and-validate.yml\' # contains jobs for linting and validating project\n\njob1:\n  extends:\n    - .scheduled_job\n  rules:\n    - if: \'""$CI_PIPELINE_SOURCE"" == ""schedule""\'\n      when: always\n\njob2:\n  script: \n    - runs on Merge request pipeline\n  rules:\n    - if: $CI_MERGE_REQUEST_ID\n      when: always\n    when: never\n']"
1604,13366,13337,CC BY-SA 4.0,2021-02-13T19:21:13.823,"<p>I believe you should be able to reference the namespace name like so:</p>
<p><code>namespace_name      = azurerm_eventhub_namespace.eventhub[0].name</code></p>
<p>However, if the namespace_name field is a required parameter on the resources you are passing it to, you might run into other issues while you are trying to set enabled to false, as the resources depend on the output of the resource you are setting to count[0]. If you want them all to be conditional on the creation of the namespace, i would recommend continuing down your approach with the for_each over the local values.</p>
<p>If you need to the other resources to not be created unless the namespace is created you can create a condition on your local value like this (assuming map):</p>
<pre><code>locals{
    hub = var.enable_eh ? {foo = &quot;bar&quot;, baz = &quot;qux&quot;} : {}
}
</code></pre>
<p>The for_each will omit the resources that are empty.</p>
",25974,2021-02-13T19:21:13.823,"['locals{\n    hub = var.enable_eh ? {foo = ""bar"", baz = ""qux""} : {}\n}\n']"
1605,13375,13359,CC BY-SA 4.0,2021-02-16T17:33:57.160,"<p>Yes, but (to the best of my knowledge) you will have to use Scripted Pipeline within the shared library.  This means that the closure that you will pass to the shared library (in the below example, the closure is <code>sh 'run-tests'</code>) will also have to be Scripted.</p>
<p><code>Jenkinsfile</code>:</p>
<pre><code>pipeline {
    agent any
    stages {
        stage('Test') {
            steps {
                runOnServers {
                    sh 'run-tests'
                }
            }
        }
        stage('Release') {
            echo 'release'
        }
    }
}
</code></pre>
<p>In your shared library, a file named <code>vars/runOnServers.groovy</code>:</p>
<pre><code>def call(Closure closure) {
  parallel({
    SanJose: {
      node(&quot;test &amp;&amp; san-jose&quot;) {
        stage('SanJose') {
          closure()
        }
      } 
    },
    Dallas: {
      node('test dallas') {
        stage('Dallas') {
          closure()
        }
      } 
    } 
  } 
}
</code></pre>
",4115,2021-02-17T20:30:02.017,"[""pipeline {\n    agent any\n    stages {\n        stage('Test') {\n            steps {\n                runOnServers {\n                    sh 'run-tests'\n                }\n            }\n        }\n        stage('Release') {\n            echo 'release'\n        }\n    }\n}\n"", 'def call(Closure closure) {\n  parallel({\n    SanJose: {\n      node(""test && san-jose"") {\n        stage(\'SanJose\') {\n          closure()\n        }\n      } \n    },\n    Dallas: {\n      node(\'test dallas\') {\n        stage(\'Dallas\') {\n          closure()\n        }\n      } \n    } \n  } \n}\n']"
1606,13377,9216,CC BY-SA 4.0,2021-02-17T02:15:54.987,"<p>As you suggested, having a build artifact to save the current commit SHA for the build would be ideal. Subsequent runs of the same workflow can download the artifact using the <a href=""https://github.com/dawidd6/action-download-artifact"" rel=""nofollow noreferrer"">dawidd6/action-download-artifact</a> action, which allows downloading artifacts generated from another workflow run.</p>
<p>Snippet for uploading artifact:</p>
<pre class=""lang-yaml prettyprint-override""><code>- name: Upload artifacts
  uses: actions/upload-artifact@v2
  with:
    name: nightly-build
    path: ./COMMIT_SHA
</code></pre>
<p>Snippet for downloading the latest artifact from another workflow run:</p>
<pre class=""lang-yaml prettyprint-override""><code>- name: Download artifacts
  uses: dawidd6/action-download-artifact@v2
  with:
    workflow: nightly.yml
    name: nightly-build
    path: .
</code></pre>
",26140,2021-02-17T02:15:54.987,"['- name: Upload artifacts\n  uses: actions/upload-artifact@v2\n  with:\n    name: nightly-build\n    path: ./COMMIT_SHA\n', '- name: Download artifacts\n  uses: dawidd6/action-download-artifact@v2\n  with:\n    workflow: nightly.yml\n    name: nightly-build\n    path: .\n']"
1607,13380,13379,CC BY-SA 4.0,2021-02-17T20:39:30.287,"<p>I believe what you're asking is: &quot;Is there any way to create just one helm chart that can be used for all microservices in my application?&quot;. If so, then you can just use the values.yaml file to store all the values for your templates. This is not considered good practice, considering your template file needs to hold the information for each of your microservice deployments (and thus will become really difficult to manage), but it is possible.</p>
<p>One example: say you have two microservices, and you need one Helm chart that will create the template for both microservices. Generally, you would create separate templates for each service under the templates folder, and deploy each Helm chart for each service individually, but instead you could create multiple deployments in one template yaml file, like</p>
<pre><code># For service 1
apiVersion: apps/v1
type: Deployment
etc., etc... (stick in all values.yaml file values here for service 1)
---
# For service 2
apiVersion: apps/v1
type: Deployment
etc., etc... (stick in all values.yaml file values here for service 2)
</code></pre>
<p>In your values.yaml file, you would then just place in the values for each of your services, like</p>
<pre><code># Service 1 Keys/Values
foo: value
# Service 2 Keys/Values
bar: otherValue
</code></pre>
<p>So to answer your question, you can package all your services into one individual Helm chart using the above method, and Kubernetes will run each service as their own ReplicaSet as expected. However, when you have many services to manage, it can be tricky to manage the template YAML files and the values.yaml files when you put in values for all your services in one file, and so it's most likely not a good practice to do this.</p>
<p>This is just my understanding of Helm so far, as I'm still learning Helm myself. As such, I'm not 100% sure if this can be done, so you might want to double check with another person that this answer is actually correct.</p>
<p>EDIT: To summarize: like I mentioned above, in theory, it is possible to use one Helm chart per service. But in practice, it will be extremely messy later on to manage the values.yaml and the templates in the templates folder. So the answer would be, &quot;Yes in theory, but not recommended at all&quot;.</p>
",26155,2021-02-17T21:20:25.863,"['# For service 1\napiVersion: apps/v1\ntype: Deployment\netc., etc... (stick in all values.yaml file values here for service 1)\n---\n# For service 2\napiVersion: apps/v1\ntype: Deployment\netc., etc... (stick in all values.yaml file values here for service 2)\n', '# Service 1 Keys/Values\nfoo: value\n# Service 2 Keys/Values\nbar: otherValue\n']"
1608,13381,13379,CC BY-SA 4.0,2021-02-17T21:26:40.637,"<p>Generally, a Helm chart would cover all your microservices - ideally, you should be able to deploy whole application in one chart. It may get a little messy if you include external 3rd party dependencies, where you would need to handle dependent charts, but I assume this is out of scope of your question.</p>
<p>More so, if your microservices are very similar you could write for loops, such as:</p>
<pre><code>{{- range $index, $service := .Values.myservices}}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-{{ $service.name }}
# --- etc ---
{{- end }}
</code></pre>
<p>Now, where to put your chart - in most cases a preferred way is to have a separate repo for all Ops CD files, including Helm chart - so this is where Helm chart would live. This is not to be mixed with CI files, such as Dockerfile - those should live alongside microservice repositories themselves.</p>
",19963,2021-02-17T21:26:40.637,"['{{- range $index, $service := .Values.myservices}}\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-{{ $service.name }}\n# --- etc ---\n{{- end }}\n']"
1609,13385,8780,CC BY-SA 4.0,2021-02-18T15:20:20.697,"<p>Did you try</p>
<pre><code>docker inspect TAG
</code></pre>
<p>Also try the manual binary search method in the answer by Timmay to Server Fault StackExchange question <a href=""https://serverfault.com/questions/747807/how-to-debug-docker-cache-invalidation"">&quot;How to debug Docker cache invalidation?&quot;</a></p>
",26167,2021-02-18T15:20:20.697,['docker inspect TAG\n']
1610,13390,13383,CC BY-SA 4.0,2021-02-19T11:48:20.537,"<p>With a bit trial and error I was able to work out the values for my &quot;vnet_id&quot; and &quot;snet_id&quot; variables.</p>
<p>I found using the full ID for the virtual network and not having a &quot;/&quot; before the subnet variable (snet_id) value fixed my problem.</p>
<p>At the moment I don't fully understand how Ansible/Azure puts it all together, but this has given me enough information to start to understand.</p>
<p>If anyone could point me to some documentation that explains the construction/interpolation of the variables it would be helpful.</p>
<pre><code>  tasks:
   - set_fact:
       vnet_rg_id: &quot;/subscriptions/REVMOVED-SUB-ID/resourceGroups/rg-ansible-test&quot;
       vnet_id: &quot;/subscriptions/REVMOVED-SUB-ID/resourceGroups/rg-ansible-test/providers/Microsoft.Network/virtualNetworks/vnet-ansible-test&quot;
       snet_id: &quot;snet-ansible-test&quot;

   - name: Create resource group
     azure_rm_resourcegroup:
       name: &quot;{{ rg }}&quot; # declared earlier in the playbook
       location: &quot;{{ location }}&quot; # declared earlier in the playbook

   - name: Create virtual network inteface cards for VM
     azure_rm_networkinterface:
       resource_group: &quot;{{ rg }}&quot; # declared earlier in the playbook
       name: &quot;{{ nic_name }}&quot; # declared earlier in the playbook
       virtual_network: &quot;{{ vnet_id }}&quot;
       subnet: &quot;{{ snet_id }}&quot;
       location: &quot;{{ location }}&quot; # declared earlier in the playbook
</code></pre>
",26163,2021-02-19T11:48:20.537,"['  tasks:\n   - set_fact:\n       vnet_rg_id: ""/subscriptions/REVMOVED-SUB-ID/resourceGroups/rg-ansible-test""\n       vnet_id: ""/subscriptions/REVMOVED-SUB-ID/resourceGroups/rg-ansible-test/providers/Microsoft.Network/virtualNetworks/vnet-ansible-test""\n       snet_id: ""snet-ansible-test""\n\n   - name: Create resource group\n     azure_rm_resourcegroup:\n       name: ""{{ rg }}"" # declared earlier in the playbook\n       location: ""{{ location }}"" # declared earlier in the playbook\n\n   - name: Create virtual network inteface cards for VM\n     azure_rm_networkinterface:\n       resource_group: ""{{ rg }}"" # declared earlier in the playbook\n       name: ""{{ nic_name }}"" # declared earlier in the playbook\n       virtual_network: ""{{ vnet_id }}""\n       subnet: ""{{ snet_id }}""\n       location: ""{{ location }}"" # declared earlier in the playbook\n']"
1611,13395,13391,CC BY-SA 4.0,2021-02-19T20:07:15.023,"<p>Yep this worked, or at least I didn't get an error</p>
<pre><code>    $ eksctl create cluster --alb-ingress-access -f config.yaml
</code></pre>
",24678,2021-02-19T20:07:15.023,['    $ eksctl create cluster --alb-ingress-access -f config.yaml\n']
1612,13405,1537,CC BY-SA 4.0,2021-02-22T04:44:09.393,"<p>I used the Groovy script console to obtain it this way:</p>
<pre><code>def executables = Jenkins.instance.computers.collect {c -&gt; c.executors}.
def runs = Jenkins.instance.computers.collect {c -&gt; c.executors}.
   flatten().
  findAll { executor -&gt; executor.isBusy() }.
  collect { executor -&gt; executor.getCurrentExecutable() }.
    collect { executable -&gt; &quot;${executable.displayName}: ${executable.number}&quot; }
</code></pre>
<p>or if you want the <code>Build</code> class, this:</p>
<pre><code>Jenkins.instance.computers.collect {c -&gt; c.executors}.
  flatten().
  findAll { executor -&gt; executor.isBusy() }.
  collect { executor -&gt;
    def u = executor.currentExecutable.url
    def n = executor.currentExecutable.number
    def job_qual_name = u.split('/')[0..-2].findAll { it != 'job' }.join('/')
    def job = Jenkins.instance.getItemByFullName(job_qual_name, Job.class)
    job.getBuildByNumber(build.number)
  }
</code></pre>
<p>It's pretty painful that Jenkins doesn't provide something as simple as this with a clear, high-level API.</p>
<p>It's extra ugly that the paths used by the folders plugin jobs don't work with <code>Jenkins.getItemByFullName()</code> without munging. Ick. Also that <code>Jenkins.getItemByFullName()</code> doesn't seem to support getting a <code>Build</code>.</p>
<p>You won't want to put this in Pipeline code. Instead put it in your script library so it isn't subject to method authorization issues, and only returns the final results.</p>
",26211,2021-02-22T06:46:15.953,"['def executables = Jenkins.instance.computers.collect {c -> c.executors}.\ndef runs = Jenkins.instance.computers.collect {c -> c.executors}.\n   flatten().\n  findAll { executor -> executor.isBusy() }.\n  collect { executor -> executor.getCurrentExecutable() }.\n    collect { executable -> ""${executable.displayName}: ${executable.number}"" }\n', ""Jenkins.instance.computers.collect {c -> c.executors}.\n  flatten().\n  findAll { executor -> executor.isBusy() }.\n  collect { executor ->\n    def u = executor.currentExecutable.url\n    def n = executor.currentExecutable.number\n    def job_qual_name = u.split('/')[0..-2].findAll { it != 'job' }.join('/')\n    def job = Jenkins.instance.getItemByFullName(job_qual_name, Job.class)\n    job.getBuildByNumber(build.number)\n  }\n""]"
1613,13409,13321,CC BY-SA 4.0,2021-02-22T20:19:59.550,"<p>Helm charts should not be built for a specific environment, IMHO. You can see that many of the official helm charts have a set of default values and they are configurable from outside. You also can create a helm chart like that and declare your deployment + environment-specific values with another tool like <a href=""https://github.com/fluxcd/helm-operator"" rel=""nofollow noreferrer"">Helm Operator</a> or <a href=""https://argoproj.github.io/argo-cd/"" rel=""nofollow noreferrer"">ArgoCD</a>. In this way, you can both simplify your build pipeline and increase <a href=""https://12factor.net/dev-prod-parity"" rel=""nofollow noreferrer"">dev/prod parity</a>. You can use that one chart and <strong>promote</strong> the same build into different environments so you can be sure that different environments are identical except the configuration.</p>
<p>Example ArgoCD application manifests:</p>
<p><strong>production-application.yaml:</strong></p>
<pre><code>apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: production-yourservice
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/yourorganisation/helm-charts
    path: yourservice
    targetRevision: master
    helm:
      values: |
        environment: production
        replicas: 10
  destination:
    server: https://kubernetes.default.svc
    namespace: production-yourservice
</code></pre>
<p><strong>staging-application.yaml:</strong></p>
<pre><code>apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: staging-yourservice
  namespace: argocd
spec:
  project: default
  source:
    repoURL: https://github.com/yourorganisation/helm-charts
    path: yourservice
    targetRevision: master
    helm:
      values: |
        environment: staging
        replicas: 1
  destination:
    server: https://kubernetes.default.svc
    namespace: staging-yourservice
</code></pre>
",26236,2021-02-22T20:19:59.550,"['apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: production-yourservice\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/yourorganisation/helm-charts\n    path: yourservice\n    targetRevision: master\n    helm:\n      values: |\n        environment: production\n        replicas: 10\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: production-yourservice\n', 'apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: staging-yourservice\n  namespace: argocd\nspec:\n  project: default\n  source:\n    repoURL: https://github.com/yourorganisation/helm-charts\n    path: yourservice\n    targetRevision: master\n    helm:\n      values: |\n        environment: staging\n        replicas: 1\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: staging-yourservice\n']"
1614,13410,13059,CC BY-SA 4.0,2021-02-22T20:49:14.263,"<p>Your <code>/etc/resolve.conf</code> should include <code>search &lt;currentnamespace&gt;.svc.cluster.local svc.cluster.local cluster.local</code> to discover hostnames that aren't FQDN.</p>
<p>As an example, this is the content of my pod's <code>/etc/resolve.conf</code>:</p>
<pre><code>nameserver 10.100.0.10
search staging.svc.cluster.local svc.cluster.local cluster.local eu-west-1.compute.internal
</code></pre>
<p>With this configuration, DNS resolution works like this:</p>
<ol>
<li>Is the hostname a fully qualified domain name (FQDN)? (In other words, does it end with a dot, like &quot;google.com.&quot;)</li>
<li>If it's an FQDN, query nameserver (<code>10.100.0.10</code>) for the hostname.</li>
<li>If it's not an FQDN, then append the <strong>1st</strong> element of the config <strong>search</strong> to the hostname. <code>svcname</code> -&gt; <code>svcname.staging.svc.cluster.local</code> and query the nameserver.</li>
<li>If no results found, try to append the <strong>2nd</strong> element of the config <strong>search</strong> to the hostname and query the nameserver.</li>
<li>...</li>
</ol>
<p>You want to resolve the hostname <code>svcname</code> but its FQDN is <code>svcname.&lt;namespace&gt;.svc.cluster.local.</code> and you need that <strong>search</strong> configuration to convert it to FQDN.</p>
",26236,2021-02-22T20:49:14.263,['nameserver 10.100.0.10\nsearch staging.svc.cluster.local svc.cluster.local cluster.local eu-west-1.compute.internal\n']
1615,13415,13400,CC BY-SA 4.0,2021-02-23T17:53:53.637,"<blockquote>
<p>Is there an 'UpstreamCause' equivalent to the example for 'UserIdCause' that would allow me to specify which upstream cause should trigger a specific stage?</p>
</blockquote>
<p>Unfortunately, not in native Declarative syntax.</p>
<p>As you can see <a href=""https://github.com/jenkinsci/pipeline-model-definition-plugin/blob/c07035710d1996ff570f1cdb86d6a20d8a2702f7/pipeline-model-definition/src/main/groovy/org/jenkinsci/plugins/pipeline/modeldefinition/Utils.groovy#L277-L291"" rel=""nofollow noreferrer"">from the source code</a>, UserIdCause is special-cased, but no other cause is:</p>
<pre><code>    static boolean shouldRunBeAllowed(Cause causeClass, String cause, String detail){
        if( causeClass instanceof Cause.UserIdCause &amp;&amp; Cause.UserIdCause.simpleName == cause){
            return detail == null || causeClass.userId == detail
        }else {
            return causeClass.class.simpleName.matches(&quot;(?i)\\.*${cause}.*&quot;)
        }
    }
</code></pre>
<p>So if you want to trigger conditionally based on which job triggered the build, you'll need to use Scripted syntax. For instance (I haven't tested this so no guarantees it will work without debugging):</p>
<pre><code>script {
  def myJob = 'put-your-job-name-here'
  def causes = currentBuild.rawBuild.getCauses()
  def triggeredByMyJob = causes.any { cause-&gt;
    cause.class.toString().contains(&quot;UpstreamCause&quot;)) &amp;&amp; cause.upstreamProject == myJob
  }

  if (triggeredByMyJob) {
    // put steps to execute when triggered by your job here
  } else {
    // put steps to execute when NOT triggered by your job here
  }
} 
</code></pre>
<p>However, there's potentially a much easier way, although it's not strictly what you asked for:  Give your downstream job a boolean parameter, for the sake of example let's call it <code>runMyStages</code>, and use a <code>when</code> clause to conditionally execute stages based on whether <code>runMyStages</code> is true or false.  Then in your upstream jobs, you can set that parameter in your build step: <code>build(job: 'downstream-job-name', parameters: [booleanParam('runMyStages', false)])</code>.</p>
",4115,2021-02-23T17:53:53.637,"['    static boolean shouldRunBeAllowed(Cause causeClass, String cause, String detail){\n        if( causeClass instanceof Cause.UserIdCause && Cause.UserIdCause.simpleName == cause){\n            return detail == null || causeClass.userId == detail\n        }else {\n            return causeClass.class.simpleName.matches(""(?i)\\\\.*${cause}.*"")\n        }\n    }\n', 'script {\n  def myJob = \'put-your-job-name-here\'\n  def causes = currentBuild.rawBuild.getCauses()\n  def triggeredByMyJob = causes.any { cause->\n    cause.class.toString().contains(""UpstreamCause"")) && cause.upstreamProject == myJob\n  }\n\n  if (triggeredByMyJob) {\n    // put steps to execute when triggered by your job here\n  } else {\n    // put steps to execute when NOT triggered by your job here\n  }\n} \n']"
1616,13420,13418,CC BY-SA 4.0,2021-02-24T01:03:41.397,"<p>Put it inside the sh?</p>
<pre><code>withKubeConfig(...) {
  sh “””
    export ...
    kubectl ...
  “””
}
</code></pre>
",24678,2021-02-24T01:03:41.397,['withKubeConfig(...) {\n  sh “””\n    export ...\n    kubectl ...\n  “””\n}\n']
1617,13426,13419,CC BY-SA 4.0,2021-02-24T16:07:01.240,"<p><a href=""https://github.com/austinsonger/vulnscout/blob/main/build.sh#L81"" rel=""nofollow noreferrer"">Line 81 of build.sh</a> is trying to run python3.  But the problem is more fundamental because you aren't getting any of the earlier <code>echo</code>s or <code>apt-get</code> command's output.  I would try:</p>
<pre><code>chmod +x build.sh
./build.sh
</code></pre>
<p>to let the sh-bang line do its job.</p>
",739,2021-02-24T16:07:01.240,['chmod +x build.sh\n./build.sh\n']
1618,13434,13413,CC BY-SA 4.0,2021-02-25T14:15:30.473,"<p>We found out what was wrong. It was not an Azure issue. The problem was that we were deploying a bad ZIP file. The ZIP file was missing <em>web.config</em>, which meant that the web application could not start up.</p>
<p>We were zipping our published web application by having this in the CSPROJ file:</p>
<pre><code>&lt;Target Name=&quot;ZipOutputPath&quot; AfterTargets=&quot;Publish&quot;&gt;
  &lt;ZipDirectory SourceDirectory=&quot;$(OutputPath)\publish&quot; DestinationFile=&quot;$(MSBuildProjectDirectory)\kmswebapp.zip&quot; Overwrite=&quot;true&quot; /&gt;
&lt;/Target&gt;
</code></pre>
<p>This turned out not to work because the compiler does things in a different order than we expected. At the time when it generated the ZIP file, <em>web.config</em> was not generated yet, so <em>web.config</em> never got packed into the ZIP file. Hence Azure could not start the application.</p>
<p>When we deployed from our local machines, it worked because we didn't clean the publish directory before each run, so there would be a <em>web.config</em> left over from the previous run, and this old (but unchanged) <em>web.config</em> would get packed into the ZIP file and deployed to Azure, so Azure would know how to start the application.</p>
<p>We solved it by removing the above from our CSPROJ file and doing (roughly) this in our Jenkinsfile:</p>
<pre><code>powershell &quot;dotnet publish ./src/webapi/WebAPI.csproj&quot;
powershell &quot;if (!(Test-Path('${publishDirectoryPath}/web.config'))){throw 'We need web.config to exist in the publish directory'}&quot;
powershell &quot;Compress-Archive -Path '${publishDirectoryPath}/*' -DestinationPath './src/webapi/kmswebapp.zip' -Force&quot;
</code></pre>
<p>This generates a proper ZIP file including <em>web.config</em>, and Azure can now start our application so it can respond properly to requests.</p>
",26015,2021-02-25T14:15:30.473,"['<Target Name=""ZipOutputPath"" AfterTargets=""Publish"">\n  <ZipDirectory SourceDirectory=""$(OutputPath)\\publish"" DestinationFile=""$(MSBuildProjectDirectory)\\kmswebapp.zip"" Overwrite=""true"" />\n</Target>\n', 'powershell ""dotnet publish ./src/webapi/WebAPI.csproj""\npowershell ""if (!(Test-Path(\'${publishDirectoryPath}/web.config\'))){throw \'We need web.config to exist in the publish directory\'}""\npowershell ""Compress-Archive -Path \'${publishDirectoryPath}/*\' -DestinationPath \'./src/webapi/kmswebapp.zip\' -Force""\n']"
1619,13448,13428,CC BY-SA 4.0,2021-02-28T02:24:51.680,"<p>This turned out to be a problem with <strong><code>pip</code></strong> determining the correct dependency: for some reason it thought that the pandas requirement was for numpy&gt;=1.15</p>
<p>The error message</p>
<pre><code>ERROR: pandas 1.2.0 has requirement numpy&gt;=1.16.5 ...
</code></pre>
<p>was coming from pandas itself (upon <code>import</code>).</p>
<p>The fix is to upgrade to a <strong>newer version of <code>pip</code></strong> (inside the script running on travisCI).  The newer version of pip is able to corrently detect that pandas needs a newer version of numpy.</p>
<p>Just put <strong><code>pip install --upgrade pip</code></strong> near the top of the script.</p>
<p>Not sure why TravisCI doesn't just use the latest <code>pip</code> by default.</p>
<p>Reference: <a href=""https://travis-ci.community/t/11214"" rel=""nofollow noreferrer"">https://travis-ci.community/t/11214</a></p>
",26277,2021-02-28T02:24:51.680,['ERROR: pandas 1.2.0 has requirement numpy>=1.16.5 ...\n']
1620,13457,13446,CC BY-SA 4.0,2021-03-01T15:15:12.880,"<p>I would just have a base script that have the things in common for most of the platform like base_install.sh</p>
<p>Then I would have multiple dockerfiles that can use this base script, an example for your amd64 dockerfile DockerfileAMD64:</p>
<pre><code>FROM mybase64image

RUN ./base_install.sh
RUN apt-get install specific64things -y
</code></pre>
<p>and you can build it with:</p>
<pre><code>docker build -f DockerfileAMD64
</code></pre>
<p>That way you can version control these files without duplicating code between the dockerfiles.</p>
",26377,2021-03-01T15:21:11.370,"['FROM mybase64image\n\nRUN ./base_install.sh\nRUN apt-get install specific64things -y\n', 'docker build -f DockerfileAMD64\n']"
1621,13471,8755,CC BY-SA 4.0,2021-03-03T14:00:59.943,"<p>I think you can just include_vars at directory level with <code>dir</code></p>
<pre><code>tasks:
  - name: &quot;Read my pets from pets folder&quot;
    include_vars:
      dir: &quot;pets&quot;
      name: all_pets
</code></pre>
",26419,2021-03-03T14:00:59.943,"['tasks:\n  - name: ""Read my pets from pets folder""\n    include_vars:\n      dir: ""pets""\n      name: all_pets\n']"
1622,13478,13477,CC BY-SA 4.0,2021-03-04T01:21:57.227,"<p><a href=""https://www.terraform.io/docs/language/resources/provisioners/syntax.html#provisioners-are-a-last-resort"" rel=""nofollow noreferrer"">Terraform Provisioners are a last resort</a>, so I'd encourage you to think about other options first.</p>
<p>In this case, your example suggests that you're already using cloud-init and so if at all possible I'd suggest modifying that cloud-init configuration to include a request to install the package you want to install. If you are using the cloud-config YAML format then you can use the <a href=""https://cloudinit.readthedocs.io/en/latest/topics/modules.html#package-update-upgrade-install"" rel=""nofollow noreferrer"">Package Update Upgrade Install</a> module to get a similar effect to your <code>yum install</code> command line:</p>
<pre><code>packages:
 - coolprogram
</code></pre>
<hr />
<p>However, if you've eliminated all other options except provisioners then the typical way to use remote-exec with an EC2 instance is to pass one of the instance's own IP addresses as the hostname, which you can do by using the special <code>self</code> object in the <code>connection</code> block to refer to the attributes of the object that the provisioner is running against, like this:</p>
<pre><code>resource &quot;aws_instance&quot; &quot;example&quot; {
  ami           = &quot;ami-1234&quot;
  instance_type = &quot;t2.large&quot;
  key_name      = &quot;foobar&quot;
  user_data     = local.cloud_config_config

  connection {
    host = self.private_ip
  }

  provisioner &quot;remote-exec&quot; {
    inline = [&quot;sudo yum -y install coolprogram&quot;]
  }
}
</code></pre>
<p>The above example uses <code>self.private_ip</code>, which will work only if the host where you are running Terraform is running in or able to connect to the VPC where you're deploying this instance. Another option is to use <code>self.public_ip</code> to use the public IP address, but that will work only if your VPC has an Internet Gateway and your instance belongs to a security group that can accept incoming SSH connections from the internet.</p>
<p>In addition to supplying a suitable IP address, you'll also need to generate and assign an allowed SSH public key to the EC2 instance and provide the corresponding private key in the <code>connection</code> block, using the <code>private_key</code> argument. (Or one of the other authentication strategies that <a href=""https://www.terraform.io/docs/language/resources/provisioners/connection.html"" rel=""nofollow noreferrer"">a <code>connection</code> block</a> supports.)</p>
<p>These connection and authentication complexities are, as you hopefully saw in the Terraform documentation I linked earlier, one of the main reasons why provisioners are a last resort. Using cloud-init instead will avoid this because cloud-init runs automatically on system boot and retrieves the <code>user_data</code> string using a private API accessible from the instance's private network interface, and so it doesn't need any outside connectivity, to start any listening services, or to generate any new credentials.</p>
",2463,2021-03-04T01:21:57.227,"['packages:\n - coolprogram\n', 'resource ""aws_instance"" ""example"" {\n  ami           = ""ami-1234""\n  instance_type = ""t2.large""\n  key_name      = ""foobar""\n  user_data     = local.cloud_config_config\n\n  connection {\n    host = self.private_ip\n  }\n\n  provisioner ""remote-exec"" {\n    inline = [""sudo yum -y install coolprogram""]\n  }\n}\n']"
1623,13481,13480,CC BY-SA 4.0,2021-03-04T10:11:14.630,"<p>Q: <em>&quot;<strong>How could I get it to fall back to Ansible's default for keys that don't exist?</strong>&quot;</em></p>
<p>A: <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#making-variables-optional"" rel=""nofollow noreferrer"">Omit</a> such parameters, e.g.</p>
<pre class=""lang-yaml prettyprint-override""><code>    create_home: &quot;{{ item.create_home|default(omit) }}&quot;
</code></pre>
",7715,2021-03-04T10:11:14.630,"['    create_home: ""{{ item.create_home|default(omit) }}""\n']"
1624,13487,13477,CC BY-SA 4.0,2021-03-04T21:15:28.950,"<p>here is a complete example:</p>
<pre><code>resource &quot;aws_key_pair&quot; &quot;my_key&quot; {
 key_name   = &quot;my_key&quot;
 public_key = file(pathexpand(&quot;~/.ssh/id_rsa.pub&quot;))
}

resource &quot;aws_instance&quot; &quot;example&quot; {
  ami = my_ami
  instance_type = &quot;t2.micro&quot;
  key_name = aws_key_pair.my_key.key_name
  ebs_block_device {
    device_name = &quot;/dev/sda1&quot;
    volume_size = 50
  }
  provisioner &quot;remote-exec&quot; {
   inline = [&quot;my_command&quot;]
  }
  connection {
   host        = coalesce(self.public_ip, self.private_ip)
   agent       = true
   type        = &quot;ssh&quot;
   user        = &quot;My_user_name&quot;
   private_key = file(pathexpand(&quot;~/.ssh/id_rsa&quot;))
  }
}
</code></pre>
<p>so I assumed that you have your public and private key located in your home directory in <code>.ssh</code> otherwise you need to hard code the path. and you need to make sure that your IP is allowd in the AWS security group.</p>
",15739,2021-03-04T21:21:05.330,"['resource ""aws_key_pair"" ""my_key"" {\n key_name   = ""my_key""\n public_key = file(pathexpand(""~/.ssh/id_rsa.pub""))\n}\n\nresource ""aws_instance"" ""example"" {\n  ami = my_ami\n  instance_type = ""t2.micro""\n  key_name = aws_key_pair.my_key.key_name\n  ebs_block_device {\n    device_name = ""/dev/sda1""\n    volume_size = 50\n  }\n  provisioner ""remote-exec"" {\n   inline = [""my_command""]\n  }\n  connection {\n   host        = coalesce(self.public_ip, self.private_ip)\n   agent       = true\n   type        = ""ssh""\n   user        = ""My_user_name""\n   private_key = file(pathexpand(""~/.ssh/id_rsa""))\n  }\n}\n']"
1625,13506,9895,CC BY-SA 4.0,2021-03-08T23:28:54.763,"<p>I had this problem too, coming from github where you can usually resolve text file changes in browser.</p>
<p>On your local repo, you want to get the latest then reverse-merge, so in your case</p>
<pre><code>// Precursor to ensure your local is the same as origin
git pull master
git checkout feature/ENGA-2514
git pull feature/ENGA-2514 

// include all of the other branches changes into yours. 
git merge master 

// This is where you'll be able to resolve the conflicts locally 
// and commit the merge into feature/ENGA-2514

git push feature/ENGA-2514
</code></pre>
<p>Then your branch wont conflict with master in devops, since youve just merged master into your branch.</p>
",26509,2021-03-08T23:28:54.763,"[""// Precursor to ensure your local is the same as origin\ngit pull master\ngit checkout feature/ENGA-2514\ngit pull feature/ENGA-2514 \n\n// include all of the other branches changes into yours. \ngit merge master \n\n// This is where you'll be able to resolve the conflicts locally \n// and commit the merge into feature/ENGA-2514\n\ngit push feature/ENGA-2514\n""]"
1626,13508,13505,CC BY-SA 4.0,2021-03-09T17:08:39.287,"<p>I suspect this job name is the issue:</p>
<pre><code>build job: 'second_job_name'
</code></pre>
<p>In a Multibranch pipeline, there are typically folders in the job name.  For instance, if you have a Multibranch project named &quot;my_project&quot;, a repo in that project named &quot;my_repo&quot;, and a branch within that repo that you wish to build, let's say &quot;master&quot;, then your build command would look like:</p>
<pre><code>build job: 'my_project/my_repo/master'
</code></pre>
<p>If you only specify up to the project or repo level in your job name, but don't include the branch, instead of running a build for the branch, Jenkins will scan for updates to all branches within that project/repo, and build any new commits which it hasn't yet built.  This results in exactly the symptoms you described:</p>
<blockquote>
<p>The only time this setup works as expected, is when there are new commits to all 3 git repos. Then all 3 jobs are triggered sequentially without issues.</p>
</blockquote>
",4115,2021-03-09T17:08:39.287,"[""build job: 'second_job_name'\n"", ""build job: 'my_project/my_repo/master'\n""]"
1627,13528,13524,CC BY-SA 4.0,2021-03-11T20:02:08.193,"<p>Here is what I did, I create a Makefile that includes my own method of image creation,</p>
<pre><code>.PHONY: image clean image-release
image: image-release

image-release:
    cargo build --release
    buildah unshare ./image/distroless.sh release

clean:
    cargo -v clean
</code></pre>
<p>For this purpose the only thing that matters is the image created by <code>./image/distroless.sh</code> matches the action (<code>redhat-actions/push-to-registry</code>) in the following flow. We'll continue using the name <code>myAlpineImage</code> as in the question,</p>
<pre><code>name: Distroless Image Creation

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Download and create image.
      run: make image-release
    - name: Push To Registry
      uses: redhat-actions/push-to-registry@v2.1.1
      with:
        image: myAlpineImage
        tags: latest
        registry: ghcr.io/evancarroll/project
        username: evancarroll
        password: ${{ secrets.GHCR_TOKEN }}
</code></pre>
<p>You can see here we make the call to <code>make image-release</code> which calls the buildah script and makes the image rootless.</p>
<p>Then I added the secret for <code>GHCR_TOKEN</code> to my repo. The token is generated in the <a href=""https://github.com/settings/tokens"" rel=""nofollow noreferrer"">&quot;Settings / Developer settings / Personal access&quot; tokens on github.</a>.</p>
",18965,2021-03-11T20:02:08.193,"['.PHONY: image clean image-release\nimage: image-release\n\nimage-release:\n    cargo build --release\n    buildah unshare ./image/distroless.sh release\n\nclean:\n    cargo -v clean\n', 'name: Distroless Image Creation\n\non:\n  push:\n    branches: [ master ]\n  pull_request:\n    branches: [ master ]\n\nenv:\n  CARGO_TERM_COLOR: always\n\njobs:\n  build:\n\n    runs-on: ubuntu-latest\n\n    steps:\n    - uses: actions/checkout@v2\n    - name: Download and create image.\n      run: make image-release\n    - name: Push To Registry\n      uses: redhat-actions/push-to-registry@v2.1.1\n      with:\n        image: myAlpineImage\n        tags: latest\n        registry: ghcr.io/evancarroll/project\n        username: evancarroll\n        password: ${{ secrets.GHCR_TOKEN }}\n']"
1628,13530,12302,CC BY-SA 4.0,2021-03-12T00:40:03.073,"<blockquote>
<p>If this is not possible is there any other way without duplicating the 100GB for each jenkins job?</p>
</blockquote>
<p>To avoid frequent clones of the repository, you can put a single clone of the repository on-disk on your executor nodes outside of the normal workspace path.  Then, in your Jenkins job, you can cd to that directory with <a href=""https://www.jenkins.io/doc/pipeline/steps/workflow-basic-steps/#dir-change-current-directory"" rel=""nofollow noreferrer"">the dir step</a>, update the repo, and checkout the branch you want, e.g.:</p>
<pre><code>dir('/path/to/repo') {
  sh('git fetch --all')
  sh('git checkout origin/lineage-16.0')
  // your build steps here
}
</code></pre>
<p>However, this has the major drawback that the one repo will be shared across all of your jobs, which means you cannot run those jobs in parallel without risking corruption.  It sounds like running jobs in parallel was one of your requirements, so this may be a no-go.</p>
<p>You could probably get parallel builds to work by using a copy-on-write filesystem so that the repo appears to be in multiple independent directories but only actually has to be cloned once, but I've never tried something like this, so I can't say how well it would work.</p>
",4115,2021-03-12T00:40:03.073,"[""dir('/path/to/repo') {\n  sh('git fetch --all')\n  sh('git checkout origin/lineage-16.0')\n  // your build steps here\n}\n""]"
1629,13533,3290,CC BY-SA 4.0,2021-03-12T15:18:01.340,"<p>Even better check this out:</p>
<pre><code>aws ec2 describe-instances | jq '.Reservations[] | .Instances[] | {PrivateAddress: .PrivateIpAddress, Tags: .Tags, KeyName: .KeyName, Tags: .Tags, RunningState: .State, InstanceId: .InstanceId, SecurityGroups: .SecurityGroups}'
</code></pre>
<p>You don't need to know anything this way ... but you need to install <code>jq</code>, to chomp the JSON o/p just right.</p>
<p>A lot of the elements there could be removed I guess ... tags, key names, running state, etc.</p>
",26577,2021-03-12T20:40:01.037,"[""aws ec2 describe-instances | jq '.Reservations[] | .Instances[] | {PrivateAddress: .PrivateIpAddress, Tags: .Tags, KeyName: .KeyName, Tags: .Tags, RunningState: .State, InstanceId: .InstanceId, SecurityGroups: .SecurityGroups}'\n""]"
1630,13538,13531,CC BY-SA 4.0,2021-03-12T22:55:06.187,"<p>I was not able to find how to <em>hide</em> a stage, however I found one can skip it using <code>stageEnabled</code> [1].</p>
<p>It takes a Spring Language Expression like so:</p>
<pre class=""lang-json prettyprint-override""><code>{
  &quot;stageEnabled&quot;: {
    &quot;expression&quot;: &quot;false&quot;, // you can also use SpEL, e.g. ${someBoolean}
    &quot;type&quot;: &quot;expression&quot;
  },
  &quot;completeOtherBranchesThenFail&quot;: true,
  &quot;continuePipeline&quot;: false,
  &quot;failPipeline&quot;: false,
  &quot;parameters&quot;: {
    &quot;FOO&quot;: &quot;bar&quot;
  },
  &quot;type&quot;: &quot;jenkins&quot;
}
</code></pre>
<p>Or from the UI editor: <code>Execution Options</code> &gt; <code>Conditional on Expression</code> &gt; Enter <code>false</code> [2].</p>
<ol>
<li><a href=""https://docs.armory.io/docs/spinnaker-user-guides/using-dinghy/#stage-fields"" rel=""nofollow noreferrer"">https://docs.armory.io/docs/spinnaker-user-guides/using-dinghy/#stage-fields</a></li>
<li><a href=""https://spinnaker.io/guides/user/pipeline/expressions/#dynamically-skip-a-stage"" rel=""nofollow noreferrer"">https://spinnaker.io/guides/user/pipeline/expressions/#dynamically-skip-a-stage</a></li>
</ol>
",8616,2021-03-12T22:55:06.187,"['{\n  ""stageEnabled"": {\n    ""expression"": ""false"", // you can also use SpEL, e.g. ${someBoolean}\n    ""type"": ""expression""\n  },\n  ""completeOtherBranchesThenFail"": true,\n  ""continuePipeline"": false,\n  ""failPipeline"": false,\n  ""parameters"": {\n    ""FOO"": ""bar""\n  },\n  ""type"": ""jenkins""\n}\n']"
1631,13545,13544,CC BY-SA 4.0,2021-03-14T20:15:21.303,"<p>Don't nest moustaches. Once you're in a Jinja context, you should reference variables by name without any further delimiters.</p>
<p>Using standard attribute access syntax can be a lot easier to read than the <code>attr()</code> filter (and actually works for this situation, which <code>attr()</code> doesn't):</p>
<pre><code>- name: Debug jinja2
  ansible.builtin.debug:
    msg: &quot;{{ server_cert_info_result.ansible_module_results[server_ssl_certificate_name].arn }}&quot;
  tags: list_server_certificate_info
</code></pre>
",26597,2021-03-19T01:18:00.330,"['- name: Debug jinja2\n  ansible.builtin.debug:\n    msg: ""{{ server_cert_info_result.ansible_module_results[server_ssl_certificate_name].arn }}""\n  tags: list_server_certificate_info\n']"
1632,13546,13544,CC BY-SA 4.0,2021-03-14T20:15:58.273,"<p>I think you don't need to do anything special:</p>
<pre class=""lang-yaml prettyprint-override""><code>&quot;{{ server_cert_info_result.ansible_module_results[server_ssl_cert_name].arn }}&quot;
</code></pre>
",26598,2021-03-14T20:15:58.273,"['""{{ server_cert_info_result.ansible_module_results[server_ssl_cert_name].arn }}""\n']"
1633,13547,12608,CC BY-SA 4.0,2021-03-15T07:52:01.867,"<p>The <code>hostnames</code> parameter controls what the plugin uses as the host name. It accepts a list of attributes, and will use the first one that the instance has defined:</p>
<pre><code>hostnames:
  - private-dns-name
  - private-ip-address
</code></pre>
<p>You can also set the <code>ansible_host</code> variable using <code>compose</code>. This changes the connection target without modifying the inventory hostname:</p>
<pre><code>compose:
  # Note the underscores; this functionality uses the Ansible variable names instead of the raw AWS attributes.
  ansible_host: private_ip_address
</code></pre>
",26597,2021-03-15T07:52:01.867,"['hostnames:\n  - private-dns-name\n  - private-ip-address\n', 'compose:\n  # Note the underscores; this functionality uses the Ansible variable names instead of the raw AWS attributes.\n  ansible_host: private_ip_address\n']"
1634,13554,13542,CC BY-SA 4.0,2021-03-15T22:58:37.620,"<p>Managed to solve this by changing the <code>values.yaml</code> in the <code>loki-stack</code> helm chart to the following:</p>
<pre><code>promtail:
  enabled: true
  pipelineStages:
  - cri: {}
</code></pre>
<p>Enjoy.</p>
",24649,2021-03-15T22:58:37.620,['promtail:\n  enabled: true\n  pipelineStages:\n  - cri: {}\n']
1635,13560,2927,CC BY-SA 4.0,2021-03-16T15:29:07.490,"<p>A few years later this thread is still the first result in Google, but running Docker+Vagrant (<strong>with VirtualBox</strong>) on Windows isn't a challenge anymore. You can easily run them both, as described <a href=""https://kubut.medium.com/it-is-2021-running-docker-and-vagrant-parallel-on-windows-isnt-impossible-anymore-a8ea7de0536c"" rel=""nofollow noreferrer"">here</a></p>
<p>If for some reason you want to use Vagrant with VirtualBox as a provider you should update to VB 6.x - after that, you can run VirtualBox, Vagrant, and Docker at the same time. Just configure your VM to use Hyper-V as Paravirtualization Interface. You can do it by VirtualBox GUI (VM's Settings -&gt; System -&gt; Acceleration -&gt; Paravirtualization Interface) or by using Vagrantfile:</p>
<pre><code>Vagrant.configure(&quot;2&quot;) do |config|
  # your config (…)
  config.vm.provider &quot;virtualbox&quot; do |vb|
    vb.customize [
      &quot;modifyvm&quot;, :id,
       &quot; - paravirtprovider&quot;, &quot;hyperv&quot;
    ]
  end
  # your config (…)
end
</code></pre>
<p>This will work not only for Windows Enterprise/Pro/Edu but also for Home Edition (with WSL2 as Docker Backend). This solution shouldn't break your VirtualBox's machine, so you <strong>don't have to switch hypervisorlaunchtype</strong> over and over again.</p>
",26619,2021-03-16T18:30:40.093,"['Vagrant.configure(""2"") do |config|\n  # your config (…)\n  config.vm.provider ""virtualbox"" do |vb|\n    vb.customize [\n      ""modifyvm"", :id,\n       ""\u200a-\u200aparavirtprovider"", ""hyperv""\n    ]\n  end\n  # your config (…)\nend\n']"
1636,13568,13564,CC BY-SA 4.0,2021-03-17T16:20:59.863,"<p>Create the list in Jinja2 and convert it, e.g.</p>
<pre class=""lang-yaml prettyprint-override""><code>- hosts: localhost
  gather_facts: true
  tasks:
    - set_fact:
         ssh_listen_to: &quot;{{ _ssh_listen_to|from_yaml }}&quot;
      vars:
        _ssh_listen_to: |
          {% if ansible_default_ipv4.address is defined %}
          - {{ ansible_default_ipv4.address }}
          {% endif %}
          {% if ansible_default_ipv6.address is defined %}
          - {{ ansible_default_ipv6.address }}
          {% endif %}
    - debug:
        var: ssh_listen_to|type_debug
    - debug:
        var: ssh_listen_to
</code></pre>
<p>gives</p>
<pre class=""lang-yaml prettyprint-override""><code>TASK [debug] ********************************************************************
ok: [localhost] =&gt; 
  ssh_listen_to|type_debug: list

TASK [debug] ********************************************************************
ok: [localhost] =&gt; 
  ssh_listen_to:
  - 10.1.0.27
</code></pre>
<hr>
<p>If you put the name of the variables into the list, e.g.</p>
<pre class=""lang-yaml prettyprint-override""><code>    vars_addr:
      - default_ipv4
      - default_ipv6
</code></pre>
<p>the task below gives the same result</p>
<pre class=""lang-yaml prettyprint-override""><code>    - set_fact:
         ssh_listen_to: &quot;{{ vars_addr|
                            map('extract', ansible_facts, 'address')|
                            select('defined')|
                            list  }}&quot;
</code></pre>
",7715,2021-03-17T16:56:12.827,"['- hosts: localhost\n  gather_facts: true\n  tasks:\n    - set_fact:\n         ssh_listen_to: ""{{ _ssh_listen_to|from_yaml }}""\n      vars:\n        _ssh_listen_to: |\n          {% if ansible_default_ipv4.address is defined %}\n          - {{ ansible_default_ipv4.address }}\n          {% endif %}\n          {% if ansible_default_ipv6.address is defined %}\n          - {{ ansible_default_ipv6.address }}\n          {% endif %}\n    - debug:\n        var: ssh_listen_to|type_debug\n    - debug:\n        var: ssh_listen_to\n', 'TASK [debug] ********************************************************************\nok: [localhost] => \n  ssh_listen_to|type_debug: list\n\nTASK [debug] ********************************************************************\nok: [localhost] => \n  ssh_listen_to:\n  - 10.1.0.27\n', '    vars_addr:\n      - default_ipv4\n      - default_ipv6\n', '    - set_fact:\n         ssh_listen_to: ""{{ vars_addr|\n                            map(\'extract\', ansible_facts, \'address\')|\n                            select(\'defined\')|\n                            list  }}""\n']"
1637,13569,13564,CC BY-SA 4.0,2021-03-17T16:52:28.117,"<p>This doesn't answer the question directly, but I found that I could query the entire ansible facts dictionary as a json document using the <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters.html#selecting-json-data-json-queries"" rel=""nofollow noreferrer""><code>json_query</code> filter</a> and a <a href=""https://jmespath.org/tutorial.html"" rel=""nofollow noreferrer"">jmespath expression</a>.</p>
<p>For example, the following produces a list of all the ip addresses.</p>
<pre><code>ssh_listen_to: &quot;{{ ansible_facts | json_query('*.address') }}&quot;
</code></pre>
<p>You can make this safer by just taking the default ipv4 &amp; ipv6 addresses like so:</p>
<pre><code>ssh_listen_to: &quot;{{ ansible_facts | json_query('[@.default_ipv4, @.default_ipv6][].address') }}&quot;
</code></pre>
<p>And you can even further check the sanity of the options by <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_filters_ipaddr.html#filtering-lists"" rel=""nofollow noreferrer"">removing anything from the list that's not an IP address</a></p>
<pre><code>ssh_listen_to: &quot;{{ ansible_facts | json_query('[@.default_ipv4, @.default_ipv6][].address') | ansible.netcommon.ipaddr }}&quot;
</code></pre>
",22501,2021-03-18T09:21:48.097,"['ssh_listen_to: ""{{ ansible_facts | json_query(\'*.address\') }}""\n', 'ssh_listen_to: ""{{ ansible_facts | json_query(\'[@.default_ipv4, @.default_ipv6][].address\') }}""\n', 'ssh_listen_to: ""{{ ansible_facts | json_query(\'[@.default_ipv4, @.default_ipv6][].address\') | ansible.netcommon.ipaddr }}""\n']"
1638,13570,3980,CC BY-SA 4.0,2021-03-17T18:09:08.347,"<p>I have faced a similar error for my Gitlab runner deployment on the GKE cluster. As you can see from the error, something is wrong with our pods. Why shouldn't we go and check the pod status?</p>
<pre><code>kubectl describe pods -n namespace 
</code></pre>
<p>You will get a fair idea about what's the real issue behind the error “<em>Does not have minimum availability</em>”.</p>
<p>In my case, the node was unable to pull the image for my deployment from the google container registry (GCR). I checked the permission for the service account used for k8s-cluster to pull the images from GCR.</p>
<p>I provided the correct roles and then it worked. Roles:</p>
<ul>
<li>storage</li>
<li>object</li>
<li>viewer</li>
</ul>
",26659,2021-03-18T13:44:40.593,['kubectl describe pods -n namespace \n']
1639,13572,13564,CC BY-SA 4.0,2021-03-17T19:56:20.757,"<p>Use <code>select()</code> with the <code>defined</code> test.</p>
<pre><code>ssh_listen_to: &quot;{{ [ansible_facts.default_ipv4.address, ansible_facts.default_ipv6.address] | select('defined') | list }}&quot;
</code></pre>
<p>As for the linked post about matching dictionary keys in JMESPath, I wouldn't use JMESPath at all for that in Ansible. As I've grown more accustomed to Jinja I've found <code>json_query()</code> less and less necessary.</p>
<pre><code>ssh_listen_to: &quot;{{ ansible_facts | select('match', '.+_ipv[46]$') | map('extract', ansible_facts, 'address') | select('defined') | list }}&quot;
</code></pre>
<p><code>ansible_facts | select('match', '.+_ipv[46]$')</code> filters the keys using a regex. Iterating over a dictionary returns its keys, which are then matched against the provided regex.</p>
<p>Passing this filtered list of keys to <code>map('extract', ansible_facts, 'address')</code> extracts their values and looks up 'address' in each value. You could do this in two steps as <code>map('extract', ansible_facts) | map(attribute='address')</code>, if that makes things clearer.</p>
<p><code>select('defined')</code> gets rid of any undefined values, then <code>list</code> converts the generator returned from <code>select()</code> into a list (this generator unrolling happens automatically in ansible-base/ansible-core &gt;= 2.10, but a lot of people are still on Ansible 2.9.)</p>
",26597,2021-03-18T14:36:27.397,"['ssh_listen_to: ""{{ [ansible_facts.default_ipv4.address, ansible_facts.default_ipv6.address] | select(\'defined\') | list }}""\n', 'ssh_listen_to: ""{{ ansible_facts | select(\'match\', \'.+_ipv[46]$\') | map(\'extract\', ansible_facts, \'address\') | select(\'defined\') | list }}""\n']"
1640,13574,12813,CC BY-SA 4.0,2021-03-18T12:44:56.793,"<p>Do your instance groups have labels identifying the groups they belong to? If so, you can filter to them using the <code>-l</code>/<code>--selector</code> option, like so:</p>
<pre class=""lang-bash prettyprint-override""><code>kubectl top nodes --selector instance-group=group-1
</code></pre>
<p>This assumes that the label name is <code>instance-group</code> and the label value for the group you want to query is <code>group-1</code>.</p>
",26666,2021-03-18T12:44:56.793,['kubectl top nodes --selector instance-group=group-1\n']
1641,13579,13573,CC BY-SA 4.0,2021-03-19T06:15:30.903,"<p>Setup a Jenkins server. Please do code checkout using Jenkins. Jenkins supports parameterized build. you can pass selected parameter from Jenkins UI to linux bash.</p>
<p>Then use linux's cli command to fire terraform.Terraform supports several workspace. You can use same code for dev, test and prod.</p>
<p><code>terraform workspace new dev</code>
Use this command to create new workspace. After that , we can use this workspace name to your code. Below is the content of <code>local.tf</code></p>
<pre><code>locals {
  env = terraform.workspace
}
</code></pre>
<p>Like below use the same code for multiple env.</p>
<pre><code>resource &quot;aws_autoscaling_group&quot; &quot;asg&quot; {
  name = &quot;${local.env}-${local.project}-demo-asg&quot;
}
</code></pre>
<p>Moreover to save your state file securely , you can use s3 as backend.</p>
<pre><code>terraform {
  backend &quot;s3&quot; {
    bucket = &quot;tfstate-demo&quot;
    key = &quot;keyfiles&quot;
    region = &quot;ap-southeast-1&quot;
    dynamodb_table = &quot;tfstate-demo&quot;
  }
}
</code></pre>
<p>To separate backend and frontend service, use best practice of AWS. Create a public ALB for frontend and then move traffic to backend services via private ALB.</p>
<p>You can use Ansible as a configuration manager to build your server then create a AMI of that using packer. Later on, use the same AMI in ASG.</p>
",6308,2021-03-19T06:15:30.903,"['locals {\n  env = terraform.workspace\n}\n', 'resource ""aws_autoscaling_group"" ""asg"" {\n  name = ""${local.env}-${local.project}-demo-asg""\n}\n', 'terraform {\n  backend ""s3"" {\n    bucket = ""tfstate-demo""\n    key = ""keyfiles""\n    region = ""ap-southeast-1""\n    dynamodb_table = ""tfstate-demo""\n  }\n}\n']"
1642,13584,4447,CC BY-SA 4.0,2021-03-20T08:12:00.143,"<p>I stumbled upon a solution which I thought was quite elegant, and only requires you to build once:</p>
<p>Use LABEL feature in your multistage builds, and then after building, you can tag based on label.</p>
<p>Advantages:</p>
<ul>
<li>only pull together the build context once</li>
<li>fast command to tag after the build has been done</li>
</ul>
<p>The example was discussed in <a href=""https://forums.docker.com/t/tag-intermediate-build-stages-multi-stage-build/34795"" rel=""nofollow noreferrer"">https://forums.docker.com/t/tag-intermediate-build-stages-multi-stage-build/34795</a></p>
<blockquote>
<p>Using the LABEL command in my dockerfile I added a label to the build
stage I’m interested in, then filter for it later:</p>
<pre><code>FROM node as builder-stage
LABEL builder=true

FROM node as app-stage
LABEL builder=false
</code></pre>
<p>Now to filter, sort newest first, cut out the date, and take the top
row:</p>
<pre><code>docker images --filter “label=builder=true” --format ‘{{.CreatedAt}}\t{{.ID}}’ | sort -nr | head -n 1 | cut -f2
</code></pre>
<p>Note that it is important to remove the label in the next build stage.</p>
</blockquote>
<p>This approach works really well for me</p>
",26698,2021-03-20T08:12:00.143,"['FROM node as builder-stage\nLABEL builder=true\n\nFROM node as app-stage\nLABEL builder=false\n', 'docker images --filter “label=builder=true” --format ‘{{.CreatedAt}}\\t{{.ID}}’ | sort -nr | head -n 1 | cut -f2\n']"
1643,13585,4503,CC BY-SA 4.0,2021-03-20T08:40:58.023,"<p>If you want pure-play bash, then you're already doing the right thing, <code>curl</code>, and although you don't mention it, it's a good idea to use <code>jq</code> when using REST APIs for parsing results, just remember to request json.</p>
<p>If you can install extra tools, then you can install the vault cli itself. Personally, I never install anything except docker, so I'd run that in a container:</p>
<pre class=""lang-sh prettyprint-override""><code>$ alias vault=&quot;docker run -it --rm --cap-add IPC_LOCK vault&quot;
$ vault --version
Vault v1.5.3 (9fcd81405feb320390b9d71e15a691c3bc1daeef)
</code></pre>
<p>As I'm sure you know, the vault cli, just like <code>curl</code>, can return json from most of its commands, which you can pipe to <code>jq</code> (again) for parsing (which is a lot easier than using go-templates IMO).</p>
<p>However, having said that, I have a suspicion that maybe you're asking the wrong question. Getting a secret on your laptop isn't really what vault is for and maybe you're just writing the code on your laptop ready to deploy to a server somewhere in order to provide a secret to that server. If that's the case then doing this in bash may be the wrong approach due to the issue of initial trust.</p>
<p>If you need to get a secret from vault then you have to authenticate first and get a token that has the correct authority (policies) to access the secret you're interested in. Authentication requires some sort of credentials (jwt/username-password/etc.). How do you get those creds to your bash script? You can't commit them to git.</p>
<p>Perhaps you're provisioning an ec2 instance with user-data that contains the creds the script needs (or any other cloud or on-prem equiv. of this process). If that's the case, then you can work out how to provision the machine with the secret it needs instead of the creds to get the secret. This is of course much easier with containers and kubernetes, but you can do the same thing with VMs of various types. In AWS you can do it with Lambda. In Azure with Azure Functions. On-prem you can do it using VMWare. With this approach, you'd be pushing the secrets management function into the platform (shift-left if you like that vocab.), rather than making it a responsibility of your application layer.</p>
<p>Maybe this is going too far and you're just playing around and learning about vault, but you did ask for help with direction. But if it's more than that, you should look at things like SPIFFE and check out the patterns hashicorp has implemented with its K8S sidecar.</p>
",7513,2021-03-20T09:20:23.943,"['$ alias vault=""docker run -it --rm --cap-add IPC_LOCK vault""\n$ vault --version\nVault v1.5.3 (9fcd81405feb320390b9d71e15a691c3bc1daeef)\n']"
1644,13597,13586,CC BY-SA 4.0,2021-03-23T14:12:27.447,"<p>Do you have network constraints to create a new subnet or what is the reason?
if it's not useful at all, you can just map the port and open the firewall of your PC so that the other machines can see the application.</p>
<pre class=""lang-yaml prettyprint-override""><code>version: '3' 
services:
  nextclouddb:
    image: mariadb
    container_name: nextcloud-mariadb
    volumes:
      - /home/username/data/mysql:/var/lib/mysql
      - /etc/localtime:/etc/localtime:ro
    environment:
      - MYSQL_ROOT_PASSWORD=STONGPASSWORD
      - MYSQL_PASSWORD=ANOTHERSTONGPASSWORD
      - MYSQL_DATABASE=nextcloud
      - MYSQL_USER=nextcloud
    restart: unless-stopped
  
  nextcloudapp:
    image: nextcloud:latest
    container_name: nextcloud-app
    volumes:
      - /home/username/data/html:/var/www/html
      - /home/username/data/config:/var/www/html/config
      - /home/username/data/apps:/var/www/html/custom_apps
      - /home/username/data/data:/var/www/html/data
      - /home/username/data/themes:/var/www/html/themes
      - /etc/localtime:/etc/localtime:ro
    restart: unless-stopped
    ports:
      - 2287:80  
</code></pre>
",26731,2021-03-23T14:12:27.447,"[""version: '3' \nservices:\n  nextclouddb:\n    image: mariadb\n    container_name: nextcloud-mariadb\n    volumes:\n      - /home/username/data/mysql:/var/lib/mysql\n      - /etc/localtime:/etc/localtime:ro\n    environment:\n      - MYSQL_ROOT_PASSWORD=STONGPASSWORD\n      - MYSQL_PASSWORD=ANOTHERSTONGPASSWORD\n      - MYSQL_DATABASE=nextcloud\n      - MYSQL_USER=nextcloud\n    restart: unless-stopped\n  \n  nextcloudapp:\n    image: nextcloud:latest\n    container_name: nextcloud-app\n    volumes:\n      - /home/username/data/html:/var/www/html\n      - /home/username/data/config:/var/www/html/config\n      - /home/username/data/apps:/var/www/html/custom_apps\n      - /home/username/data/data:/var/www/html/data\n      - /home/username/data/themes:/var/www/html/themes\n      - /etc/localtime:/etc/localtime:ro\n    restart: unless-stopped\n    ports:\n      - 2287:80  \n""]"
1645,13598,4609,CC BY-SA 4.0,2021-03-23T20:38:04.973,"<p>Adding on @sysadmin1138's answer, to push the content of a folder to another folder while keeping the directory structure starting from the source folder, you can use:</p>
<pre><code>(cd source-folder &amp;&amp; jfrog rt upload --detailed-summary --flat=false --recursive ./ artifact-repo/target-folder/
</code></pre>
<p>The <code>--detailed-summary</code> will tell you the details of all the files uploaded.</p>
",26757,2021-03-23T20:38:04.973,['(cd source-folder && jfrog rt upload --detailed-summary --flat=false --recursive ./ artifact-repo/target-folder/\n']
1646,13604,11228,CC BY-SA 4.0,2021-03-25T06:46:33.997,"<p>It should be written as:</p>
<pre><code>output &quot;vpc_id&quot; {
  value = aws_vpc.production_vpc.id
}
</code></pre>
",26801,2021-03-25T08:07:08.083,"['output ""vpc_id"" {\n  value = aws_vpc.production_vpc.id\n}\n']"
1647,13610,13609,CC BY-SA 4.0,2021-03-26T08:00:29.373,"<p>It sounds like you want a <a href=""https://www.jenkins.io/doc/book/pipeline/syntax/#when"" rel=""nofollow noreferrer""><code>when</code></a> statement.</p>
<p>As I understand it, you want to execute stage B <strong>when</strong> you are on branch <code>update/jenkinsfile</code>. In order to do this, you need to add a condition to stage B:</p>
<pre class=""lang-java prettyprint-override""><code>pipeline {
    agent any
    stages {
        stage('A') {
            steps {
                sh 'echo &quot;Step A&quot;'
            }
        }
        stage('B') {
            when {
              branch 'update/jenkinsfile'
            }
            steps {
                sh 'echo &quot;Step B&quot;'
            }
        }
    }
}

</code></pre>
<p>Note that you also need your jenkins to discover this new branch - this will depend on how you have configured the job. The above assumes that you have a multibranch pipeline job which is configured to include that branch.</p>
",354,2021-03-26T08:00:29.373,"['pipeline {\n    agent any\n    stages {\n        stage(\'A\') {\n            steps {\n                sh \'echo ""Step A""\'\n            }\n        }\n        stage(\'B\') {\n            when {\n              branch \'update/jenkinsfile\'\n            }\n            steps {\n                sh \'echo ""Step B""\'\n            }\n        }\n    }\n}\n\n']"
1648,13617,7956,CC BY-SA 4.0,2021-03-26T18:01:14.430,"<p>Even though this is a year old...</p>
<p>If the containers important data isn't in a volume mount already, you could always try copying the important content out of the still running container and mount it into your more permanent container.</p>
<pre><code>docker cp &lt;container&gt;:/path/in/container /path/on/host
docker run -it -v /path/on/host:/path/in/container ....
</code></pre>
",26835,2021-03-26T18:01:14.430,['docker cp <container>:/path/in/container /path/on/host\ndocker run -it -v /path/on/host:/path/in/container ....\n']
1649,13621,13576,CC BY-SA 4.0,2021-03-27T07:35:36.767,"<p>If you're looking to access your database only from localhost, you can do something like that:</p>
<pre><code>    ports:
      - &quot;127.0.0.1:5432:5432&quot;
</code></pre>
",26840,2021-03-27T07:35:36.767,"['    ports:\n      - ""127.0.0.1:5432:5432""\n']"
1650,13625,13618,CC BY-SA 4.0,2021-03-27T18:17:22.063,"<p>No, you cannot nest jinja2 expansion i.e. the following <strong>won't work</strong>:</p>
<pre class=""lang-yaml prettyprint-override""><code># Warning ! Those will fail !
some_var: &quot;{{ some_dict[{{ some_dynamic_key }}] }}&quot;
other_var: &quot;{{ {{ dynamicaly_prefixed }}_var }}&quot;
# Did I forget to say the above examples will fail ?
</code></pre>
<p>But you can use your var without any problem, just as in almost any other programming language dealing with list and indexes. There is actually an <a href=""https://docs.ansible.com/ansible/latest/reference_appendices/faq.html#when-should-i-use-also-how-to-interpolate-variables-or-dynamic-variable-names"" rel=""nofollow noreferrer"">ansible FAQ entry on this particular subject</a></p>
<pre class=""lang-yaml prettyprint-override""><code>some_inventory_hostname: 192.168.0.162
node1_hostname: &quot;{{ hostvars[some_inventory_hostname].node1_hostname }}&quot;
</code></pre>
",13111,2021-03-28T22:49:41.547,"['# Warning ! Those will fail !\nsome_var: ""{{ some_dict[{{ some_dynamic_key }}] }}""\nother_var: ""{{ {{ dynamicaly_prefixed }}_var }}""\n# Did I forget to say the above examples will fail ?\n', 'some_inventory_hostname: 192.168.0.162\nnode1_hostname: ""{{ hostvars[some_inventory_hostname].node1_hostname }}""\n']"
1651,13628,13549,CC BY-SA 4.0,2021-03-28T23:49:46.087,"<blockquote>
<p>Order of execution is important Server (Task A) needs to run before the client (Task B)</p>
</blockquote>
<p>Then why are your running Task A async in that case ? Is it just because <code>iperf --server</code> is not falling in the background and dying as soon as the shell task finishes ? A quick look at the <a href=""https://iperf.fr/iperf-doc.php#3doc"" rel=""nofollow noreferrer"">documentation</a> shows we can probably work around that problem with something like:</p>
<pre class=""lang-bash prettyprint-override""><code>iperf3 --server --daemon --pidfile /path/to/iperf3.pid --logfile /path/to/log
</code></pre>
<p>Notes:</p>
<ul>
<li>I added the <code>logfile</code> option since I guess it can be useful but it is not mandatory for the current issue</li>
<li>I took for granted you are running the server on a linux platform. Running it on Windows would apparently slightly change the below scenario. See <a href=""https://iperf.fr/iperf-doc.php#service"" rel=""nofollow noreferrer"">Running as a service on windows</a></li>
</ul>
<p>From what I understand the last unsolved issue is running the client tasks sequentially on each client host. This can be done using the <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_strategies.html#rolling-update-batch-size"" rel=""nofollow noreferrer""><code>serial</code> keyword</a> on your play.</p>
<p>Here is an untested pseudo ansible setup summarizing what I understand from your requirements. Adapt to your real use-case.</p>
<p><strong><code>inventory/iperf_hosts.yml</code></strong></p>
<pre class=""lang-yaml prettyprint-override""><code>---
iperf_servers:
  vars:
    iperf_pid_file: /tmp/iperf.pid
    iperf_log_file: /tmp/iperf.log
  hosts:
    server1.local:
iperf_clients:
  vars:
    iperf_time: 1
    iperf_dest: some\win\directory
  hosts:
    host1.local:
    host2.local:
    host3.local:
</code></pre>
<p><strong><code>playbook.yml</code></strong></p>
<pre class=""lang-yaml prettyprint-override""><code>---
- name: Start the iperf server
  hosts: iperf_servers
  
  tasks:
    - name: Fire the start command
      command: &quot;iperf3 --server --daemon --pidfile {{ iperf_pid_file }} --logfile {{ iperf_log_file }}&quot;

- name: Launch clients one after the other.
  hosts: iperf_clients
  serial: 1
  
  tasks:
    - name: Run iperf3 client
      win_command: &quot;iperf3 -c {{ hostvars[group['iperf_servers'][0]].inventory_hostname }} -t {{ iperf_time }}&quot;
      args:
        chdir: &quot;{{ iperf_dest }}&quot;
      register: iperf3_out

    - debug:
        var: iperf3_out.stdout

- name: Now we are over with clients, kill the server
  hosts: iperf_servers
  # We already gathered facts at first play so we disable here
  # You might want to disable in all other plays if you don't need facts at all
  gather_facts: false

  tasks:
    - name: Slurp pid from file
      slurp:
        path: &quot;{{ iperf_pid_file }}&quot;
      register: slurped_pid

    - name: kill the iperf3 process
      command: &quot;kill {{ slurped_pid.content | b64decode }}&quot;
</code></pre>
",13111,2021-04-08T07:15:11.200,"['iperf3 --server --daemon --pidfile /path/to/iperf3.pid --logfile /path/to/log\n', '---\niperf_servers:\n  vars:\n    iperf_pid_file: /tmp/iperf.pid\n    iperf_log_file: /tmp/iperf.log\n  hosts:\n    server1.local:\niperf_clients:\n  vars:\n    iperf_time: 1\n    iperf_dest: some\\win\\directory\n  hosts:\n    host1.local:\n    host2.local:\n    host3.local:\n', '---\n- name: Start the iperf server\n  hosts: iperf_servers\n  \n  tasks:\n    - name: Fire the start command\n      command: ""iperf3 --server --daemon --pidfile {{ iperf_pid_file }} --logfile {{ iperf_log_file }}""\n\n- name: Launch clients one after the other.\n  hosts: iperf_clients\n  serial: 1\n  \n  tasks:\n    - name: Run iperf3 client\n      win_command: ""iperf3 -c {{ hostvars[group[\'iperf_servers\'][0]].inventory_hostname }} -t {{ iperf_time }}""\n      args:\n        chdir: ""{{ iperf_dest }}""\n      register: iperf3_out\n\n    - debug:\n        var: iperf3_out.stdout\n\n- name: Now we are over with clients, kill the server\n  hosts: iperf_servers\n  # We already gathered facts at first play so we disable here\n  # You might want to disable in all other plays if you don\'t need facts at all\n  gather_facts: false\n\n  tasks:\n    - name: Slurp pid from file\n      slurp:\n        path: ""{{ iperf_pid_file }}""\n      register: slurped_pid\n\n    - name: kill the iperf3 process\n      command: ""kill {{ slurped_pid.content | b64decode }}""\n']"
1652,13637,12964,CC BY-SA 4.0,2021-03-30T16:42:21.250,"<p>There is no built-in configuration/annotation to handle this.</p>
<p>Although, you can use the <a href=""https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#server-snippet"" rel=""nofollow noreferrer"">server-snippet</a> annotation to create a custom configuration that <a href=""http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_intercept_errors"" rel=""nofollow noreferrer"">intercepts</a> the error 503, proxying the request to a service that is serving your custom error page. Example:</p>
<pre><code>apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress
  annotations:
    kubernetes.io/ingress.class: &quot;nginx&quot;
    nginx.ingress.kubernetes.io/server-snippet: |
      proxy_intercept_errors on;
      error_page 503 = @errorpages;
      
      location @errorpages {
        proxy_set_header X-Code $status;
        proxy_pass http://errors-svc.default.svc.cluster.local;
      }
spec:
  rules:
  - host: ameba.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx
            port:
              number: 80
</code></pre>
",13139,2021-03-30T16:42:21.250,"['apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress\n  annotations:\n    kubernetes.io/ingress.class: ""nginx""\n    nginx.ingress.kubernetes.io/server-snippet: |\n      proxy_intercept_errors on;\n      error_page 503 = @errorpages;\n      \n      location @errorpages {\n        proxy_set_header X-Code $status;\n        proxy_pass http://errors-svc.default.svc.cluster.local;\n      }\nspec:\n  rules:\n  - host: ameba.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n']"
1653,13655,13650,CC BY-SA 4.0,2021-04-02T07:18:34.953,"<p>The default Dockerfile shell is <code>sh</code>. I don't think echo there has the <code>-e</code> modifier for backslash. Newline &amp; other special symbols will work by default. In your command, resulting <code>.my.cnf</code> would contain a litteral <code>-e</code>.</p>
<p>Remove <code>-e</code> <strong>or</strong> use the original command in Dockerfile in a different shell, for instance:</p>
<pre><code>RUN /bin/bash -c '&lt;your-command&gt;'
</code></pre>
",25529,2021-04-02T07:18:34.953,"[""RUN /bin/bash -c '<your-command>'\n""]"
1654,13661,13611,CC BY-SA 4.0,2021-04-04T05:57:07.707,"<p>Million dollar question - are you running your fluentD as a DaemonSet?  If not, there's a chance that fluentd simply isn't running on the node where some containers live.</p>
<p>Otherwise, my best guess is, it's missing permissions to read from all namespaces, especially since you mentioned you haven't attached a ServiceAccount to it.  If you used a public FluentD Helm chart such as <a href=""https://github.com/fluent/helm-charts"" rel=""nofollow noreferrer"">this one</a>, try making sure you're deploying it with rbac enabled, i.e.:</p>
<pre><code>rbac:
  create: true

serviceAccount:
  create: true
</code></pre>
<p>It'll also help if you post some logs from your fluentd container.</p>
",3175,2021-04-04T05:57:07.707,['rbac:\n  create: true\n\nserviceAccount:\n  create: true\n']
1655,13665,13663,CC BY-SA 4.0,2021-04-04T13:46:00.197,"<p>You can deploy docker on same host where you have k3s and then use same technique with docker sock via mounting volume. I.e. this is part of the spec we did for Jenkins on k3s:</p>
<pre><code>apiVersion: v1
kind: Pod
metadata:
  labels:
    run: jenkins-slave
spec:
  containers:
  - name: dind
    image: docker:19.03.12-dind
    command:
    - cat
    volumeMounts:
    - mountPath: /var/run/docker.sock
      name: dockersock
    tty: true
  volumes:
  - name: dockersock
    hostPath:
      path: /var/run/docker.sock
</code></pre>
",19963,2021-04-04T13:46:00.197,['apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: jenkins-slave\nspec:\n  containers:\n  - name: dind\n    image: docker:19.03.12-dind\n    command:\n    - cat\n    volumeMounts:\n    - mountPath: /var/run/docker.sock\n      name: dockersock\n    tty: true\n  volumes:\n  - name: dockersock\n    hostPath:\n      path: /var/run/docker.sock\n']
1656,13666,13649,CC BY-SA 4.0,2021-04-05T02:51:20.610,"<p>As per <a href=""https://cloud.google.com/compute/docs/troubleshooting/known-issues#keyexpired"" rel=""nofollow noreferrer"">compute/docs/troubleshooting/known-issues</a>:</p>
<blockquote>
<p>On Debian and Ubuntu based systems, including your local workstations,
you might encounter an error similar to the following example:
[...] The following signatures were invalid: XXXX [...]</p>
</blockquote>
<p>To resolve this error, get the latest valid <code>apt-key.gpg</code> key file from <code>https://packages.cloud.google.com</code> by running the following command:</p>
<pre><code>curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
</code></pre>
",13139,2021-04-05T02:51:20.610,['curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n']
1657,13670,13647,CC BY-SA 4.0,2021-04-05T15:39:57.663,"<p>withCredentials publish environment variables, and in sh to access the environment variables, you have to do it like this: &quot;${env.JOB_BASE_NAME}&quot;.</p>
<p>Try this:</p>
<pre><code>withCredentials([usernamePassword(credentialsId: params.git_credential, passwordVariable: 'DOCKER_PASSWORD', usernameVariable: 'DOCKER_USERNAME')]) {
   sh 'git reset --hard; git clone https://${env.DOCKER_USERNAME}:${env.DOCKER_PASSWORD}@repo_url/scm/${params.repository}.git --branch master'
}
</code></pre>
",26977,2021-04-05T15:39:57.663,"[""withCredentials([usernamePassword(credentialsId: params.git_credential, passwordVariable: 'DOCKER_PASSWORD', usernameVariable: 'DOCKER_USERNAME')]) {\n   sh 'git reset --hard; git clone https://${env.DOCKER_USERNAME}:${env.DOCKER_PASSWORD}@repo_url/scm/${params.repository}.git --branch master'\n}\n""]"
1658,13671,13663,CC BY-SA 4.0,2021-04-05T18:24:19.217,"<p>If you simply need to build a docker image, I recommend using <a href=""https://github.com/GoogleContainerTools/kaniko"" rel=""nofollow noreferrer"">Kaniko</a>. It allows you to build a docker image without having to expose the docker.sock or running your pods in privileged mode, which introduces potential security vulnerabilities. Per the Kaniko documentation, your spec file would look similar to:</p>
<pre><code>apiVersion: v1
kind: Pod
metadata:
  name: kaniko
spec:
  containers:
  - name: kaniko
    image: gcr.io/kaniko-project/executor:latest
    args:
    - &quot;--dockerfile=&lt;path to Dockerfile within the build context&gt;&quot;
  restartPolicy: Never
</code></pre>
",4328,2021-04-05T18:24:19.217,"['apiVersion: v1\nkind: Pod\nmetadata:\n  name: kaniko\nspec:\n  containers:\n  - name: kaniko\n    image: gcr.io/kaniko-project/executor:latest\n    args:\n    - ""--dockerfile=<path to Dockerfile within the build context>""\n  restartPolicy: Never\n']"
1659,13676,13652,CC BY-SA 4.0,2021-04-06T14:32:10.300,"<p>I found my fault.
It's necessary define a <code>cassandra.service</code> to Systemd manages Cassandra:</p>
<p><em>path</em>: <code>/etc/systemd/system/cassandra.service</code></p>
<p>And adjust like you installation</p>
<pre><code>[Unit]
Description=Cassandra Cluster Node Daemon

[Service]
Type=forking
User=cassandra
ExecStartPre=/usr/bin/echo &quot;Starting Cassandra Daemon&quot;
ExecStart=/usr/sbin/cassandra
ExecStartPost=/usr/bin/echo &quot;Cassandra Daemon Running&quot;

ExecStopPost=/usr/bin/rm -rf /cassandra/saved_caches;/usr/bin/echo &quot;Cassandra Daemon Stopped&quot;

SuccessExitStatus=143

[Install]
WantedBy=default.target
</code></pre>
",18637,2021-04-06T14:32:10.300,"['[Unit]\nDescription=Cassandra Cluster Node Daemon\n\n[Service]\nType=forking\nUser=cassandra\nExecStartPre=/usr/bin/echo ""Starting Cassandra Daemon""\nExecStart=/usr/sbin/cassandra\nExecStartPost=/usr/bin/echo ""Cassandra Daemon Running""\n\nExecStopPost=/usr/bin/rm -rf /cassandra/saved_caches;/usr/bin/echo ""Cassandra Daemon Stopped""\n\nSuccessExitStatus=143\n\n[Install]\nWantedBy=default.target\n']"
1660,13679,13678,CC BY-SA 4.0,2021-03-12T09:47:13.807,"<p>I figured out what was going on. The return from <code>hosts</code> var was a single string with comma separated hostnames <code>host1, host2</code>, I had to convert it to List  using the comma as delimiter. The following post <a href=""https://stackoverflow.com/questions/7488643/how-to-convert-comma-separated-string-to-list"">How to convert comma-separated String to List?</a> helped me with that task.</p>
<p>Basically the last section now reads</p>
<pre><code>                script: 
                &quot;&quot;&quot;
                List&lt;String&gt; list = Arrays.asList(hosts.split(&quot;\\\\s*,\\\\s*&quot;));
                return list
                &quot;&quot;&quot;
</code></pre>
",11271,2021-03-12T14:50:19.870,"['                script: \n                """"""\n                List<String> list = Arrays.asList(hosts.split(""\\\\\\\\s*,\\\\\\\\s*""));\n                return list\n                """"""\n']"
1661,13700,13680,CC BY-SA 4.0,2021-04-10T23:07:35.483,"<p>Your use case is very simple, so relying on <code>GIT_STRATEGY=fetch</code> is probably sufficient and as you said the default behavior.</p>
<p>You should be cautious using <a href=""https://docs.gitlab.com/ee/ci/yaml/README.html#artifacts"" rel=""nofollow noreferrer"">artifacts</a> unnecessarily as they are uploaded to the gitlab server.</p>
<p>The answer to your question generally depends on a few things, like the size of your repository, network connection, runner executor type, and so on. One option is to configure a cache (in this case at the pipeline level and for the deploy just set the <code>GIT_STRATEGY=none</code>:</p>
<pre><code>default:
  cache:
    key: &quot;$CI_COMMIT_REF_SLUG&quot;
    paths:
      - deployment.spec.config

build:
  stage: build
  script:
    - build something

deploy:
  stage: deploy
  variables:
    GIT_STRATEGY: none
  script:
    - push-deployment ./deployment.spec.config
</code></pre>
<p>An added benefit here, depending on your build process, is the possibility of caching your dependencies when running multiple pipelines against the same branch. Note that you can only cache files relative to the project build directory.</p>
",25974,2021-04-13T12:52:25.003,"['default:\n  cache:\n    key: ""$CI_COMMIT_REF_SLUG""\n    paths:\n      - deployment.spec.config\n\nbuild:\n  stage: build\n  script:\n    - build something\n\ndeploy:\n  stage: deploy\n  variables:\n    GIT_STRATEGY: none\n  script:\n    - push-deployment ./deployment.spec.config\n']"
1662,13701,13639,CC BY-SA 4.0,2021-04-11T16:15:54.790,"<p>It's a bug; <code>origin_ssl_protocols</code> is defined as a list <a href=""https://github.com/ansible-collections/community.aws/blob/63769d5ffd2e3e513d06fb1b0d3d6111fef7bfb8/plugins/modules/cloudfront_distribution.py#L173-L176"" rel=""nofollow noreferrer"">here</a>, then the code tries to treat it as a dict <a href=""https://github.com/ansible-collections/community.aws/blob/63769d5ffd2e3e513d06fb1b0d3d6111fef7bfb8/plugins/modules/cloudfront_distribution.py#L1729"" rel=""nofollow noreferrer"">here</a> (which is the line referenced in your stack trace.)</p>
<p>As a workaround, it looks like the code might accept</p>
<pre class=""lang-yaml prettyprint-override""><code>          origin_ssl_protocols:
            items:
             - &quot;TLSv1.2&quot;
</code></pre>
",26597,2021-04-11T17:17:29.160,"['          origin_ssl_protocols:\n            items:\n             - ""TLSv1.2""\n']"
1663,13708,12558,CC BY-SA 4.0,2021-04-13T09:45:52.147,"<p>If your after the branch name, and your branches don't include &quot;directories&quot; (example: releases/my_release), then <code>Build.SourceBranchName</code> will you give you &quot;The last path segment in the ref&quot;. So, if <code>Build.SourceBranch</code> is <code>refs/heads/master</code>, then Build.SourceBranch will be <code>master</code>.</p>
<p>Your YAML:</p>
<pre><code>trigger:
  branches:
    include:
    - master
    - staging
...
manifests: |
  $(Pipeline.Workspace)/manifests/azure/${{ variables.Build.SourceBranchName }}/api.yaml
</code></pre>
",27135,2021-04-13T09:45:52.147,['trigger:\n  branches:\n    include:\n    - master\n    - staging\n...\nmanifests: |\n  $(Pipeline.Workspace)/manifests/azure/${{ variables.Build.SourceBranchName }}/api.yaml\n']
1664,13709,12178,CC BY-SA 4.0,2021-04-13T09:54:32.503,"<p>I'm not familiar with Invoke-Build, but appearantly it's a part of the InvokeBuild PowerShell module? In that case, you'll have to install the module as part of the script where you're using it. Your YAML should be something like this:</p>
<pre><code>- stage: Build
  jobs:
    - job: Build
      steps:
        - task: PowerShell@2
          inputs:
            targetType: 'inline'
            script: |
              Install-Module InvokeBuild
              Invoke-Build build
</code></pre>
<p>As @Michael Erpenbeck said &quot;the hosted agent starts off as a clean slate&quot;. That is to say that it starts off as a clean slate for each job in your pipeline. I'm not sure what bootstrap.ps1 is supposed to do so I can't really comment on whether that script and your <code>Invoke-Build</code> should be run as steps in the same job. But the main point to remember is that any requirements beyond what the standard Azure Pipelines agents offer should be taken care off within each job.</p>
",27135,2021-04-13T09:54:32.503,"[""- stage: Build\n  jobs:\n    - job: Build\n      steps:\n        - task: PowerShell@2\n          inputs:\n            targetType: 'inline'\n            script: |\n              Install-Module InvokeBuild\n              Invoke-Build build\n""]"
1665,13715,11977,CC BY-SA 4.0,2021-04-14T04:05:09.523,"<p>Environment approvals work per-stage. Split your jobs into separate stages:</p>
<pre class=""lang-yaml prettyprint-override""><code>stages:
  - stage: development
    condition: contains(variables['Build.SourceBranch'], 'refs/heads/develop')
    jobs:
    - deployment: Deploy_Dev
      displayName: 'Deploy Develop to Dev Machine'
      pool:
        name: Development
      environment: 'development'
      strategy:
        runOnce:
          deploy:
            steps:
              - checkout: none
              - task: Bash@3
                inputs:
                  targetType: 'inline'
                  script: |
                    echo $(hostname)
                  workingDirectory: '/var/www'
                  noProfile: false
                  noRc: false

  - stage: production
    condition: contains(variables['Build.SourceBranch'], 'refs/heads/master')
    jobs:
    - deployment: Deploy_Master_to_Hotfix
      displayName: 'Deploy Master to Hotfix Machine'
      pool:
        name: Hotfix
      environment: 'production'
      strategy:
        runOnce:
          deploy:
            steps:
              - checkout: none
              - task: Bash@3
                inputs:
                  targetType: 'inline'
                  script: |
                      echo $(hostname)         
                  workingDirectory: '/var/www'
                  noProfile: false
                  noRc: false
</code></pre>
",4090,2021-04-14T04:05:09.523,"[""stages:\n  - stage: development\n    condition: contains(variables['Build.SourceBranch'], 'refs/heads/develop')\n    jobs:\n    - deployment: Deploy_Dev\n      displayName: 'Deploy Develop to Dev Machine'\n      pool:\n        name: Development\n      environment: 'development'\n      strategy:\n        runOnce:\n          deploy:\n            steps:\n              - checkout: none\n              - task: Bash@3\n                inputs:\n                  targetType: 'inline'\n                  script: |\n                    echo $(hostname)\n                  workingDirectory: '/var/www'\n                  noProfile: false\n                  noRc: false\n\n  - stage: production\n    condition: contains(variables['Build.SourceBranch'], 'refs/heads/master')\n    jobs:\n    - deployment: Deploy_Master_to_Hotfix\n      displayName: 'Deploy Master to Hotfix Machine'\n      pool:\n        name: Hotfix\n      environment: 'production'\n      strategy:\n        runOnce:\n          deploy:\n            steps:\n              - checkout: none\n              - task: Bash@3\n                inputs:\n                  targetType: 'inline'\n                  script: |\n                      echo $(hostname)         \n                  workingDirectory: '/var/www'\n                  noProfile: false\n                  noRc: false\n""]"
1666,13721,13699,CC BY-SA 4.0,2021-04-14T15:00:47.270,"<p>So I believe I came up with a somewhat re-usable solution for this problem using <a href=""https://pypi.org/project/devpi/"" rel=""nofollow noreferrer"">devpi</a>. It allows you to use the same Dockerfile for the testing and production image.</p>
<p>Devpi allows me to create my own index which can shadow my production index with versions of software that haven't been officially released.</p>
<p>Steps to make this work:</p>
<p><strong>1. Base image from ARG</strong></p>
<p>I first edited my Dockerfile to allow overwriting the base image used. This will allow me to create a layer in the middle that configures pip to talk to devpi:</p>
<pre><code># Builds image reistry.myorg.com/python-app
ARG BASE=reistry.myorg.com/python-base:latest
FROM $BASE

COPY . /app

# Implicitly gets the latest `myorg.lib1` and `myorg.lib2` from PyPI
RUN pip install /app
</code></pre>
<p><strong>2. Upload test versions of library</strong></p>
<p>For each python change:</p>
<ul>
<li>Clone the repo</li>
<li><code>python -m build</code> the repo</li>
<li><code>devpi upload</code> the wheels</li>
</ul>
<p><strong>3. Create a layer with devpi pip conf</strong></p>
<p>Make a pip conf that can access your devpi instance and configure to your index name:</p>
<pre><code>[global]
index-url = http://&lt;some ip&gt;:&lt;some port&gt;/root/dev/+simple/
trusted-host = &lt;some ip&gt;
disable-pip-version-check = true

[search]
index = http://&lt;some ip&gt;:&lt;some port&gt;/root/dev/
</code></pre>
<p>And add that to your base images pip conf:</p>
<pre><code>FROM reistry.myorg.com/python-base:latest

COPY pip.conf /etc/pip.conf
</code></pre>
<p><strong>4. Chain the images together</strong></p>
<pre class=""lang-bash prettyprint-override""><code>docker build -t devpi-base -f devpi.Dockerfile .
docker build -t my-app -f Dockerfile --build-arg=BASE=devpi-base .
docker tag my-app reistry.myorg.com/my-app:test1
docker push reistry.myorg.com/my-app:test1
</code></pre>
<hr />
<p>Now when pip installs all of your dependencies you can have it pick up lower level changes to python packages. This concept should be re-usable for a lot of languages I imagine!</p>
",23396,2021-04-14T15:10:45.443,"['# Builds image reistry.myorg.com/python-app\nARG BASE=reistry.myorg.com/python-base:latest\nFROM $BASE\n\nCOPY . /app\n\n# Implicitly gets the latest `myorg.lib1` and `myorg.lib2` from PyPI\nRUN pip install /app\n', '[global]\nindex-url = http://<some ip>:<some port>/root/dev/+simple/\ntrusted-host = <some ip>\ndisable-pip-version-check = true\n\n[search]\nindex = http://<some ip>:<some port>/root/dev/\n', 'FROM reistry.myorg.com/python-base:latest\n\nCOPY pip.conf /etc/pip.conf\n', 'docker build -t devpi-base -f devpi.Dockerfile .\ndocker build -t my-app -f Dockerfile --build-arg=BASE=devpi-base .\ndocker tag my-app reistry.myorg.com/my-app:test1\ndocker push reistry.myorg.com/my-app:test1\n']"
1667,13737,13707,CC BY-SA 4.0,2021-04-19T06:41:31.503,"<p>You can do:</p>
<pre class=""lang-yaml prettyprint-override""><code>variables:
  templates.ref: $[ resources.repositories['templates'].ref ]
</code></pre>
<p>See <a href=""https://docs.microsoft.com/en-us/azure/devops/pipelines/repos/multi-repo-checkout?view=azure-devops#repository-details"" rel=""nofollow noreferrer"">Repository Details docs</a>.</p>
",4090,2021-04-19T06:41:31.503,"[""variables:\n  templates.ref: $[ resources.repositories['templates'].ref ]\n""]"
1668,13750,13732,CC BY-SA 4.0,2021-04-20T17:50:55.780,"<p>According the documentation you're giving, you need to remove <code>run-build</code> from the command :</p>
<pre><code>$ oc run NAME --image=&lt;image&gt; \
    [--generator=&lt;resource&gt;] \
    [--port=&lt;port&gt;] \
    [--replicas=&lt;replicas&gt;] \
    [--dry-run=&lt;bool&gt;] \
    [--overrides=&lt;inline_json&gt;] \
    [options]
</code></pre>
",5058,2021-04-20T17:50:55.780,['$ oc run NAME --image=<image> \\\n    [--generator=<resource>] \\\n    [--port=<port>] \\\n    [--replicas=<replicas>] \\\n    [--dry-run=<bool>] \\\n    [--overrides=<inline_json>] \\\n    [options]\n']
1669,13758,5669,CC BY-SA 4.0,2021-04-21T14:38:53.153,"<p>You are not able to create multiple <code>.gitlab-ci.yml</code> but you can manage to have what you want.</p>
<p>You currently have multiple software in the same repository with the same CI/CD Pipeline or jobs for your softwares.</p>
<p>You can use <code>include</code> in order to include local files from your repository, so you would get</p>
<pre class=""lang-yaml prettyprint-override""><code>include:
  - local: 'my_folder/.gitlab-ci.yml'
</code></pre>
<p>You can reach the generic way you want by using <a href=""https://docs.gitlab.com/ee/ci/variables/"" rel=""nofollow noreferrer"">Gitlab Variables</a> and <a href=""https://docs.gitlab.com/ee/ci/yaml/#extends"" rel=""nofollow noreferrer"">extends</a>.</p>
<p>Basically, you would end up with something like the following:</p>
<pre><code>## my_folder/build.yml
# the `.` (dot) before build means that we don't want it run alone, we must
# extends to run this part
.build:
  variables:
    SOFTWARE_ROOT: &quot;&quot;
  script:
    - build ${SOFTWARE_ROOT}

## .gitlab-ci.yml
include:
  - local: 'my_folder/build.yml'

my_first_build:
  extends: .build
  variables:
   SOFTWARE_ROOT: &quot;first_software/&quot;

my_second_build:
  extends: .build
  variables:
    SOFTWARE_ROOT: &quot;second_software/&quot;

</code></pre>
<p>You can also put everything in the same file.</p>
<p>This way you only declare your build job once for all.</p>
",27266,2021-04-21T14:38:53.153,"[""include:\n  - local: 'my_folder/.gitlab-ci.yml'\n"", '## my_folder/build.yml\n# the `.` (dot) before build means that we don\'t want it run alone, we must\n# extends to run this part\n.build:\n  variables:\n    SOFTWARE_ROOT: """"\n  script:\n    - build ${SOFTWARE_ROOT}\n\n## .gitlab-ci.yml\ninclude:\n  - local: \'my_folder/build.yml\'\n\nmy_first_build:\n  extends: .build\n  variables:\n   SOFTWARE_ROOT: ""first_software/""\n\nmy_second_build:\n  extends: .build\n  variables:\n    SOFTWARE_ROOT: ""second_software/""\n\n']"
1670,13759,986,CC BY-SA 4.0,2021-04-21T15:48:07.837,"<p>Working off of the existing answers and the Jenkins <a href=""https://www.jenkins.io/doc/pipeline/examples/#parallel-from-grep"" rel=""nofollow noreferrer"">example documentation</a> I came up with the following nested parallel solution. The <a href=""https://plugins.jenkins.io/pipeline-stage-view"" rel=""nofollow noreferrer"">Stage View (2.19)</a> plugin and <a href=""https://plugins.jenkins.io/blueocean"" rel=""nofollow noreferrer"">Blue Ocean (1.24.5)</a> do not display them as you would hope, so I used the <a href=""https://plugins.jenkins.io/groovy-postbuild/"" rel=""nofollow noreferrer"">Groovy Postbuild (2.5)</a> plugin (whitelisted) to show a result summary on the build page of the Classic View (the Badge plugin may work as well).</p>
<p>Current environment is using Jenkins LTS 2.277.2, a main &quot;trigger&quot; job, and 4 downstream jobs that build the pieces of my application, all of which are Multibranch pipelines.</p>
<p>I added a method to trigger my downstream Multibranch Pipeline jobs, since they all do the same thing. This is at the end of my Jenkinsfile.</p>
<pre class=""lang-java prettyprint-override""><code>// In case you want to work on the results of the downstream jobs
buildResults = []

// Common code to trigger a downstream job
// Outputs a URL that you can follow in Blue Ocean and Classic View
def performTriggerJob(String jobID) {
    // We need to wrap what we return in a Groovy closure, or else it's invoked
    // when this method is called, not when we pass it to parallel.
    // To do this, you need to wrap the code below in { }, and either return
    // that explicitly, or use { -&gt; } syntax.
    return {
        GIT_BRANCH_FIXUP = env.BRANCH_NAME.replace(&quot;/&quot;,&quot;%2F&quot;)
        // propagate: false so we can work after it returns. Try/catch will also work
        res = build( job: &quot;../${jobID}/${GIT_BRANCH_FIXUP}&quot;, propagate: false)
        echo &quot;${jobID}: ${res.getResult()} - ${res.buildVariables.get('RUN_DISPLAY_URL')}&quot;
        // Add to buildResults
        buildResults &lt;&lt; res

        text = &quot;Downstream Run Result: &lt;a href=\&quot;${res.buildVariables.get('RUN_DISPLAY_URL')}\&quot;&gt;${jobID} - ${res.getResult()}&lt;/a&gt;&quot;

        if (res.getResult().equals(&quot;SUCCESS&quot;)) {
            manager.createSummary(&quot;green.gif&quot;).appendText(text)
        } else {
            manager.createSummary(&quot;red.png&quot;).appendText(text)
            error 'JOB FAILED' // this fails the stage
        }
    }
}
</code></pre>
<p>Then in the main pipeline of the main Triggering job, I use <code>script</code> blocks to start the nested parallel jobs.</p>
<pre class=""lang-java prettyprint-override""><code>pipeline {
agent any
stages {
stage('Build Nested parallel') {
   steps {
      script {
         // Runs all these builds in parallel, the 2 nested Jobs
         // have a requirement on the cmake build, but can also run in
         // parallel after that finishes. Declarative cannot nest, but
         // Scripted can.

         // This is a map of 'name': action
         // performTriggerJob returns a Closure which is why this is just a method &quot;call&quot;
         // as Groovy will invoke .call() on parallel 'actions' automatically
         def builds = [
            &quot;subJob1&quot;: performTriggerJob('subJob1'),
            &quot;subJob2&quot;: performTriggerJob('subJob2'),
            &quot;subJob3&quot;: { script {
               // Since we have more work to do than just trigger a job,
               // we have to .call() this Closure directly in the script block to get it to run
               performTriggerJob('subJob3').call()

               // You can also pass a map directly into the parallel 
               parallel (
                  'nestedJob1': performTriggerJob('nestedJob1'),
                  'nestedJob2': performTriggerJob('nestedJob2')
               )
            } }
         ]
         parallel builds
      }
   }
}
// Other stages
}
}
</code></pre>
<p>Since <code>performTriggerJob</code> adds the results of the jobs to the variable <code>buildResults</code> we can do something with all the results once everything is done. I copy all artifacts from the last successful build and then zip them up so they're available on the trigger job.</p>
<p><code>buildResults</code> is a list of (what I believe are) <a href=""https://javadoc.jenkins.io/plugin/workflow-support/org/jenkinsci/plugins/workflow/support/steps/build/RunWrapper.html"" rel=""nofollow noreferrer"">RunWrapper</a> objects, so the methods in this javadoc are what you can call on this object.</p>
<pre class=""lang-java prettyprint-override""><code>// Other stages
stage(&quot;Post steps&quot;) {
steps {
script {
   for( finishedBuildObj in buildResults ) {
      // Obj to use. Could be this build or the last successful build
      buildObj       = finishedBuildObj
      projectName    = buildObj.getFullProjectName()
      if (buildObj.getResult() != &quot;SUCCESS&quot;) {
         buildObj = buildObj.getPreviousSuccessfulBuild()
      }
      copyArtifacts(
         projectName: projectName,
         // Allow this build to continue even if no build is found matching the &quot;Which build&quot; condition,
         // the build's workspace does not exist or is inaccessible, or no artifacts are found matching the specified pattern.
         // By default this build step fails the build if no artifacts are copied.
         optional: true,
         // Ignore the directory structure of the artifacts in the source project and copy all matching artifacts directly into the specified target directory.
         // By default the artifacts are copied in the same directory structure as the source project.
         flatten: true,
         // Target base directory for copy, or leave blank to use the workspace.
         // Directory (and parent directories, if any) will be created if needed.
         //May contain references to build parameters like $PARAM.
         target: 'allArtifacts',
         fingerprintArtifacts: true,
         // How to select the build to copy artifacts from, such as latest successful or stable build, or latest &quot;keep forever&quot; build. Other plugins may provide additional selections.
         // The build number of the selected build will be recorded in the environment for later build steps to reference. For details, see the help of &quot;Result variable suffix&quot; in &quot;Advanced&quot; section.
         selector: specific(buildObj.getNumber().toString())
      )
   }
}}}
</code></pre>
",17758,2021-04-21T15:48:07.837,"['// In case you want to work on the results of the downstream jobs\nbuildResults = []\n\n// Common code to trigger a downstream job\n// Outputs a URL that you can follow in Blue Ocean and Classic View\ndef performTriggerJob(String jobID) {\n    // We need to wrap what we return in a Groovy closure, or else it\'s invoked\n    // when this method is called, not when we pass it to parallel.\n    // To do this, you need to wrap the code below in { }, and either return\n    // that explicitly, or use { -> } syntax.\n    return {\n        GIT_BRANCH_FIXUP = env.BRANCH_NAME.replace(""/"",""%2F"")\n        // propagate: false so we can work after it returns. Try/catch will also work\n        res = build( job: ""../${jobID}/${GIT_BRANCH_FIXUP}"", propagate: false)\n        echo ""${jobID}: ${res.getResult()} - ${res.buildVariables.get(\'RUN_DISPLAY_URL\')}""\n        // Add to buildResults\n        buildResults << res\n\n        text = ""Downstream Run Result: <a href=\\""${res.buildVariables.get(\'RUN_DISPLAY_URL\')}\\"">${jobID} - ${res.getResult()}</a>""\n\n        if (res.getResult().equals(""SUCCESS"")) {\n            manager.createSummary(""green.gif"").appendText(text)\n        } else {\n            manager.createSummary(""red.png"").appendText(text)\n            error \'JOB FAILED\' // this fails the stage\n        }\n    }\n}\n', 'pipeline {\nagent any\nstages {\nstage(\'Build Nested parallel\') {\n   steps {\n      script {\n         // Runs all these builds in parallel, the 2 nested Jobs\n         // have a requirement on the cmake build, but can also run in\n         // parallel after that finishes. Declarative cannot nest, but\n         // Scripted can.\n\n         // This is a map of \'name\': action\n         // performTriggerJob returns a Closure which is why this is just a method ""call""\n         // as Groovy will invoke .call() on parallel \'actions\' automatically\n         def builds = [\n            ""subJob1"": performTriggerJob(\'subJob1\'),\n            ""subJob2"": performTriggerJob(\'subJob2\'),\n            ""subJob3"": { script {\n               // Since we have more work to do than just trigger a job,\n               // we have to .call() this Closure directly in the script block to get it to run\n               performTriggerJob(\'subJob3\').call()\n\n               // You can also pass a map directly into the parallel \n               parallel (\n                  \'nestedJob1\': performTriggerJob(\'nestedJob1\'),\n                  \'nestedJob2\': performTriggerJob(\'nestedJob2\')\n               )\n            } }\n         ]\n         parallel builds\n      }\n   }\n}\n// Other stages\n}\n}\n', '// Other stages\nstage(""Post steps"") {\nsteps {\nscript {\n   for( finishedBuildObj in buildResults ) {\n      // Obj to use. Could be this build or the last successful build\n      buildObj       = finishedBuildObj\n      projectName    = buildObj.getFullProjectName()\n      if (buildObj.getResult() != ""SUCCESS"") {\n         buildObj = buildObj.getPreviousSuccessfulBuild()\n      }\n      copyArtifacts(\n         projectName: projectName,\n         // Allow this build to continue even if no build is found matching the ""Which build"" condition,\n         // the build\'s workspace does not exist or is inaccessible, or no artifacts are found matching the specified pattern.\n         // By default this build step fails the build if no artifacts are copied.\n         optional: true,\n         // Ignore the directory structure of the artifacts in the source project and copy all matching artifacts directly into the specified target directory.\n         // By default the artifacts are copied in the same directory structure as the source project.\n         flatten: true,\n         // Target base directory for copy, or leave blank to use the workspace.\n         // Directory (and parent directories, if any) will be created if needed.\n         //May contain references to build parameters like $PARAM.\n         target: \'allArtifacts\',\n         fingerprintArtifacts: true,\n         // How to select the build to copy artifacts from, such as latest successful or stable build, or latest ""keep forever"" build. Other plugins may provide additional selections.\n         // The build number of the selected build will be recorded in the environment for later build steps to reference. For details, see the help of ""Result variable suffix"" in ""Advanced"" section.\n         selector: specific(buildObj.getNumber().toString())\n      )\n   }\n}}}\n']"
1671,13764,3221,CC BY-SA 4.0,2021-04-22T10:13:39.497,"<p>SSH into the instance and add the script that will collect the inode usage and send metrics to the alarm</p>
<pre><code>!/bin/bash
USAGE=80
INODE_USED=$(df -ih | sed -n '4p'| awk '{print $5}'| grep -v U | cut -d% -f1)
aws cloudwatch put-metric-data --metric-name inode-usage --dimensions Instance=&lt;Instance id&gt;  --namespace &quot;Custom&quot; --value $INODE_USED
</code></pre>
",27283,2021-04-22T10:13:39.497,"['!/bin/bash\nUSAGE=80\nINODE_USED=$(df -ih | sed -n \'4p\'| awk \'{print $5}\'| grep -v U | cut -d% -f1)\naws cloudwatch put-metric-data --metric-name inode-usage --dimensions Instance=<Instance id>  --namespace ""Custom"" --value $INODE_USED\n']"
1672,13781,8458,CC BY-SA 4.0,2021-04-26T15:55:07.730,"<p>What @Jon Ravenscraft posted as a comment on his own accepted (non) answer did in fact work for me as a solution. I am just formatting it here as an answer for anybody who stumbles here in the future:</p>
<ul>
<li>Follow <a href=""https://community.pivotal.io/s/article/How-to-get-into-an-App-Container-Manually-with-Garden-RunC-Backend?language=en_US"" rel=""nofollow noreferrer"">these steps</a> to get instance GUID (also included below for convenience)</li>
</ul>
<pre class=""lang-bash prettyprint-override""><code># Establish the process-guid for the app:
cf curl /v2/apps/$(cf app &lt;app_name&gt; --guid)| jq -r '.metadata.guid + &quot;-&quot; + .entity.version'
b06b2901-2093-4be4-9f37-f7788d04ce8c-ff93f0e2-285f-4f18-a6fc-806802f3dde9

# Find the hosts where the app instances are running:
cf curl v2/apps/$(cf app &lt;app-name&gt; --guid)/stats | grep host

# Identify the Diego cell you want to ssh to by running bosh vms | grep &lt;cell_ip&gt;

# bosh ssh to the Diego cell (grab the cell_id from step 3).

# Once in the Diego cell, as root, run the following command to grab the container_guid/instance_guid:
cfdot actual-lrp-groups-for-guid &lt;process_guid_from_step_1&gt; | jq '.instance | select (.address == &quot;&lt;diego_cell_ip&gt;&quot;)' | jq .instance_guid
</code></pre>
<ul>
<li>Then, from your terminal on the appropriate diego cell:</li>
</ul>
<pre class=""lang-bash prettyprint-override""><code>sudo /var/vcap/packages/containerd/bin/ctr -a /var/vcap/sys/run/containerd/containerd.sock -n garden tasks exec --exec-id my-shell --tty &lt;instance-guid&gt; /bin/sh
</code></pre>
<p>And voilà , you are dropped at a shell...</p>
<p>P.S. I believe the speculated reasoning given in the other answer is in fact, also correct, per <a href=""https://docs.pivotal.io/pivotalcf/2-6/pcf-release-notes/runtime-rn.html"" rel=""nofollow noreferrer"">https://docs.pivotal.io/pivotalcf/2-6/pcf-release-notes/runtime-rn.html</a>:</p>
<blockquote>
<p>PAS v2.6 enables containerd mode by default to bring PAS in line with other container providers. When you upgrade to PAS v2.6, Garden switches the container runtime from runc to containerd. Since the restart of Garden and the re-creation of containers are a normal part of a PAS upgrade, there is no operational impact to running applications.</p>
</blockquote>
",27344,2021-04-26T16:45:20.700,"['# Establish the process-guid for the app:\ncf curl /v2/apps/$(cf app <app_name> --guid)| jq -r \'.metadata.guid + ""-"" + .entity.version\'\nb06b2901-2093-4be4-9f37-f7788d04ce8c-ff93f0e2-285f-4f18-a6fc-806802f3dde9\n\n# Find the hosts where the app instances are running:\ncf curl v2/apps/$(cf app <app-name> --guid)/stats | grep host\n\n# Identify the Diego cell you want to ssh to by running bosh vms | grep <cell_ip>\n\n# bosh ssh to the Diego cell (grab the cell_id from step 3).\n\n# Once in the Diego cell, as root, run the following command to grab the container_guid/instance_guid:\ncfdot actual-lrp-groups-for-guid <process_guid_from_step_1> | jq \'.instance | select (.address == ""<diego_cell_ip>"")\' | jq .instance_guid\n', 'sudo /var/vcap/packages/containerd/bin/ctr -a /var/vcap/sys/run/containerd/containerd.sock -n garden tasks exec --exec-id my-shell --tty <instance-guid> /bin/sh\n']"
1673,13782,13777,CC BY-SA 4.0,2021-04-27T12:26:20.820,"<p><code>yarn start</code> should be the <code>CMD</code> of your docker image (I.e what is run when you start a container) and not a <code>RUN</code> command (which is run when creating the image used to satrt a container later)</p>
<p>From your exemple, something like this should be better:</p>
<pre><code> FROM node:12-alpine
 
 WORKDIR /app
 COPY ./server /app
 
 WORKDIR /app/server
 RUN yarn
 CMD yarn start
</code></pre>
",13,2021-04-27T12:26:20.820,[' FROM node:12-alpine\n \n WORKDIR /app\n COPY ./server /app\n \n WORKDIR /app/server\n RUN yarn\n CMD yarn start\n']
1674,13786,13576,CC BY-SA 4.0,2021-04-27T23:23:25.083,"<p>Instead of using <code>network_mode</code> to <code>host</code>, you can simply make use of <code>links</code> (new versions uses <code>networks</code>) which will make the communication to happen between two containers.</p>
<p>I have updated the <code>docker-compose.yaml</code> file and added <code>links</code> to connect <code>database</code> service (database container) to be accessed from your <code>backend</code> service.</p>
<p>In your backend database configuration, you need to use <code>database</code> as the db host. (Here <code>database</code> is the service name which is defined in the compose.yaml file)</p>
<pre><code>version: &quot;3&quot;

services:
  redis:
    image: redis:latest
    ports:
      - 6379:6379
    command: [&quot;redis-server&quot;, &quot;/redis.conf&quot;]
  database:
    image: &quot;postgres&quot;
    env_file:
      - ./database/database.env
    volumes:
      - database-data:/var/lib/postgresql/data
      - ./database/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    restart: always
  backend:
    depends_on: [database]
    build: ./server
    volumes:
      - ./files:/var/lib/files
    ports:
      - 3333:3333
    restart: always
    links:
      - &quot;database&quot;

volumes:
  database-data:
</code></pre>
",12138,2021-04-27T23:23:25.083,"['version: ""3""\n\nservices:\n  redis:\n    image: redis:latest\n    ports:\n      - 6379:6379\n    command: [""redis-server"", ""/redis.conf""]\n  database:\n    image: ""postgres""\n    env_file:\n      - ./database/database.env\n    volumes:\n      - database-data:/var/lib/postgresql/data\n      - ./database/init-db.sql:/docker-entrypoint-initdb.d/init.sql\n    restart: always\n  backend:\n    depends_on: [database]\n    build: ./server\n    volumes:\n      - ./files:/var/lib/files\n    ports:\n      - 3333:3333\n    restart: always\n    links:\n      - ""database""\n\nvolumes:\n  database-data:\n']"
1675,13787,13576,CC BY-SA 4.0,2021-04-28T01:22:57.037,"<p>When you use network_mode host, the <a href=""https://docs.docker.com/network/host/"" rel=""nofollow noreferrer"">published ports are ignored</a>, which means the ports that are open in the containers will be the same port in the host. Does not matter what you had declared in <code>ports</code></p>
<p>The default behavior is every service in the compose can talk to each other.</p>
<blockquote>
<p><a href=""https://docs.docker.com/compose/networking/#links"" rel=""nofollow noreferrer"">Links</a> are not required to enable services to communicate - by default, any service can reach any other service at that service’s name</p>
</blockquote>
<p>let's use this simple compose as an example. There is no network defined, docker will create one.</p>
<pre><code>version: '3.7'
services:
  nginx1:
    image: nginx
    ports:
      - '8080:80'
  nginx2:
    image: nginx
</code></pre>
<p>Nginx1 will be reachable through port 8080 on localhost and any other machines in the network.</p>
<pre><code>$ curl -I http://localhost:8080
HTTP/1.1 200 OK
Server: nginx/1.19.10
</code></pre>
<p>While nginx2 will even have a port on the host.</p>
<pre><code>$ docker-compose ps
      Name                     Command               State                  Ports                
-------------------------------------------------------------------------------------------------
nginx1_1   /docker-entrypoint.sh ngin ...   Up      0.0.0.0:8080-&gt;80/tcp,:::8080-&gt;80/tcp
nginx2_1   /docker-entrypoint.sh ngin ...   Up      80/tcp                              
</code></pre>
<p>And they still reach each other by their internal port using the service name</p>
<p>Accessing nginx1 from nginx2</p>
<pre><code>$ docker exec -it nginx2_1 curl -I http://nginx1:80
HTTP/1.1 200 OK
Server: nginx/1.19.10
</code></pre>
<p>Accessing nginx2 from nginx1</p>
<pre><code>$ docker exec -it nginx1_1 curl -I http://nginx2:80
HTTP/1.1 200 OK
Server: nginx/1.19.10
</code></pre>
",12988,2021-04-28T01:22:57.037,"[""version: '3.7'\nservices:\n  nginx1:\n    image: nginx\n    ports:\n      - '8080:80'\n  nginx2:\n    image: nginx\n"", '$ curl -I http://localhost:8080\nHTTP/1.1 200 OK\nServer: nginx/1.19.10\n', '$ docker-compose ps\n      Name                     Command               State                  Ports                \n-------------------------------------------------------------------------------------------------\nnginx1_1   /docker-entrypoint.sh ngin ...   Up      0.0.0.0:8080->80/tcp,:::8080->80/tcp\nnginx2_1   /docker-entrypoint.sh ngin ...   Up      80/tcp                              \n', '$ docker exec -it nginx2_1 curl -I http://nginx1:80\nHTTP/1.1 200 OK\nServer: nginx/1.19.10\n', '$ docker exec -it nginx1_1 curl -I http://nginx2:80\nHTTP/1.1 200 OK\nServer: nginx/1.19.10\n']"
1676,13799,8329,CC BY-SA 4.0,2021-04-29T21:06:28.740,"<p>The best way I have found so far is to use Docker containers with a docker file that does the installation of node_modules before running other steps.</p>
<p>I make sure all jobs of this multi branch pipeline run on the same node and keep the latest docker image for EACH branch on this node locally. That way unless the dependencies in packages.json change, then docker will use the cache to build the new image (or just generate the artifact you want to create and transfer it to the local workspace). If all branches have the same dependencies, they will all use the same cached image, if not they will just create a new one.</p>
<p>Example:</p>
<pre><code>## CHOSE YOUR LOCAL BASE IMAGE
FROM debian:10.0

### ADD YOUR DEPENDENCIES
ADD packages.json build-deps.sh

### INSTALL DEPENDENCIES (we use a custom script)
RUN build-deps.sh

### ADD THE REST OF YOUR CODE 
### This will break the cache assuming your code changes each time,
### but previous docker build commands will be cached 
### (if your dependencies didn't change)
ADD my-code.tar.gz .

### RUN YOUR COMMANDS
RUN run-your-scripts.sh

</code></pre>
<p>After building you image with docker build, you can then do soemthing like this to extract the artifact</p>
<pre><code>docker run --name SOME-NAME YOUR-REPO:YOUR-TAG
sudo docker cp SOME-NAME:/path/to/artifact/artifact.tar.gz ${WORKSPACE}
</code></pre>
<p>I hope this helps</p>
",27405,2021-04-29T21:22:53.713,"[""## CHOSE YOUR LOCAL BASE IMAGE\nFROM debian:10.0\n\n### ADD YOUR DEPENDENCIES\nADD packages.json build-deps.sh\n\n### INSTALL DEPENDENCIES (we use a custom script)\nRUN build-deps.sh\n\n### ADD THE REST OF YOUR CODE \n### This will break the cache assuming your code changes each time,\n### but previous docker build commands will be cached \n### (if your dependencies didn't change)\nADD my-code.tar.gz .\n\n### RUN YOUR COMMANDS\nRUN run-your-scripts.sh\n\n"", 'docker run --name SOME-NAME YOUR-REPO:YOUR-TAG\nsudo docker cp SOME-NAME:/path/to/artifact/artifact.tar.gz ${WORKSPACE}\n']"
1677,13809,13807,CC BY-SA 4.0,2021-05-03T01:38:37.490,"<p>From the same page:</p>
<pre><code>The steps to integrate ALB and NLB with API Gateway are identical.
</code></pre>
<p>Which follows by a sentence with a link to a documentation for an <a href=""https://docs.aws.amazon.com/eks/latest/userguide/alb-ingress.html"" rel=""nofollow noreferrer"">ALB ingress</a>, including prerequisites for VPC subnets and EKS resources.</p>
<p>Yes, you have to create one unless you'd want to configure ALB manually instead of using <code>Ingress</code> manifests inside k8s.</p>
",2956,2021-05-03T01:38:37.490,['The steps to integrate ALB and NLB with API Gateway are identical.\n']
1678,13810,13740,CC BY-SA 4.0,2021-05-03T04:55:46.443,"<p>Package facts (as any other facts like devices, disks and their partitions, IP addresses...) don't refresh automagically.</p>
<p>In your case, you can use a <a href=""https://docs.ansible.com/ansible/latest/user_guide/playbooks_handlers.html"" rel=""nofollow noreferrer"">handler</a> and notify it from any task that can possibly invalidate the cache. Here is a quickNdirty example:</p>
<pre class=""lang-yaml prettyprint-override""><code>- name: Pseudo code demo for package facts refresh
  hosts: localhost
  
  tasks:

    - name: Gather the package facts unconditionally at play start
      package_facts:

    - name: Make sure package X is installed
      package:
        name: package_X
      notify: refresh_package_facts
    
    # By default, handlers run at the end of the play.
    # If you want to force them to run at a certain point,
    # you need the following meta task.
    # Note =&gt; this will run !!ALL!! notified handlers
    - name: Run handlers if notified
      meta: flush_handlers

    - name: This task will run with an up-to-date cache
      debug:
        msg: &quot;{{ ansible_facts.packages | length }} packages are installed&quot;

  handlers:

    - name: Refresh the package facts
      package_facts:
      listen: refresh_package_facts
</code></pre>
",13111,2021-05-03T05:03:11.413,"['- name: Pseudo code demo for package facts refresh\n  hosts: localhost\n  \n  tasks:\n\n    - name: Gather the package facts unconditionally at play start\n      package_facts:\n\n    - name: Make sure package X is installed\n      package:\n        name: package_X\n      notify: refresh_package_facts\n    \n    # By default, handlers run at the end of the play.\n    # If you want to force them to run at a certain point,\n    # you need the following meta task.\n    # Note => this will run !!ALL!! notified handlers\n    - name: Run handlers if notified\n      meta: flush_handlers\n\n    - name: This task will run with an up-to-date cache\n      debug:\n        msg: ""{{ ansible_facts.packages | length }} packages are installed""\n\n  handlers:\n\n    - name: Refresh the package facts\n      package_facts:\n      listen: refresh_package_facts\n']"
1679,13819,13808,CC BY-SA 4.0,2021-05-04T14:47:30.530,"<p>This isn't really an ArgoCD thing. <a href=""https://keel.sh/"" rel=""nofollow noreferrer"">Keel is a good tool</a> to help keep your images updated across the cluster and is super easy to implement. Basically, you'd just add some annotations to your manifest.</p>
<pre><code>metadata:
  annotations:
    keel.sh/policy: force
    keel.sh/trigger: poll      
    keel.sh/pollSchedule: &quot;@every 10m&quot;
</code></pre>
<p>It may be worth noting that if you are moving to run this in production, avoid the use of the latest tag. This is considered bad practice as it can burn you when breaking changes are pushed. Keel can handle that through an innate understanding of semver tags allowing you to update on minor version changes, but avoid major without testing, etc.</p>
",20204,2021-05-04T14:47:30.530,"['metadata:\n  annotations:\n    keel.sh/policy: force\n    keel.sh/trigger: poll      \n    keel.sh/pollSchedule: ""@every 10m""\n']"
1680,13832,2656,CC BY-SA 4.0,2021-05-05T17:07:57.657,"<p>Failure to validate SSL certificate seems to be happening widely across Linux distributions. Therefore I will post a solution (general idea) which worked for me. The surface problem seems to be that Python is not able to recognize the certificate bundle file. Meanwhile, commandline <code>curl</code> can recognize SSL certificate and download file. The path to the certificate bundle differs depending on your Linux distribution.</p>
<p>In my case,</p>
<p>Ansible version: 2.10,
Debian distribution</p>
<p>after certificate was added by</p>
<pre><code>- name: Add the intermediate certificate to certificate bundle
  command: update-ca-certificates
</code></pre>
<p>Then, specify the SSL_CERT_FILE variable to the certificate bundle.</p>
<pre><code>- name: download a file
  get_url:
    url: &quot;url&quot;
    dest: &quot;destination&quot;
  environment:                                           # Explicitly specify SSL_CERT_FILE here.
    SSL_CERT_FILE: /etc/ssl/certs/ca-certificates.crt     
</code></pre>
",27496,2021-05-05T17:07:57.657,"['- name: Add the intermediate certificate to certificate bundle\n  command: update-ca-certificates\n', '- name: download a file\n  get_url:\n    url: ""url""\n    dest: ""destination""\n  environment:                                           # Explicitly specify SSL_CERT_FILE here.\n    SSL_CERT_FILE: /etc/ssl/certs/ca-certificates.crt     \n']"
1681,13834,11897,CC BY-SA 4.0,2021-05-05T21:42:55.267,"<p>You can use <code>when: on_failure</code>, in your case you can create a new job for rollback when your <code>some more tests</code> have failed.</p>
<h3>Example:</h3>
<pre class=""lang-yaml prettyprint-override""><code>cleanup_build_job:
  stage: cleanup_build
  script:
    - cleanup build when failed
  when: on_failure
</code></pre>
<p>For more example: <a href=""https://docs.gitlab.com/ee/ci/yaml/#when"" rel=""nofollow noreferrer"">https://docs.gitlab.com/ee/ci/yaml/#when</a></p>
",27502,2021-05-05T21:42:55.267,['cleanup_build_job:\n  stage: cleanup_build\n  script:\n    - cleanup build when failed\n  when: on_failure\n']
1682,13846,13842,CC BY-SA 4.0,2021-05-08T00:45:13.203,"<p>When your configuration or a provider marks an attribute as sensitive, Terraform will always hide that value in any output that's intended for human consumption.</p>
<p>The real values are available in machine-readable output though. This is primarily with the aim of integrating with external software, but if you need to then you can also inspect the machine-readable output directly yourself.</p>
<p>You can get a machine-readable (JSON) rendering of a plan like this:</p>
<pre><code>terraform plan -out=tfplan
terraform show -json tfplan
</code></pre>
<p>If you intend to read it directly in the terminal then it can help to pipe it into <a href=""https://stedolan.github.io/jq/"" rel=""nofollow noreferrer""><code>jq</code></a>, if you have that utility installed:</p>
<pre><code>terraform show -json tfplan | jq
</code></pre>
",2463,2021-05-08T00:45:13.203,"['terraform plan -out=tfplan\nterraform show -json tfplan\n', 'terraform show -json tfplan | jq\n']"
1683,13852,13826,CC BY-SA 4.0,2021-05-09T10:47:06.513,"<p>If you are using the docker-compose file from that github repo it's using traefik and should correctly expose port 8000, that should default to 0.0.0.0:8000.
Maybe Ubuntu firewall is blocking incoming TCP port 8000. That could explain why it works on drupal.localhost:8000 which most likely resolves to 127.0.0.1 but not from 192.* LAN.</p>
<p>Check Ubuntu firewall:</p>
<p><code>$ sudo ufw status</code></p>
<p>Make sure incoming TCP 8000 is allowed from anywhere, or at least for your LAN ip range.
If not, you can open it with:</p>
<pre><code>$ sudo ufw allow from any to any port 8000 proto tcp
</code></pre>
",24251,2021-05-09T10:47:06.513,['$ sudo ufw allow from any to any port 8000 proto tcp\n']
1684,13857,13856,CC BY-SA 4.0,2021-05-09T22:17:44.943,"<blockquote>
<p><code>monitor-prometheus-server-5587c7f464-z9tcj        1/2     CrashLoopBackOff</code></p>
</blockquote>
<p><code>1/2</code> here means that 1 of 2 <strong>containers</strong> in the Pod is &quot;Ready&quot;</p>
<p>When you describe the Pod, you see the status of the containers:</p>
<pre><code>Containers:
  prometheus-server-configmap-reload:
    Ready:          True
...
  prometheus-server:
    Ready:          False
</code></pre>
<p>You probably need to check the logs for the crashing container to see the reason.</p>
",6162,2021-05-09T22:17:44.943,['Containers:\n  prometheus-server-configmap-reload:\n    Ready:          True\n...\n  prometheus-server:\n    Ready:          False\n']
1685,13859,3127,CC BY-SA 4.0,2021-05-10T09:35:25.430,"<p><code>-r</code> is not needed to copy the folder. The below command will work. I tested this on <code>kubectl</code> version 1.21.</p>
<pre><code>kubectl cp &lt;pod_id&gt;:/home/test_folder test_folder_localhost
</code></pre>
",27575,2021-05-10T15:56:56.757,['kubectl cp <pod_id>:/home/test_folder test_folder_localhost\n']
1686,13860,13826,CC BY-SA 4.0,2021-05-10T13:59:34.433,"<p>It turned out it was only a setting in Traefik. I had to add a second router http rule for the nginx container in my <code>docker-compose.yml</code>:</p>
<pre><code>- &quot;traefik.http.routers.${PROJECT_NAME}_nginx_lan.rule=Host(`192.168.10.100`)&quot;
</code></pre>
<p>So the full nginx section now looks like that:</p>
<pre><code>  nginx:
    image: wodby/nginx:$NGINX_TAG
    container_name: &quot;${PROJECT_NAME}_nginx&quot;
    depends_on:
    - php
    environment:
      NGINX_STATIC_OPEN_FILE_CACHE: &quot;off&quot;
      NGINX_ERROR_LOG_LEVEL: debug
      NGINX_BACKEND_HOST: php
      NGINX_SERVER_ROOT: /var/www/html/web
      NGINX_VHOST_PRESET: $NGINX_VHOST_PRESET
    #      NGINX_DRUPAL_FILE_PROXY_URL: http://example.com
    volumes:
    - ./web:/var/www/html:cached
    labels:
    - &quot;traefik.http.routers.${PROJECT_NAME}_nginx.rule=Host(`${PROJECT_BASE_URL}`)&quot;
    - &quot;traefik.http.routers.${PROJECT_NAME}_nginx_lan.rule=Host(`192.168.10.100`)&quot;
</code></pre>
<p>It works fine. I can now access my Drupal website at <a href=""http://192.168.10.100:8000"" rel=""nofollow noreferrer"">http://192.168.10.100:8000</a> from any other device on the same LAN.</p>
<p>In my case, <code>PROJECT_BASE_URL</code> and <code>PROJECT_NAME</code> are configured in an <code>.env</code> file and correspond to <code>drupal.localhost</code> and <code>drupal</code> respectively.</p>
",27485,2021-05-10T13:59:34.433,"['- ""traefik.http.routers.${PROJECT_NAME}_nginx_lan.rule=Host(`192.168.10.100`)""\n', '  nginx:\n    image: wodby/nginx:$NGINX_TAG\n    container_name: ""${PROJECT_NAME}_nginx""\n    depends_on:\n    - php\n    environment:\n      NGINX_STATIC_OPEN_FILE_CACHE: ""off""\n      NGINX_ERROR_LOG_LEVEL: debug\n      NGINX_BACKEND_HOST: php\n      NGINX_SERVER_ROOT: /var/www/html/web\n      NGINX_VHOST_PRESET: $NGINX_VHOST_PRESET\n    #      NGINX_DRUPAL_FILE_PROXY_URL: http://example.com\n    volumes:\n    - ./web:/var/www/html:cached\n    labels:\n    - ""traefik.http.routers.${PROJECT_NAME}_nginx.rule=Host(`${PROJECT_BASE_URL}`)""\n    - ""traefik.http.routers.${PROJECT_NAME}_nginx_lan.rule=Host(`192.168.10.100`)""\n']"
1687,13876,13341,CC BY-SA 4.0,2021-05-12T01:43:06.773,"<p>It looks like you are on the right approach here, the issue seems to be one of debugging. I have found this <a href=""https://cryptic-cliffs-32040.herokuapp.com/"" rel=""nofollow noreferrer"">jinja2 live templating engine</a> to be helpful with debugging in the past.</p>
<p>In python (on which jinja is based) <a href=""https://problemsolvingwithpython.com/04-Data-Types-and-Variables/04.02-Boolean-Data-Type/"" rel=""nofollow noreferrer"">&quot;True&quot; is a keyword</a> which is probably getting interpreted as a boolean <a href=""https://en.wikipedia.org/wiki/Data_type"" rel=""nofollow noreferrer"">data type</a>. This would be in contrast to the string, integer, or floating point (decimal) data types which are a C/C++ concept that python inherits since it's interpreter is written in C. Python tries to be agnostic to data type and variables are not <a href=""https://en.wikipedia.org/wiki/Strong_and_weak_typing"" rel=""nofollow noreferrer"">strongly typed</a>. This appears to be a situation in which the lack of strong typing may be getting you into some hot water.</p>
<p>In your boolean logic in the &quot;if&quot; block says to only render the section if <code>allow_httpd</code> is a string - but it isn't! It's a boolean! This is likely the error. Instead, you may wish to try simply:</p>
<pre><code>{% if allow_httpd %}
Make sure httpd service is running:
  service.enabled:
    - name: httpd

{% else %}

stop and disable httpd:
  service.dead:
    - name: httpd
    - enable: False

{% endif %}
</code></pre>
<p>I'd also recommend you remove your quotes in the pillar data if you use this approach.</p>
",2845,2021-05-12T01:43:06.773,['{% if allow_httpd %}\nMake sure httpd service is running:\n  service.enabled:\n    - name: httpd\n\n{% else %}\n\nstop and disable httpd:\n  service.dead:\n    - name: httpd\n    - enable: False\n\n{% endif %}\n']
1688,13879,11679,CC BY-SA 4.0,2021-05-12T02:54:17.070,"<p>There is no error in what you have posted here. The error lies elsewhere in your code which you did not include in the OP. Using the <a href=""https://cryptic-cliffs-32040.herokuapp.com/"" rel=""nofollow noreferrer"">Jinja live parser</a>, when pasting in:</p>
<pre><code>{% if spade.corename == 'FI' and spade.nodetype == 'master' %}
dataimport-script:
  file.managed:
    - name: /opt/bin/DataImport.py
    - source: salt://files/DataImport.py

dataimport-crontab:
  file.managed:
    - name: /etc/cron.d/solr-dataimport
    - contents: |
                # # set up data import for FI every 2 minutes
                */2 * * * * root /usr/bin/python /opt/bin/DataImport.py
{% elif spade.nodetype in ['slave','ds'] and spade.corename == 'FI' %}
update-fi-solrconfig:
  file.replace:
    - name: {{ salt['pillar.get']('solr:home_dir') }}/data/{{ 
salt['pillar.get']('spade:Corename') }}/conf/solrconfig.xml
    - pattern: '&quot;autoDeletePeriodSeconds&quot;&gt;30'
    - repl: '&quot;autoDeletePeriodSeconds&quot;&gt;-1'
{% endif %}
</code></pre>
<p>With a pillar of:</p>
<pre><code>spade:
  corename: FI
  nodetype: master
</code></pre>
<p>Everything renders just fine. This tells me there is nothing wrong with your snippet. The fact that your error indicates you have at least 205 lines of code, but the example has far less tells me the issue was with another &quot;if&quot; block further up in your code.</p>
",2845,2021-05-12T02:54:17.070,"['{% if spade.corename == \'FI\' and spade.nodetype == \'master\' %}\ndataimport-script:\n  file.managed:\n    - name: /opt/bin/DataImport.py\n    - source: salt://files/DataImport.py\n\ndataimport-crontab:\n  file.managed:\n    - name: /etc/cron.d/solr-dataimport\n    - contents: |\n                # # set up data import for FI every 2 minutes\n                */2 * * * * root /usr/bin/python /opt/bin/DataImport.py\n{% elif spade.nodetype in [\'slave\',\'ds\'] and spade.corename == \'FI\' %}\nupdate-fi-solrconfig:\n  file.replace:\n    - name: {{ salt[\'pillar.get\'](\'solr:home_dir\') }}/data/{{ \nsalt[\'pillar.get\'](\'spade:Corename\') }}/conf/solrconfig.xml\n    - pattern: \'""autoDeletePeriodSeconds"">30\'\n    - repl: \'""autoDeletePeriodSeconds"">-1\'\n{% endif %}\n', 'spade:\n  corename: FI\n  nodetype: master\n']"
1689,13881,13880,CC BY-SA 4.0,2021-05-12T12:55:43.957,"<p>Your question is not silly at all, indeed managing WordPress at scale requires broad knowledges due to how WordPress is implemented.</p>
<p>It's good to know that WordPress consists of 1) core PHP code, 2) plugins/themes and 3) uploaded media assets.
To serve the core and plugins, you'll need to locate the code either in local disk or NFS. Local disk is obviously faster since it doesn't interact with network, but NFS is a good choice if you want to have multiple servers to share the same code.</p>
<p>The uploaded media assets are a bit different. The most common &quot;assets&quot; are image files, and you can completely offload the server traffic to object storage such as AWS S3 or GCP Cloud Storage. Unlike plugins and themes, the media assets  are <strong>static</strong> meaning it will never run server-side logics like PHP.</p>
<p>Moreover, WordPress is <strong>read-heavy</strong> application that most of the MySQL query is to render blog posts to your public audiences, means any-sized server may blow up when unexpected number of visitors rush to your website. This is where CDN shines, to cache rendered HTMLs in the edge servers at the first visit, then serve the cached files without reaching to origins. <a href=""https://aws.amazon.com/cloudfront/"" rel=""nofollow noreferrer"">AWS CloudFront</a> and <a href=""https://cloud.google.com/cdn"" rel=""nofollow noreferrer"">GCP Cloud CDN</a> are popular CDNs to turn cheap WordPress server to globally-scalable media site.</p>
<p>So, I recommend to have the following architecture:</p>
<pre><code>Visitor --&gt; CDN --&gt; Web/PHP Server --&gt; MySQL
</code></pre>
<p>When configured correctly, you can serve millions of traffics backed with $10 web server.</p>
",27634,2021-05-12T12:55:43.957,['Visitor --> CDN --> Web/PHP Server --> MySQL\n']
1690,13900,3794,CC BY-SA 4.0,2021-05-14T00:50:38.067,"<p>If you prefer ssh connection use this:</p>
<pre><code>after_script:
  - git --version
  - git remote remove origin
  - git remote add origin git@gitlab.com:$CI_PROJECT_PATH.git
  - git tag -a v-$CI_COMMIT_SHORT_SHA -m &quot;Version created by gitlab-ci Build&quot;
  - git push --tags
</code></pre>
",27663,2021-05-14T00:50:38.067,"['after_script:\n  - git --version\n  - git remote remove origin\n  - git remote add origin git@gitlab.com:$CI_PROJECT_PATH.git\n  - git tag -a v-$CI_COMMIT_SHORT_SHA -m ""Version created by gitlab-ci Build""\n  - git push --tags\n']"
1691,13907,13905,CC BY-SA 4.0,2021-05-14T06:25:36.517,"<p>There's a few things to note. First is that in the absense of a shebang being supplied, the actual interpreter that will be used is actually &quot;sh&quot;, not &quot;bash&quot;.</p>
<p>Taking a look at the Jenkins source for the <a href=""https://github.com/jenkinsci/durable-task-plugin/blob/master/src/main/java/org/jenkinsci/plugins/durabletask/BourneShellScript.java"" rel=""nofollow noreferrer"">BourneShellScript task</a>, what happens is that Jenkins does not actually return the exit code from the subshell - it monitors a file called &quot;jenkins-result.txt for changes (using a <a href=""https://github.com/jenkinsci/durable-task-plugin/blob/master/src/main/java/org/jenkinsci/plugins/durabletask/FileMonitoringTask.java"" rel=""nofollow noreferrer"">FileMonitoringTask</a>) and when that file has been updated, it merely assigns the content of it as the exit status.</p>
<p>From what I can see, when you call &quot;sh&quot; it does not just run your script code, but actually wraps it in a fairly substantial block of boilerplate code (refer line 272 of the above linked BourneShellScript). In effect, something closer to this:</p>
<pre><code>sh -c ({ while [ -d '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0' -a \\! -f '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/jenkins-result.txt' ]; do touch '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/jenkins-log.txt'; sleep 3; done } &amp; jsc=durable-2fa119e0; JENKINS_SERVER_COOKIE=$jsc sh -xe '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/script.sh' &gt; '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/jenkins-output.txt' 2&gt; 'jenkins-log.txt'; echo $? &gt; '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/jenkins-result.txt.tmp'; mv '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/jenkins-result.txt.tmp' '/home/user/workspace/newbie_dont_know_what_hes_doin\@tmp/durable-2fa119e0/jenkins-result.txt'; wait) &gt;&amp;- 2&gt;&amp;- &amp;
</code></pre>
<p>This is likely necessary to support scenarios where the node on which the script is executed is not the node on which the pipeline is executing, however it does leave a lot of room for error in returning the result, depending on the idiosyncracies of whatever interpreter &quot;sh&quot; is aliased to (not necessarily bash) and the OS on which it is running.</p>
",27667,2021-05-14T06:25:36.517,"[""sh -c ({ while [ -d '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0' -a \\\\! -f '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/jenkins-result.txt' ]; do touch '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/jenkins-log.txt'; sleep 3; done } & jsc=durable-2fa119e0; JENKINS_SERVER_COOKIE=$jsc sh -xe '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/script.sh' > '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/jenkins-output.txt' 2> 'jenkins-log.txt'; echo $? > '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/jenkins-result.txt.tmp'; mv '/home/user/workspace/newbie_dont_know_what_hes_doin@tmp/durable-2fa119e0/jenkins-result.txt.tmp' '/home/user/workspace/newbie_dont_know_what_hes_doin\\@tmp/durable-2fa119e0/jenkins-result.txt'; wait) >&- 2>&- &\n""]"
1692,13910,13886,CC BY-SA 4.0,2021-05-14T09:57:18.763,"<p>you need to create the www-data user in the dockerfile eg</p>
<pre><code>RUN addgroup -g 1000 www-data &amp;&amp; adduser -G www-data -g www-data -s /bin/sh -D www-data

RUN chown -R www-data:www-data /home/www-data &amp;&amp; \
    chown -R www-data:www-data /var/www
</code></pre>
",27673,2021-05-14T09:57:18.763,['RUN addgroup -g 1000 www-data && adduser -G www-data -g www-data -s /bin/sh -D www-data\n\nRUN chown -R www-data:www-data /home/www-data && \\\n    chown -R www-data:www-data /var/www\n']
1693,13920,12866,CC BY-SA 4.0,2021-05-15T12:14:57.977,"<p>After Further research, I found <a href=""https://gitlab.com/gitlab-org/gitlab-runner/-/issues/3750"" rel=""nofollow noreferrer"">an open issue on gitlab</a> pretty similar to mine.
They describe runners freshly created and unable to pick up jobs.
As for my use case, The runner was created but with warning stating &quot;New Runner, has not connected yet&quot;.</p>
<p>In order to further check the status of the runner, I went to my terminal on the machine where I installed and registered the runner, namely my mac book pro, and I ran the following command:</p>
<pre><code>sudo gitlab-runner verify
</code></pre>
<p><a href=""https://i.stack.imgur.com/zYWy6.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zYWy6.png"" alt=""enter image description here"" /></a></p>
<p>In the settings of the project, the runner's status switches to &quot;<strong>Online</strong>&quot; as you can see below, with a green label:</p>
<p><a href=""https://i.stack.imgur.com/2QIZc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2QIZc.png"" alt=""enter image description here"" /></a></p>
<p>As a result, the project's pipeline status went from &quot;Pending&quot; to &quot;Running&quot;</p>
<p><a href=""https://i.stack.imgur.com/zldkt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zldkt.png"" alt=""enter image description here"" /></a></p>
<p>Nevertheless, while the change of pipeline status, from &quot;pending&quot; to &quot;running&quot; thanks to gitlab runner's status going &quot;Online&quot;, the associated CI build Job Status is still stuck at &quot;Pending&quot;. This means that gitlab runner, even with all its characteristics looking fine, fails to pick up the job he's supposed to.
<a href=""https://i.stack.imgur.com/ZaKpB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZaKpB.png"" alt=""enter image description here"" /></a></p>
<p>I'm aware this is not really a pure answer with final solution but I hope this will help move things forward on this topic !</p>
",27696,2021-05-15T12:36:57.420,['sudo gitlab-runner verify\n']
1694,13931,13885,CC BY-SA 4.0,2021-05-16T20:10:38.837,"<p>The sample I posted initially works as is:</p>
<pre><code>apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: my-service-ingress
spec:
  entryPoints:
    - web
    - websecure
  routes:
    - kind: Rule
      match: Host(`myservice.mycompany.example`)
      services:
        - kind: Service
          name: myservice-node1-clusterip
          passHostHeader: true
          port: 80
        - kind: Service
          name: myservice-node2-clusterip
          passHostHeader: true
          port: 80
        - kind: Service
          name: myservice-node3-clusterip
          passHostHeader: true
          port: 80
        - kind: Service
          name: myservice-node4-clusterip
          passHostHeader: true
          port: 80
</code></pre>
",27443,2021-05-16T20:10:38.837,['apiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: my-service-ingress\nspec:\n  entryPoints:\n    - web\n    - websecure\n  routes:\n    - kind: Rule\n      match: Host(`myservice.mycompany.example`)\n      services:\n        - kind: Service\n          name: myservice-node1-clusterip\n          passHostHeader: true\n          port: 80\n        - kind: Service\n          name: myservice-node2-clusterip\n          passHostHeader: true\n          port: 80\n        - kind: Service\n          name: myservice-node3-clusterip\n          passHostHeader: true\n          port: 80\n        - kind: Service\n          name: myservice-node4-clusterip\n          passHostHeader: true\n          port: 80\n']
1695,13932,13929,CC BY-SA 4.0,2021-05-16T21:33:47.947,"<p>Try using this:- <a href=""https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/configmap/#use-forwarded-headers"" rel=""nofollow noreferrer"">use-forwarded-headers</a></p>
<pre><code>apiVersion: v1
kind: ConfigMap
data:
  use-forwarded-headers: &quot;true&quot;
metadata:
  name: nginx-configuration
  namespace: default
</code></pre>
",25999,2021-05-16T21:33:47.947,"['apiVersion: v1\nkind: ConfigMap\ndata:\n  use-forwarded-headers: ""true""\nmetadata:\n  name: nginx-configuration\n  namespace: default\n']"
1696,13941,13939,CC BY-SA 4.0,2021-05-17T21:20:32.470,"<p>If anyone comes across this later I resolved my issue by using an <code>initContainer</code> for any Pod that needed to write to the file system.</p>
<p>For example:</p>
<pre class=""lang-yaml prettyprint-override""><code>apiVersion: v1
kind: Pod
metadata:
  name: app3
spec:
  containers:
  - name: app3
    image: busybox
    command: [&quot;/bin/sh&quot;]
    args: [&quot;-c&quot;, &quot;while true; do echo $(date -u) &gt;&gt; /data/out3.txt; sleep 5; done&quot;]
    volumeMounts:
    - name: persistent-storage
      mountPath: /data
    securityContext:
      runAsGroup: 1337
  initContainers:
  - name: fs-owner-change
    image: busybox
    command:
    - chown
    - &quot;root:1337&quot;
    - &quot;/efs-fs&quot;
    volumeMounts
    - mountPath: /efs-fs
      name: cog-data
  securityContext:
    fsGroup: 1337
  volumes:
  - name: persistent-storage
    persistentVolumeClaim:
      claimName: efs-claim
</code></pre>
<p>The rest of the definitions match what was in my question.</p>
",27740,2021-05-17T21:20:32.470,"['apiVersion: v1\nkind: Pod\nmetadata:\n  name: app3\nspec:\n  containers:\n  - name: app3\n    image: busybox\n    command: [""/bin/sh""]\n    args: [""-c"", ""while true; do echo $(date -u) >> /data/out3.txt; sleep 5; done""]\n    volumeMounts:\n    - name: persistent-storage\n      mountPath: /data\n    securityContext:\n      runAsGroup: 1337\n  initContainers:\n  - name: fs-owner-change\n    image: busybox\n    command:\n    - chown\n    - ""root:1337""\n    - ""/efs-fs""\n    volumeMounts\n    - mountPath: /efs-fs\n      name: cog-data\n  securityContext:\n    fsGroup: 1337\n  volumes:\n  - name: persistent-storage\n    persistentVolumeClaim:\n      claimName: efs-claim\n']"
1697,13957,13956,CC BY-SA 4.0,2021-05-20T15:54:14.003,"<p>One option is to <a href=""https://docs.gitlab.com/ee/ci/variables/#pass-an-environment-variable-to-another-job"" rel=""nofollow noreferrer"">inherit your environment variable</a> from another job. You can create two different jobs, one to create the environment variable, and one to trigger the local CI pipeline.</p>
<p>Once all that is done, you should have something like this:</p>
<pre><code>stages:
  - build
  - deploy

nightlies_env:
  stage: build
  variables:
    BUILD_NAME: &quot;nightly&quot;
  script:
    - BUILD_NAME=&quot;${BUILD_NAME}-$(date +&quot;%Y%m%d&quot;)&quot;
    - echo &quot;BUILD_NAME=$BUILD_NAME&quot; &gt;&gt; build.env
  artifacts:
    reports:
      dotenv: build.env

nightlies:
  stage: deploy
  variables:
    BUILD_NAME: $BUILD_NAME
  trigger:
    include: build.yml
    strategy: depend
</code></pre>
",4328,2021-05-20T19:34:33.810,"['stages:\n  - build\n  - deploy\n\nnightlies_env:\n  stage: build\n  variables:\n    BUILD_NAME: ""nightly""\n  script:\n    - BUILD_NAME=""${BUILD_NAME}-$(date +""%Y%m%d"")""\n    - echo ""BUILD_NAME=$BUILD_NAME"" >> build.env\n  artifacts:\n    reports:\n      dotenv: build.env\n\nnightlies:\n  stage: deploy\n  variables:\n    BUILD_NAME: $BUILD_NAME\n  trigger:\n    include: build.yml\n    strategy: depend\n']"
1698,13959,13947,CC BY-SA 4.0,2021-05-20T17:47:36.670,"<p>You can update the daemon.json config to specify your normal syslog driver (assuming linux) to use the normal syslog logrotation method for keeping log files or shipping off-box</p>
<p><a href=""https://docs.docker.com/config/containers/logging/syslog/"" rel=""nofollow noreferrer"">https://docs.docker.com/config/containers/logging/syslog/</a></p>
<pre><code>{
  &quot;log-driver&quot;: &quot;syslog&quot;,
  &quot;log-opts&quot;: {
    &quot;syslog-address&quot;: &quot;udp://localhost:514&quot;
  }
}
</code></pre>
",323,2021-05-20T17:47:36.670,"['{\n  ""log-driver"": ""syslog"",\n  ""log-opts"": {\n    ""syslog-address"": ""udp://localhost:514""\n  }\n}\n']"
1699,13963,13947,CC BY-SA 4.0,2021-05-21T08:10:04.310,"<p>You can copy the actual logs from <code>/var/lib/docker/containers/&lt;container id&gt;/&lt;container id&gt;-json.log</code> to archive them then clear the logs manually (since you have only 2 services, influxdb and grafana). The containers won't stop with this procedure.</p>
<p>There is a <a href=""https://stackoverflow.com/a/42510314/3756843"">full and clear answer</a> on <a href=""https://stackoverflow.com/questions/42510002/how-to-clear-the-logs-properly-for-a-docker-container"">this StackOverflow question</a> about clearing container logs. It also explains how to configure the Docker daemon to rotate logs.</p>
<blockquote>
<p>From <a href=""https://serverfault.com/q/637996/351549"">this question</a> there's a one-liner that you can run:</p>
<pre><code>echo &quot;&quot; &gt; $(docker inspect --format='{{.LogPath}}' &lt;container_name_or_id&gt;)
</code></pre>
<p>[...]</p>
<p>You can also set this as part of your <a href=""https://docs.docker.com/engine/reference/commandline/dockerd/#on-linux"" rel=""nofollow noreferrer"">daemon.json</a> file instead of modifying your startup scripts:</p>
<pre><code>{
  &quot;log-driver&quot;: &quot;json-file&quot;,
  &quot;log-opts&quot;: {&quot;max-size&quot;: &quot;10m&quot;, &quot;max-file&quot;: &quot;3&quot;}
}
</code></pre>
<p>@BMitch - <a href=""https://stackoverflow.com/a/42510314/3756843"">https://stackoverflow.com/a/42510314/3756843</a></p>
</blockquote>
<p>As adviced, you should do this only until you configure the Docker daemon as your needs.</p>
",5058,2021-05-21T08:10:04.310,"['echo """" > $(docker inspect --format=\'{{.LogPath}}\' <container_name_or_id>)\n', '{\n  ""log-driver"": ""json-file"",\n  ""log-opts"": {""max-size"": ""10m"", ""max-file"": ""3""}\n}\n']"
1700,13966,13961,CC BY-SA 4.0,2021-05-21T18:20:09.453,"<p>You can use AWS CLI and run the below command to get details of all ec2 instances in your account.</p>
<pre><code>aws ec2 describe-instances
</code></pre>
<p>You can also use filters, if required. Please refer the <a href=""https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-instances.html"" rel=""nofollow noreferrer"">documentation</a>.</p>
",12138,2021-05-23T15:19:04.367,['aws ec2 describe-instances\n']
1701,13974,13970,CC BY-SA 4.0,2021-05-23T18:24:07.637,"<p><code>volumeMount</code> based on <code>configMap</code> actually creates the files for the data keys. You don't need the filename in the <code>mountPath</code> or the <code>subPath</code></p>
<pre class=""lang-bash prettyprint-override""><code>$ cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: v1
data:
  settings.conf: |
    test: config
    multi: line
kind: ConfigMap
metadata:
  name: test-config
---
apiVersion: v1
kind: Pod
metadata:
  name: dapi-test-pod
spec:
  containers:
    - name: test-container
      image: k8s.gcr.io/busybox
      command: [ &quot;/bin/sh&quot;, &quot;-c&quot;, &quot;ls /etc/config/&quot; ]
      volumeMounts:
      - name: config-volume
        mountPath: /etc/config
  restartPolicy: Never
  volumes:
    - name: config-volume
      configMap:
        name: test-config
EOF

$ kubectl logs dapi-test-pod
settings.conf
</code></pre>
<p>Ref:</p>
<ul>
<li><a href=""https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/"" rel=""nofollow noreferrer"">https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/</a></li>
</ul>
",11288,2021-05-24T02:06:40.983,"['$ cat <<EOF | kubectl apply -f -\napiVersion: v1\ndata:\n  settings.conf: |\n    test: config\n    multi: line\nkind: ConfigMap\nmetadata:\n  name: test-config\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: dapi-test-pod\nspec:\n  containers:\n    - name: test-container\n      image: k8s.gcr.io/busybox\n      command: [ ""/bin/sh"", ""-c"", ""ls /etc/config/"" ]\n      volumeMounts:\n      - name: config-volume\n        mountPath: /etc/config\n  restartPolicy: Never\n  volumes:\n    - name: config-volume\n      configMap:\n        name: test-config\nEOF\n\n$ kubectl logs dapi-test-pod\nsettings.conf\n']"
1702,13979,13978,CC BY-SA 4.0,2021-05-24T14:26:20.113,"<p>Kubernetes supports TCP, HTTP, and shell-exec <a href=""https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes"" rel=""nofollow noreferrer"">probes</a> for an application startup, readiness, and liveness <a href=""https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/"" rel=""nofollow noreferrer"">health checks</a>. If your application is a web application, you can use HTTP based liveness healthcheck as shown in the following code snippet:</p>
<pre class=""lang-yaml prettyprint-override""><code>apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-http
spec:
  containers:
  - name: liveness
    image: k8s.gcr.io/liveness
    args:
    - /server
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
      initialDelaySeconds: 3
      periodSeconds: 300
</code></pre>
",11288,2021-05-24T14:26:20.113,['apiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-http\nspec:\n  containers:\n  - name: liveness\n    image: k8s.gcr.io/liveness\n    args:\n    - /server\n    livenessProbe:\n      httpGet:\n        path: /healthz\n        port: 8080\n      initialDelaySeconds: 3\n      periodSeconds: 300\n']
1703,13985,13983,CC BY-SA 4.0,2021-05-25T09:40:13.633,"<p>I found a solution - the trick here is <em>delegate_to</em> and <em>delegate_facts</em>:</p>
<pre><code>- hosts: all
  remote_user: ansible
  become: false

  tasks:
  - name: read join line from controlPlane
    shell: kubeadm token create --print-join-command
    when: inventory_hostname in groups['workerNodes']
    register: joinCmd
    delegate_to: &quot;{{ item }}&quot;
    delegate_facts: true
    with_items: &quot;{{ groups['controlPlane'] }}&quot;

  - name: join all worker nodes to cluster
    command: &quot;{{ joinCmd.results[0].stdout }}&quot;
    become: yes
    when: inventory_hostname in groups['workerNodes']
</code></pre>
<p>The first task kind of reads backwards to my mind - <em>when</em> says 'run this task on all the  workerNode hosts...' but <em>delegate_to</em> says '..but actually run it on a different host'. It works for me though (I've only got 1 host in controlPlane group, not sure of outcome with more hosts).</p>
",27857,2021-05-25T09:40:13.633,"['- hosts: all\n  remote_user: ansible\n  become: false\n\n  tasks:\n  - name: read join line from controlPlane\n    shell: kubeadm token create --print-join-command\n    when: inventory_hostname in groups[\'workerNodes\']\n    register: joinCmd\n    delegate_to: ""{{ item }}""\n    delegate_facts: true\n    with_items: ""{{ groups[\'controlPlane\'] }}""\n\n  - name: join all worker nodes to cluster\n    command: ""{{ joinCmd.results[0].stdout }}""\n    become: yes\n    when: inventory_hostname in groups[\'workerNodes\']\n']"
1704,13988,13987,CC BY-SA 4.0,2021-05-25T14:36:48.930,"<h2>tl;dr</h2>
<p>You can execute the following to pin the public root key for <code>debian</code>:</p>
<pre><code>sudo su -
mkdir -p /root/.docker/trust/tuf/docker.io/library/debian/metadata
chown -R root:root /root/.docker
chmod -R 0700 /root/.docker
echo '{&quot;signed&quot;:{&quot;_type&quot;:&quot;Root&quot;,&quot;consistent_snapshot&quot;:false,&quot;expires&quot;:&quot;2025-08-07T20:55:22.677722315-07:00&quot;,&quot;keys&quot;:{&quot;5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a&quot;:{&quot;keytype&quot;:&quot;ecdsa&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEsslGF2xHOYztrocb2OsRF2zth16v170QiLAyKdce1nQgOJ34FOk679ClPL9/RNnJukf2JfQXSlVV/qcsvxV2dQ==&quot;}},&quot;575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84&quot;:{&quot;keytype&quot;:&quot;ecdsa-x509&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJlVENDQVIrZ0F3SUJBZ0lRWExkUFFHTGJaOE84UXFlTzVuZlBRekFLQmdncWhrak9QUVFEQWpBak1TRXcKSHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrWldKcFlXNHdIaGNOTVRVd09ERXhNRE0xTlRJeQpXaGNOTWpVd09EQTRNRE0xTlRJeVdqQWpNU0V3SHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrClpXSnBZVzR3V1RBVEJnY3Foa2pPUFFJQkJnZ3Foa2pPUFFNQkJ3TkNBQVE1ZGkxcmxPQjBMQmRNS2N0VFQxYmwKUGd6aXYxOUJDdW9tNEFNL3BUdURtdjBnS0E5S1ptNUVjLy9VQmhSODVCYmR0cTk0cXhQM3IwUjhRc3FQV1Y4SQpvelV3TXpBT0JnTlZIUThCQWY4RUJBTUNBS0F3RXdZRFZSMGxCQXd3Q2dZSUt3WUJCUVVIQXdNd0RBWURWUjBUCkFRSC9CQUl3QURBS0JnZ3Foa2pPUFFRREFnTklBREJGQWlBOUFOZ3dPN2tBdUVIK3U2N25XNlFLWmlMdWd5UVcKaEQ3Vys5WjIza01mTndJaEFJa3RTaW1TdFdRQkFoOG9WOXhjaWNVWWVUN0pyUG82a0RqeHU1YitGZ3MxCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K&quot;}},&quot;728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70&quot;:{&quot;keytype&quot;:&quot;ecdsa&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAENtpBkDJ2oYaAAVdOkP0A6J0XwUkYGuFRk+q8N4WCPu2VnNIuBJkatPCWdEtHfQ9nNYLeanWgG62/UmJnx3E2Yg==&quot;}},&quot;d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69&quot;:{&quot;keytype&quot;:&quot;ecdsa&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEwfs26T/cpjvNTXVJpK7Wv8oDOnNKL78AT3Y1QD356OIAggwPupX2LQjZU6CVzCjm+pkJIO4clu9Q2n540gKuzQ==&quot;}}},&quot;roles&quot;:{&quot;root&quot;:{&quot;keyids&quot;:[&quot;575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84&quot;],&quot;threshold&quot;:1},&quot;snapshot&quot;:{&quot;keyids&quot;:[&quot;d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69&quot;],&quot;threshold&quot;:1},&quot;targets&quot;:{&quot;keyids&quot;:[&quot;5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a&quot;],&quot;threshold&quot;:1},&quot;timestamp&quot;:{&quot;keyids&quot;:[&quot;728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70&quot;],&quot;threshold&quot;:1}},&quot;version&quot;:1},&quot;signatures&quot;:[{&quot;keyid&quot;:&quot;575d013f89e3cbbb19e0fb06aa33566c22718318e0c9f
fb1ab5cc4291e07bf84&quot;,&quot;method&quot;:&quot;ecdsa&quot;,&quot;sig&quot;:&quot;3WbX1VXN9E8LRmSG+E4SQlBUNqBNchhwAStWnRWLLyAOoFNBq5xmIgSO3UYYuKyJvL7kbMoONRbn5Vk2p2Wqrg==&quot;}]}' &gt; /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json

export DOCKER_CONTENT_TRUST=1
docker pull debian:stable-slim
</code></pre>
<h2>Long Answer</h2>
<blockquote>
<p>⚠ Disclaimer: I am not a docker developer. As of 2021, it appears that DCT is broken out-of-the-box and is far from being useful. My answer here is a best-guess, but I have not confirmed with the docker team if this is the &quot;correct&quot; way to pre-load and pin a given publisher's root key into the DCT keyring.</p>
<p>Be advised, proceed with caution, and your comments are very welcome.</p>
</blockquote>
<p>It doesn't appear to be documented anywhere, but per <a href=""https://security.stackexchange.com/questions/238916/how-to-pin-public-root-key-when-downloading-an-image-with-docker-pull-docker-co?noredirect=1&amp;lq=1"">this question</a> it's clear that docker puts its DCT metadata (including root public keys) in the following location:</p>
<pre><code>$HOME/.docker/trust/tuf/docker.io/library
</code></pre>
<p>Inside this <code>library</code> dir exists one dir per publisher. For the purposes of this answer, I'll use <code>debian</code> as our example publisher.</p>
<p>You can see the list of the <code>debian</code> docker images published to Docker Hub here:</p>
<ul>
<li><a href=""https://hub.docker.com/_/debian/"" rel=""nofollow noreferrer"">https://hub.docker.com/_/debian/</a></li>
</ul>
<h3>Solution</h3>
<p>Let's say we want to download the <code>stable-slim</code> image from the <code>debian</code> publisher on Docker Hub. In this example, we'll also use a fresh install of Debian 10 as the docker host.</p>
<pre><code>##
# first, install docker
## 
root@disp2716:~# apt-get install docker.io
...
root@disp2716:~#

##
# confirm that there is no docker config dir yet
##

root@disp2716:~# ls -lah /root/.docker
ls: cannot access '/root/.docker': No such file or directory
root@disp2716:~# 

##
# add the debian publisher's root DCT key
##

root@disp2716:~# mkdir -p /root/.docker/trust/tuf/docker.io/library/debian/metadata
root@disp2716:~# chown -R root:root /root/.docker
root@disp2716:~# chmod -R 0700 /root/.docker
root@disp2716:~# echo '{&quot;signed&quot;:{&quot;_type&quot;:&quot;Root&quot;,&quot;consistent_snapshot&quot;:false,&quot;expires&quot;:&quot;2025-08-07T20:55:22.677722315-07:00&quot;,&quot;keys&quot;:{&quot;5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a&quot;:{&quot;keytype&quot;:&quot;ecdsa&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEsslGF2xHOYztrocb2OsRF2zth16v170QiLAyKdce1nQgOJ34FOk679ClPL9/RNnJukf2JfQXSlVV/qcsvxV2dQ==&quot;}},&quot;575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84&quot;:{&quot;keytype&quot;:&quot;ecdsa-x509&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJlVENDQVIrZ0F3SUJBZ0lRWExkUFFHTGJaOE84UXFlTzVuZlBRekFLQmdncWhrak9QUVFEQWpBak1TRXcKSHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrWldKcFlXNHdIaGNOTVRVd09ERXhNRE0xTlRJeQpXaGNOTWpVd09EQTRNRE0xTlRJeVdqQWpNU0V3SHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrClpXSnBZVzR3V1RBVEJnY3Foa2pPUFFJQkJnZ3Foa2pPUFFNQkJ3TkNBQVE1ZGkxcmxPQjBMQmRNS2N0VFQxYmwKUGd6aXYxOUJDdW9tNEFNL3BUdURtdjBnS0E5S1ptNUVjLy9VQmhSODVCYmR0cTk0cXhQM3IwUjhRc3FQV1Y4SQpvelV3TXpBT0JnTlZIUThCQWY4RUJBTUNBS0F3RXdZRFZSMGxCQXd3Q2dZSUt3WUJCUVVIQXdNd0RBWURWUjBUCkFRSC9CQUl3QURBS0JnZ3Foa2pPUFFRREFnTklBREJGQWlBOUFOZ3dPN2tBdUVIK3U2N25XNlFLWmlMdWd5UVcKaEQ3Vys5WjIza01mTndJaEFJa3RTaW1TdFdRQkFoOG9WOXhjaWNVWWVUN0pyUG82a0RqeHU1YitGZ3MxCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K&quot;}},&quot;728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70&quot;:{&quot;keytype&quot;:&quot;ecdsa&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAENtpBkDJ2oYaAAVdOkP0A6J0XwUkYGuFRk+q8N4WCPu2VnNIuBJkatPCWdEtHfQ9nNYLeanWgG62/UmJnx3E2Yg==&quot;}},&quot;d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69&quot;:{&quot;keytype&quot;:&quot;ecdsa&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEwfs26T/cpjvNTXVJpK7Wv8oDOnNKL78AT3Y1QD356OIAggwPupX2LQjZU6CVzCjm+pkJIO4clu9Q2n540gKuzQ==&quot;}}},&quot;roles&quot;:{&quot;root&quot;:{&quot;keyids&quot;:[&quot;575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84&quot;],&quot;threshold&quot;:1},&quot;snapshot&quot;:{&quot;keyids&quot;:[&quot;d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69&quot;],&quot;threshold&quot;:1},&quot;targets&quot;:{&quot;keyids&quot;:[&quot;5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a&quot;],&quot;threshold&quot;:1},&quot;timestamp&quot;:{&quot;keyids&quot;:[&quot;728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70&quot;],&quot;threshold&quot;:1}},&quot;version&quot;:1},&quot;signatures&quot;:[{&quot;keyid&quot;:&quot;575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84&quot;,&quot;method&quot;:&quot;ecdsa&quot;,&quot;sig&quot;:&quot;3WbX1VXN9E8LRmSG+E4SQlBUNqBNchhwAStWnRWLLyAOoFNBq5xmIgSO3UYYuKyJvL7kbMoONRbn5Vk2p2Wqrg==&quot;}]}' &gt; /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json
root@disp2716:~# 
root@disp2716:~# chown root:root /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json
root@disp2716:~# chmod 0600 /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json
root@disp2716:~# 

##
# pull the docker image with DCT verification
##

root@disp2716:~# export DOCKER_CONTENT_TRUST=1
root@disp2716:~# docker pull debian:stable-slim
Pull (1 of 1): debian:stable-slim@sha256:850a7ee21c49c99b0e5e06df21f898a0e64335ae84eb37d6f71abc1bf28f5632
sha256:850a7ee21c49c99b0e5e06df21f898a0e64335ae84eb37d6f71abc1bf28f5632: Pulling from library/debian
6e640006d1cd: Pull complete 
Digest: sha256:850a7ee21c49c99b0e5e06df21f898a0e64335ae84eb37d6f71abc1bf28f5632
Status: Downloaded newer image for debian@sha256:850a7ee21c49c99b0e5e06df21f898a0e64335ae84eb37d6f71abc1bf28f5632
Tagging debian@sha256:850a7ee21c49c99b0e5e06df21f898a0e64335ae84eb37d6f71abc1bf28f5632 as debian:stable-slim
root@disp2716:~# 
</code></pre>
<h3>Proof</h3>
<p>While there's <a href=""https://github.com/docker/cli/issues/2752"" rel=""nofollow noreferrer"">no way to tell <code>docker</code> to fail on TOFU</a>, we can confirm that the above key pinning works by making the public key something else</p>
<pre><code>##
# first, move the docker config dir out of the way
## 

mv /root/.docker /root/.docker.bak

##
# add the debian publisher's root DCT key (note I just overwrote the first 8
# characters of the actual key with &quot;INVALID/&quot;)
##

root@disp2716:~# mkdir -p /root/.docker/trust/tuf/docker.io/library/debian/metadata
root@disp2716:~# chown -R root:root /root/.docker
root@disp2716:~# chmod -R 0700 /root/.docker
root@disp2716:~# echo '{&quot;signed&quot;:{&quot;_type&quot;:&quot;Root&quot;,&quot;consistent_snapshot&quot;:false,&quot;expires&quot;:&quot;2025-08-07T20:55:22.677722315-07:00&quot;,&quot;keys&quot;:{&quot;5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a&quot;:{&quot;keytype&quot;:&quot;ecdsa&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;INVALID/KoZIzj0CAQYIKoZIzj0DAQcDQgAEsslGF2xHOYztrocb2OsRF2zth16v170QiLAyKdce1nQgOJ34FOk679ClPL9/RNnJukf2JfQXSlVV/qcsvxV2dQ==&quot;}},&quot;575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84&quot;:{&quot;keytype&quot;:&quot;ecdsa-x509&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;INVALID/RUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJlVENDQVIrZ0F3SUJBZ0lRWExkUFFHTGJaOE84UXFlTzVuZlBRekFLQmdncWhrak9QUVFEQWpBak1TRXcKSHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrWldKcFlXNHdIaGNOTVRVd09ERXhNRE0xTlRJeQpXaGNOTWpVd09EQTRNRE0xTlRJeVdqQWpNU0V3SHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrClpXSnBZVzR3V1RBVEJnY3Foa2pPUFFJQkJnZ3Foa2pPUFFNQkJ3TkNBQVE1ZGkxcmxPQjBMQmRNS2N0VFQxYmwKUGd6aXYxOUJDdW9tNEFNL3BUdURtdjBnS0E5S1ptNUVjLy9VQmhSODVCYmR0cTk0cXhQM3IwUjhRc3FQV1Y4SQpvelV3TXpBT0JnTlZIUThCQWY4RUJBTUNBS0F3RXdZRFZSMGxCQXd3Q2dZSUt3WUJCUVVIQXdNd0RBWURWUjBUCkFRSC9CQUl3QURBS0JnZ3Foa2pPUFFRREFnTklBREJGQWlBOUFOZ3dPN2tBdUVIK3U2N25XNlFLWmlMdWd5UVcKaEQ3Vys5WjIza01mTndJaEFJa3RTaW1TdFdRQkFoOG9WOXhjaWNVWWVUN0pyUG82a0RqeHU1YitGZ3MxCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K&quot;}},&quot;728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70&quot;:{&quot;keytype&quot;:&quot;ecdsa&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;INVALID/KoZIzj0CAQYIKoZIzj0DAQcDQgAENtpBkDJ2oYaAAVdOkP0A6J0XwUkYGuFRk+q8N4WCPu2VnNIuBJkatPCWdEtHfQ9nNYLeanWgG62/UmJnx3E2Yg==&quot;}},&quot;d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69&quot;:{&quot;keytype&quot;:&quot;ecdsa&quot;,&quot;keyval&quot;:{&quot;private&quot;:null,&quot;public&quot;:&quot;INVALID/KoZIzj0CAQYIKoZIzj0DAQcDQgAEwfs26T/cpjvNTXVJpK7Wv8oDOnNKL78AT3Y1QD356OIAggwPupX2LQjZU6CVzCjm+pkJIO4clu9Q2n540gKuzQ==&quot;}}},&quot;roles&quot;:{&quot;root&quot;:{&quot;keyids&quot;:[&quot;575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84&quot;],&quot;threshold&quot;:1},&quot;snapshot&quot;:{&quot;keyids&quot;:[&quot;d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69&quot;],&quot;threshold&quot;:1},&quot;targets&quot;:{&quot;keyids&quot;:[&quot;5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a&quot;],&quot;threshold&quot;:1},&quot;timestamp&quot;:{&quot;keyids&quot;:[&quot;728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70&quot;],&quot;threshold&quot;:1}},&quot;version&quot;:1},&quot;signatures&quot;:[{&quot;keyid&quot;:&quot;575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84&quot;,&quot;method&quot;:&quot;ecdsa&quot;,&quot;sig&quot;:&quot;3WbX1VXN9E8LRmSG+E4SQlBUNqBNchhwAStWnRWLLyAOoFNBq5xmIgSO3UYYuKyJvL7kbMoONRbn5Vk2p2Wqrg==&quot;}]}' &gt; /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json
root@disp2716:~# 
root@disp2716:~# chown root:root /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json
root@disp2716:~# chmod 0600 /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json
root@disp2716:~# 

##
# pull the docker image with DCT verification
##

root@disp2716:~# export DOCKER_CONTENT_TRUST=1
root@disp2716:~# docker pull debian:stable-slim
could not validate the path to a trusted root: unable to retrieve valid leaf certificates
root@disp2716:~# 
root@disp2716:~# echo $?
1
root@disp2716:~# 
</code></pre>
<p>Note that docker exits 1 with an error refusing to pull the <code>debian:stable-slim</code> docker image from Docker Hub because it cannot trust its signature</p>
",22501,2021-05-25T15:20:46.387,"['sudo su -\nmkdir -p /root/.docker/trust/tuf/docker.io/library/debian/metadata\nchown -R root:root /root/.docker\nchmod -R 0700 /root/.docker\necho \'{""signed"":{""_type"":""Root"",""consistent_snapshot"":false,""expires"":""2025-08-07T20:55:22.677722315-07:00"",""keys"":{""5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a"":{""keytype"":""ecdsa"",""keyval"":{""private"":null,""public"":""MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEsslGF2xHOYztrocb2OsRF2zth16v170QiLAyKdce1nQgOJ34FOk679ClPL9/RNnJukf2JfQXSlVV/qcsvxV2dQ==""}},""575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84"":{""keytype"":""ecdsa-x509"",""keyval"":{""private"":null,""public"":""LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJlVENDQVIrZ0F3SUJBZ0lRWExkUFFHTGJaOE84UXFlTzVuZlBRekFLQmdncWhrak9QUVFEQWpBak1TRXcKSHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrWldKcFlXNHdIaGNOTVRVd09ERXhNRE0xTlRJeQpXaGNOTWpVd09EQTRNRE0xTlRJeVdqQWpNU0V3SHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrClpXSnBZVzR3V1RBVEJnY3Foa2pPUFFJQkJnZ3Foa2pPUFFNQkJ3TkNBQVE1ZGkxcmxPQjBMQmRNS2N0VFQxYmwKUGd6aXYxOUJDdW9tNEFNL3BUdURtdjBnS0E5S1ptNUVjLy9VQmhSODVCYmR0cTk0cXhQM3IwUjhRc3FQV1Y4SQpvelV3TXpBT0JnTlZIUThCQWY4RUJBTUNBS0F3RXdZRFZSMGxCQXd3Q2dZSUt3WUJCUVVIQXdNd0RBWURWUjBUCkFRSC9CQUl3QURBS0JnZ3Foa2pPUFFRREFnTklBREJGQWlBOUFOZ3dPN2tBdUVIK3U2N25XNlFLWmlMdWd5UVcKaEQ3Vys5WjIza01mTndJaEFJa3RTaW1TdFdRQkFoOG9WOXhjaWNVWWVUN0pyUG82a0RqeHU1YitGZ3MxCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K""}},""728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70"":{""keytype"":""ecdsa"",""keyval"":{""private"":null,""public"":""MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAENtpBkDJ2oYaAAVdOkP0A6J0XwUkYGuFRk+q8N4WCPu2VnNIuBJkatPCWdEtHfQ9nNYLeanWgG62/UmJnx3E2Yg==""}},""d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69"":{""keytype"":""ecdsa"",""keyval"":{""private"":null,""public"":""MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEwfs26T/cpjvNTXVJpK7Wv8oDOnNKL78AT3Y1QD356OIAggwPupX2LQjZU6CVzCjm+pkJIO4clu9Q2n540gKuzQ==""}}},""roles"":{""root"":{""keyids"":[""575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84""],""threshold"":1},""snapshot"":{""keyids"":[""d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69""],""threshold"":1},""targets"":{""keyids"":[""5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a""],""threshold"":1},""timestamp"":{""keyids"":[""728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70""],""threshold"":1}},""version"":1},""signatures"":[{""keyid"":""575d013f89e3cbbb19e0fb06aa33566c22718318e0c9f\nfb1ab5cc4291e07bf84"",""method"":""ecdsa"",""sig"":""3WbX1VXN9E8LRmSG+E4SQlBUNqBNchhwAStWnRWLLyAOoFNBq5xmIgSO3UYYuKyJvL7kbMoONRbn5Vk2p2Wqrg==""}]}\' > /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json\n\nexport DOCKER_CONTENT_TRUST=1\ndocker pull debian:stable-slim\n', '$HOME/.docker/trust/tuf/docker.io/library\n', '##\n# first, install docker\n## \nroot@disp2716:~# apt-get install docker.io\n...\nroot@disp2716:~#\n\n##\n# confirm that there is no docker config dir yet\n##\n\nroot@disp2716:~# ls -lah /root/.docker\nls: cannot access \'/root/.docker\': No such file or directory\nroot@disp2716:~# \n\n##\n# add the debian publisher\'s root DCT key\n##\n\nroot@disp2716:~# mkdir -p /root/.docker/trust/tuf/docker.io/library/debian/metadata\nroot@disp2716:~# chown -R root:root /root/.docker\nroot@disp2716:~# chmod -R 0700 /root/.docker\nroot@disp2716:~# echo \'{""signed"":{""_type"":""Root"",""consistent_snapshot"":false,""expires"":""2025-08-07T20:55:22.677722315-07:00"",""keys"":{""5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a"":{""keytype"":""ecdsa"",""keyval"":{""private"":null,""public"":""MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEsslGF2xHOYztrocb2OsRF2zth16v170QiLAyKdce1nQgOJ34FOk679ClPL9/RNnJukf2JfQXSlVV/qcsvxV2dQ==""}},""575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84"":{""keytype"":""ecdsa-x509"",""keyval"":{""private"":null,""public"":""LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJlVENDQVIrZ0F3SUJBZ0lRWExkUFFHTGJaOE84UXFlTzVuZlBRekFLQmdncWhrak9QUVFEQWpBak1TRXcKSHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrWldKcFlXNHdIaGNOTVRVd09ERXhNRE0xTlRJeQpXaGNOTWpVd09EQTRNRE0xTlRJeVdqQWpNU0V3SHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrClpXSnBZVzR3V1RBVEJnY3Foa2pPUFFJQkJnZ3Foa2pPUFFNQkJ3TkNBQVE1ZGkxcmxPQjBMQmRNS2N0VFQxYmwKUGd6aXYxOUJDdW9tNEFNL3BUdURtdjBnS0E5S1ptNUVjLy9VQmhSODVCYmR0cTk0cXhQM3IwUjhRc3FQV1Y4SQpvelV3TXpBT0JnTlZIUThCQWY4RUJBTUNBS0F3RXdZRFZSMGxCQXd3Q2dZSUt3WUJCUVVIQXdNd0RBWURWUjBUCkFRSC9CQUl3QURBS0JnZ3Foa2pPUFFRREFnTklBREJGQWlBOUFOZ3dPN2tBdUVIK3U2N25XNlFLWmlMdWd5UVcKaEQ3Vys5WjIza01mTndJaEFJa3RTaW1TdFdRQkFoOG9WOXhjaWNVWWVUN0pyUG82a0RqeHU1YitGZ3MxCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K""}},""728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70"":{""keytype"":""ecdsa"",""keyval"":{""private"":null,""public"":""MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAENtpBkDJ2oYaAAVdOkP0A6J0XwUkYGuFRk+q8N4WCPu2VnNIuBJkatPCWdEtHfQ9nNYLeanWgG62/UmJnx3E2Yg==""}},""d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69"":{""keytype"":""ecdsa"",""keyval"":{""private"":null,""public"":""MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEwfs26T/cpjvNTXVJpK7Wv8oDOnNKL78AT3Y1QD356OIAggwPupX2LQjZU6CVzCjm+pkJIO4clu9Q2n540gKuzQ==""}}},""roles"":{""root"":{""keyids"":[""575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84""],""threshold"":1},""snapshot"":{""keyids"":[""d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69""],""threshold"":1},""targets"":{""keyids"":[""5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a""],""threshold"":1},""timestamp"":{""keyids"":[""728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70""],""threshold"":1}},""version"":1},""signatures"":[{""keyid"":""575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84"",""method"":""ecdsa"",""sig"":""3WbX1VXN9E8LRmSG+E4SQlBUNqBNchhwAStWnRWLLyAOoFNBq5xmIgSO3UYYuKyJvL7kbMoONRbn5Vk2p2Wqrg==""}]}\' > /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json\nroot@disp2716:~# \nroot@disp2716:~# chown root:root /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json\nroot@disp2716:~# chmod 0600 /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json\nroot@disp2716:~# \n\n##\n# pull the docker image with DCT verification\n##\n\nroot@disp2716:~# export DOCKER_CONTENT_TRUST=1\nroot@disp2716:~# docker pull debian:stable-slim\nPull (1 of 1): debian:stable-slim@sha256:850a7ee21c49c99b0e5e06df21f898a0e64335ae84eb37d6f71abc1bf28f5632\nsha256:850a7ee21c49c99b0e5e06df21f898a0e64335ae84eb37d6f71abc1bf28f5632: Pulling from library/debian\n6e640006d1cd: Pull complete \nDigest: sha256:850a7ee21c49c99b0e5e06df21f898a0e64335ae84eb37d6f71abc1bf28f5632\nStatus: Downloaded newer image for debian@sha256:850a7ee21c49c99b0e5e06df21f898a0e64335ae84eb37d6f71abc1bf28f5632\nTagging debian@sha256:850a7ee21c49c99b0e5e06df21f898a0e64335ae84eb37d6f71abc1bf28f5632 as debian:stable-slim\nroot@disp2716:~# \n', '##\n# first, move the docker config dir out of the way\n## \n\nmv /root/.docker /root/.docker.bak\n\n##\n# add the debian publisher\'s root DCT key (note I just overwrote the first 8\n# characters of the actual key with ""INVALID/"")\n##\n\nroot@disp2716:~# mkdir -p /root/.docker/trust/tuf/docker.io/library/debian/metadata\nroot@disp2716:~# chown -R root:root /root/.docker\nroot@disp2716:~# chmod -R 0700 /root/.docker\nroot@disp2716:~# echo \'{""signed"":{""_type"":""Root"",""consistent_snapshot"":false,""expires"":""2025-08-07T20:55:22.677722315-07:00"",""keys"":{""5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a"":{""keytype"":""ecdsa"",""keyval"":{""private"":null,""public"":""INVALID/KoZIzj0CAQYIKoZIzj0DAQcDQgAEsslGF2xHOYztrocb2OsRF2zth16v170QiLAyKdce1nQgOJ34FOk679ClPL9/RNnJukf2JfQXSlVV/qcsvxV2dQ==""}},""575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84"":{""keytype"":""ecdsa-x509"",""keyval"":{""private"":null,""public"":""INVALID/RUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJlVENDQVIrZ0F3SUJBZ0lRWExkUFFHTGJaOE84UXFlTzVuZlBRekFLQmdncWhrak9QUVFEQWpBak1TRXcKSHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrWldKcFlXNHdIaGNOTVRVd09ERXhNRE0xTlRJeQpXaGNOTWpVd09EQTRNRE0xTlRJeVdqQWpNU0V3SHdZRFZRUURFeGhrYjJOclpYSXVhVzh2YkdsaWNtRnllUzlrClpXSnBZVzR3V1RBVEJnY3Foa2pPUFFJQkJnZ3Foa2pPUFFNQkJ3TkNBQVE1ZGkxcmxPQjBMQmRNS2N0VFQxYmwKUGd6aXYxOUJDdW9tNEFNL3BUdURtdjBnS0E5S1ptNUVjLy9VQmhSODVCYmR0cTk0cXhQM3IwUjhRc3FQV1Y4SQpvelV3TXpBT0JnTlZIUThCQWY4RUJBTUNBS0F3RXdZRFZSMGxCQXd3Q2dZSUt3WUJCUVVIQXdNd0RBWURWUjBUCkFRSC9CQUl3QURBS0JnZ3Foa2pPUFFRREFnTklBREJGQWlBOUFOZ3dPN2tBdUVIK3U2N25XNlFLWmlMdWd5UVcKaEQ3Vys5WjIza01mTndJaEFJa3RTaW1TdFdRQkFoOG9WOXhjaWNVWWVUN0pyUG82a0RqeHU1YitGZ3MxCi0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K""}},""728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70"":{""keytype"":""ecdsa"",""keyval"":{""private"":null,""public"":""INVALID/KoZIzj0CAQYIKoZIzj0DAQcDQgAENtpBkDJ2oYaAAVdOkP0A6J0XwUkYGuFRk+q8N4WCPu2VnNIuBJkatPCWdEtHfQ9nNYLeanWgG62/UmJnx3E2Yg==""}},""d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69"":{""keytype"":""ecdsa"",""keyval"":{""private"":null,""public"":""INVALID/KoZIzj0CAQYIKoZIzj0DAQcDQgAEwfs26T/cpjvNTXVJpK7Wv8oDOnNKL78AT3Y1QD356OIAggwPupX2LQjZU6CVzCjm+pkJIO4clu9Q2n540gKuzQ==""}}},""roles"":{""root"":{""keyids"":[""575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84""],""threshold"":1},""snapshot"":{""keyids"":[""d48327d85f0490827db7c931eedb58d293e1da5fc425ea0cde3e6c13b397ad69""],""threshold"":1},""targets"":{""keyids"":[""5717dcd81d9fb5b73aa15f2d887a6a0de543829ab9b2d411acce9219c2f8ba3a""],""threshold"":1},""timestamp"":{""keyids"":[""728c96ff5e9f48d4e66d5a0c3ecabfdd90bee2b5f9f80b950ed9c668db264a70""],""threshold"":1}},""version"":1},""signatures"":[{""keyid"":""575d013f89e3cbbb19e0fb06aa33566c22718318e0c9ffb1ab5cc4291e07bf84"",""method"":""ecdsa"",""sig"":""3WbX1VXN9E8LRmSG+E4SQlBUNqBNchhwAStWnRWLLyAOoFNBq5xmIgSO3UYYuKyJvL7kbMoONRbn5Vk2p2Wqrg==""}]}\' > /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json\nroot@disp2716:~# \nroot@disp2716:~# chown root:root /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json\nroot@disp2716:~# chmod 0600 /root/.docker/trust/tuf/docker.io/library/debian/metadata/root.json\nroot@disp2716:~# \n\n##\n# pull the docker image with DCT verification\n##\n\nroot@disp2716:~# export DOCKER_CONTENT_TRUST=1\nroot@disp2716:~# docker pull debian:stable-slim\ncould not validate the path to a trusted root: unable to retrieve valid leaf certificates\nroot@disp2716:~# \nroot@disp2716:~# echo $?\n1\nroot@disp2716:~# \n']"
1705,14014,14013,CC BY-SA 4.0,2021-05-28T14:55:36.060,"<p>I figured it out. The stub resource has to have a provider that is configured with the proper AWS region. All these security groups were in us-west-2. You need this:</p>
<pre><code>resource &quot;aws_security_group&quot; &quot;rds-launch-wizard-2&quot; { provider = aws.us_west_2 }
</code></pre>
<p>instead of this:</p>
<pre><code>resource &quot;aws_security_group&quot; &quot;rds-launch-wizard-2&quot; {}
</code></pre>
<p>This assumes you have a provider already configured thus:</p>
<pre><code>provider &quot;aws&quot; {
  region  = &quot;us-west-2&quot;
  alias   = &quot;us_west_2&quot;
}
</code></pre>
",27706,2021-05-28T14:55:36.060,"['resource ""aws_security_group"" ""rds-launch-wizard-2"" { provider = aws.us_west_2 }\n', 'resource ""aws_security_group"" ""rds-launch-wizard-2"" {}\n', 'provider ""aws"" {\n  region  = ""us-west-2""\n  alias   = ""us_west_2""\n}\n']"
